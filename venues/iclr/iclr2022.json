[
    {
        "id": "-0Cjhnl-dhK",
        "title": "Towards Uncertainties in Deep Learning that Are Accurate and Calibrated",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "3;4;2;3",
        "correctness": "2;3;1;2",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.0,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "-0LuSWi6j4",
        "title": "Mind Your Bits and Errors: Prioritizing the Bits that Matter in Variational Autoencoders",
        "track": "main",
        "status": "Reject",
        "keywords": "deep generative models;variational autoencoders",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5;6",
        "confidence": "4;4;4;4;3",
        "correctness": "2;2;2;4;3",
        "technical_novelty": "3;2;3;2;3",
        "empirical_novelty": "2;2;4;2;4",
        "presentation": "",
        "rating_avg": 4.4,
        "confidence_avg": 3.8,
        "correctness_avg": 2.6,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 2.8,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6666666666666666,
        "corr_rating_correctness": 0.5833333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "-0qmvlqnVw4",
        "title": "How Frequency Effect Graph Neural Networks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "graph neural networks",
        "author": "",
        "aff": "",
        "rating": "1;3;3;3",
        "confidence": "5;4;4;4",
        "correctness": "2;3;3;2",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;0",
        "presentation": "",
        "rating_avg": 2.5,
        "confidence_avg": 4.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "-29uFS4FiDZ",
        "title": "Word Sense Induction with Knowledge Distillation from BERT",
        "track": "main",
        "status": "Reject",
        "keywords": "word embeddings;sense embeddings;word sense induction",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6;6",
        "confidence": "4;5;4;3;3",
        "correctness": "2;3;3;3;4",
        "technical_novelty": "3;1;3;3;4",
        "empirical_novelty": "3;2;2;3;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.8,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.8,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.48795003647426666,
        "corr_rating_correctness": 0.8660254037844387,
        "project": "",
        "github": ""
    },
    {
        "id": "-3Qj7Jl6UP5",
        "title": "The magnitude vector of images",
        "track": "main",
        "status": "Reject",
        "keywords": "magnitude;magnitude vector;edge detection;adversarial robustness;metric space;algebraic topology",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "4;3;3;4",
        "correctness": "3;3;3;2",
        "technical_novelty": "1;3;2;2",
        "empirical_novelty": "2;3;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "-3yxxvDis3L",
        "title": "How to Improve Sample Complexity of SGD over Highly Dependent Data?",
        "track": "main",
        "status": "Reject",
        "keywords": "Dependent data sampling;SGD;sample complexity",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "5;3;4;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "1;2;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6488856845230502,
        "corr_rating_correctness": 0.6882472016116854,
        "project": "",
        "github": ""
    },
    {
        "id": "-4hMlsXK4st",
        "title": "Improving Robustness with Optimal Transport based Adversarial Generalization",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Optimal Transport;Adversarial Machine Learning;Adversarial Training",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5;6",
        "confidence": "4;4;4;2;4",
        "correctness": "3;3;4;3;3",
        "technical_novelty": "2;2;2;2;3",
        "empirical_novelty": "2;2;0;4;3",
        "presentation": "",
        "rating_avg": 5.2,
        "confidence_avg": 3.6,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.2,
        "empirical_novelty_avg": 2.2,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.25,
        "corr_rating_correctness": -0.25000000000000006,
        "project": "",
        "github": ""
    },
    {
        "id": "-6me0AsJVdu",
        "title": "Model Validation Using Mutated Training Labels: An Exploratory Study",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "Under double-blind review",
        "rating": "3;5;6;8",
        "confidence": "4;4;3;4",
        "correctness": "2;2;4;3",
        "technical_novelty": "2;3;3;4",
        "empirical_novelty": "3;2;4;4",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.16012815380508713,
        "corr_rating_correctness": 0.5853694070049635,
        "project": "",
        "github": ""
    },
    {
        "id": "-70L8lpp9DF",
        "title": "Hyperparameter Tuning with Renyi Differential Privacy",
        "track": "main",
        "status": "Oral",
        "keywords": "differential privacy;hyperparameter tuning",
        "author": "",
        "aff": "Google Research, Brain Team",
        "rating": "6;8;8;10",
        "confidence": "4;3;3;5",
        "correctness": "4;3;4;4",
        "technical_novelty": "3;4;3;4",
        "empirical_novelty": "3;3;3;4",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.5,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.4264014327112209,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "-7NOEQcD-xH",
        "title": "Deep Ensemble Policy Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "5;5;3;4",
        "correctness": "4;4;3;3",
        "technical_novelty": "3;2;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9045340337332909,
        "corr_rating_correctness": -1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "-7UeX2KPqs",
        "title": "State-Action Joint Regularized Implicit Policy for Offline Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Implicit Policy;State-action Visitation;Distribution Matching;Generative Adversarial Networks",
        "author": "",
        "aff": "",
        "rating": "3;6;6",
        "confidence": "4;4;4",
        "correctness": "2;3;3",
        "technical_novelty": "2;3;2",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "-7usTUgt7N",
        "title": "Implicit vs Unfolded Graph Neural Networks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;3;3;3",
        "correctness": "2;3;4;3",
        "technical_novelty": "1;2;3;3",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "-8sBpe7rDiV",
        "title": "NETWORK INSENSITIVITY TO PARAMETER NOISE VIA PARAMETER ATTACK DURING TRAINING",
        "track": "main",
        "status": "Poster",
        "keywords": "parameter attack;adversarial attack;neural network;deep learning;optimisation;neuromorphic processor",
        "author": "",
        "aff": "IBM Research - Zurich, SynSense, Z\u00fcrich, Switzerland, ETH Z\u00fcrich, Switzerland; ETH Z\u00fcrich, Switzerland; SynSense, Z\u00fcrich, Switzerland",
        "rating": "6;6;8",
        "confidence": "2;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "-9ffJ9NQmal",
        "title": "VICE: Variational Inference for Concept Embeddings",
        "track": "main",
        "status": "Reject",
        "keywords": "cognitive science;variational Bayes;category representation;sparse coding;representation learning;interpretable representations",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "4;3;3;3",
        "correctness": "2;4;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;1;2;2",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5555555555555555,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "-9uy3c7b_ks",
        "title": "Learning Controllable Elements Oriented Representations for Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "reinforcement learning;representation learning;mutual information",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "4;4;4;3",
        "correctness": "3;3;2;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "-AOEi-5VTU8",
        "title": "Fast Differentiable Matrix Square Root",
        "track": "main",
        "status": "Poster",
        "keywords": "Differentiabl Matrix Square Root;Differentiable Matrix Decomposition;Vision Transformers",
        "author": "",
        "aff": "Department of Information Engineering and Computer Science (DISI), University of Trento, Trento, TN 38123, Italy",
        "rating": "8;8;8",
        "confidence": "4;5;4",
        "correctness": "4;3;4",
        "technical_novelty": "3;3;2",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/KingJamesSong/FastDifferentiableMatSqrt"
    },
    {
        "id": "-AW3SFO63GO",
        "title": "Dissecting Local Properties of Adversarial Examples",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "1;3;3",
        "confidence": "4;4;3",
        "correctness": "2;3;3",
        "technical_novelty": "1;2;2",
        "empirical_novelty": "1;2;2",
        "presentation": "",
        "rating_avg": 2.3333333333333335,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 1.6666666666666667,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "-AY7C3f26C_",
        "title": "Rethinking Deep Face Restoration",
        "track": "main",
        "status": "Withdraw",
        "keywords": "face restoration;generative model",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "5;4;5;4",
        "correctness": "3;2;2;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.40824829046386296,
        "corr_rating_correctness": -0.40824829046386296,
        "project": "",
        "github": ""
    },
    {
        "id": "-ApAkox5mp",
        "title": "SHINE: SHaring the INverse Estimate from the forward pass for bi-level optimization and implicit models",
        "track": "main",
        "status": "Spotlight",
        "keywords": "implicit models;bi-level optimization;quasi-newton methods",
        "author": "",
        "aff": "Carnegie Mellon University, Pittsburgh, USA; Inria (Parietal), Gif-sur-Yvette, France; AIM, CEA, CNRS, Gif-sur-Yvette, France; University of Graz, Graz, Austria; CEA (Neurospin & Cosmostat), Inria (Parietal), Gif-sur-Yvette, France; CEA (Neurospin), Inria (Parietal), Gif-sur-Yvette, France",
        "rating": "8;8;8",
        "confidence": "3;3;3",
        "correctness": "4;3;4",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "-BBL3b4Tqfo",
        "title": "Modeling Unknown Semantic Labels as Uncertainty in the Prediction: Evidential Deep Learning for Class-Incremental Semantic Segmentation",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Class-Incremental Learning;Semantic Segmentation;Evidential Deep Learrning;Deep Neural Networks;Class-Incremental Semantic Segmentation;Continual-Learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;4;4",
        "correctness": "2;3;4;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "1;2;0;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.7071067811865475,
        "project": "",
        "github": ""
    },
    {
        "id": "-BTmxCddppP",
        "title": "Revisiting Out-of-Distribution Detection: A Simple Baseline is Surprisingly Effective",
        "track": "main",
        "status": "Reject",
        "keywords": "out-of-distribution detection;robustness;OOD",
        "author": "",
        "aff": "",
        "rating": "3;6;6;8;10",
        "confidence": "2;4;4;2;3",
        "correctness": "2;3;3;4;4",
        "technical_novelty": "2;2;3;3;4",
        "empirical_novelty": "2;2;2;3;0",
        "presentation": "",
        "rating_avg": 6.6,
        "confidence_avg": 3.0,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.8,
        "empirical_novelty_avg": 1.8,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0958706236059213,
        "corr_rating_correctness": 0.9625334218796219,
        "project": "",
        "github": ""
    },
    {
        "id": "-FP1-bBxOzv",
        "title": "Self Reward Design with Fine-grained Interpretability",
        "track": "main",
        "status": "Reject",
        "keywords": "Reinforcement Learning;Interpretability;Explainable Artificial Intelligence;Neural Networks",
        "author": "",
        "aff": "",
        "rating": "1;1;1;3;3",
        "confidence": "3;4;4;2;4",
        "correctness": "2;2;1;2;2",
        "technical_novelty": "1;2;1;2;2",
        "empirical_novelty": "2;1;1;2;0",
        "presentation": "",
        "rating_avg": 1.8,
        "confidence_avg": 3.4,
        "correctness_avg": 1.8,
        "technical_novelty_avg": 1.6,
        "empirical_novelty_avg": 1.2,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.408248290463863,
        "corr_rating_correctness": 0.408248290463863,
        "project": "",
        "github": ""
    },
    {
        "id": "-GU1sfGnM5K",
        "title": "A Reinforcement Learning Environment for Mathematical Reasoning via Program Synthesis",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "1;3;5",
        "confidence": "4;4;4",
        "correctness": "2;2;3",
        "technical_novelty": "1;2;3",
        "empirical_novelty": "1;2;3",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.8660254037844385,
        "project": "",
        "github": ""
    },
    {
        "id": "-Gk_IPJWvk",
        "title": "Top-N: Equivariant Set and Graph Generation without Exchangeability",
        "track": "main",
        "status": "Poster",
        "keywords": "set generation;graph generation;permutation equivariance;generative models;Top-N",
        "author": "",
        "aff": "LTS4, EPFL, Lausanne, Switzerland",
        "rating": "5;6;6;8",
        "confidence": "4;3;4;4",
        "correctness": "2;3;3;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;2;2",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.13245323570650439,
        "corr_rating_correctness": 0.9733285267845754,
        "project": "",
        "github": ""
    },
    {
        "id": "-H48S9ePSUC",
        "title": "Fundamental Limits of Transfer Learning in Binary Classifications",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6;6",
        "confidence": "4;3;2;2;4",
        "correctness": "2;3;3;3;3",
        "technical_novelty": "2;2;2;3;3",
        "empirical_novelty": "2;1;3;2;3",
        "presentation": "",
        "rating_avg": 5.2,
        "confidence_avg": 3.0,
        "correctness_avg": 2.8,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 2.2,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5752237416355278,
        "corr_rating_correctness": 0.9432422182837988,
        "project": "",
        "github": ""
    },
    {
        "id": "-HSOjDPfhBJ",
        "title": "PER-ETD: A Polynomially Efficient Emphatic Temporal Difference Learning Method",
        "track": "main",
        "status": "Poster",
        "keywords": "emphatic temporal difference;finite-time analysis;off-policy evaluation;reinforcement learning",
        "author": "",
        "aff": "Department of Electrical and Computer Engineering, Ohio State University, Columbus, OH 43210, USA",
        "rating": "8;8;8;8",
        "confidence": "3;3;3;3",
        "correctness": "4;3;4;4",
        "technical_novelty": "3;3;4;4",
        "empirical_novelty": "3;3;2;2",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "-JW-1Fg-v2",
        "title": "Language-Guided Image Clustering",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Clustering",
        "author": "",
        "aff": "",
        "rating": "3;5;6",
        "confidence": "3;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.7559289460184545,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "-NefWT-x2xE",
        "title": "DYNASHARE: DYNAMIC NEURAL NETWORKS FOR MULTI-TASK LEARNING",
        "track": "main",
        "status": "Withdraw",
        "keywords": "multi-task learning;dynamic networks;adaptive inference;neural network",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3;3",
        "confidence": "4;4;4;4;5",
        "correctness": "2;3;2;3;2",
        "technical_novelty": "3;2;3;1;3",
        "empirical_novelty": "3;3;2;1;1",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.2,
        "correctness_avg": 2.4,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "-Nf6TikpjQ",
        "title": "Multi-agent Performative Prediction: From Global Stability and Optimality to Chaos",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "6;6;6",
        "confidence": "4;3;3",
        "correctness": "4;3;4",
        "technical_novelty": "2;3;2",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "-O_9iYmcbZm",
        "title": "Zero-Round Active Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;4;4;5",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "-RAFyM-YPj",
        "title": "Counting Substructures with Higher-Order Graph Neural Networks: Possibility and Impossibility Results",
        "track": "main",
        "status": "Reject",
        "keywords": "graph neural networks;expressive power;complexity",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6;6",
        "confidence": "3;3;4;3;5",
        "correctness": "3;3;3;3;4",
        "technical_novelty": "3;3;3;3;4",
        "empirical_novelty": "2;0;2;2;2",
        "presentation": "",
        "rating_avg": 5.6,
        "confidence_avg": 3.6,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 3.2,
        "empirical_novelty_avg": 1.6,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.6123724356957945,
        "corr_rating_correctness": 0.408248290463863,
        "project": "",
        "github": ""
    },
    {
        "id": "-TSe5o7STVR",
        "title": "Non-Parallel Text Style Transfer with Self-Parallel Supervision",
        "track": "main",
        "status": "Poster",
        "keywords": "style transfer;non-parallel corpus;imitation learning;language models;political stance transfer",
        "author": "",
        "aff": "University of California, Los Angeles; Northwestern University; Dartmouth College; University of Texas, Austin",
        "rating": "3;6;6;8;8",
        "confidence": "4;3;5;4;4",
        "correctness": "3;3;3;4;3",
        "technical_novelty": "2;2;3;3;3",
        "empirical_novelty": "3;3;2;3;3",
        "presentation": "",
        "rating_avg": 6.2,
        "confidence_avg": 4.0,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 2.8,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.4909902530309828,
        "project": "",
        "github": ""
    },
    {
        "id": "-Txy_1wHJ4f",
        "title": "Safe Deep RL in 3D Environments using Human Feedback",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5",
        "confidence": "4;3;3",
        "correctness": "4;3;4",
        "technical_novelty": "1;2;2",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 4.333333333333333,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 1.6666666666666667,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9999999999999998,
        "corr_rating_correctness": -0.49999999999999983,
        "project": "",
        "github": ""
    },
    {
        "id": "-VsGCG_AQ69",
        "title": "MARNET: Backdoor Attacks against Value-Decomposition Multi-Agent Reinforcement Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Backdoor Attacks;Multi-Agent Reinforcement Learning",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "3;4;3;2",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;1;3",
        "empirical_novelty": "2;0;1;3",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.816496580927726,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "-YAqAIsxr7v",
        "title": "OVD-Explorer: A General Information-theoretic Exploration Approach for Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Exploration;Uncertainty;Reinforcement Learning",
        "author": "",
        "aff": "",
        "rating": "3;3;6;6",
        "confidence": "3;3;3;3",
        "correctness": "2;2;2;3",
        "technical_novelty": "2;1;3;3",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.0,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896258,
        "project": "",
        "github": ""
    },
    {
        "id": "-_1NWqlnaGH",
        "title": "A Compositional Approach to Occlusion in Panoptic Segmentation",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "4;4;3;5",
        "correctness": "3;2;1;2",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;1;1;3",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "-bV96qRQuz",
        "title": "Ranking Convolutional Architectures by their Feature Extraction Capabilities",
        "track": "main",
        "status": "Withdraw",
        "keywords": "AutoML;NAS;Neural Architecture Search;Ranking",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;4;5;4",
        "correctness": "3;2;3;3",
        "technical_novelty": "1;2;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "-cII-Vju5C",
        "title": "Orthogonalising gradients to speedup neural network optimisation",
        "track": "main",
        "status": "Reject",
        "keywords": "machine learning;deep learning;orthogonalisation;optmisation;optimization",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "4;5;4;5",
        "correctness": "2;2;2;2",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.5,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "-dzXGe2FyW6",
        "title": "Equalized Robustness: Towards Sustainable Fairness Under Distributional Shifts",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;6;8",
        "confidence": "4;4;2;3",
        "correctness": "3;2;3;3",
        "technical_novelty": "2;2;3;4",
        "empirical_novelty": "1;2;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7106690545187014,
        "corr_rating_correctness": 0.5443310539518174,
        "project": "",
        "github": ""
    },
    {
        "id": "-e4EXDWXnSn",
        "title": "Invariant Causal Representation Learning for Out-of-Distribution Generalization",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "1University of Cambridge, 2MPI for Intelligent Systems; 1University of Cambridge, 5The Alan Turing Institute; 2MPI for Intelligent Systems; 3Stanford University, 4Google Research",
        "rating": "6;6;8",
        "confidence": "3;3;3",
        "correctness": "3;3;4",
        "technical_novelty": "3;3;4",
        "empirical_novelty": "3;3;4",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.3333333333333335,
        "empirical_novelty_avg": 3.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9999999999999998,
        "project": "",
        "github": ""
    },
    {
        "id": "-e7awdzWsOc",
        "title": "Towards Structured Dynamic Sparse Pre-Training of BERT",
        "track": "main",
        "status": "Reject",
        "keywords": "sparsity;natural language processing;pre-training;computational efficiency",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5;6",
        "confidence": "4;4;3;4;2",
        "correctness": "3;3;3;2;3",
        "technical_novelty": "1;2;2;2;2",
        "empirical_novelty": "2;2;2;3;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.4,
        "correctness_avg": 2.8,
        "technical_novelty_avg": 1.8,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5929270612815711,
        "corr_rating_correctness": -0.3952847075210474,
        "project": "",
        "github": ""
    },
    {
        "id": "-fORBF5k2ZB",
        "title": "Gating Mechanisms Underlying Sequence-to-Sequence Working Memory",
        "track": "main",
        "status": "Reject",
        "keywords": "Working Memory;RNN;Dynamical Systems;Slow Manifold;Gating",
        "author": "",
        "aff": "",
        "rating": "3;6;6;8",
        "confidence": "4;3;4;3",
        "correctness": "4;3;3;4",
        "technical_novelty": "1;3;2;3",
        "empirical_novelty": "1;1;3;4",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7001400420140049,
        "corr_rating_correctness": -0.14002800840280097,
        "project": "",
        "github": ""
    },
    {
        "id": "-geBFMKGlkq",
        "title": "Density-based Clustering with Kernel Diffusion",
        "track": "main",
        "status": "Reject",
        "keywords": "density-based clustering;diffusion process;density function;face clustering",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "3;5;4;4",
        "correctness": "2;3;2;2",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "3;2;2;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 4.0,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.816496580927726,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "-h5rboREox7",
        "title": "Double Descent in Adversarial Training: An Implicit Label Noise Perspective",
        "track": "main",
        "status": "Reject",
        "keywords": "Adversarial training;Robust overfitting;Double descent;Label noise",
        "author": "",
        "aff": "",
        "rating": "5;6;6;6",
        "confidence": "4;4;3;5",
        "correctness": "4;4;3;3",
        "technical_novelty": "2;3;2;4",
        "empirical_novelty": "2;3;0;4",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "-llS6TiOew",
        "title": "Fairness in Representation for Multilingual NLP: Insights from Controlled Experiments on Conditional Language Modeling",
        "track": "main",
        "status": "Spotlight",
        "keywords": "fairness;evaluation;multilingual NLP / multilinguality;representation learning for language data;statistical comparisons;Double Descent;conditional language modeling;data-centric approach;diversity in AI;morphology;Transformer;meta evaluation;visualization or interpretation of learned representations;character encoding;internationalization and localization;robustness;statistical science for NLP;science in the era of AI/DL (AIxScience);transdisciplinarity",
        "author": "",
        "aff": "University of Zurich",
        "rating": "6;6;8;8;8",
        "confidence": "3;5;4;3;4",
        "correctness": "3;3;3;3;3",
        "technical_novelty": "2;3;2;4;3",
        "empirical_novelty": "2;3;3;4;3",
        "presentation": "",
        "rating_avg": 7.2,
        "confidence_avg": 3.8,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.8,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.21821789023599233,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "-ngwPqanCEZ",
        "title": "Representation-Agnostic Shape Fields",
        "track": "main",
        "status": "Poster",
        "keywords": "shape embedding;3D deep learning;shape classification and segmentation",
        "author": "",
        "aff": "School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University; Anhui University",
        "rating": "5;5;6;6",
        "confidence": "4;4;4;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;3;4",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": "https://github.com/seanywang0408/RASF"
    },
    {
        "id": "-qg9k1ftTc",
        "title": "S$^3$ADNet: Sequential Anomaly Detection with Pessimistic Contrastive Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "deep learning;anomaly detection;unsupervised learning;sequential data",
        "author": "",
        "aff": "",
        "rating": "1;3;5;5;5",
        "confidence": "4;4;4;3;4",
        "correctness": "2;3;3;3;3",
        "technical_novelty": "2;2;3;3;4",
        "empirical_novelty": "1;2;2;3;2",
        "presentation": "",
        "rating_avg": 3.8,
        "confidence_avg": 3.8,
        "correctness_avg": 2.8,
        "technical_novelty_avg": 2.8,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.37500000000000006,
        "corr_rating_correctness": 0.8750000000000001,
        "project": "",
        "github": ""
    },
    {
        "id": "-r_OrYjUMJK",
        "title": "Reynolds Equivariant and Invariant Networks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;6",
        "confidence": "3;2;3",
        "correctness": "3;4;3",
        "technical_novelty": "3;2;4",
        "empirical_novelty": "1;2;2",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.4999999999999999,
        "corr_rating_correctness": -0.4999999999999999,
        "project": "",
        "github": ""
    },
    {
        "id": "-spj8FZD4y2",
        "title": "Contextual Multi-Armed Bandit with Communication Constraints",
        "track": "main",
        "status": "Reject",
        "keywords": "Machine Learning;Information Theory;Multi-Armed Bandits",
        "author": "",
        "aff": "",
        "rating": "5;6;6;6",
        "confidence": "4;3;3;2",
        "correctness": "4;4;4;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.816496580927726,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "-u8EliRNW8k",
        "title": "Speech-MLP: a simple MLP architecture for speech processing",
        "track": "main",
        "status": "Reject",
        "keywords": "MLP;transformers;speech signal processing",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5;8",
        "confidence": "4;4;3;4;4",
        "correctness": "3;3;3;3;4",
        "technical_novelty": "2;2;2;3;3",
        "empirical_novelty": "0;2;2;3;3",
        "presentation": "",
        "rating_avg": 5.2,
        "confidence_avg": 3.8,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.06250000000000001,
        "corr_rating_correctness": 0.875,
        "project": "",
        "github": ""
    },
    {
        "id": "-uPIaaZdMLF",
        "title": "Attentional meta-learners for few-shot polythetic classification",
        "track": "main",
        "status": "Reject",
        "keywords": "Meta-learning;self-attention;feature-selection",
        "author": "",
        "aff": "",
        "rating": "6;6;6;6",
        "confidence": "4;4;4;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "3;3;2;4",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "-uZp67PZ7p",
        "title": "Multi-Agent Reinforcement Learning with Shared Resource in Inventory Management",
        "track": "main",
        "status": "Reject",
        "keywords": "Multi-Agent Reinforcement Learning;Inventory Management;Shared Resource;Decentralized Training Paradigm;Model-based RL",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "4;4;4;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "-w2oomO6qgc",
        "title": "GeneDisco: A Benchmark for Experimental Design in Drug Discovery",
        "track": "main",
        "status": "Poster",
        "keywords": "batch active learning;drug discovery;benchmark",
        "author": "",
        "aff": "Department of Computer Science, University of Oxford; GlaxoSmithKline, Artificial Intelligence & Machine Learning; MIT",
        "rating": "6;6;6",
        "confidence": "4;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "1;3;2",
        "empirical_novelty": "3;4;2",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "-xhk0O7iAc0",
        "title": "A Topological View of Rule Learning in Knowledge Graphs",
        "track": "main",
        "status": "Reject",
        "keywords": "Inductive Relation Prediction;Topological Data Analysis;Cycle Basis;Homology",
        "author": "",
        "aff": "",
        "rating": "1;3;5;5",
        "confidence": "4;4;3;4",
        "correctness": "2;2;4;2",
        "technical_novelty": "2;3;4;2",
        "empirical_novelty": "2;3;3;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.75,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5222329678670935,
        "corr_rating_correctness": 0.5222329678670935,
        "project": "",
        "github": ""
    },
    {
        "id": "-ybZRQktdgc",
        "title": "LRN: Limitless Routing Networks for Effective Multi-task Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "multi-task learning;MTL;reinforcement learning;machine learning;routing networks;modular networks",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "4;5;4;4",
        "correctness": "3;2;4;3",
        "technical_novelty": "2;2;1;2",
        "empirical_novelty": "2;1;1;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "00UIZu1IRU",
        "title": "Learning mixture of neural temporal point processes for event sequence clustering",
        "track": "main",
        "status": "Withdraw",
        "keywords": "temporal point process;event sequence clustering;deep learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;4;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;0;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "00Vc1Ov5KZn",
        "title": "Vi-MIX FOR SELF-SUPERVISED VIDEO REPRESENTATION",
        "track": "main",
        "status": "Withdraw",
        "keywords": "data augmentation;self-supervision;video representation",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "5;5;3;4",
        "correctness": "3;3;2;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;1;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.17407765595569782,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "01AMRlen9wJ",
        "title": "Online Hyperparameter Meta-Learning with Hypergradient Distillation",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Hyperparameter Optimization;Meta-learning",
        "author": "",
        "aff": "",
        "rating": "6;6;8;8",
        "confidence": "3;4;2;3",
        "correctness": "3;3;3;4",
        "technical_novelty": "3;3;3;2",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7071067811865475,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "01CDUB3v6H",
        "title": "LARGE: Latent-Based Regression through GAN Semantics",
        "track": "main",
        "status": "Withdraw",
        "keywords": "GAN;Latent Space;Latent semantics;Regression;Few-Shot",
        "author": "",
        "aff": "",
        "rating": "5;5;5;8",
        "confidence": "4;4;4;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "3;2;2;3",
        "empirical_novelty": "3;3;2;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "03RLpj-tc_",
        "title": "Crystal Diffusion Variational Autoencoder for Periodic Material Generation",
        "track": "main",
        "status": "Poster",
        "keywords": "materials;graph neural networks;periodic;diffusion models;score matching;molecule;3D;generative",
        "author": "",
        "aff": "",
        "rating": "3;5;6;8",
        "confidence": "4;4;5;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "3;3;3;4",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 4.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.16012815380508713,
        "corr_rating_correctness": 0.8320502943378437,
        "project": "",
        "github": ""
    },
    {
        "id": "04pGUg0-pdZ",
        "title": "Finite-Time Convergence and Sample Complexity of Multi-Agent Actor-Critic Reinforcement Learning with Average Reward",
        "track": "main",
        "status": "Spotlight",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "6;6;6;8;8",
        "confidence": "3;3;4;3;4",
        "correctness": "4;3;3;4;4",
        "technical_novelty": "3;2;3;3;3",
        "empirical_novelty": "2;1;2;2;3",
        "presentation": "",
        "rating_avg": 6.8,
        "confidence_avg": 3.4,
        "correctness_avg": 3.6,
        "technical_novelty_avg": 2.8,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.16666666666666663,
        "corr_rating_correctness": 0.6666666666666667,
        "project": "",
        "github": ""
    },
    {
        "id": "057dxuWpfx",
        "title": "Shaped Rewards Bias Emergent Language",
        "track": "main",
        "status": "Reject",
        "keywords": "emergent language;reinforcement learning;neural networks",
        "author": "",
        "aff": "",
        "rating": "1;3;3;3;6",
        "confidence": "4;4;3;3;4",
        "correctness": "2;3;3;3;3",
        "technical_novelty": "1;2;2;2;4",
        "empirical_novelty": "1;2;2;2;4",
        "presentation": "",
        "rating_avg": 3.2,
        "confidence_avg": 3.6,
        "correctness_avg": 2.8,
        "technical_novelty_avg": 2.2,
        "empirical_novelty_avg": 2.2,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.10206207261596574,
        "corr_rating_correctness": 0.6875000000000002,
        "project": "",
        "github": ""
    },
    {
        "id": "06Wy2BtxXrz",
        "title": "Learning Scenario Representation for Solving Two-stage Stochastic Integer Programs",
        "track": "main",
        "status": "Poster",
        "keywords": "Conditional Variational Autoencoder;Stochastic Integer Programming;Scenario Reduction",
        "author": "",
        "aff": "Singapore Institute of Manufacturing Technology, A*STAR, Singapore; Institute of Marine Science and Technology, Shandong University, Qingdao, China; School of Computer Science and Engineering, Nanyang Technological University, Singapore",
        "rating": "6;6;6",
        "confidence": "3;2;3",
        "correctness": "3;3;4",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "06fUz_bJStS",
        "title": "Differentially Private SGD with Sparse Gradients",
        "track": "main",
        "status": "Reject",
        "keywords": "differential privacy;differentially private SGD;privacy-preserving training",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;3;3;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;2;4;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "085y6YPaYjP",
        "title": "Zero-Shot Self-Supervised Learning for MRI Reconstruction",
        "track": "main",
        "status": "Poster",
        "keywords": "Zero-shot learning;Self-supervised learning;MRI Reconstruction;Transfer learning;Physics-guided deep learning",
        "author": "",
        "aff": "Department of Electrical&Computer Engineering, University of Minnesota; Center for Magnetic Resonance Research, University of Minnesota",
        "rating": "5;5;6",
        "confidence": "5;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4999999999999999,
        "corr_rating_correctness": -0.4999999999999999,
        "project": "",
        "github": ""
    },
    {
        "id": "0DLwqQLmqV",
        "title": "NAS-Bench-Suite: NAS Evaluation is (Now) Surprisingly Easy",
        "track": "main",
        "status": "Poster",
        "keywords": "neural architecture search;AutoML",
        "author": "",
        "aff": "University of Freiburg; University of Freiburg, Bosch Center for AI; Abacus.AI",
        "rating": "6;8;8;8",
        "confidence": "4;5;4;3",
        "correctness": "4;3;4;4",
        "technical_novelty": "2;1;3;3",
        "empirical_novelty": "3;4;3;3",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": "https://github.com/automl/naslib"
    },
    {
        "id": "0DcZxeWfOPt",
        "title": "Fast Model Editing at Scale",
        "track": "main",
        "status": "Poster",
        "keywords": "editing;transfomers;meta-learning",
        "author": "",
        "aff": "Stanford University",
        "rating": "3;6;8;8",
        "confidence": "4;3;4;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;3;4",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.07053456158585983,
        "corr_rating_correctness": 0.49374193110101877,
        "project": "https://sites.google.com/view/mend-editing",
        "github": ""
    },
    {
        "id": "0DecTiJFbm",
        "title": "A New Perspective on Fluid Simulation: An Image-to-Image Translation Task via Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "cGAN;CFD;Image-to-Image;Fluid Simulation",
        "author": "",
        "aff": "",
        "rating": "1;1;3;3",
        "confidence": "5;5;5;4",
        "correctness": "2;3;3;1",
        "technical_novelty": "1;1;2;1",
        "empirical_novelty": "1;1;2;0",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.75,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 1.25,
        "empirical_novelty_avg": 1.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": -0.30151134457776363,
        "project": "",
        "github": ""
    },
    {
        "id": "0EL4vLgYKRW",
        "title": "Plan Better Amid Conservatism: Offline Multi-Agent Reinforcement Learning with Actor Rectification",
        "track": "main",
        "status": "Reject",
        "keywords": "Multi-Agent Reinforcement Learning (MARL);Offline reinforcement learning (RL);Offline Multi-Agent Reinforcement Learning",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "3;4;3;3",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "2;3;3;2",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "0EXmFzUn5I",
        "title": "Pyraformer: Low-Complexity Pyramidal Attention for Long-Range Time Series Modeling and Forecasting",
        "track": "main",
        "status": "Oral",
        "keywords": "sparse attention;pyramidal graph;Transformer;time series forecasting;long-range dependence;multiresolution",
        "author": "",
        "aff": "Shanghai Jiaotong University; Ant Group; Ant Group, Shanghai Jiaotong University; TU Wien, Austria",
        "rating": "6;6;8;8",
        "confidence": "4;4;3;4",
        "correctness": "4;3;4;4",
        "technical_novelty": "4;2;3;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": "https://github.com/alipay/Pyraformer"
    },
    {
        "id": "0GhVG1de-Iv",
        "title": "Stability and Generalisation in Batch Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Reinforcement Learning;Algorithmic Stability;Generalisation;Overfitting;Target Network;Fitted TD;Off-Policy;Batch Reinforcement Learning",
        "author": "",
        "aff": "",
        "rating": "3;3;3",
        "confidence": "4;4;2",
        "correctness": "3;2;3",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "2;0;0",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 0.6666666666666666,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "0HkFxvSRDSW",
        "title": "Role Diversity Matters: A Study of Cooperative Training Strategies for Multi-Agent RL",
        "track": "main",
        "status": "Reject",
        "keywords": "Multi-agent Reinforcement Learning",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "3;2;4;4",
        "correctness": "3;2;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "3;2;4;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9045340337332909,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "0IqFsR9wJvI",
        "title": "Online graph nets",
        "track": "main",
        "status": "Withdraw",
        "keywords": "continuous-time dynamic graphs;temporal graph neural networks;graph neural networks",
        "author": "",
        "aff": "",
        "rating": "5;6;6;6",
        "confidence": "5;4;4;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "3;3;2;2",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.816496580927726,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "0J98XyjlQ1",
        "title": "D$^2$-GCN: Data-Dependent GCNs for Boosting Both Efficiency and Scalability",
        "track": "main",
        "status": "Reject",
        "keywords": "Graph Convolutional Networks;Efficient Networks",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "3;3;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "3;3;4;2",
        "empirical_novelty": "3;3;4;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8164965809277259,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "0JzqUlIVVDd",
        "title": "KL Guided Domain Adaptation",
        "track": "main",
        "status": "Poster",
        "keywords": "domain adaptation;invariant representation",
        "author": "",
        "aff": "University of Oxford, Oxford, United Kingdom; VinAI Research, Hanoi, Vietnam",
        "rating": "3;6;6;8",
        "confidence": "4;3;3;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.14002800840280097,
        "corr_rating_correctness": 0.7276068751089989,
        "project": "",
        "github": ""
    },
    {
        "id": "0Kj5mhn6sw",
        "title": "Gesture2Vec: Clustering Gestures using Representation Learning Methods for Co-speech Gesture Generation",
        "track": "main",
        "status": "Reject",
        "keywords": "representation learning;gesture generation;vector quantization;machine translation",
        "author": "",
        "aff": "",
        "rating": "3;5;6",
        "confidence": "5;4;5",
        "correctness": "2;3;3",
        "technical_novelty": "2;1;3",
        "empirical_novelty": "0;2;3",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.18898223650461357,
        "corr_rating_correctness": 0.9449111825230683,
        "project": "",
        "github": ""
    },
    {
        "id": "0LHZ4UXEPOy",
        "title": "Generative Kernel Continual Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "kernel continual learning;generative learning;catastrophic forgetting",
        "author": "",
        "aff": "",
        "rating": "3;3;3;6;6",
        "confidence": "4;4;4;4;4",
        "correctness": "3;3;2;4;3",
        "technical_novelty": "2;2;2;3;3",
        "empirical_novelty": "1;2;2;3;2",
        "presentation": "",
        "rating_avg": 4.2,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.6454972243679027,
        "project": "",
        "github": ""
    },
    {
        "id": "0Mo_5PkLpwc",
        "title": "Robust Cross-Modal Semi-supervised Few Shot Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "few-shot learning;noisy labels;variational inference;cross-modality;uncertainty;robustness",
        "author": "",
        "aff": "",
        "rating": "5;6;8",
        "confidence": "2;2;3",
        "correctness": "3;3;4",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 6.333333333333333,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.944911182523068,
        "corr_rating_correctness": 0.944911182523068,
        "project": "",
        "github": ""
    },
    {
        "id": "0Q6BzWbvg0P",
        "title": "Less is More: Dimension Reduction Finds On-Manifold Adversarial Examples in Hard-Label Attacks",
        "track": "main",
        "status": "Reject",
        "keywords": "hard-label attacks;adversarial machine learning;generalization",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;2;3;2",
        "correctness": "1;3;2;3",
        "technical_novelty": "1;3;3;2",
        "empirical_novelty": "1;0;3;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 2.75,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8703882797784891,
        "corr_rating_correctness": 0.8703882797784891,
        "project": "",
        "github": ""
    },
    {
        "id": "0RDcd5Axok",
        "title": "Towards a Unified View of Parameter-Efficient Transfer Learning",
        "track": "main",
        "status": "Spotlight",
        "keywords": "parameter-efficient transfer learning;unified view;natural language processing",
        "author": "",
        "aff": "UC San Diego; Carnegie Mellon University; University of Southern California",
        "rating": "8;8;10",
        "confidence": "4;3;5",
        "correctness": "3;4;4",
        "technical_novelty": "3;3;4",
        "empirical_novelty": "3;3;4",
        "presentation": "",
        "rating_avg": 8.666666666666666,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 3.3333333333333335,
        "empirical_novelty_avg": 3.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8660254037844385,
        "corr_rating_correctness": 0.4999999999999999,
        "project": "",
        "github": "https://github.com/jxhe/unify-parameter-ef\ufb01cient-tuning"
    },
    {
        "id": "0RqDp8FCW5Z",
        "title": "W-CTC: a Connectionist Temporal Classification Loss with Wild Cards",
        "track": "main",
        "status": "Poster",
        "keywords": "CTC;wild cards;dynamic programing;partial alignment",
        "author": "",
        "aff": "Baidu Research, 1195 Bordeaux Dr, Sunnyvale, CA 94089, USA",
        "rating": "6;6;6;6",
        "confidence": "5;4;4;4",
        "correctness": "4;3;4;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "0SiVrAfIxOe",
        "title": "Closed-Loop Control of Additive Manufacturing via Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "additive manufacturing;closed-loop;reinforcement learning;in-process",
        "author": "",
        "aff": "",
        "rating": "5;5;5",
        "confidence": "3;3;4",
        "correctness": "3;4;2",
        "technical_novelty": "3;2;2",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "0Tnl8uBHfQw",
        "title": "Deep Classifiers with Label Noise Modeling and Distance Awareness",
        "track": "main",
        "status": "Reject",
        "keywords": "Deep learning;uncertainty estimation;out-of-distribution detection",
        "author": "",
        "aff": "",
        "rating": "5;5;6;8",
        "confidence": "3;3;4;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8164965809277259,
        "corr_rating_correctness": 0.8164965809277259,
        "project": "",
        "github": ""
    },
    {
        "id": "0U0C2pXfTZl",
        "title": "SLASH: Embracing Probabilistic Circuits into Neural Answer Set Programming",
        "track": "main",
        "status": "Reject",
        "keywords": "Deep Probabilistic Programming Languages;Probabilistic Circuits;Neuro-Symbolic Computations",
        "author": "",
        "aff": "",
        "rating": "3;5;6;8",
        "confidence": "5;4;3;2",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9922778767136676,
        "corr_rating_correctness": 0.8006407690254357,
        "project": "",
        "github": ""
    },
    {
        "id": "0UXT6PpRpW",
        "title": "Large-Scale Representation Learning on Graphs via Bootstrapping",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "Georgia Institute of Technology; DeepMind",
        "rating": "5;6;6;8",
        "confidence": "3;5;5;5",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "4;3;3;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 4.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.6622661785325219,
        "corr_rating_correctness": 0.6882472016116854,
        "project": "",
        "github": ""
    },
    {
        "id": "0VezzBzLmBr",
        "title": "Online Tuning for Offline Decentralized Multi-Agent Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "multi-agent reinforcement learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "5;5;4;4",
        "correctness": "3;3;3;2",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "0WHn7Dj52cS",
        "title": "Vibration-based Uncertainty Estimation for Learning from Limited Supervision",
        "track": "main",
        "status": "Withdraw",
        "keywords": "uncertainty estimation;semi-supervised learning;active learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5",
        "confidence": "4;4;3",
        "correctness": "2;2;2",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "2;2;4",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "0WIM9dHzQBh",
        "title": "DP-InstaHide: Data Augmentations Provably Enhance Guarantees Against Dataset Manipulations",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "3;4;5;4",
        "correctness": "2;3;4;4",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "1;2;3;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.7071067811865475,
        "corr_rating_correctness": 0.9045340337332909,
        "project": "",
        "github": ""
    },
    {
        "id": "0bXmbOt1oq",
        "title": "Towards Learning to Speak and Hear Through Multi-Agent Communication over a Continuous Acoustic Channel",
        "track": "main",
        "status": "Reject",
        "keywords": "multi-agent reinforcement learning;language acquisition;emergent communication;acoustic communication;continuous signalling",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;4;5;4",
        "correctness": "2;4;3;4",
        "technical_novelty": "1;3;2;2",
        "empirical_novelty": "1;1;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.5222329678670935,
        "project": "",
        "github": ""
    },
    {
        "id": "0cgU-BZp2ky",
        "title": "Efficient Learning of Safe Driving Policy via Human-AI Copilot Optimization",
        "track": "main",
        "status": "Poster",
        "keywords": "Human in the Loop;Safe Reinforcement Learning;Autonomous Driving",
        "author": "",
        "aff": "University of California, Los Angeles; Centre for Perceptual and Interactive Intelligence; The Chinese University of Hong Kong",
        "rating": "6;6;6;8",
        "confidence": "3;3;3;3",
        "correctness": "4;3;3;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;3;3;4",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": "https://decisionforce.github.io/HACO/"
    },
    {
        "id": "0d1mLPC2q2",
        "title": "Understanding the Success of Knowledge Distillation -- A Data Augmentation Perspective",
        "track": "main",
        "status": "Reject",
        "keywords": "knowledge distillation;data augmentation;mixup;cutmix;model compression;active learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5",
        "confidence": "5;4;4",
        "correctness": "3;2;3",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "3;2;3",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4999999999999999,
        "corr_rating_correctness": 0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "0jFw-C30hm",
        "title": "Less is more: Selecting the right benchmarking set of data for time series classification",
        "track": "main",
        "status": "Withdraw",
        "keywords": "benchmarking;time-series classification;landscape analysis",
        "author": "",
        "aff": "",
        "rating": "3;3;6",
        "confidence": "4;3;3",
        "correctness": "2;2;3",
        "technical_novelty": "1;1;2",
        "empirical_novelty": "2;1;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 1.3333333333333333,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "0jP2n0YFmKG",
        "title": "Towards Training Billion Parameter Graph Neural Networks for Atomic Simulations",
        "track": "main",
        "status": "Poster",
        "keywords": "Graph Neural Networks;Atomic Simulations;Computational Chemistry",
        "author": "",
        "aff": "Meta FAIR; National Energy Research Scientific Computing Center (NERSC)",
        "rating": "5;5;6;8",
        "confidence": "1;3;3;2",
        "correctness": "3;3;3;3",
        "technical_novelty": "3;3;2;3",
        "empirical_novelty": "3;3;3;4",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 2.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "0kNbTghw7q",
        "title": "Improving Generative Adversarial Networks via Adversarial Learning in Latent Space",
        "track": "main",
        "status": "Reject",
        "keywords": "Generative Adversarial Networks;Adversarial Traing;Latent Space",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "4;4;4;3",
        "correctness": "2;3;3;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4714045207910316,
        "corr_rating_correctness": 0.8660254037844386,
        "project": "",
        "github": ""
    },
    {
        "id": "0kPL3xO4R5",
        "title": "Fast topological clustering with Wasserstein distance",
        "track": "main",
        "status": "Poster",
        "keywords": "Topological data analysis;cluster analysis;persistent homology;Wasserstein distance;Wasserstein barycenter;brain networks;intracranial electrophysiology;consciousness",
        "author": "",
        "aff": "Department of Anesthesiology, Department of Neuroscience, University of Wisconsin\u2013Madison, USA; Department of Electrical and Computer Engineering, University of Wisconsin\u2013Madison, USA; Department of Neurosurgery, Iowa Neuroscience Institute, University of Iowa, USA",
        "rating": "6;8;8",
        "confidence": "4;5;5",
        "correctness": "3;4;3",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 7.333333333333333,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9999999999999997,
        "corr_rating_correctness": 0.49999999999999983,
        "project": "",
        "github": "https://github.com/topolearn"
    },
    {
        "id": "0kwQV5SkHWW",
        "title": "Partially Relaxed Masks for Lightweight Knowledge Transfer without Forgetting in Continual Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Continual learning;Task similarity;Catastrophic forgetting;Knowledge transfer",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;3;4",
        "correctness": "2;4;3;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "0lGKTI1tho",
        "title": "POLAR: A Polynomial Arithmetic Framework for Verifying Neural-Network Controlled Systems",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Neural network controlled systems;safety;verification;Taylor model arithmetic",
        "author": "",
        "aff": "",
        "rating": "1;3;6",
        "confidence": "5;4;3",
        "correctness": "2;2;3",
        "technical_novelty": "1;2;2",
        "empirical_novelty": "1;2;2",
        "presentation": "",
        "rating_avg": 3.3333333333333335,
        "confidence_avg": 4.0,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 1.6666666666666667,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9933992677987827,
        "corr_rating_correctness": 0.9176629354822468,
        "project": "",
        "github": ""
    },
    {
        "id": "0lSoIruExF",
        "title": "Incorporating User-Item Similarity in Hybrid Neighborhood-based Recommendation System",
        "track": "main",
        "status": "Reject",
        "keywords": "Recommendation system;Neighborhood-based;Collaborative filtering;Data mining",
        "author": "",
        "aff": "",
        "rating": "1;1;3;3;5",
        "confidence": "4;4;5;4;3",
        "correctness": "3;2;2;4;3",
        "technical_novelty": "1;2;1;2;2",
        "empirical_novelty": "1;1;2;2;3",
        "presentation": "",
        "rating_avg": 2.6,
        "confidence_avg": 4.0,
        "correctness_avg": 2.8,
        "technical_novelty_avg": 1.6,
        "empirical_novelty_avg": 1.8,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.42257712736425823,
        "corr_rating_correctness": 0.2857142857142857,
        "project": "",
        "github": ""
    },
    {
        "id": "0m4c9ZfDrDt",
        "title": "Generalizing Successor Features to continuous domains for Multi-task Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Reinforcement learning;multi-task learning;representation learning",
        "author": "",
        "aff": "",
        "rating": "3;3;3",
        "confidence": "4;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "2;2;1",
        "empirical_novelty": "2;2;1",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 1.6666666666666667,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "0n1UvVzW99x",
        "title": "Synthetic Reduced Nearest Neighbor Model for Regression",
        "track": "main",
        "status": "Reject",
        "keywords": "Regression;Nearest Neighbor;Prototype Learning;Prototype Nearest Neighbor",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "3;4;4;3",
        "correctness": "3;2;3;3",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "3;2;3;0",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "0no8Motr-zO",
        "title": "An Experimental Design Perspective on Model-Based Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "reinforcement learning;acquisition function;information gain",
        "author": "",
        "aff": "Computer Science Department, Stanford University, Stanford, CA, USA; Robotics Insitute & Machine Learning Department, Carnegie Mellon University, Pittsburgh, PA, USA",
        "rating": "5;8;8;8",
        "confidence": "4;3;4;3",
        "correctness": "3;4;3;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;3;2",
        "presentation": "",
        "rating_avg": 7.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "0oSM3TC9Z5a",
        "title": "Learning to Persuade",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;3;6",
        "confidence": "5;4;4;3",
        "correctness": "2;4;3;4",
        "technical_novelty": "2;2;1;3",
        "empirical_novelty": "2;2;1;3",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.816496580927726,
        "corr_rating_correctness": 0.5222329678670935,
        "project": "",
        "github": ""
    },
    {
        "id": "0q0REJNgtg",
        "title": "Retrieval-Augmented Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "replay buffer;reinforcement learning;offline RL;attention",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "3;4;3;4",
        "correctness": "2;3;4;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;4;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.7071067811865475,
        "project": "",
        "github": ""
    },
    {
        "id": "0qpEfoNObj",
        "title": "Weight Expansion: A New Perspective on Dropout and Generalization",
        "track": "main",
        "status": "Withdraw",
        "keywords": "dropout;generalization;PAC-Bayes",
        "author": "",
        "aff": "",
        "rating": "5;6;6;8",
        "confidence": "4;4;3;3",
        "correctness": "4;3;3;4",
        "technical_novelty": "3;3;3;4",
        "empirical_novelty": "3;3;3;4",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6882472016116854,
        "corr_rating_correctness": 0.2294157338705618,
        "project": "",
        "github": ""
    },
    {
        "id": "0rcbOaoBXbg",
        "title": "Neural Spectral Marked Point Processes",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "Georgia Institute of Technology; Duke University",
        "rating": "3;6;8",
        "confidence": "3;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "2;2;0",
        "presentation": "",
        "rating_avg": 5.666666666666667,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 1.3333333333333333,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.1147078669352809,
        "corr_rating_correctness": 0.8029550685469661,
        "project": "",
        "github": ""
    },
    {
        "id": "0rjx6jy25R4",
        "title": "Classify and Generate Reciprocally: Simultaneous Positive-Unlabelled Learning and Conditional Generation with Extra Data",
        "track": "main",
        "status": "Reject",
        "keywords": "PU learning;Robust Generative Models;Lable noises",
        "author": "",
        "aff": "",
        "rating": "1;5;5;5",
        "confidence": "4;4;3;5",
        "correctness": "3;3;3;4",
        "technical_novelty": "1;3;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "0sEIBFb4cs",
        "title": "Practical Adversarial Attacks on Brain--Computer Interfaces",
        "track": "main",
        "status": "Reject",
        "keywords": "neuroscience;brain-computer interfaces;practical attacks;adversarial attacks;EEGNet;edge computing;embedded systems",
        "author": "",
        "aff": "",
        "rating": "3;3;6;8",
        "confidence": "5;5;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9428090415820635,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "0sgntlpKDOz",
        "title": "Learning Graphon Mean Field Games and Approximate Nash Equilibria",
        "track": "main",
        "status": "Poster",
        "keywords": "Mean Field Games;Reinforcement Learning;Multi Agent Systems",
        "author": "",
        "aff": "Department of Electrical Engineering, Technische Universit\u00e4t Darmstadt, Germany",
        "rating": "5;5;6;8",
        "confidence": "4;4;4;3",
        "correctness": "4;3;4;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;2;2;4",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9428090415820632,
        "corr_rating_correctness": 0.4714045207910316,
        "project": "",
        "github": ""
    },
    {
        "id": "0uZu36la_y4",
        "title": "Protect the weak: Class focused online learning for adversarial training",
        "track": "main",
        "status": "Reject",
        "keywords": "Adversarial training;Adversarial examples;Minimax;Robustness",
        "author": "",
        "aff": "",
        "rating": "3;3;6;6",
        "confidence": "4;3;4;4",
        "correctness": "3;4;4;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896258,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "0xiJLKH-ufZ",
        "title": "Analytic-DPM: an Analytic Estimate of the Optimal Reverse Variance in Diffusion Probabilistic Models",
        "track": "main",
        "status": "Oral",
        "keywords": "diffusion probabilistic models;generative models",
        "author": "",
        "aff": "Dept. of Comp. Sci. & Tech., Institute for AI, Tsinghua-Huawei Joint Center for AI, BNRist Center, State Key Lab for Intell. Tech. & Sys., Tsinghua University, Beijing, China; Gaoling School of Arti\ufb01cial Intelligence, Renmin University of China, Beijing, China",
        "rating": "8;8;8;8;8",
        "confidence": "4;4;3;3;4",
        "correctness": "4;4;3;4;3",
        "technical_novelty": "4;3;4;3;3",
        "empirical_novelty": "3;3;3;3;3",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.6,
        "correctness_avg": 3.6,
        "technical_novelty_avg": 3.4,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "0ze7XgWcYNV",
        "title": "Learning When and What to Ask: a Hierarchical Reinforcement Learning Framework",
        "track": "main",
        "status": "Reject",
        "keywords": "human-agent interaction;reinforcement learning;navigation",
        "author": "",
        "aff": "",
        "rating": "3;3;5",
        "confidence": "4;3;4",
        "correctness": "2;3;3",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "1;1;3",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5,
        "corr_rating_correctness": 0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "1-58A45OkER",
        "title": "Delving into Channels: Exploring Hyperparameter Space of Channel Bit Widths with Linear Complexity",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Deep Learning;Neural Network Compression;Rate-Distortion Theories",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "5;5;5;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "3;2;2;3",
        "empirical_novelty": "0;1;2;0",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 0.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6622661785325219,
        "corr_rating_correctness": 0.9271726499455306,
        "project": "",
        "github": ""
    },
    {
        "id": "1-YP2squpa7",
        "title": "Deep learning via message passing algorithms based on belief propagation",
        "track": "main",
        "status": "Reject",
        "keywords": "belief propagation;neural networks;graphical models;gradient-free algorithms;discrete neural networks",
        "author": "",
        "aff": "",
        "rating": "3;5;6;8",
        "confidence": "4;4;4;3",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8006407690254357,
        "corr_rating_correctness": 0.8006407690254357,
        "project": "",
        "github": ""
    },
    {
        "id": "1-lFH8oYTI",
        "title": "Calibration Regularized Training of Deep Neural Networks using Kernel Density Estimation",
        "track": "main",
        "status": "Reject",
        "keywords": "calibration;dirichlet kernel density estimation",
        "author": "",
        "aff": "",
        "rating": "5;5;5;8",
        "confidence": "5;4;3;3",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5222329678670935,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "11PMuvv3tEO",
        "title": "Lagrangian Generative Adversarial Imitation Learning with Safety",
        "track": "main",
        "status": "Withdraw",
        "keywords": "safe imitation learning;inverse reinforcement learning",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "3;4;5;4",
        "correctness": "3;2;2;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;3;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "11aY89G7YY4",
        "title": "Data-centric Semi-supervised Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Data-centric;semi-supervised learning",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "4;4;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "1;2;2;2",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "12RoR2o32T",
        "title": "Out-of-distribution Generalization in the Presence of Nuisance-Induced Spurious Correlations",
        "track": "main",
        "status": "Poster",
        "keywords": "spurious correlations;out of distribution generalization;ml for health;representation learning",
        "author": "",
        "aff": "New York University",
        "rating": "5;5;6;8;8",
        "confidence": "5;4;3;3;3",
        "correctness": "2;2;3;4;4",
        "technical_novelty": "2;2;3;3;4",
        "empirical_novelty": "2;3;3;2;4",
        "presentation": "",
        "rating_avg": 6.4,
        "confidence_avg": 3.6,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.8,
        "empirical_novelty_avg": 2.8,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7740702698132101,
        "corr_rating_correctness": 0.9890707100936805,
        "project": "",
        "github": "https://github.com/aahladpuli/Nuisance-Randomized-Distillation"
    },
    {
        "id": "14F3fI6MGxX",
        "title": "A Generalized Weighted Optimization Method for Computational Learning and Inversion",
        "track": "main",
        "status": "Poster",
        "keywords": "weighted optimization;generalization error;feature regression;machine learning",
        "author": "",
        "aff": "Columbia University, New York, NY 10027, USA; ETH Z\u00a8urich, Z\u00a8urich, Switzerland; The University of Texas at Austin, Austin, TX 78712, USA",
        "rating": "5;6;6;6;6",
        "confidence": "4;4;2;2;4",
        "correctness": "4;4;3;4;4",
        "technical_novelty": "3;4;3;3;3",
        "empirical_novelty": "3;4;0;0;0",
        "presentation": "",
        "rating_avg": 5.8,
        "confidence_avg": 3.2,
        "correctness_avg": 3.8,
        "technical_novelty_avg": 3.2,
        "empirical_novelty_avg": 1.4,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.408248290463863,
        "corr_rating_correctness": -0.25000000000000006,
        "project": "",
        "github": ""
    },
    {
        "id": "14kbUbOaZUc",
        "title": "Metric Learning on Temporal Graphs via Few-Shot Examples",
        "track": "main",
        "status": "Reject",
        "keywords": "Metric Learning;Few-Shot Learning;Temporal Graph",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "3;4;3;3",
        "correctness": "3;2;3;4",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.7071067811865475,
        "project": "",
        "github": ""
    },
    {
        "id": "18Ys0-PzyPI",
        "title": "Online Ad Hoc Teamwork under Partial Observability",
        "track": "main",
        "status": "Poster",
        "keywords": "coordination;reinforcement learning",
        "author": "",
        "aff": "Noah\u2019s Ark Lab, Huawei; College of Intelligence and Computing, Tianjin University; School of Computer Science and Engineering, Nanyang Technological University, Singapore",
        "rating": "6;6;6;8",
        "confidence": "4;4;2;4",
        "correctness": "3;4;3;4",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "1DUwCRNAbA",
        "title": "An Investigation into the Role of Author Demographics in ICLR Participation and Review",
        "track": "main",
        "status": "Reject",
        "keywords": "Conference Review;OpenReview;Gender;Bias;Fairness",
        "author": "",
        "aff": "",
        "rating": "1;5;6;6",
        "confidence": "5;4;4;4",
        "correctness": "2;3;4;3",
        "technical_novelty": "1;1;2;3",
        "empirical_novelty": "1;2;3;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 4.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9801960588196067,
        "corr_rating_correctness": 0.8574929257125441,
        "project": "",
        "github": ""
    },
    {
        "id": "1HxTO6CTkz",
        "title": "Unifying Likelihood-free Inference with Black-box Optimization and Beyond",
        "track": "main",
        "status": "Spotlight",
        "keywords": "biological sequence design;black-box optimization;likelihood-free inference;Bayesian inference",
        "author": "",
        "aff": "Mila, University of Montreal; Mila, University of Montreal, CIFAR Fellow",
        "rating": "6;6;8;10",
        "confidence": "4;4;3;4",
        "correctness": "3;4;4;4",
        "technical_novelty": "2;3;4;4",
        "empirical_novelty": "2;0;2;3",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.17407765595569782,
        "corr_rating_correctness": 0.5222329678670935,
        "project": "",
        "github": ""
    },
    {
        "id": "1IiJQTDpuG",
        "title": "ImaginE: An Imagination-Based Automatic Evaluation Metric for Natural Language Generation",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;4;4;4",
        "correctness": "2;3;3;4",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9733285267845754,
        "project": "",
        "github": ""
    },
    {
        "id": "1JDiK_TbV4S",
        "title": "Source-Free Adaptation to Measurement Shift via Bottom-Up Feature Restoration",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Transfer learning;dataset shift;unsupervised domain adaptation;source-free domain adaptation",
        "author": "",
        "aff": "MPI for Intelligent Systems, T\u00fcbingen; School of Informatics, University of Edinburgh",
        "rating": "6;8;8;8;8",
        "confidence": "4;4;4;4;5",
        "correctness": "2;4;4;4;4",
        "technical_novelty": "3;3;3;3;3",
        "empirical_novelty": "3;3;3;4;3",
        "presentation": "",
        "rating_avg": 7.6,
        "confidence_avg": 4.2,
        "correctness_avg": 3.6,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.2,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.2500000000000001,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "1JN7MepVDFv",
        "title": "On the relationship between disentanglement and multi-task learning",
        "track": "main",
        "status": "Reject",
        "keywords": "disentanglement representations;multi-task learning",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "4;4;3;3",
        "correctness": "2;3;3;3",
        "technical_novelty": "3;3;3;2",
        "empirical_novelty": "2;3;4;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "1L0C5ROtFp",
        "title": "Filtered-CoPhy: Unsupervised Learning of Counterfactual Physics in Pixel Space",
        "track": "main",
        "status": "Oral",
        "keywords": "",
        "author": "",
        "aff": "LIRIS, INSA Lyon, France; Naver Labs Europe, France; Simon Fraser Univ., Canada; LAGEPP, Univ. Lyon 1, France; Meta AI",
        "rating": "8;8;10",
        "confidence": "4;5;3",
        "correctness": "4;4;4",
        "technical_novelty": "3;3;4",
        "empirical_novelty": "3;4;4",
        "presentation": "",
        "rating_avg": 8.666666666666666,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 3.3333333333333335,
        "empirical_novelty_avg": 3.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8660254037844385,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "1LVeBXpLohL",
        "title": "Network calibration by weight scaling",
        "track": "main",
        "status": "Withdraw",
        "keywords": "network calibration;temperature scaling;Expected Calibration Error (ECE)",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "4;5;4;3",
        "correctness": "3;2;3;3",
        "technical_novelty": "1;2;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "1NUsBU-7HAL",
        "title": "Map Induction: Compositional spatial submap learning for efficient exploration in novel environments",
        "track": "main",
        "status": "Poster",
        "keywords": "Cognitive Science;Bayesian Framework;Program Induction;Spatial Navigation;Planning;Map Learning",
        "author": "",
        "aff": "Massachusetts Institute of Technology",
        "rating": "6;6;6;8",
        "confidence": "3;4;3;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "4;2;4;3",
        "empirical_novelty": "4;3;2;4",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "1NvflqAdoom",
        "title": "Neural Networks as Kernel Learners: The Silent Alignment Effect",
        "track": "main",
        "status": "Poster",
        "keywords": "Neural Tangent Kernel;Feature Learning;Inductive Bias of Neural Networks",
        "author": "",
        "aff": "Harvard University, Cambridge, MA 02138, USA",
        "rating": "5;6;8",
        "confidence": "4;4;3",
        "correctness": "4;2;4",
        "technical_novelty": "3;4;3",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 6.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.3333333333333335,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.944911182523068,
        "corr_rating_correctness": 0.18898223650461365,
        "project": "",
        "github": ""
    },
    {
        "id": "1O5UK-zoK8g",
        "title": "Adaptive Generalization for Semantic Segmentation",
        "track": "main",
        "status": "Reject",
        "keywords": "domain generalization;semantic segmentation;test-time training",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "4;3;3;3",
        "correctness": "4;3;2;3",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "1OHZX4YDqhT",
        "title": "FedNAS: Federated Deep Learning via Neural Architecture Search",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "4;4;3;3",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "1QxveKM654",
        "title": "Genome Sequence Reconstruction Using Gated Graph Convolutional Network",
        "track": "main",
        "status": "Reject",
        "keywords": "genome assembly;graph neural networks;assembly graph;path finding",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;2;5",
        "correctness": "4;2;3;3",
        "technical_novelty": "3;2;4;2",
        "empirical_novelty": "1;3;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.22941573387056177,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "1R_PRbQK2eu",
        "title": "Dual Training of Energy-Based Models with Overparametrized Shallow Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "energy-based models;generative modeling;neural networks;duality;Fenchel;maximum mean discrepancy;maximum likelihood;active;lazy;score matching;measure;feature",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "3;4;3;3",
        "correctness": "3;4;3;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "1;1;2;2",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.13245323570650439,
        "corr_rating_correctness": 0.6882472016116854,
        "project": "",
        "github": ""
    },
    {
        "id": "1RqyBxJU_Wy",
        "title": "A Flexible Measurement of Diversity in Datasets with Random Network Distillation",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Diversity;Metric;Random Network Distillation;Generative",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;5;3;4",
        "correctness": "4;2;2;3",
        "technical_novelty": "3;3;3;2",
        "empirical_novelty": "3;1;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.17407765595569782,
        "project": "",
        "github": ""
    },
    {
        "id": "1T5FmILBsq2",
        "title": "SGORNN: Combining Scalar Gates and Orthogonal Constraints in Recurrent Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "Deep Learning;Recurrent Neural Networks;Exploding Gradient Problem;Deep Learning Generalization;Orthogonal RNNs",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "4;3;4;4",
        "correctness": "3;4;4;3",
        "technical_novelty": "1;1;3;3",
        "empirical_novelty": "1;1;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5555555555555555,
        "corr_rating_correctness": -0.19245008972987526,
        "project": "",
        "github": ""
    },
    {
        "id": "1W0z96MFEoH",
        "title": "Benchmarking the Spectrum of Agent Capabilities",
        "track": "main",
        "status": "Poster",
        "keywords": "Evaluation;Reinforcement Learning;Environment;Benchmark;Unsupervised Reinforcement Learning;Exploration",
        "author": "",
        "aff": "Google Research, Brain Team; University of Toronto",
        "rating": "5;5;6;8",
        "confidence": "4;4;4;4",
        "correctness": "4;4;3;4",
        "technical_novelty": "3;2;2;3",
        "empirical_novelty": "2;2;2;0",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "1XdUvpaTNlM",
        "title": "BWCP: Probabilistic Learning-to-Prune Channels for ConvNets via Batch Whitening",
        "track": "main",
        "status": "Reject",
        "keywords": "Classification;Normalization",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "5;4;4;5",
        "correctness": "3;4;2;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "1;3;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.2294157338705618,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "1Z3h4rCLvo-",
        "title": "Improving Long-Horizon Imitation Through Language Prediction",
        "track": "main",
        "status": "Reject",
        "keywords": "imitation learning;language;planning",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "4;5;5;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "3;1;2;2",
        "empirical_novelty": "1;2;3;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 4.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": "<github will be made public after reviewing period>"
    },
    {
        "id": "1Z5P--ntu8",
        "title": "On the Global Convergence of Gradient Descent for multi-layer ResNets in the mean-field regime",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "Paper under double-blind review",
        "rating": "3;5;6;8",
        "confidence": "4;3;3;5",
        "correctness": "4;4;3;3",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.4181210050035454,
        "corr_rating_correctness": -0.8320502943378437,
        "project": "",
        "github": ""
    },
    {
        "id": "1Zxv7TdLquI",
        "title": "YOUR AUTOREGRESSIVE GENERATIVE MODEL CAN BE BETTER IF YOU TREAT IT AS AN ENERGY-BASED ONE",
        "track": "main",
        "status": "Reject",
        "keywords": "autoregressive generative model;exposure bias;energy-based model",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6;6",
        "confidence": "4;2;3;4;5",
        "correctness": "3;3;3;3;3",
        "technical_novelty": "2;2;4;3;3",
        "empirical_novelty": "1;3;3;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.8,
        "empirical_novelty_avg": 2.6,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.17902871850985824,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "1_s0_W2V7R",
        "title": "Amortized Posterior on Latent Variables in Gaussian Process",
        "track": "main",
        "status": "Withdraw",
        "keywords": "meta-learning;uncertainty estimation",
        "author": "",
        "aff": "",
        "rating": "1;3;3;3",
        "confidence": "4;3;3;4",
        "correctness": "2;3;3;2",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "0;2;3;2",
        "presentation": "",
        "rating_avg": 2.5,
        "confidence_avg": 3.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "1bEaEzGwfhP",
        "title": "Learning to Model Editing Processes",
        "track": "main",
        "status": "Reject",
        "keywords": "Edit;Representation Learning;Source-code;natural language editing",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;4;4;5",
        "correctness": "3;2;2;2",
        "technical_novelty": "1;3;3;2",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 4.25,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": -1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "1ch9DLxqF-",
        "title": "Dominant Datapoints and the Block Structure Phenomenon in Neural Network Hidden Representations",
        "track": "main",
        "status": "Reject",
        "keywords": "representation learning;representational similarity;distributed representations",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6;6",
        "confidence": "3;4;4;3;3",
        "correctness": "2;4;2;4;4",
        "technical_novelty": "2;2;2;3;2",
        "empirical_novelty": "2;2;3;3;2",
        "presentation": "",
        "rating_avg": 4.6,
        "confidence_avg": 3.4,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.2,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3611575592573077,
        "corr_rating_correctness": 0.3611575592573077,
        "project": "",
        "github": ""
    },
    {
        "id": "1eGFH6yYAJn",
        "title": "Modality Laziness: Everybody's Business is Nobody's Business",
        "track": "main",
        "status": "Withdraw",
        "keywords": "multi-modal learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "4;3;3;3",
        "correctness": "2;4;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "1;2;3;0",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5555555555555555,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "1gEb_H1DEqZ",
        "title": "Logic Pre-Training of Language Models",
        "track": "main",
        "status": "Reject",
        "keywords": "Language Models;Pre-training;Logical Reasoning;Natural Language Understanding",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "5;5;4;4",
        "correctness": "2;2;3;3",
        "technical_novelty": "1;2;2;4",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "1hw-h1C8bch",
        "title": "Practical Adversarial Training with Differential Privacy for Deep Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "adversarial robustness;differential privacy;adversarial training;calibration;deep learning",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;5;3;5",
        "correctness": "2;1;3;4",
        "technical_novelty": "1;1;2;3",
        "empirical_novelty": "0;1;1;3",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 1.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5222329678670935,
        "corr_rating_correctness": 0.7745966692414834,
        "project": "",
        "github": ""
    },
    {
        "id": "1iDVz-khM4P",
        "title": "Neural Networks Playing Dough: Investigating Deep Cognition With a Gradient-Based Adversarial Attack",
        "track": "main",
        "status": "Reject",
        "keywords": "Deep Learning;Adversarial Perturbation;Adversarial Example;Categorical Learning",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "4;5;2;4",
        "correctness": "3;2;2;2",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;1;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "1kqWZlj4QYJ",
        "title": "Learning Two-Step Hybrid Policy for Graph-Based Interpretable Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Interpretable Reinforcement Learning;Generalization;Robustness",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;3;4;4",
        "correctness": "4;3;4;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;3;3;0",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "1nlRIagHDUB",
        "title": "Coresets for Kernel Clustering",
        "track": "main",
        "status": "Reject",
        "keywords": "coreset;clustering;kernel;PTAS;streaming;spectral clustering;k-means",
        "author": "",
        "aff": "Paper under double-blind review",
        "rating": "3;5;8",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "1oEvY1a67c1",
        "title": "If your data distribution shifts, use self-learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Self-Learning;Domain Adaptation;Robustness;Pseudolabeling;Entropy Minimization;Corruption Robustness",
        "author": "",
        "aff": "",
        "rating": "5;6;8",
        "confidence": "4;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "2;3;4",
        "presentation": "",
        "rating_avg": 6.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.944911182523068,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "1saVY0lW1x",
        "title": "Machine Learning Applications in Forecasting of COVID-19 Based on Patients' Individual Symptoms",
        "track": "main",
        "status": "Withdraw",
        "keywords": "COVID-19;Machine learning;Classification",
        "author": "",
        "aff": "Under double-blind review",
        "rating": "1;1;3",
        "confidence": "5;5;5",
        "correctness": "2;3;2",
        "technical_novelty": "1;1;1",
        "empirical_novelty": "1;2;2",
        "presentation": "",
        "rating_avg": 1.6666666666666667,
        "confidence_avg": 5.0,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 1.0,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.4999999999999999,
        "project": "",
        "github": ""
    },
    {
        "id": "1sx0Drq4jfT",
        "title": "Training Meta-Surrogate Model for Transferable Adversarial Attack",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "5;3;3;5",
        "correctness": "3;2;3;3",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "2;2;3;0",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "1uf_kj0GUF-",
        "title": "Nonparametric Learning of Two-Layer ReLU Residual Units",
        "track": "main",
        "status": "Reject",
        "keywords": "neural network learning;nonparametric methods;convex optimization",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "4;4;3;4",
        "correctness": "3;4;4;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4714045207910316,
        "corr_rating_correctness": 0.9428090415820632,
        "project": "",
        "github": ""
    },
    {
        "id": "1ugNpm7W6E",
        "title": "Cold Brew: Distilling Graph Node Representations with Incomplete or Missing Neighborhoods",
        "track": "main",
        "status": "Poster",
        "keywords": "Graph Neural Networks;Cold Start;Knowledge Distillation",
        "author": "",
        "aff": "Amazon.com",
        "rating": "6;6;6;6",
        "confidence": "3;4;3;4",
        "correctness": "3;4;3;3",
        "technical_novelty": "4;3;3;2",
        "empirical_novelty": "0;2;3;2",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/amazon-research/gnn-tail-generalization"
    },
    {
        "id": "1v1N7Zhmgcx",
        "title": "Maximum Likelihood Training of Parametrized Diffusion Model",
        "track": "main",
        "status": "Reject",
        "keywords": "Score-based Diffusion Model;Normalizing Flow Model;Variational Inference;Variational Gap;Stochastic Calculus",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "4;4;4;3",
        "correctness": "4;4;3;3",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": -1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "1wVvweK3oIb",
        "title": "Simple GNN Regularisation for 3D Molecular Property Prediction and Beyond",
        "track": "main",
        "status": "Poster",
        "keywords": "Graph Neural Networks;GNNs;Deep Learning;Molecular Property Prediction",
        "author": "",
        "aff": "DeepMind, London",
        "rating": "6;6;6;8",
        "confidence": "4;4;4;2",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;3;0;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "1xXvPrAshao",
        "title": "Learning Multimodal VAEs through Mutual Supervision",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Multimodal Variational Autoencoder;Variational Autoencoder",
        "author": "",
        "aff": "",
        "rating": "5;6;6;8",
        "confidence": "3;3;5;4",
        "correctness": "4;4;3;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;3;2",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3458572319330373,
        "corr_rating_correctness": 0.13245323570650439,
        "project": "",
        "github": ""
    },
    {
        "id": "1zwleytEpYx",
        "title": "Imitation Learning by Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "reinforcement learning;imitation learning;Markov Decision Process;continuous control",
        "author": "",
        "aff": "",
        "rating": "5;6;6;6",
        "confidence": "4;4;3;4",
        "correctness": "4;3;4;3",
        "technical_novelty": "3;3;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "2-mkiUs9Jx7",
        "title": "Stein Latent Optimization for Generative Adversarial Networks",
        "track": "main",
        "status": "Poster",
        "keywords": "Generative Adversarial Networks;Unsupervised Conditional GANs",
        "author": "",
        "aff": "",
        "rating": "6;6;6;6",
        "confidence": "3;4;3;4",
        "correctness": "4;3;4;3",
        "technical_novelty": "3;4;3;2",
        "empirical_novelty": "3;3;3;2",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "24N4XH2NaYq",
        "title": "Sparse Hierarchical Table Ensemble",
        "track": "main",
        "status": "Reject",
        "keywords": "tabular data;DL alternative;architecture",
        "author": "",
        "aff": "",
        "rating": "1;5;5;5",
        "confidence": "5;4;3;2",
        "correctness": "3;3;3;3",
        "technical_novelty": "1;2;2;3",
        "empirical_novelty": "1;2;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7745966692414834,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "25HMCfbzOC",
        "title": "Learning Complex Geometric Structures from Data with Deep Riemannian Manifolds",
        "track": "main",
        "status": "Withdraw",
        "keywords": "manifold;geometry;graph embedding;geodesic;differential equations;BVP;differentiable programming",
        "author": "",
        "aff": "",
        "rating": "1;3;3;6",
        "confidence": "2;3;4;3",
        "correctness": "2;3;2;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "1;2;3;3",
        "presentation": "",
        "rating_avg": 3.25,
        "confidence_avg": 3.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.39605901719066966,
        "corr_rating_correctness": 0.8866206949335731,
        "project": "",
        "github": ""
    },
    {
        "id": "25kzAhUB1lz",
        "title": "Direct then Diffuse: Incremental Unsupervised Skill Discovery for State Covering and Goal Reaching",
        "track": "main",
        "status": "Poster",
        "keywords": "unsupervised reinforcement learning;skill discovery;mutual information",
        "author": "",
        "aff": "",
        "rating": "6;6;8;8",
        "confidence": "4;4;4;3",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "26gKg6x-ie",
        "title": "Adversarial Support Alignment",
        "track": "main",
        "status": "Spotlight",
        "keywords": "support alignment;distribution alignment;optimal transport;domain adaptation",
        "author": "",
        "aff": "",
        "rating": "3;8;8;8",
        "confidence": "3;4;4;3",
        "correctness": "3;4;3;4",
        "technical_novelty": "2;3;4;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "27aftiBeius",
        "title": "$$Research on fusion algorithm of multi-attribute decision making and reinforcement learning based on intuitionistic fuzzy number in wargame environment$$",
        "track": "main",
        "status": "Reject",
        "keywords": "Wargame;Reinforcement learning;Multiple attribute decision making;Intelligent game",
        "author": "",
        "aff": "Under double-blind review",
        "rating": "1;1;3;5",
        "confidence": "4;4;4;2",
        "correctness": "1;1;2;3",
        "technical_novelty": "1;2;2;2",
        "empirical_novelty": "1;2;1;0",
        "presentation": "",
        "rating_avg": 2.5,
        "confidence_avg": 3.5,
        "correctness_avg": 1.75,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 1.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8703882797784891,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "28ib9tf6zhr",
        "title": "Patch-Fool: Are Vision Transformers Always Robust Against Adversarial Perturbations?",
        "track": "main",
        "status": "Poster",
        "keywords": "Vision transformer;adversarial examples;robustness",
        "author": "",
        "aff": "Department of Electrical and Computer Engineering, Rice University",
        "rating": "6;6;8;8",
        "confidence": "4;3;4;4",
        "correctness": "3;4;4;4",
        "technical_novelty": "3;3;4;3",
        "empirical_novelty": "2;3;4;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": "https://github.com/RICE-EIC/Patch-Fool"
    },
    {
        "id": "2DJn3E7lXu",
        "title": "What to expect of hardware metric predictors in NAS",
        "track": "main",
        "status": "Reject",
        "keywords": "Neural Architecture Search;Hardware-Aware;Predictors;Deep Learning",
        "author": "",
        "aff": "",
        "rating": "5;6;6;6",
        "confidence": "2;4;5;4",
        "correctness": "4;3;4;4",
        "technical_novelty": "1;1;2;1",
        "empirical_novelty": "2;4;3;2",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 1.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9271726499455306,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "2DJwuD-elOt",
        "title": "Hybrid Cloud-Edge Networks for Efficient Inference",
        "track": "main",
        "status": "Reject",
        "keywords": "low-capacity model;large-scale prediction;efficient inference;hybrid networks;routing nets;coverage and latency;FLOPs",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "3;4;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "3;3;2;3",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "2DT7DptUiXv",
        "title": "ConVAEr: Convolutional Variational AutoEncodeRs for incremental similarity learning",
        "track": "main",
        "status": "Reject",
        "keywords": "catastrophic forgetting;incremental similarity learning",
        "author": "",
        "aff": "",
        "rating": "1;1;5",
        "confidence": "4;3;3",
        "correctness": "2;2;3",
        "technical_novelty": "1;2;2",
        "empirical_novelty": "1;1;0",
        "presentation": "",
        "rating_avg": 2.3333333333333335,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 1.6666666666666667,
        "empirical_novelty_avg": 0.6666666666666666,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4999999999999999,
        "corr_rating_correctness": 0.9999999999999997,
        "project": "",
        "github": ""
    },
    {
        "id": "2I1wy0y6xo",
        "title": "Stability analysis of SGD through the normalized loss function",
        "track": "main",
        "status": "Reject",
        "keywords": "Generalization bounds;deep neural networks;stability",
        "author": "",
        "aff": "",
        "rating": "3;5;8",
        "confidence": "4;4;3",
        "correctness": "2;4;4",
        "technical_novelty": "1;2;3",
        "empirical_novelty": "1;2;3",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9176629354822472,
        "corr_rating_correctness": 0.8029550685469663,
        "project": "",
        "github": ""
    },
    {
        "id": "2JFVnWuvrvV",
        "title": "A Closer Look at Distribution Shifts and Out-of-Distribution Generalization on Graphs",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Graph Neural Networks;Distribution Shifts;Out-of-Distribution Generalization",
        "author": "",
        "aff": "",
        "rating": "3;3;3",
        "confidence": "5;4;4",
        "correctness": "3;2;3",
        "technical_novelty": "1;2;1",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 1.3333333333333333,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "2M0WXSP6Qi",
        "title": "Information-theoretic stochastic contrastive conditional GAN: InfoSCC-GAN",
        "track": "main",
        "status": "Reject",
        "keywords": "GANs;Generative adversarial networks;Contrastive learning;Conditional image generation",
        "author": "",
        "aff": "",
        "rating": "1;3;5",
        "confidence": "4;4;4",
        "correctness": "2;2;3",
        "technical_novelty": "1;1;3",
        "empirical_novelty": "1;2;3",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 1.6666666666666667,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.8660254037844385,
        "project": "https://anonymous.4open.science/r/InfoSCC-GAN-D113",
        "github": ""
    },
    {
        "id": "2NqIV8dzR7N",
        "title": "Automatic Termination for Hyperparameter Optimization",
        "track": "main",
        "status": "Reject",
        "keywords": "Bayesian optimization;hyperparameter optimization;automatic termination",
        "author": "",
        "aff": "",
        "rating": "5;6;6",
        "confidence": "4;3;4",
        "correctness": "3;3;2",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 5.666666666666667,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4999999999999999,
        "corr_rating_correctness": -0.4999999999999999,
        "project": "",
        "github": ""
    },
    {
        "id": "2O_pIShVl-",
        "title": "Polygonal Unadjusted Langevin Algorithms: Creating stable and efficient adaptive algorithms for neural networks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "nonconvex optimization;Langevin based algorithm",
        "author": "",
        "aff": "",
        "rating": "5;5;8",
        "confidence": "3;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "2;0;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "2PSrjVtj6gU",
        "title": "Graph Attention Multi-layer Perceptron",
        "track": "main",
        "status": "Reject",
        "keywords": "Graph Neural Network;Attention;Scalability",
        "author": "",
        "aff": "",
        "rating": "3;6;6;6",
        "confidence": "4;4;3;4",
        "correctness": "4;4;3;3",
        "technical_novelty": "2;1;2;2",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "2RNpZ8S4alJ",
        "title": "KINet: Keypoint Interaction Networks for Unsupervised Forward Modeling",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;4;4;4",
        "correctness": "3;3;2;2",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "2RYOwBOFesi",
        "title": "An Empirical Study of Pre-trained Models on Out-of-distribution Generalization",
        "track": "main",
        "status": "Reject",
        "keywords": "out-of-distribution generalization;domain generalization;pre-training",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "5;3;2;3",
        "correctness": "2;3;3;3",
        "technical_novelty": "1;2;1;2",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 1.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7894736842105263,
        "corr_rating_correctness": 0.9271726499455306,
        "project": "",
        "github": ""
    },
    {
        "id": "2_dQlkDHnvN",
        "title": "Defending Backdoor Data Poisoning Attacks by Using Noisy Label Defense Algorithm",
        "track": "main",
        "status": "Reject",
        "keywords": "Backdoor Attack;Data Poisoning;Noisy Label",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;3;4;4",
        "correctness": "3;2;4;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.13245323570650439,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "2_vhkAMARk",
        "title": "Escaping limit cycles: Global convergence for constrained nonconvex-nonconcave minimax problems",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Minimax;Nonconvex-Nonconcave;Variational inequilities;Saddle point problem;First-order methods;Limit cycles",
        "author": " Thomas Pethick \"3026 Puya Latafat \"3026 Panagiotis Patrinos[2] \"3026 Olivier Fercoq \"3026 Volkan Cevher[1] ",
        "aff": "Laboratory for Information and Inference Systems (LIONS), EPFL; Department of Electrical Engineering (ESAT-STADIUS), KU Leuven; Laboratoire Traitement et Communication d\u2019Information, T\u00e9l\u00e9com Paris, Institut Polytechnique de Paris; Not provided in the text",
        "rating": "5;8;8;8",
        "confidence": "3;3;3;4",
        "correctness": "4;4;4;4",
        "technical_novelty": "2;3;3;4",
        "empirical_novelty": "0;3;3;3",
        "presentation": "",
        "rating_avg": 7.25,
        "confidence_avg": 3.25,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "2aC0_RxkBL_",
        "title": "Where is the bottleneck in long-tailed classification?",
        "track": "main",
        "status": "Reject",
        "keywords": "fairness;bias;long tailed learning;imbalanced learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;8",
        "confidence": "5;4;5;5",
        "correctness": "2;2;3;4",
        "technical_novelty": "2;2;1;3",
        "empirical_novelty": "2;2;2;4",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.49374193110101877,
        "corr_rating_correctness": 0.9945577827230725,
        "project": "",
        "github": ""
    },
    {
        "id": "2bO2x8NAIMB",
        "title": "Should We Be Pre-training? An Argument for End-task Aware Training as an Alternative",
        "track": "main",
        "status": "Poster",
        "keywords": "pre-training;multitask learning;meta-learning;deeplearning;end-task aware training;NLP",
        "author": "",
        "aff": "Carnegie Mellon University, Determined AI; Carnegie Mellon University; ENS PSL University",
        "rating": "5;6;6;6",
        "confidence": "4;3;4;3",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "2big50UF39",
        "title": "Active Deep Multiple Instance Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "multiple instance learning;active learning",
        "author": "",
        "aff": "",
        "rating": "3;3;3;6",
        "confidence": "3;5;5;3",
        "correctness": "2;2;4;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.17407765595569782,
        "project": "",
        "github": ""
    },
    {
        "id": "2cpsEstmH1",
        "title": "Beyond Examples: Constructing Explanation Space for Explaining Prototypes",
        "track": "main",
        "status": "Reject",
        "keywords": "Interpretable machine learning;XAI;Uncertainty;Prototype-based classification",
        "author": "",
        "aff": "",
        "rating": "3;5;5;8",
        "confidence": "3;3;2;3",
        "correctness": "2;3;2;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 2.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.08084520834544431,
        "corr_rating_correctness": 0.8866206949335731,
        "project": "",
        "github": ""
    },
    {
        "id": "2d4riGOpmU8",
        "title": "Sequential Covariate Shift Detection Using Classifier Two-Sample Tests",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "3;5;3;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "3;0;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.24618298195866545,
        "corr_rating_correctness": 0.4714045207910316,
        "project": "",
        "github": ""
    },
    {
        "id": "2e7Bf6b-v_P",
        "title": "ES-ENAS: Blackbox Optimization over Hybrid Spaces via Combinatorial and Continuous Evolution",
        "track": "main",
        "status": "Withdraw",
        "keywords": "ES;ENAS;hybrid;search;space;blackbox;combinatorial;optimization;reinforcement;learning;mujoco;policies;evolutionary;computation;neuroevolution;high;dimension;supernet;one-shot;nas;neural;architecture;search;efficient",
        "author": "",
        "aff": "",
        "rating": "3;3;5",
        "confidence": "4;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "2eXhNpHeW6E",
        "title": "R5: Rule Discovery with Reinforced and Recurrent Relational Reasoning",
        "track": "main",
        "status": "Spotlight",
        "keywords": "systematicity;graph reasoning",
        "author": "",
        "aff": "Huawei Kirin Solution; RALI & Mila, Universit\u00e9 de Montr\u00e9al, Canada CIFAR AI Chair; Department of Electrical and Computer Engineering, University of Alberta",
        "rating": "5;6;6",
        "confidence": "3;5;3",
        "correctness": "3;4;3",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 5.666666666666667,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.4999999999999999,
        "corr_rating_correctness": 0.4999999999999999,
        "project": "",
        "github": ""
    },
    {
        "id": "2f1z55GVQN",
        "title": "Critical Points in Quantum Generative Models",
        "track": "main",
        "status": "Poster",
        "keywords": "loss landscapes;quantum;Wishart spin-glass model",
        "author": "",
        "aff": "MIT Center for Theoretical Physics, Cambridge, MA 02139, USA",
        "rating": "6;8;8",
        "confidence": "4;3;3",
        "correctness": "2;4;4",
        "technical_novelty": "3;4;4",
        "empirical_novelty": "2;3;2",
        "presentation": "",
        "rating_avg": 7.333333333333333,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.6666666666666665,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9999999999999998,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "2g9m74He1Ky",
        "title": "Spatio-temporal Disentangled representation learning for mobility prediction",
        "track": "main",
        "status": "Reject",
        "keywords": "Disentangled representation learning;Spatio-temporal data;principle of relevant information",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "5;5;4;3",
        "correctness": "3;3;2;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;0;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8703882797784891,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "2ggNjUisGyr",
        "title": "Partial Wasserstein Adversarial Network for Non-rigid Point Set Registration",
        "track": "main",
        "status": "Poster",
        "keywords": "partial Wasserstein discrepancy;partial distribution matching;point set registration",
        "author": "",
        "aff": "CAPTAIN, Wuhan University",
        "rating": "6;6;6;6;6",
        "confidence": "3;4;3;4;3",
        "correctness": "3;4;4;4;3",
        "technical_novelty": "3;3;2;3;2",
        "empirical_novelty": "3;2;3;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.4,
        "correctness_avg": 3.6,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 2.8,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "2hMEdc35xZ6",
        "title": "Defect Transfer GAN: Diverse Defect Synthesis for Data Augmentation",
        "track": "main",
        "status": "Reject",
        "keywords": "Defect synthesis;Generative Adversarial Networks;Content transfer;Automated visual inspection;Data augmentation",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3;5",
        "confidence": "5;4;4;4;4",
        "correctness": "3;3;3;3;2",
        "technical_novelty": "2;2;2;2;2",
        "empirical_novelty": "2;3;2;2;2",
        "presentation": "",
        "rating_avg": 3.4,
        "confidence_avg": 4.2,
        "correctness_avg": 2.8,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.2,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.25,
        "corr_rating_correctness": -1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "2hnbGJBFsv",
        "title": "Domain Adaptation via Maximizing Surrogate Mutual Information",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Domain Adaptation;Transfer Learning;Information Theory",
        "author": "",
        "aff": "",
        "rating": "5;5;5",
        "confidence": "3;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "4;3;3",
        "empirical_novelty": "0;2;0",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.3333333333333335,
        "empirical_novelty_avg": 0.6666666666666666,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "2jYxq9_TkpG",
        "title": "Network Pruning Optimization by Simulated Annealing Algorithm",
        "track": "main",
        "status": "Reject",
        "keywords": "optimization;network pruning",
        "author": "",
        "aff": "",
        "rating": "1;3;3;3",
        "confidence": "4;4;4;4",
        "correctness": "2;3;3;2",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;1",
        "presentation": "",
        "rating_avg": 2.5,
        "confidence_avg": 4.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "2p_5F9sHN9",
        "title": "The Geometry of Adversarial Subspaces",
        "track": "main",
        "status": "Reject",
        "keywords": "adversarial attack;decision boundary;riemannian geometry;differential geometry;interpretability;adversarial training",
        "author": "",
        "aff": "",
        "rating": "6;6;6;6",
        "confidence": "4;4;4;4",
        "correctness": "3;4;4;3",
        "technical_novelty": "3;3;3;2",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "2s4sNT11IcH",
        "title": "On the Convergence and Calibration of Deep Learning with Differential Privacy",
        "track": "main",
        "status": "Reject",
        "keywords": "Deep Learning;Differential Privacy;Optimization Algorithms;Convergence Theory;Calibration",
        "author": "",
        "aff": "",
        "rating": "3;3;5;8",
        "confidence": "4;3;3;4",
        "correctness": "2;4;3;4",
        "technical_novelty": "2;2;3;4",
        "empirical_novelty": "2;2;4;4",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3665083330689157,
        "corr_rating_correctness": 0.47886115464444223,
        "project": "",
        "github": ""
    },
    {
        "id": "2sDQwC_hmnM",
        "title": "ZeroFL: Efficient On-Device Training for Federated Learning with Local Sparsity",
        "track": "main",
        "status": "Poster",
        "keywords": "Federated Learning;sparse training",
        "author": "",
        "aff": "Department of Computer Science, University of Oxford; Department of Computer Science and Technology, University of Cambridge; Laboratoire Informatique d\u2019Avignon, Avignon Universit\u00e9",
        "rating": "5;6;6",
        "confidence": "4;4;3",
        "correctness": "4;4;2",
        "technical_novelty": "2;3;2",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 5.666666666666667,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4999999999999999,
        "corr_rating_correctness": -0.4999999999999999,
        "project": "",
        "github": ""
    },
    {
        "id": "2t7CkQXNpuq",
        "title": "ToM2C: Target-oriented Multi-agent Communication and Cooperation with Theory of Mind",
        "track": "main",
        "status": "Poster",
        "keywords": "Theory of Mind;Target-oriented Multi-Agent Cooperation;Multi-agent Communication",
        "author": "",
        "aff": "Center on Frontiers of Computing Studies, School of Computer Science, Peking University; Center for Data Science, Peking University; School of Arti\ufb01cial Intelligence, Peking University",
        "rating": "6;6;6",
        "confidence": "4;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "3;3;2",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "2wiaitACS_O",
        "title": "CUP: A Conservative Update Policy Algorithm for Safe Reinforcement Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "reinforcement learning;constrained Markov decision processes;safety learning",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "3;4;4;2",
        "correctness": "4;3;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;0;2",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.20751433915982243,
        "corr_rating_correctness": -0.9271726499455306,
        "project": "",
        "github": ""
    },
    {
        "id": "2yITmG7YIFT",
        "title": "HD-cos Networks: Efficient Neural Architechtures for Secure Multi-Party Computation",
        "track": "main",
        "status": "Reject",
        "keywords": "multi-party computation;privacy;cryptography;privacy-preserving machine learning",
        "author": "",
        "aff": "",
        "rating": "1;3;5;5",
        "confidence": "5;3;4;4",
        "correctness": "1;2;3;3",
        "technical_novelty": "1;2;2;3",
        "empirical_novelty": "0;2;2;3",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.0,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.42640143271122083,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "2z5h4hY-LQ",
        "title": "GAETS: A Graph Autoencoder Time Series Approach Towards Battery Parameter Estimation",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "3;4;4;3",
        "correctness": "2;2;4;2",
        "technical_novelty": "2;2;1;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "30SXt3-vvnM",
        "title": "Model-Efficient Deep Learning with Kernelized Classification",
        "track": "main",
        "status": "Reject",
        "keywords": "deep networks;kernels on the sphere;nonlinear classification",
        "author": "",
        "aff": "",
        "rating": "3;3;6;6",
        "confidence": "4;4;3;4",
        "correctness": "3;2;4;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896258,
        "corr_rating_correctness": 0.9045340337332909,
        "project": "",
        "github": ""
    },
    {
        "id": "30nbp1eV0dJ",
        "title": "Tight lower bounds for Differentially Private ERM",
        "track": "main",
        "status": "Reject",
        "keywords": "Differential Privacy;Empirical Risk Minimization;Lower bounds",
        "author": "",
        "aff": "",
        "rating": "3;5;5;8",
        "confidence": "4;3;2;3",
        "correctness": "4;2;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "0;0;3;1",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 1.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.39605901719066966,
        "corr_rating_correctness": 0.08084520834544431,
        "project": "",
        "github": ""
    },
    {
        "id": "31d5RLCUuXC",
        "title": "A Tale of Two Flows: Cooperative Learning of Langevin Flow and Normalizing Flow Toward Energy-Based Model",
        "track": "main",
        "status": "Poster",
        "keywords": "Langevin dynamics;energy-based model;normalizing flow;cooperative learning;short-run MCMC",
        "author": "",
        "aff": "Cognitive Computing Lab, Baidu Research, 10900 NE 8th St. Bellevue, WA 98004, USA",
        "rating": "3;6;6;8",
        "confidence": "4;3;4;3",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7001400420140049,
        "corr_rating_correctness": 0.7276068751089989,
        "project": "",
        "github": ""
    },
    {
        "id": "327eol9Xgyi",
        "title": "Trident Pyramid Networks: The importance of processing at the feature pyramid level for better object detection",
        "track": "main",
        "status": "Reject",
        "keywords": "feature pyramid;network architecture;object detection;deep learning",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "5;5;4;4",
        "correctness": "4;4;3;3",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8164965809277259,
        "corr_rating_correctness": -0.8164965809277259,
        "project": "",
        "github": ""
    },
    {
        "id": "32KyhxmvmO",
        "title": "Learning Representations of Partial Subgraphs by Subgraph InfoMax",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Graph Neural Network;Subgraph;Mutual Information Maximization",
        "author": "",
        "aff": "",
        "rating": "3;3;3",
        "confidence": "4;4;4",
        "correctness": "3;3;2",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "3;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "32OdIHsu1_",
        "title": "DL-based prediction of optimal actions of human experts",
        "track": "main",
        "status": "Reject",
        "keywords": "deep learning;expert system;sequential learning",
        "author": "",
        "aff": "",
        "rating": "1;3;3;5",
        "confidence": "4;4;3;4",
        "correctness": "3;1;1;1",
        "technical_novelty": "1;2;2;2",
        "empirical_novelty": "1;2;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 1.5,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "33nhOe3cTd",
        "title": "Spending Thinking Time Wisely: Accelerating MCTS with Virtual Expansions",
        "track": "main",
        "status": "Reject",
        "keywords": "Computer Go;Monte-Carlo Tree Search;Reinforcement learning;Adaptive;Acceleration",
        "author": "",
        "aff": "",
        "rating": "3;5;8",
        "confidence": "5;4;4",
        "correctness": "2;3;3",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8029550685469661,
        "corr_rating_correctness": 0.8029550685469661,
        "project": "",
        "github": ""
    },
    {
        "id": "34k1OWJWtDW",
        "title": "Sample-specific and Context-aware Augmentation for Long Tail Image Classification",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Long-tail image classification;Semantic augmentation",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;4;4;3",
        "correctness": "3;2;1;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "3;2;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.75,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.5222329678670935,
        "project": "",
        "github": ""
    },
    {
        "id": "34mWBCWMxh9",
        "title": "Blur Is an Ensemble: Spatial Smoothings to Improve Accuracy, Uncertainty, and Robustness",
        "track": "main",
        "status": "Reject",
        "keywords": "bayesian neural network;uncertainty;uncertainty estimation;uncertainty quantification",
        "author": "",
        "aff": "",
        "rating": "5;5;5;8",
        "confidence": "4;3;4;2",
        "correctness": "2;3;3;3",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8703882797784892,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "35-QqyfmjfP",
        "title": "AnoSeg: Anomaly Segmentation Network Using Self-Supervised Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Anomaly detection;Anomaly segmentation;Self-Supervised learning",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;3;3;5",
        "correctness": "1;3;3;3",
        "technical_novelty": "1;2;3;2",
        "empirical_novelty": "1;2;4;4",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.75,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.20751433915982243,
        "corr_rating_correctness": 0.9271726499455306,
        "project": "",
        "github": ""
    },
    {
        "id": "35jJIcBiEyj",
        "title": "From Biased Data to Unbiased Models: a Meta-Learning Approach",
        "track": "main",
        "status": "Withdraw",
        "keywords": "dataset bias;out of distribution;meta-learning;data augmentation",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;3;4;3",
        "correctness": "3;2;3;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6882472016116854,
        "corr_rating_correctness": 0.3244428422615251,
        "project": "",
        "github": ""
    },
    {
        "id": "36SHWj0Gp1",
        "title": "GenTAL: Generative Denoising Skip-gram Transformer for Unsupervised Binary Code Similarity Detection",
        "track": "main",
        "status": "Reject",
        "keywords": "Representation Learning;Transformer;Autoencoder;Binary Code Similarity Detection",
        "author": "",
        "aff": "",
        "rating": "1;3;6",
        "confidence": "5;5;2",
        "correctness": "3;3;3",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 3.3333333333333335,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.917662935482247,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "36rU1ecTFvR",
        "title": "Can standard training with clean images outperform adversarial one in robust accuracy?",
        "track": "main",
        "status": "Reject",
        "keywords": "Adversarial Training;Robust Accuracy",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "4;3;4;4",
        "correctness": "2;2;4;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;4;2",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5555555555555555,
        "corr_rating_correctness": 0.7543365091413573,
        "project": "",
        "github": ""
    },
    {
        "id": "39Q__qgCpAH",
        "title": "Achieving Small-Batch Accuracy with Large-Batch Scalability via Adaptive Learning Rate Adjustment",
        "track": "main",
        "status": "Withdraw",
        "keywords": "deep learning;large-batch training",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;4;5",
        "correctness": "3;2;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "3AkuJOgL_X",
        "title": "Federated Robustness Propagation: Sharing Adversarial Robustness in Federated Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "federated learning;data heterogeneity;hardware heterogeneity;security heterogeneity;adversarial robustness",
        "author": "",
        "aff": "",
        "rating": "3;3;6;8;8",
        "confidence": "4;4;3;4;4",
        "correctness": "2;4;3;4;3",
        "technical_novelty": "3;2;3;3;3",
        "empirical_novelty": "3;2;2;3;3",
        "presentation": "",
        "rating_avg": 5.6,
        "confidence_avg": 3.8,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.8,
        "empirical_novelty_avg": 2.6,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.08908708063747481,
        "corr_rating_correctness": 0.28571428571428575,
        "project": "",
        "github": ""
    },
    {
        "id": "3ByLvyOSyan",
        "title": "A Robust Initialization of Residual Blocks for Effective ResNet Training without Batch Normalization",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Normalization-Free ResNets;Weights Initialization;Exploding Gradient;Residual Blocks",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "5;3;4;5",
        "correctness": "3;3;3;2",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5222329678670935,
        "corr_rating_correctness": -1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "3CRkJ9GRs3I",
        "title": "Understanding ResNet from a Discrete Dynamical System Perspective",
        "track": "main",
        "status": "Withdraw",
        "keywords": "the condition number of modules;median principal angle;network mathematical description",
        "author": "",
        "aff": "",
        "rating": "1;3;3",
        "confidence": "3;3;5",
        "correctness": "1;2;1",
        "technical_novelty": "1;1;1",
        "empirical_novelty": "1;1;2",
        "presentation": "",
        "rating_avg": 2.3333333333333335,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 1.3333333333333333,
        "technical_novelty_avg": 1.0,
        "empirical_novelty_avg": 1.3333333333333333,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5000000000000001,
        "corr_rating_correctness": 0.5000000000000001,
        "project": "",
        "github": ""
    },
    {
        "id": "3FvF1db-bKT",
        "title": "Local Augmentation for Graph Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "Local Augmentation;Graph Neural Networks",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;3;3;2",
        "correctness": "2;3;3;2",
        "technical_novelty": "3;4;2;2",
        "empirical_novelty": "1;3;2;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.816496580927726,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "3GHHpYrYils",
        "title": "On Anytime Learning at Macroscale",
        "track": "main",
        "status": "Reject",
        "keywords": "Anytime Learning;Mixture of experts;growing architectures",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;4;4;3",
        "correctness": "1;3;3;4",
        "technical_novelty": "2;2;1;2",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6622661785325219,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "3HJOA-1hb0e",
        "title": "Toward Efficient Low-Precision Training: Data Format Optimization and Hysteresis Quantization",
        "track": "main",
        "status": "Poster",
        "keywords": "low-precision training;quantized training;logarithmic weight;data format optimization;hysteresis quantization",
        "author": "",
        "aff": "Graduate School of Convergence Science and Technology, Seoul National University, Seoul, Korea",
        "rating": "5;5;6;8",
        "confidence": "4;5;4;5",
        "correctness": "3;2;3;3",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.40824829046386296,
        "corr_rating_correctness": 0.4714045207910316,
        "project": "",
        "github": ""
    },
    {
        "id": "3ILxkQ7yElm",
        "title": "Learning Continuous Environment Fields via Implicit Functions",
        "track": "main",
        "status": "Poster",
        "keywords": "Continuous Scene Representation;Implicit Neural Networks",
        "author": "",
        "aff": "UC San Diego; NVIDIA; UC Merced",
        "rating": "1;6;8",
        "confidence": "5;4;2",
        "correctness": "1;3;4",
        "technical_novelty": "1;2;3",
        "empirical_novelty": "1;2;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9078412990032039,
        "corr_rating_correctness": 0.9986254289035241,
        "project": "",
        "github": ""
    },
    {
        "id": "3JvRnAzw_0",
        "title": "Robust Weight Perturbation for Adversarial Training",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;5;4;4",
        "correctness": "2;1;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.25,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.9045340337332909,
        "project": "",
        "github": ""
    },
    {
        "id": "3Li0OPkhQU",
        "title": "Provable Learning of Convolutional Neural Networks with Data Driven Features",
        "track": "main",
        "status": "Reject",
        "keywords": "Deep learning theory;convolutional neural networks",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "3;5;3;3",
        "correctness": "3;1;3;4",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "0;1;2;4",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": -0.13245323570650439,
        "project": "",
        "github": ""
    },
    {
        "id": "3M3t3tUbA2Y",
        "title": "DreamerPro: Reconstruction-Free Model-Based Reinforcement Learning with Prototypical Representations",
        "track": "main",
        "status": "Reject",
        "keywords": "model-based reinforcement learning;representation learning",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;4;3;4",
        "correctness": "2;4;3;4",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;3;3;2",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.13245323570650439,
        "corr_rating_correctness": 0.899228803025897,
        "project": "",
        "github": ""
    },
    {
        "id": "3MjOIZ2CF9",
        "title": "An evaluation of quality and robustness of smoothed explanations",
        "track": "main",
        "status": "Reject",
        "keywords": "Explanation methods;Interpretability;Robustness;Adversarial attacks",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "4;4;4;4",
        "correctness": "2;3;3;4",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.7071067811865475,
        "project": "",
        "github": ""
    },
    {
        "id": "3Od_-TkEdnG",
        "title": "Domain-wise Adversarial Training for Out-of-Distribution Generalization",
        "track": "main",
        "status": "Reject",
        "keywords": "Domain Generalization;IRM;Adversarial Training",
        "author": "",
        "aff": "",
        "rating": "5;6;6;8",
        "confidence": "4;5;4;3",
        "correctness": "4;3;4;3",
        "technical_novelty": "3;2;2;4",
        "empirical_novelty": "0;2;2;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6488856845230502,
        "corr_rating_correctness": -0.6882472016116854,
        "project": "",
        "github": ""
    },
    {
        "id": "3PN4iyXBeF",
        "title": "Amortized Implicit Differentiation for Stochastic Bilevel Optimization",
        "track": "main",
        "status": "Poster",
        "keywords": "bilevel optimization;stochastic optimization",
        "author": "",
        "aff": "Univ. Grenoble Alpes, Inria, CNRS, Grenoble INP, LJK, 38000 Grenoble, France.",
        "rating": "3;6;6;6;8",
        "confidence": "3;3;3;3;2",
        "correctness": "2;4;3;4;3",
        "technical_novelty": "2;3;2;3;3",
        "empirical_novelty": "2;2;2;2;2",
        "presentation": "",
        "rating_avg": 5.8,
        "confidence_avg": 2.8,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6875000000000001,
        "corr_rating_correctness": 0.5345224838248488,
        "project": "",
        "github": ""
    },
    {
        "id": "3Pbra-_u76D",
        "title": "Rethinking Network Design and Local Geometry in Point Cloud: A Simple Residual MLP Framework",
        "track": "main",
        "status": "Poster",
        "keywords": "point cloud representation;local relation;mlp",
        "author": "",
        "aff": "Columbia University, New York, NY, USA; Northeastern University, Boston, MA, USA",
        "rating": "6;6;8",
        "confidence": "2;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "2;2;0",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 1.3333333333333333,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/ma-xu/pointMLP-pytorch"
    },
    {
        "id": "3Qh8ezpsca",
        "title": "Towards simple time-to-event modeling: optimizing neural networks via rank regression",
        "track": "main",
        "status": "Reject",
        "keywords": "time-to-event analysis;survival analysis;semiparametric method;accelerated failure time",
        "author": "",
        "aff": "",
        "rating": "1;3;3;5;6",
        "confidence": "5;4;4;2;4",
        "correctness": "2;2;2;3;3",
        "technical_novelty": "2;1;2;2;3",
        "empirical_novelty": "2;2;1;1;3",
        "presentation": "",
        "rating_avg": 3.6,
        "confidence_avg": 3.8,
        "correctness_avg": 2.4,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.8,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6321954228176435,
        "corr_rating_correctness": 0.8897565210026093,
        "project": "",
        "github": ""
    },
    {
        "id": "3SUToIxuIT3",
        "title": "Efficient Point Transformer for Large-scale 3D Scene Understanding",
        "track": "main",
        "status": "Withdraw",
        "keywords": "3D scene understanding;self-attention;transformer",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "4;3;4;4",
        "correctness": "4;3;3;3",
        "technical_novelty": "3;3;3;2",
        "empirical_novelty": "3;3;0;2",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "3Skn65dgAr4",
        "title": "Differentiable Self-Adaptive Learning Rate",
        "track": "main",
        "status": "Reject",
        "keywords": "self-adaptive learning rate",
        "author": "",
        "aff": "",
        "rating": "1;3;3;8",
        "confidence": "5;5;5;5",
        "correctness": "3;3;2;4",
        "technical_novelty": "1;2;1;3",
        "empirical_novelty": "1;2;1;3",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 5.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.6835859270246631,
        "project": "",
        "github": ""
    },
    {
        "id": "3UeYAgzUe3",
        "title": "Encouraging Disentangled and Convex Representation with Controllable Interpolation Regularization",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;6",
        "confidence": "4;4;2",
        "correctness": "2;3;4",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "1;2;3",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7559289460184546,
        "corr_rating_correctness": 0.9819805060619659,
        "project": "",
        "github": ""
    },
    {
        "id": "3Uk9_JRVwiF",
        "title": "AID-PURIFIER: A LIGHT AUXILIARY NETWORK FOR BOOSTING ADVERSARIAL DEFENSE",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;6",
        "confidence": "4;3;4",
        "correctness": "3;3;4",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.18898223650461363,
        "corr_rating_correctness": 0.7559289460184545,
        "project": "",
        "github": ""
    },
    {
        "id": "3Wybo29gGlx",
        "title": "Should we Replace CNNs with Transformers for Medical Images?",
        "track": "main",
        "status": "Reject",
        "keywords": "vision transformers;medical image analysis",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5;6",
        "confidence": "4;4;4;4;5",
        "correctness": "4;2;2;2;3",
        "technical_novelty": "1;1;1;2;1",
        "empirical_novelty": "2;2;2;2;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.2,
        "correctness_avg": 2.6,
        "technical_novelty_avg": 1.2,
        "empirical_novelty_avg": 2.2,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.7905694150420948,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "3XD_rnM97s",
        "title": "Understanding Knowledge Integration in Language Models with Graph Convolutions",
        "track": "main",
        "status": "Reject",
        "keywords": "knowledge integration;graph convolution;language model;interpretation;knowledge graph;mutual information",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6;8",
        "confidence": "4;4;3;3;3",
        "correctness": "2;3;3;2;4",
        "technical_novelty": "3;2;3;3;4",
        "empirical_novelty": "2;3;4;3;3",
        "presentation": "",
        "rating_avg": 5.6,
        "confidence_avg": 3.4,
        "correctness_avg": 2.8,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8040302522073698,
        "corr_rating_correctness": 0.7566444492037343,
        "project": "",
        "github": ""
    },
    {
        "id": "3XcEQTRyxhp",
        "title": "Object-Aware Cropping for Self-Supervised Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Object cropping;Self-Supervised learning for multi-object dataset.",
        "author": "",
        "aff": "",
        "rating": "1;3;3;6",
        "confidence": "5;5;4;4",
        "correctness": "1;4;2;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "1;2;2;2",
        "presentation": "",
        "rating_avg": 3.25,
        "confidence_avg": 4.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7001400420140049,
        "corr_rating_correctness": 0.7815036806726284,
        "project": "",
        "github": ""
    },
    {
        "id": "3YqeuCVwy1d",
        "title": "GDA-AM: ON THE EFFECTIVENESS OF SOLVING MIN-IMAX OPTIMIZATION VIA ANDERSON MIXING",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "Department of Computer Science, Emory University, Atlanta, GA 30329, USA; Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MN 55455, USA",
        "rating": "5;6;6;8",
        "confidence": "3;5;4;3",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;1;3;3",
        "empirical_novelty": "2;3;3;2",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.20751433915982243,
        "corr_rating_correctness": 0.9271726499455306,
        "project": "",
        "github": "https://github.com/hehuannb/GDA-AM"
    },
    {
        "id": "3ZuLmU7zBpy",
        "title": "Sanitizer: Sanitizing data for anonymizing sensitive information",
        "track": "main",
        "status": "Withdraw",
        "keywords": "privacy preserving machine learning;private data release;privacy for computer vision",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "3;4;4;3",
        "correctness": "2;2;2;2",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "0;2;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "3aZMdP1BdSm",
        "title": "Identifying Interactions among Categorical Predictors with Monte-Carlo Tree Search",
        "track": "main",
        "status": "Withdraw",
        "keywords": "interaction identification;Monte Carlo tree search;decision tree",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "3;3;3;3",
        "correctness": "2;2;4;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;0;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9045340337332909,
        "project": "",
        "github": ""
    },
    {
        "id": "3eIrli0TwQ",
        "title": "On the Importance of Difficulty Calibration in Membership Inference Attacks",
        "track": "main",
        "status": "Poster",
        "keywords": "membership inference attack;privacy",
        "author": "",
        "aff": "Meta AI; University of Edinburgh",
        "rating": "5;5;5;8",
        "confidence": "2;4;4;5",
        "correctness": "3;3;3;4",
        "technical_novelty": "3;2;2;2",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.662266178532522,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "3iH9ewU_KJT",
        "title": "MT-GBM: A Multi-Task Gradient Boosting Machine with Shared Decision Trees",
        "track": "main",
        "status": "Reject",
        "keywords": "Multi-Task learning;Classification",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "4;4;3;3",
        "correctness": "1;2;2;3",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "3jooF27-0Wy",
        "title": "FlexConv: Continuous Kernel Convolutions With Differentiable Kernel Sizes",
        "track": "main",
        "status": "Poster",
        "keywords": "Convolutional neural networks;learnable kernel size;continuous convolutional kernels;alias-free convolutional networks;implicit neural representations;resolution-agnostic representations;time series;sequential data;computer vision",
        "author": "",
        "aff": "Vrije Universiteit Amsterdam; Delft University of Technology; University of Amsterdam",
        "rating": "6;6;6;8",
        "confidence": "3;3;4;4",
        "correctness": "3;2;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "3kK8x_92hnD",
        "title": "Topological Vanilla Transfer Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "vanilla transfer learning;topological machine learning;linear homeomorphism",
        "author": "",
        "aff": "",
        "rating": "3;3;3",
        "confidence": "4;3;4",
        "correctness": "2;3;4",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "3kTt_W1_tgw",
        "title": "$f$-Mutual Information Contrastive Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "contrastive learning;f-divergence;mutual information",
        "author": "",
        "aff": "",
        "rating": "5;6;6;6",
        "confidence": "4;3;4;4",
        "correctness": "2;3;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.8703882797784891,
        "project": "",
        "github": ""
    },
    {
        "id": "3mgYqlH60Uj",
        "title": "Learning Symmetric Locomotion using Cumulative Fatigue for Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "reinforcement learning;biomechanical model;cumulative fatigue;animation;bioinspired models;physics-based simulation;locomotion",
        "author": "",
        "aff": "",
        "rating": "5;6;6;6",
        "confidence": "5;3;4;3",
        "correctness": "3;3;3;1",
        "technical_novelty": "3;3;3;2",
        "empirical_novelty": "3;2;2;0",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.75,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8703882797784891,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "3mm5rjb7nR8",
        "title": "Learning Global Spatial Information for Multi-View Object-Centric Models",
        "track": "main",
        "status": "Reject",
        "keywords": "deep generative models;object-centric representation learning;segmentation",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5",
        "confidence": "4;5;3;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;3;2;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "3pZTPQjeQDR",
        "title": "How BPE Affects Memorization in Transformers",
        "track": "main",
        "status": "Reject",
        "keywords": "training data memorization;Byte-Pair Encoding;Transformers",
        "author": "",
        "aff": "",
        "rating": "6;6;6",
        "confidence": "5;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "3pugbNqOh5m",
        "title": "Practical Conditional Neural Process Via Tractable Dependent Predictions",
        "track": "main",
        "status": "Poster",
        "keywords": "conditional neural processes;neural processes;meta-learning;convolutional conditional neural processes;Gaussian neural processes",
        "author": "",
        "aff": "University of Cambridge; University of Cambridge, Invenia Labs",
        "rating": "6;6;8",
        "confidence": "3;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "2;3;2",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.49999999999999983,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "3r034NfDKnL",
        "title": "The Role of Learning Regime, Architecture and Dataset Structure on Systematic Generalization in Simple Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "Systematic Generalization;Iterated Learning;Linear Neural Networks",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;3;3;4",
        "correctness": "4;3;3;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": -1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "3rULBvOJ8D2",
        "title": "Unraveling Model-Agnostic Meta-Learning via The Adaptation Learning Rate",
        "track": "main",
        "status": "Poster",
        "keywords": "Meta-Learning;Learning rate;Optimization",
        "author": "",
        "aff": "National University of Singapore, Singapore",
        "rating": "5;5;5;6;6",
        "confidence": "4;2;4;1;2",
        "correctness": "3;3;4;3;3",
        "technical_novelty": "2;3;3;3;3",
        "empirical_novelty": "2;3;2;0;0",
        "presentation": "",
        "rating_avg": 5.4,
        "confidence_avg": 2.6,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.8,
        "empirical_novelty_avg": 1.4,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7484551991837489,
        "corr_rating_correctness": -0.408248290463863,
        "project": "",
        "github": ""
    },
    {
        "id": "3t0ZcNhBs5",
        "title": "Beyond Message Passing Paradigm: Training Graph Data with Consistency Constraints",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Graph Learning;Multilayer Perceptrons;Consistency Constraints",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "4;4;4;5",
        "correctness": "3;2;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.7777777777777777,
        "corr_rating_correctness": 0.5555555555555555,
        "project": "",
        "github": ""
    },
    {
        "id": "3tbDrs77LJ5",
        "title": "Large Learning Rate Tames Homogeneity: Convergence and Balancing Effect",
        "track": "main",
        "status": "Poster",
        "keywords": "large learning rate;gradient descent;matrix factorization;implicit regularization;convergence;balancing;alignment",
        "author": "",
        "aff": "Georgia Institute of Technology",
        "rating": "5;6;8;8",
        "confidence": "4;3;3;4",
        "correctness": "4;3;4;3",
        "technical_novelty": "2;3;4;3",
        "empirical_novelty": "2;3;0;0",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 1.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.19245008972987526,
        "corr_rating_correctness": -0.19245008972987526,
        "project": "",
        "github": ""
    },
    {
        "id": "3wNcr5nq56",
        "title": "The Uncanny Similarity of Recurrence and Depth",
        "track": "main",
        "status": "Poster",
        "keywords": "Deep learning;recurrent networks;depth",
        "author": "",
        "aff": "Department of Robotics, University of Maryland, College Park, MD, USA; Department of Computer Science, University of Maryland, College Park, MD, USA; Department of Mathematics, University of Maryland, College Park, MD, USA",
        "rating": "6;6;6;8",
        "confidence": "5;4;5;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "1;2;2;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 4.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "3wU2UX0voE",
        "title": "The Information Geometry of Unsupervised Reinforcement Learning",
        "track": "main",
        "status": "Oral",
        "keywords": "unsupervised skill learning;reward-free RL;mutual information;DIAYN",
        "author": "",
        "aff": "Carnegie Mellon University; Google Brain, UC Berkeley",
        "rating": "8;8;8",
        "confidence": "4;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "4;4;4",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 4.0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "3z9RnbAS49",
        "title": "A Theoretical and Empirical Model of the Generalization Error under Time-Varying Learning Rate",
        "track": "main",
        "status": "Reject",
        "keywords": "deep learning;generalization error;stochastic gradient descent;functional form;hyperparameter;batch size;learning rate",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "3;4;4;4",
        "correctness": "2;2;2;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "3zJVXU311-Q",
        "title": "Hopular: Modern Hopfield Networks for Tabular Data",
        "track": "main",
        "status": "Withdraw",
        "keywords": "deep learning;tabular data;gradient boosting;Hopfield networks;associative memory",
        "author": "",
        "aff": "",
        "rating": "3;3;3;6",
        "confidence": "4;4;3;4",
        "correctness": "2;3;2;3",
        "technical_novelty": "3;2;2;3",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 3.75,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "4-D6CZkRXxI",
        "title": "Value Gradient weighted Model-Based Reinforcement Learning",
        "track": "main",
        "status": "Spotlight",
        "keywords": "model-based reinforcement learning;reinforcment learning;objective mismatch;value function;sensitivity",
        "author": "",
        "aff": "Vector Institute, University of Waterloo; Vector Institute, University of Toronto, Nvidia; Vector Institute, University of Toronto",
        "rating": "6;6;8;8",
        "confidence": "5;5;5;5",
        "correctness": "3;4;3;4",
        "technical_novelty": "3;3;3;4",
        "empirical_novelty": "4;2;3;2",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 5.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "41e9o6cQPj",
        "title": "GreaseLM: Graph REASoning Enhanced Language Models",
        "track": "main",
        "status": "Spotlight",
        "keywords": "language models;commonsense;question answering;knowledge graphs;KG augmentation",
        "author": "",
        "aff": "Stanford University",
        "rating": "6;6;8;8",
        "confidence": "4;3;4;3",
        "correctness": "4;3;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": "https://github.com/snap-stanford/GreaseLM"
    },
    {
        "id": "45L_dgP48Vd",
        "title": "Graph-Augmented Normalizing Flows for Anomaly Detection of Multiple Time Series",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Anomaly Detection;Normalizing Flow;DAG;Multiple Time Series",
        "author": "",
        "aff": "Pennsylvania State University; MIT-IBM Watson AI Lab, IBM Research",
        "rating": "6;6;8;8",
        "confidence": "4;4;4;3",
        "correctness": "1;4;3;3",
        "technical_novelty": "2;3;3;4",
        "empirical_novelty": "1;3;3;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.22941573387056177,
        "project": "",
        "github": ""
    },
    {
        "id": "45Mr7LeKR9",
        "title": "Explanations of Black-Box Models based on Directional Feature Interactions",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Explainability;Shapley values;Interpretability;Directional interaction;feature interaction",
        "author": "",
        "aff": "Brigham and Women\u2019s Hospital, Channing Division of Network Medicine, Boston, MA, USA; Northeastern University, Department of Electrical and Computer Engineering, Boston, MA, USA",
        "rating": "8;8;8;8",
        "confidence": "3;3;4;4",
        "correctness": "4;4;3;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;3;2",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "46lmrnVBHBL",
        "title": "Explanatory Learning: Beyond Empiricism in Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "explainability;rationalism;deep learning",
        "author": "",
        "aff": "",
        "rating": "3;5;6;8",
        "confidence": "4;2;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;3;0",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.16012815380508713,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "48RBsJwGkJf",
        "title": "CrossMatch: Cross-Classifier Consistency Regularization for Open-Set Single Domain Generalization",
        "track": "main",
        "status": "Poster",
        "keywords": "Single Domain Generalization;Open-Set Recognition",
        "author": "",
        "aff": "University of Georgia",
        "rating": "5;5;6;8",
        "confidence": "4;4;5;4",
        "correctness": "4;2;4;3",
        "technical_novelty": "3;3;2;3",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "49A1Y6tRhaq",
        "title": "Linking Emergent and Natural Languages via Corpus Transfer",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Emergent Language;Emergent Communication;Transfer Learning",
        "author": "",
        "aff": "MIT-IBM Watson AI Lab; Princeton University; Wechat AI; MIT",
        "rating": "3;6;8;8",
        "confidence": "4;3;4;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;3;3;4",
        "empirical_novelty": "2;3;3;4",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.07053456158585983,
        "corr_rating_correctness": 0.9169493006161777,
        "project": "",
        "github": "https://github.com/ysymyth/ec-nl"
    },
    {
        "id": "49h_IkpJtaE",
        "title": "How to Train Your MAML to Excel in Few-Shot Classification",
        "track": "main",
        "status": "Poster",
        "keywords": "meta-learning;few-shot learning;classification;MAML",
        "author": "",
        "aff": "State Key Laboratory for Novel Software Technology, Nanjing University; The Ohio State University",
        "rating": "3;8;8;8",
        "confidence": "5;4;4;5",
        "correctness": "3;4;3;4",
        "technical_novelty": "2;3;3;4",
        "empirical_novelty": "2;4;3;4",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 4.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "4AZz9osqrar",
        "title": "Self-supervised Learning is More Robust to Dataset Imbalance",
        "track": "main",
        "status": "Spotlight",
        "keywords": "self-supervised learning;dataset imbalance;representation learning;long-tailed recognition",
        "author": "",
        "aff": "Stanford University; Toyota Research Institute",
        "rating": "5;8;8;8",
        "confidence": "2;4;4;3",
        "correctness": "2;4;3;3",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "2;4;3;2",
        "presentation": "",
        "rating_avg": 7.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8703882797784892,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "4ApXq4y81kY",
        "title": "Co-variance: Tackling Noisy Labels with Sample Selection by Emphasizing High-variance Examples",
        "track": "main",
        "status": "Withdraw",
        "keywords": "noisy labels;sample selection;high variances",
        "author": "",
        "aff": "",
        "rating": "3;5;6",
        "confidence": "4;4;5",
        "correctness": "3;4;4",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;4;4",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 3.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.7559289460184544,
        "corr_rating_correctness": 0.9449111825230683,
        "project": "",
        "github": ""
    },
    {
        "id": "4C93Qvn-tz",
        "title": "MCMC Should Mix: Learning Energy-Based Model with Neural Transport Latent Space MCMC",
        "track": "main",
        "status": "Poster",
        "keywords": "Generative models;energy-based models;MCMC",
        "author": "",
        "aff": "Department of Statistics, UCLA; Department of Statistics, UCLA; Beijing Institute for General Artificial Intelligence (BIGAI); Google Research; Department of Statistics, UCLA; Salesforce Research",
        "rating": "6;6;8;8",
        "confidence": "4;4;2;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "4GBHVfEcmoS",
        "title": "Propagating Distributions through Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "propagating distributions;uncertainty quantification",
        "author": "",
        "aff": "",
        "rating": "3;6;6;6",
        "confidence": "4;4;4;2",
        "correctness": "4;4;3;4",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "2;3;2;2",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "4JlwgTbmzXQ",
        "title": "EqR: Equivariant Representations for Data-Efficient Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Equivariance;Invariance;Representation learning;Reinforcement learning;Symmetric MDPs;MDP homomorphism;Lie parameterization.",
        "author": "",
        "aff": "",
        "rating": "5;6;8;8",
        "confidence": "3;3;3;3",
        "correctness": "2;3;4;4",
        "technical_novelty": "1;3;3;3",
        "empirical_novelty": "2;2;4;2",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 3.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.986440050415621,
        "project": "",
        "github": ""
    },
    {
        "id": "4KOJ5XJ_z5W",
        "title": "Improving State-of-the-Art in One-Class Classification by Leveraging Unlabeled Data",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "3;4;3;4",
        "correctness": "3;2;3;4",
        "technical_novelty": "2;2;2;1",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.7071067811865475,
        "project": "",
        "github": ""
    },
    {
        "id": "4Muj-t_4o4",
        "title": "Learning a subspace of policies for online adaptation in Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "Deep Reinforcement Learning;Online adaptation",
        "author": "",
        "aff": "Facebook AI Research; CNRS-ISIR, Sorbonne University, Paris, France; Ubisoft",
        "rating": "3;6;6;8",
        "confidence": "5;4;4;5",
        "correctness": "2;3;3;4",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "2;4;3;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 4.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.14002800840280097,
        "corr_rating_correctness": 0.9901475429766743,
        "project": "",
        "github": "https://github.com/facebookresearch/salina/tree/main/salina_examples/rl/subspace_of_policies"
    },
    {
        "id": "4N-17dske79",
        "title": "Associated Learning: an Alternative to End-to-End Backpropagation that Works on CNN, RNN, and Transformer",
        "track": "main",
        "status": "Poster",
        "keywords": "pipeline training;parallel training;backpropagation;associated learning",
        "author": "",
        "aff": "Institute of Information Science, Academia Sinica; Department of Computer Science, National Central University",
        "rating": "5;5;6;6",
        "confidence": "4;3;4;3",
        "correctness": "3;3;4;3",
        "technical_novelty": "3;3;2;2",
        "empirical_novelty": "3;3;2;2",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": "https://github.com/Hibb-bb/AL"
    },
    {
        "id": "4PzEuW0JxAB",
        "title": "Disentangled Representations using Trained Models",
        "track": "main",
        "status": "Withdraw",
        "keywords": "disentangled representation",
        "author": "",
        "aff": "",
        "rating": "",
        "confidence": "",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "4QUoBU27oXN",
        "title": "Cognitively Inspired Learning of Incremental Drifting Concepts",
        "track": "main",
        "status": "Reject",
        "keywords": "Complementary Learning Systems;continual learning;Parallel Distributed Processing",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;3;4;3",
        "correctness": "2;3;3;4",
        "technical_novelty": "1;4;3;3",
        "empirical_novelty": "1;3;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6882472016116854,
        "corr_rating_correctness": 0.9733285267845754,
        "project": "",
        "github": ""
    },
    {
        "id": "4Stc6i97dVN",
        "title": "Sharper Utility Bounds for Differentially Private Models",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;6;8",
        "confidence": "4;4;3;5",
        "correctness": "3;3;4;4",
        "technical_novelty": "3;2;3;4",
        "empirical_novelty": "3;2;1;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.8164965809277259,
        "project": "",
        "github": ""
    },
    {
        "id": "4V4TZG7i7L_",
        "title": "Hierarchical Multimodal Variational Autoencoders",
        "track": "main",
        "status": "Reject",
        "keywords": "hierarchical vae;variational inference;multimodal learning",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "4;4;3;3",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;2;3;4",
        "empirical_novelty": "2;1;3;0",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "4XtpgPsvxE8",
        "title": "Multi-Objective Model Selection for Time Series Forecasting",
        "track": "main",
        "status": "Reject",
        "keywords": "time series;forecasting;model selection;multiobjective optimization;transfer-learning;tabular dataset.",
        "author": "",
        "aff": "",
        "rating": "5;5;6",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "3;3;4",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 3.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "4YOOO4ZNKM",
        "title": "Self-supervised Learning for Sequential Recommendation with Model Augmentation",
        "track": "main",
        "status": "Reject",
        "keywords": "Sequential Recommendation;Self-supervised Learning;Contrastive Learning;Model Augmentation",
        "author": "",
        "aff": "",
        "rating": "3;3;5",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "4Ycr8oeCoIh",
        "title": "When, Why, and Which Pretrained GANs Are Useful?",
        "track": "main",
        "status": "Poster",
        "keywords": "GAN;pretraining",
        "author": "",
        "aff": "Yandex",
        "rating": "6;6;8",
        "confidence": "3;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "3;3;4",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 3.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.49999999999999983,
        "corr_rating_correctness": -0.9999999999999998,
        "project": "",
        "github": ""
    },
    {
        "id": "4ZEJ_Z18NH",
        "title": "Learning Perceptual Compression of Facial Video",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;6",
        "confidence": "3;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9449111825230683,
        "corr_rating_correctness": -0.9449111825230683,
        "project": "",
        "github": ""
    },
    {
        "id": "4j4qVy8OQA1",
        "title": "A Koopman Approach to Understanding Sequence Neural Models",
        "track": "main",
        "status": "Reject",
        "keywords": "Koopman methods;sequence neural models;understanding deep learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "4;5;4;3",
        "correctness": "4;2;3;4",
        "technical_novelty": "1;2;2;3",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.816496580927726,
        "corr_rating_correctness": 0.4061811972299616,
        "project": "",
        "github": ""
    },
    {
        "id": "4jUmjIoTz2",
        "title": "Collaborate to Defend Against Adversarial Attacks",
        "track": "main",
        "status": "Reject",
        "keywords": "adversarial defense;collaboration;ensemble.",
        "author": "",
        "aff": "",
        "rating": "3;6;8",
        "confidence": "5;3;4",
        "correctness": "1;4;3",
        "technical_novelty": "3;3;4",
        "empirical_novelty": "2;3;4",
        "presentation": "",
        "rating_avg": 5.666666666666667,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 3.3333333333333335,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5960395606792698,
        "corr_rating_correctness": 0.7370434740955019,
        "project": "",
        "github": ""
    },
    {
        "id": "4l5iO9eoh3f",
        "title": "Supervised Permutation Invariant Networks for solving the CVRP with bounded fleet size",
        "track": "main",
        "status": "Reject",
        "keywords": "Deep Learning;Combinatorial Optimization;Vehicle Routing",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "3;4;4;3",
        "correctness": "2;3;2;3",
        "technical_novelty": "2;3;2;2",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.2294157338705618,
        "corr_rating_correctness": 0.6882472016116854,
        "project": "",
        "github": ""
    },
    {
        "id": "4l9eWfCM3Jb",
        "title": "Jointly Learning Identification and Control for Few-Shot Policy Adaptation",
        "track": "main",
        "status": "Withdraw",
        "keywords": "policy learning;control;system identification;few-shot domain adaptation",
        "author": "",
        "aff": "",
        "rating": "3;3;3",
        "confidence": "4;3;4",
        "correctness": "2;3;2",
        "technical_novelty": "2;1;1",
        "empirical_novelty": "2;2;1",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 1.3333333333333333,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "4lLyoISm9M",
        "title": "Range-Net: A High Precision Neural SVD",
        "track": "main",
        "status": "Reject",
        "keywords": "SVD;Eigen;Interpretable;Neural Nets;Streaming;Big Data",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "5;4;2;3",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7181848464596079,
        "corr_rating_correctness": 0.6622661785325219,
        "project": "",
        "github": ""
    },
    {
        "id": "4o1xPXaS4X",
        "title": "Fooling Adversarial Training with Induction Noise",
        "track": "main",
        "status": "Reject",
        "keywords": "Data poisoning;adversarial training;data privacy",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "4;4;4;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "3;2;3;4",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "4p6_5HBWPCw",
        "title": "Graph-less Neural Networks: Teaching Old MLPs New Tricks Via Distillation",
        "track": "main",
        "status": "Poster",
        "keywords": "Graph Neural Networks;Distillation;Node Classification;Model Inference Acceleration",
        "author": "",
        "aff": "University of California, Los Angeles; Snap Inc.",
        "rating": "3;8;8;10",
        "confidence": "5;4;3;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "1;3;3;4",
        "empirical_novelty": "1;3;3;4",
        "presentation": "",
        "rating_avg": 7.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6835859270246631,
        "corr_rating_correctness": 0.6767155423319645,
        "project": "",
        "github": "https://github.com/snap-research/graphless-neural-networks"
    },
    {
        "id": "4pijrj4H_B",
        "title": "Fair Node Representation Learning via Adaptive Data Augmentation",
        "track": "main",
        "status": "Reject",
        "keywords": "Fair node representations;fairness-aware graph data augmentations;unsupervised node representation learning;graph contrastive learning",
        "author": "",
        "aff": "",
        "rating": "3;6;6;8",
        "confidence": "5;3;4;2",
        "correctness": "2;3;3;4",
        "technical_novelty": "3;3;3;4",
        "empirical_novelty": "3;3;3;4",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9393364366277244,
        "corr_rating_correctness": 0.9901475429766743,
        "project": "",
        "github": ""
    },
    {
        "id": "4rLw09TgRw9",
        "title": "Query Embedding on Hyper-Relational Knowledge Graphs",
        "track": "main",
        "status": "Poster",
        "keywords": "Query embedding;Approximate Query Answering;Graph Neural Network;Hyper-relational Graph;Knowledge Graph",
        "author": "",
        "aff": "LMU Munich; Vrije Universiteit Amsterdam, Discovery Lab, Elsevier; Mila, McGill University",
        "rating": "5;5;6;6;8",
        "confidence": "2;4;4;3;4",
        "correctness": "3;3;3;3;4",
        "technical_novelty": "2;2;3;3;3",
        "empirical_novelty": "2;3;3;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.4,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 2.8,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.4564354645876385,
        "corr_rating_correctness": 0.912870929175277,
        "project": "",
        "github": ""
    },
    {
        "id": "4sz0AcJ8HUB",
        "title": "SERCNN: Stacked Embedding Recurrent Convolutional Neural Network in Depression Detection on Twitter",
        "track": "main",
        "status": "Reject",
        "keywords": "Social Media;Twitter;NLP;Depression;Mental Health",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "5;5;2;4",
        "correctness": "3;2;4;2",
        "technical_novelty": "1;1;2;1",
        "empirical_novelty": "1;2;1;0",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 1.25,
        "empirical_novelty_avg": 1.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.5222329678670935,
        "project": "",
        "github": ""
    },
    {
        "id": "4tOrvK-fFOR",
        "title": "Sound Source Detection from Raw Waveforms with Multi-Scale Synperiodic Filterbanks",
        "track": "main",
        "status": "Reject",
        "keywords": "speech processing;object detection;deep neural network;sound object;detection and localization;filter bank design",
        "author": "",
        "aff": "",
        "rating": "5;6;6;6",
        "confidence": "4;5;2;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "1;2;3;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.2581988897471611,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "4x50D2_CMVA",
        "title": "Automatic Tuning of Federated Learning Hyper-Parameters from System Perspective",
        "track": "main",
        "status": "Withdraw",
        "keywords": "federated learning;training preference;system perspective;hyper-parameter tuning",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3;6",
        "confidence": "4;4;4;3;4",
        "correctness": "3;2;2;3;3",
        "technical_novelty": "1;2;2;2;3",
        "empirical_novelty": "2;2;2;2;3",
        "presentation": "",
        "rating_avg": 3.6,
        "confidence_avg": 3.8,
        "correctness_avg": 2.6,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.2,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.25000000000000006,
        "corr_rating_correctness": 0.408248290463863,
        "project": "",
        "github": ""
    },
    {
        "id": "5-2mX9_U5i",
        "title": "Sqrt(d) Dimension Dependence of Langevin Monte Carlo",
        "track": "main",
        "status": "Poster",
        "keywords": "unadjusted Langevin algorithm / Langevin Monte Carlo;non-asymptotic sampling error in Wasserstein-2 distance;optimal dimension dependence;mean square analysis",
        "author": "",
        "aff": "Georgia Institute of Technology; School of Data Science, Shenzhen Institute of Arti\ufb01cial Intelligence and Robotics for Society, The Chinese University of Hong Kong, Shenzhen",
        "rating": "6;6;8;8",
        "confidence": "4;3;4;4",
        "correctness": "3;4;4;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;3;3;0",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "541PxiEKN3F",
        "title": "Acceleration of Federated Learning with Alleviated Forgetting in Local Training",
        "track": "main",
        "status": "Poster",
        "keywords": "Federated learning;non-i.i.d. data",
        "author": "",
        "aff": "Department of Computer Science and Technology, Tsinghua University, Beijing 100084, China; BNRIST, Tsinghua University, Beijing 100084, China; Department of Computer Science and Engineering, UCR, CA 92521, USA",
        "rating": "5;6;6;6",
        "confidence": "2;4;4;3",
        "correctness": "3;3;2;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;3;0",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8703882797784891,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/Zoesgithub/FedReg"
    },
    {
        "id": "57PipS27Km",
        "title": "Continuous-Time Meta-Learning with Forward Mode Differentiation",
        "track": "main",
        "status": "Spotlight",
        "keywords": "meta-learning;few-shot learning;dynamical systems",
        "author": "Tristan Deleu, David Kanaa, Leo Feng, Giancarlo Kerg, Yoshua Bengio, Guillaume Lajoie, Pierre-Luc Bacon",
        "aff": "CIFAR Senior Fellow, Mila \u2013 Universit\u00e9 de Montr\u00e9al; Mila \u2013 Universit\u00e9 de Montr\u00e9al; CIFAR AI Chair, Mila \u2013 Universit\u00e9 de Montr\u00e9al",
        "rating": "6;8;8;8",
        "confidence": "4;4;4;3",
        "correctness": "3;4;4;4",
        "technical_novelty": "3;3;4;3",
        "empirical_novelty": "3;2;4;3",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": "https://github.com/tristandeleu/jax-comln"
    },
    {
        "id": "57T1ctyxtP",
        "title": "Structured Stochastic Gradient MCMC",
        "track": "main",
        "status": "Reject",
        "keywords": "Approximate MCMC;Langevin Dynamics;Stochastic Gradient MCMC",
        "author": "",
        "aff": "",
        "rating": "3;5;5;8",
        "confidence": "4;4;3;5",
        "correctness": "1;3;2;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;2;2;1",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 4.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5940885257860046,
        "corr_rating_correctness": 0.9393364366277244,
        "project": "",
        "github": ""
    },
    {
        "id": "5ALGcXpmFyC",
        "title": "Training Data Size Induced Double Descent For Denoising Neural Networks and the Role of Training Noise Level",
        "track": "main",
        "status": "Reject",
        "keywords": "Double Descent;Denoising Neural Neworks;High Dimensional Statistics.",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "3;2;3;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "3;3;2;4",
        "empirical_novelty": "3;3;4;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.28867513459481287,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "5Bw_CZer00j",
        "title": "Self-supervised Discovery of Human Actons from Long Kinematic Videos",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Self-supervised Learning;Video Analysis",
        "author": "",
        "aff": "",
        "rating": "3;3;5",
        "confidence": "4;5;4",
        "correctness": "4;4;3",
        "technical_novelty": "2;1;2",
        "empirical_novelty": "0;2;0",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 1.6666666666666667,
        "empirical_novelty_avg": 0.6666666666666666,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4999999999999999,
        "corr_rating_correctness": -1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "5ECQL05ub0J",
        "title": "Resonance in Weight Space: Covariate Shift Can Drive Divergence of SGD with Momentum",
        "track": "main",
        "status": "Poster",
        "keywords": "optimization;momentum;stochastic gradient descent;non-iid sampling",
        "author": "",
        "aff": "Department of Mathematical and Statistical Sciences, University of Alberta; Department of Computing Science, University of Alberta",
        "rating": "3;6;8;8",
        "confidence": "3;4;4;2",
        "correctness": "3;4;4;4",
        "technical_novelty": "2;2;4;4",
        "empirical_novelty": "0;3;3;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.03683547343418787,
        "corr_rating_correctness": 0.9169493006161777,
        "project": "",
        "github": ""
    },
    {
        "id": "5FUq05QRc5b",
        "title": "Understanding Latent Correlation-Based Multiview Learning and Self-Supervision: An Identifiability Perspective",
        "track": "main",
        "status": "Spotlight",
        "keywords": "",
        "author": "",
        "aff": "IBM Research, Yorktown Heights; School of EECS, Oregon State Univ.; Google Inc., Mountain View",
        "rating": "8;8;8",
        "confidence": "2;2;4",
        "correctness": "4;4;4",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "3;3;4",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "5HvpvYd68b",
        "title": "switch-GLAT: Multilingual Parallel Machine Translation Via Code-Switch Decoder",
        "track": "main",
        "status": "Poster",
        "keywords": "multilingual non-autoregressive machine translation;contextualized code-switching;back-translation",
        "author": "",
        "aff": "ByteDance AI Lab, Shanghai, China; University of California, Santa Barbara",
        "rating": "5;6;8",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 6.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "5JdLZg346Lw",
        "title": "Generative Modeling with Optimal Transport Maps",
        "track": "main",
        "status": "Poster",
        "keywords": "Optimal Transport Map;Generative Modeling;Unpaired Image Restoration",
        "author": "",
        "aff": "Skolkovo Institute of Science and Technology, Artificial Intelligence Research Institute (AIRI); Space Applications Centre, Indian Space Research Organisation",
        "rating": "5;6;6;8",
        "confidence": "4;5;3;4",
        "correctness": "2;3;3;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9733285267845754,
        "project": "",
        "github": ""
    },
    {
        "id": "5Jj1qMVtS9W",
        "title": "Universally rank consistent ordinal regression in neural networks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;3;4",
        "correctness": "4;3;3;2",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;3;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": -0.7071067811865475,
        "project": "",
        "github": ""
    },
    {
        "id": "5K7RRqZEjoS",
        "title": "Multiset-Equivariant Set Prediction with Approximate Implicit Differentiation",
        "track": "main",
        "status": "Poster",
        "keywords": "set prediction;permutation equivariance;implicit differentiation",
        "author": "",
        "aff": "Mila, Universit \u00e9 de Montreal; Samsung - SAIT AI Lab, Montreal; University of Amsterdam; TNO",
        "rating": "5;6;8;8",
        "confidence": "3;4;4;4",
        "correctness": "2;4;3;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;4;3;4",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.7777777777777777,
        "corr_rating_correctness": 0.5222329678670935,
        "project": "",
        "github": ""
    },
    {
        "id": "5LXw_QplBiF",
        "title": "Learning Hierarchical Structures with Differentiable Nondeterministic Stacks",
        "track": "main",
        "status": "Spotlight",
        "keywords": "RNN;pushdown automata;nondeterminism;formal languages;language modeling",
        "author": "",
        "aff": "Department of Computer Science and Engineering, University of Notre Dame",
        "rating": "6;6;8;8",
        "confidence": "3;3;2;3",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;4;4;3",
        "empirical_novelty": "2;4;4;2",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 2.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "5LYsQ7kkb57",
        "title": "Dynamically Decoding Source Domain Knowledge For Unseen Domain Generalization",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "5;4;2;3",
        "correctness": "4;4;3;2",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8944271909999159,
        "corr_rating_correctness": -0.9045340337332909,
        "project": "",
        "github": ""
    },
    {
        "id": "5MLb3cLCJY",
        "title": "Adaptive Wavelet Transformer Network for 3D Shape Representation Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "NYU Multimedia and Visual Computing Lab, USA; NYU Tandon School of Engineering, New York University, USA; NYUAD Center for Artificial Intelligence and Robotics (CAIR), Abu Dhabi, UAE; New York University Abu Dhabi, UAE",
        "rating": "6;6;6;6",
        "confidence": "4;3;4;4",
        "correctness": "3;4;3;4",
        "technical_novelty": "3;4;3;4",
        "empirical_novelty": "2;3;3;4",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.5,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "5MbRzxoCAql",
        "title": "Fight fire with fire: countering bad shortcuts in imitation learning with good shortcuts",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;4;2;4",
        "correctness": "3;2;3;3",
        "technical_novelty": "2;3;2;4",
        "empirical_novelty": "3;2;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "5N4bCRdqHAw",
        "title": "MFE-NER: Multi-feature Fusion Embedding for Chinese Named Entity Recognition",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Named Entity Recognition;Natural Language Processing",
        "author": "",
        "aff": "",
        "rating": "1;3;5;5",
        "confidence": "5;4;4;4",
        "correctness": "2;3;3;4",
        "technical_novelty": "1;2;2;2",
        "empirical_novelty": "1;2;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8703882797784891,
        "corr_rating_correctness": 0.8528028654224417,
        "project": "",
        "github": ""
    },
    {
        "id": "5QhUE1qiVC6",
        "title": "The Convex Geometry of Backpropagation: Neural Network Gradient Flows Converge to Extreme Points of the Dual Convex Program",
        "track": "main",
        "status": "Poster",
        "keywords": "Two-layer ReLU networks;convex optimization;convex duality;gradient flow",
        "author": "",
        "aff": "Department of Electrical Engineering, Stanford University, Stanford, CA 94305, USA",
        "rating": "6;6;8",
        "confidence": "2;3;3",
        "correctness": "3;4;4",
        "technical_novelty": "3;3;4",
        "empirical_novelty": "0;3;0",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 3.3333333333333335,
        "empirical_novelty_avg": 1.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.49999999999999983,
        "corr_rating_correctness": 0.49999999999999983,
        "project": "",
        "github": ""
    },
    {
        "id": "5Qkd7-bZfI",
        "title": "On the role of population heterogeneity in emergent communication",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "DeepMind; EHESS, ENS-PSL, CNRS, INRIA, Meta AI Research; Google Research, Brain Team; INRIA, Paris",
        "rating": "6;6;6;6",
        "confidence": "4;2;4;4",
        "correctness": "3;3;3;2",
        "technical_novelty": "3;4;3;4",
        "empirical_novelty": "3;4;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 3.5,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "5SgoJKayTvs",
        "title": "Intervention Adversarial Auto-Encoder",
        "track": "main",
        "status": "Reject",
        "keywords": "Deep Learning;Generative Models;Adversarial Training",
        "author": "",
        "aff": "",
        "rating": "3;3;3",
        "confidence": "4;5;3",
        "correctness": "2;2;2",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "5XmLzdslFNN",
        "title": "Modular Lifelong Reinforcement Learning via Neural Composition",
        "track": "main",
        "status": "Poster",
        "keywords": "lifelong learning;continual learning;reinforcement learning;composition;modularity;compositionality",
        "author": "",
        "aff": "Microsoft Research; Department of Computer and Information Science, University of Pennsylvania",
        "rating": "6;6;6;8",
        "confidence": "4;3;4;4",
        "correctness": "3;4;4;4",
        "technical_novelty": "3;4;3;2",
        "empirical_novelty": "2;4;3;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "5_zwnS5oJDp",
        "title": "Bayesian Learning with Information Gain Provably Bounds Risk for a Robust Adversarial Defense",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;4;4;5",
        "correctness": "2;2;2;3",
        "technical_novelty": "2;2;1;2",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.25,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 1.0,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "5alVAdi6wW4",
        "title": "Generating Unobserved Alternatives with Tower Implicit Model (TIM)",
        "track": "main",
        "status": "Withdraw",
        "keywords": "one-to-many prediction;inverse problem;implicit maximum likelihood estimation",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "3;4;3;3",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5555555555555555,
        "corr_rating_correctness": 0.5555555555555555,
        "project": "",
        "github": ""
    },
    {
        "id": "5fbUEUTZEn7",
        "title": "Graph Kernel Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "graph neural network;graph kernel;deep learning",
        "author": "",
        "aff": "",
        "rating": "5;6;6",
        "confidence": "4;4;3",
        "correctness": "4;3;3",
        "technical_novelty": "3;4;3",
        "empirical_novelty": "2;3;2",
        "presentation": "",
        "rating_avg": 5.666666666666667,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.3333333333333335,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4999999999999999,
        "corr_rating_correctness": -0.9999999999999997,
        "project": "",
        "github": ""
    },
    {
        "id": "5fmBRf5rrC",
        "title": "Knothe-Rosenblatt transport for Unsupervised Domain Adaptation",
        "track": "main",
        "status": "Reject",
        "keywords": "domain adaptation;transfer learning;deep learning;density estimation;transport",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "4;4;3;4",
        "correctness": "3;3;2;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;0;1;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "5hLP5JY9S2d",
        "title": "Open-Set Recognition: A Good Closed-Set Classifier is All You Need",
        "track": "main",
        "status": "Oral",
        "keywords": "open set recognition;image recognition;computer vision",
        "author": "",
        "aff": "The University of Hong Kong; Visual Geometry Group, University of Oxford",
        "rating": "6;8;8",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "2;3;2",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 7.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/sgvaze/osr_closed_set_all_you_need"
    },
    {
        "id": "5i2f-aR6B8H",
        "title": "Privacy Implications of Shuffling",
        "track": "main",
        "status": "Poster",
        "keywords": "local differential privacy;shuffle DP model",
        "author": "",
        "aff": "UC San Diego; University of Wisconsin, Madison",
        "rating": "6;6;8",
        "confidence": "3;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "3;2;4",
        "empirical_novelty": "3;3;4",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "5i7lJLuhTm",
        "title": "Learning by Directional Gradient Descent",
        "track": "main",
        "status": "Poster",
        "keywords": "credit assignment;directional derivative;recurrent networks",
        "author": "",
        "aff": "Mila, University of Montreal; DeepMind, London, UK",
        "rating": "1;5;6;6",
        "confidence": "5;3;3;3",
        "correctness": "2;3;4;3",
        "technical_novelty": "1;1;3;3",
        "empirical_novelty": "0;3;3;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9801960588196067,
        "corr_rating_correctness": 0.8574929257125441,
        "project": "",
        "github": ""
    },
    {
        "id": "5kq11Tl1z4",
        "title": "IGLU: Efficient GCN Training via Lazy Updates",
        "track": "main",
        "status": "Poster",
        "keywords": "Graph convolutional networks;Graph neural networks;Optimization;Lazy updates",
        "author": "",
        "aff": "Microsoft Research India; IIT Kanpur & Microsoft Research India",
        "rating": "6;6;6",
        "confidence": "3;3;3",
        "correctness": "4;3;4",
        "technical_novelty": "3;3;4",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 3.3333333333333335,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "5n7kJBpTSU4",
        "title": "ABC: Attention with Bounded-memory Control",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Attention;transformers;efficiency;machine translation;language modeling",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "2;3;4;2",
        "correctness": "4;3;4;4",
        "technical_novelty": "2;3;3;4",
        "empirical_novelty": "2;3;4;4",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.4923659639173309,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "5o7lEUYRvM",
        "title": "Function-Space Variational Inference for Deep Bayesian Classification",
        "track": "main",
        "status": "Reject",
        "keywords": "Bayesian deep learning;image classification;functional variational inference;Dirichlet distribution",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "4;4;3;3",
        "correctness": "2;3;3;4",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8164965809277259,
        "corr_rating_correctness": 0.8660254037844386,
        "project": "",
        "github": ""
    },
    {
        "id": "5qwA7LLbgP0",
        "title": "Disentangling Sources of Risk for Distributional Multi-Agent Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "multi-agent reinforcement learning;risk-sensitive reinforcement learning;reinforcement learning;distributional reinforcement learning",
        "author": "",
        "aff": "",
        "rating": "3;3;6;6;6",
        "confidence": "4;4;4;4;3",
        "correctness": "2;3;4;3;4",
        "technical_novelty": "2;2;3;3;3",
        "empirical_novelty": "2;2;3;3;2",
        "presentation": "",
        "rating_avg": 4.8,
        "confidence_avg": 3.8,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.408248290463863,
        "corr_rating_correctness": 0.7637626158259733,
        "project": "",
        "github": ""
    },
    {
        "id": "5qz8nIzTkml",
        "title": "$L_q$ regularization for Fairness AI robust to sampling bias",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Fairness AI;Sampling bias;Robustness",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;3;5;4",
        "correctness": "3;4;2;3",
        "technical_novelty": "3;2;2;2",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "5sP_PUUS78v",
        "title": "SeqPATE: Differentially Private Text Generation via Knowledge Distillation",
        "track": "main",
        "status": "Reject",
        "keywords": "Natural Language Generation;Text Generation;Privacy Protection",
        "author": "",
        "aff": "",
        "rating": "3;6;6;8",
        "confidence": "4;3;4;4",
        "correctness": "4;3;3;4",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.08084520834544431,
        "corr_rating_correctness": -0.14002800840280097,
        "project": "",
        "github": ""
    },
    {
        "id": "5ueTHF0yAlZ",
        "title": "Improving greedy core-set configurations for active learning with uncertainty-scaled distances",
        "track": "main",
        "status": "Reject",
        "keywords": "Active learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;8",
        "confidence": "4;4;4;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "3;2;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9169493006161777,
        "project": "",
        "github": ""
    },
    {
        "id": "5vjyt5JHmaU",
        "title": "Safe Exploration in Linear Equality Constraint",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Reinforcement Learning;safe exploration;Singular Value Decomposition;strictly satisfy constraint;Model-based",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "2;2;3;5",
        "correctness": "3;3;3;4",
        "technical_novelty": "3;2;4;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9428090415820632,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "5x7J3WXasqy",
        "title": "Spatially and Seamlessly Hierarchical Reinforcement Learning for State Space and Policy Space in Autonomous Driving",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Hierarchical Reinforcement Learning;Spatial Hierarchy;Autonomous Driving;Path Planning",
        "author": "",
        "aff": "",
        "rating": "1;3;5",
        "confidence": "4;4;3",
        "correctness": "2;3;3",
        "technical_novelty": "1;2;2",
        "empirical_novelty": "1;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 1.6666666666666667,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8660254037844385,
        "corr_rating_correctness": 0.8660254037844385,
        "project": "",
        "github": ""
    },
    {
        "id": "5xEgrl_5FAJ",
        "title": "BiBERT: Accurate Fully Binarized BERT",
        "track": "main",
        "status": "Poster",
        "keywords": "Network Binarization;Model Compression;BERT;NLP",
        "author": "",
        "aff": "State Key Lab of Software Development Environment, Beihang University; Shen Yuan Honors College, Beihang University; Baidu Inc.; S-Lab, Nanyang Technological University; State Key Lab of Software Development Environment, Beihang University",
        "rating": "5;6;6;6;8",
        "confidence": "4;4;3;3;3",
        "correctness": "3;3;3;4;4",
        "technical_novelty": "2;3;3;3;3",
        "empirical_novelty": "3;2;2;2;3",
        "presentation": "",
        "rating_avg": 6.2,
        "confidence_avg": 3.4,
        "correctness_avg": 3.4,
        "technical_novelty_avg": 2.8,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5833333333333334,
        "corr_rating_correctness": 0.6666666666666667,
        "project": "",
        "github": ""
    },
    {
        "id": "5y35LXrRMMz",
        "title": "Exploiting Minimum-Variance Policy Evaluation for Policy Optimization",
        "track": "main",
        "status": "Reject",
        "keywords": "Reinforcement Learning;Policy Optimization;Importance Sampling;Variance Reduction",
        "author": "",
        "aff": "",
        "rating": "3;5;6;10",
        "confidence": "4;3;4;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "1;2;2;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.22645540682891915,
        "corr_rating_correctness": 0.7844645405527362,
        "project": "",
        "github": ""
    },
    {
        "id": "5ziLr3pWz77",
        "title": "Neural network architectures for disentangling the multimodal structure of data ensembles",
        "track": "main",
        "status": "Reject",
        "keywords": "autoencoders;SEMs",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "3;3;2;3",
        "correctness": "3;1;2;3",
        "technical_novelty": "2;1;2;3",
        "empirical_novelty": "2;1;0;0",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 2.75,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 0.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.5222329678670935,
        "project": "",
        "github": ""
    },
    {
        "id": "6-lLt2zxbZR",
        "title": "An Application of Pseudo-log-likelihoods to Natural Language Scoring",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "1;3;3;5",
        "confidence": "4;4;3;4",
        "correctness": "1;2;2;3",
        "technical_novelty": "2;2;1;2",
        "empirical_novelty": "0;2;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "62r41yOG5m",
        "title": "Inducing Reusable Skills From Demonstrations with Option-Controller Network",
        "track": "main",
        "status": "Reject",
        "keywords": "Reusable Skill;Option-Controller Network",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "5;4;5;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;1;3;2",
        "empirical_novelty": "3;2;3;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "63PjP_UEKe",
        "title": "Cross Domain Ensemble Distillation for Domain Generalization",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;6;6",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "1;3;3",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "64trBbOhdGU",
        "title": "HyAR: Addressing Discrete-Continuous Action Reinforcement Learning via Hybrid Action Representation",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "School of Arti\ufb01cial Intelligence, Optics and Electronics (iOPEN) and School of Cybersecurity, Northwestern Polytechnical University; College of Intelligence and Computing, Tianjin University",
        "rating": "6;8;8;8",
        "confidence": "4;1;4;4",
        "correctness": "4;4;3;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;4;3",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "66kgCIYQW3",
        "title": "Automatic Concept Extraction for Concept Bottleneck-based Video Classification",
        "track": "main",
        "status": "Reject",
        "keywords": "Explainable AI;Video Classification;Concept Extraction",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "4;3;3;3",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "66miN107dRS",
        "title": "Contrastive Attraction and Contrastive Repulsion for Representation Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "contrastive learning;Bayesian methods;conditional distribution;label imbalance;doubly contrastive",
        "author": "",
        "aff": "",
        "rating": "3;6;6;8",
        "confidence": "4;5;4;4",
        "correctness": "4;3;3;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "0;2;3;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 4.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.08084520834544431,
        "corr_rating_correctness": -0.14002800840280097,
        "project": "",
        "github": ""
    },
    {
        "id": "67T66kchK_7",
        "title": "SPLID: Self-Imitation Policy Learning through Iterative Distillation",
        "track": "main",
        "status": "Reject",
        "keywords": "Multi-goal RL;RL with sparse reward.",
        "author": "",
        "aff": "",
        "rating": "3;3;3;8",
        "confidence": "4;4;3;3",
        "correctness": "3;2;3;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "68n2s9ZJWF8",
        "title": "Offline Reinforcement Learning with Implicit Q-Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "Deep Reinforcement Learning;Offline Reinforcement Learning;Batch Reinforcement Learning;Continuous Control",
        "author": "",
        "aff": "Department of Electrical Engineering and Computer Science, University of California, Berkeley",
        "rating": "5;5;6;8",
        "confidence": "4;5;2;4",
        "correctness": "4;4;4;4",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "0;2;2;2",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.75,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.18731716231633877,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "6A7zcZ43m1S",
        "title": "R-GSN: The Relation-based Graph Similar Network for Heterogeneous Graph",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Heterogeneous graph;graph neural network.",
        "author": "",
        "aff": "Under double-blind review",
        "rating": "3;3;5",
        "confidence": "5;3;4",
        "correctness": "2;3;3",
        "technical_novelty": "3;2;2",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "6CrZzjpjWdk",
        "title": "KG-FiD: Infusing Knowledge Graph in Fusion-in-Decoder for Open-Domain Question Answering",
        "track": "main",
        "status": "Withdraw",
        "keywords": "open-domain question answering;knowledge graph;pre-trained language model",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "5;4;3;3",
        "correctness": "3;2;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "0;2;2;2",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.899228803025897,
        "corr_rating_correctness": -0.13245323570650439,
        "project": "",
        "github": ""
    },
    {
        "id": "6Dz7RiRiMFd",
        "title": "3D-Transformer: Molecular Representation with Transformer in 3D Space",
        "track": "main",
        "status": "Reject",
        "keywords": "structural biology;self-attention;transformer;proteins;small molecules;crystals;geometric deel learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "3;3;2;4",
        "correctness": "3;2;3;2",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;3;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "6ET9SzlgNX",
        "title": "Understanding Intrinsic Robustness Using Label Uncertainty",
        "track": "main",
        "status": "Poster",
        "keywords": "Concentration of Measure;Intrinsic Adversarial Robustness;Label Uncertainty",
        "author": "",
        "aff": "Department of Computer Science, University of Virginia",
        "rating": "6;6;6;8",
        "confidence": "3;4;4;2",
        "correctness": "3;3;4;4",
        "technical_novelty": "3;3;3;4",
        "empirical_novelty": "3;3;3;4",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8703882797784891,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "6EVxJKlpGR",
        "title": "Surprise Minimizing Multi-Agent Learning with Energy-based Models",
        "track": "main",
        "status": "Reject",
        "keywords": "Multi-Agent Learning;Reinforcement Learning;Energy-based Models.",
        "author": "",
        "aff": "",
        "rating": "5;6;6;6",
        "confidence": "4;4;1;3",
        "correctness": "3;3;2;4",
        "technical_novelty": "3;2;2;3",
        "empirical_novelty": "3;2;0;2",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4714045207910316,
        "corr_rating_correctness": 0.0,
        "project": "sites.google.com/view/surprise-web/",
        "github": ""
    },
    {
        "id": "6HN7LHyzGgC",
        "title": "Uncertainty Modeling for Out-of-Distribution Generalization",
        "track": "main",
        "status": "Poster",
        "keywords": "domain generalization;uncertainty modeling",
        "author": "",
        "aff": "Singapore University of Technology and Design, Singapore; ARC Lab, Tencent PCG; Peking University, Beijing, China and Peng Cheng Laboratory, Shenzhen, China; Peking University, Beijing, China",
        "rating": "6;6;8",
        "confidence": "4;3;3",
        "correctness": "4;3;4",
        "technical_novelty": "3;2;4",
        "empirical_novelty": "3;2;4",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.49999999999999983,
        "corr_rating_correctness": 0.49999999999999983,
        "project": "",
        "github": "https://github.com/lixiaotong97/DSU"
    },
    {
        "id": "6IYp-35L-xJ",
        "title": "CADDA: Class-wise Automatic Differentiable Data Augmentation for EEG Signals",
        "track": "main",
        "status": "Poster",
        "keywords": "Neuroscience;EEG;Sleep staging;Automatic data augmentation",
        "author": "",
        "aff": "Universit\u00e9 Paris-Saclay, Inria, CEA, Palaiseau, 91120, France",
        "rating": "5;6;6;8",
        "confidence": "3;3;2;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.6488856845230502,
        "corr_rating_correctness": -0.13245323570650439,
        "project": "",
        "github": ""
    },
    {
        "id": "6Jf6HX4MoLH",
        "title": "Motion Planning Transformers: One Model to Plan them All",
        "track": "main",
        "status": "Reject",
        "keywords": "Motion Planning;Attention Networks",
        "author": "",
        "aff": "",
        "rating": "3;6;6;6",
        "confidence": "4;3;4;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;2;3;4",
        "empirical_novelty": "2;2;3;4",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "6LHiNULIeiC",
        "title": "SOInter: A Novel Deep Energy-Based Interpretation Method for Explaining Structured Output Models",
        "track": "main",
        "status": "Reject",
        "keywords": "Structured Output Model;Interpretable Learning;Deep Learning",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "2;4;3;4",
        "correctness": "2;3;2;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;0;2;1",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "6LNPEcJAGWe",
        "title": "Federated Contrastive Representation Learning with Feature Fusion and Neighborhood Matching",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Federated Learning;Contrastive Learning;Self-supervised Learning",
        "author": "",
        "aff": "",
        "rating": "1;3;3;6",
        "confidence": "5;5;4;2",
        "correctness": "3;2;2;4",
        "technical_novelty": "2;2;1;3",
        "empirical_novelty": "2;3;1;3",
        "presentation": "",
        "rating_avg": 3.25,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.914659120760047,
        "corr_rating_correctness": 0.5488604301969737,
        "project": "",
        "github": ""
    },
    {
        "id": "6MFWE6u2b6R",
        "title": "Bandits for Black-box Attacks to Graph Neural Networks with Structure Perturbation",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Graph neural networks;Black-box attacks;Structure perturbation;Bandits;Sublinear query complexity",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "5;3;3;3",
        "correctness": "2;3;3;4",
        "technical_novelty": "2;3;4;2",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "6MmiS0HUJHR",
        "title": "When Can We Learn General-Sum Markov Games with a Large Number of Players Sample-Efficiently?",
        "track": "main",
        "status": "Poster",
        "keywords": "reinforcement learning theory;multi-agent RL;Markov games;general-sum games",
        "author": "",
        "aff": "School of Mathematical Sciences, Peking University; Salesforce Research; Department of Statistics, UC Berkeley",
        "rating": "6;8;8;8",
        "confidence": "3;3;4;4",
        "correctness": "3;4;4;4",
        "technical_novelty": "3;2;3;4",
        "empirical_novelty": "3;0;0;0",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 0.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "6NT1a56mNim",
        "title": "Language Models as Zero-Shot Planners: Extracting Actionable Knowledge for Embodied Agents",
        "track": "main",
        "status": "Reject",
        "keywords": "GPT-3;Codex;LLMs;Language Models;Knowledge Extraction;Embodied Agents;Action Planning",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6;8",
        "confidence": "4;4;4;4;5",
        "correctness": "3;3;3;4;3",
        "technical_novelty": "2;2;2;4;3",
        "empirical_novelty": "2;2;3;4;4",
        "presentation": "",
        "rating_avg": 5.4,
        "confidence_avg": 4.2,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8000946913656628,
        "corr_rating_correctness": 0.1846372364689991,
        "project": "https://sites.google.com/view/language-model-as-planner",
        "github": ""
    },
    {
        "id": "6NePxZwfae",
        "title": "Goal-Directed Planning via Hindsight Experience Replay",
        "track": "main",
        "status": "Poster",
        "keywords": "Reinforcement Learning;Goal-Directed Planning;Monte Carlo Tree Search",
        "author": "",
        "aff": "DEIB, Politecnico di Milano, Milan, Italy; CNR-IFN, Milan, Italy; FABIT, Universita di Bologna, Bologna, Italy",
        "rating": "3;6;8;8",
        "confidence": "4;4;5;4",
        "correctness": "4;4;4;3",
        "technical_novelty": "2;2;4;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 4.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.49374193110101877,
        "corr_rating_correctness": -0.49374193110101877,
        "project": "",
        "github": ""
    },
    {
        "id": "6P6-N1gLQDC",
        "title": "Structural Causal Interpretation Theorem",
        "track": "main",
        "status": "Reject",
        "keywords": "causality;interpretations;neural causal models;induction",
        "author": "",
        "aff": "",
        "rating": "3;6;8",
        "confidence": "3;3;4",
        "correctness": "2;3;3",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "3;2;4",
        "presentation": "",
        "rating_avg": 5.666666666666667,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8029550685469661,
        "corr_rating_correctness": 0.9176629354822472,
        "project": "",
        "github": ""
    },
    {
        "id": "6PTUd_zPdHL",
        "title": "Differentiable Top-k Classification Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "top-k;top-5;imagenet",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "4;5;4;2",
        "correctness": "3;3;3;3",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.37463432463267754,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "6PahjGFjVG-",
        "title": "Secure Distributed Training at Scale",
        "track": "main",
        "status": "Reject",
        "keywords": "distributed training;byzantine tolerance;volunteer computing",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6;6",
        "confidence": "2;4;3;4;3",
        "correctness": "2;2;3;4;3",
        "technical_novelty": "2;2;2;3;3",
        "empirical_novelty": "2;1;2;3;2",
        "presentation": "",
        "rating_avg": 4.6,
        "confidence_avg": 3.2,
        "correctness_avg": 2.8,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.2758386421836853,
        "corr_rating_correctness": 0.9063269671749656,
        "project": "",
        "github": ""
    },
    {
        "id": "6Pe99Juo9gd",
        "title": "Learning Value Functions from Undirected State-only Experience",
        "track": "main",
        "status": "Poster",
        "keywords": "Reinforcement Learning;Offline RL;Offline RL without actions",
        "author": "",
        "aff": "University of Illinois at Urbana-Champaign",
        "rating": "5;6;6;8",
        "confidence": "2;4;4;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;2;4",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.20751433915982243,
        "corr_rating_correctness": 0.0,
        "project": "https://matthewchang.github.io/latent-action-qlearning-site/",
        "github": ""
    },
    {
        "id": "6PlIkYUK9As",
        "title": "Less data is more: Selecting informative and diverse subsets with balancing constraints",
        "track": "main",
        "status": "Reject",
        "keywords": "subset selection;approximation algorithm;active learning;efficient training",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;4;3",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "6PvWo1kEvlT",
        "title": "Exposing the Implicit Energy Networks behind Masked Language Models via Metropolis--Hastings",
        "track": "main",
        "status": "Poster",
        "keywords": "Masked Language Models;Energy-based models;Metropolis Hastings Monte Carlo;Bidirectional Sequence models",
        "author": "",
        "aff": "Deepmind; Carnegie Mellon University; UC San Diego",
        "rating": "3;6;8;8",
        "confidence": "4;4;4;5",
        "correctness": "3;4;4;4",
        "technical_novelty": "2;3;3;4",
        "empirical_novelty": "3;3;4;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 4.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.49374193110101877,
        "corr_rating_correctness": 0.9169493006161777,
        "project": "",
        "github": ""
    },
    {
        "id": "6Q52pZ-Th7N",
        "title": "Pseudo-Labeled Auto-Curriculum Learning for Semi-Supervised Keypoint Localization",
        "track": "main",
        "status": "Poster",
        "keywords": "Keypoint Localization;Semi-Supervised Learning;Curriculum Learning",
        "author": "",
        "aff": "The University of Hong Kong; SenseTime Research and Tetras.AI; The University of Sydney",
        "rating": "5;6;8",
        "confidence": "4;3;4",
        "correctness": "4;3;4",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 6.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.18898223650461363,
        "corr_rating_correctness": 0.18898223650461363,
        "project": "",
        "github": ""
    },
    {
        "id": "6Q5RdltG3L",
        "title": "Human imperceptible attacks and applications to improve fairness",
        "track": "main",
        "status": "Desk Reject",
        "keywords": "",
        "author": "",
        "aff": "Paper under double-blind review",
        "rating": "",
        "confidence": "",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "6Qvjzr2VGLl",
        "title": "Towards Generative Latent Variable Models for Speech",
        "track": "main",
        "status": "Reject",
        "keywords": "hierarchical temporal latent variable models;generative speech modelling;variational autoencoder",
        "author": "",
        "aff": "",
        "rating": "3;5;6",
        "confidence": "4;4;3",
        "correctness": "2;4;4",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7559289460184545,
        "corr_rating_correctness": 0.944911182523068,
        "project": "",
        "github": ""
    },
    {
        "id": "6Tk2noBdvxt",
        "title": "Programmatic Reinforcement Learning without Oracles",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Reinforcement Learning;Programmatic Reinforcement Learning;Compositional Reinforcement Learning;Program Synthesis;Differentiable Architecture Search",
        "author": "",
        "aff": "Department of Computer Science, Rutgers University",
        "rating": "8;8;8",
        "confidence": "5;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "3;3;4",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "6VpeS27viTq",
        "title": "Learnability Lock: Authorized Learnability Control Through Adversarial Invertible Transformations",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "Yale University; Pennsylvania State University",
        "rating": "6;8;8;8",
        "confidence": "3;4;4;3",
        "correctness": "4;4;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.5,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "6XGgutacQ0B",
        "title": "Demystifying Batch Normalization in ReLU Networks: Equivalent Convex Optimization Models and Implicit Regularization",
        "track": "main",
        "status": "Poster",
        "keywords": "batch normalization;ReLU networks;deep networks;convex optimization;whitening;implicit regularization;algorithmic bias",
        "author": "",
        "aff": "Department of Electrical Engineering, Stanford University, Stanford, CA 94305, USA",
        "rating": "5;6;6",
        "confidence": "3;3;4",
        "correctness": "2;3;4",
        "technical_novelty": "4;3;3",
        "empirical_novelty": "4;3;3",
        "presentation": "",
        "rating_avg": 5.666666666666667,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.3333333333333335,
        "empirical_novelty_avg": 3.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.4999999999999999,
        "corr_rating_correctness": 0.8660254037844385,
        "project": "",
        "github": ""
    },
    {
        "id": "6YVIk0sAkF_",
        "title": "Multi-Mode Deep Matrix and Tensor Factorization",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "School of Data Science, The Chinese University of Hong Kong (Shenzhen), China; Shenzhen Research Institute of Big Data, China",
        "rating": "5;6;6;8",
        "confidence": "4;4;4;2",
        "correctness": "4;3;4;3",
        "technical_novelty": "3;3;4;3",
        "empirical_novelty": "2;2;4;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9271726499455306,
        "corr_rating_correctness": -0.6882472016116854,
        "project": "",
        "github": ""
    },
    {
        "id": "6g4VoBTaq6I",
        "title": "A Variance Reduction Method for Neural-based Divergence Estimation",
        "track": "main",
        "status": "Reject",
        "keywords": "Divergence estimation;Variational formulas;Variance reduction;Representation learning",
        "author": "",
        "aff": "",
        "rating": "3;3;8;8",
        "confidence": "4;4;3;3",
        "correctness": "2;3;4;1",
        "technical_novelty": "2;2;3;1",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "6gLEKETxUWp",
        "title": "Interpreting Molecule Generative Models for Interactive Molecule Discovery",
        "track": "main",
        "status": "Reject",
        "keywords": "Molecule Generation;Controllable Molecule Generation;Interpretable Molecule Generation;Molecule Manipulation",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "4;5;4;4",
        "correctness": "3;3;2;2",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;1",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "6hTObFz_nB",
        "title": "Do Androids Dream of Electric Fences? Safety-Aware Reinforcement Learning with Latent Shielding",
        "track": "main",
        "status": "Reject",
        "keywords": "Model-Based Reinforcement Learning;Safety-Aware Reinforcement Learning;Shielding;World Models",
        "author": "",
        "aff": "",
        "rating": "5;5;5;8",
        "confidence": "4;3;4;3",
        "correctness": "3;3;2;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "6iEcgoZ1Aek",
        "title": "Crossformer: Transformer with Alternated Cross-Layer Guidance",
        "track": "main",
        "status": "Withdraw",
        "keywords": "attention;language model;machine translation;deep learning",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "3;4;3;4",
        "correctness": "3;3;2;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "6j9YOwh8itH",
        "title": "Unified Recurrence Modeling for Video Action Anticipation",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "3;4;5;3",
        "correctness": "3;3;2;4",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.058025885318565944,
        "corr_rating_correctness": 0.2721655269759087,
        "project": "",
        "github": ""
    },
    {
        "id": "6jZo9g3MiVV",
        "title": "Contrastive Quant: Quantization Makes Stronger Contrastive Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Contrastive learning;quantization",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "5;5;4;4",
        "correctness": "2;3;3;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;2;3;4",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 4.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "6kCiVaoQdx9",
        "title": "Few-shot Learning via Dirichlet Tessellation Ensemble",
        "track": "main",
        "status": "Poster",
        "keywords": "Few-shot Learning;Computational Geometry;Dirichlet Tessellation;Voronoi Diagram;Ensemble Learning",
        "author": "",
        "aff": "Computer Science and Software Engineering, Penn State Erie; Department of Computer Science and Engineering, University at Buffalo",
        "rating": "6;6;6;8",
        "confidence": "3;5;2;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;3;2;4",
        "empirical_novelty": "3;3;2;4",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.2581988897471611,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "6kruvdT0yfY",
        "title": "C+1 Loss: Learn to Classify C Classes of Interest and the Background Class Differentially",
        "track": "main",
        "status": "Reject",
        "keywords": "C+1 loss;classes of interest;background class",
        "author": "",
        "aff": "",
        "rating": "1;3;3;6",
        "confidence": "5;4;5;4",
        "correctness": "3;2;3;4",
        "technical_novelty": "1;1;1;2",
        "empirical_novelty": "1;1;2;3",
        "presentation": "",
        "rating_avg": 3.25,
        "confidence_avg": 4.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 1.25,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7001400420140049,
        "corr_rating_correctness": 0.5940885257860046,
        "project": "",
        "github": ""
    },
    {
        "id": "6lcE6GdcHyQ",
        "title": "Will a Blind Model Hear Better? Advanced Audiovisual Recognition System with Brain-Like Compensating and Gating",
        "track": "main",
        "status": "Withdraw",
        "keywords": "brain-inspired computing;multi-modal neural network;audio-visual speech recognition",
        "author": "",
        "aff": "",
        "rating": "1;3;5",
        "confidence": "5;5;4",
        "correctness": "1;3;2",
        "technical_novelty": "1;2;2",
        "empirical_novelty": "1;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 1.6666666666666667,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8660254037844385,
        "corr_rating_correctness": 0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "6ooiNCGZa5K",
        "title": "On-Target Adaptation",
        "track": "main",
        "status": "Reject",
        "keywords": "domain adaptation;source-free adaptation;unsupervised domain adaptation",
        "author": "",
        "aff": "",
        "rating": "3;5;6",
        "confidence": "3;4;3",
        "correctness": "3;2;3",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "3;2;3",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.18898223650461363,
        "corr_rating_correctness": -0.18898223650461363,
        "project": "",
        "github": ""
    },
    {
        "id": "6p8D4V_Wmyp",
        "title": "RainNet: A Large-Scale Imagery Dataset for Spatial Precipitation Downscaling",
        "track": "main",
        "status": "Reject",
        "keywords": "Dateset;Downscaling;Computer Vision;Physics;Weather Forecast",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "5;5;4;4",
        "correctness": "2;3;4;3",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "2;3;0;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 4.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9622504486493761,
        "corr_rating_correctness": 0.5443310539518174,
        "project": "",
        "github": ""
    },
    {
        "id": "6q_2b6u0BnJ",
        "title": "TRAIL: Near-Optimal Imitation Learning with Suboptimal Data",
        "track": "main",
        "status": "Poster",
        "keywords": "Imitation Learning;Action Representations;Latent Dynamics Model;Offline Datasets",
        "author": "",
        "aff": "UC Berkeley, Google Brain; Google Brain",
        "rating": "6;6;8",
        "confidence": "3;3;3",
        "correctness": "4;3;3",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "3;2;3",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.49999999999999983,
        "project": "",
        "github": ""
    },
    {
        "id": "6res1KC1Z3Z",
        "title": "Batch-Softmax Contrastive Loss for Pairwise Sentence Scoring Tasks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5",
        "confidence": "5;4;4",
        "correctness": "1;1;3",
        "technical_novelty": "1;2;2",
        "empirical_novelty": "2;1;2",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 1.6666666666666667,
        "technical_novelty_avg": 1.6666666666666667,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4999999999999999,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": "http://anonymous"
    },
    {
        "id": "6sh3pIzKS-",
        "title": "Chemical-Reaction-Aware Molecule Representation Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "molecule representation learning;graph neural networks;chemical reaction",
        "author": "",
        "aff": "University of Illinois Urbana-Champaign; New York University, Genentech",
        "rating": "6;6;8;8",
        "confidence": "4;3;5;4",
        "correctness": "3;4;4;4",
        "technical_novelty": "4;3;3;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.7071067811865475,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": "https://github.com/hwwang55/MolR"
    },
    {
        "id": "6tmjoym9LR6",
        "title": "Stability Regularization for Discrete Representation Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "4;4;3;3",
        "correctness": "3;3;4;4",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "0;2;3;2",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "6u6N8WWwYSM",
        "title": "Bootstrapping Semantic Segmentation with Regional Contrast",
        "track": "main",
        "status": "Poster",
        "keywords": "semi-supervised learning;semantic segmentation;contrastive learning",
        "author": "",
        "aff": "Robot Learning Lab, Imperial College London; Dyson Robotics Lab, Imperial College London",
        "rating": "6;6;8;8",
        "confidence": "4;4;5;3",
        "correctness": "4;3;4;4",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "6uu1t8jQ-M",
        "title": "Generating Novel Scene Compositions from Single Images and Videos",
        "track": "main",
        "status": "Reject",
        "keywords": "GANs;Image Generation;Deep Learning;Image Synthesis;Generative Models",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "5;5;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;3;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 4.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "6vSDzn-4FlW",
        "title": "Synaptic Diversity in ANNs Can Facilitate Faster Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "5;4;3;4",
        "correctness": "2;4;3;2",
        "technical_novelty": "2;4;3;3",
        "empirical_novelty": "1;3;3;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "6vkzF28Hur8",
        "title": "Training Transition Policies via Distribution Matching for Complex Tasks",
        "track": "main",
        "status": "Poster",
        "keywords": "Reinforcement Learning;Hierarchical Reinforcement Learning;Inverse Reinforcement Learning",
        "author": "",
        "aff": "Department of Computer Science & Engineering, The Ohio State University, Columbus, OH 43210, USA",
        "rating": "6;6;6",
        "confidence": "2;2;3",
        "correctness": "4;4;4",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "3;3;2",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "6w2zSI9RAnf",
        "title": "Reasoning With Hierarchical Symbols: Reclaiming Symbolic Policies For Visual Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Symbolic Regression;Reinforcement Learning;Convolutional Neural Networks;Interpretability",
        "author": "",
        "aff": "",
        "rating": "3;3;6;6;8",
        "confidence": "4;4;4;4;4",
        "correctness": "2;2;4;3;4",
        "technical_novelty": "2;2;3;4;4",
        "empirical_novelty": "2;2;2;4;4",
        "presentation": "",
        "rating_avg": 5.2,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.8,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9225312080288851,
        "project": "",
        "github": ""
    },
    {
        "id": "6y2KBh-0Fd9",
        "title": "Revisiting flow generative models for Out-of-distribution detection",
        "track": "main",
        "status": "Poster",
        "keywords": "flow models;out-of-distribution detection;random projection;distribution comparison",
        "author": "",
        "aff": "School of Computer Science, University of Waterloo, National Research Council; School of Computer Science, University of Waterloo, Vector Institute",
        "rating": "6;8;8;8",
        "confidence": "4;4;3;4",
        "correctness": "4;4;3;4",
        "technical_novelty": "3;2;3;1",
        "empirical_novelty": "3;3;2;2",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "6yVvwR9H9Oj",
        "title": "On Non-Random Missing Labels in Semi-Supervised Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "Semi-Supervised Learning;Missing Not At Random;Image Classification",
        "author": "",
        "aff": "Nanyang Technological University; Damo Academy, Alibaba Group",
        "rating": "6;6;8",
        "confidence": "2;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "3;2;3",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8660254037844385,
        "corr_rating_correctness": 0.49999999999999983,
        "project": "",
        "github": ""
    },
    {
        "id": "6ya8C6sCiD",
        "title": "Multi-Agent Language Learning: Symbolic Mapping",
        "track": "main",
        "status": "Reject",
        "keywords": "emergent communication;multi-agent reinforcement learning",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6;6",
        "confidence": "2;3;4;4;4",
        "correctness": "2;4;3;2;3",
        "technical_novelty": "1;2;3;2;4",
        "empirical_novelty": "1;0;2;3;3",
        "presentation": "",
        "rating_avg": 5.2,
        "confidence_avg": 3.4,
        "correctness_avg": 2.8,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 1.8,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9861168645694258,
        "corr_rating_correctness": 0.2750095491084634,
        "project": "",
        "github": ""
    },
    {
        "id": "73MEhZ0anV",
        "title": "QUERY EFFICIENT DECISION BASED SPARSE ATTACKS AGAINST BLACK-BOX DEEP LEARNING MODELS",
        "track": "main",
        "status": "Poster",
        "keywords": "decision-based attacks;sparse attacks;evolution algorithms;vision transformer;convolutional neural network",
        "author": "",
        "aff": "The University Of Adelaide",
        "rating": "5;6;6;6",
        "confidence": "3;3;2;5",
        "correctness": "3;3;4;4",
        "technical_novelty": "1;3;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.13245323570650439,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "74cDdRwm4NV",
        "title": "Learning to Shape Rewards using a Game of Two Partners",
        "track": "main",
        "status": "Reject",
        "keywords": "Reinforcement learning;Reward Shaping;Markov game;Sparse rewards",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "3;4;3;4",
        "correctness": "2;2;3;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "1;2;3;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.6882472016116854,
        "corr_rating_correctness": 0.6882472016116854,
        "project": "",
        "github": ""
    },
    {
        "id": "74x5BXs4bWD",
        "title": "Evolutionary Diversity Optimization with Clustering-based Selection for Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "Reinforcement learning;Quality-Diversity;Evolutionary algorithms",
        "author": "",
        "aff": "State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing 210023, China",
        "rating": "5;6;6;8",
        "confidence": "5;4;4;3",
        "correctness": "3;4;3;4",
        "technical_novelty": "1;3;3;3",
        "empirical_novelty": "2;3;4;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9733285267845754,
        "corr_rating_correctness": 0.6882472016116854,
        "project": "",
        "github": ""
    },
    {
        "id": "77_zstKV8HQ",
        "title": "SimMER: Simple Maximization of Entropy and Rank for Self-supervised Representation Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "self-supervised learning;representation learning;computer vision;image classification",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "5;5;4;4",
        "correctness": "3;2;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "1;0;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "7ADMMyZpeY",
        "title": "A theoretically grounded characterization of feature representations",
        "track": "main",
        "status": "Reject",
        "keywords": "features;analysis;generalization;transfer;few-shot",
        "author": "",
        "aff": "",
        "rating": "5;6;6;6;8",
        "confidence": "3;3;3;3;2",
        "correctness": "4;4;3;3;3",
        "technical_novelty": "2;2;3;3;4",
        "empirical_novelty": "3;2;3;2;4",
        "presentation": "",
        "rating_avg": 6.2,
        "confidence_avg": 2.8,
        "correctness_avg": 3.4,
        "technical_novelty_avg": 2.8,
        "empirical_novelty_avg": 2.8,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9185586535436918,
        "corr_rating_correctness": -0.5833333333333334,
        "project": "",
        "github": ""
    },
    {
        "id": "7AssAnH5vyJ",
        "title": "A Game-Theoretic Approach for Improving Generalization Ability of TSP Solvers",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Combinatorial Optimization Problem;Policy Space Response Oracle;Reinforcement Learning",
        "author": "",
        "aff": "",
        "rating": "3;3;3;6",
        "confidence": "4;4;4;3",
        "correctness": "4;3;3;4",
        "technical_novelty": "3;3;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "7AzOUBeajwl",
        "title": "Text Style Transfer with Confounders",
        "track": "main",
        "status": "Reject",
        "keywords": "style transfer;confounder;invariance",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "4;4;4;4",
        "correctness": "2;3;3;4",
        "technical_novelty": "2;2;2;4",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "7B3IJMM1k_M",
        "title": "Optimal ANN-SNN Conversion for High-accuracy and Ultra-low-latency Spiking Neural Networks",
        "track": "main",
        "status": "Poster",
        "keywords": "Spiking Neural Networks;ANN-SNN Conversion;Ultra-low Latency;Quantization Clip-floor-shift Activation",
        "author": "",
        "aff": "Southwest Jiaotong University; Peking University",
        "rating": "6;6;6;8",
        "confidence": "4;4;5;5",
        "correctness": "3;3;2;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;2;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 4.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": "https://github.com/putshua/SNN conversion QCFS"
    },
    {
        "id": "7Bc2U-dLJ6N",
        "title": "SGDEM: stochastic gradient descent with energy and momentum",
        "track": "main",
        "status": "Reject",
        "keywords": "stochastic optimization;energy stability;momentum",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "4;4;5;5",
        "correctness": "3;4;2;4",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "1;2;2;2",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 4.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.5222329678670935,
        "project": "",
        "github": ""
    },
    {
        "id": "7DI6op61AY",
        "title": "Neural Markov Controlled SDE: Stochastic Optimization for Continuous-Time Data",
        "track": "main",
        "status": "Poster",
        "keywords": "controlled stochastic differential equation;time-series prediction",
        "author": "",
        "aff": "Artificial Intelligence Graduate School, Chung-Ang University, Korea; School of Computer Science and Engineering, Chung-Ang University, Korea; School of Computer Science and Engineering, Chung-Ang University, Korea; Artificial Intelligence Graduate School, Chung-Ang University, Korea",
        "rating": "3;6;8;8",
        "confidence": "4;2;3;4",
        "correctness": "4;3;3;4",
        "technical_novelty": "3;3;4;4",
        "empirical_novelty": "3;0;2;4",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.18417736717093933,
        "corr_rating_correctness": -0.3665083330689157,
        "project": "",
        "github": ""
    },
    {
        "id": "7F9cOhdvfk_",
        "title": "$\\mathrm{SO}(2)$-Equivariant Reinforcement Learning",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Reinforcement Learning;Equivariance;Robotic Manipulation",
        "author": "",
        "aff": "Khoury College of Computer Sciences, Northeastern University, Boston, MA 02115, USA",
        "rating": "5;6;8;8;8",
        "confidence": "4;3;3;4;3",
        "correctness": "3;3;3;4;3",
        "technical_novelty": "2;3;2;2;3",
        "empirical_novelty": "2;3;3;4;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.4,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3227486121839514,
        "corr_rating_correctness": 0.3952847075210474,
        "project": "",
        "github": ""
    },
    {
        "id": "7HhX4mbern",
        "title": "Randomized Signature Layers for Signal Extraction in Time Series Data",
        "track": "main",
        "status": "Reject",
        "keywords": "signature;random features;time series;SDE;differential equations;rough path",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "4;4;5;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;3;2;1",
        "empirical_novelty": "3;2;4;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "7I8LPkcx8V",
        "title": "Differentially Private Fractional Frequency Moments Estimation with Polylogarithmic Space",
        "track": "main",
        "status": "Poster",
        "keywords": "Differential Privacy;Fractional Frequency Moments",
        "author": "",
        "aff": "Michigan Tech; UC Berkeley",
        "rating": "6;6;8;8",
        "confidence": "4;4;3;3",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "3;0;2;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "7IWGzQ6gZ1D",
        "title": "Constructing a Good Behavior Basis for Transfer using Generalized Policy Updates",
        "track": "main",
        "status": "Poster",
        "keywords": "reinforcement learning;lifelong learning;transfer learning;successor features",
        "author": "",
        "aff": "Mila, McGill University and DeepMind; Mila, McGill University",
        "rating": "6;6;10",
        "confidence": "3;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "2;3;4",
        "empirical_novelty": "2;2;4",
        "presentation": "",
        "rating_avg": 7.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "7KdAoOsI81C",
        "title": "Transfer RL across Observation Feature Spaces via Model-Based Regularization",
        "track": "main",
        "status": "Poster",
        "keywords": "transfer reinforcement learning;representation learning;observation space change;latent dynamics model",
        "author": "",
        "aff": "University of Maryland, College Park; Unity Technologies",
        "rating": "5;5;6;8",
        "confidence": "3;4;3;3",
        "correctness": "3;2;3;3",
        "technical_novelty": "2;2;3;4",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4714045207910316,
        "corr_rating_correctness": 0.4714045207910316,
        "project": "",
        "github": ""
    },
    {
        "id": "7KgeqhkbZab",
        "title": "Contrastive Learning for Source Code with Structural and Functional Properties",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Source Code Modeling;Contrastive Learning;Pre-trained Models",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "5;4;5;4",
        "correctness": "2;3;4;4",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "1;2;3;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9045340337332909,
        "project": "",
        "github": ""
    },
    {
        "id": "7MLeqJrHNa",
        "title": "Continual Learning of Neural Networks for Realtime Wireline Cable Position Inference",
        "track": "main",
        "status": "Reject",
        "keywords": "Continual Learning;Wireline Automation",
        "author": "",
        "aff": "",
        "rating": "1;3;3;5",
        "confidence": "5;4;5;4",
        "correctness": "1;2;4;3",
        "technical_novelty": "1;2;1;2",
        "empirical_novelty": "1;2;1;3",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 1.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7071067811865476,
        "corr_rating_correctness": 0.6324555320336759,
        "project": "",
        "github": ""
    },
    {
        "id": "7MV6uLzOChW",
        "title": "Conditional Image Generation by Conditioning Variational Auto-Encoders",
        "track": "main",
        "status": "Poster",
        "keywords": "variational auto-encoders;Bayesian inference;variational inference;amortized inference;image completion",
        "author": "",
        "aff": "Department of Computer Science, University of British Columbia, Vancouver, Canada; Department of Computer Science, University of British Columbia, Vancouver, Canada; Montr\u00b4eal Institute for Learning Algorithms (Mila) and Inverted AI",
        "rating": "6;8;8;8",
        "confidence": "3;4;3;5",
        "correctness": "4;3;4;3",
        "technical_novelty": "2;3;4;3",
        "empirical_novelty": "2;3;4;3",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5222329678670935,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "7N-6ZLyFUXz",
        "title": "Thompson Sampling for (Combinatorial) Pure Exploration",
        "track": "main",
        "status": "Reject",
        "keywords": "pure exploration;(combinatorial) multi-armed bandit;Thompson Sampling",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "4;2;4;3",
        "correctness": "3;3;4;3",
        "technical_novelty": "3;3;2;2",
        "empirical_novelty": "0;2;0;0",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 0.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.30151134457776363,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "7QDPaL-Yl8U",
        "title": "LPRules: Rule Induction in Knowledge Graphs Using Linear Programming",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "Paper under double-blind review",
        "rating": "3;3;6;6",
        "confidence": "5;3;5;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "7QfLW-XZTl",
        "title": "Energy-Inspired Molecular Conformation Optimization",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "AIR, Tsinghua University; University of Texas at Austin; University of Illinois at Urbana-Champaign, AIR, Tsinghua University, HeliXon Limited; Peking University, Beijing Institute for General Arti\ufb01cial Intelligence; University of Illinois at Urbana-Champaign",
        "rating": "3;6;6;8",
        "confidence": "4;3;4;3",
        "correctness": "3;3;2;4",
        "technical_novelty": "3;3;2;3",
        "empirical_novelty": "0;3;3;2",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7001400420140049,
        "corr_rating_correctness": 0.39605901719066966,
        "project": "",
        "github": ""
    },
    {
        "id": "7Rnf1F7rQhR",
        "title": "Best Practices in Pool-based Active Learning for Image Classification",
        "track": "main",
        "status": "Reject",
        "keywords": "Active Learning;Deep Learning;Image classification",
        "author": "",
        "aff": "",
        "rating": "5;6;6;8",
        "confidence": "3;5;3;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;3;1;2",
        "empirical_novelty": "3;3;3;2",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3458572319330373,
        "corr_rating_correctness": -0.13245323570650439,
        "project": "",
        "github": ""
    },
    {
        "id": "7TFcl1Xkr7",
        "title": "Interactive Model with Structural Loss for Language-based Abductive Reasoning",
        "track": "main",
        "status": "Reject",
        "keywords": "abductive  natural  language;abductive reasoning;BiLSTM;joint loss function.",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3;3",
        "confidence": "3;4;4;3;4",
        "correctness": "2;2;3;2;3",
        "technical_novelty": "1;2;2;3;2",
        "empirical_novelty": "2;2;2;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6,
        "correctness_avg": 2.4,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "7TZeCsNOUB_",
        "title": "Collapse by Conditioning: Training Class-conditional GANs with Limited Data",
        "track": "main",
        "status": "Poster",
        "keywords": "Generative Adversarial Network;GAN;Conditional GAN;limited data",
        "author": "",
        "aff": "Computer Vision Lab (CVL), ETH Zurich, Switzerland",
        "rating": "5;6;6;8",
        "confidence": "4;4;4;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "3;2;4;2",
        "empirical_novelty": "4;3;3;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9271726499455306,
        "project": "",
        "github": "https://github.com/mshahbazi72/transitional-cGAN"
    },
    {
        "id": "7U-rmW7TPHM",
        "title": "EfficientPhys: Enabling Simple, Fast, and Accurate Camera-Based Vitals Measurement",
        "track": "main",
        "status": "Reject",
        "keywords": "Computer Vision;Healthcare;Deep Learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;8",
        "confidence": "4;4;4;4",
        "correctness": "3;2;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.49374193110101877,
        "project": "",
        "github": ""
    },
    {
        "id": "7UmjRGzp-A",
        "title": "Understanding over-squashing and bottlenecks on graphs via curvature",
        "track": "main",
        "status": "Oral",
        "keywords": "Graph neural networks;Geometric deep learning;Differential geometry;Ricci curvature",
        "author": "",
        "aff": "Twitter; University of Oxford; Imperial College London",
        "rating": "8;8;8;10",
        "confidence": "3;3;4;4",
        "correctness": "4;3;4;4",
        "technical_novelty": "4;3;4;4",
        "empirical_novelty": "3;3;2;2",
        "presentation": "",
        "rating_avg": 8.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "7VH_ZMpwZXa",
        "title": "No Shifted Augmentations (NSA): strong baselines for self-supervised Anomaly Detection",
        "track": "main",
        "status": "Reject",
        "keywords": "self-supervised learning;anomaly detection",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "5;4;3;3",
        "correctness": "3;4;4;3",
        "technical_novelty": "2;2;4;2",
        "empirical_novelty": "2;3;0;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9045340337332909,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "7VYh_3ZD84",
        "title": "Sharpness-Aware Minimization in Large-Batch Training: Training Vision Transformer In Minutes",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Distributed Machine Learning;Large-Batch Training",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "4;4;4;4",
        "correctness": "2;2;2;3",
        "technical_novelty": "2;3;3;4",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 4.0,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.7777777777777777,
        "project": "",
        "github": ""
    },
    {
        "id": "7WVAI3dRwhR",
        "title": "Adversarial twin neural networks: maximizing physics recovery for physical system",
        "track": "main",
        "status": "Reject",
        "keywords": "Physical Equation Learning;Incomplete Observability;Twin Neural Network;Mini-Max Game",
        "author": "",
        "aff": "",
        "rating": "5;5;6",
        "confidence": "4;2;3",
        "correctness": "3;3;2",
        "technical_novelty": "2;3;2",
        "empirical_novelty": "2;0;3",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 3.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.9999999999999997,
        "project": "",
        "github": ""
    },
    {
        "id": "7YDLgf9_zgm",
        "title": "Continual Learning with Recursive Gradient Optimization",
        "track": "main",
        "status": "Spotlight",
        "keywords": "continual learning;lifelong learning",
        "author": "",
        "aff": "Department of Computer Science, Tsinghua University, Beijing, China",
        "rating": "5;8;8;8",
        "confidence": "4;4;4;4",
        "correctness": "3;4;4;3",
        "technical_novelty": "3;4;4;3",
        "empirical_novelty": "2;4;3;3",
        "presentation": "",
        "rating_avg": 7.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.5,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "7Z7u2z1Ornl",
        "title": "Pruning Edges and Gradients to Learn Hypergraphs from Larger Sets",
        "track": "main",
        "status": "Reject",
        "keywords": "set-to-hypergraph",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "2;3;3;3",
        "correctness": "2;2;3;3",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "3;0;2;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 2.75,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 1.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "7_JR7WpwKV1",
        "title": "The Effects of Invertibility on the Representational Complexity of Encoders in Variational Autoencoders",
        "track": "main",
        "status": "Poster",
        "keywords": "variational autoencoders;encoder;representational complexity;Langevin;invertibility;deep learning theory",
        "author": "",
        "aff": "Machine Learning Department, Carnegie Mellon University, Pittsburgh, PA, 15213",
        "rating": "6;6;6",
        "confidence": "3;3;3",
        "correctness": "4;3;4",
        "technical_novelty": "2;2;4",
        "empirical_novelty": "3;2;0",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "7b4zxUnrO2N",
        "title": "Possibility Before Utility: Learning And Using Hierarchical Affordances",
        "track": "main",
        "status": "Spotlight",
        "keywords": "RL;HRL;reinforcement learning;hierarchical reinforcement learning;affordances;hierarchical affordances",
        "author": "",
        "aff": "University of Southern California; Google Research",
        "rating": "8;8;8;8",
        "confidence": "4;3;4;3",
        "correctness": "3;3;4;3",
        "technical_novelty": "3;3;4;3",
        "empirical_novelty": "3;2;4;3",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/robbycostales/HAL"
    },
    {
        "id": "7d_GchF1e7",
        "title": "Variance Pruning: Pruning Language Models via Temporal Neuron Variance",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Natural language processing;Transformers;Language Models;Pruning",
        "author": "",
        "aff": "",
        "rating": "3;3;3;6",
        "confidence": "4;4;3;4",
        "correctness": "3;2;3;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "7fFO4cMBx_9",
        "title": "Variational Neural Cellular Automata",
        "track": "main",
        "status": "Poster",
        "keywords": "Neural Cellular Automata;Cellular Automata;Self-Organization;Generative Models",
        "author": "",
        "aff": "; Creative AI Lab, IT University of Copenhagen, Copenhagen, Denmark",
        "rating": "5;5;5;8",
        "confidence": "4;4;4;5",
        "correctness": "3;4;4;4",
        "technical_novelty": "3;2;2;3",
        "empirical_novelty": "2;1;3;0",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 4.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 1.0,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "7gE9V9GBZaI",
        "title": "Exploring Memorization in Adversarial Training",
        "track": "main",
        "status": "Poster",
        "keywords": "Adversarial examples;adversarial training;memorization;robust overfitting",
        "author": "",
        "aff": "Dept. of Comp. Sci. and Tech., Institute for AI, Tsinghua-Bosch Joint ML Center, THBI Lab, BNRist Center, Tsinghua University, Beijing, China; RealAI; Peng Cheng Laboratory; Dept. of Comp. Sci. and Tech., Institute for AI, Tsinghua-Bosch Joint ML Center, THBI Lab, BNRist Center, Tsinghua University, Beijing, China; RealAI; Dept. of Comp. Sci. and Tech., Institute for AI, Tsinghua-Bosch Joint ML Center, THBI Lab, BNRist Center, Tsinghua University, Beijing, China; Peng Cheng Laboratory; Dept. of Comp. Sci. and Tech., Institute for AI, Tsinghua-Bosch Joint ML Center, THBI Lab, BNRist Center, Tsinghua University, Beijing, China; Dept. of Comp. Sci. and Tech., Institute for AI, Tsinghua-Bosch Joint ML Center, THBI Lab, BNRist Center, Tsinghua University, Beijing, China; CMU",
        "rating": "3;6;8;10",
        "confidence": "4;4;2;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;2;3;4",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.27907278609297376,
        "corr_rating_correctness": 0.8700628401410974,
        "project": "",
        "github": ""
    },
    {
        "id": "7gRvcAulxa",
        "title": "A Frequency Perspective of Adversarial Robustness",
        "track": "main",
        "status": "Reject",
        "keywords": "Adversarial examples;Frequency analysis;Adversarial Robustness;Adversarial training",
        "author": "",
        "aff": "",
        "rating": "3;5;6;8",
        "confidence": "3;4;4;4",
        "correctness": "2;3;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8006407690254357,
        "corr_rating_correctness": 0.9198662110077999,
        "project": "",
        "github": ""
    },
    {
        "id": "7gWSJrP3opB",
        "title": "A General Analysis of Example-Selection for Stochastic Gradient Descent",
        "track": "main",
        "status": "Spotlight",
        "keywords": "",
        "author": "",
        "aff": "Department of Computer Science, Cornell University, Ithaca, NY 14853, USA",
        "rating": "8;8;8;8",
        "confidence": "3;4;4;3",
        "correctness": "4;4;3;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/EugeneLYC/qmc-ordering"
    },
    {
        "id": "7grkzyj89A_",
        "title": "Generalization Through the Lens of Leave-One-Out Error",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "Department of Computer Science, ETH Z\u00fcrich, Switzerland; Department of Mathematics and Computer Science, University of Basel",
        "rating": "6;6;6",
        "confidence": "3;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "3;2;2",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "7inCJ3MhXt3",
        "title": "Learning Neural Contextual Bandits through Perturbed Rewards",
        "track": "main",
        "status": "Poster",
        "keywords": "contextual bandit;neural bandit",
        "author": "",
        "aff": "Department of Computer Science, University of Virginia; Department of Computer Science, University of California, Los Angeles",
        "rating": "5;6;8;8",
        "confidence": "4;3;3;3",
        "correctness": "4;4;3;4",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 3.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7777777777777777,
        "corr_rating_correctness": -0.5555555555555555,
        "project": "",
        "github": ""
    },
    {
        "id": "7kOsYRp4EmB",
        "title": "Improving Meta-Continual Learning Representations with Representation Replay",
        "track": "main",
        "status": "Reject",
        "keywords": "meta-learning;continual learning;meta-continual learning;replay",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "4;3;4;3",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "7kqWcX_r2w",
        "title": "Meta Attention For Off-Policy Actor-Critic",
        "track": "main",
        "status": "Reject",
        "keywords": "reinforcement learning;meta learning;Attention Mechanism",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;3;3;4",
        "correctness": "2;3;2;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "1;2;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "7ktHTjV9FHw",
        "title": "Relative Molecule Self-Attention Transformer",
        "track": "main",
        "status": "Reject",
        "keywords": "molecular property prediction;transformer-based methods;graph neural networks;self-supervised learing",
        "author": "",
        "aff": "",
        "rating": "6;6;6",
        "confidence": "3;2;4",
        "correctness": "3;4;3",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "7l1IjZVddDW",
        "title": "Improving Federated Learning Face Recognition via Privacy-Agnostic Clusters",
        "track": "main",
        "status": "Spotlight",
        "keywords": "",
        "author": "",
        "aff": "Algorithm Research, Aibee Inc.; Independent Researcher",
        "rating": "5;8;8;8",
        "confidence": "5;5;4;3",
        "correctness": "2;4;3;3",
        "technical_novelty": "2;4;3;4",
        "empirical_novelty": "2;4;3;3",
        "presentation": "",
        "rating_avg": 7.25,
        "confidence_avg": 4.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5222329678670935,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "7oyVOECcrt",
        "title": "Local Permutation Equivariance For Graph Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "Graphs;Equivariance;Permutation Equivariance;Graph Neural Networks;Representations",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;4;3;2",
        "correctness": "2;2;2;3",
        "technical_novelty": "2;2;1;3",
        "empirical_novelty": "0;2;1;3",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.25,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8703882797784891,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "7pZiaojaVGU",
        "title": "An Equivalence Between Data Poisoning and Byzantine Gradient Attacks",
        "track": "main",
        "status": "Reject",
        "keywords": "Federated learning;PAC learning;Byzantine attack;Data poisoning;Personalized  learning",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5;6",
        "confidence": "4;3;4;3;3",
        "correctness": "3;4;4;3;4",
        "technical_novelty": "3;2;3;2;3",
        "empirical_novelty": "2;3;2;1;4",
        "presentation": "",
        "rating_avg": 4.8,
        "confidence_avg": 3.4,
        "correctness_avg": 3.6,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6666666666666667,
        "corr_rating_correctness": 0.6666666666666667,
        "project": "",
        "github": ""
    },
    {
        "id": "7qaCQiuOVf",
        "title": "Interpreting Reinforcement Policies through Local Behaviors",
        "track": "main",
        "status": "Reject",
        "keywords": "Reinforcement Learning;Explainability",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "5;3;3;4",
        "correctness": "2;3;4;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6225430174794673,
        "corr_rating_correctness": 0.6488856845230502,
        "project": "",
        "github": ""
    },
    {
        "id": "7r6kDq0mK_",
        "title": "Latent Image Animator: Learning to Animate Images via Latent Space Navigation",
        "track": "main",
        "status": "Poster",
        "keywords": "Video generation;Generative Adversarial Network",
        "author": "",
        "aff": "Inria, Universit \u00b4e C\u02c6ote d\u2019Azur",
        "rating": "6;6;6;8;8",
        "confidence": "4;4;4;4;3",
        "correctness": "4;4;3;4;4",
        "technical_novelty": "2;2;3;3;3",
        "empirical_novelty": "2;3;2;3;3",
        "presentation": "",
        "rating_avg": 6.8,
        "confidence_avg": 3.8,
        "correctness_avg": 3.8,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 2.6,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6123724356957946,
        "corr_rating_correctness": 0.408248290463863,
        "project": "https://wyhsirius.github.io/LIA-project/",
        "github": "https://github.com/wyhsirius/LIA-project"
    },
    {
        "id": "7sz69eztw9",
        "title": "Context-invariant, multi-variate time series representations",
        "track": "main",
        "status": "Reject",
        "keywords": "time series;representation learning;contrastive learning;context invariance;anomaly detection;domain adversarial learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5",
        "confidence": "3;4;3",
        "correctness": "2;3;3",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5,
        "corr_rating_correctness": 0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "7t_6BiC69a",
        "title": "Fieldwise Factorized Networks for Tabular Data Classification",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "3;4;3;2",
        "correctness": "2;3;3;3",
        "technical_novelty": "3;3;3;4",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.28867513459481287,
        "corr_rating_correctness": 0.9428090415820632,
        "project": "",
        "github": ""
    },
    {
        "id": "7twQI5VnC8",
        "title": "Learning Causal Models from Conditional Moment Restrictions by Importance Weighting",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Causal inference;Conditional moment restrictions",
        "author": "",
        "aff": "Temple University; The University of Tokyo; AI Lab, CyberAgent, Inc.",
        "rating": "6;8;8",
        "confidence": "3;3;2",
        "correctness": "3;4;4",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 7.333333333333333,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.49999999999999983,
        "corr_rating_correctness": 0.9999999999999998,
        "project": "",
        "github": ""
    },
    {
        "id": "7uSajQt2ki",
        "title": "Zero-shot Cross-lingual Conversational Semantic Role Labeling",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "3;5;4;4",
        "correctness": "3;2;3;4",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "3;0;2;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "7udZAsEzd60",
        "title": "VC dimension of partially quantized neural networks in the overparametrized regime",
        "track": "main",
        "status": "Poster",
        "keywords": "VC dimension;quantized neural networks;classification;minimax theory;overparametrization",
        "author": "",
        "aff": "Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI 48109, USA; Department of Electrical Engineering and Computer Science, Department of Statistics, University of Michigan, Ann Arbor, MI 48109, USA",
        "rating": "6;6;8",
        "confidence": "2;3;2",
        "correctness": "4;4;3",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "3;3;4",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 3.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.49999999999999983,
        "corr_rating_correctness": -0.9999999999999998,
        "project": "",
        "github": ""
    },
    {
        "id": "7vXQJ2QW8hR",
        "title": "Max-Affine Spline Insights Into Deep Network Pruning",
        "track": "main",
        "status": "Reject",
        "keywords": "DNN Interpretability;Network pruning;Max-affine spline theory;Visualization",
        "author": "",
        "aff": "",
        "rating": "5;6;6;8",
        "confidence": "4;4;5;3",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "3;3;2;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6488856845230502,
        "corr_rating_correctness": 0.6622661785325219,
        "project": "",
        "github": ""
    },
    {
        "id": "7vcKot39bsv",
        "title": "Adaptive Inertia: Disentangling the Effects of Adaptive Learning Rate and Momentum",
        "track": "main",
        "status": "Reject",
        "keywords": "Learning Dynamics;Diffusion;Stochastic Optimization;Momentum",
        "author": "",
        "aff": "",
        "rating": "3;5;6;8",
        "confidence": "4;4;3;4",
        "correctness": "2;2;3;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.16012815380508713,
        "corr_rating_correctness": 0.9198662110077999,
        "project": "",
        "github": ""
    },
    {
        "id": "7x_47XJULn",
        "title": "Federated Learning with Heterogeneous Architectures using Graph HyperNetworks",
        "track": "main",
        "status": "Reject",
        "keywords": "federated learning;graph neural networks;hypernetworks",
        "author": "",
        "aff": "",
        "rating": "3;3;6;6",
        "confidence": "4;4;3;3",
        "correctness": "3;2;3;2",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;3;4;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "7xzVpAP5Cm",
        "title": "Non-reversible Parallel Tempering for Uncertainty Approximation in Deep Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "replica exchange;parallel tempering;non-reversibility;stochastic approximation;round trip rate;deep learning",
        "author": "",
        "aff": "",
        "rating": "3;5;5;8",
        "confidence": "4;3;3;2",
        "correctness": "2;3;3;4",
        "technical_novelty": "4;3;3;3",
        "empirical_novelty": "4;3;3;0",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9901475429766743,
        "corr_rating_correctness": 0.9901475429766743,
        "project": "",
        "github": ""
    },
    {
        "id": "7y0AmECNwE",
        "title": "Parameter Estimation for the SEIR Model Using Recurrent Nets",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;6;6",
        "confidence": "3;4;4;5",
        "correctness": "3;4;3;4",
        "technical_novelty": "3;2;2;2",
        "empirical_novelty": "3;2;2;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.7071067811865476,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "7yuU9VeIpde",
        "title": "Memory-Constrained Policy Optimization",
        "track": "main",
        "status": "Reject",
        "keywords": "reinforcement learning;trust region policy optimization;on-policy;policy gradient;neural network",
        "author": "",
        "aff": "",
        "rating": "3;5;5;8",
        "confidence": "3;4;5;4",
        "correctness": "2;4;4;4",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.39605901719066966,
        "corr_rating_correctness": 0.7276068751089989,
        "project": "",
        "github": ""
    },
    {
        "id": "7zFokR7k_86",
        "title": "Learning Symbolic Rules for Reasoning in Quasi-Natural Language",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;6;8",
        "confidence": "1;3;5;3",
        "correctness": "2;4;3;4",
        "technical_novelty": "2;3;4;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5883484054145521,
        "corr_rating_correctness": 0.7526178090063818,
        "project": "",
        "github": ""
    },
    {
        "id": "7zc05Ua_HOK",
        "title": "Learning Sample Reweighting for Adversarial Robustness",
        "track": "main",
        "status": "Reject",
        "keywords": "deep learning;adversarial attack;robust training",
        "author": "",
        "aff": "",
        "rating": "3;3;6;6;8;8",
        "confidence": "4;4;4;4;4;4",
        "correctness": "3;3;3;3;4;4",
        "technical_novelty": "2;2;3;2;2;3",
        "empirical_novelty": "2;2;3;3;3;3",
        "presentation": "",
        "rating_avg": 5.666666666666667,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.8029550685469661,
        "project": "",
        "github": ""
    },
    {
        "id": "80GQMJCj5oD",
        "title": "Gradient-based Hyperparameter Optimization without Validation Data for Learning fom Limited Labels",
        "track": "main",
        "status": "Withdraw",
        "keywords": "hyperparameter optimization;learning from limited labels;bayesian model selection",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "3;3;3;2",
        "correctness": "4;1;3;4",
        "technical_novelty": "2;2;2;1",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.40824829046386296,
        "project": "",
        "github": ""
    },
    {
        "id": "81e1aeOt-sd",
        "title": "On-Policy Model Errors in Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "Model-based reinforcement learning;reinforcement learning;model learning",
        "author": "",
        "aff": "Bosch Center for Arti\ufb01cial Intelligence, Renningen, Germany; Institute for Dynamic Systems and Control, ETH Z\u00fcrich, Zurich, Switzerland",
        "rating": "5;6;6;8",
        "confidence": "4;3;4;3",
        "correctness": "4;3;3;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;0;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6882472016116854,
        "corr_rating_correctness": 0.2294157338705618,
        "project": "",
        "github": ""
    },
    {
        "id": "827jG3ahxL",
        "title": "REFACTOR: Learning to Extract Theorems from Proofs",
        "track": "main",
        "status": "Reject",
        "keywords": "theorem extraction;mathematical reasoning;theorem proving;reasoning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5;6",
        "confidence": "3;4;4;5;4",
        "correctness": "3;4;4;3;3",
        "technical_novelty": "2;2;2;3;3",
        "empirical_novelty": "3;3;2;2;3",
        "presentation": "",
        "rating_avg": 4.4,
        "confidence_avg": 4.0,
        "correctness_avg": 3.4,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 2.6,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5270462766947298,
        "corr_rating_correctness": -0.2721655269759087,
        "project": "",
        "github": ""
    },
    {
        "id": "83grvoIJRnb",
        "title": "SGTR: Generating Scene Graph by Learning Compositional Triplets with Transformer",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Computer Vision;Scene graph Generation;Scene Understanding",
        "author": "",
        "aff": "",
        "rating": "1;3;5;5",
        "confidence": "4;5;4;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "3;2;2;2",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.17407765595569782,
        "corr_rating_correctness": 0.8703882797784891,
        "project": "",
        "github": ""
    },
    {
        "id": "844kbKgwDL",
        "title": "Predicting subscriber usage: Analyzing multi-dimensional time-series using Convolutional Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "Convolutional Neural Network;time series;usage prediction",
        "author": "",
        "aff": "Under double-blind review",
        "rating": "3;3;3;3;3",
        "confidence": "3;4;5;5;5",
        "correctness": "2;2;3;3;3",
        "technical_novelty": "2;2;2;2;2",
        "empirical_novelty": "2;1;3;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.4,
        "correctness_avg": 2.6,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "847CwJv9Vx",
        "title": "Benchmarking person re-identification approaches and training datasets for practical real-world implementations",
        "track": "main",
        "status": "Reject",
        "keywords": "person re-identification;benchmark study;practical deployment",
        "author": "",
        "aff": "",
        "rating": "3;5;5",
        "confidence": "4;4;4",
        "correctness": "2;3;3",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "3;2;2",
        "presentation": "",
        "rating_avg": 4.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9999999999999998,
        "project": "",
        "github": ""
    },
    {
        "id": "84NMXTHYe-",
        "title": "Evidential Turing Processes",
        "track": "main",
        "status": "Poster",
        "keywords": "Evidential Deep Learning;Neural Processes;Attention;Neural Turing Machines",
        "author": "",
        "aff": "Department of Computer Engineering, Istanbul Technical University, Istanbul, Turkey; Department of Computer Science, Aalto University, Espoo, Finland; Dept of Math and Computer Science, University of Southern Denmark, Odense, Denmark",
        "rating": "5;6;6;8",
        "confidence": "3;2;2;3",
        "correctness": "2;4;4;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 2.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.2294157338705618,
        "corr_rating_correctness": 0.20751433915982243,
        "project": "",
        "github": ""
    },
    {
        "id": "86sEVRfeGYS",
        "title": "Continual Backprop: Stochastic Gradient Descent with Persistent Randomness",
        "track": "main",
        "status": "Reject",
        "keywords": "Continual Adaptation;Reinforcement Learning;Continual Learning;Online Learning",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;4;5;4",
        "correctness": "3;4;4;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;3;4",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.13245323570650439,
        "corr_rating_correctness": 0.2294157338705618,
        "project": "",
        "github": ""
    },
    {
        "id": "87Ks7PvYVJi",
        "title": "Offline Decentralized Multi-Agent Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "multi-agent reinforcement learning",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "5;3;2;4",
        "correctness": "2;3;3;2",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;2;2;0",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.2581988897471611,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "87ULMOeCnE-",
        "title": "From Graph Local Embedding to Deep Metric Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "metric learning;fine-grained retrieval",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;4;4",
        "correctness": "2;3;2;3",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "89W18gW0-6o",
        "title": "Provably Improved Context-Based Offline Meta-RL with Attention and Contrastive Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Reinforcement Learning;Representation learning for planning;Meta-RL;Attention Mechanism;Contrastive Learning;Offline RL",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "4;3;2;3",
        "correctness": "4;3;2;4",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "3;3;1;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7071067811865475,
        "corr_rating_correctness": -0.30151134457776363,
        "project": "",
        "github": ""
    },
    {
        "id": "8CEJlHbKoP4",
        "title": "Learning a metacognition for object detection",
        "track": "main",
        "status": "Reject",
        "keywords": "metacognition;object detection;unsupervised learning",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "3;4;3;4",
        "correctness": "3;2;3;2",
        "technical_novelty": "2;3;2;2",
        "empirical_novelty": "0;3;2;4",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.6882472016116854,
        "corr_rating_correctness": -0.6882472016116854,
        "project": "",
        "github": ""
    },
    {
        "id": "8Dhw-NmmwT3",
        "title": "Lifting Imbalanced Regression with Self-Supervised Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Imbalanced Regression;Self-Supervised Learning;Long-Tailed Learning",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "3;4;5;3",
        "correctness": "4;3;3;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;2;4;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.30151134457776363,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "8FhxBtXSl0",
        "title": "CKConv: Continuous Kernel Convolution For Sequential Data",
        "track": "main",
        "status": "Poster",
        "keywords": "Convolutional Networks;Continuous kernel Convolutions;Continuous Convolutional Kernels;Implicit Neural Representations;Sequential Data.",
        "author": "",
        "aff": "Vrije Universiteit Amsterdam; University of Amsterdam",
        "rating": "6;8;8;8",
        "confidence": "3;3;4;4",
        "correctness": "4;4;4;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.5,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "8H5bpVwvt5",
        "title": "AdaRL: What, Where, and How to Adapt in Transfer Reinforcement Learning",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Transfer RL;Graphical models;Efficient adaptation",
        "author": "",
        "aff": "University of Amsterdam & MIT-IBM Watson AI Lab; University of Cambridge & Max Planck Institute for Intelligent Systems; Carnegie Mellon University; City University of Hong Kong; Carnegie Mellon University & Mohamed bin Zayed University of Artificial Intelligence",
        "rating": "8;8;8;8",
        "confidence": "4;4;4;3",
        "correctness": "4;4;3;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/Adaptive-RL/AdaRL-code"
    },
    {
        "id": "8IXBbFjkMat",
        "title": "Bag-of-Vectors Autoencoders for Unsupervised Conditional Text Generation",
        "track": "main",
        "status": "Reject",
        "keywords": "autoencoders;latent space learning;variable-size;natural language processing",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "3;4;4;3",
        "correctness": "4;3;3;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "8KD0wdSF2NE",
        "title": "A composable autoencoder-based algorithm for accelerating numerical simulations",
        "track": "main",
        "status": "Reject",
        "keywords": "numerical simulations;machine learning",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5",
        "confidence": "5;2;3;3",
        "correctness": "2;3;2;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "0;3;0;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "8MN_GH4Ckp4",
        "title": "Model Compression via Symmetries of the Parameter Space",
        "track": "main",
        "status": "Reject",
        "keywords": "symmetry;orthogonal group;quiver representation;representation theory;model compression;parameter optimization;projected gradient descent",
        "author": "",
        "aff": "",
        "rating": "3;3;5",
        "confidence": "5;3;4",
        "correctness": "3;4;3",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "8Py-W8lSUgy",
        "title": "Relational Multi-Task Learning: Modeling Relations between Data and Tasks",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Graph Neural Networks;Relational Representation Learning;Multi-task Learning;Meta Learning",
        "author": "",
        "aff": "Department of Computer Science, Stanford University",
        "rating": "5;6;6;8",
        "confidence": "4;4;4;4",
        "correctness": "3;4;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;4;3;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.6622661785325219,
        "project": "",
        "github": ""
    },
    {
        "id": "8QE3pwEVc8P",
        "title": "Zero-Cost Operation Scoring in Differentiable Architecture Search",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;6;8",
        "confidence": "4;4;3;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/avail-upon-acceptance"
    },
    {
        "id": "8TnLOVrNRNp",
        "title": "Visual TransforMatcher: Efficient Match-to-Match Attention for Visual Correspondence",
        "track": "main",
        "status": "Withdraw",
        "keywords": "image matching;semantic correspondence;visual transformer;4D attention",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "2;4;3;4",
        "correctness": "3;3;2;2",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5222329678670935,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "8WRYT8QAcj",
        "title": "COMBO: Conservative Offline Model-Based Policy Optimization",
        "track": "main",
        "status": "Withdraw",
        "keywords": "offline reinforcement learning;model-based reinforcement learning",
        "author": "",
        "aff": "",
        "rating": "",
        "confidence": "",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "8WawVDdKqlL",
        "title": "Label Encoding for Regression Networks",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Regression;Label encoding;Output codes",
        "author": "",
        "aff": "Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, BC, Canada",
        "rating": "6;8;8;8",
        "confidence": "3;3;4;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/ubc-aamodt-group/BEL_regression"
    },
    {
        "id": "8Wdj6IJsSyJ",
        "title": "Fully differentiable model discovery",
        "track": "main",
        "status": "Reject",
        "keywords": "Model discovery;Sparse Bayesian Learning;Normalizing Flows",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5",
        "confidence": "3;3;3;3",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;3;2;2",
        "empirical_novelty": "3;2;3;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "8XM-AXMnAk_",
        "title": "Deep Active Learning by Leveraging Training Dynamics",
        "track": "main",
        "status": "Reject",
        "keywords": "deep learning;active learning;neural tangent kernel",
        "author": "",
        "aff": "",
        "rating": "3;6;6;6",
        "confidence": "3;3;3;3",
        "correctness": "3;4;3;4",
        "technical_novelty": "4;3;3;3",
        "empirical_novelty": "1;2;2;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "8Z7-NG11HY",
        "title": "Constrained Density Matching and Modeling for Effective Contextualized Alignment",
        "track": "main",
        "status": "Reject",
        "keywords": "Cross-lingual Alignment;Word Embeddings;NLP",
        "author": "",
        "aff": "",
        "rating": "3;5;6;8",
        "confidence": "4;4;3;2",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;3;4",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9198662110077999,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "8apIRxHxZC",
        "title": "Learning to Actively Learn: A Robust Approach",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5",
        "confidence": "3;2;3",
        "correctness": "3;3;3",
        "technical_novelty": "2;4;3",
        "empirical_novelty": "2;4;2",
        "presentation": "",
        "rating_avg": 4.333333333333333,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.49999999999999983,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "8c50f-DoWAu",
        "title": "Diffusion-Based Voice Conversion with Fast Maximum Likelihood Sampling Scheme",
        "track": "main",
        "status": "Oral",
        "keywords": "speech;voice conversion;diffusion models;stochastic differential equations",
        "author": "",
        "aff": "Huawei Noah\u2019s Ark Lab, Moscow, Russia",
        "rating": "8;8;10",
        "confidence": "4;4;3",
        "correctness": "4;3;4",
        "technical_novelty": "4;3;4",
        "empirical_novelty": "3;3;4",
        "presentation": "",
        "rating_avg": 8.666666666666666,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 3.6666666666666665,
        "empirical_novelty_avg": 3.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9999999999999997,
        "corr_rating_correctness": 0.4999999999999999,
        "project": "",
        "github": ""
    },
    {
        "id": "8dF_13D2SmD",
        "title": "RoDesigner: Variation-Aware Optimization for Robust Analog Design with Multi-Task RL",
        "track": "main",
        "status": "Withdraw",
        "keywords": "multi-task reinforcement learning;circuit automation",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;3;3;2",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;2;1;3",
        "empirical_novelty": "1;2;3;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9733285267845754,
        "corr_rating_correctness": 0.13245323570650439,
        "project": "",
        "github": ""
    },
    {
        "id": "8e2vrVvvaeQ",
        "title": "Indiscriminate Poisoning Attacks Are Shortcuts",
        "track": "main",
        "status": "Reject",
        "keywords": "Data Security;Data Poisoning;Shortcuts",
        "author": "",
        "aff": "",
        "rating": "3;5;8;8",
        "confidence": "5;4;5;5",
        "correctness": "4;3;3;3",
        "technical_novelty": "1;2;4;3",
        "empirical_novelty": "2;2;4;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.2721655269759087,
        "corr_rating_correctness": -0.8164965809277261,
        "project": "",
        "github": ""
    },
    {
        "id": "8eb12UQYxrG",
        "title": "The Role of Pretrained Representations for the OOD Generalization of RL Agents",
        "track": "main",
        "status": "Poster",
        "keywords": "representations;out-of-distribution;generalization;deep learning;reinforcement learning",
        "author": "",
        "aff": "Amazon Lablets; KTH Stockholm; Technical University of Denmark; Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany; Google Brain",
        "rating": "3;5;6;8",
        "confidence": "4;4;4;3",
        "correctness": "3;4;4;4",
        "technical_novelty": "1;2;2;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8006407690254357,
        "corr_rating_correctness": 0.8006407690254357,
        "project": "",
        "github": ""
    },
    {
        "id": "8f95ajHrIFc",
        "title": "On Reward Maximization and Distribution Matching for Fine-Tuning Language Models",
        "track": "main",
        "status": "Reject",
        "keywords": "Reinforcement Learning;Language Models;Reward Maximization;Distribution Matching;Energy Based Models;Controlled Text Generation",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "4;4;3;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "8gX3bY78aCb",
        "title": "Molecular Graph Representation Learning via Heterogeneous Motif Graph Construction",
        "track": "main",
        "status": "Reject",
        "keywords": "Molecular Graph Representation;Graph Neural Networks;Heterogeneous",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;4;4;5",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.6622661785325219,
        "corr_rating_correctness": 0.13245323570650439,
        "project": "",
        "github": ""
    },
    {
        "id": "8hWs60AZcWk",
        "title": "Discrete Representations Strengthen Vision Transformer Robustness",
        "track": "main",
        "status": "Poster",
        "keywords": "vision transformer;robustness;image recognition",
        "author": "",
        "aff": "School of Interactive Computing, Georgia Insitute of Technology; Computer Science, Columbia University; Google Research",
        "rating": "3;5;8;8",
        "confidence": "4;4;4;3",
        "correctness": "2;3;3;2",
        "technical_novelty": "2;3;4;3",
        "empirical_novelty": "2;2;4;0",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5443310539518174,
        "corr_rating_correctness": 0.23570226039551587,
        "project": "",
        "github": ""
    },
    {
        "id": "8in_5gN9I0",
        "title": "Triangle and Four Cycle Counting with Predictions in Graph Streams",
        "track": "main",
        "status": "Poster",
        "keywords": "learning augmented;streaming;graph streaming;data driven;cycle counting;triangle counting",
        "author": "",
        "aff": "Computer Science and Arti\ufb01cial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA 02139, USA; Computer Science Department, Carnegie Mellon University, Pittsburgh, PA 15213, USA; Microsoft Research, Redmond, WA 98052, USA; Massachusetts Institute of Technology and Boston University, Cambridge, MA 02139, USA",
        "rating": "6;6;8",
        "confidence": "4;3;4",
        "correctness": "4;3;4",
        "technical_novelty": "4;3;3",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 3.3333333333333335,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.49999999999999983,
        "corr_rating_correctness": 0.49999999999999983,
        "project": "",
        "github": ""
    },
    {
        "id": "8kVP8m93VqN",
        "title": "Task-oriented Dialogue System for Automatic Disease Diagnosis via Hierarchical Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Dialogue System;Automatic Disease Diagnosis;Hierarchical Reinforcement Learning",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "3;4;4;3",
        "correctness": "3;1;4;3",
        "technical_novelty": "1;1;2;3",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.13245323570650439,
        "project": "",
        "github": ""
    },
    {
        "id": "8kpSWDgzsh0",
        "title": "Network Learning in Quadratic Games from Fictitious Plays",
        "track": "main",
        "status": "Reject",
        "keywords": "network learning;game theory",
        "author": "",
        "aff": "",
        "rating": "3;3;6",
        "confidence": "4;4;2",
        "correctness": "2;2;4",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "2;2;0",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 1.3333333333333333,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "8la28hZOwug",
        "title": "Prototypical Contrastive Predictive Coding",
        "track": "main",
        "status": "Poster",
        "keywords": "Knowledge distillation;contrastive learning;self-supervised learning",
        "author": "",
        "aff": "Agency for Defense Development",
        "rating": "6;6;6;8",
        "confidence": "3;3;4;3",
        "correctness": "3;4;4;4",
        "technical_novelty": "3;3;2;3",
        "empirical_novelty": "3;3;2;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "8p5qvzrmMj",
        "title": "Confidence Score Weighting Adaptation for Source-Free Unsupervised Domain Adaptation",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Unsupervised Domain Adaptation;Source-free Unsupervised Domain Adaptation;Confidence score",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;4;5",
        "correctness": "4;2;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;0;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "8qQ48aMXR_g",
        "title": "On Locality in Graph Learning via Graph Neural Network",
        "track": "main",
        "status": "Reject",
        "keywords": "Graph Neural Network;Structural Behavior;Learning Process",
        "author": "",
        "aff": "",
        "rating": "1;3;3;6",
        "confidence": "4;4;4;4",
        "correctness": "3;2;2;3",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 3.25,
        "confidence_avg": 4.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.14002800840280097,
        "project": "",
        "github": ""
    },
    {
        "id": "8qWazUd8Jm",
        "title": "How Faithful is your Synthetic Data? Sample-level Metrics for Evaluating and Auditing Generative Models",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;6;6;8",
        "confidence": "5;3;4;4",
        "correctness": "4;3;4;4",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "2;3;2;2",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5940885257860046,
        "corr_rating_correctness": -0.08084520834544431,
        "project": "",
        "github": ""
    },
    {
        "id": "8r1wpu__y3S",
        "title": "Efficient Regularization for Adversarially Robustness Deep ReLU Networks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "adversarial robustness;regularization",
        "author": "",
        "aff": "",
        "rating": "3;3;6;6",
        "confidence": "4;3;3;2",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;2;4;3",
        "empirical_novelty": "2;3;0;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7071067811865476,
        "corr_rating_correctness": 0.5773502691896258,
        "project": "",
        "github": ""
    },
    {
        "id": "8rCMq0yJMG",
        "title": "Source-Target Unified Knowledge Distillation for Memory-Efficient Federated Domain Adaptation on Edge Devices",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;6;8",
        "confidence": "4;3;3;4",
        "correctness": "3;4;4;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.8006407690254357,
        "project": "",
        "github": ""
    },
    {
        "id": "8rR8bIZnzMA",
        "title": "Dynamic Graph Representation Learning via Graph Transformer Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "dynamic graphs;graph neural networks;graph representation learning;transformers;graph transformers",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;4;4;3",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6622661785325219,
        "corr_rating_correctness": 0.6622661785325219,
        "project": "",
        "github": ""
    },
    {
        "id": "8rpv8g3zfF",
        "title": "Federated Learning with GAN-based Data Synthesis for Non-IID Clients",
        "track": "main",
        "status": "Reject",
        "keywords": "federated learning;non-IID;generative model;data augmentation",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;4;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "8svLJL54sj8",
        "title": "Automatic prior selection for meta Bayesian optimization with a case study on tuning deep neural network optimizers",
        "track": "main",
        "status": "Reject",
        "keywords": "Bayesian optimization;Gaussian process;hyperparameter tuning;meta learning;transfer learning;multi task",
        "author": "",
        "aff": "",
        "rating": "3;3;5;8",
        "confidence": "4;4;3;4",
        "correctness": "3;2;4;3",
        "technical_novelty": "2;1;3;4",
        "empirical_novelty": "1;1;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.07053456158585983,
        "corr_rating_correctness": 0.34554737023254406,
        "project": "",
        "github": ""
    },
    {
        "id": "8uqOMUHgW4M",
        "title": "Learning shared neural manifolds from multi-subject FMRI data",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6;8",
        "confidence": "5;3;4;5;4",
        "correctness": "4;3;2;4;3",
        "technical_novelty": "1;3;3;3;3",
        "empirical_novelty": "1;2;3;3;3",
        "presentation": "",
        "rating_avg": 5.6,
        "confidence_avg": 4.2,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.26318067798390754,
        "corr_rating_correctness": -0.4276686017238498,
        "project": "",
        "github": ""
    },
    {
        "id": "8uz0EWPQIMu",
        "title": "On the Pitfalls of Analyzing Individual Neurons in Language Models",
        "track": "main",
        "status": "Poster",
        "keywords": "NLP;interpretability;multilingual;individual neurons",
        "author": "",
        "aff": "Technion \u2013 Israel Institute of Technology",
        "rating": "6;8;8;8",
        "confidence": "3;4;3;3",
        "correctness": "4;3;3;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": "https://github.com/technion-cs-nlp/Individual-Neurons-Pitfalls"
    },
    {
        "id": "8wI4UUN5RxC",
        "title": "Variational Inference via Resolution of Singularities",
        "track": "main",
        "status": "Reject",
        "keywords": "singular learning theory;Bayesian neural networks;variational inference;normalizing flow",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5",
        "confidence": "4;3;2;2",
        "correctness": "3;3;2;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "9-Rfew334N",
        "title": "Givens Coordinate Descent Methods for Rotation Matrix Learning in Trainable Embedding Indexes",
        "track": "main",
        "status": "Poster",
        "keywords": "Search index;Product quantization;Block coordinate descent",
        "author": "",
        "aff": "JD.com, Mountain View, CA, United States & Beijing, China",
        "rating": "6;6;6;6",
        "confidence": "4;3;4;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "3;3;3;2",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "91muTwt1_t5",
        "title": "Knowledge Guided Geometric Editing for Unsupervised Drug Design",
        "track": "main",
        "status": "Reject",
        "keywords": "drug discovery;3D molecular generation;monte carlo sampling",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;4;4;3",
        "correctness": "2;3;3;4",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6622661785325219,
        "corr_rating_correctness": 0.9733285267845754,
        "project": "",
        "github": ""
    },
    {
        "id": "92awwjGxIZI",
        "title": "Self-GenomeNet: Self-supervised Learning with Reverse-Complement Context Prediction for Nucleotide-level Genomics Data",
        "track": "main",
        "status": "Reject",
        "keywords": "Genome Sequence Analysis;Self-supervised Learning;Representation Learning;Application in Computational Biology",
        "author": "",
        "aff": "",
        "rating": "5;5;6;8",
        "confidence": "4;4;4;4",
        "correctness": "4;2;3;3",
        "technical_novelty": "2;2;2;4",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "92tYQiil17",
        "title": "Learning Transferable Reward for Query Object Localization with Policy Adaptation",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "Department of Computer Science, Rutgers University\u00a7; NEC Labs America\u2020, Department of Computer Science, Rutgers University\u00a7; NEC Labs America\u2020",
        "rating": "6;6;8;8",
        "confidence": "4;4;2;3",
        "correctness": "3;4;4;3",
        "technical_novelty": "3;3;2;3",
        "empirical_novelty": "4;3;3;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9045340337332909,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/litingfeng/Localization-by-OrdEmbed"
    },
    {
        "id": "93SVBUB1r5C",
        "title": "Learning with convolution and pooling operations in kernel methods",
        "track": "main",
        "status": "Reject",
        "keywords": "convolutional kernels;inductive bias;average pooling;downsampling;kernel ridge regression;generalization error;neural tangent kernel",
        "author": "",
        "aff": "",
        "rating": "5;5;6",
        "confidence": "4;3;3",
        "correctness": "3;4;4",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4999999999999999,
        "corr_rating_correctness": 0.4999999999999999,
        "project": "",
        "github": ""
    },
    {
        "id": "97WDkHzofx",
        "title": "Interventional Black-Box Explanations",
        "track": "main",
        "status": "Reject",
        "keywords": "Causal Inference;Interventions;black-Box Models;Explanations;Deep Neural Networks",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "4;3;3;3",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "97r5Y5DrJTo",
        "title": "The Effect of diversity in Meta-Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Meta-Learning;Few-shot learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5",
        "confidence": "5;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "3;2;3",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8660254037844387,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "97ru13Fdmbt",
        "title": "Monotonicity as a requirement and as a regularizer: efficient methods and applications",
        "track": "main",
        "status": "Reject",
        "keywords": "Monotonic neural networks;Gradient penalties;Structural risk minimization",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "4;3;4;3",
        "correctness": "3;2;3;3",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;1;2;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "99v8tgOhZH",
        "title": "Multi-objective optimization for Hardware-aware Neural Architecture Search",
        "track": "main",
        "status": "Withdraw",
        "keywords": "multi-objective optimization;neural architecture search;evolutionary algorithm;hardware-aware;accuracy predictor;latency estimator;FPGA",
        "author": "",
        "aff": "",
        "rating": "1;1;1;3",
        "confidence": "4;5;5;4",
        "correctness": "1;2;2;3",
        "technical_novelty": "1;1;1;1",
        "empirical_novelty": "1;1;1;1",
        "presentation": "",
        "rating_avg": 1.5,
        "confidence_avg": 4.5,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 1.0,
        "empirical_novelty_avg": 1.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": "https://anonymous.4open.science/r/multi-objective-optimization-0E27/README.md"
    },
    {
        "id": "9AuUv3LKWe2",
        "title": "MGA-VQA: Multi-Granularity Alignment for Visual Question Answering",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Computer Vision;Visual Question Answering",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;4;4",
        "correctness": "3;4;3;3",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;2;2;0",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "9BIN1yr5Gp",
        "title": "Parallel Deep Neural Networks Have Zero Duality Gap",
        "track": "main",
        "status": "Reject",
        "keywords": "Deep neural networks;convex duality;convex optimization",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "4;4;4;3",
        "correctness": "2;2;3;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "1;0;0;0",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 0.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.8703882797784891,
        "project": "",
        "github": ""
    },
    {
        "id": "9Cwxjd6nRh",
        "title": "High Fidelity Visualization of What Your Self-Supervised Representation Knows About",
        "track": "main",
        "status": "Reject",
        "keywords": "self-supervised learning;visualization;diffusion model;conditional generative model;representation",
        "author": "",
        "aff": "",
        "rating": "5;5;6;8",
        "confidence": "4;4;4;3",
        "correctness": "4;3;3;4",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "3;2;2;4",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9428090415820632,
        "corr_rating_correctness": 0.40824829046386296,
        "project": "",
        "github": ""
    },
    {
        "id": "9FfAEgUYGON",
        "title": "Mismatched No More: Joint Model-Policy Optimization for Model-Based RL",
        "track": "main",
        "status": "Reject",
        "keywords": "reinforcement learning;model-based RL;joint optimization",
        "author": "",
        "aff": "",
        "rating": "3;6;6;6",
        "confidence": "4;4;3;4",
        "correctness": "2;4;4;3",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.8703882797784892,
        "project": "",
        "github": ""
    },
    {
        "id": "9HXfisrWl1",
        "title": "DeepDebug: Fixing Python Bugs Using Stack Traces, Backtranslation, and Code Skeletons",
        "track": "main",
        "status": "Reject",
        "keywords": "program repair;bugpatching;backtranslation;transformers",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;3;3;4",
        "correctness": "2;3;4;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;3;2;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "9HmtMeHmyR4",
        "title": "Self-Supervision is All You Need for Solving Rubik's Cube",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Rubik's Cube;self-supervised learning;combinatorial search;pathfinding;planning",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "5;4;4;5",
        "correctness": "2;2;3;3",
        "technical_novelty": "2;3;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 4.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "9Hrka5PA7LW",
        "title": "Representational Continuity for Unsupervised Continual Learning",
        "track": "main",
        "status": "Oral",
        "keywords": "Continual Learning;Representational Learning;Deep Learning",
        "author": "",
        "aff": "New York University; KAIST; Institute for AI Industry Research (AIR), Tsinghua University; KAIST, AITRICS",
        "rating": "8;8;8;8",
        "confidence": "3;4;4;4",
        "correctness": "3;4;4;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;4;3",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "https://project_website.com (if available)",
        "github": "https://github.com/author_or_organization/repo_name (if available)"
    },
    {
        "id": "9KVfvieKho6",
        "title": "LPMARL: Linear Programming based Implicit Task Assigment for Hiearchical Multi-Agent Reinforcement Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Multi-Agent Reinforcement Learning;Hierarchical Multi-Agent Reinforcement Learning;Implicit Deep Learning;Differentiable Optimization",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5;5",
        "confidence": "5;2;5;3;3",
        "correctness": "3;3;3;4;3",
        "technical_novelty": "2;3;2;3;2",
        "empirical_novelty": "2;2;2;2;2",
        "presentation": "",
        "rating_avg": 3.8,
        "confidence_avg": 3.6,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4082482904638631,
        "corr_rating_correctness": 0.6123724356957946,
        "project": "",
        "github": ""
    },
    {
        "id": "9L1BsI4wP1H",
        "title": "Adversarially Robust Conformal Prediction",
        "track": "main",
        "status": "Poster",
        "keywords": "Conformal Prediction;Adversarial Robustness;Randomized Smoothing;Uncertainty Estimation;Calibration",
        "author": "",
        "aff": "Department of Electrical and Computer Engineering, Technion - Israel Institute of Technology; Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology",
        "rating": "5;6;8;8",
        "confidence": "4;4;3;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5555555555555555,
        "corr_rating_correctness": 0.9622504486493761,
        "project": "",
        "github": ""
    },
    {
        "id": "9LJkfH5rtc",
        "title": "Patchwise Sparse Dictionary Learning from pre-trained Neural Network Activation Maps for Anomaly Detection in Images",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "5;5;5;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "1;2;2;2",
        "empirical_novelty": "1;3;2;2",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6622661785325219,
        "corr_rating_correctness": 0.13245323570650439,
        "project": "",
        "github": ""
    },
    {
        "id": "9NVd-DMtThY",
        "title": "Distributionally Robust Fair Principal Components via Geodesic Descents",
        "track": "main",
        "status": "Poster",
        "keywords": "fair principal component analysis;distributionally robust optimization;manifold optimization",
        "author": "",
        "aff": "VinAI Research, Vietnam; Hong Kong Polytechnic University",
        "rating": "5;6;6;6",
        "confidence": "5;4;3;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.816496580927726,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "9Nk6AJkVYB",
        "title": "Audio Lottery: Speech Recognition Made Ultra-Lightweight, Noise-Robust, and Transferable",
        "track": "main",
        "status": "Poster",
        "keywords": "Speech Recognition;Lottery Ticket Hypothesis",
        "author": "",
        "aff": "University of Texas at Austin; Texas A&M University",
        "rating": "5;6;6;6",
        "confidence": "4;4;4;3",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "3;3;3;2",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": "https://github.com/VITA-Group/Audio-Lottery"
    },
    {
        "id": "9RUHPlladgh",
        "title": "Visual Representation Learning Does Not Generalize Strongly Within the Same Domain",
        "track": "main",
        "status": "Poster",
        "keywords": "Generalization;Composition;Out of distribution;Disentanglement",
        "author": "",
        "aff": "Amazon Web Services; Max Planck Institute for Intelligent Systems, T\u00fcbingen; University of T\u00fcbingen",
        "rating": "8;8;8;8",
        "confidence": "5;3;4;3",
        "correctness": "4;4;4;2",
        "technical_novelty": "3;4;2;2",
        "empirical_novelty": "3;3;3;2",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "9SDQB3b68K",
        "title": "DARA: Dynamics-Aware Reward Augmentation in Offline Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "Westlake University",
        "rating": "5;6;6;8",
        "confidence": "5;3;3;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;4;3",
        "empirical_novelty": "2;2;3;4",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.20751433915982243,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "9Sf8fbue1br",
        "title": "Improving Mini-batch Optimal Transport via Partial Transportation",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Deep Domain Adaptation;Deep Generative Models;Color Transfer;Optimal Transport",
        "author": "",
        "aff": "",
        "rating": "3;3;6",
        "confidence": "3;4;2",
        "correctness": "2;2;4",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8660254037844387,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "9TdCcMlmsLm",
        "title": "Text Generation with Efficient (Soft) $Q$-Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "text generation;reinforcement learning for text generation",
        "author": "",
        "aff": "",
        "rating": "5;5;6",
        "confidence": "4;3;4",
        "correctness": "3;3;4",
        "technical_novelty": "2;1;3",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.4999999999999999,
        "corr_rating_correctness": 0.9999999999999997,
        "project": "",
        "github": ""
    },
    {
        "id": "9Vimsa_gGG5",
        "title": "Initializing ReLU networks in an expressive subspace of weights",
        "track": "main",
        "status": "Reject",
        "keywords": "Signal propagation;deep ReLU networks;mean-field theory;improved initialization",
        "author": "",
        "aff": "",
        "rating": "1;3;5;5",
        "confidence": "3;3;3;4",
        "correctness": "3;2;3;4",
        "technical_novelty": "1;2;2;3",
        "empirical_novelty": "1;2;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5222329678670935,
        "corr_rating_correctness": 0.42640143271122083,
        "project": "",
        "github": ""
    },
    {
        "id": "9Vrb9D0WI4",
        "title": "Multitask Prompted Training Enables Zero-Shot Task Generalization",
        "track": "main",
        "status": "Spotlight",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;6;8;8",
        "confidence": "5;4;4;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "1;3;3;2",
        "empirical_novelty": "2;3;4;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9169493006161777,
        "corr_rating_correctness": 0.49374193110101877,
        "project": "",
        "github": ""
    },
    {
        "id": "9W2KnHqm_xN",
        "title": "Successive POI Recommendation via Brain-inspired Spatiotemporal Aware Representation",
        "track": "main",
        "status": "Reject",
        "keywords": "Neuroscience;spatiotemporal aware modeling;successive POI recommendation",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "3;4;5;4",
        "correctness": "3;3;2;3",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "9WJ-fT_92Hp",
        "title": "Efficient Reinforcement Learning Experimentation in PyTorch",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Deep Reinforcement Learning;Python library",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5;6",
        "confidence": "4;4;4;4;4",
        "correctness": "3;2;3;3;3",
        "technical_novelty": "2;2;2;2;3",
        "empirical_novelty": "2;2;2;2;2",
        "presentation": "",
        "rating_avg": 4.4,
        "confidence_avg": 4.0,
        "correctness_avg": 2.8,
        "technical_novelty_avg": 2.2,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5833333333333335,
        "project": "",
        "github": ""
    },
    {
        "id": "9XhPLAjjRB",
        "title": "SGD Can Converge to Local Maxima",
        "track": "main",
        "status": "Spotlight",
        "keywords": "stochastic gradient descent;saddle points;convergence;amsgrad;deep learning",
        "author": "",
        "aff": "ENS, Universit\u00e9 PSL, CNRS, Sorbonne Universit\u00e9, Universit\u00e9 de Paris; University of California, Berkeley; The University of Tokyo",
        "rating": "6;6;8;8;8",
        "confidence": "4;5;3;4;4",
        "correctness": "4;3;3;3;4",
        "technical_novelty": "2;4;4;3;4",
        "empirical_novelty": "2;2;2;2;4",
        "presentation": "",
        "rating_avg": 7.2,
        "confidence_avg": 4.0,
        "correctness_avg": 3.4,
        "technical_novelty_avg": 3.4,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6454972243679028,
        "corr_rating_correctness": -0.16666666666666663,
        "project": "",
        "github": ""
    },
    {
        "id": "9ZPegFuFTFv",
        "title": "miniF2F: a cross-system benchmark for formal Olympiad-level mathematics",
        "track": "main",
        "status": "Poster",
        "keywords": "Neural theorem proving;Benchmark dataset",
        "author": "",
        "aff": "OpenAI, University of Pittsburgh; OpenAI; \u00b4Ecole Polytechnique",
        "rating": "5;6;8;8",
        "confidence": "3;3;4;5",
        "correctness": "4;4;4;4",
        "technical_novelty": "2;1;3;4",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 3.75,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8703882797784892,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "9dn7CjyTFoS",
        "title": "One Thing to Fool them All: Generating Interpretable, Universal, and Physically-Realizable Adversarial Features",
        "track": "main",
        "status": "Reject",
        "keywords": "adversaries;interpretablity;generative modeling",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "5;4;3;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;3;2;4",
        "empirical_novelty": "1;3;2;2",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6488856845230502,
        "corr_rating_correctness": 0.9271726499455306,
        "project": "",
        "github": ""
    },
    {
        "id": "9gz8qakpyhG",
        "title": "Test-time Batch Statistics Calibration for Covariate Shift",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "4;4;4;5",
        "correctness": "3;3;2;3",
        "technical_novelty": "3;2;2;3",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "9jInD9JjicF",
        "title": "PoNet: Pooling Network for Efficient Token Mixing in Long Sequences",
        "track": "main",
        "status": "Poster",
        "keywords": "Transformer;Efficient Transformers;Token Mixing;Pooling;Linear;Long Range Arena;Transfer Learning;BERT;GLUE",
        "author": "",
        "aff": "National Engineering Laboratory for Speech and Language Information Processing, University of Science and Technology of China; Speech Lab, Alibaba Group",
        "rating": "5;5;6;8",
        "confidence": "4;5;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4714045207910316,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/lxchtan/PoNet"
    },
    {
        "id": "9jsZiUgkCZP",
        "title": "Unified Visual Transformer Compression",
        "track": "main",
        "status": "Poster",
        "keywords": "Vision Transformer;Model Compression;Pruning;Layer Skipping;Distillation",
        "author": "",
        "aff": "University of Texas at Austin; Texas A&M University; Kwai Inc.",
        "rating": "5;6;8",
        "confidence": "5;4;4",
        "correctness": "2;4;4",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "2;4;4",
        "presentation": "",
        "rating_avg": 6.333333333333333,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7559289460184544,
        "corr_rating_correctness": 0.7559289460184546,
        "project": "",
        "github": "https://github.com/VITA-Group/UVC"
    },
    {
        "id": "9kBDWEmA6i",
        "title": "When high-performing models behave poorly in practice: periodic sampling can help",
        "track": "main",
        "status": "Reject",
        "keywords": "Periodic sampling;deep learning;computer vision;mammography",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5;6",
        "confidence": "4;4;4;4;4",
        "correctness": "3;4;4;2;4",
        "technical_novelty": "1;2;3;2;3",
        "empirical_novelty": "2;2;2;2;3",
        "presentation": "",
        "rating_avg": 4.8,
        "confidence_avg": 4.0,
        "correctness_avg": 3.4,
        "technical_novelty_avg": 2.2,
        "empirical_novelty_avg": 2.2,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.3572172541558801,
        "project": "",
        "github": ""
    },
    {
        "id": "9kpuB2bgnim",
        "title": "Huber Additive Models for Non-stationary Time Series Analysis",
        "track": "main",
        "status": "Poster",
        "keywords": "Sparse additive models;variable selection;Huber;non-stationary;robust forecasting",
        "author": "",
        "aff": "College of Informatics, Huazhong Agricultural University, China; College of Science, Huazhong Agricultural University, China; JD Explore Academy, JD.com Inc, China; Department of Computer Science, University of Illinois at Urbana-Champaign, USA",
        "rating": "6;6;6;8",
        "confidence": "4;2;3;2",
        "correctness": "3;3;3;3",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "2;0;2;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 2.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5222329678670935,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/xianruizhong/SpHAM"
    },
    {
        "id": "9mls_1dBQS",
        "title": "Model-based Reinforcement Learning with Ensembled Model-value Expansion",
        "track": "main",
        "status": "Withdraw",
        "keywords": "MBRL;Model-based Reinforcement Learning;Ensemble;Dynamics;Neural Network;Reinforcement Learning",
        "author": "",
        "aff": "",
        "rating": "1;1;1;3",
        "confidence": "5;4;4;4",
        "correctness": "1;1;4;3",
        "technical_novelty": "1;2;1;1",
        "empirical_novelty": "1;2;1;2",
        "presentation": "",
        "rating_avg": 1.5,
        "confidence_avg": 4.25,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 1.25,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "9n9c8sf0xm",
        "title": "Plant 'n' Seek: Can You Find the Winning Ticket?",
        "track": "main",
        "status": "Poster",
        "keywords": "lottery tickets;ground truth;planting;LTH",
        "author": "",
        "aff": "CISPA Helmholtz Center for Information Security; Max Planck Institute for Informatics",
        "rating": "5;5;6;6;6",
        "confidence": "3;3;3;3;4",
        "correctness": "3;3;4;4;4",
        "technical_novelty": "2;2;3;2;3",
        "empirical_novelty": "2;2;4;2;3",
        "presentation": "",
        "rating_avg": 5.6,
        "confidence_avg": 3.2,
        "correctness_avg": 3.6,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 2.6,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.408248290463863,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": "www.github.com/RelationalML/PlantNSeek"
    },
    {
        "id": "9otKVlgrpZG",
        "title": "Multi-Task Processes",
        "track": "main",
        "status": "Poster",
        "keywords": "stochastic processes;neural processes;multi-task learning;incomplete data",
        "author": "",
        "aff": "School of Computing, KAIST",
        "rating": "5;6;6;8",
        "confidence": "5;4;4;3",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "3;3;2;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9733285267845754,
        "corr_rating_correctness": 0.9271726499455306,
        "project": "",
        "github": "https://github.com/GitGyun/multi_task_neural_processes"
    },
    {
        "id": "9pEJSVfDbba",
        "title": "Embedded-model flows: Combining the inductive biases of model-free deep learning and explicit probabilistic modeling",
        "track": "main",
        "status": "Poster",
        "keywords": "Normalizing Flows;Probabilistic model;Probabilistic programming;Generative modeling;Variational Inference",
        "author": "",
        "aff": "OnePlanet Research Center, imec-the Netherlands, Wageningen, Netherlands; Department of Artificial Intelligence, Donders Institute for Brain, Cognition and Behaviour, Radboud University, Nijmegen, Netherlands; Google Research, San Francisco, CA, USA",
        "rating": "6;6;8;8",
        "confidence": "4;3;4;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "9poQ2m0R--",
        "title": "Green CWS: Extreme Distillation and Efficient Decode Method Towards Industrial Application",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Chinese Word Segmentation;Knowledge Distillation;Decoding",
        "author": "",
        "aff": "Under double-blind review",
        "rating": "3;3;3;3",
        "confidence": "4;4;3;3",
        "correctness": "3;2;3;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "3;2;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "9q3g_5gQbbA",
        "title": "Towards Understanding Data Values: Empirical Results on Synthetic Data",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;3;6",
        "confidence": "4;5;4;3",
        "correctness": "2;3;4;4",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "3;3;2;3",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.816496580927726,
        "corr_rating_correctness": 0.5222329678670935,
        "project": "",
        "github": ""
    },
    {
        "id": "9qKAGxS1Tq2",
        "title": "From SCAN to Real Data: Systematic Generalization via Meaningful Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "systematic generalization;meaningful learning;inductive learning;deductive learning;data augmentation",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "5;4;4;2",
        "correctness": "4;3;3;3",
        "technical_novelty": "2;1;2;2",
        "empirical_novelty": "1;2;3;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6622661785325219,
        "corr_rating_correctness": -1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "9r4_7GxTLnS",
        "title": "PolyViT: Co-training Vision Transformers on Images, Videos and Audio",
        "track": "main",
        "status": "Withdraw",
        "keywords": "transformers;multi-task learning;image classification;video;audio;co-training",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;5;4;4",
        "correctness": "2;3;2;3",
        "technical_novelty": "2;1;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "9rKTy4oZAQt",
        "title": "A Risk-Sensitive Policy Gradient Method",
        "track": "main",
        "status": "Reject",
        "keywords": "deep reinforcement learning;policy gradient;risk-sensitive;ai safety",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "4;4;2;3",
        "correctness": "3;2;3;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9045340337332909,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "9rr7pFeIEuq",
        "title": "A general sample complexity analysis of vanilla policy gradient",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Reinforcement learning;policy optimization;policy gradient;sample complexity",
        "author": "",
        "aff": "",
        "rating": "",
        "confidence": "",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "9u5E8AFudRx",
        "title": "Help Me Explore: Minimal Social Interventions for Graph-Based Autotelic Agents",
        "track": "main",
        "status": "Reject",
        "keywords": "Deep reinforcement learning;intrinsic motivations;autonomous learning;social learning",
        "author": "",
        "aff": "",
        "rating": "3;5;8",
        "confidence": "4;3;3",
        "correctness": "2;3;4",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8029550685469661,
        "corr_rating_correctness": 0.9933992677987828,
        "project": "",
        "github": ""
    },
    {
        "id": "9vsRT9mc7U",
        "title": "Generative Adversarial Training for Neural Combinatorial Optimization Models",
        "track": "main",
        "status": "Reject",
        "keywords": "Deep Learning;Combinatorial Optimization Problem",
        "author": "",
        "aff": "",
        "rating": "3;3;6;6",
        "confidence": "4;3;4;4",
        "correctness": "2;2;4;3",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896258,
        "corr_rating_correctness": 0.9045340337332909,
        "project": "",
        "github": ""
    },
    {
        "id": "9wOQOgNe-w",
        "title": "Differentiable DAG Sampling",
        "track": "main",
        "status": "Poster",
        "keywords": "DAG;Differentiable;Sampling;Probabilistic model",
        "author": "",
        "aff": "Department of Informatics & Munich Data Science Institute, Technical University Munich",
        "rating": "5;5;8",
        "confidence": "4;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "0;2;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "9xhgmsNVHu",
        "title": "Is High Variance Unavoidable in RL? A Case Study in Continuous Control",
        "track": "main",
        "status": "Poster",
        "keywords": "reinforcement learning;continuous control",
        "author": "",
        "aff": "Cornell University",
        "rating": "6;6;6;10",
        "confidence": "3;3;4;4",
        "correctness": "4;3;4;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "4;2;3;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "9zcjXdavnX",
        "title": "Sampling from Discrete Energy-Based Models with Quality/Efficiency Trade-offs",
        "track": "main",
        "status": "Reject",
        "keywords": "Monte Carlo;sampling;rejection sampling;Energy-Based Models;EBMs;controlled text generation;language models",
        "author": "",
        "aff": "",
        "rating": "1;5;6",
        "confidence": "5;3;4",
        "correctness": "3;2;4",
        "technical_novelty": "1;2;3",
        "empirical_novelty": "0;2;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7559289460184544,
        "corr_rating_correctness": 0.1889822365046136,
        "project": "",
        "github": ""
    },
    {
        "id": "A05I5IvrdL-",
        "title": "The Geometry of Memoryless Stochastic Policy Optimization in Infinite-Horizon POMDPs",
        "track": "main",
        "status": "Poster",
        "keywords": "POMDPs;Memoryless Policies;Critical points;State-action frequencies;Algebraic degree",
        "author": "",
        "aff": "Department of Mathematics and Department of Statistics, UCLA, CA, USA; Max Planck Institute for Mathematics in the Sciences, Leipzig, Germany; Max Planck Institute for Mathematics in the Sciences, Leipzig, Germany",
        "rating": "6;6;8;8",
        "confidence": "2;3;3;2",
        "correctness": "3;4;4;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;0;0;0",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 2.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 0.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "A209HjoI2fq",
        "title": "POI-Transformers: POI Entity Matching through POI Embeddings by Incorporating Semantic and Geographic Information",
        "track": "main",
        "status": "Withdraw",
        "keywords": "POI entity matching;POI entity embedding;transformer-based model;POI-Transformers",
        "author": "",
        "aff": "",
        "rating": "1;5;5;5",
        "confidence": "2;3;4;4",
        "correctness": "1;4;3;3",
        "technical_novelty": "1;2;2;2",
        "empirical_novelty": "1;3;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8703882797784891,
        "corr_rating_correctness": 0.9271726499455306,
        "project": "",
        "github": ""
    },
    {
        "id": "A3HHaEdqAJL",
        "title": "Task Relatedness-Based Generalization Bounds for Meta Learning",
        "track": "main",
        "status": "Spotlight",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "8;8;8;8",
        "confidence": "3;3;2;1",
        "correctness": "4;3;3;4",
        "technical_novelty": "4;3;4;3",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 2.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.5,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "A4-dkBuXbA",
        "title": "Deep convolutional recurrent neural network for short-interval EEG motor imagery classification",
        "track": "main",
        "status": "Reject",
        "keywords": "Attention;Brain-Computer Interface (BCI);Electroencephalography (EEG);Convolutional Neural Networks (CNN);Motor Imagery (MI);Recurrent Neural Networks (RNN);grad-CAM",
        "author": "",
        "aff": "",
        "rating": "1;1;3",
        "confidence": "5;5;2",
        "correctness": "2;3;2",
        "technical_novelty": "1;2;2",
        "empirical_novelty": "1;0;2",
        "presentation": "",
        "rating_avg": 1.6666666666666667,
        "confidence_avg": 4.0,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 1.6666666666666667,
        "empirical_novelty_avg": 1.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9999999999999999,
        "corr_rating_correctness": -0.4999999999999999,
        "project": "",
        "github": ""
    },
    {
        "id": "A89KIvRYooT",
        "title": "FoxInst: A Frustratingly Simple Baseline for Weakly Few-shot Instance Segmentation",
        "track": "main",
        "status": "Withdraw",
        "keywords": "few-shot learning;instance segmentation;weakly supervised learning",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "5;4;3;5",
        "correctness": "3;2;3;2",
        "technical_novelty": "1;2;2;2",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "A9PXKSUYrJe",
        "title": "Robust Learning with Adaptive Sample Credibility Modeling",
        "track": "main",
        "status": "Withdraw",
        "keywords": "robust learning;label noise;divide-and-conquer",
        "author": "",
        "aff": "",
        "rating": "3;3;5",
        "confidence": "5;5;3",
        "correctness": "3;2;3",
        "technical_novelty": "3;2;2",
        "empirical_novelty": "3;2;2",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "AAHL45-O7tV",
        "title": "TransTCN: An Attention-based TCN Framework for Sequential Modeling",
        "track": "main",
        "status": "Withdraw",
        "keywords": "sequential modeling;multi-head attention;TCN;Transformer",
        "author": "",
        "aff": "",
        "rating": "1;3;5",
        "confidence": "3;3;4",
        "correctness": "1;2;3",
        "technical_novelty": "1;3;2",
        "empirical_novelty": "1;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8660254037844385,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "AAJLBoGt0XM",
        "title": "Conditional Contrastive Learning with Kernel",
        "track": "main",
        "status": "Poster",
        "keywords": "Contrastive Learning;Conditional Sampling;Kernel methods",
        "author": "",
        "aff": "",
        "rating": "5;6;6;8",
        "confidence": "4;4;4;4",
        "correctness": "3;4;2;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.48420012470625223,
        "project": "",
        "github": ""
    },
    {
        "id": "AAeMQz0x4nA",
        "title": "Learning Explicit Credit Assignment for Multi-agent Joint Q-learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Mutli-agent Credit Assignment;Mutli-agent Joint Q-learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "4;3;3;4",
        "correctness": "1;2;3;4",
        "technical_novelty": "3;1;3;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.19245008972987526,
        "corr_rating_correctness": 0.9467292624062574,
        "project": "",
        "github": ""
    },
    {
        "id": "AB2r0YKBSpD",
        "title": "Data Scaling Laws in NMT: The Effect of Noise and Architecture",
        "track": "main",
        "status": "Reject",
        "keywords": "Scaling laws;Neural Machine Translation",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "4;3;4;4",
        "correctness": "2;3;3;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.8660254037844386,
        "project": "",
        "github": ""
    },
    {
        "id": "ABv1puMlSgp",
        "title": "On Neurons Invariant to Sentence Structural Changes in Neural Machine Translation",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "1;3;5;5;5",
        "confidence": "4;3;3;4;4",
        "correctness": "2;3;3;3;3",
        "technical_novelty": "1;2;3;1;2",
        "empirical_novelty": "2;2;3;2;2",
        "presentation": "",
        "rating_avg": 3.8,
        "confidence_avg": 3.6,
        "correctness_avg": 2.8,
        "technical_novelty_avg": 1.8,
        "empirical_novelty_avg": 2.2,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.10206207261596574,
        "corr_rating_correctness": 0.8750000000000001,
        "project": "",
        "github": ""
    },
    {
        "id": "AEa_UepnMDX",
        "title": "Resolving label uncertainty with implicit generative models",
        "track": "main",
        "status": "Reject",
        "keywords": "weakly supervised learning;generative models;image segmentation",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "4;4;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;0;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "AFH3FnBksHT",
        "title": "Model Fusion of Heterogeneous Neural Networks via Cross-Layer Alignment",
        "track": "main",
        "status": "Reject",
        "keywords": "Model Fusion;Cross-layer Alignment;Knowledge Distillation;Model Compression;Model Transfer",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;3;4;5",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.7071067811865475,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "AIgn9uwfcD1",
        "title": "Prospect Pruning: Finding Trainable Weights at Initialization using Meta-Gradients",
        "track": "main",
        "status": "Poster",
        "keywords": "pruning;lottery ticket hypothesis;pruning at initialization",
        "author": "",
        "aff": "",
        "rating": "5;6;6;8",
        "confidence": "3;4;4;4",
        "correctness": "4;3;3;4",
        "technical_novelty": "3;2;3;4",
        "empirical_novelty": "3;3;3;4",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.6622661785325219,
        "corr_rating_correctness": 0.2294157338705618,
        "project": "",
        "github": ""
    },
    {
        "id": "AJAR-JgNw__",
        "title": "DEPTS: Deep Expansion Learning for Periodic Time Series Forecasting",
        "track": "main",
        "status": "Spotlight",
        "keywords": "",
        "author": "",
        "aff": "Microsoft Research; University of Central Florida",
        "rating": "6;8;8;8",
        "confidence": "3;3;4;4",
        "correctness": "4;3;3;4",
        "technical_novelty": "3;3;3;4",
        "empirical_novelty": "3;3;3;4",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": "https://github.com/weifantt/DEPTS"
    },
    {
        "id": "AJO2mBSTOHl",
        "title": "Analytically Tractable Bayesian Deep Q-Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Bayesian Learning;Probabilistic Methods;Uncertainty Quantification;Reinforcement Learning;Deep Q-learning",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "3;2;3;2",
        "correctness": "2;4;3;2",
        "technical_novelty": "3;2;3;2",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "AJg35fkqOPA",
        "title": "Text-Driven Image Manipulation via Semantic-Aware Knowledge Transfer",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;4;3;3",
        "correctness": "3;3;2;4",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;0;0;2",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6882472016116854,
        "corr_rating_correctness": 0.3244428422615251,
        "project": "",
        "github": ""
    },
    {
        "id": "AJsI-ymaKn_",
        "title": "POETREE: Interpretable Policy Learning with Adaptive Decision Trees",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Imitation Learning;Interpretable ML;Clinical Decision Support;Sequential Decision-Making",
        "author": "",
        "aff": "University of Cambridge, UK; Cambridge Centre for AI in Medicine, UK; The Alan Turing Institute, UK; University of Cambridge, UK; ETH AI Center, Switzerland; ETH Z\u00fcrich, Switzerland; MPI for Intelligent Systems, T\u00fcbingen, Germany",
        "rating": "5;8;8;8",
        "confidence": "4;3;3;3",
        "correctness": "2;4;4;3",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 7.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.8703882797784892,
        "project": "",
        "github": ""
    },
    {
        "id": "AK9LrCKUp9",
        "title": "Towards Robust Point Cloud Models with Context-Consistency Network and Adaptive Augmentation",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "Paper under double-blind review",
        "rating": "3;5;6;6",
        "confidence": "3;4;4;4",
        "correctness": "3;2;4;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9428090415820632,
        "corr_rating_correctness": 0.28867513459481287,
        "project": "",
        "github": ""
    },
    {
        "id": "AKIlm8fp1b",
        "title": "Generating Realistic Physical Adversarial Examplesby Patch Transformer Network",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Adversarial attack;Physical Adversarial Examples;object detection",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;4;3;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "1;2;2;2",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "AMpki9kp8Cn",
        "title": "Nonlinear ICA Using Volume-Preserving Transformations",
        "track": "main",
        "status": "Poster",
        "keywords": "Independent Component Analysis;Nonlinear ICA;Identifiability",
        "author": "",
        "aff": "Huawei Noah\u2019s Ark Lab; Shanghai Jiao Tong University",
        "rating": "6;6;6;6;6",
        "confidence": "3;4;3;3;3",
        "correctness": "4;3;3;4;3",
        "technical_novelty": "3;2;3;3;2",
        "empirical_novelty": "3;2;3;2;2",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.2,
        "correctness_avg": 3.4,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "AOn-gHymcx",
        "title": "A neural network framework for learning Green's function",
        "track": "main",
        "status": "Reject",
        "keywords": "Green's function;partial differential equation;boundary integral;neural network",
        "author": "",
        "aff": "",
        "rating": "1;3;3;3",
        "confidence": "5;4;5;3",
        "correctness": "4;2;1;3",
        "technical_novelty": "1;1;2;2",
        "empirical_novelty": "0;1;2;1",
        "presentation": "",
        "rating_avg": 2.5,
        "confidence_avg": 4.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 1.5,
        "empirical_novelty_avg": 1.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5222329678670935,
        "corr_rating_correctness": -0.7745966692414834,
        "project": "",
        "github": ""
    },
    {
        "id": "AP1MKT37rJ",
        "title": "Should I Run Offline Reinforcement Learning or Behavioral Cloning?",
        "track": "main",
        "status": "Poster",
        "keywords": "offline RL",
        "author": "",
        "aff": "",
        "rating": "6;6;8;8",
        "confidence": "3;4;3;5",
        "correctness": "3;4;4;3",
        "technical_novelty": "2;3;4;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.30151134457776363,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "APS9U4pNiI8",
        "title": "Secure Byzantine-Robust Federated Learning with Dimension-free Error",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Federated Learning;Robust Mean Estimator;Secure Aggregation",
        "author": "",
        "aff": "",
        "rating": "3;3;6",
        "confidence": "3;4;4",
        "correctness": "2;2;3",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "3;2;0",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "AQV2-jDKEt2",
        "title": "PRNet: A Progressive Regression Network for No-Reference User-Generated-Content Video Quality Assessment",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;3",
        "confidence": "3;5;4",
        "correctness": "2;2;2",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "ARw4igiN2Qm",
        "title": "A stepped sampling method for video detection using LSTM",
        "track": "main",
        "status": "Reject",
        "keywords": "stepped sampler;LSTM;video detection;psychology;human memory rule",
        "author": "",
        "aff": "",
        "rating": "1;1;5",
        "confidence": "5;5;5",
        "correctness": "1;1;2",
        "technical_novelty": "1;1;2",
        "empirical_novelty": "1;1;3",
        "presentation": "",
        "rating_avg": 2.3333333333333335,
        "confidence_avg": 5.0,
        "correctness_avg": 1.3333333333333333,
        "technical_novelty_avg": 1.3333333333333333,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "ARyEf6Z77Y",
        "title": "Collaboration of Experts: Achieving 80% Top-1 Accuracy on ImageNet with 100M FLOPs",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;6;8",
        "confidence": "3;3;3;5",
        "correctness": "4;3;3;4",
        "technical_novelty": "3;2;3;4",
        "empirical_novelty": "3;3;3;4",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9428090415820632,
        "corr_rating_correctness": 0.40824829046386296,
        "project": "",
        "github": ""
    },
    {
        "id": "AS0dhAKIYA0",
        "title": "Interpretable Semantic Role Relation Table for Supporting Facts Recognition of Reading Comprehension",
        "track": "main",
        "status": "Reject",
        "keywords": "interpretability;semantic role relation table;supporting facts",
        "author": "",
        "aff": "",
        "rating": "1;1;3;5",
        "confidence": "4;4;4;3",
        "correctness": "1;2;2;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "1;2;2;3",
        "presentation": "",
        "rating_avg": 2.5,
        "confidence_avg": 3.75,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8703882797784891,
        "corr_rating_correctness": 0.8528028654224417,
        "project": "",
        "github": ""
    },
    {
        "id": "AT0K-SZ3QGq",
        "title": "On Heterogeneously Distributed Data, Sparsity Matters",
        "track": "main",
        "status": "Reject",
        "keywords": "Federated Learning;Dynamic Sparse Training;Communication-efficient Personalized Federated Learning",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "4;3;3;3",
        "correctness": "2;3;3;3",
        "technical_novelty": "3;2;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "ATUh28lnSuW",
        "title": "Graph Auto-Encoder via Neighborhood Wasserstein Reconstruction",
        "track": "main",
        "status": "Poster",
        "keywords": "graph representation learning;unsupervised learning;autoencoder;wasserstein distance",
        "author": "",
        "aff": "",
        "rating": "5;6;6;8",
        "confidence": "4;3;4;4",
        "correctness": "4;4;3;3",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.13245323570650439,
        "corr_rating_correctness": -0.6882472016116854,
        "project": "",
        "github": ""
    },
    {
        "id": "AUGBfDIV9rL",
        "title": "Emergent Communication at Scale",
        "track": "main",
        "status": "Spotlight",
        "keywords": "emergent communication;multi-agent reinforcement learning;representation learning",
        "author": "",
        "aff": "",
        "rating": "8;8;8;8",
        "confidence": "3;4;4;3",
        "correctness": "4;4;3;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "4;4;4;4",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 4.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "AUszBTiYBB6",
        "title": "FEDERATED LEARNING FRAMEWORK BASED ON TRIMMED MEAN AGGREGATION RULES",
        "track": "main",
        "status": "Reject",
        "keywords": "Tmean\uff0cByzantine attack\uff0cByzantine-resilient",
        "author": "",
        "aff": "",
        "rating": "3;3;3",
        "confidence": "4;5;4",
        "correctness": "2;3;3",
        "technical_novelty": "1;2;2",
        "empirical_novelty": "1;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 1.6666666666666667,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "AV8FPoMTTa",
        "title": "Shallow and Deep Networks are Near-Optimal Approximators of Korobov Functions",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "6;6;6;8",
        "confidence": "3;3;4;3",
        "correctness": "3;4;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;0;0;0",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 0.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "AVPSfvFXqJy",
        "title": "Self-supervised Models are Good Teaching Assistants for Vision Transformers",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Transformer;Knowledge Distillation;Self-supervised Learning",
        "author": "",
        "aff": "",
        "rating": "3;3;8;8",
        "confidence": "5;4;5;4",
        "correctness": "2;4;4;4",
        "technical_novelty": "3;1;4;4",
        "empirical_novelty": "2;1;4;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 4.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "AVShGWiL9z",
        "title": "Tractable Dendritic RNNs for Identifying Unknown Nonlinear Dynamical Systems",
        "track": "main",
        "status": "Reject",
        "keywords": "chaos;dendritic computation;piecewise linear;recurrent neural network;variational inference;interpretability;tractability;basis expansion",
        "author": "",
        "aff": "Paper under double-blind review",
        "rating": "3;5;6",
        "confidence": "4;4;4",
        "correctness": "3;2;4",
        "technical_novelty": "2;2;4",
        "empirical_novelty": "1;2;4",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.3273268353539886,
        "project": "",
        "github": ""
    },
    {
        "id": "AXWygMvuT6Q",
        "title": "Retriever: Learning Content-Style Representation as a Token-Level Bipartite Graph",
        "track": "main",
        "status": "Poster",
        "keywords": "Content-style decomposed representation;Zero-shot voice conversion;Style transfer;Transformer;Unsupervised learning",
        "author": "",
        "aff": "",
        "rating": "6;6;8",
        "confidence": "3;3;4",
        "correctness": "3;3;4",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "0;2;4",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9999999999999998,
        "corr_rating_correctness": 0.9999999999999998,
        "project": "",
        "github": ""
    },
    {
        "id": "AXXohj2qWlw",
        "title": "Discovering Novel Customer Features with Recurrent Neural Networks for Personality Based Financial Services",
        "track": "main",
        "status": "Withdraw",
        "keywords": "AI in finance;micro-segmentation;personality traits;explainability;recurrent neural networks;trajectory clustering;attractors",
        "author": "",
        "aff": "",
        "rating": "1;3;3;3",
        "confidence": "4;4;4;4",
        "correctness": "2;2;3;2",
        "technical_novelty": "2;1;1;2",
        "empirical_novelty": "2;1;2;2",
        "presentation": "",
        "rating_avg": 2.5,
        "confidence_avg": 4.0,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 1.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "AawMbgacl0t",
        "title": "Image Functions In Neural Networks: A Perspective On Generalization",
        "track": "main",
        "status": "Reject",
        "keywords": "generalization;ensembling;algorithmic stability",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "3;2;4;3",
        "correctness": "2;2;2;3",
        "technical_novelty": "1;1;2;2",
        "empirical_novelty": "1;2;3;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 1.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "Ab0o8YMJ8a",
        "title": "Automated Channel Pruning with Learned Importance",
        "track": "main",
        "status": "Reject",
        "keywords": "channel pruning;knowledge distillation",
        "author": "",
        "aff": "",
        "rating": "3;5;5",
        "confidence": "3;5;3",
        "correctness": "3;3;3",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 4.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "AcrlgZ9BKed",
        "title": "A Reduction-Based Framework for Conservative Bandits and Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "bandits;lower bound;reinforcement learning theory",
        "author": "",
        "aff": "Facebook AI Research; Center for Data Science, Peking University; University of California, Berkeley; University of Washington; Key Laboratory of Machine Perception, MOE, School of Artificial Intelligence, Peking University, International Center for Machine Learning Research, Peking University",
        "rating": "6;6;8;8",
        "confidence": "4;4;4;3",
        "correctness": "3;4;4;4",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "1;0;0;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 1.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "AdEM_SzfSd",
        "title": "Assessing two novel distance-based loss functions for few-shot image classification",
        "track": "main",
        "status": "Reject",
        "keywords": "Metric learning;few-shot learning;image classification",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "3;5;4;4",
        "correctness": "3;2;2;2",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;2;2;1",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "AfeeU77SUx",
        "title": "Learning with Few-Shot Complementary Labels",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Complementary-label learning;Few-shot learning",
        "author": "",
        "aff": "",
        "rating": "",
        "confidence": "",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "AgDwZa1AiJt",
        "title": "When in Doubt, Summon the Titans: A Framework for Efficient Inference with Large Models",
        "track": "main",
        "status": "Reject",
        "keywords": "Distillation;Large models;Efficient inference",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "4;3;3;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "1;2;3;2",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.40824829046386296,
        "corr_rating_correctness": 0.9428090415820632,
        "project": "",
        "github": ""
    },
    {
        "id": "AjGC97Aofee",
        "title": "Learning Efficient Image Super-Resolution Networks via Structure-Regularized Pruning",
        "track": "main",
        "status": "Poster",
        "keywords": "image super-resolution",
        "author": "",
        "aff": "",
        "rating": "5;6;8;8",
        "confidence": "4;4;4;5",
        "correctness": "3;1;4;3",
        "technical_novelty": "2;3;3;4",
        "empirical_novelty": "3;2;3;4",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5555555555555555,
        "corr_rating_correctness": 0.4856618642571827,
        "project": "",
        "github": ""
    },
    {
        "id": "AkJyAE46GA",
        "title": "Pretrained models are active learners",
        "track": "main",
        "status": "Reject",
        "keywords": "pretraining;active learning;alignment;safety",
        "author": "",
        "aff": "",
        "rating": "3;3;5;8",
        "confidence": "4;4;5;3",
        "correctness": "4;3;3;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5183210553488161,
        "corr_rating_correctness": 0.3665083330689157,
        "project": "",
        "github": ""
    },
    {
        "id": "AlPBx2zq7Jt",
        "title": "Align-RUDDER: Learning From Few Demonstrations by Reward Redistribution",
        "track": "main",
        "status": "Reject",
        "keywords": "RUDDER;reinforcement learning;reward redistribution;return decomposition;delayed reward;sparse reward;episodic reward;minecraft",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "4;4;3;4",
        "correctness": "2;3;4;3",
        "technical_novelty": "3;3;2;2",
        "empirical_novelty": "3;3;3;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4714045207910316,
        "corr_rating_correctness": 0.8660254037844386,
        "project": "",
        "github": ""
    },
    {
        "id": "AmUhwTOHgm",
        "title": "Trans-Encoder: Unsupervised sentence-pair modelling through self- and mutual-distillations",
        "track": "main",
        "status": "Poster",
        "keywords": "self-supervised learning;sentence embeddings;sentence representations;knowledge distillation",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "3;4;4;4",
        "correctness": "2;3;4;4",
        "technical_novelty": "3;3;3;2",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.9045340337332909,
        "project": "",
        "github": ""
    },
    {
        "id": "Aot3sKdraW",
        "title": "AA-PINN: ATTENTION AUGMENTED PHYSICS INFORMED NEURAL NETWORKS",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "3;4;4;3",
        "correctness": "3;2;3;3",
        "technical_novelty": "3;2;2;2",
        "empirical_novelty": "3;1;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "ArY-zkyHI_l",
        "title": "Resilience to Multiple Attacks via Adversarially Trained MIMO Ensembles",
        "track": "main",
        "status": "Reject",
        "keywords": "Adversarial Example;Adversarial Attack;Evasion Attack;Defense;Adversarial Training;Security in Machine Learning",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;4;4;5",
        "correctness": "3;3;4;3",
        "technical_novelty": "3;2;3;2",
        "empirical_novelty": "2;0;2;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "AsDSpwXYGeT",
        "title": "Back to Basics: Efficient Network Compression via IMP",
        "track": "main",
        "status": "Reject",
        "keywords": "Magnitude pruning;Sparsity;IMP;Model Compression",
        "author": "",
        "aff": "",
        "rating": "5;5;6",
        "confidence": "4;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;3;4",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9999999999999997,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "AsQz_GFFDQp",
        "title": "Agnostic Personalized Federated Learning with Kernel Factorization",
        "track": "main",
        "status": "Reject",
        "keywords": "Federated Learning;Personalized Federated Learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6;6",
        "confidence": "4;4;4;3;3",
        "correctness": "2;3;3;3;3",
        "technical_novelty": "2;1;3;3;3",
        "empirical_novelty": "2;1;2;3;2",
        "presentation": "",
        "rating_avg": 4.6,
        "confidence_avg": 3.6,
        "correctness_avg": 2.8,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8427009716003845,
        "corr_rating_correctness": 0.5897678246195884,
        "project": "",
        "github": ""
    },
    {
        "id": "AsyICRrQ7Lp",
        "title": "Bootstrapped Hindsight Experience replay with Counterintuitive Prioritization",
        "track": "main",
        "status": "Reject",
        "keywords": "Reinforcement learning;hindsight experience replay;counterintuitive prioritization",
        "author": "",
        "aff": "",
        "rating": "1;3;5;5",
        "confidence": "4;4;4;2",
        "correctness": "2;3;4;4",
        "technical_novelty": "1;2;3;2",
        "empirical_novelty": "2;3;3;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5222329678670935,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "AvcfxqRy4Y",
        "title": "Understanding the Role of Self Attention for Efficient Speech Recognition",
        "track": "main",
        "status": "Spotlight",
        "keywords": "transformer;self attention;speech recognition",
        "author": "",
        "aff": "",
        "rating": "6;8;8;8",
        "confidence": "4;5;4;4",
        "correctness": "3;4;3;4",
        "technical_novelty": "3;3;3;4",
        "empirical_novelty": "2;3;3;4",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 4.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "AwgtcUAhBq",
        "title": "Domain Adversarial Training: A Game Perspective",
        "track": "main",
        "status": "Poster",
        "keywords": "Domain Adversarial Training;Domain Adaptation;Neural Networks Optimization;Game Theory",
        "author": "",
        "aff": "",
        "rating": "6;6;8;8",
        "confidence": "5;3;3;2",
        "correctness": "3;4;4;4",
        "technical_novelty": "4;2;3;3",
        "empirical_novelty": "4;3;3;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6882472016116854,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "AypVMhFfuc5",
        "title": "FrugalMCT: Efficient Online ML API Selection for Multi-Label Classification Tasks",
        "track": "main",
        "status": "Reject",
        "keywords": "ML as a Service;Multi-label classifications;ML systems;adaptive learning",
        "author": "",
        "aff": "",
        "rating": "3;6;8;8",
        "confidence": "4;3;3;4",
        "correctness": "2;3;4;4",
        "technical_novelty": "1;3;3;3",
        "empirical_novelty": "1;3;4;4",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3665083330689157,
        "corr_rating_correctness": 0.9945577827230725,
        "project": "",
        "github": ""
    },
    {
        "id": "Az-7gJc6lpr",
        "title": "Relational Learning with Variational Bayes",
        "track": "main",
        "status": "Poster",
        "keywords": "Relational learning;psychology;unsupervised learning;variational inference;probabilistic graphical model.",
        "author": "",
        "aff": "ExxonMobil Research and Engineering",
        "rating": "5;6;6;6;6",
        "confidence": "4;3;3;3;3",
        "correctness": "3;3;3;3;3",
        "technical_novelty": "3;3;3;3;3",
        "empirical_novelty": "3;3;3;2;3",
        "presentation": "",
        "rating_avg": 5.8,
        "confidence_avg": 3.2,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.8,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "Az7opqbQE-3",
        "title": "Heteroscedastic Temporal Variational Autoencoder For Irregularly Sampled Time Series",
        "track": "main",
        "status": "Poster",
        "keywords": "irregular sampling;uncertainty;imputation;interpolation;multivariate time series;missing data;variational autoencoder",
        "author": "",
        "aff": "",
        "rating": "5;6;6;8",
        "confidence": "4;3;3;4",
        "correctness": "4;4;4;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.5,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.2294157338705618,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "Azh9QBQ4tR7",
        "title": "Reducing Excessive Margin to Achieve a Better Accuracy vs. Robustness Trade-off",
        "track": "main",
        "status": "Poster",
        "keywords": "adversarial training;robustness",
        "author": "",
        "aff": "ETH Z\u00fcrich, Switzerland; Imperial College London, UK",
        "rating": "6;6;6;8",
        "confidence": "4;5;4;5",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;3;3;4",
        "empirical_novelty": "3;4;4;4",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 4.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": "https://github.com/imrahulr/hat"
    },
    {
        "id": "B0JH7vR2iGh",
        "title": "PMIC: Improving Multi-Agent Reinforcement Learning with Progressive Mutual Information Collaboration",
        "track": "main",
        "status": "Reject",
        "keywords": "Multi-Agent Reinforcement Learning;Collaboration",
        "author": "",
        "aff": "",
        "rating": "5;6;6;6",
        "confidence": "4;4;3;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "B0oHOwT5ENL",
        "title": "Neural Deep Equilibrium Solvers",
        "track": "main",
        "status": "Poster",
        "keywords": "Deep learning;Implicit models;Deep equilibrium models",
        "author": "",
        "aff": "",
        "rating": "8;8;8",
        "confidence": "4;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "3;2;4",
        "empirical_novelty": "4;4;4",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 4.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "B2pZkS2urk_",
        "title": "Do What Nature Did To Us: Evolving Plastic Recurrent Neural Networks For Generalized Tasks",
        "track": "main",
        "status": "Reject",
        "keywords": "Evolving Plasticity;Learning to learn",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;4;4;4",
        "correctness": "2;4;3;3",
        "technical_novelty": "2;1;2;2",
        "empirical_novelty": "1;1;3;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "B31WdoD2VXQ",
        "title": "IDENTIFYING CONCEALED OBJECTS FROM VIDEOS",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "5;4;3;3",
        "correctness": "2;3;3;4",
        "technical_novelty": "1;2;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8703882797784892,
        "corr_rating_correctness": 0.816496580927726,
        "project": "Link provided in the abstract",
        "github": ""
    },
    {
        "id": "B3Nde6lvab",
        "title": "Eliminating Sharp Minima from SGD with Truncated Heavy-tailed Noise",
        "track": "main",
        "status": "Poster",
        "keywords": "Stochastic Gradient Descent;SGD;Heavy-Tails;Generalization",
        "author": "",
        "aff": "Northwestern University; University of Washington",
        "rating": "5;6;8",
        "confidence": "3;3;5",
        "correctness": "3;3;3",
        "technical_novelty": "2;3;4",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 6.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.944911182523068,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "B4uS3efOEW",
        "title": "Confidence Adaptive Regularization for Deep Learning with Noisy Labels",
        "track": "main",
        "status": "Withdraw",
        "keywords": "noisy labels;regularization;label correction",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "5;5;4;5",
        "correctness": "3;3;2;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 4.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "B5XahNLmna",
        "title": "Data Poisoning Won\u2019t Save You From Facial Recognition",
        "track": "main",
        "status": "Poster",
        "keywords": "Poisoning attacks;adversarial examples;facial recognition;arms race;defenses",
        "author": "",
        "aff": "Stanford University; Oregon State University; Google; Stanford University, Google",
        "rating": "1;6;8;8",
        "confidence": "5;4;3;5",
        "correctness": "3;4;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5005202012851406,
        "corr_rating_correctness": 0.050443327230531826,
        "project": "",
        "github": ""
    },
    {
        "id": "B6EIcyp-Rb7",
        "title": "Learning Object-Oriented Dynamics for Planning from Text",
        "track": "main",
        "status": "Poster",
        "keywords": "Object Oriented Markov Decision Process;Reinforcement Learning;Model-Based Planning;Text-Based Games;Knowledge Extraction",
        "author": "",
        "aff": "University of Waterloo, Microsoft; University of Waterloo, Vector Institute; University of Toronto, Vector Institute",
        "rating": "5;6;8;8",
        "confidence": "3;2;4;3",
        "correctness": "3;4;4;4",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 3.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5443310539518174,
        "corr_rating_correctness": 0.7777777777777777,
        "project": "",
        "github": ""
    },
    {
        "id": "B6YDcqpMk30",
        "title": "PRIMA: Planner-Reasoner Inside a Multi-task Reasoning Agent",
        "track": "main",
        "status": "Reject",
        "keywords": "inductive logic programming;logic reasoning;first-order logic;reinforcement learning;Monte Carlo tree search",
        "author": "",
        "aff": "",
        "rating": "5;6;6;6",
        "confidence": "3;3;3;3",
        "correctness": "2;3;4;3",
        "technical_novelty": "2;3;4;3",
        "empirical_novelty": "2;3;3;2",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "B72HXs80q4",
        "title": "Taming Sparsely Activated Transformer with Stochastic Experts",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "Georgia Institute of Technology; Microsoft",
        "rating": "5;6;6;8",
        "confidence": "4;5;3;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;3;3;4",
        "empirical_novelty": "2;4;3;4",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9271726499455306,
        "project": "",
        "github": "https://github.com/microsoft/Stochastic-Mixture-of-Experts"
    },
    {
        "id": "B7O85qTDgU4",
        "title": "Meta-Learning Dynamics Forecasting Using Task Inference",
        "track": "main",
        "status": "Reject",
        "keywords": "meta-learning;generalizability;dynamical systems",
        "author": "",
        "aff": "",
        "rating": "5;6;6;8",
        "confidence": "4;4;4;3",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "3;4;3;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9271726499455306,
        "corr_rating_correctness": 0.6882472016116854,
        "project": "",
        "github": ""
    },
    {
        "id": "B7ZbqNLDn-_",
        "title": "Recycling Model Updates in Federated Learning: Are Gradient Subspaces Low-Rank?",
        "track": "main",
        "status": "Poster",
        "keywords": "Distributed Machine Learning;Federated Learning;Gradient Subspace;SGD",
        "author": "",
        "aff": "School of ECE, Purdue University",
        "rating": "5;8;8;8",
        "confidence": "4;3;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;3;4",
        "empirical_novelty": "2;3;2;4",
        "presentation": "",
        "rating_avg": 7.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "B7abCaIiN_v",
        "title": "Triangular Dropout: Variable Network Width without Retraining",
        "track": "main",
        "status": "Reject",
        "keywords": "architecture;compression;variable network;neural network design;deep learning",
        "author": "",
        "aff": "",
        "rating": "1;5;5;6",
        "confidence": "5;4;3;5",
        "correctness": "3;3;3;4",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "1;2;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3532809023904868,
        "corr_rating_correctness": 0.5261522196019801,
        "project": "",
        "github": ""
    },
    {
        "id": "B8DVo9B1YE0",
        "title": "Relating transformers to models and neural representations of the hippocampal formation",
        "track": "main",
        "status": "Poster",
        "keywords": "Neuroscience;representation learning;hippocampus;cortex;transformers",
        "author": "",
        "aff": "University of Oxford; University of Oxford & Stanford University; University of Oxford & University College London",
        "rating": "6;8;8;8",
        "confidence": "3;3;4;4",
        "correctness": "3;4;3;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "0;3;3;3",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "B9LUI0pZFGc",
        "title": "The KFIoU Loss for Rotated Object Detection",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Rotation Detection;SkewIoU loss;Kalman Filter",
        "author": "",
        "aff": "",
        "rating": "3;3;3;6",
        "confidence": "3;4;3;4",
        "correctness": "3;2;2;3",
        "technical_novelty": "1;2;2;3",
        "empirical_novelty": "2;1;2;2",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 3.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "BAtutOziapg",
        "title": "Can Stochastic Gradient Langevin Dynamics Provide Differential Privacy for Deep Learning?",
        "track": "main",
        "status": "Reject",
        "keywords": "differential privacy;bayesian inference;sgld",
        "author": "",
        "aff": "Paper under double-blind review",
        "rating": "3;5;5;6",
        "confidence": "4;4;4;3",
        "correctness": "3;4;4;3",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "0;2;0;0",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 0.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6622661785325219,
        "corr_rating_correctness": 0.2294157338705618,
        "project": "",
        "github": ""
    },
    {
        "id": "BB4e8Atc1eR",
        "title": "Scalable Sampling for Nonsymmetric Determinantal Point Processes",
        "track": "main",
        "status": "Spotlight",
        "keywords": "determinantal point processes;sampling",
        "author": "",
        "aff": "Facebook AI Research; Yale University; Criteo AI Lab; Google Research",
        "rating": "8;8;8;8",
        "confidence": "4;3;4;3",
        "correctness": "4;3;4;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;3;3;2",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "BGvt0ghNgA",
        "title": "Lipschitz-constrained Unsupervised Skill Discovery",
        "track": "main",
        "status": "Poster",
        "keywords": "Reinforcement learning",
        "author": "",
        "aff": "University of Michigan; Seoul National University",
        "rating": "6;6;6;8",
        "confidence": "4;3;3;3",
        "correctness": "4;4;4;4",
        "technical_novelty": "3;3;3;4",
        "empirical_novelty": "4;4;3;4",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.25,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://shpark.me/projects/lsd/"
    },
    {
        "id": "BIpTWmO_BY",
        "title": "Sleeper Agent: Scalable Hidden Trigger Backdoors for Neural Networks Trained from Scratch",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Backdoor attacks;data poisoning;clean labels;adversarial examples;security",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5",
        "confidence": "5;3;4;4",
        "correctness": "2;3;4;3",
        "technical_novelty": "3;2;2;4",
        "empirical_novelty": "3;3;3;4",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "BJ-NSus8wXk",
        "title": "Towards Unknown-aware Deep Q-Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "3;5;4;3",
        "correctness": "4;4;2;3",
        "technical_novelty": "1;2;2;2",
        "empirical_novelty": "1;1;3;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.30151134457776363,
        "corr_rating_correctness": -0.9045340337332909,
        "project": "",
        "github": ""
    },
    {
        "id": "BK-4qbGgIE3",
        "title": "No One Representation to Rule Them All: Overlapping Features of Training Methods",
        "track": "main",
        "status": "Poster",
        "keywords": "Representation Learning;Understanding Deep Learning;Deep Phenomena;Diversity;Novelty;Features;Training Methodologies;Contrastive Learning",
        "author": "",
        "aff": "Google Research, Brain Team",
        "rating": "6;8;8;8",
        "confidence": "4;4;4;3",
        "correctness": "4;4;3;3",
        "technical_novelty": "3;2;4;4",
        "empirical_novelty": "3;4;4;4",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "BKOiqcdpml3",
        "title": "Low Entropy Deep Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "Quantisation;Compression;AI Accelerators",
        "author": "",
        "aff": "",
        "rating": "5;5;5;8",
        "confidence": "4;3;3;4",
        "correctness": "3;2;3;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "BKmoW5K4sS",
        "title": "On Adversarial Bias and the Robustness of Fair Machine Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Robustness;Algorithmic fairness",
        "author": "",
        "aff": "",
        "rating": "3;3;5;8",
        "confidence": "5;4;3;4",
        "correctness": "3;2;3;4",
        "technical_novelty": "2;1;2;3",
        "empirical_novelty": "1;2;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.34554737023254406,
        "corr_rating_correctness": 0.8638684255813602,
        "project": "",
        "github": ""
    },
    {
        "id": "BM7RjuhAK7W",
        "title": "Model-Invariant State Abstractions for Model-Based Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Reinforcement Learning;Model-based RL;State Abstractions;Generalization in RL",
        "author": "Manan Tomar",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;3;4;4",
        "correctness": "4;2;3;3",
        "technical_novelty": "3;2;2;3",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "BNIt2myzSzS",
        "title": "IA-MARL: Imputation Assisted Multi-Agent Reinforcement Learning for Missing Training Data",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "1;3;3;5",
        "confidence": "4;4;3;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;2;4",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "BRFWxcZfAdC",
        "title": "LOSSY COMPRESSION WITH DISTRIBUTION SHIFT AS ENTROPY CONSTRAINED OPTIMAL TRANSPORT",
        "track": "main",
        "status": "Poster",
        "keywords": "Image Compression;Image Restoration;Optimal Transport;Deep Learning",
        "author": "",
        "aff": "McMaster University; University of Toronto",
        "rating": "3;6;6;8;8",
        "confidence": "4;2;3;3;3",
        "correctness": "1;4;4;4;4",
        "technical_novelty": "1;3;3;3;3",
        "empirical_novelty": "1;3;3;3;3",
        "presentation": "",
        "rating_avg": 6.2,
        "confidence_avg": 3.0,
        "correctness_avg": 3.4,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 2.6,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5175491695067655,
        "corr_rating_correctness": 0.8728715609439694,
        "project": "",
        "github": ""
    },
    {
        "id": "BS49l-B5Bql",
        "title": "GNN-LM: Language Modeling based on Global Contexts via GNN",
        "track": "main",
        "status": "Spotlight",
        "keywords": "",
        "author": "",
        "aff": "Nanyang Technological University; Zhejiang University; Shannon.AI; Nanjing University",
        "rating": "6;8;10",
        "confidence": "3;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "3;4;3",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 3.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8660254037844385,
        "corr_rating_correctness": 0.8660254037844385,
        "project": "",
        "github": "https://github.com/ShannonAI/GNN-LM"
    },
    {
        "id": "BZbUtxOy3R",
        "title": "Character Generation through Self-Supervised Vectorization",
        "track": "main",
        "status": "Reject",
        "keywords": "character generation;parsing;reconstruction;self-supervised;omniglot",
        "author": "",
        "aff": "",
        "rating": "3;5;5",
        "confidence": "4;3;4",
        "correctness": "2;3;3",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "1;1;2",
        "presentation": "",
        "rating_avg": 4.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 1.3333333333333333,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.49999999999999983,
        "corr_rating_correctness": 0.9999999999999998,
        "project": "",
        "github": ""
    },
    {
        "id": "BZnnMbt0pW",
        "title": "Promoting Saliency From Depth: Deep Unsupervised RGB-D Saliency Detection",
        "track": "main",
        "status": "Poster",
        "keywords": "RGB-D saliency detection;salient object detection;deep learning;unsupervised learning",
        "author": "",
        "aff": "Dalian University of Technology, China; Wuhan University, China; University of Alberta, Canada",
        "rating": "6;8;8",
        "confidence": "3;4;4",
        "correctness": "2;4;3",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "0;3;3",
        "presentation": "",
        "rating_avg": 7.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9999999999999998,
        "corr_rating_correctness": 0.8660254037844385,
        "project": "",
        "github": ""
    },
    {
        "id": "Bc4fwa76mRp",
        "title": "Head2Toe: Utilizing Intermediate Representations for Better OOD Generalization",
        "track": "main",
        "status": "Reject",
        "keywords": "efficient training;transfer learning;efficient transfer;fine tuning;computer vision;linear probe",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "3;4;3;5",
        "correctness": "3;2;3;3",
        "technical_novelty": "3;2;2;3",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.30151134457776363,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "Bd8JSwLVWQ5",
        "title": "Equivalence of State Equations from Different Methods in High-dimensional Regression",
        "track": "main",
        "status": "Reject",
        "keywords": "Approximate message passing;Lasso;High dimensional statistics",
        "author": "",
        "aff": "",
        "rating": "1;3;3;8",
        "confidence": "5;4;4;4",
        "correctness": "2;3;4;4",
        "technical_novelty": "1;2;2;4",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6139601294045424,
        "corr_rating_correctness": 0.7287050466613612,
        "project": "",
        "github": ""
    },
    {
        "id": "BdPhV0Y6qkk",
        "title": "InterTrain: Accelerating DNN Training using Input Interpolation",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Efficient DNN Training",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;4;4;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;1;1",
        "empirical_novelty": "1;2;2;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 1.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "BduNVoPyXBK",
        "title": "Task-driven Discovery of Perceptual Schemas for Generalization in Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "deep reinforcement learning;reinforcement learning;deep learning;compositional generalization;generalization;recurrent architecture",
        "author": "",
        "aff": "",
        "rating": "5;5;6",
        "confidence": "4;4;4",
        "correctness": "3;2;3",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "3;2;3",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.4999999999999999,
        "project": "",
        "github": ""
    },
    {
        "id": "BefW4ttKMFt",
        "title": "Meta Learning with Minimax Regularization",
        "track": "main",
        "status": "Withdraw",
        "keywords": "meta learning;generalization;minimax regularization",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;3;3;3",
        "correctness": "1;3;3;4",
        "technical_novelty": "3;2;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.6622661785325219,
        "project": "",
        "github": ""
    },
    {
        "id": "Bel1Do_eZC",
        "title": "Inductive Lottery Ticket Learning for Graph Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "Lottery Ticket Hypothesis;Graph Neural Networks;Neural Network Pruning",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "3;4;3;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;0;3;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "BjyvwnXXVn_",
        "title": "EViT: Expediting Vision Transformers via Token Reorganizations",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Vision Transformers;multi-head self-attention;efficient inference",
        "author": "",
        "aff": "The University of Hong Kong; UC San Diego; Tencent AI Lab",
        "rating": "8;8;8;8",
        "confidence": "5;5;4;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "4;4;4;4",
        "empirical_novelty": "4;3;4;4",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 4.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 4.0,
        "empirical_novelty_avg": 3.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/youweiliang/evit"
    },
    {
        "id": "BkIV7EOXkSs",
        "title": "Implicit Regularization of Bregman Proximal Point Algorithm and Mirror Descent on Separable Data",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "Paper under double-blind review",
        "rating": "5;6;6;6",
        "confidence": "4;3;2;2",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;3;2;2",
        "empirical_novelty": "2;2;1;2",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 2.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8703882797784891,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "Bl8CQrx2Up4",
        "title": "cosFormer: Rethinking Softmax In Attention",
        "track": "main",
        "status": "Poster",
        "keywords": "Linear Transformer;softmax attention",
        "author": "",
        "aff": "Shanghai AI Laboratory; Australian National University; SenseTime Research, Shanghai AI Laboratory; SenseTime Research",
        "rating": "6;6;8;8",
        "confidence": "4;5;5;3",
        "correctness": "3;2;3;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.30151134457776363,
        "corr_rating_correctness": 0.7071067811865475,
        "project": "COSFORMER",
        "github": "Not provided"
    },
    {
        "id": "BlyXYc4wF2-",
        "title": "Multi-Agent Constrained Policy Optimisation",
        "track": "main",
        "status": "Reject",
        "keywords": "Safe Multi-Agent Reinforcement Learning;Safe Multi-Agent Trust Region Policy Optimisation;Safe Multi-Agent Proximal Policy Optimisation;Constrained Policy Optimisation",
        "author": "",
        "aff": "",
        "rating": "5;5;5",
        "confidence": "3;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "3;3;2",
        "empirical_novelty": "2;3;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "https://sites.google.com/view/macpo",
        "github": ""
    },
    {
        "id": "BmJV7kyAmg",
        "title": "Towards Understanding the Robustness Against Evasion Attack on Categorical Data",
        "track": "main",
        "status": "Poster",
        "keywords": "robustness certification;adversarial learning;categorical data",
        "author": "",
        "aff": "University of Notre Dame; King Abdullah University of Science and Technology; NetApp; INRIA",
        "rating": "6;6;8",
        "confidence": "4;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.49999999999999983,
        "corr_rating_correctness": -0.49999999999999983,
        "project": "",
        "github": ""
    },
    {
        "id": "Bn09TnDngN",
        "title": "How to Inject Backdoors with Better Consistency: Logit Anchoring on Clean Data",
        "track": "main",
        "status": "Poster",
        "keywords": "backdoor learning;weight perturbation;consistency",
        "author": "",
        "aff": "Ant Group, Hangzhou, China; Sony AI, Tokyo, Japan; Lehigh University, Bethlehem, PA, USA; Peking University, Beijing, China",
        "rating": "6;8;8;8",
        "confidence": "3;4;4;4",
        "correctness": "4;3;4;4",
        "technical_novelty": "2;4;4;4",
        "empirical_novelty": "3;4;4;4",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.5,
        "empirical_novelty_avg": 3.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 1.0,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "BnQhMqDfcKG",
        "title": "Probabilistic Implicit Scene Completion",
        "track": "main",
        "status": "Spotlight",
        "keywords": "3D shape completion;3D generative model",
        "author": "",
        "aff": "",
        "rating": "8;8;8;8;8",
        "confidence": "3;4;4;4;3",
        "correctness": "3;3;4;4;3",
        "technical_novelty": "3;3;3;3;3",
        "empirical_novelty": "2;3;3;3;0",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.6,
        "correctness_avg": 3.4,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.2,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "BpUXKoZM0J",
        "title": "Rethinking Rehearsal in Lifelong Learning: Does An Example Contribute the Plasticity or Stability?",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Lifelong Learning;Rehearsal",
        "author": "",
        "aff": "",
        "rating": "3;3;5",
        "confidence": "4;4;3",
        "correctness": "3;2;3",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "BrFIKuxrZE",
        "title": "Fair Normalizing Flows",
        "track": "main",
        "status": "Poster",
        "keywords": "fairness;fair representation learning;adversarial fairness;trustworthy machine learning",
        "author": "",
        "aff": "ETH Zurich, DeepMind; ETH Zurich",
        "rating": "5;6;6;6;8",
        "confidence": "4;4;3;2;4",
        "correctness": "3;4;3;3;3",
        "technical_novelty": "2;4;3;3;2",
        "empirical_novelty": "2;4;3;2;3",
        "presentation": "",
        "rating_avg": 6.2,
        "confidence_avg": 3.4,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.8,
        "empirical_novelty_avg": 2.8,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.15309310892394865,
        "corr_rating_correctness": -0.10206207261596578,
        "project": "",
        "github": ""
    },
    {
        "id": "BrPdX1bDZkQ",
        "title": "DemoDICE: Offline Imitation Learning with Supplementary Imperfect Demonstrations",
        "track": "main",
        "status": "Poster",
        "keywords": "imitation learning;offline imitation learning;imperfect demonstration;non-expert demonstration",
        "author": "",
        "aff": "Kim Jaechul Graduate School of AI, KAIST, Daejeon, Republic of Korea; School of Computing, KAIST, Daejeon, Republic of Korea; School of Computing, KAIST, Daejeon, Republic of Korea; Kim Jaechul Graduate School of AI, KAIST, Daejeon, Republic of Korea; Discrete Mathematics Group, Institute for Basic Science (IBS), Daejeon, Republic of Korea; Mila, Quebec AI Institute; School of Computer Science, McGill University; School of Computing, KAIST, Daejeon, Republic of Korea; Kim Jaechul Graduate School of AI, KAIST, Daejeon, Republic of Korea",
        "rating": "8;8;8",
        "confidence": "4;3;3",
        "correctness": "4;3;4",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "3;3;2",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "BrfHcL-99sy",
        "title": "Defending Graph Neural Networks via Tensor-Based Robust Graph Aggregation",
        "track": "main",
        "status": "Reject",
        "keywords": "Graph Neural Networks;Adversarial Attacks;Robustness;Tensor Decomposition",
        "author": "",
        "aff": "",
        "rating": "3;6;6;6",
        "confidence": "4;5;4;4",
        "correctness": "3;4;4;3",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;4;2;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 4.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "BsDYmsrCjr",
        "title": "Scalable Robust Federated Learning with Provable Security Guarantees",
        "track": "main",
        "status": "Reject",
        "keywords": "Federated Learning;Robustness;MPC;Privacy Preserving ML",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "3;4;3;3",
        "correctness": "2;3;4;3",
        "technical_novelty": "3;3;3;2",
        "empirical_novelty": "3;3;3;1",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "Bvk8Dn6Cfy",
        "title": "DaSeGAN: Domain Adaptation for Segmentation Tasks via Generative Adversarial Networks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "1;3;3;5",
        "confidence": "5;5;3;3",
        "correctness": "2;3;4;3",
        "technical_novelty": "1;2;2;3",
        "empirical_novelty": "1;2;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7071067811865476,
        "corr_rating_correctness": 0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "BvowzJp_Yl6",
        "title": "Homogeneous Learning: Self-Attention Decentralized Deep Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "supervised representation learning;reinforcement learning;privacy;decentralized learning;data heterogeneity;communication efficiency",
        "author": "",
        "aff": "",
        "rating": "3;3;5",
        "confidence": "4;4;3",
        "correctness": "2;2;3",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "1;2;2",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "BwPaPxwgyQb",
        "title": "Provable Learning-based Algorithm For Sparse Recovery",
        "track": "main",
        "status": "Poster",
        "keywords": "learning to learn;sparse parameter estimation;learning to optimize;algorithm unrolling;generalization bound",
        "author": "",
        "aff": "School of Mathematics, Georgia Institute of Technology, Atlanta, USA; Machine Learning Department, MBZUAI & BioMap, UAE & China",
        "rating": "5;6;6;8",
        "confidence": "4;4;3;3",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;4;2;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6882472016116854,
        "corr_rating_correctness": 0.9271726499455306,
        "project": "",
        "github": ""
    },
    {
        "id": "By5Uwd_xzNF",
        "title": "Neural Structure Mapping For Learning Abstract Visual Analogies",
        "track": "main",
        "status": "Reject",
        "keywords": "cognitive science;analogy;psychology;cognitive theory;cognition;abstraction;abstract reasoning;generalization;systematic generalization",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5;5",
        "confidence": "5;5;4;4;4",
        "correctness": "2;2;3;3;2",
        "technical_novelty": "1;2;2;3;3",
        "empirical_novelty": "1;2;2;2;2",
        "presentation": "",
        "rating_avg": 4.6,
        "confidence_avg": 4.4,
        "correctness_avg": 2.4,
        "technical_novelty_avg": 2.2,
        "empirical_novelty_avg": 1.8,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6123724356957946,
        "corr_rating_correctness": 0.408248290463863,
        "project": "",
        "github": ""
    },
    {
        "id": "C03Ajc-NS5W",
        "title": "An Autoregressive Flow Model for 3D Molecular Geometry Generation from Scratch",
        "track": "main",
        "status": "Poster",
        "keywords": "3D molecular geometry generation;flow models;SphereNet",
        "author": "",
        "aff": "Department of Computer Science & Engineering, Texas A&M University, College Station, TX 77843, USA",
        "rating": "5;6;6;8",
        "confidence": "3;3;3;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;2;0;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/divelab/DIG"
    },
    {
        "id": "C1_esHN6AVn",
        "title": "Learning Synthetic Environments and Reward Networks for Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "Synthetic Environments;Synthetic Data;Meta-Learning;Reinforcement Learning;Evolution Strategies;Reward Shaping",
        "author": "",
        "aff": "University of Freiburg, Bosch Center for Artificial Intelligence; University of Freiburg",
        "rating": "3;6;6;8",
        "confidence": "3;4;4;3",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;3;4",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.14002800840280097,
        "corr_rating_correctness": 0.7276068751089989,
        "project": "",
        "github": ""
    },
    {
        "id": "C1lXY_T1LTs",
        "title": "Shap-CAM: Visual Explanations for Convolutional Neural Networks based on Shapley Value",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "",
        "confidence": "",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "C4o-EEUx-6",
        "title": "Flashlight: Enabling Innovation in Tools for Machine Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "machine learning;deep learning;systems;frameworks;autograd library;tensor library",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;2;3;4",
        "correctness": "4;3;2;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;1;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.20751433915982243,
        "corr_rating_correctness": -0.6488856845230502,
        "project": "",
        "github": ""
    },
    {
        "id": "C54V-xTWfi",
        "title": "MonoDistill: Learning Spatial Features for Monocular 3D Object Detection",
        "track": "main",
        "status": "Poster",
        "keywords": "3D object detection;monocular images",
        "author": "",
        "aff": "Dalian University of Technology; The University of Sydney",
        "rating": "5;6;8;8;8",
        "confidence": "5;5;4;4;3",
        "correctness": "3;4;3;3;3",
        "technical_novelty": "3;3;2;2;2",
        "empirical_novelty": "3;3;3;3;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 4.2,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8451542547285165,
        "corr_rating_correctness": -0.39528470752104744,
        "project": "",
        "github": "https://github.com/monster-ghost/MonoDistill"
    },
    {
        "id": "C5Q04gnc4f",
        "title": "An object-centric sensitivity analysis of deep learning based instance segmentation",
        "track": "main",
        "status": "Reject",
        "keywords": "robust vision;instance segmentation;deep learning;object-centric;robustness;sensitivity analysis",
        "author": "",
        "aff": "",
        "rating": "3;3;6;6",
        "confidence": "5;2;5;3",
        "correctness": "1;4;3;3",
        "technical_novelty": "1;1;2;2",
        "empirical_novelty": "1;1;2;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 1.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.1924500897298753,
        "corr_rating_correctness": 0.2294157338705618,
        "project": "",
        "github": ""
    },
    {
        "id": "C5u6Z9voQ1",
        "title": "Evaluating the Robustness of Time Series Anomaly and Intrusion Detection Methods against Adversarial Attacks",
        "track": "main",
        "status": "Reject",
        "keywords": "Time series;Anomaly Detection;Intrusion Detection;Adversarial Attack",
        "author": "",
        "aff": "Paper under double-blind review",
        "rating": "5;5;5",
        "confidence": "5;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://anonymous.4open.science/r/ICLR298"
    },
    {
        "id": "C7LB5_Zt_Vp",
        "title": "ZeroLiers: Diminishing Large Outliers in ReLU-like Activations",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Deep Neural Network;Rectified Linear Units;Generalization;Regularization;Dropout",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "4;4;4;4",
        "correctness": "3;3;2;2",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "3;2;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "C7ViqmpuBl",
        "title": "On Learning the Transformer Kernel",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Transformers;Kernel learning",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "5;4;3;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "3;2;2;2",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.899228803025897,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "C81udlH5yMv",
        "title": "Invariant Causal Mechanisms through Distribution Matching",
        "track": "main",
        "status": "Reject",
        "keywords": "representation learning;causality;invariance;distribution matching",
        "author": "",
        "aff": "",
        "rating": "1;3;5",
        "confidence": "5;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "1;2;2",
        "empirical_novelty": "1;2;3",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 1.6666666666666667,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "C8L4I381u2C",
        "title": "On The Transferability of Deep-Q Networks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Transfer Learning;Deep-Q Networks;Model-Free Deep Reinforcement Learning",
        "author": "",
        "aff": "Affiliation; Second Affiliation",
        "rating": "3;3;3;3",
        "confidence": "3;3;4;4",
        "correctness": "3;3;2;2",
        "technical_novelty": "3;2;1;2",
        "empirical_novelty": "2;3;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "C8Ltz08PtBp",
        "title": "Distributional Reinforcement Learning with Monotonic Splines",
        "track": "main",
        "status": "Poster",
        "keywords": "Distributional RL",
        "author": "",
        "aff": "Simon Fraser University; University of Waterloo, Vector Institute; University of Toronto, Vector Institute",
        "rating": "5;6;6;8",
        "confidence": "4;5;5;3",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;2;3;4",
        "empirical_novelty": "2;2;3;4",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 4.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6225430174794673,
        "corr_rating_correctness": 0.6882472016116854,
        "project": "",
        "github": ""
    },
    {
        "id": "CA51pvZJ0xX",
        "title": "Robust Feature Selection using Sparse Centroid-Encoder",
        "track": "main",
        "status": "Reject",
        "keywords": "Feature Selection;Sparse Centroid-encoder;Non-linear feature Selection;Deep Feature Selection;Multi-class Feature Selection;Iterative Feature Selection",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "5;4;3;5",
        "correctness": "4;3;4;3",
        "technical_novelty": "1;2;2;1",
        "empirical_novelty": "1;1;2;1",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 1.5,
        "empirical_novelty_avg": 1.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "CALFyKVs87",
        "title": "Dynamics-Aware Comparison of Learned Reward Functions",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Reward Learning;Inverse Reinforcement Learning;Reinforcement Learning;Comparing Reward Functions",
        "author": "",
        "aff": "Toyota Research Institute (TRI); University of California, Berkeley",
        "rating": "5;6;8;8",
        "confidence": "3;3;3;3",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "3;3;4;3",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 3.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9622504486493761,
        "project": "https://sites.google.com/view/dard-paper",
        "github": ""
    },
    {
        "id": "CAjxVodl_v",
        "title": "Generalized Decision Transformer for Offline Hindsight Information Matching",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Hindsight Information Matching;Decision Transformer;State-Marginal Matching;Hindsight Experience Replay;Reinforcement Learning",
        "author": "",
        "aff": "The University of Tokyo; Google Research",
        "rating": "6;8;8",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 7.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "CBchIgBBrwj",
        "title": "Objective Evaluation of Deep Visual Interpretations on Time Series Data",
        "track": "main",
        "status": "Reject",
        "keywords": "explainable ai;deep learning;time series;visual interpretation;evaluation metrics;classification;segmentation",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "4;2;2;4",
        "correctness": "2;4;4;3",
        "technical_novelty": "1;2;2;2",
        "empirical_novelty": "1;2;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.40824829046386296,
        "corr_rating_correctness": 0.7385489458759963,
        "project": "",
        "github": ""
    },
    {
        "id": "CC-BbehJKTe",
        "title": "Building the Building Blocks: From Simplification to Winning Trees in Genetic Programming",
        "track": "main",
        "status": "Reject",
        "keywords": "Genetic Programming;Building Blocks;Regression;Bloat;Experimental evaluation",
        "author": "",
        "aff": "",
        "rating": "1;3;3;3",
        "confidence": "5;5;4;3",
        "correctness": "1;2;2;3",
        "technical_novelty": "1;2;2;2",
        "empirical_novelty": "1;2;2;2",
        "presentation": "",
        "rating_avg": 2.5,
        "confidence_avg": 4.25,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5222329678670935,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "CCu6RcUMwK0",
        "title": "Neural Link Prediction with Walk Pooling",
        "track": "main",
        "status": "Poster",
        "keywords": "Graph neural network;Link prediction;Random walk;Graph topology.",
        "author": "",
        "aff": "Departement Mathematik und Informatik, Universit\u00a8 at Basel, 4051 Basel, Switzerland.; School of Computer and Electronic Information, Nanjing Normal University, 210023 Nanjing, China.",
        "rating": "5;6;6;8",
        "confidence": "4;4;4;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "1;3;3;3",
        "empirical_novelty": "1;2;3;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.6622661785325219,
        "project": "",
        "github": ""
    },
    {
        "id": "CD_gGnX9RnD",
        "title": "Early-Stopping for Meta-Learning: Estimating Generalization from the Activation Dynamics",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Meta-Learning;Generalization;Early-Stopping;Out-of-Distribution",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "3;4;4;4",
        "correctness": "3;2;3;4",
        "technical_novelty": "2;1;3;1",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "CES-KyrKcTM",
        "title": "The weighted mean trick \u2013 optimization strategies for robustness",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "1;3;5;6",
        "confidence": "3;4;3;4",
        "correctness": "2;4;3;4",
        "technical_novelty": "1;2;2;3",
        "empirical_novelty": "0;2;2;3",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.39056673294247163,
        "corr_rating_correctness": 0.6673083711820306,
        "project": "",
        "github": ""
    },
    {
        "id": "CI-xXX9dg9l",
        "title": "On Distributed Adaptive Optimization with Gradient Compression",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "Cognitive Computing Lab, Baidu Research, 10900 NE 8th St. Bellevue, WA 98004, USA",
        "rating": "5;8;8",
        "confidence": "3;2;3",
        "correctness": "4;4;4",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "CIaQKbTBwtU",
        "title": "Learning to Generalize across Domains on Single Test Samples",
        "track": "main",
        "status": "Poster",
        "keywords": "domain generalization;single test sample generalization;meta learning;variational inference",
        "author": "",
        "aff": "National Center for Artificial Intelligence, Saudi Data and Artificial Intelligence Authority; Inception Institute of Artificial Intelligence; AIM Lab, University of Amsterdam",
        "rating": "5;5;8;8;8",
        "confidence": "3;3;4;4;4",
        "correctness": "3;4;3;3;4",
        "technical_novelty": "3;3;2;3;3",
        "empirical_novelty": "3;2;2;2;3",
        "presentation": "",
        "rating_avg": 6.8,
        "confidence_avg": 3.6,
        "correctness_avg": 3.4,
        "technical_novelty_avg": 2.8,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": 1.0,
        "corr_rating_correctness": -0.16666666666666669,
        "project": "",
        "github": "https://github.com/zzzx1224/SingleSampleGeneralization-ICLR2022"
    },
    {
        "id": "CJzi3dRlJE-",
        "title": "Connectome-constrained Latent Variable Model of Whole-Brain Neural Activity",
        "track": "main",
        "status": "Poster",
        "keywords": "connectome;latent-variable model;variational autoencoder;biophysics;whole-brain;neural activity;calcium imaging;caenorhabditis elegans;voltage;generative model;inference network",
        "author": "",
        "aff": "Harvard University; MIT; HHMI Janelia Research Campus",
        "rating": "3;6;8;8",
        "confidence": "4;4;3;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;3;2;2",
        "empirical_novelty": "1;3;3;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.49374193110101877,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "CLpxpXqqBV",
        "title": "Learning State Representations via Retracing in Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "Representation learning;model-based reinforcement learning",
        "author": "",
        "aff": "Huawei Noah\u2019s Ark Lab; College of Intelligence and Computing, Tianjin University; UCL, London, United Kingdom",
        "rating": "3;5;6;8",
        "confidence": "4;3;3;3",
        "correctness": "2;3;4;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8006407690254357,
        "corr_rating_correctness": 0.5883484054145521,
        "project": "",
        "github": ""
    },
    {
        "id": "CNY9h3uyfiO",
        "title": "Reward Shifting for Optimistic Exploration and Conservative Exploitation",
        "track": "main",
        "status": "Reject",
        "keywords": "Reward Shift;Reinforcement Learning;Batch RL;Offline RL;Online RL;Curiosity-Driven Method",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "4;3;3;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.19245008972987526,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "CO0ZuH5vaMu",
        "title": "Using Document Similarity Methods to create Parallel Datasets for Code Translation",
        "track": "main",
        "status": "Reject",
        "keywords": "code translation;machine translation;document similarity",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;3;5",
        "correctness": "4;2;3;4",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.30151134457776363,
        "project": "",
        "github": ""
    },
    {
        "id": "CQzlxFVcmw1",
        "title": "Message Function Search for Hyper-relational Knowledge Graph",
        "track": "main",
        "status": "Reject",
        "keywords": "Graph Neural Network;Hyper-relational Knowledge Graph;Knowledge Base Embedding",
        "author": "",
        "aff": "",
        "rating": "5;6;6",
        "confidence": "4;3;3",
        "correctness": "3;4;4",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 5.666666666666667,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9999999999999997,
        "corr_rating_correctness": 0.9999999999999997,
        "project": "",
        "github": ""
    },
    {
        "id": "CS4463zx6Hi",
        "title": "Geometric Transformers for Protein Interface Contact Prediction",
        "track": "main",
        "status": "Poster",
        "keywords": "Geometric Deep Learning;Graph Transformers;Protein Bioinformatics;Invariance",
        "author": "",
        "aff": "Department of Electrical Engineering & Computer Science, University of Missouri, Columbia, MO 65211, USA",
        "rating": "5;6;6;6",
        "confidence": "2;5;4;4",
        "correctness": "3;4;4;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "1;3;3;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9271726499455306,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": "https://github.com/BioinfoMachineLearning/DeepInteract"
    },
    {
        "id": "CSfcOznpDY",
        "title": "Recursive Disentanglement Network",
        "track": "main",
        "status": "Poster",
        "keywords": "disentanglement;representation learning;compositional",
        "author": "",
        "aff": "School of Microelectronics, Fudan University, Shanghai, China; Microsoft Research Asia, Shanghai, China; Department of Electrical Engineering and Computer Science, University of Michigan, Michigan, United States; Department of Computer Science, University of Colorado Boulder, Boulder, United States; Department of Computing, Imperial College London, London, United Kingdom; China and Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University, Shanghai, China",
        "rating": "6;6;6;6",
        "confidence": "5;4;3;3",
        "correctness": "3;4;4;4",
        "technical_novelty": "3;3;3;4",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "CSw5zgTjXyb",
        "title": "Learning to Collaborate",
        "track": "main",
        "status": "Reject",
        "keywords": "collaboration equilibrium",
        "author": "",
        "aff": "",
        "rating": "3;5;5;8",
        "confidence": "2;3;4;2",
        "correctness": "4;4;3;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 2.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.1266600992762247,
        "corr_rating_correctness": 0.08084520834544431,
        "project": "",
        "github": ""
    },
    {
        "id": "CTOJRqLMsl",
        "title": "On the Convergence of Nonconvex Continual Learning with Adaptive Learning Rate",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5;8",
        "confidence": "4;3;3;3",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "3;3;2;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7276068751089989,
        "corr_rating_correctness": 0.8892972917998875,
        "project": "",
        "github": ""
    },
    {
        "id": "CTvr5sjVi2_",
        "title": "Training with Worst-Case Distributional Shift causes Overestimation and Inaccuracies in State-Action Value Functions",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5",
        "confidence": "4;5;4",
        "correctness": "2;4;3",
        "technical_novelty": "2;3;2",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 4.333333333333333,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.4999999999999999,
        "corr_rating_correctness": 0.8660254037844385,
        "project": "",
        "github": ""
    },
    {
        "id": "CVfLvQq9gLo",
        "title": "ARTEMIS: Attention-based Retrieval with Text-Explicit Matching and Implicit Similarity",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "NAVER LABS Europe",
        "rating": "6;8;8",
        "confidence": "4;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "2;3;2",
        "empirical_novelty": "0;4;2",
        "presentation": "",
        "rating_avg": 7.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9999999999999998,
        "project": "",
        "github": "https://github.com/naver/artemis"
    },
    {
        "id": "CZZ7KWOP0-M",
        "title": "ShiftAddNAS: Hardware-Inspired Search for More Accurate and Efficient Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "Neural Architecture Search;Bit-wise Shift and Add;Hardware Acceleration;Multiplication-Reduced Networks",
        "author": "",
        "aff": "",
        "rating": "5;6;6;6",
        "confidence": "4;5;4;3",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "C_RTGckbu-A",
        "title": "Multi-Subspace Structured Meta-Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "meta-learning",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "4;3;4;4",
        "correctness": "2;2;2;3",
        "technical_novelty": "3;2;2;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.75,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "C_vsGwEIjAr",
        "title": "Trivial or Impossible --- dichotomous data difficulty masks model differences (on ImageNet and beyond)",
        "track": "main",
        "status": "Poster",
        "keywords": "CNNs;Cognitive Science;Vision Science;Psychophysics;Neuroscience;Visual perception;Inductive bias;ImageNet;CIFAR;RSA;Representation similarity analysis;Error consistency;Datasets",
        "author": "",
        "aff": "University of T\u00fcbingen; University of T\u00fcbingen & IMPRS-IS",
        "rating": "6;6;6;8",
        "confidence": "3;5;5;3",
        "correctness": "2;4;4;4",
        "technical_novelty": "3;4;3;4",
        "empirical_novelty": "3;3;3;4",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.5,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "CdBDMQkx3hU",
        "title": "DAAS: Differentiable Architecture and Augmentation Policy Search",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5",
        "confidence": "4;5;5;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "3;3;2;2",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "CdNRpVj215",
        "title": "Towards Non-Parametric Models for Confidence Aware Video Prediction on Smooth Dynamics",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Video Prediction;Non-Parametric Models;Gaussian Processes;Confidence Aware",
        "author": "",
        "aff": "",
        "rating": "3;3;3",
        "confidence": "3;2;4",
        "correctness": "3;3;4",
        "technical_novelty": "3;1;1",
        "empirical_novelty": "2;1;1",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 1.6666666666666667,
        "empirical_novelty_avg": 1.3333333333333333,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "CdqsSPLNx-",
        "title": "Deep Dynamic Attention Model with Gate Mechanism for Solving Time-dependent Vehicle Routing Problems",
        "track": "main",
        "status": "Desk Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "",
        "confidence": "",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "CgIEctmcXx1",
        "title": "ADAVI: Automatic Dual Amortized Variational Inference Applied To Pyramidal Bayesian Models",
        "track": "main",
        "status": "Poster",
        "keywords": "Bayesian inference;Hierarchical Bayesian Models;structured Variational Inference;Simulation Based Inference;Inference amortization;Neuroimaging",
        "author": "",
        "aff": "Universit \u00b4e Paris-Saclay, Inria, CEA, Palaiseau, 91120, France",
        "rating": "5;5;6;6",
        "confidence": "3;3;2;5",
        "correctness": "3;3;4;4",
        "technical_novelty": "3;3;4;2",
        "empirical_novelty": "2;2;0;0",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 1.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.22941573387056177,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "CgV7NVOgDJZ",
        "title": "Guided-TTS:Text-to-Speech with Untranscribed Speech",
        "track": "main",
        "status": "Reject",
        "keywords": "Text-to-Speech;Speech Synthesis;DDPM;TTS;Untranscribed speech",
        "author": "",
        "aff": "",
        "rating": "3;5;5;8",
        "confidence": "4;5;4;4",
        "correctness": "3;2;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "1;3;3;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.08084520834544431,
        "corr_rating_correctness": 0.08084520834544431,
        "project": "",
        "github": ""
    },
    {
        "id": "ChKNCDB0oYj",
        "title": "Mistake-driven Image Classification with FastGAN and SpinalNet",
        "track": "main",
        "status": "Reject",
        "keywords": "Deep Learning;Data Augmentation;Image Classification;Supervised Learning;Generative models",
        "author": "",
        "aff": "",
        "rating": "1;3;3",
        "confidence": "5;5;4",
        "correctness": "3;3;4",
        "technical_novelty": "2;1;1",
        "empirical_novelty": "2;2;1",
        "presentation": "",
        "rating_avg": 2.3333333333333335,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 1.3333333333333333,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4999999999999999,
        "corr_rating_correctness": 0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "ChMLTGRjFcU",
        "title": "How many degrees of freedom do we need to train deep networks: a loss landscape perspective",
        "track": "main",
        "status": "Poster",
        "keywords": "loss landscape;high-dimensional geometry;random hyperplanes;optimization",
        "author": "",
        "aff": "Stanford University; Stanford University | Meta AI",
        "rating": "6;6;6;8",
        "confidence": "4;4;4;4",
        "correctness": "4;4;3;4",
        "technical_novelty": "3;4;3;4",
        "empirical_novelty": "3;3;3;4",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.5,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "Ck_iw4jMC4l",
        "title": "Logical Activation Functions: Logit-space equivalents of Boolean Operators",
        "track": "main",
        "status": "Reject",
        "keywords": "activation functions;logits",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "3;3;4;3",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;2;3;4",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.7777777777777777,
        "project": "",
        "github": ""
    },
    {
        "id": "Clre-Prt128",
        "title": "Complex-valued deep learning with differential privacy",
        "track": "main",
        "status": "Reject",
        "keywords": "Differential privacy;complex-valued deep learning",
        "author": "",
        "aff": "",
        "rating": "5;6;8",
        "confidence": "4;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "2;2;4",
        "empirical_novelty": "2;4;4",
        "presentation": "",
        "rating_avg": 6.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 3.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.18898223650461363,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "Cm08egNmrl3",
        "title": "BLOOD: Bi-level Learning Framework for Out-of-distribution Generalization",
        "track": "main",
        "status": "Reject",
        "keywords": "Out-of-Distribution Generalization;Generalization;Spurious Correlations;Bi-level Optimization",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "3;4;4;4",
        "correctness": "2;3;2;3",
        "technical_novelty": "1;1;3;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.75,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 1.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "CmsfC7u054S",
        "title": "Reinforcement Learning in Presence of Discrete Markovian Context Evolution",
        "track": "main",
        "status": "Poster",
        "keywords": "context-dependent Reinforcement Learning;model-based reinforcement learning;hierarchical Dirichlet process",
        "author": "",
        "aff": "Huawei UK R&D; Huawei UK R&D and Honorary Lecturer at UCL; Huawei UK R&D, University of Cambridge; University College London",
        "rating": "6;6;6;8;8",
        "confidence": "4;4;3;3;2",
        "correctness": "4;3;3;3;4",
        "technical_novelty": "3;3;2;4;3",
        "empirical_novelty": "2;2;2;3;0",
        "presentation": "",
        "rating_avg": 6.8,
        "confidence_avg": 3.2,
        "correctness_avg": 3.4,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 1.8,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7637626158259733,
        "corr_rating_correctness": 0.16666666666666663,
        "project": "",
        "github": ""
    },
    {
        "id": "CoMOKHYWf2",
        "title": "AdaFocal: Calibration-aware Adaptive Focal Loss",
        "track": "main",
        "status": "Reject",
        "keywords": "neural networks;uncertainity calibration;out of distribution detection",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "3;3;3;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "3;3;4;4",
        "empirical_novelty": "3;2;3;4",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.5,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "CpTuR2ECuW",
        "title": "LIGS: Learnable Intrinsic-Reward Generation Selection for Multi-Agent Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "multi-agent;reinforcement learning;intrinsic rewards;exploration",
        "author": "",
        "aff": "Institute for AI, Peking University & BIGAI; University College London; Huawei Technologies; Shanghaitech University; Imperial College London",
        "rating": "5;5;6;8",
        "confidence": "4;4;4;3",
        "correctness": "3;3;3;4",
        "technical_novelty": "3;3;3;4",
        "empirical_novelty": "3;2;0;4",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9428090415820632,
        "corr_rating_correctness": 0.9428090415820632,
        "project": "",
        "github": ""
    },
    {
        "id": "CpgtwW8GBxe",
        "title": "Label Refining: a semi-supervised method to extract voice characteristics without ground truth",
        "track": "main",
        "status": "Reject",
        "keywords": "characteristics;characteristics extraction;characteristics evaluation;voice characteristics;label refining;refined labels;semi-supervision",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3;5",
        "confidence": "3;4;3;3;3",
        "correctness": "3;2;2;2;3",
        "technical_novelty": "1;2;2;1;3",
        "empirical_novelty": "1;2;2;1;2",
        "presentation": "",
        "rating_avg": 3.4,
        "confidence_avg": 3.2,
        "correctness_avg": 2.4,
        "technical_novelty_avg": 1.8,
        "empirical_novelty_avg": 1.6,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.25,
        "corr_rating_correctness": 0.6123724356957946,
        "project": "",
        "github": ""
    },
    {
        "id": "CrCvGNHAIrz",
        "title": "Explainable GNN-Based Models over Knowledge Graphs",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "Department of Informatics, University of Oslo, Norway; Department of Computer Science, University of Oxford, UK",
        "rating": "5;6;6;8",
        "confidence": "4;4;4;3",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9271726499455306,
        "corr_rating_correctness": 0.6882472016116854,
        "project": "",
        "github": ""
    },
    {
        "id": "CrXLp_yeA-K",
        "title": "Conversational Artificial Intelligence in Natural Language Processing Application with Lifelong Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Conversational AI;Lifelong Learning;Machine Learning;Natural Language Processing;Neural Network.",
        "author": "",
        "aff": "",
        "rating": "1;1;1;1;3",
        "confidence": "5;5;4;4;4",
        "correctness": "2;1;1;2;2",
        "technical_novelty": "1;1;1;1;2",
        "empirical_novelty": "1;1;1;1;1",
        "presentation": "",
        "rating_avg": 1.4,
        "confidence_avg": 4.4,
        "correctness_avg": 1.6,
        "technical_novelty_avg": 1.2,
        "empirical_novelty_avg": 1.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.40824829046386296,
        "corr_rating_correctness": 0.4082482904638631,
        "project": "",
        "github": ""
    },
    {
        "id": "Ctjb37IOldV",
        "title": "A Variance Principle Explains why Dropout Finds Flatter Minima",
        "track": "main",
        "status": "Reject",
        "keywords": "dropout;stochastic gradient descent;loss landscape;flatness;neural network",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5",
        "confidence": "5;2;3;2",
        "correctness": "3;2;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "3;2;2;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "CuV_qYkmKb3",
        "title": "Scarf: Self-Supervised Contrastive Learning using Random Feature Corruption",
        "track": "main",
        "status": "Spotlight",
        "keywords": "self-supervised learning;tabular data;pre-training;contrastive learning;openML",
        "author": "",
        "aff": "Google Research",
        "rating": "6;6;8;8",
        "confidence": "4;4;4;4",
        "correctness": "3;4;4;3",
        "technical_novelty": "3;2;2;3",
        "empirical_novelty": "3;3;4;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "CxebB5Psl1",
        "title": "Graph Similarities and Dual Approach for Sequential Text-to-Image Retrieval",
        "track": "main",
        "status": "Reject",
        "keywords": "sequential text-to-image retrieval;story-to-image retrieval;scene graph embedding;dual learning",
        "author": "",
        "aff": "",
        "rating": "1;3;5",
        "confidence": "5;5;3",
        "correctness": "2;2;4",
        "technical_novelty": "1;2;3",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8660254037844385,
        "corr_rating_correctness": 0.8660254037844387,
        "project": "",
        "github": ""
    },
    {
        "id": "Cy0n0WCvLPU",
        "title": "Topic Aware Neural Language Model: Domain Adaptation of Unconditional Text Generation Models",
        "track": "main",
        "status": "Reject",
        "keywords": "Neural language models;Unconditional Text Generation;Transformer",
        "author": "",
        "aff": "",
        "rating": "1;5;5",
        "confidence": "2;3;2",
        "correctness": "2;3;3",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "1;2;3",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.4999999999999999,
        "corr_rating_correctness": 0.9999999999999997,
        "project": "",
        "github": ""
    },
    {
        "id": "CyKHoKyvgnp",
        "title": "Transition to Linearity of Wide Neural Networks is an Emerging Property of Assembling Weak Models",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Assembling;linearity;Transition to linearity;wide neural networks",
        "author": "",
        "aff": "HDSI, UC, San Diego; Depart. of Computer Science, UC, San Diego; Depart. of Computer Science, Ohio State University",
        "rating": "6;8;8",
        "confidence": "2;3;3",
        "correctness": "3;4;4",
        "technical_novelty": "2;4;3",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 7.333333333333333,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9999999999999998,
        "corr_rating_correctness": 0.9999999999999998,
        "project": "",
        "github": ""
    },
    {
        "id": "CyKQiiCPBEv",
        "title": "Stepping Back to SMILES Transformers for Fast Molecular Representation Inference",
        "track": "main",
        "status": "Reject",
        "keywords": "molecular representation learning;knowledge distillation",
        "author": "",
        "aff": "",
        "rating": "3;5;5;8",
        "confidence": "4;3;4;4",
        "correctness": "4;3;2;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;2;0;4",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.08084520834544431,
        "corr_rating_correctness": 0.1266600992762247,
        "project": "",
        "github": ""
    },
    {
        "id": "CyhUPn9RDT3",
        "title": "IQNAS: Interpretable Integer Quadratic programming Neural Architecture Search",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Neural Architecture Search",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5;5",
        "confidence": "4;4;3;4;4",
        "correctness": "3;3;3;3;4",
        "technical_novelty": "2;3;3;2;2",
        "empirical_novelty": "2;3;3;2;2",
        "presentation": "",
        "rating_avg": 4.6,
        "confidence_avg": 3.8,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.25000000000000006,
        "corr_rating_correctness": 0.2500000000000001,
        "project": "",
        "github": ""
    },
    {
        "id": "CzceR82CYc",
        "title": "Score-Based Generative Modeling with Critically-Damped Langevin Diffusion",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Score-based generative modeling;denoising diffusion models;image synthesis",
        "author": "",
        "aff": "NVIDIA, University of Waterloo, Vector Institute; NVIDIA",
        "rating": "8;8;8;10",
        "confidence": "3;4;4;5",
        "correctness": "4;3;3;4",
        "technical_novelty": "4;4;4;4",
        "empirical_novelty": "4;3;3;4",
        "presentation": "",
        "rating_avg": 8.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 4.0,
        "empirical_novelty_avg": 3.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.816496580927726,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "https://nv-tlabs.github.io/CLD-SGM",
        "github": "https://github.com/nv-tlabs/CLD-SGM"
    },
    {
        "id": "Czsdv-S4-w9",
        "title": "Generating Videos with Dynamics-aware Implicit Generative Adversarial Networks",
        "track": "main",
        "status": "Poster",
        "keywords": "video generation;implicit neural representations;generative adversarial networks",
        "author": "",
        "aff": "Korea Advanced Institute of Science and Technology (KAIST); NAVER AI Lab",
        "rating": "5;6;8;10",
        "confidence": "4;4;4;5",
        "correctness": "3;4;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 7.25,
        "confidence_avg": 4.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8268106308031117,
        "corr_rating_correctness": 0.676481425202546,
        "project": "https://sihyun-yu.github.io/digan/",
        "github": "https://github.com/sihyun-yu/digan"
    },
    {
        "id": "D1TYemnoRN",
        "title": "Short optimization paths lead to good generalization",
        "track": "main",
        "status": "Reject",
        "keywords": "optimization;generalization;machine learning theory",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "4;4;3;3",
        "correctness": "3;4;4;3",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "D1hTwPPmMVv",
        "title": "Enhanced countering adversarial attacks via input denoising and feature restoring",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;4;4;3",
        "correctness": "2;2;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.75,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": "https://github.com/ID-FR/IDFR"
    },
    {
        "id": "D637S6zBRLD",
        "title": "Learning Symmetric Representations for Equivariant World Models",
        "track": "main",
        "status": "Reject",
        "keywords": "equivariant;symmetry;contrastive loss;world models;transition;representation theory;generalization",
        "author": "",
        "aff": "",
        "rating": "6;6;6;6",
        "confidence": "3;4;3;2",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;1;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "D6nH3719vZy",
        "title": "On Improving Adversarial Transferability of Vision Transformers",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Vision Transformers;Adversarial Perturbations",
        "author": "",
        "aff": "Mohamed bin Zayed University of AI; Qualcomm USA; Stony Brook University; Link\u00f6ping University",
        "rating": "6;8;8;8",
        "confidence": "4;5;3;3",
        "correctness": "4;4;3;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;3;4",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.17407765595569782,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": "https://t.ly/hBbW"
    },
    {
        "id": "D78Go4hVcxO",
        "title": "How Do Vision Transformers Work?",
        "track": "main",
        "status": "Spotlight",
        "keywords": "vision transformer;self-attention;multi-head self-attention;loss landscape",
        "author": "",
        "aff": "Yonsei University; Yonsei University, NAVER AI Lab",
        "rating": "5;8;8;8",
        "confidence": "4;3;4;3",
        "correctness": "2;4;4;3",
        "technical_novelty": "3;2;3;4",
        "empirical_novelty": "2;4;4;4",
        "presentation": "",
        "rating_avg": 7.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.8703882797784892,
        "project": "",
        "github": ""
    },
    {
        "id": "D7hX1d3ov2c",
        "title": "Ensembles and Encoders for Task-Free Continual Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "continual learning;task-free continual learning;self-supervised learning;pre-training;ensemble methods",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;3;4;5",
        "correctness": "2;3;3;3",
        "technical_novelty": "1;2;2;3",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.7071067811865475,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "D8njK_Ix5dJ",
        "title": "Maximum Mean Discrepancy for Generalization in the Presence of Distribution and Missingness Shift",
        "track": "main",
        "status": "Reject",
        "keywords": "maximum mean discrepancy;data shift;covariate shift;representation learning;missing data",
        "author": "",
        "aff": "Paper under double-blind review",
        "rating": "3;3;3;3",
        "confidence": "3;5;4;2",
        "correctness": "3;4;2;3",
        "technical_novelty": "2;2;1;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "D8pn0BlHaGe",
        "title": "Single-Cell Capsule Attention : an interpretable method of cell type classification for single-cell RNA-sequencing data",
        "track": "main",
        "status": "Reject",
        "keywords": "Single-Cell RNA-sequencing;cell type classification;capsule network;attention;interpretable model",
        "author": "",
        "aff": "",
        "rating": "1;1;3;3",
        "confidence": "3;4;4;5",
        "correctness": "4;2;3;2",
        "technical_novelty": "2;1;2;1",
        "empirical_novelty": "1;1;2;2",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 1.5,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.7071067811865475,
        "corr_rating_correctness": -0.30151134457776363,
        "project": "",
        "github": ""
    },
    {
        "id": "D9E8MKsfhw",
        "title": "An Empirical Investigation of the Role of Pre-training in Lifelong Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Lifelong Learning;Continual Learning;Catastrophic Forgetting;Pre-training",
        "author": "",
        "aff": "",
        "rating": "5;5;6",
        "confidence": "4;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "2;3;2",
        "empirical_novelty": "2;3;2",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9999999999999997,
        "project": "",
        "github": ""
    },
    {
        "id": "D9SuLzhgK9",
        "title": "Adam is no better than normalized SGD: Dissecting how adaptivity improves GAN performance",
        "track": "main",
        "status": "Reject",
        "keywords": "Generative adversarial networks;non-convex optimization",
        "author": "",
        "aff": "",
        "rating": "5;5;8",
        "confidence": "3;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "2;4;4",
        "empirical_novelty": "2;3;4",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 3.3333333333333335,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5,
        "corr_rating_correctness": 0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "D9hpqJyXAi",
        "title": "Open-sampling: Re-balancing Long-tailed Datasets with Out-of-Distribution Data",
        "track": "main",
        "status": "Withdraw",
        "keywords": "long-tailed recognition;Out-of-Distribution;open-set noisy labels;deep learning",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;3;5;3",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3458572319330373,
        "corr_rating_correctness": 0.9271726499455306,
        "project": "",
        "github": ""
    },
    {
        "id": "DBOibe1ISzB",
        "title": "SiT: Simulation Transformer for Particle-based Physics Simulation",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;6;6",
        "confidence": "4;4;3;3",
        "correctness": "2;2;3;3",
        "technical_novelty": "3;2;3;2",
        "empirical_novelty": "3;2;3;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "DBiQQYWykyy",
        "title": "Environment Predictive Coding for Visual Navigation",
        "track": "main",
        "status": "Poster",
        "keywords": "Self-supervised learning;visual navigation;representation learning",
        "author": "",
        "aff": "The University of Texas at Austin, Facebook AI Research; The University of Texas at Austin",
        "rating": "6;8;8;8",
        "confidence": "2;5;5;4",
        "correctness": "4;3;3;3",
        "technical_novelty": "3;2;2;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9428090415820632,
        "corr_rating_correctness": -1.0,
        "project": "",
        "github": "https://vision.cs.utexas.edu/projects/epc/"
    },
    {
        "id": "DF4ebNexXta",
        "title": "Fine-Tuning from Limited Feedbacks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Fine-tuning;Query-feedback;Transfer learning;Weakly supervised learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5",
        "confidence": "4;4;4",
        "correctness": "2;1;3",
        "technical_novelty": "1;1;2",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 4.0,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 1.3333333333333333,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.8660254037844387,
        "project": "",
        "github": ""
    },
    {
        "id": "DFYtZFo_1u",
        "title": "Federated Inference through Aligning Local Representations and Learning a Consensus Graph",
        "track": "main",
        "status": "Reject",
        "keywords": "Federated inference;local latent representation;feature alignment;graph structure learning;Gumbel softmax",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "4;5;5;3",
        "correctness": "2;2;2;3",
        "technical_novelty": "3;1;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.25,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "DHLngM1mR3W",
        "title": "AAVAE: Augmentation-Augmented Variational Autoencoders",
        "track": "main",
        "status": "Reject",
        "keywords": "Self-Supervised Learning;Autoencoders;Variational Autoencoders;Data Augmentation",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5;5",
        "confidence": "5;5;4;3;4",
        "correctness": "4;1;2;2;3",
        "technical_novelty": "2;1;2;3;3",
        "empirical_novelty": "2;1;3;2;3",
        "presentation": "",
        "rating_avg": 3.8,
        "confidence_avg": 4.2,
        "correctness_avg": 2.4,
        "technical_novelty_avg": 2.2,
        "empirical_novelty_avg": 2.2,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7637626158259733,
        "corr_rating_correctness": 0.08006407690254354,
        "project": "",
        "github": ""
    },
    {
        "id": "DIjCrlsu6Z",
        "title": "Controlling Directions Orthogonal to a Classifier",
        "track": "main",
        "status": "Spotlight",
        "keywords": "orthogonal classifier;invariance",
        "author": "",
        "aff": "Computer Science and Artificial Intelligence Lab, Massachusetts Institute of Technology",
        "rating": "6;8;8",
        "confidence": "3;4;3",
        "correctness": "3;4;4",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 7.333333333333333,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.49999999999999983,
        "corr_rating_correctness": 0.9999999999999998,
        "project": "",
        "github": "https://github.com/Newbeeer/orthogonal_classifier"
    },
    {
        "id": "DIsWHvtU7lF",
        "title": "Composing Partial Differential Equations with Physics-Aware Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "physics-aware neural networks;partial differential equations;advection-diffusion equations;learning constituents;out-of-distribution generalization",
        "author": "",
        "aff": "",
        "rating": "3;6;6;6",
        "confidence": "3;2;3;4",
        "correctness": "4;3;4;3",
        "technical_novelty": "3;3;2;3",
        "empirical_novelty": "2;3;0;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "DNRADop4ksB",
        "title": "On the Importance of Firth Bias Reduction in Few-Shot Classification",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Few-shot Classification;Firth Regularization;MLE Bias",
        "author": "",
        "aff": "Department of Computer Science, University of Illinois Urbana-Champaign",
        "rating": "6;8;8;8",
        "confidence": "4;5;3;3",
        "correctness": "4;3;4;4",
        "technical_novelty": "3;4;4;3",
        "empirical_novelty": "3;4;3;3",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.5,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.17407765595569782,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": "https://github.com/ehsansaleh/firth_bias_reduction"
    },
    {
        "id": "DOrrKPEDnBp",
        "title": "The Impact of Spatiotemporal Augmentations on Self-Supervised Audiovisual Representation Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Representation Learning;Audiovisual;Self-Supervised Learning;Spatiotemporal Augmentations",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "5;4;3;4",
        "correctness": "2;3;3;2",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7071067811865475,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "DSCsslei9r",
        "title": "Multi-modal Self-supervised Pre-training for Regulatory Genome Across Cell Types",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "1;3;6;6",
        "confidence": "5;5;4;4",
        "correctness": "2;4;3;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "0;1;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9428090415820635,
        "corr_rating_correctness": 0.5685352436149612,
        "project": "",
        "github": ""
    },
    {
        "id": "DSQHjibtgKR",
        "title": "Online Facility Location with Predictions",
        "track": "main",
        "status": "Poster",
        "keywords": "online algorithms;facility location;prediction;learning-augmented",
        "author": "",
        "aff": "Peking University; Shanghai Jiao Tong University; Shanghai University of Finance and Economics",
        "rating": "6;6;6;6;8;8",
        "confidence": "4;4;5;4;4;4",
        "correctness": "3;4;4;4;4;4",
        "technical_novelty": "3;3;3;3;3;3",
        "empirical_novelty": "2;4;1;2;2;3",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 4.166666666666667,
        "correctness_avg": 3.8333333333333335,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.31622776601683794,
        "corr_rating_correctness": 0.31622776601683805,
        "project": "",
        "github": ""
    },
    {
        "id": "DTXZqTNV5nW",
        "title": "Actor-Critic Policy Optimization in a Large-Scale Imperfect-Information Game",
        "track": "main",
        "status": "Poster",
        "keywords": "Policy Optimization;Nash Equilibrium;Mahjong AI",
        "author": "",
        "aff": "Peking University, Beijing, China; University of Science and Technology of China, Hefei, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; Tencent AI Lab, Shenzhen, China; Institute of Automation, Chinese Academy of Sciences, Beijing, China",
        "rating": "5;6;8;8",
        "confidence": "3;5;5;4",
        "correctness": "4;4;4;4",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "3;2;3;4",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 4.25,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5222329678670935,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "DTg98fkyoyn",
        "title": "Unsupervised Contrastive Learning for Signal-Dependent Noise Synthesis",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Noise Synthesis;Self-Supervised Learning;Contrastive Learning",
        "author": "",
        "aff": "",
        "rating": "1;5;5",
        "confidence": "4;3;3",
        "correctness": "1;3;3",
        "technical_novelty": "1;3;3",
        "empirical_novelty": "1;2;2",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9999999999999997,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "DTkEfj0Ygb8",
        "title": "Learning meta-features for AutoML",
        "track": "main",
        "status": "Spotlight",
        "keywords": "AutoML;Meta-features;Hyper-parameter Optimization;Optimal Transport",
        "author": "",
        "aff": "TAU, LISN-CNRS\u2013INRIA, Universit\u00e9 Paris-Saclay, Orsay, France; MISA, LMI, Universit\u00e9 d\u2019Antananarivo, Ankatso, Madagascar",
        "rating": "5;6;6;8;8",
        "confidence": "2;3;3;4;4",
        "correctness": "3;3;3;4;3",
        "technical_novelty": "2;3;3;3;4",
        "empirical_novelty": "3;3;3;3;3",
        "presentation": "",
        "rating_avg": 6.6,
        "confidence_avg": 3.2,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9799578870122229,
        "corr_rating_correctness": 0.5833333333333334,
        "project": "",
        "github": "https://github.com/luxusg1/metabu"
    },
    {
        "id": "DVSN9nJB1_",
        "title": "E-LANG: Energy-based Joint Inferencing of Super and Swift Language Models",
        "track": "main",
        "status": "Desk Reject",
        "keywords": "energy-based models;dynamic inference;joint language models;super model optimization;NLP;BERT;T5",
        "author": "",
        "aff": "",
        "rating": "",
        "confidence": "",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "DXPftn5kjQK",
        "title": "The Rich Get Richer: Disparate Impact of Semi-Supervised Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "semi-supervised learning;fairness;disparate impact;Matthew effect;consistency regularization",
        "author": "",
        "aff": "Computer Science and Engineering, University of California, Santa Cruz",
        "rating": "6;6;6;6",
        "confidence": "4;4;4;3",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;4;3;3",
        "empirical_novelty": "3;4;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "DXRwVRh4i8g",
        "title": "Reachability Traces for Curriculum Design in Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "reinforcement learning;curriculum learning;sparse rewards",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;4;3;5",
        "correctness": "3;1;2;3",
        "technical_novelty": "1;3;3;3",
        "empirical_novelty": "2;1;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.0,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.816496580927726,
        "corr_rating_correctness": 0.5222329678670935,
        "project": "",
        "github": ""
    },
    {
        "id": "DXU0DQUDWLA",
        "title": "Disentangling One Factor at a Time",
        "track": "main",
        "status": "Reject",
        "keywords": "unsupervised representation learning;disentanglement;Variational Autoencoders;Generative Adversarial Networks",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;3;2;4",
        "correctness": "3;3;2;3",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5222329678670935,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": "https://github.com/OATFactor/OATFactor"
    },
    {
        "id": "DYaFB19z1ig",
        "title": "Self-Distribution Distillation: Efficient Uncertainty Estimation",
        "track": "main",
        "status": "Reject",
        "keywords": "distillation;self-distillation;distribution distillation;uncertainty;robustness",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5",
        "confidence": "3;3;5;3",
        "correctness": "4;2;3;4",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "DYypjaRdph2",
        "title": "Inverse Online Learning: Understanding Non-Stationary and Reactionary Policies",
        "track": "main",
        "status": "Poster",
        "keywords": "Decision Modelling;Imitation Learning;Inverse Online Learning",
        "author": "",
        "aff": "University of Cambridge, Department of Applied Mathematics and Theoretical Physics, Cambridge, UK",
        "rating": "6;6;8",
        "confidence": "3;3;3",
        "correctness": "3;2;3",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "3;2;3",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 3.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.49999999999999983,
        "project": "",
        "github": ""
    },
    {
        "id": "Da3ZcbjRWy",
        "title": "Self-Supervised Representation Learning via Latent Graph Prediction",
        "track": "main",
        "status": "Reject",
        "keywords": "Self-supervised learning;representation learning;graph neural networks",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "3;3;3;3",
        "correctness": "4;3;3;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;3;2;2",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "DaQVj6qY2-s",
        "title": "Understanding Graph Learning with Local Intrinsic Dimensionality",
        "track": "main",
        "status": "Reject",
        "keywords": "Local Intrinsic Dimensionality;Graph Neural Networks",
        "author": "",
        "aff": "",
        "rating": "1;5;6",
        "confidence": "5;3;4",
        "correctness": "1;4;4",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "0;3;4",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7559289460184544,
        "corr_rating_correctness": 0.9819805060619657,
        "project": "",
        "github": ""
    },
    {
        "id": "DesNW4-5ai9",
        "title": "Transferable Adversarial Attack based on Integrated Gradients",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "School of Computer Science and Engineering, Nanyang Technological University, Singapore",
        "rating": "5;5;6;8",
        "confidence": "3;4;3;4",
        "correctness": "3;2;3;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "3;0;3;4",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.40824829046386296,
        "corr_rating_correctness": 0.8660254037844386,
        "project": "",
        "github": "https://github.com/yihuang2016/TAIG"
    },
    {
        "id": "DfMqlB0PXjM",
        "title": "Interpretable Unsupervised Diversity Denoising and Artefact Removal",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Interpretable Unsupervised Image Restoration;Diversity Image Restoration;Unsupervised Image Denoising;Unsupervised Artefact Removal",
        "author": "",
        "aff": "Center for Systems Biology Dresden, Max Planck Institute (CBG), Fondazione Human Technopole; Google Research; Center for Systems Biology Dresden, Max Planck Institute (CBG)",
        "rating": "6;8;8;8",
        "confidence": "3;4;3;4",
        "correctness": "4;4;4;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.5,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "DfUjyyRW90",
        "title": "Information Prioritization through Empowerment in Visual Model-based RL",
        "track": "main",
        "status": "Poster",
        "keywords": "model-based reinforcement learning;visual distractors;empowerment",
        "author": "",
        "aff": "Carnegie Mellon University; Google Research, Brain Team, University of California Berkeley; Google Research, Brain Team",
        "rating": "6;8;8;8",
        "confidence": "4;3;3;4",
        "correctness": "4;4;4;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;0;3;4",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.5,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "DhP9L8vIyLc",
        "title": "PAC Prediction Sets Under Covariate Shift",
        "track": "main",
        "status": "Poster",
        "keywords": "probably approximately correct;prediction set;covariate shift;importance weight;calibration;Clopper-Pearson binomial interval;rejection sampling",
        "author": "",
        "aff": "Dept. of Computer & Info. Science, PRECISE Center, University of Pennsylvania; Dept. of Statistics & Data Science, The Wharton School, University of Pennsylvania",
        "rating": "6;6;6;8",
        "confidence": "3;2;3;4",
        "correctness": "3;4;3;3",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "3;3;2;4",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.816496580927726,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "DhzIU48OcZh",
        "title": "P-Adapters: Robustly Extracting Factual Information from Language Models with Diverse Prompts",
        "track": "main",
        "status": "Poster",
        "keywords": "NLP;Prompting;Commonsense;information extraction;factual extraction;Large Language Models",
        "author": "",
        "aff": "Stanford University; Salesforce Research",
        "rating": "5;6;6;8;8",
        "confidence": "4;4;3;3;4",
        "correctness": "3;3;3;4;4",
        "technical_novelty": "2;3;3;3;3",
        "empirical_novelty": "2;2;3;3;3",
        "presentation": "",
        "rating_avg": 6.6,
        "confidence_avg": 3.6,
        "correctness_avg": 3.4,
        "technical_novelty_avg": 2.8,
        "empirical_novelty_avg": 2.6,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.2721655269759087,
        "corr_rating_correctness": 0.9525793444156803,
        "project": "",
        "github": ""
    },
    {
        "id": "DkeCkhLIVGZ",
        "title": "Understanding Metric Learning on Unit Hypersphere and Generating Better Examples for Adversarial Training",
        "track": "main",
        "status": "Reject",
        "keywords": "Metric learning;Adversarial learning",
        "author": "",
        "aff": "Under double-blind review",
        "rating": "5;5;6;8",
        "confidence": "3;4;3;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.40824829046386296,
        "corr_rating_correctness": 0.9428090415820632,
        "project": "",
        "github": ""
    },
    {
        "id": "Dl4LetuLdyK",
        "title": "A Fine-Grained Analysis on Distribution Shift",
        "track": "main",
        "status": "Oral",
        "keywords": "robustness;distribution shifts",
        "author": "",
        "aff": "DeepMind, London, UK; Google",
        "rating": "8;8;10",
        "confidence": "4;4;4",
        "correctness": "2;3;4",
        "technical_novelty": "2;4;3",
        "empirical_novelty": "3;4;3",
        "presentation": "",
        "rating_avg": 8.666666666666666,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.8660254037844385,
        "project": "",
        "github": "github.com/deepmind/distribution_shift_framework"
    },
    {
        "id": "DmKu5T2gEqc",
        "title": "CDNet: A cascaded decoupling architecture for video prediction",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Video Prediction;RNNs",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;4;4;4",
        "correctness": "2;3;2;4",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;0;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.7608859102526822,
        "project": "",
        "github": ""
    },
    {
        "id": "DmpCfq6Mg39",
        "title": "Omni-Dimensional Dynamic Convolution",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Convolutional Neural Networks;Dynamic Convolution;Attention;Image Classification",
        "author": "",
        "aff": "Intel Labs China; CUHK-SenseTime Joint Lab, The Chinese University of Hong Kong",
        "rating": "6;8;8;8",
        "confidence": "4;5;3;4",
        "correctness": "3;4;3;4",
        "technical_novelty": "2;4;4;3",
        "empirical_novelty": "3;1;3;0",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": "https://github.com/OSVAI/ODConv"
    },
    {
        "id": "DnG75_KyHjX",
        "title": "MoReL: Multi-omics Relational Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "relational learning;data integration;multi-view learning;Bayesian generative model",
        "author": "",
        "aff": "Department of Electrical and Computer Engineering, Texas A&M University",
        "rating": "5;5;6;8",
        "confidence": "2;3;3;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 2.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.4714045207910316,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "DnG8f7gweH4",
        "title": "Piecing and Chipping: An effective solution for the information-erasing view generation in Self-supervised Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Data Augmentation;Self-supervised;Contrastive Learning;Deep Learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "2;4;4;3",
        "correctness": "2;2;3;3",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;4;0;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.17407765595569782,
        "corr_rating_correctness": 0.9622504486493761,
        "project": "",
        "github": ""
    },
    {
        "id": "DqJgzrcA8lH",
        "title": "Latent Space Smoothing for Individually Fair Representations",
        "track": "main",
        "status": "Withdraw",
        "keywords": "fairness;fair representation learning;adversarial fairness;trustworthy machine learning;randomized smoothing",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;4;4",
        "correctness": "2;2;3;3",
        "technical_novelty": "2;2;4;3",
        "empirical_novelty": "1;1;3;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "DrCsriMQ1o",
        "title": "Gradient-based Counterfactual Explanations using Tractable Probabilistic Models",
        "track": "main",
        "status": "Reject",
        "keywords": "Counterfactual example;Sum product networks;tractable probabilistic models;counterfactual explanation.",
        "author": "",
        "aff": "",
        "rating": "3;3;5;8",
        "confidence": "2;3;5;4",
        "correctness": "2;3;3;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.6009942011789684,
        "corr_rating_correctness": 0.8638684255813602,
        "project": "",
        "github": ""
    },
    {
        "id": "DrZXuTGg2A-",
        "title": "Shuffle Private Stochastic Convex Optimization",
        "track": "main",
        "status": "Poster",
        "keywords": "shuffle privacy;stochastic convex optimization;differential privacy",
        "author": "",
        "aff": "Georgetown University; Columbia University; Google Research",
        "rating": "6;6;8;8",
        "confidence": "4;4;3;3",
        "correctness": "3;4;4;4",
        "technical_novelty": "3;2;3;4",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "DrpKmCmPMSC",
        "title": "Meta-free few-shot learning via representation learning with weight averaging",
        "track": "main",
        "status": "Reject",
        "keywords": "few-shot learning;representation learning",
        "author": "",
        "aff": "",
        "rating": "5;5;6",
        "confidence": "3;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "0;2;3",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.4999999999999999,
        "corr_rating_correctness": 0.9999999999999997,
        "project": "",
        "github": ""
    },
    {
        "id": "DtfrnB1fiX",
        "title": "Squeezing SGD Parallelization Performance in Distributed Training Using Delayed Averaging",
        "track": "main",
        "status": "Reject",
        "keywords": "SGD;distributed training;hide communication cost;convergence",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "4;3;3;5",
        "correctness": "4;4;3;3",
        "technical_novelty": "1;1;2;2",
        "empirical_novelty": "1;2;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 1.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "Dup_dDqkZC5",
        "title": "Latent Variable Sequential Set Transformers for Joint Multi-Agent Motion Prediction",
        "track": "main",
        "status": "Spotlight",
        "keywords": "trajectory prediction;motion forecasting;transformers;latent variable models",
        "author": "",
        "aff": "2Mila, Quebec AI Institute, 6McGill University, 7\u00c9cole de technologie sup\u00e9rieure, 8Canada CIFAR AI Chair; 2Mila, Quebec AI Institute, 4Independent Robotics; 1Polytechnique Montr\u00e9al, 2Mila, Quebec AI Institute; 1Polytechnique Montr\u00e9al, 2Mila, Quebec AI Institute, 3ElementAI / Service Now, 8Canada CIFAR AI Chair; 5Algolux; 2Mila, Quebec AI Institute, 3ElementAI / Service Now; 5Algolux, 9Princeton University",
        "rating": "6;8;8;8",
        "confidence": "4;4;3;5",
        "correctness": "3;4;4;3",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "3;3;2;3",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "https://fgolemo.github.io/autobots/",
        "github": "https://github.com/fgolemo/autobots"
    },
    {
        "id": "DvcMMKmDJ3q",
        "title": "Generating Symbolic Reasoning Problems with Transformer GANs",
        "track": "main",
        "status": "Reject",
        "keywords": "Transformer;GAN;symbolic reasoning;temporal logic",
        "author": "",
        "aff": "",
        "rating": "3;5;5;8",
        "confidence": "4;4;3;4",
        "correctness": "3;2;3;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "3;0;2;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.08084520834544431,
        "corr_rating_correctness": 0.5940885257860046,
        "project": "",
        "github": ""
    },
    {
        "id": "Dy8gq-LuckD",
        "title": "Recognizing and overcoming the greedy nature of learning in multi-modal deep neural networks",
        "track": "main",
        "status": "Reject",
        "keywords": "multi-modal learning;deep neural networks;multi-view learning",
        "author": "",
        "aff": "Under double-blind review",
        "rating": "3;3;5;8",
        "confidence": "4;4;4;4",
        "correctness": "2;2;3;3",
        "technical_novelty": "2;2;3;4",
        "empirical_novelty": "3;2;3;4",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.8551861104941366,
        "project": "",
        "github": ""
    },
    {
        "id": "DyPCANHXFRI",
        "title": "How Curriculum Learning Impacts Model Calibration",
        "track": "main",
        "status": "Withdraw",
        "keywords": "calibration;deep learning;curriculum learning;image classification",
        "author": "",
        "aff": "",
        "rating": "1;3;5;5",
        "confidence": "4;4;4;4",
        "correctness": "2;2;3;3",
        "technical_novelty": "1;1;2;2",
        "empirical_novelty": "1;3;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 1.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9045340337332909,
        "project": "",
        "github": ""
    },
    {
        "id": "DzBDB7y8UOy",
        "title": "CoLLIE: Continual Learning of Language Grounding from Language-Image Embeddings",
        "track": "main",
        "status": "Reject",
        "keywords": "Continual Learning;Language Grounding;Language-Image Embeddings;Multimodal Distributional Semantics;Reference Resolution",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "3;5;4;4",
        "correctness": "3;2;3;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.6488856845230502,
        "corr_rating_correctness": 0.3244428422615251,
        "project": "",
        "github": ""
    },
    {
        "id": "DzKPXXr-CLK",
        "title": "Abelian Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "algebra;Abelian group;word analogy;invertible neural networks;permutation invariant;size generalization",
        "author": "",
        "aff": "",
        "rating": "3;6;6",
        "confidence": "4;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "3;0;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5,
        "corr_rating_correctness": -1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "Dzpe9C1mpiv",
        "title": "A Unified Wasserstein Distributional Robustness Framework for Adversarial Training",
        "track": "main",
        "status": "Poster",
        "keywords": "Adversarial Machine Learning;Distributional Robustness",
        "author": "",
        "aff": "Monash University, VinAI Research; Monash University; Adobe Research",
        "rating": "5;6;6;8;8",
        "confidence": "3;3;3;2;4",
        "correctness": "4;3;3;3;3",
        "technical_novelty": "2;3;3;3;3",
        "empirical_novelty": "2;3;3;3;3",
        "presentation": "",
        "rating_avg": 6.6,
        "confidence_avg": 3.0,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.8,
        "empirical_novelty_avg": 2.8,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.6666666666666666,
        "project": "",
        "github": "https://github.com/tuananhbui89/Unified-Distributional-Robustness"
    },
    {
        "id": "E-dq2kN8lt",
        "title": "FedPAGE: A Fast Local Stochastic Gradient Method for Communication-Efficient Federated Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "federated learning;nonconvex optimization;convex optimization;local gradient method",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5;5",
        "confidence": "4;4;3;3;4",
        "correctness": "3;4;4;4;3",
        "technical_novelty": "2;3;3;3;2",
        "empirical_novelty": "2;2;3;3;2",
        "presentation": "",
        "rating_avg": 4.6,
        "confidence_avg": 3.6,
        "correctness_avg": 3.6,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.408248290463863,
        "corr_rating_correctness": 0.6123724356957948,
        "project": "",
        "github": ""
    },
    {
        "id": "E0zOKxQsZhN",
        "title": "Recurrent Model-Free RL is a Strong Baseline for Many POMDPs",
        "track": "main",
        "status": "Reject",
        "keywords": "POMDP;RNN;recurrent model-free RL;baseline;meta RL;robust RL;generalization in RL",
        "author": "",
        "aff": "",
        "rating": "5;6;8",
        "confidence": "4;4;4",
        "correctness": "2;3;3",
        "technical_novelty": "3;3;1",
        "empirical_novelty": "3;3;4",
        "presentation": "",
        "rating_avg": 6.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 3.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.7559289460184545,
        "project": "https://drive.google.com/drive/folders/1I5mLlKPf2Gmdpm0nzy9OkR494nCJll1g?usp=sharing",
        "github": ""
    },
    {
        "id": "E3gF8L-mmS3",
        "title": "Use of small auxiliary networks and scarce data to improve the adversarial robustness of deep learning models",
        "track": "main",
        "status": "Withdraw",
        "keywords": "adversarial learning;adversarial robustness;deep learning;cnn",
        "author": "",
        "aff": "",
        "rating": "3;3;3",
        "confidence": "4;4;4",
        "correctness": "2;3;3",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;1;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "E4EE_ohFGz",
        "title": "Diurnal or Nocturnal? Federated Learning of Multi-branch Networks from Periodically Shifting Distributions",
        "track": "main",
        "status": "Poster",
        "keywords": "Federated Learning;Peroredical Distribution Shift",
        "author": "",
        "aff": "University of Maryland, College Park; Google",
        "rating": "3;5;6;8",
        "confidence": "4;5;4;2",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;0;3;4",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6999132392733556,
        "corr_rating_correctness": 0.8320502943378437,
        "project": "",
        "github": ""
    },
    {
        "id": "E7rUJ4uRbzt",
        "title": "Extraneousness-Aware Imitation Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "visual imitation learning;imitation learning from noisy video",
        "author": "",
        "aff": "",
        "rating": "1;3;3;5",
        "confidence": "4;4;5;4",
        "correctness": "2;2;2;2",
        "technical_novelty": "3;2;2;3",
        "empirical_novelty": "2;3;1;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.25,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "https://sites.google.com/view/iclr2022eil/home",
        "github": ""
    },
    {
        "id": "E8tsHT1YG0",
        "title": "Ridgeless Interpolation with Shallow ReLU Networks in $1D$ is Nearest Neighbor Curvature Extrapolation and Provably Generalizes on Lipschitz Functions",
        "track": "main",
        "status": "Withdraw",
        "keywords": "theory;deep learning theory;implicit bias;generalization;interpolation;ridgeless regression",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "3;3;3;4",
        "correctness": "2;4;3;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;0;1;0",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 0.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.6622661785325219,
        "corr_rating_correctness": 0.6488856845230502,
        "project": "",
        "github": ""
    },
    {
        "id": "E9UL8UJvysW",
        "title": "Structured Federated Aggregation for Personalizing On-device Intelligence",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Federated Learning;Structure Aggregation;Personalisation;Graph Neural Network",
        "author": "",
        "aff": "",
        "rating": "",
        "confidence": "",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "E9e18Ms5TeV",
        "title": "A Large Batch Optimizer Reality Check: Traditional, Generic Optimizers Suffice Across Batch Sizes",
        "track": "main",
        "status": "Reject",
        "keywords": "neural networks;deep learning;neural network optimization;hyperparameter tuning;optimizer comparison",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "5;4;4;4",
        "correctness": "3;4;4;4",
        "technical_novelty": "2;1;2;1",
        "empirical_novelty": "0;2;3;2",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 1.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9271726499455306,
        "corr_rating_correctness": 0.9271726499455306,
        "project": "",
        "github": ""
    },
    {
        "id": "E9z2A1-O7e",
        "title": "HyperTransformer: Attention-Based CNN Model Generation from Few Samples",
        "track": "main",
        "status": "Reject",
        "keywords": "few-shot learning;transformer model;weight generation;supervised learning;semi-supervised learning",
        "author": "",
        "aff": "",
        "rating": "3;5;8",
        "confidence": "4;4;4",
        "correctness": "2;3;4",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9933992677987828,
        "project": "",
        "github": ""
    },
    {
        "id": "EAy7C1cgE1L",
        "title": "Increasing the Cost of Model Extraction with Calibrated Proof of Work",
        "track": "main",
        "status": "Spotlight",
        "keywords": "model extraction;model stealing;model functionality stealing;proof-of-work;adversarial machine learning;trustworthy machine learning;deep learning",
        "author": "",
        "aff": "Stanford University; University of Toronto and Vector Institute",
        "rating": "3;6;8;8",
        "confidence": "4;4;4;3",
        "correctness": "3;3;4;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.49374193110101877,
        "corr_rating_correctness": 0.49374193110101877,
        "project": "",
        "github": ""
    },
    {
        "id": "EBn0uInJZWh",
        "title": "Model-Based Offline Meta-Reinforcement Learning with Regularization",
        "track": "main",
        "status": "Poster",
        "keywords": "offline reinforcement learning;model-based reinforcement learning;behavior policy;Meta-reinforcement learning",
        "author": "",
        "aff": "School of ECEE, Arizona State University; Department of ECE, The Ohio State University; Department of ECE, University of California, Davis",
        "rating": "6;6;6;8",
        "confidence": "3;4;4;4",
        "correctness": "2;4;4;4",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "ECC7T-torK",
        "title": "Early Stop And Adversarial Training Yield Better surrogate Model: Very Non-Robust Features Harm Adversarial Transferability",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Adversarial Tranferability;Early stop;Adversarial Training;Non-robust Features",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;3;4",
        "correctness": "3;2;2;2",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;3;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "ECvgmYVyeUz",
        "title": "Chaos is a Ladder: A New Theoretical Understanding of Contrastive Learning via Augmentation Overlap",
        "track": "main",
        "status": "Poster",
        "keywords": "Contrastive Learning;Representation Learning;Self-supervised Learning",
        "author": "",
        "aff": "School of Computer Science and Engineering, Sun Yat-sen University; School of Mathematical Sciences, Peking University; Key Lab. of Machine Perception (MoE), School of Arti\ufb01cial Intelligence, Peking University; Institute for Arti\ufb01cial Intelligence, Peking University",
        "rating": "6;6;8;8",
        "confidence": "4;4;4;3",
        "correctness": "4;3;3;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/zhangq327/ARC"
    },
    {
        "id": "ECzghp9oujq",
        "title": "Look at here : Utilizing supervision to attend subtle key regions",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Medical image diagnosis;Deep learning;Regularization strategy;Data augmentation",
        "author": "",
        "aff": "",
        "rating": "3;5;6",
        "confidence": "5;4;4",
        "correctness": "2;2;3",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.944911182523068,
        "corr_rating_correctness": 0.7559289460184545,
        "project": "",
        "github": ""
    },
    {
        "id": "EDeVYpT42oS",
        "title": "Deconstructing the Inductive Biases of Hamiltonian Neural Networks",
        "track": "main",
        "status": "Spotlight",
        "keywords": "",
        "author": "",
        "aff": "New York University",
        "rating": "6;8;8;8",
        "confidence": "4;4;4;3",
        "correctness": "3;3;4;3",
        "technical_novelty": "3;4;3;3",
        "empirical_novelty": "3;4;4;3",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "EFSctTwY4xn",
        "title": "Towards Generalizable Personalized Federated Learning with Adaptive Local Adaptation",
        "track": "main",
        "status": "Reject",
        "keywords": "Personalized federated learning;Meta-learning;Information theory",
        "author": "",
        "aff": "",
        "rating": "3;5;6",
        "confidence": "4;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.18898223650461363,
        "corr_rating_correctness": 0.9449111825230683,
        "project": "",
        "github": ""
    },
    {
        "id": "EFgzhSJYIj6",
        "title": "RL-DARTS: Differentiable Architecture Search for Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "darts;differentiable;architecture;search;neural;nas;rl;reinforcement;learning;procgen;supernet;softmax;variable;ppo;rainbow;off-policy;on-policy;convolutional;autorl;automated;one-shot;efficient",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "4;4;5;3",
        "correctness": "4;3;3;3",
        "technical_novelty": "2;2;2;4",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.9428090415820632,
        "project": "",
        "github": ""
    },
    {
        "id": "EG5Pgd7-MY",
        "title": "Privacy Auditing of Machine Learning using Membership Inference Attacks",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5",
        "confidence": "4;4;4",
        "correctness": "3;3;2",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;3;2",
        "presentation": "",
        "rating_avg": 4.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.49999999999999983,
        "project": "",
        "github": "https://github.com/privacytrustlab/ml_privacy_meter"
    },
    {
        "id": "EGtUVDm991w",
        "title": "Token Pooling in Vision Transformers",
        "track": "main",
        "status": "Reject",
        "keywords": "Transformer;Pooling;Downsampling;Efficiency",
        "author": "",
        "aff": "",
        "rating": "5;5;8",
        "confidence": "4;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "3;3;4",
        "empirical_novelty": "3;2;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 3.3333333333333335,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "EHaUTlm2eHg",
        "title": "Policy Gradients Incorporating the Future",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "McGill University; Google Brain; Mila, McGill University; Mila, McGill University, DeepMind",
        "rating": "6;6;6;8",
        "confidence": "3;5;3;3",
        "correctness": "3;3;4;4",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "EIm_pvFJx5k",
        "title": "Meta-Forecasting by combining Global Deep Representations with Local Adaptation",
        "track": "main",
        "status": "Reject",
        "keywords": "time-series;meta-learning;closed-form;solvers",
        "author": "",
        "aff": "",
        "rating": "3;3;5",
        "confidence": "4;3;3",
        "correctness": "2;2;2",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "1;2;1",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.3333333333333333,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "EJKLVMB_9T",
        "title": "SplitRegex: Faster Regex Synthesis via Neural Example Splitting",
        "track": "main",
        "status": "Reject",
        "keywords": "regular expression;program synthesis;programming by examples;deep learning;neural network",
        "author": "",
        "aff": "",
        "rating": "5;5;6;8",
        "confidence": "4;4;3;3",
        "correctness": "3;3;4;4",
        "technical_novelty": "3;2;2;3",
        "empirical_novelty": "2;2;3;4",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8164965809277259,
        "corr_rating_correctness": 0.8164965809277259,
        "project": "",
        "github": ""
    },
    {
        "id": "EKjUnoX-7M0",
        "title": "A new look at fairness in stochastic multi-armed bandit problems",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "4;4;4;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "3;1;3;2",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "EMLJ_mTz_z",
        "title": "Convolutional Neural Network Dynamics: A Graph Perspective",
        "track": "main",
        "status": "Reject",
        "keywords": "neural network dynamics;time-evolving graphs;interpretation of neural networks;performance prediction",
        "author": "",
        "aff": "",
        "rating": "3;5;6;8",
        "confidence": "5;3;3;3",
        "correctness": "2;3;4;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8006407690254357,
        "corr_rating_correctness": 0.9198662110077999,
        "project": "",
        "github": ""
    },
    {
        "id": "EMigfE6ZeS",
        "title": "Hybrid Random Features",
        "track": "main",
        "status": "Poster",
        "keywords": "random features;softmax kernel;attention mechanism;compositional kernels",
        "author": "",
        "aff": "University of Cambridge; Google Brain Robotics; The Alan Turing Institute; Columbia University",
        "rating": "6;8;8",
        "confidence": "4;5;4",
        "correctness": "3;3;4",
        "technical_novelty": "3;3;4",
        "empirical_novelty": "3;3;2",
        "presentation": "",
        "rating_avg": 7.333333333333333,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.3333333333333335,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.4999999999999999,
        "corr_rating_correctness": 0.49999999999999983,
        "project": "",
        "github": ""
    },
    {
        "id": "EMxu-dzvJk",
        "title": "GRAND++: Graph Neural Diffusion with A Source Term",
        "track": "main",
        "status": "Poster",
        "keywords": "graph deep learning;low-labeling rates;diffusion on graphs;random walk",
        "author": "",
        "aff": "Department of Mathematics, University of Manchester, Manchester M13 9PL, UK; Department of Mathematics, UC Davis, Davis, CA 95616, USA; Department of Mathematics and Scientific Computing and Imaging (SCI) Institute, University of Utah, Salt Lake City, UT, 84102, USA; Department of Mathematics, UCLA, Los Angeles, CA, 90095, USA",
        "rating": "6;6;6;6;8",
        "confidence": "4;4;3;3;3",
        "correctness": "4;3;3;3;4",
        "technical_novelty": "3;3;2;2;3",
        "empirical_novelty": "2;2;2;2;0",
        "presentation": "",
        "rating_avg": 6.4,
        "confidence_avg": 3.4,
        "correctness_avg": 3.4,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 1.6,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.408248290463863,
        "corr_rating_correctness": 0.6123724356957947,
        "project": "",
        "github": ""
    },
    {
        "id": "EO4VJGAllb",
        "title": "Adversarial Training: A simple and efficient technique to Improving NLP Robustness",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Adversarial training;NLP models;NLP robustness;adversarial attacks.",
        "author": "Marwan Omar",
        "aff": "Under double-blind review",
        "rating": "",
        "confidence": "",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "EPIeOo3ql96",
        "title": "Testing-Time Adaptation through Online Normalization Estimation",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5",
        "confidence": "4;5;4",
        "correctness": "2;3;3",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 4.333333333333333,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.4999999999999999,
        "corr_rating_correctness": 0.9999999999999998,
        "project": "",
        "github": ""
    },
    {
        "id": "EQ7A6F7k0r_",
        "title": "QTN-VQC: An End-to-End Learning Framework for Quantum Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "quantum neural networks;variational quantum circuits;end-to-end learning framework;tensor-train network",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5;5",
        "confidence": "3;4;3;4;4",
        "correctness": "3;2;3;3;3",
        "technical_novelty": "2;2;2;2;2",
        "empirical_novelty": "2;1;2;2;2",
        "presentation": "",
        "rating_avg": 4.2,
        "confidence_avg": 3.6,
        "correctness_avg": 2.8,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.8,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.16666666666666663,
        "corr_rating_correctness": 0.6123724356957947,
        "project": "",
        "github": ""
    },
    {
        "id": "EQmAP4F859",
        "title": "The Three Stages of Learning Dynamics in High-dimensional Kernel Methods",
        "track": "main",
        "status": "Poster",
        "keywords": "training dynamics;kernels;SGD;deep bootstrap;gradient flow;random features;high-dimensional asymptotics;random matrix theory",
        "author": "",
        "aff": "",
        "rating": "5;6;6;8",
        "confidence": "2;4;4;5",
        "correctness": "3;4;4;4",
        "technical_novelty": "1;3;3;4",
        "empirical_novelty": "2;0;3;4",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.894736842105263,
        "corr_rating_correctness": 0.6622661785325219,
        "project": "",
        "github": ""
    },
    {
        "id": "ET1UAOYeU42",
        "title": "Edge Partition Modulated Graph Convolutional Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "Latent Variable Models;Bayesian Methods;Variational Inference;Graph Neural Networks",
        "author": "",
        "aff": "",
        "rating": "3;3;5;8",
        "confidence": "5;4;3;3",
        "correctness": "2;3;3;4",
        "technical_novelty": "2;2;3;4",
        "empirical_novelty": "2;0;3;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7735449421179452,
        "corr_rating_correctness": 0.8638684255813602,
        "project": "",
        "github": ""
    },
    {
        "id": "ETiaOyNwJW",
        "title": "Revisiting Virtual Nodes in Graph Neural Networks for Link Prediction",
        "track": "main",
        "status": "Reject",
        "keywords": "graph neural network;link prediction;virtual node",
        "author": "",
        "aff": "",
        "rating": "5;6;6;6",
        "confidence": "4;4;4;3",
        "correctness": "4;4;3;4",
        "technical_novelty": "3;2;2;3",
        "empirical_novelty": "2;2;3;4",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "EVVadRFRgL7",
        "title": "Bayesian Modeling and Uncertainty Quantification for Learning to Optimize: What, Why, and How",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "Department of Electrical and Computer Engineering, Texas A&M University; Department of Electrical and Computer Engineering, University of Texas at Austin; Department of Electrical and Computer Engineering, Texas A&M University and Department of Computer Science and Engineering, Texas A&M University",
        "rating": "5;5;6;6",
        "confidence": "3;3;4;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;3;3;2",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 1.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": "https://github.com/Shen-Lab/Bayesian-L2O"
    },
    {
        "id": "EVqFdCB5PfV",
        "title": "Iterative Hierarchical Attention for Answering Complex Questions over Long Documents",
        "track": "main",
        "status": "Reject",
        "keywords": "Question Answering;Natural Language Processing;Attention Methods",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;3;4;3",
        "correctness": "2;2;2;2",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.5,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "EXHG-A3jlM",
        "title": "Efficient Token Mixing for Transformers via Adaptive Fourier Neural Operators",
        "track": "main",
        "status": "Poster",
        "keywords": "self attention;linear complexity;high-resolution inputs;operator learning;Fourier transform",
        "author": "",
        "aff": "Stanford University; NVIDIA; NVIDIA, California Institute of Technology",
        "rating": "6;6;8",
        "confidence": "4;4;3",
        "correctness": "4;1;3",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "4;2;2",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9999999999999998,
        "corr_rating_correctness": 0.1889822365046136,
        "project": "",
        "github": "github.com/jtguibas/AdaptiveFourierNeuralOperator"
    },
    {
        "id": "EXe93Md8RqS",
        "title": "Data Quality Matters For Adversarial Training: An Empirical Study",
        "track": "main",
        "status": "Reject",
        "keywords": "Adversarial training;Data quality;Robust overfitting;Robustness overestimation;Robustness-accuracy trade-off",
        "author": "",
        "aff": "",
        "rating": "6;6;6;6",
        "confidence": "4;4;5;3",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "4;2;3;2",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "EYCm0AFjaSS",
        "title": "ZerO Initialization: Initializing Residual Networks with only Zeros and Ones",
        "track": "main",
        "status": "Reject",
        "keywords": "weight initialization;deep residual network;deterministic initialization;optimization",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5;6",
        "confidence": "3;3;4;4;3",
        "correctness": "4;2;3;3;4",
        "technical_novelty": "2;3;3;1;3",
        "empirical_novelty": "2;3;2;2;3",
        "presentation": "",
        "rating_avg": 5.2,
        "confidence_avg": 3.4,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.408248290463863,
        "corr_rating_correctness": 0.5345224838248488,
        "project": "",
        "github": ""
    },
    {
        "id": "EZNOb_uNpJk",
        "title": "ClimateGAN: Raising Climate Change Awareness by Generating Images of Floods",
        "track": "main",
        "status": "Poster",
        "keywords": "GAN;Climate Change;Domain Adaptation;Representation Learning;Computer Vision;Application",
        "author": "",
        "aff": "CDRIN, Matane, Canada; Mila Quebec AI Institute, Montreal, Canada and Universite de Montreal, Montreal, Canada; Columbia University, New York City, USA",
        "rating": "5;5;6",
        "confidence": "4;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9999999999999997,
        "project": "https://thisclimatedoesnotexist.com",
        "github": ""
    },
    {
        "id": "EcGGFkNTxdJ",
        "title": "Trust Region Policy Optimisation in Multi-Agent Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "Multi-Agent Reinforcement Learning;trust-region method;policy gradient method",
        "author": "",
        "aff": "Institute for AI, Peking University & BIGAI; University of Oxford, Huawei R&D UK; University College London; ShanghaiTech University; Shanghai Jiao Tong University",
        "rating": "6;6;6;8",
        "confidence": "3;3;4;4",
        "correctness": "3;4;3;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": "https://github.com/PKU-MARL/TRPO-PPO-in-MARL"
    },
    {
        "id": "Eceabn-Spyz",
        "title": "Generalizable Learning to Optimize into Wide Valleys",
        "track": "main",
        "status": "Reject",
        "keywords": "L2O;Generalization;Flatness;Entropy-SGD",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "4;3;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "3;0;2;2",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "Ee2ugKwgvyy",
        "title": "Graph Information Matters: Understanding Graph Filters from Interaction Probability",
        "track": "main",
        "status": "Reject",
        "keywords": "Node classification;graph filters;homophily degree;interaction probability;frequency distribution;filter bank;spectral graph neural networks",
        "author": "",
        "aff": "",
        "rating": "3;5;6",
        "confidence": "4;4;5",
        "correctness": "2;2;3",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;0;1",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 1.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.7559289460184544,
        "corr_rating_correctness": 0.7559289460184545,
        "project": "",
        "github": ""
    },
    {
        "id": "EgkZwzEwciE",
        "title": "Adversarial Collaborative Learning on Non-IID Features",
        "track": "main",
        "status": "Reject",
        "keywords": "Federated Learning;Collaborative Learning",
        "author": "",
        "aff": "",
        "rating": "3;5;5;8",
        "confidence": "5;4;4;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7276068751089989,
        "corr_rating_correctness": 0.8892972917998875,
        "project": "",
        "github": ""
    },
    {
        "id": "EhYjZy6e1gJ",
        "title": "PiCO: Contrastive Label Disambiguation for Partial Label Learning",
        "track": "main",
        "status": "Oral",
        "keywords": "Partial Label Learning;Contrastive Learning;Prototype-based Disambiguation",
        "author": "",
        "aff": "University of Wisconsin-Madison; Chongqing University; Zhejiang University; RIKEN",
        "rating": "8;8;8",
        "confidence": "4;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "3;4;3",
        "empirical_novelty": "3;4;4",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.3333333333333335,
        "empirical_novelty_avg": 3.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/hbzju/PiCO"
    },
    {
        "id": "EhdacditHf9",
        "title": "The Number of Steps Needed for Nonconvex Optimization of a Deep Learning Optimizer is a Rational Function of Batch Size",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Adam;deep learning optimizer;momentum;nonconvex optimization;optimal batch size;SGD",
        "author": "",
        "aff": "",
        "rating": "1;3;5;6;6",
        "confidence": "5;3;3;3;3",
        "correctness": "1;1;3;4;3",
        "technical_novelty": "4;2;2;3;4",
        "empirical_novelty": "4;0;2;2;2",
        "presentation": "",
        "rating_avg": 4.2,
        "confidence_avg": 3.4,
        "correctness_avg": 2.4,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8251369970070346,
        "corr_rating_correctness": 0.9110887675286008,
        "project": "",
        "github": ""
    },
    {
        "id": "Ehhk6jyas6v",
        "title": "On The Quality Assurance Of Concept-Based Representations",
        "track": "main",
        "status": "Reject",
        "keywords": "Concept learning;Disentanglement learning;Explainability;Interpretability",
        "author": "",
        "aff": "",
        "rating": "5;5;5",
        "confidence": "4;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "4;2;3",
        "empirical_novelty": "4;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "EhwEUb2ynIa",
        "title": "How to Adapt Your Large-Scale Vision-and-Language Model",
        "track": "main",
        "status": "Reject",
        "keywords": "transfer learning;fine-tuning;layernorm;CLIP;prompt-tuning;adaptation;zero-shot;pretraining",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;4;4;3",
        "correctness": "2;3;3;3",
        "technical_novelty": "1;2;2;2",
        "empirical_novelty": "1;2;3;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 1.0,
        "project": "https://sites.google.com/view/adapt-large-scale-models",
        "github": ""
    },
    {
        "id": "Ek7PSN7Y77z",
        "title": "Multi-Stage Episodic Control for Strategic Exploration in Text Games",
        "track": "main",
        "status": "Spotlight",
        "keywords": "reinforcement learning;language understanding;text-based games",
        "author": "",
        "aff": "John A. Paulson School of Engineering and Applied Sciences, Harvard University; Department of Computer Science, Princeton University",
        "rating": "6;6;8;8",
        "confidence": "5;4;3;3",
        "correctness": "3;4;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "3;3;0;4",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9045340337332909,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": "https://github.com/princeton-nlp/XTX"
    },
    {
        "id": "El9kZ2caYVy",
        "title": "Noise-Contrastive Variational Information Bottleneck Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "uncertainty estimation;variational information bottleneck",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "3;3;3;4",
        "correctness": "2;3;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.6622661785325219,
        "corr_rating_correctness": 0.899228803025897,
        "project": "",
        "github": ""
    },
    {
        "id": "EnwCZixjSh",
        "title": "On Evaluation Metrics for Graph Generative Models",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "University of Guelph, Vector Institute, Samsung, SAIT AI Lab, Montreal; University of Guelph, Vector Institute; Vector Institute; POSTECH",
        "rating": "6;6;6;8",
        "confidence": "3;4;4;3",
        "correctness": "3;3;3;4",
        "technical_novelty": "1;2;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": "https://github.com/uoguelph-mlrg/GGM-metrics"
    },
    {
        "id": "Eot1M5o2Zy",
        "title": "AestheticNet: Reducing bias in facial data sets under ethical considerations",
        "track": "main",
        "status": "Reject",
        "keywords": "societal considerations of machine learning;fairness;safety;privacy;responsible AI;discrimination prevention;facial aesthetics;unconscious Bias",
        "author": "",
        "aff": "",
        "rating": "1;1;1;6",
        "confidence": "4;5;5;4",
        "correctness": "3;2;1;3",
        "technical_novelty": "1;1;1;3",
        "empirical_novelty": "1;0;1;3",
        "presentation": "",
        "rating_avg": 2.25,
        "confidence_avg": 4.5,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 1.5,
        "empirical_novelty_avg": 1.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.5222329678670935,
        "project": "",
        "github": ""
    },
    {
        "id": "ErX-xMSek2",
        "title": "A Study on Representation Transfer for Few-Shot Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "few-shot learning;transfer learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5;6",
        "confidence": "5;4;5;4;4",
        "correctness": "3;3;3;3;3",
        "technical_novelty": "1;1;3;2;2",
        "empirical_novelty": "2;2;3;2;3",
        "presentation": "",
        "rating_avg": 4.4,
        "confidence_avg": 4.4,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 1.8,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.2721655269759087,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "ErsRrojuPzw",
        "title": "Fast and Efficient Once-For-All Networks for Diverse Hardware Deployment",
        "track": "main",
        "status": "Reject",
        "keywords": "neural architecture search;computer vision;convolutional neural networks",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;4;4;2",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6622661785325219,
        "corr_rating_correctness": 0.6622661785325219,
        "project": "",
        "github": ""
    },
    {
        "id": "Esk2g83ELUt",
        "title": "UniNet: Unified Architecture Search with Convolution, Transformer, and MLP",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Neural architecture search;transformer",
        "author": "",
        "aff": "",
        "rating": "3;5;8",
        "confidence": "5;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8029550685469661,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "EskfH0bwNVn",
        "title": "Resolving Training Biases via Influence-based Data Relabeling",
        "track": "main",
        "status": "Oral",
        "keywords": "Training bias;influence functions;data relabeling",
        "author": "",
        "aff": "Department of Computer Science and Engineering, Shanghai Jiao Tong University",
        "rating": "6;6;8;8",
        "confidence": "4;5;4;3",
        "correctness": "4;4;4;4",
        "technical_novelty": "2;4;3;2",
        "empirical_novelty": "3;4;3;2",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7071067811865475,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "Ew4hVmrrqJE",
        "title": "Sample and Communication-Efficient Decentralized Actor-Critic Algorithms with Finite-Time Analysis",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;6;8",
        "confidence": "4;5;3;4",
        "correctness": "3;2;3;4",
        "technical_novelty": "3;2;2;4",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.28867513459481287,
        "corr_rating_correctness": 0.8660254037844386,
        "project": "",
        "github": ""
    },
    {
        "id": "EwqEx5ipbOu",
        "title": "How Well Does Self-Supervised Pre-Training Perform with Streaming Data?",
        "track": "main",
        "status": "Poster",
        "keywords": "Pre-Training;Representation Learning;Continual Learning;Self-Supervised Learning",
        "author": "",
        "aff": "Huawei Noah\u2019s Ark Lab; National University of Singapore; AARC, Huawei Technologies; ShanghaiTech University",
        "rating": "5;6;6;8",
        "confidence": "4;4;4;4",
        "correctness": "4;3;3;4",
        "technical_novelty": "2;1;2;4",
        "empirical_novelty": "3;3;3;4",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.2294157338705618,
        "project": "",
        "github": ""
    },
    {
        "id": "ExJ4lMbZcqa",
        "title": "Learning Audio-Visual Dereverberation",
        "track": "main",
        "status": "Reject",
        "keywords": "speech enhancement;audio-visual learning;speech dereverberation;room acoustics",
        "author": "",
        "aff": "",
        "rating": "3;6;6;8",
        "confidence": "4;5;5;4",
        "correctness": "4;3;4;4",
        "technical_novelty": "2;2;4;4",
        "empirical_novelty": "2;2;3;4",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 4.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.14002800840280097,
        "corr_rating_correctness": -0.08084520834544431,
        "project": "",
        "github": ""
    },
    {
        "id": "F0v5uBM-q5K",
        "title": "Beyond Quantization: Power aware neural networks",
        "track": "main",
        "status": "Reject",
        "keywords": "Deep neural networks;weight quantization;model compression;power-accuracy tradeoff;power consumption",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "4;3;4;2",
        "correctness": "1;2;3;3",
        "technical_novelty": "2;2;4;3",
        "empirical_novelty": "1;0;3;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.25,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5222329678670935,
        "corr_rating_correctness": 0.8703882797784892,
        "project": "",
        "github": ""
    },
    {
        "id": "F1Z3QH-VjZE",
        "title": "A Fair Generative Model Using Total Variation Distance",
        "track": "main",
        "status": "Reject",
        "keywords": "trustworthy AI;fairness;generative model;total variation distance",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "3;5;4;3",
        "correctness": "4;2;3;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4061811972299616,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "F2r3wYar3Py",
        "title": "Learning from One and Only One Shot",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "5;4;3;5",
        "correctness": "4;3;4;3",
        "technical_novelty": "4;4;3;3",
        "empirical_novelty": "4;2;1;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 4.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5222329678670935,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "F5Em8ASCosV",
        "title": "Causal Contextual Bandits with Targeted Interventions",
        "track": "main",
        "status": "Poster",
        "keywords": "causality;contextual bandits;causal inference;bandits",
        "author": "",
        "aff": "Robert Bosch Centre for Data Science and Artificial Intelligence, Department of Computer Science and Engineering, Indian Institute of Technology Madras, Chennai, India",
        "rating": "5;5;6;6",
        "confidence": "3;3;3;3",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "F6S_3RSWFI7",
        "title": "Revisiting the Monotonicity Constraint in Cooperative Multi-Agent Reinforcement Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "multi-agent;reinforcement learning;monotonicity constraint",
        "author": "",
        "aff": "",
        "rating": "3;3;3",
        "confidence": "5;3;3",
        "correctness": "2;3;3",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "3;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "F72ximsx7C1",
        "title": "How Attentive are Graph Attention Networks?",
        "track": "main",
        "status": "Poster",
        "keywords": "graph attention networks;dynamic attention;GAT;GNN",
        "author": "",
        "aff": "Technion; Language Technologies Institute, Carnegie Mellon University",
        "rating": "5;5;6;8",
        "confidence": "5;4;3;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;2;3;4",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.28867513459481287,
        "corr_rating_correctness": 0.9428090415820632,
        "project": "",
        "github": "https://github.com/tech-srl/how_attentive_are_gats"
    },
    {
        "id": "F7_odJIeQ26",
        "title": "Pretrained Language Models are Symbolic Mathematics Solvers too!",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "1;3;3;6",
        "confidence": "4;4;4;5",
        "correctness": "2;2;3;3",
        "technical_novelty": "1;2;1;2",
        "empirical_novelty": "2;3;1;4",
        "presentation": "",
        "rating_avg": 3.25,
        "confidence_avg": 4.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 1.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8892972917998875,
        "corr_rating_correctness": 0.7001400420140049,
        "project": "",
        "github": ""
    },
    {
        "id": "F7nD--1JIC",
        "title": "Shapley-NAS: Discovering Operation Contribution for Neural Architecture Search",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "2;4;4;4",
        "correctness": "2;2;3;3",
        "technical_novelty": "3;2;2;2",
        "empirical_novelty": "3;2;3;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 1.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "F9McnN1dITx",
        "title": "Evolving Neural Update Rules for Sequence Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Neural Update Rules;Evolution",
        "author": "",
        "aff": "",
        "rating": "3;3;5",
        "confidence": "3;3;3",
        "correctness": "2;3;3",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 3.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "FASW5Ed837",
        "title": "Bandwidth-based Step-Sizes for Non-Convex Stochastic Optimization",
        "track": "main",
        "status": "Reject",
        "keywords": "Stochastic gradient descent;bandwidth-based step size;non-asymptotic analysis",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "5;4;3;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.899228803025897,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "FCxWzalZp9N",
        "title": "AF$_2$: Adaptive Focus Framework for Aerial Imagery Segmentation",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;3;5",
        "correctness": "3;4;3;4",
        "technical_novelty": "2;1;2;2",
        "empirical_novelty": "2;1;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "FD8xldQIgdq",
        "title": "Robust Models Are More Interpretable Because Attributions Look Normal",
        "track": "main",
        "status": "Reject",
        "keywords": "Explainability;Decision Boundary;Attribution;Adversarial Robustness",
        "author": "",
        "aff": "",
        "rating": "3;6;6;6",
        "confidence": "3;3;4;3",
        "correctness": "2;3;4;4",
        "technical_novelty": "4;2;2;3",
        "empirical_novelty": "0;2;2;0",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 1.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.8703882797784892,
        "project": "",
        "github": ""
    },
    {
        "id": "FEBFJ98FKx",
        "title": "TPU-GAN: Learning temporal coherence from dynamic point cloud sequences",
        "track": "main",
        "status": "Poster",
        "keywords": "Point cloud super resolution;Temporal learning;Generative Adversarial Networks",
        "author": "",
        "aff": "School of Computer Science, Carnegie Mellon University; Department of Mechanical Engineering, Carnegie Mellon University",
        "rating": "6;6;6;6;6",
        "confidence": "4;4;3;3;4",
        "correctness": "3;4;4;3;3",
        "technical_novelty": "3;2;2;2;3",
        "empirical_novelty": "3;3;3;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.6,
        "correctness_avg": 3.4,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "FEDfGWVZYIn",
        "title": "RelaxLoss: Defending Membership Inference Attacks without Losing Utility",
        "track": "main",
        "status": "Spotlight",
        "keywords": "membership inference attack;defense",
        "author": "",
        "aff": "CISPA Helmholtz Center for Information Security; Salesforce Research, University of Maryland, Max Planck Institute for Informatics",
        "rating": "8;8;8",
        "confidence": "4;4;2",
        "correctness": "3;3;3",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "3;0;3",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/DingfanChen/RelaxLoss"
    },
    {
        "id": "FFGDKzLasUa",
        "title": "Stochastic Deep Networks with Linear Competing Units for Model-Agnostic Meta-Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Stochastic Deep Networks;LWTA;Meta-Learning",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "3;3;3;4",
        "correctness": "3;2;2;4",
        "technical_novelty": "3;2;3;2",
        "empirical_novelty": "3;3;3;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": -0.17407765595569782,
        "project": "",
        "github": ""
    },
    {
        "id": "FFM_oJeqZx",
        "title": "Adaptive Pseudo-labeling for Quantum Calculations",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "3;3;4;5",
        "correctness": "3;4;3;4",
        "technical_novelty": "1;2;4;3",
        "empirical_novelty": "2;3;4;4",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.7608859102526822,
        "corr_rating_correctness": 0.6882472016116854,
        "project": "",
        "github": ""
    },
    {
        "id": "FH_mZOKFX-b",
        "title": "Takeuchi's Information Criteria as Generalization Measures for DNNs Close to NTK Regime",
        "track": "main",
        "status": "Reject",
        "keywords": "Generalization;correlation;experiments",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "3;3;4;3",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "FKp8-pIRo3y",
        "title": "Wish you were here: Hindsight Goal Selection for long-horizon dexterous manipulation",
        "track": "main",
        "status": "Poster",
        "keywords": "goal-conditioned reinforcement learning;learning from demonstrations;long-horizon dexterous manipulation;bi-manual manipulation",
        "author": "",
        "aff": "Intrinsic LLC; DeepMind, University of Edinburgh; DeepMind",
        "rating": "6;6;6;6",
        "confidence": "3;3;4;4",
        "correctness": "4;2;4;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "3;2;2;2",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "FLA55mBee6Q",
        "title": "COptiDICE: Offline Constrained Reinforcement Learning via Stationary Distribution Correction Estimation",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Offline Reinforcement Learning;Offline Constrained Reinforcement Learning;Stationary Distribution Correction Estimation",
        "author": "",
        "aff": "KAIST; DeepMind",
        "rating": "6;6;8;8",
        "confidence": "3;3;4;2",
        "correctness": "4;4;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "FLa1RPjpm2L",
        "title": "ED2: An Environment Dynamics Decomposition Framework for World Model Construction",
        "track": "main",
        "status": "Reject",
        "keywords": "model based reinforcement learning",
        "author": "",
        "aff": "",
        "rating": "3;5;5",
        "confidence": "4;5;3",
        "correctness": "4;3;2",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 4.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.8660254037844385,
        "project": "",
        "github": "https://github.com/ED2-source-code/ED2"
    },
    {
        "id": "FNSR8Okx8a",
        "title": "Beyond Prioritized Replay: Sampling States in Model-Based Reinforcement Learning via Simulated Priorities",
        "track": "main",
        "status": "Reject",
        "keywords": "experience replay;model-based reinforcement learning;sampling distribution;search-control;Dyna;stochastic gradient Langevin dynamics",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "5;4;4;4",
        "correctness": "3;3;2;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "FOfKpDnp2P",
        "title": "BIGRoC: Boosting Image Generation via a Robust Classifier",
        "track": "main",
        "status": "Reject",
        "keywords": "Image Generation;Adversarial Robustness;Perceptually Aligned Gradients",
        "author": "",
        "aff": "",
        "rating": "3;5;5",
        "confidence": "5;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "2;3;2",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 4.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "FPCMqjI0jXN",
        "title": "Domino: Discovering Systematic Errors with Cross-Modal Embeddings",
        "track": "main",
        "status": "Oral",
        "keywords": "robustness;subgroup analysis;error analysis;multimodal;slice discovery",
        "author": "",
        "aff": "; Stanford University, USA",
        "rating": "6;8;8",
        "confidence": "3;2;2",
        "correctness": "2;3;4",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 7.333333333333333,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9999999999999998,
        "corr_rating_correctness": 0.8660254037844385,
        "project": "",
        "github": ""
    },
    {
        "id": "FPGs276lUeq",
        "title": "Palette: Image-to-Image Diffusion Models",
        "track": "main",
        "status": "Withdraw",
        "keywords": "machine learning;artificial intelligence;computer vision",
        "author": "",
        "aff": "",
        "rating": "3;3;3;10",
        "confidence": "4;4;3;4",
        "correctness": "1;3;4;4",
        "technical_novelty": "1;2;2;3",
        "empirical_novelty": "2;2;2;4",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.4714045207910316,
        "project": "",
        "github": ""
    },
    {
        "id": "FQOC5u-1egI",
        "title": "Handling Distribution Shifts on Graphs: An Invariance Perspective",
        "track": "main",
        "status": "Poster",
        "keywords": "Representation Learning on Graphs;Out-of-Distribution Generalization;Domain Shift;Graph Structure Learning;Invariant Models",
        "author": "",
        "aff": "University of Illinois at Chicago; Amazon; Shanghai Jiao Tong University",
        "rating": "5;6;6;6",
        "confidence": "4;2;4;3",
        "correctness": "3;4;4;3",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "2;3;3;0",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5222329678670935,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": "https://github.com/qitianwu/GraphOOD-EERM"
    },
    {
        "id": "FRct9agbco",
        "title": "Constrained Mean Shift for Representation Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Computer Vision;Self-Supervised Learning;Representation Learning",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5",
        "confidence": "5;3;4;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "FRxhHdnxt1",
        "title": "Amortized Tree Generation for Bottom-up Synthesis Planning and Synthesizable Molecular Design",
        "track": "main",
        "status": "Spotlight",
        "keywords": "molecular design;synthesis planning;tree generation;graph generation",
        "author": "",
        "aff": "Department of Chemical Engineering, Massachusetts Institute of Technology; Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology",
        "rating": "3;8;8;8",
        "confidence": "4;3;4;5",
        "correctness": "2;3;4;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;3;3;4",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.8703882797784891,
        "project": "",
        "github": ""
    },
    {
        "id": "FS0XKbpkdOu",
        "title": "Sphere2Vec: Self-Supervised Location Representation Learning on Spherical Surfaces",
        "track": "main",
        "status": "Reject",
        "keywords": "Self-Supervised Learning;Location Representation Learning;Double Fourier Sphere",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;4;2;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;2;1;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.13245323570650439,
        "corr_rating_correctness": 0.6622661785325219,
        "project": "",
        "github": ""
    },
    {
        "id": "FVJTyOUJzti",
        "title": "Adaptive Differential Privacy in Federated Learning: A Priority-Based Approach",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Federated Learning;Differential privacy;Feature importance;Deep neural networks",
        "author": "",
        "aff": "",
        "rating": "1;1;3;3;3",
        "confidence": "3;5;4;4;4",
        "correctness": "2;1;2;2;4",
        "technical_novelty": "1;1;2;1;3",
        "empirical_novelty": "2;1;2;1;2",
        "presentation": "",
        "rating_avg": 2.2,
        "confidence_avg": 4.0,
        "correctness_avg": 2.2,
        "technical_novelty_avg": 1.6,
        "empirical_novelty_avg": 1.6,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5833333333333334,
        "project": "",
        "github": ""
    },
    {
        "id": "FWiwSGJ_Bpa",
        "title": "Non-Parametric Neuro-Adaptive Control Subject to Task Specifications",
        "track": "main",
        "status": "Reject",
        "keywords": "Neural-network-control;nonlinear systems;continuous control;adaptive control;task specification;signal temporal logic",
        "author": "",
        "aff": "",
        "rating": "3;5;5",
        "confidence": "4;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "2;1;3",
        "empirical_novelty": "2;1;3",
        "presentation": "",
        "rating_avg": 4.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.49999999999999983,
        "corr_rating_correctness": 0.49999999999999983,
        "project": "",
        "github": ""
    },
    {
        "id": "FYUzzBPh_j",
        "title": "Communicating via Markov Decision Processes",
        "track": "main",
        "status": "Reject",
        "keywords": "coding;communication;maximum entropy reinforcement learning;minimum entropy coupling",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;3;4;3",
        "correctness": "2;3;2;3",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;1;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "FZoZ7a31GCW",
        "title": "Ancestral protein sequence reconstruction using a tree-structured Ornstein-Uhlenbeck variational autoencoder",
        "track": "main",
        "status": "Poster",
        "keywords": "biological sequences;variational autoencoders;latent representations;ornstein-uhlenbeck process;evolution",
        "author": "",
        "aff": "Probabilistic programming group, PLTC Section, University of Copenhagen, Copenhagen, Denmark; Department of Statistics, University of Oxford, Oxford, United Kingdom; Probabilistic programming group, SCARB / PLTC Section, Departments of Biology / Computer Science, University of Copenhagen, Copenhagen, Denmark; Biochemistry Department, Brandeis University, MA, USA",
        "rating": "5;8;8",
        "confidence": "4;5;4",
        "correctness": "3;3;3",
        "technical_novelty": "3;3;4",
        "empirical_novelty": "1;3;2",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.3333333333333335,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "FZyZiRYbdK8",
        "title": "Distributionally Robust Learning for Uncertainty Calibration under Domain Shift",
        "track": "main",
        "status": "Reject",
        "keywords": "Domain shift;uncertainty estimation;calibration;distributional robustness;unsupervised domain adaptation;semi-supervised learning",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "3;3;5;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.17407765595569782,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "FeaitX_a5Av",
        "title": "GSD: Generalized Stochastic Decoding",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Natural Language Processing;Decoding Algorithms",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "5;4;4;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "1;2;2;1",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": "https://github.com/ginoailab/gsd.git"
    },
    {
        "id": "Fh_NyEuejsZ",
        "title": "ZenDet: Revisiting Efficient Object Detection Backbones from Zero-Shot Neural Architecture Search",
        "track": "main",
        "status": "Reject",
        "keywords": "Object Detection;Detection Backbone;Neural Architecture Search;Zero-Shot NAS",
        "author": "",
        "aff": "",
        "rating": "6;6;6",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "4;2;3",
        "empirical_novelty": "4;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "Fia60I79-4B",
        "title": "TS-BERT: A fusion model for Pre-trainning Time Series-Text Representations",
        "track": "main",
        "status": "Reject",
        "keywords": "Time Series-Text Representations;Pre-training;Mutilmodal",
        "author": "",
        "aff": "",
        "rating": "1;3;3",
        "confidence": "4;5;4",
        "correctness": "2;2;3",
        "technical_novelty": "1;1;2",
        "empirical_novelty": "2;1;2",
        "presentation": "",
        "rating_avg": 2.3333333333333335,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 1.3333333333333333,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.4999999999999999,
        "corr_rating_correctness": 0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "Fj1Tpym9KxH",
        "title": "A Closer Look at Smoothness in Domain Adversarial Training",
        "track": "main",
        "status": "Reject",
        "keywords": "Domain Adaptation;Optimization",
        "author": "",
        "aff": "",
        "rating": "5;5;5;8",
        "confidence": "2;3;4;4",
        "correctness": "4;3;3;4",
        "technical_novelty": "2;2;2;4",
        "empirical_novelty": "2;2;3;4",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5222329678670935,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "Fl3Mg_MZR-",
        "title": "On Lottery Tickets and Minimal Task Representations in Deep Reinforcement Learning",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Reinforcement Learning;Sparsity;Pruning;Lottery Ticket Hypothesis",
        "author": "",
        "aff": "Technical University Berlin, Science of Intelligence",
        "rating": "5;8;8",
        "confidence": "4;3;4",
        "correctness": "3;4;3",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "3;3;4",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 3.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5,
        "corr_rating_correctness": 0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "FlwzVjfMryn",
        "title": "Multi-objective Optimization by Learning Space Partition",
        "track": "main",
        "status": "Poster",
        "keywords": "Optimization;Machine Learning",
        "author": "",
        "aff": "Worcester Polytechnic Institute; Facebook AI Research; Brown University; UC Berkeley",
        "rating": "6;6;8;8",
        "confidence": "4;4;4;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;3;4",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "FmBegXJToY",
        "title": "Procedural generalization by planning with self-supervised world models",
        "track": "main",
        "status": "Poster",
        "keywords": "Self-Supervised Learning;Model-Based RL;Generalization in RL",
        "author": "",
        "aff": "DeepMind, London, UK",
        "rating": "6;6;8;8",
        "confidence": "3;4;4;2",
        "correctness": "4;2;4;4",
        "technical_novelty": "1;2;2;3",
        "empirical_novelty": "3;2;4;4",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.30151134457776363,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "Fn7i_r5rR0q",
        "title": "Do deep networks transfer invariances across classes?",
        "track": "main",
        "status": "Poster",
        "keywords": "invariance;augmentation;nuisance transformation;imbalance;long tail",
        "author": "",
        "aff": "Stanford University; University of Pennsylvania",
        "rating": "5;6;6;8",
        "confidence": "5;2;4;4",
        "correctness": "4;2;2;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "3;3;3;4",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.15789473684210528,
        "corr_rating_correctness": -0.20751433915982243,
        "project": "",
        "github": "https://github.com/AllanYangZhou/generative-invariance-transfer"
    },
    {
        "id": "FndDxSz3LxQ",
        "title": "Learn Locally, Correct Globally: A Distributed Algorithm for Training Graph Neural Networks",
        "track": "main",
        "status": "Poster",
        "keywords": "Graph Neural Networks;GNN;GCN;Distributed Training",
        "author": "",
        "aff": "Pennsylvania State University, University Park, PA 16802, USA",
        "rating": "5;6;6;6",
        "confidence": "3;2;3;3",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "0;3;3;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 2.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "FpKgG31Z_i9",
        "title": "Learning Rate Grafting: Transferability of Optimizer Tuning",
        "track": "main",
        "status": "Reject",
        "keywords": "Optimization;Learning Rate Schedules;BERT",
        "author": "",
        "aff": "",
        "rating": "3;3;3;8",
        "confidence": "5;3;5;3",
        "correctness": "3;2;2;3",
        "technical_novelty": "1;2;2;3",
        "empirical_novelty": "2;2;2;4",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 4.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "FpnQMmnsE8Y",
        "title": "Recurrent Parameter Generators",
        "track": "main",
        "status": "Reject",
        "keywords": "recurrent;parameters;degrees of freedom",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "5;5;4;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 4.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9045340337332909,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "FqKolXKrQGA",
        "title": "Learning to Infer the Structure of Network Games",
        "track": "main",
        "status": "Reject",
        "keywords": "graphs;networks;game theory;graph neural networks",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6;6",
        "confidence": "3;3;3;3;2",
        "correctness": "4;2;4;4;4",
        "technical_novelty": "2;1;1;3;2",
        "empirical_novelty": "3;1;2;0;3",
        "presentation": "",
        "rating_avg": 4.6,
        "confidence_avg": 2.8,
        "correctness_avg": 3.6,
        "technical_novelty_avg": 1.8,
        "empirical_novelty_avg": 1.8,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5160468465421401,
        "corr_rating_correctness": 0.5897678246195885,
        "project": "",
        "github": ""
    },
    {
        "id": "FqMXxvHquTA",
        "title": "SegTime: Precise Time Series Segmentation without Sliding Window",
        "track": "main",
        "status": "Reject",
        "keywords": "time series;time series segmentation;lstm;rnn;architecture;cnn;pyramid pooling;multi-scale pooling;sequence;encoder;decoder;resnet;step-wise",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "5;4;3;3",
        "correctness": "2;3;2;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8703882797784891,
        "corr_rating_correctness": 0.5222329678670935,
        "project": "",
        "github": ""
    },
    {
        "id": "FqRHeQTDU5N",
        "title": "Learning to Give Checkable Answers with Prover-Verifier Games",
        "track": "main",
        "status": "Reject",
        "keywords": "AI Safety;verifiable learning;robustness;adversarial learning;proof systems",
        "author": "",
        "aff": "",
        "rating": "5;6;6;6",
        "confidence": "3;3;1;3",
        "correctness": "4;4;4;3",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 2.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "FrJFF4YxWm",
        "title": "Learning Rational Skills for Planning from Demonstrations and Instructions",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Learning for Planning;Compositional Generalization",
        "author": "",
        "aff": "",
        "rating": "3;3;6;6",
        "confidence": "4;4;2;2",
        "correctness": "3;2;3;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;3;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.7071067811865476,
        "project": "",
        "github": ""
    },
    {
        "id": "FuLL40HLCRn",
        "title": "ST-DDPM: Explore Class Clustering for Conditional Diffusion Probabilistic Models",
        "track": "main",
        "status": "Reject",
        "keywords": "conditional generation;diffusion models;decoupling;interpretability",
        "author": "",
        "aff": "",
        "rating": "6;6;6;6",
        "confidence": "4;3;3;3",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "FvfV64rovnY",
        "title": "Explaining Scaling Laws of Neural Network Generalization",
        "track": "main",
        "status": "Reject",
        "keywords": "scaling laws;neural networks;generalization;overparameterized models;underparameterized models",
        "author": "",
        "aff": "",
        "rating": "3;3;5",
        "confidence": "4;3;2",
        "correctness": "2;3;3",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "3;3;4",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 3.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 3.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8660254037844387,
        "corr_rating_correctness": 0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "FxBdFwFjXX",
        "title": "Multi-Task Distribution Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Data Augmentation;Distribution Shift;Multi-Task Learning",
        "author": "",
        "aff": "",
        "rating": "1;1;3",
        "confidence": "4;4;4",
        "correctness": "2;3;2",
        "technical_novelty": "1;1;3",
        "empirical_novelty": "0;1;3",
        "presentation": "",
        "rating_avg": 1.6666666666666667,
        "confidence_avg": 4.0,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 1.6666666666666667,
        "empirical_novelty_avg": 1.3333333333333333,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.4999999999999999,
        "project": "",
        "github": ""
    },
    {
        "id": "Fza94Y8VS4a",
        "title": "The Evolution of Uncertainty of Learning in Games",
        "track": "main",
        "status": "Poster",
        "keywords": "learning in games;differential entropy",
        "author": "",
        "aff": "Singapore University of Technology and Design; Royal Holloway, University of London; London School of Economics",
        "rating": "5;6;6;8",
        "confidence": "2;3;2;3",
        "correctness": "3;4;4;4",
        "technical_novelty": "2;3;4;2",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 2.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.6882472016116854,
        "corr_rating_correctness": 0.6622661785325219,
        "project": "",
        "github": ""
    },
    {
        "id": "G-7GlfTneYg",
        "title": "VoiceFixer: Toward General Speech Restoration with Neural Vocoder",
        "track": "main",
        "status": "Reject",
        "keywords": "Speech Restoration;Neural Vocoder;Speech Denoising;Speech Declipping;Speech Dereverberation;Speech Super-resolution",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "5;5;4;4",
        "correctness": "2;3;2;3",
        "technical_novelty": "1;2;2;2",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 4.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9622504486493761,
        "corr_rating_correctness": 0.19245008972987526,
        "project": "https://anonymous20211004.github.io/demo-vf/",
        "github": ""
    },
    {
        "id": "G0CuTynjgQa",
        "title": "Generalization of GANs and overparameterized models under Lipschitz continuity",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;6;8",
        "confidence": "4;4;3;3",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8320502943378437,
        "corr_rating_correctness": 0.8320502943378437,
        "project": "",
        "github": ""
    },
    {
        "id": "G1J5OYjoiWb",
        "title": "An Attempt to Model Human Trust with Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Trust;Confidence;Q-learning;Reward Circuit",
        "author": "",
        "aff": "",
        "rating": "3;3;3;6",
        "confidence": "4;3;3;3",
        "correctness": "1;2;2;3",
        "technical_novelty": "1;3;2;3",
        "empirical_novelty": "1;2;1;3",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 3.25,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "G33_uTwQiL",
        "title": "Equivariant Vector Field Network for Many-body System Modeling",
        "track": "main",
        "status": "Reject",
        "keywords": "equivariant neural network;gradient fields;many-body system;molecular conformation generation",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;5;3;4",
        "correctness": "3;3;2;2",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;3;3;0",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "G7PfyLimZBp",
        "title": "Understanding the Generalization of Adam in Learning Neural Networks with Proper Regularization",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "4;4;3;3",
        "correctness": "2;4;3;4",
        "technical_novelty": "3;4;3;3",
        "empirical_novelty": "2;0;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8164965809277259,
        "corr_rating_correctness": 0.7385489458759963,
        "project": "",
        "github": ""
    },
    {
        "id": "G89-1yZLFHk",
        "title": "Data Efficient Language-Supervised Zero-Shot Recognition with Optimal Transport Distillation",
        "track": "main",
        "status": "Poster",
        "keywords": "Zero shot learning;contrastive learning;optimal transport;vision and language",
        "author": "",
        "aff": "Meta Reality Labs; UC Berkeley",
        "rating": "5;6;6;6;6",
        "confidence": "4;4;5;4;4",
        "correctness": "3;3;3;3;3",
        "technical_novelty": "3;3;3;4;3",
        "empirical_novelty": "2;4;2;2;3",
        "presentation": "",
        "rating_avg": 5.8,
        "confidence_avg": 4.2,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.2,
        "empirical_novelty_avg": 2.6,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.25000000000000006,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/facebookresearch/OTTER"
    },
    {
        "id": "G9JXCpShpni",
        "title": "The guide and the explorer: smart agents for resource-limited iterated batch reinforcement learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Model-based reinforcement learning;Dyna;exploration;planning;DQN",
        "author": "",
        "aff": "",
        "rating": "3;3;5",
        "confidence": "4;2;4",
        "correctness": "1;3;3",
        "technical_novelty": "2;1;3",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5000000000000001,
        "corr_rating_correctness": 0.5000000000000001,
        "project": "",
        "github": ""
    },
    {
        "id": "G9M4FU8Ggo",
        "title": "Neural Architecture Search via Ensemble-based Knowledge Distillation",
        "track": "main",
        "status": "Reject",
        "keywords": "NAS;Knowledge Distillation;Imagenet",
        "author": "",
        "aff": "",
        "rating": "3;3;5",
        "confidence": "4;4;5",
        "correctness": "3;2;2",
        "technical_novelty": "2;3;2",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 1.0,
        "corr_rating_correctness": -0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "GBszJ1XlKDj",
        "title": "Quasi-Newton policy gradient algorithms",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "3;3;4;3",
        "correctness": "3;4;3;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "1;0;2;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "GDUfz1phf06",
        "title": "AutoNF: Automated Architecture Optimization of Normalizing Flows Using a Mixture Distribution Formulation",
        "track": "main",
        "status": "Reject",
        "keywords": "normalizing flow;architecture optimization",
        "author": "",
        "aff": "",
        "rating": "3;5;5;8",
        "confidence": "4;2;4;3",
        "correctness": "3;3;2;3",
        "technical_novelty": "3;2;3;4",
        "empirical_novelty": "3;1;3;4",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.37998029782867415,
        "corr_rating_correctness": 0.08084520834544431,
        "project": "",
        "github": ""
    },
    {
        "id": "GE0w59n2mqe",
        "title": "Learning to Estimate Epistemic Uncertainty in Neural Networks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "uncertainty quantification;regression;machine learning;deep learning",
        "author": "",
        "aff": "",
        "rating": "1;1;1;3",
        "confidence": "4;5;4;5",
        "correctness": "2;3;1;2",
        "technical_novelty": "1;1;1;2",
        "empirical_novelty": "1;1;1;2",
        "presentation": "",
        "rating_avg": 1.5,
        "confidence_avg": 4.5,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 1.25,
        "empirical_novelty_avg": 1.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "GFRq2JxiI7d",
        "title": "How much pre-training is enough to discover a good subnetwork?",
        "track": "main",
        "status": "Withdraw",
        "keywords": "lottery ticket hypothesis;pruning;greedy selection",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "3;3;2;2",
        "correctness": "3;2;3;3",
        "technical_novelty": "3;3;3;2",
        "empirical_novelty": "2;2;3;0",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 2.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "GIBm-_kax6",
        "title": "Expected Improvement-based Contextual Bandits",
        "track": "main",
        "status": "Reject",
        "keywords": "Linear Bandits;Contextual Bandits;Expected Improvement;Neural Tangent Kernel",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6;6",
        "confidence": "4;4;4;3;4",
        "correctness": "2;1;4;4;3",
        "technical_novelty": "2;3;3;4;3",
        "empirical_novelty": "3;2;2;3;2",
        "presentation": "",
        "rating_avg": 5.2,
        "confidence_avg": 3.8,
        "correctness_avg": 2.8,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.34299717028501764,
        "corr_rating_correctness": 0.6176470588235294,
        "project": "",
        "github": ""
    },
    {
        "id": "GIEPR9OomyX",
        "title": "Langevin Autoencoders for Learning Deep Latent Variable Models",
        "track": "main",
        "status": "Reject",
        "keywords": "Langevin dynamics;amortized inference;latent variable model;deep generative model",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "3;4;3;3",
        "correctness": "3;2;3;3",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "3;2;0;2",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "GJyRarXzT7Q",
        "title": "Your Fairness May Vary: Pretrained Language Model Fairness in Toxic Text Classification",
        "track": "main",
        "status": "Withdraw",
        "keywords": "group fairness;language models;toxic text classification",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5;6",
        "confidence": "4;5;3;4;4",
        "correctness": "4;2;3;3;4",
        "technical_novelty": "2;2;2;3;2",
        "empirical_novelty": "2;3;2;4;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.2,
        "empirical_novelty_avg": 2.8,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.42257712736425823,
        "project": "",
        "github": ""
    },
    {
        "id": "GMYWzWztDx5",
        "title": "NormFormer: Improved Transformer Pretraining with Extra Normalization",
        "track": "main",
        "status": "Reject",
        "keywords": "Language Modeling;NLP;Transformer;Zero Shot Learning",
        "author": "",
        "aff": "REDACTED",
        "rating": "5;5;8;8",
        "confidence": "4;4;5;4",
        "correctness": "4;3;3;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;4;3;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 4.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896258,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "REDACTED"
    },
    {
        "id": "GOr80bgf52v",
        "title": "Factored World Models for Zero-Shot Generalization in Robotic Manipulation",
        "track": "main",
        "status": "Reject",
        "keywords": "reinforcement learning;world models;robotic manipulation;zero-shot transfer",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "4;3;4;4",
        "correctness": "1;3;3;4",
        "technical_novelty": "3;2;2;3",
        "empirical_novelty": "0;2;2;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.6622661785325219,
        "project": "",
        "github": ""
    },
    {
        "id": "GQcB1D2bxSC",
        "title": "SHAQ: Incorporating Shapley Value Theory into Multi-Agent Q-Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "multi-agent reinforcement learning;Shapley value;value factorisation;Q-learning",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "2;3;2;2",
        "correctness": "2;4;3;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 2.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.8703882797784891,
        "project": "",
        "github": ""
    },
    {
        "id": "GQd7mXSPua",
        "title": "Meta Learning Low Rank Covariance Factors for Energy Based Deterministic Uncertainty",
        "track": "main",
        "status": "Poster",
        "keywords": "calibration;meta-learning",
        "author": "",
        "aff": "KAIST; KAIST, AITRICS",
        "rating": "5;6;6",
        "confidence": "2;3;4",
        "correctness": "3;3;4",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 5.666666666666667,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8660254037844385,
        "corr_rating_correctness": 0.4999999999999999,
        "project": "",
        "github": ""
    },
    {
        "id": "GQjaI9mLet",
        "title": "Independent SE(3)-Equivariant Models for End-to-End Rigid Protein Docking",
        "track": "main",
        "status": "Spotlight",
        "keywords": "protein complexes;protein structure;rigid body docking;SE(3) equivariance;graph neural networks",
        "author": "",
        "aff": "ETH Zurich, Work done during an internship at Tencent AI Lab; MIT; Tencent AI Lab; ETH Zurich",
        "rating": "8;8;8",
        "confidence": "3;5;5",
        "correctness": "4;4;4",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "3;2;3",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/octavian-ganea/equidock_public"
    },
    {
        "id": "GU11Lbci5J",
        "title": "Understanding AdamW through Proximal Methods and Scale-Freeness",
        "track": "main",
        "status": "Reject",
        "keywords": "Optimization of Deep Neural Networks;Scale-free;AdamW",
        "author": "",
        "aff": "",
        "rating": "3;6;6;6",
        "confidence": "4;4;4;4",
        "correctness": "3;4;2;3",
        "technical_novelty": "1;4;2;3",
        "empirical_novelty": "1;3;2;0",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "GUrhfTuf_3",
        "title": "SimVLM: Simple Visual Language Model Pretraining with Weak Supervision",
        "track": "main",
        "status": "Poster",
        "keywords": "Vision-Language Pretraining;Multimodal Language Model;Weak Supervision",
        "author": "",
        "aff": "University of Washington; Carnegie Mellon University; Google Research, Brain Team",
        "rating": "6;6;8",
        "confidence": "5;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "3;3;4",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 3.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4999999999999999,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "GVDwiINkMR",
        "title": "Picking Daisies in Private: Federated Learning from Small Datasets",
        "track": "main",
        "status": "Reject",
        "keywords": "federated learning;distributed;sparse data;daisy chain;small datasets",
        "author": "anonymous",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "3;3;4;4",
        "correctness": "3;2;3;3",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 1.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "GWQWAeE9EpB",
        "title": "DictFormer: Tiny Transformer with Shared Dictionary",
        "track": "main",
        "status": "Poster",
        "keywords": "Transformer;Parameters Sharing;Tiny;On-device Transformer;Machine Translation;Attention;Dictionary Sharing",
        "author": "",
        "aff": "Samsung Research America",
        "rating": "6;6;6;6",
        "confidence": "3;4;2;5",
        "correctness": "4;3;3;3",
        "technical_novelty": "3;4;3;2",
        "empirical_novelty": "3;4;3;2",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "GdPZJxjk46V",
        "title": "Dataset transformations trade-offs to adapt machine learning methods across domains",
        "track": "main",
        "status": "Reject",
        "keywords": "Datasets;multiple domains;cyber-attacks;optimal transport",
        "author": "",
        "aff": "",
        "rating": "1;3;3",
        "confidence": "4;5;4",
        "correctness": "2;3;2",
        "technical_novelty": "1;1;1",
        "empirical_novelty": "1;2;1",
        "presentation": "",
        "rating_avg": 2.3333333333333335,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 1.0,
        "empirical_novelty_avg": 1.3333333333333333,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.4999999999999999,
        "corr_rating_correctness": 0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "GesLOTU_r23",
        "title": "Gradient Explosion and Representation Shrinkage in Infinite Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "deep learning theory;mean-field approximation",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5;8",
        "confidence": "3;3;4;4;3",
        "correctness": "2;3;4;2;3",
        "technical_novelty": "2;2;2;2;3",
        "empirical_novelty": "2;2;3;0;3",
        "presentation": "",
        "rating_avg": 5.2,
        "confidence_avg": 3.4,
        "correctness_avg": 2.8,
        "technical_novelty_avg": 2.2,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.10206207261596574,
        "corr_rating_correctness": 0.36748420762958356,
        "project": "",
        "github": ""
    },
    {
        "id": "GgIq3pALeHW",
        "title": "UAE-PUPET: An Uncertainty-Autoencoder-Based Privacy and Utility Preserving End-to-End Transformation",
        "track": "main",
        "status": "Withdraw",
        "keywords": "privacy;privacy utility tradeoff;autoencoders;deep learning;machine learning;adversary;privacy utility metric;gan;game theory;min-max;variational autoencoder",
        "author": "",
        "aff": "",
        "rating": "1;3;6",
        "confidence": "5;3;3",
        "correctness": "2;4;4",
        "technical_novelty": "1;2;3",
        "empirical_novelty": "1;3;3",
        "presentation": "",
        "rating_avg": 3.3333333333333335,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.802955068546966,
        "corr_rating_correctness": 0.802955068546966,
        "project": "",
        "github": ""
    },
    {
        "id": "GgOEm9twFO_",
        "title": "PhaseFool: Phase-oriented Audio Adversarial Examples via Energy Dissipation",
        "track": "main",
        "status": "Reject",
        "keywords": "Audio adversarial examples;audio adversarial attacks;automatic speech recognition",
        "author": "",
        "aff": "",
        "rating": "5;5;5;8",
        "confidence": "3;4;4;4",
        "correctness": "2;3;3;4",
        "technical_novelty": "3;3;3;4",
        "empirical_novelty": "2;2;2;4",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.816496580927726,
        "project": "https://phasefool-demo.github.io/phasefool-demo/",
        "github": ""
    },
    {
        "id": "GhVS8_yPeEa",
        "title": "Effect of scale on catastrophic forgetting in neural networks",
        "track": "main",
        "status": "Poster",
        "keywords": "Catastrophic forgetting;continual learning;scaling;language modeling;image classification",
        "author": "",
        "aff": "Google Research, Blueshift",
        "rating": "5;5;8;8",
        "confidence": "4;4;4;5",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896258,
        "corr_rating_correctness": 0.5773502691896258,
        "project": "",
        "github": ""
    },
    {
        "id": "GiddFXGDmqp",
        "title": "Spatially Invariant Unsupervised 3D Object-Centric Learning and Scene Decomposition",
        "track": "main",
        "status": "Reject",
        "keywords": "generatvie model;variational autoencoder;mixture model;unsupervised object centric learning",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6;6",
        "confidence": "4;4;2;4;5",
        "correctness": "3;3;3;4;3",
        "technical_novelty": "2;3;2;3;4",
        "empirical_novelty": "2;3;2;3;3",
        "presentation": "",
        "rating_avg": 5.4,
        "confidence_avg": 3.8,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.8,
        "empirical_novelty_avg": 2.6,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5833333333333333,
        "corr_rating_correctness": 0.6123724356957945,
        "project": "",
        "github": ""
    },
    {
        "id": "GlN8MUkciwi",
        "title": "Learning Context-Adapted Video-Text Retrieval by Attending to User Comments",
        "track": "main",
        "status": "Reject",
        "keywords": "Multimodal Representation Learning;Video;Text;Retrieval;User Comments",
        "author": "",
        "aff": "Under Review at ICLR 2022",
        "rating": "5;5;6;6",
        "confidence": "4;4;3;3",
        "correctness": "2;3;3;2",
        "technical_novelty": "3;3;2;2",
        "empirical_novelty": "2;3;3;2",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "Gnh9rFw6ff0",
        "title": "What Makes for Good Representations for Contrastive Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Unsupervised learning;Self-supervised learning;Contrastive learning;Minimal sufficient representation",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "4;4;4;4",
        "correctness": "2;3;2;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5222329678670935,
        "project": "",
        "github": ""
    },
    {
        "id": "GoCNFW6Emb",
        "title": "VORTEX: Physics-Driven Data Augmentations for Consistency Training for Robust Accelerated MRI Reconstruction",
        "track": "main",
        "status": "Withdraw",
        "keywords": "medical imaging;MRI;radiology;image reconstruction;inverse problems;distribution shift;robustness",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "3;4;3;5",
        "correctness": "2;3;3;3",
        "technical_novelty": "1;2;2;2",
        "empirical_novelty": "0;2;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.7608859102526822,
        "corr_rating_correctness": 0.9271726499455306,
        "project": "",
        "github": ""
    },
    {
        "id": "Gpp1dfvZYYH",
        "title": "ProgFed: Effective, Communication, and Computation Efficient Federated Learning by Progressive Training",
        "track": "main",
        "status": "Reject",
        "keywords": "federated learning;progressive learning",
        "author": "",
        "aff": "",
        "rating": "5;5;6;8",
        "confidence": "3;5;3;4",
        "correctness": "3;2;3;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.8660254037844386,
        "project": "",
        "github": ""
    },
    {
        "id": "GrFix2vWsh4",
        "title": "The hidden label-marginal biases of segmentation losses",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "5;3;4;3",
        "correctness": "4;3;3;3",
        "technical_novelty": "1;2;3;3",
        "empirical_novelty": "1;2;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7385489458759963,
        "corr_rating_correctness": -0.9428090415820632,
        "project": "",
        "github": ""
    },
    {
        "id": "GrJDb8KXPA3",
        "title": "FEATURE-AUGMENTED HYPERGRAPH NEURAL NETWORKS",
        "track": "main",
        "status": "Withdraw",
        "keywords": "graph representation learning\uff0chypergraph learning",
        "author": "",
        "aff": "",
        "rating": "3;3;3;6",
        "confidence": "5;2;3;4",
        "correctness": "3;2;2;4",
        "technical_novelty": "2;1;2;3",
        "empirical_novelty": "1;2;2;2",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.2581988897471611,
        "corr_rating_correctness": 0.8703882797784892,
        "project": "",
        "github": ""
    },
    {
        "id": "GrvigKxc13E",
        "title": "Gradient play in stochastic games: stationary points, convergence, and sample complexity",
        "track": "main",
        "status": "Reject",
        "keywords": "multiagent reinforcement learning;stochastic game;policy gradient;Nash equilibrium;sample complexity",
        "author": "",
        "aff": "",
        "rating": "3;6;8",
        "confidence": "5;4;5",
        "correctness": "4;4;4",
        "technical_novelty": "4;3;3",
        "empirical_novelty": "3;0;0",
        "presentation": "",
        "rating_avg": 5.666666666666667,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 3.3333333333333335,
        "empirical_novelty_avg": 1.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.11470786693528084,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "GsH-K1VIyy",
        "title": "Data-Driven Offline Optimization for Architecting Hardware Accelerators",
        "track": "main",
        "status": "Poster",
        "keywords": "computer architecture and systems;machine learning;data-driven optimization",
        "author": "",
        "aff": "Not provided; Google Research; UC Berkeley",
        "rating": "6;6;8;8",
        "confidence": "3;3;4;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "3;2;3;2",
        "empirical_novelty": "3;3;3;0",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 1.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "GthNKCqdDg",
        "title": "Selective Token Generation for Few-shot Language Modeling",
        "track": "main",
        "status": "Reject",
        "keywords": "Natural Language Generation;Reinforcement Learning;Few-shot Learning;Deep Learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;5;4;3",
        "correctness": "3;2;2;4",
        "technical_novelty": "2;1;3;2",
        "empirical_novelty": "2;1;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7071067811865475,
        "corr_rating_correctness": 0.30151134457776363,
        "project": "",
        "github": ""
    },
    {
        "id": "GuEEPa5tqW",
        "title": "Enhancing Transformer Efficiency for Multivariate Time Series Classification",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;3;6",
        "confidence": "4;4;4;3",
        "correctness": "4;3;2;3",
        "technical_novelty": "1;2;1;2",
        "empirical_novelty": "1;2;1;2",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 1.5,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "GugZ5DzzAu",
        "title": "Permutation Compressors for Provably Faster Distributed Nonconvex Optimization",
        "track": "main",
        "status": "Poster",
        "keywords": "MARINA;distributed training;permutation compressor;correlated compressor;Hessian variance;communication complexity;nonconvex optimization",
        "author": "",
        "aff": "KAUST, Saudi Arabia",
        "rating": "5;6;6;6",
        "confidence": "3;2;3;3",
        "correctness": "3;4;4;4",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "1;3;2;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 2.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "Gw9vA80c8_n",
        "title": "HyperCube: Implicit Field Representations of Voxelized 3D Models",
        "track": "main",
        "status": "Withdraw",
        "keywords": "voxel;implicit field;3D objects",
        "author": "",
        "aff": "",
        "rating": "3;3;3;6",
        "confidence": "4;3;2;3",
        "correctness": "3;2;3;4",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;0",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "GwA--zyF4w",
        "title": "Learning Canonical Embedding for Non-rigid Shape Matching",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Deep Functional Maps;Symmetry group;Point Clouds;Linear Transformation;Canonical 3D shape Embedding",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;3;4",
        "correctness": "2;2;3;4",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.9045340337332909,
        "project": "",
        "github": ""
    },
    {
        "id": "Gx6Tvlm-hWW",
        "title": "Trading Coverage for Precision: Conformal Prediction with Limited False Discoveries",
        "track": "main",
        "status": "Reject",
        "keywords": "conformal prediction;confidence;uncertainty estimation;false discovery;natural language processing;computer vision;chemistry",
        "author": "",
        "aff": "",
        "rating": "6;6;6;6",
        "confidence": "4;3;4;4",
        "correctness": "3;3;4;1",
        "technical_novelty": "3;3;2;2",
        "empirical_novelty": "3;3;0;1",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "H-iABMvzIc",
        "title": "Switch to Generalize: Domain-Switch Learning for Cross-Domain Few-Shot Classification",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "State Key Laboratory of Industrial Control Technology, Zhejiang University and Baidu Research, China; CCAI, College of Computer Science and Technology, Zhejiang University; Baidu Research, China",
        "rating": "5;6;6;8",
        "confidence": "4;3;4;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;4;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6882472016116854,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "H-sddFpZAp4",
        "title": "ModeRNN: Harnessing Spatiotemporal Mode Collapse in Unsupervised Predictive Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Predictive Learning;Video Prediction",
        "author": "",
        "aff": "",
        "rating": "5;5;8",
        "confidence": "3;4;3",
        "correctness": "2;3;4",
        "technical_novelty": "2;2;4",
        "empirical_novelty": "1;1;4",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5,
        "corr_rating_correctness": 0.8660254037844387,
        "project": "",
        "github": ""
    },
    {
        "id": "H0oaWl6THa",
        "title": "Hybrid Local SGD for Federated Learning with Heterogeneous Communications",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Federated Learning;Communication Efficiency;Heterogeneity;Local SGD",
        "author": "",
        "aff": "The University of Texas at San Antonio, San Antonio, Texas 78249 USA; Pennsylvania State University, State College, PA 16801 USA",
        "rating": "6;8;8;8",
        "confidence": "3;4;3;3",
        "correctness": "3;4;4;3",
        "technical_novelty": "2;3;4;3",
        "empirical_novelty": "2;3;4;3",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "H2bV7F_lEjX",
        "title": "Directional Domain Generalization",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Domain Generalization;Domain Adaptation",
        "author": "",
        "aff": "",
        "rating": "3;5;8;8",
        "confidence": "4;3;4;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.2721655269759087,
        "corr_rating_correctness": 0.5443310539518174,
        "project": "",
        "github": ""
    },
    {
        "id": "H3zl1mDHDTn",
        "title": "Lagrangian Method for Episodic Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Reinforcement Learning;Imitation Learning;Lagrangian Duality;Machine Translation",
        "author": "",
        "aff": "",
        "rating": "5;5;6",
        "confidence": "3;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "2;3;2",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "H4EXaI6HR2",
        "title": "Representing value functions in power systems using parametric network series",
        "track": "main",
        "status": "Reject",
        "keywords": "approximate dynamic programming;cost function approximation;artificial neural networks;parametric network series",
        "author": "",
        "aff": "",
        "rating": "1;3;3",
        "confidence": "4;4;3",
        "correctness": "2;3;3",
        "technical_novelty": "1;1;1",
        "empirical_novelty": "1;2;4",
        "presentation": "",
        "rating_avg": 2.3333333333333335,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 1.0,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5,
        "corr_rating_correctness": 1.0,
        "project": "https://simsee.org",
        "github": ""
    },
    {
        "id": "H4J8FGHOhx_",
        "title": "A Principled Permutation Invariant Approach to Mean-Field Multi-Agent Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;8",
        "confidence": "4;2;5",
        "correctness": "2;3;4",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "3;2;3",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.43355498476206006,
        "corr_rating_correctness": 0.9933992677987828,
        "project": "",
        "github": ""
    },
    {
        "id": "H4PmOqSZDY",
        "title": "Towards Empirical Sandwich Bounds on the Rate-Distortion Function",
        "track": "main",
        "status": "Poster",
        "keywords": "information theory;deep generative modeling;lossy data compression",
        "author": "",
        "aff": "Department of Computer Science, UC Irvine",
        "rating": "3;6;6;8",
        "confidence": "4;3;3;3",
        "correctness": "2;4;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "1;2;0;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8892972917998875,
        "corr_rating_correctness": 0.8892972917998875,
        "project": "",
        "github": ""
    },
    {
        "id": "H6mR1eaBP1l",
        "title": "Training sequence labeling models using prior knowledge",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "1;1;1;1",
        "confidence": "5;5;4;5",
        "correctness": "4;1;3;2",
        "technical_novelty": "1;2;1;1",
        "empirical_novelty": "0;1;1;1",
        "presentation": "",
        "rating_avg": 1.0,
        "confidence_avg": 4.75,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 1.25,
        "empirical_novelty_avg": 0.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "H78NdTUTls8",
        "title": "A precortical module for robust CNNs to light variations",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Neurogeometry;Deep Learning",
        "author": "",
        "aff": "",
        "rating": "1;1;3;3",
        "confidence": "5;5;5;4",
        "correctness": "1;1;3;2",
        "technical_novelty": "1;1;1;2",
        "empirical_novelty": "1;0;2;2",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.75,
        "correctness_avg": 1.75,
        "technical_novelty_avg": 1.25,
        "empirical_novelty_avg": 1.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.9045340337332909,
        "project": "",
        "github": ""
    },
    {
        "id": "H7Edu1_IZgR",
        "title": "Transformers are Meta-Reinforcement Learners",
        "track": "main",
        "status": "Reject",
        "keywords": "Reinforcement Learning;Meta-Reinforcement Learning;Transformers",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "5;3;4;4",
        "correctness": "2;2;3;3",
        "technical_novelty": "1;2;2;3",
        "empirical_novelty": "1;2;2;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "H7HDG--DJF0",
        "title": "Multi-Agent MDP Homomorphic Networks",
        "track": "main",
        "status": "Poster",
        "keywords": "multiagent systems;reinforcement learning;equivariance;symmetry",
        "author": "",
        "aff": "Department of Intelligent Systems, Delft University of Technology; UvA-Bosch Deltalab, University of Amsterdam",
        "rating": "5;6;6;8",
        "confidence": "4;3;3;2",
        "correctness": "3;3;4;4",
        "technical_novelty": "4;2;3;3",
        "empirical_novelty": "3;3;3;4",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9733285267845754,
        "corr_rating_correctness": 0.6882472016116854,
        "project": "",
        "github": ""
    },
    {
        "id": "H94a1_Pyr-6",
        "title": "Auto-scaling Vision Transformers without Training",
        "track": "main",
        "status": "Poster",
        "keywords": "vision transformer;neural architecture search;training-free search;efficient training",
        "author": "",
        "aff": "Google; University of Technology Sydney; University of Texas, Austin",
        "rating": "5;6;8",
        "confidence": "4;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "2;3;4",
        "presentation": "",
        "rating_avg": 6.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.18898223650461363,
        "project": "",
        "github": "https://github.com/VITA-Group/AsViT"
    },
    {
        "id": "HBsJNesj2S",
        "title": "Neural Relational Inference with Node-Specific Information",
        "track": "main",
        "status": "Poster",
        "keywords": "Graph Neural Networks;Variational Inference;Trajectory Prediction",
        "author": "",
        "aff": "Amazon Alexa AI, Toronto, Canada",
        "rating": "5;8;8",
        "confidence": "2;3;2",
        "correctness": "4;3;3",
        "technical_novelty": "2;3;4",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5,
        "corr_rating_correctness": -1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "HCRVf71PMF",
        "title": "LFPT5: A Unified Framework for Lifelong Few-shot Language Learning Based on Prompt Tuning of T5",
        "track": "main",
        "status": "Poster",
        "keywords": "lifelong few-shot language Learning;prompt tuning;pseudo samples;knowledge distillation",
        "author": "",
        "aff": "Nanyang Technological University; Salesforce Research",
        "rating": "5;5;6;6",
        "confidence": "2;5;4;3",
        "correctness": "2;3;3;4",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.7071067811865475,
        "project": "",
        "github": ""
    },
    {
        "id": "HCelXXcSEuH",
        "title": "Doubly Adaptive Scaled Algorithm for Machine Learning Using Second-Order Information",
        "track": "main",
        "status": "Poster",
        "keywords": "Convex Optimization;Non-Convex Optimization;Stochastic Optimization;Second-Order Optimization;Deep Learning",
        "author": "",
        "aff": "University of California, Berkeley, USA; Lehigh University; KAUST; Mohamed bin Zayed University of Artificial Intelligence (MBZUAI)",
        "rating": "5;6;8",
        "confidence": "4;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "2;4;2",
        "empirical_novelty": "2;0;3",
        "presentation": "",
        "rating_avg": 6.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.944911182523068,
        "corr_rating_correctness": -0.18898223650461363,
        "project": "",
        "github": ""
    },
    {
        "id": "HFE5P8nhmmL",
        "title": "SVMnet: Non-parametric image classification based on convolutional SVM ensembles for small training sets",
        "track": "main",
        "status": "Reject",
        "keywords": "machine learning;support vector machine;convolutional neural network",
        "author": "",
        "aff": "",
        "rating": "1;3;3;6",
        "confidence": "5;4;4;4",
        "correctness": "2;1;3;3",
        "technical_novelty": "1;1;2;3",
        "empirical_novelty": "1;1;2;3",
        "presentation": "",
        "rating_avg": 3.25,
        "confidence_avg": 4.25,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7276068751089989,
        "corr_rating_correctness": 0.46442036401282394,
        "project": "",
        "github": ""
    },
    {
        "id": "HFPTzdwN39",
        "title": "Measuring the Interpretability of Unsupervised Representations via Quantized Reversed Probing",
        "track": "main",
        "status": "Poster",
        "keywords": "Representation learning;Computer vision;Interpretability",
        "author": "",
        "aff": "University of Oxford; University of Amsterdam",
        "rating": "3;5;6;8",
        "confidence": "4;3;4;4",
        "correctness": "2;4;3;4",
        "technical_novelty": "1;2;3;3",
        "empirical_novelty": "1;2;3;4",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.16012815380508713,
        "corr_rating_correctness": 0.7526178090063818,
        "project": "",
        "github": "https://github.com/iro-cp/ssl-qrp"
    },
    {
        "id": "HFmAukZ-k-2",
        "title": "Learning the Dynamics of Physical Systems from Sparse Observations with Finite Element Networks",
        "track": "main",
        "status": "Spotlight",
        "keywords": "spatio-temporal;finite;elements;forecasting;continuous;partial;differential;equation;PDE;graph;gnn;time-series",
        "author": "",
        "aff": "Department of Informatics & Munich Data Science Institute, Technical University of Munich, Germany",
        "rating": "6;8;8;8",
        "confidence": "4;4;4;3",
        "correctness": "3;4;3;4",
        "technical_novelty": "4;3;3;4",
        "empirical_novelty": "2;4;0;4",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "https://www.daml.in.tum.de/finite-element-networks/",
        "github": ""
    },
    {
        "id": "HG7vlodGGm",
        "title": "TempoRL: Temporal Priors for Exploration in Off-Policy Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "deep reinforcement learning;exploration;prior",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3;6;8;8",
        "confidence": "4;4;3;3;3;5;4",
        "correctness": "3;2;3;2;4;2;4",
        "technical_novelty": "2;2;3;2;2;4;4",
        "empirical_novelty": "3;2;2;2;3;4;3",
        "presentation": "",
        "rating_avg": 4.857142857142857,
        "confidence_avg": 3.7142857142857144,
        "correctness_avg": 2.857142857142857,
        "technical_novelty_avg": 2.7142857142857144,
        "empirical_novelty_avg": 2.7142857142857144,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5227083734893168,
        "corr_rating_correctness": 0.37328844382740006,
        "project": "",
        "github": ""
    },
    {
        "id": "HHUSDJb_4KJ",
        "title": "Unifying Distribution Alignment as a Loss for Imbalanced Semi-supervised Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "semi-supervised learning;imbalanced learning",
        "author": "",
        "aff": "",
        "rating": "3;3;6;6",
        "confidence": "4;2;4;4",
        "correctness": "3;2;4;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896258,
        "corr_rating_correctness": 0.9045340337332909,
        "project": "",
        "github": ""
    },
    {
        "id": "HHpWuWayMo",
        "title": "Evaluating Robustness of Cooperative MARL",
        "track": "main",
        "status": "Reject",
        "keywords": "cooperative multi-agent reinforcement learning;adversarial attack;continuous action",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;3;4;3",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "HI99z0aLsl",
        "title": "Benign Overfitting in Adversarially Robust Linear Classification",
        "track": "main",
        "status": "Reject",
        "keywords": "Benign Overfitting;Robust Linear Classification",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "3;2;4;4",
        "correctness": "3;4;4;4",
        "technical_novelty": "3;3;3;2",
        "empirical_novelty": "3;1;1;2",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5222329678670935,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "HLTLhiBtUcW",
        "title": "Enhanced neural network regularization with macro-block dropout",
        "track": "main",
        "status": "Desk Reject",
        "keywords": "macro block dropout;regularization",
        "author": "",
        "aff": "Samsung Research, Seoul, South Korea; Seoul National University, Seoul, South Korea",
        "rating": "",
        "confidence": "",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "HL_qE4fz-JZ",
        "title": "Input Dependent Sparse Gaussian Processes",
        "track": "main",
        "status": "Reject",
        "keywords": "gaussian processes;variational inference;neural networks;sparse approximations",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6;8",
        "confidence": "3;4;4;3;3",
        "correctness": "3;3;3;3;3",
        "technical_novelty": "2;3;2;2;4",
        "empirical_novelty": "2;2;2;2;4",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.4,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4303314829119353,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "HMJdXzbWKH",
        "title": "Online Target Q-learning with Reverse Experience Replay: Efficiently finding the Optimal Policy for Linear MDPs",
        "track": "main",
        "status": "Poster",
        "keywords": "Q Learning;RL with Function Approximation;Experience Replay;Online Target Learning",
        "author": "",
        "aff": "University of California, Berkeley; Google Research",
        "rating": "5;6;8;8",
        "confidence": "4;3;3;3",
        "correctness": "4;3;4;4",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "1;0;3;2",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 3.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7777777777777777,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "HMR-7-4-Zr",
        "title": "Contractive error feedback for gradient compression",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5",
        "confidence": "4;3;4",
        "correctness": "3;2;3",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5,
        "corr_rating_correctness": 0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "HO_LL-oqBzW",
        "title": "FCause: Flow-based Causal Discovery",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6;8",
        "confidence": "3;4;3;4;3",
        "correctness": "2;2;3;3;4",
        "technical_novelty": "2;2;3;3;3",
        "empirical_novelty": "2;2;0;3;0",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.4,
        "correctness_avg": 2.8,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 1.4,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.21516574145596765,
        "corr_rating_correctness": 0.9860132971832695,
        "project": "",
        "github": ""
    },
    {
        "id": "HObMhrCeAAF",
        "title": "GradSign: Model Performance Inference with Theoretical Insights",
        "track": "main",
        "status": "Poster",
        "keywords": "Model Performance Inference;Optimization Landscape;NAS",
        "author": "",
        "aff": "Carnegie Mellon University",
        "rating": "6;6;8",
        "confidence": "3;2;4",
        "correctness": "4;3;4",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "3;2;3",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8660254037844385,
        "corr_rating_correctness": 0.49999999999999983,
        "project": "",
        "github": "https://github.com/JackFram/GradSign"
    },
    {
        "id": "HOjLHrlZhmx",
        "title": "CROP: Certifying Robust Policies for Reinforcement Learning through Functional Smoothing",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "University of Illinois at Urbana-Champaign; Washington University in St. Louis; Carnegie Mellon University",
        "rating": "3;5;6;6",
        "confidence": "3;4;2;4",
        "correctness": "3;2;3;4",
        "technical_novelty": "1;3;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.28867513459481287,
        "project": "https://crop-leaderboard.github.io",
        "github": "https://github.com/crop-leaderboard"
    },
    {
        "id": "HRF6T1SsyDn",
        "title": "On the Expressiveness and Learning of Relational Neural Networks on Hypergraphs",
        "track": "main",
        "status": "Reject",
        "keywords": "graph neural networks;deep learning theory",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5;5",
        "confidence": "5;3;4;2;4",
        "correctness": "3;2;2;4;3",
        "technical_novelty": "1;3;3;2;2",
        "empirical_novelty": "1;2;1;2;3",
        "presentation": "",
        "rating_avg": 4.2,
        "confidence_avg": 3.6,
        "correctness_avg": 2.8,
        "technical_novelty_avg": 2.2,
        "empirical_novelty_avg": 1.8,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.32025630761017426,
        "corr_rating_correctness": 0.3273268353539886,
        "project": "",
        "github": ""
    },
    {
        "id": "HRL6el2SBQ",
        "title": "Intra-class Mixup for Out-of-Distribution Detection",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;6;8",
        "confidence": "4;5;3;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.19611613513818402,
        "corr_rating_correctness": 0.8006407690254357,
        "project": "",
        "github": ""
    },
    {
        "id": "HTVch9AMPa",
        "title": "Delaunay Component Analysis for Evaluation of Data Representations",
        "track": "main",
        "status": "Poster",
        "keywords": "Interpretation and Evaluation of Learned Representations;Generative Models;Contrastive Learning",
        "author": "",
        "aff": "KTH Royal Institute of Technology, Stockholm, Sweden",
        "rating": "6;8;8",
        "confidence": "3;4;3",
        "correctness": "3;4;4",
        "technical_novelty": "3;3;2",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 7.333333333333333,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.49999999999999983,
        "corr_rating_correctness": 0.9999999999999998,
        "project": "",
        "github": ""
    },
    {
        "id": "HTfUrAxjPkR",
        "title": "Translatotron 2: Robust direct speech-to-speech translation",
        "track": "main",
        "status": "Reject",
        "keywords": "Speech-to-speech translation;voice transferring;end-to-end",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6;6",
        "confidence": "3;5;4;2;4",
        "correctness": "4;4;3;3;4",
        "technical_novelty": "3;2;2;3;2",
        "empirical_novelty": "2;3;2;3;2",
        "presentation": "",
        "rating_avg": 5.6,
        "confidence_avg": 3.6,
        "correctness_avg": 3.6,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.32025630761017415,
        "corr_rating_correctness": -0.6666666666666665,
        "project": "",
        "github": ""
    },
    {
        "id": "HTp-6yLGGX",
        "title": "Hot-Refresh Model Upgrades with Regression-Free Compatible Training in Image Retrieval",
        "track": "main",
        "status": "Poster",
        "keywords": "Compatible Representation Learning;Image Retrieval;Model Regression",
        "author": "",
        "aff": "AI Technology Center of Tencent Video; ARC Lab, Tencent PCG; International Digital Economy Academy; Tsinghua University",
        "rating": "6;6;6;6",
        "confidence": "4;3;4;5",
        "correctness": "3;3;3;4",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "3;3;3;2",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/binjiezhang/RACT_ICLR2022"
    },
    {
        "id": "HTx7vrlLBEj",
        "title": "Half-Inverse Gradients for Physical Deep Learning",
        "track": "main",
        "status": "Spotlight",
        "keywords": "physical simulation;partial differential equations;physical loss functions;optimization",
        "author": "",
        "aff": "Department of Informatics, Technical University of Munich",
        "rating": "6;6;8",
        "confidence": "3;3;3",
        "correctness": "3;3;4",
        "technical_novelty": "3;3;4",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.3333333333333335,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9999999999999998,
        "project": "",
        "github": ""
    },
    {
        "id": "HUeyM2qVey2",
        "title": "Universal Joint Approximation of Manifolds and Densities by Simple Injective Flows",
        "track": "main",
        "status": "Reject",
        "keywords": "Universality;Flow Networks;Manifold Learning;Density Estimation",
        "author": "",
        "aff": "",
        "rating": "5;6;6;8",
        "confidence": "3;4;2;4",
        "correctness": "2;4;4;4",
        "technical_novelty": "3;4;3;4",
        "empirical_novelty": "0;0;2;4",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.5,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.48420012470625223,
        "corr_rating_correctness": 0.6622661785325219,
        "project": "",
        "github": ""
    },
    {
        "id": "HUjgF0G9FxN",
        "title": "SemiFL: Communication Efficient Semi-Supervised Federated Learning with Unlabeled Clients",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Federated Learning;Semi-Supervised Learning;Strong data augmentation;Unlabeled data",
        "author": "",
        "aff": "",
        "rating": "3;3;5",
        "confidence": "4;5;3",
        "correctness": "3;3;3",
        "technical_novelty": "3;1;3",
        "empirical_novelty": "2;1;3",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8660254037844387,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "HY6i9FYBeFG",
        "title": "S3: Supervised Self-supervised Learning under Label Noise",
        "track": "main",
        "status": "Reject",
        "keywords": "Learning under label noise;Supervised learning;Self-supervised learning",
        "author": "",
        "aff": "",
        "rating": "5;5;6",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "1;2;3",
        "empirical_novelty": "1;2;3",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "HZ83Rymg-tf",
        "title": "L2E: Learning to Exploit Your Opponent",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Opponent Modeling;Learning to Learn",
        "author": "",
        "aff": "",
        "rating": "3;3;5",
        "confidence": "5;4;4",
        "correctness": "2;2;3",
        "technical_novelty": "3;2;2",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4999999999999999,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "H_qwVb8DQb-",
        "title": "Balancing Average and Worst-case Accuracy in Multitask Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "multitask learning;distributionally robust optimization",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "4;4;3;4",
        "correctness": "4;3;3;3",
        "technical_novelty": "3;3;3;2",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "Harn4_EZBw",
        "title": "Generative Pseudo-Inverse Memory",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "Kha Pham 1, Hung Le 1, Man Ngo 2, Truyen Tran 1, Bao Ho 3 and Svetha Venkatesh 1 , 1 Applied Artificial Intelligence Institute, Deakin University , 2 Faculty of Mathematics and Computer Science, VNUHCM-University of Science , 3 Vietnam Institute for Advanced Study in Mathematics , , 1{phti, thai.le, truyen.tran, svetha.venkatesh}@deakin.edu.au,  , 2 nmman@hcmus.edu.vn, , 3 bao@viasm.edu.vn ",
        "aff": "Vietnam Institute for Advanced Study in Mathematics; Faculty of Mathematics and Computer Science, VNUHCM-University of Science; Applied Arti\ufb01cial Intelligence Institute, Deakin University",
        "rating": "5;5;8",
        "confidence": "2;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5000000000000001,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "HavXnq6KyT3",
        "title": "Optimizing Class Distribution in Memory for Multi-Label Continual Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "online continual learning",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "4;5;3;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "3;2;3;4",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "HbtFCX2PLq0",
        "title": "Churn Reduction via Distillation",
        "track": "main",
        "status": "Spotlight",
        "keywords": "distillation;churn;constraints",
        "author": "",
        "aff": "Google Research",
        "rating": "5;8;8",
        "confidence": "4;2;4",
        "correctness": "3;4;3",
        "technical_novelty": "2;4;3",
        "empirical_novelty": "2;4;4",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5000000000000001,
        "corr_rating_correctness": 0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "HdnUQk9jbUO",
        "title": "Linear Convergence of SGD on Overparametrized Shallow Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "1;3;3;5",
        "confidence": "5;3;4;4",
        "correctness": "2;4;3;4",
        "technical_novelty": "1;2;2;2",
        "empirical_novelty": "0;2;0;1",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 0.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5,
        "corr_rating_correctness": 0.8528028654224418,
        "project": "",
        "github": ""
    },
    {
        "id": "HfUyCRBeQc",
        "title": "Selective Ensembles for Consistent Predictions",
        "track": "main",
        "status": "Poster",
        "keywords": "consistency;prediction consistency;model duplicity;inconsistent predictions;deep models;deep networks;explanations;saliency maps;gradient-based explanations;fairness;interpretability",
        "author": "",
        "aff": "Carnegie Mellon University",
        "rating": "5;5;6;8",
        "confidence": "4;2;2;4",
        "correctness": "4;2;4;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.40824829046386296,
        "corr_rating_correctness": 0.4714045207910316,
        "project": "",
        "github": ""
    },
    {
        "id": "Hfw5Q2Zn1w",
        "title": "Modeling and Eliminating Adversarial Examples using Function Theory of Several Complex Variables",
        "track": "main",
        "status": "Withdraw",
        "keywords": "adversarial examples;learning theory;robust training;complex analysis",
        "author": "",
        "aff": "",
        "rating": "1;3;3;3",
        "confidence": "2;4;2;2",
        "correctness": "2;2;3;2",
        "technical_novelty": "2;4;3;4",
        "empirical_novelty": "1;0;0;2",
        "presentation": "",
        "rating_avg": 2.5,
        "confidence_avg": 2.5,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 0.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "Hg7xLoENqHW",
        "title": "Robust Imitation via Mirror Descent Inverse Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "inverse reinforcement learning;reward learning;regularized markov decision processes;imitation learning",
        "author": "",
        "aff": "",
        "rating": "5;5;5",
        "confidence": "4;3;3",
        "correctness": "3;3;4",
        "technical_novelty": "3;3;2",
        "empirical_novelty": "3;2;1",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "HiHWMiLP035",
        "title": "E$^2$CM: Early Exit via Class Means for Efficient Supervised and Unsupervised Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "class means;early exit;efficient neural networks",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "5;5;4;3",
        "correctness": "3;3;4;3",
        "technical_novelty": "3;3;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9045340337332909,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "HmFBdvBkUUY",
        "title": "SpecTRA: Spectral Transformer for Graph Representation Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Graph Representation Learning;Transformer;GNNs",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "5;4;2;4",
        "correctness": "2;4;4;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6622661785325219,
        "corr_rating_correctness": 0.8703882797784891,
        "project": "",
        "github": ""
    },
    {
        "id": "HndgQudNb91",
        "title": "Learning to Downsample for Segmentation of Ultra-High Resolution Images",
        "track": "main",
        "status": "Poster",
        "keywords": "ultra-high resolution image segmentation;non-uniform dowmsampling;efficient segmentation;large volume image segmentation;medical image segmentation",
        "author": "",
        "aff": "Healthcare Intelligence, Microsoft Research Cambridge; Centre for Medical Image Computing, Department of Computer Science, University College London",
        "rating": "6;6;6;8",
        "confidence": "3;2;3;3",
        "correctness": "4;3;3;4",
        "technical_novelty": "3;3;2;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 2.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "https://lxasqjc.github.io/learn-downsample.github.io/",
        "github": "https://github.com/lxasqjc/learn-downsample.github.io"
    },
    {
        "id": "HpLOYOBbnt",
        "title": "Generalized Maximum Entropy Reinforcement Learning via Reward Shaping",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Reinforcement Learning;Reward Shaping;Soft Policy Gradient",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;3;4;2",
        "correctness": "1;3;4;3",
        "technical_novelty": "1;4;2;3",
        "empirical_novelty": "0;4;3;0",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5222329678670935,
        "corr_rating_correctness": 0.9271726499455306,
        "project": "",
        "github": "https://github.com/ResearchSharedCode/Generalized-Maximum-Entropy-RL"
    },
    {
        "id": "Ht85_jyihxp",
        "title": "Efficient and Differentiable Conformal Prediction with General Function Classes",
        "track": "main",
        "status": "Poster",
        "keywords": "uncertainty quantification;conformal prediction;prediction sets",
        "author": "",
        "aff": "Salesforce Research; UC Berkeley",
        "rating": "6;6;6;8",
        "confidence": "4;4;4;4",
        "correctness": "4;4;4;3",
        "technical_novelty": "3;2;2;4",
        "empirical_novelty": "3;2;0;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -1.0,
        "project": "",
        "github": "https://github.com/allenbai01/cp-gen"
    },
    {
        "id": "HuaYQfggn5u",
        "title": "FedBABU: Toward Enhanced Representation for Federated Image Classification",
        "track": "main",
        "status": "Poster",
        "keywords": "Federated Learning;Representation Learning",
        "author": "",
        "aff": "Graduate School of AI, KAIST; Graduate School of KSE, KAIST",
        "rating": "5;6;6;8",
        "confidence": "3;4;4;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.6622661785325219,
        "corr_rating_correctness": 0.9271726499455306,
        "project": "",
        "github": "https://github.com/jhoon-oh/FedBABU"
    },
    {
        "id": "I-nQMZfQz7F",
        "title": "Learning Neural Implicit Functions as Object Representations for Robotic Manipulation",
        "track": "main",
        "status": "Reject",
        "keywords": "Representation Learning;nerual implicit representation;robotic manipulation;task and motion planning",
        "author": "",
        "aff": "",
        "rating": "1;5;6;6",
        "confidence": "4;3;4;3",
        "correctness": "2;3;3;4",
        "technical_novelty": "1;2;3;3",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.48507125007266594,
        "corr_rating_correctness": 0.8574929257125441,
        "project": "",
        "github": ""
    },
    {
        "id": "I13PP8-cdvz",
        "title": "SSR-GNNs: Stroke-based Sketch Representation with Graph Neural Networks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Stroke-based representation;Spatial robustness;Robust feature learning;Novel pattern generation",
        "author": "",
        "aff": "",
        "rating": "1;3;3;5",
        "confidence": "5;2;5;5",
        "correctness": "2;4;2;2",
        "technical_novelty": "2;2;4;2",
        "empirical_novelty": "2;0;3;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "I1dg7let3Q",
        "title": "Semi-supervised learning objectives as log-likelihoods in a generative model of data curation",
        "track": "main",
        "status": "Reject",
        "keywords": "Bayesian neural network;semi-supervised learning;Bayesian inference",
        "author": "",
        "aff": "",
        "rating": "3;3;6;8",
        "confidence": "4;4;2;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;2;3;4",
        "empirical_novelty": "1;2;3;4",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.2721655269759087,
        "corr_rating_correctness": 0.9428090415820635,
        "project": "",
        "github": "https://anonymous.4open.science/r/GZ_SSL-B6CC"
    },
    {
        "id": "I1hQbx10Kxn",
        "title": "On Bridging Generic and Personalized Federated Learning for Image Classification",
        "track": "main",
        "status": "Spotlight",
        "keywords": "federated learning;personalization;image classification",
        "author": "",
        "aff": "The Ohio State University, USA",
        "rating": "5;8;8",
        "confidence": "2;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "3;3;2",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8660254037844387,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "I2Hw58KHp8O",
        "title": "Improving Non-Autoregressive Translation Models Without Distillation",
        "track": "main",
        "status": "Poster",
        "keywords": "Natural Language Processing;Deep Learning;Non-autoregressive Machine Translation;Transformer;Distillation",
        "author": "",
        "aff": "Layer 6 AI",
        "rating": "3;8;8;8",
        "confidence": "4;4;4;4",
        "correctness": "2;3;3;4",
        "technical_novelty": "2;4;3;2",
        "empirical_novelty": "2;3;0;3",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": "https://github.com/layer6ai-labs/CMLMC"
    },
    {
        "id": "I2KAe7x67JU",
        "title": "Benchmarking Graph Neural Networks on Dynamic Link Prediction",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Graph neural network;dynamic graph neural network;link prediction;dynamic link prediction;temporal graph",
        "author": "",
        "aff": "",
        "rating": "1;3;3;5",
        "confidence": "4;5;4;4",
        "correctness": "4;4;3;3",
        "technical_novelty": "1;1;1;2",
        "empirical_novelty": "2;3;3;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 1.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.7071067811865476,
        "project": "",
        "github": ""
    },
    {
        "id": "I7Tuih6s7Dj",
        "title": "Towards Axiomatic, Hierarchical, and Symbolic Explanation for Deep Models",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "3;5;3;4",
        "correctness": "2;2;3;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.17407765595569782,
        "corr_rating_correctness": 0.986440050415621,
        "project": "",
        "github": ""
    },
    {
        "id": "IDwN6xjHnK8",
        "title": "Transformer-based Transform Coding",
        "track": "main",
        "status": "Poster",
        "keywords": "transformer;transform coding;image compression;video compression",
        "author": "",
        "aff": "Qualcomm AI Research",
        "rating": "6;6;8;8;8",
        "confidence": "4;5;5;4;3",
        "correctness": "4;4;4;3;4",
        "technical_novelty": "3;3;4;2;4",
        "empirical_novelty": "3;4;4;4;3",
        "presentation": "",
        "rating_avg": 7.2,
        "confidence_avg": 4.2,
        "correctness_avg": 3.8,
        "technical_novelty_avg": 3.2,
        "empirical_novelty_avg": 3.6,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3273268353539886,
        "corr_rating_correctness": -0.408248290463863,
        "project": "",
        "github": ""
    },
    {
        "id": "IEKL-OihqX0",
        "title": "Gradient-Guided Importance Sampling for Learning Discrete Energy-Based Models",
        "track": "main",
        "status": "Reject",
        "keywords": "Discrete energy-based models;ratio matching;importance sampling;gradient",
        "author": "",
        "aff": "",
        "rating": "5;6;6;6",
        "confidence": "3;3;5;5",
        "correctness": "3;4;4;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;2;3;2",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "IEsx-jwFk3g",
        "title": "Deep Representations for Time-varying Brain Datasets",
        "track": "main",
        "status": "Reject",
        "keywords": "fMRI;graph neural networks;feature attribution",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "4;4;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "3;3;3;2",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "IHLQyVXKbx",
        "title": "Unsupervised Domain Adaptation Via Pseudo-labels And Objectness Constraints",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Unsupervised Domain Adaptation;Self-Training;Semantic Segmentation;Multimodal Learning",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "4;4;4;5",
        "correctness": "2;3;2;2",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;1;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.25,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "IJ-88dRfkdz",
        "title": "SoftHebb: Bayesian inference in unsupervised Hebbian soft winner-take-all networks",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "Paper under double-blind review",
        "rating": "6;6;6;6",
        "confidence": "3;4;4;4",
        "correctness": "2;4;3;3",
        "technical_novelty": "2;3;2;2",
        "empirical_novelty": "2;0;2;2",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "IK9ap6nxXr2",
        "title": "Interacting Contour Stochastic Gradient Langevin Dynamics",
        "track": "main",
        "status": "Poster",
        "keywords": "stochastic gradient Langevin dynamics;MCMC;importance sampling;Wang-Landau algorithm;Parallel MCMC Methods;stochastic approximation",
        "author": "",
        "aff": "Purdue University; DeepMind",
        "rating": "6;6;6;8",
        "confidence": "3;4;3;3",
        "correctness": "4;2;4;4",
        "technical_novelty": "3;4;4;3",
        "empirical_novelty": "3;4;4;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.5,
        "empirical_novelty_avg": 3.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "ILYX-vQnwe_",
        "title": "Breaking Down Questions for Outside-Knowledge VQA",
        "track": "main",
        "status": "Withdraw",
        "keywords": "knowledge-based VQA",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "3;4;4;5",
        "correctness": "4;4;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.816496580927726,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "INO8hGXD2M",
        "title": "Adversarial Distributions Against Out-of-Distribution Detectors",
        "track": "main",
        "status": "Reject",
        "keywords": "out-of-distribution detection;outlier detection;adversarial attack;model evaluation;markov chain monte carlo",
        "author": "",
        "aff": "",
        "rating": "3;3;6;6",
        "confidence": "4;3;3;4",
        "correctness": "2;2;4;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "IOA9fJUUa0",
        "title": "How does BERT address polysemy of Korean adverbial postpositions -ey, -eyse, and -(u)lo?",
        "track": "main",
        "status": "Reject",
        "keywords": "polysemy;natural language processing;classification;language model;BERT;data visualization;Korean",
        "author": "",
        "aff": "Under double-blind review",
        "rating": "1;3;3;3",
        "confidence": "3;4;4;4",
        "correctness": "2;2;3;3",
        "technical_novelty": "1;2;1;1",
        "empirical_novelty": "2;1;2;1",
        "presentation": "",
        "rating_avg": 2.5,
        "confidence_avg": 3.75,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 1.25,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 1.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "IPwwNwMvHFW",
        "title": "Multi-Agent Decentralized Belief Propagation on Graphs",
        "track": "main",
        "status": "Desk Reject",
        "keywords": "I-pomdps;Belief propagation;Multi-agent control",
        "author": "",
        "aff": "",
        "rating": "",
        "confidence": "",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "IPy3URgH47U",
        "title": "ACTIVE REFINEMENT OF WEAKLY SUPERVISED MODELS",
        "track": "main",
        "status": "Reject",
        "keywords": "Weak Supervision;Active Learning;Fuzzy logic;AI in Healthcare",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6;6",
        "confidence": "3;5;2;4;3",
        "correctness": "4;3;3;4;3",
        "technical_novelty": "2;2;3;3;3",
        "empirical_novelty": "2;3;3;3;3",
        "presentation": "",
        "rating_avg": 5.4,
        "confidence_avg": 3.4,
        "correctness_avg": 3.4,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 2.8,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0800640769025436,
        "corr_rating_correctness": 0.16666666666666669,
        "project": "",
        "github": ""
    },
    {
        "id": "IR-V6-aP-mv",
        "title": "Batch size-invariance for policy optimization",
        "track": "main",
        "status": "Reject",
        "keywords": "reinforcement learning;policy gradient;learning rate",
        "author": "",
        "aff": "",
        "rating": "1;5;5;8",
        "confidence": "5;4;4;5",
        "correctness": "3;2;2;3",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.10050378152592121,
        "corr_rating_correctness": -0.10050378152592121,
        "project": "",
        "github": ""
    },
    {
        "id": "IRLKq_V1lt9",
        "title": "Dict-BERT: Enhancing Language Model Pre-training with Dictionary",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5;6",
        "confidence": "4;5;4;4;3",
        "correctness": "2;2;3;3;3",
        "technical_novelty": "2;2;2;3;3",
        "empirical_novelty": "2;0;2;3;3",
        "presentation": "",
        "rating_avg": 4.4,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7905694150420948,
        "corr_rating_correctness": 0.9525793444156803,
        "project": "",
        "github": ""
    },
    {
        "id": "IXrQxlxr0iB",
        "title": "ERNIE-SPARSE: Robust Efficient Transformer Through Hierarchically Unifying Isolated Information",
        "track": "main",
        "status": "Withdraw",
        "keywords": "sparse transformer;robustness;language model;dropout;regularization",
        "author": "",
        "aff": "",
        "rating": "3;5;6",
        "confidence": "5;5;4",
        "correctness": "2;3;3",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7559289460184544,
        "corr_rating_correctness": 0.9449111825230683,
        "project": "",
        "github": ""
    },
    {
        "id": "IY4IsjvUhZ",
        "title": "Characterising the Area Under the Curve Loss Function Landscape",
        "track": "main",
        "status": "Reject",
        "keywords": "loss function landscape;loss function;AUC;area under the curve;alternative loss functions;loss function visualisation",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5;6",
        "confidence": "3;4;4;2;3",
        "correctness": "2;2;3;3;3",
        "technical_novelty": "2;1;1;3;3",
        "empirical_novelty": "2;1;2;2;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.2,
        "correctness_avg": 2.6,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6338656910463873,
        "corr_rating_correctness": 0.6454972243679028,
        "project": "",
        "github": ""
    },
    {
        "id": "IY6Zt3Qu0cT",
        "title": "Fragment-Based Sequential Translation for Molecular Optimization",
        "track": "main",
        "status": "Reject",
        "keywords": "molecular optimization;molecular generation;drug discovery;reinforcement learning",
        "author": "",
        "aff": "",
        "rating": "3;3;6;6",
        "confidence": "4;4;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;0;4;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "IYMuTbGzjFU",
        "title": "Representing Mixtures of Word Embeddings with Mixtures of Topic Embeddings",
        "track": "main",
        "status": "Poster",
        "keywords": "topic model;text mining;distribution matching",
        "author": "",
        "aff": "The Chinese University of Hong Kong, Shenzhen; Monash University; The University of Texas at Austin; Xidian University",
        "rating": "5;5;5;6",
        "confidence": "5;4;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "3;0;2;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 4.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "I_RLPhVUfw8",
        "title": "Dense Gaussian Processes for Few-Shot Segmentation",
        "track": "main",
        "status": "Reject",
        "keywords": "few-shot learning;few-shot segmentation;segmentation;gaussian processes",
        "author": "",
        "aff": "",
        "rating": "5;6;6;6",
        "confidence": "5;5;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "2;3;2;2",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 4.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "IbyMcLKUCqT",
        "title": "Theoretical Analysis of Consistency Regularization with Limited Augmented Data",
        "track": "main",
        "status": "Reject",
        "keywords": "data augmentation;consistency regularization;generalization bound",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;4;4;4",
        "correctness": "3;3;2;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "1;2;2;4",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.13245323570650439,
        "project": "",
        "github": ""
    },
    {
        "id": "IcUWShptD7d",
        "title": "Monotonic Differentiable Sorting Networks",
        "track": "main",
        "status": "Poster",
        "keywords": "differentiable sorting;monotonic;sorting;ranking;sorting networks",
        "author": "",
        "aff": "University of Salzburg; University of Konstanz; IBM-MIT Watson AI Lab; University of Frankfurt",
        "rating": "5;6;6;8",
        "confidence": "2;4;3;3",
        "correctness": "3;4;4;4",
        "technical_novelty": "3;3;2;4",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3244428422615251,
        "corr_rating_correctness": 0.6622661785325219,
        "project": "",
        "github": ""
    },
    {
        "id": "IeYEepOLsFT",
        "title": "Bayesian Imbalanced Regression Debiasing",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Imbalanced Regression;Bayesian Debiasing",
        "author": "",
        "aff": "",
        "rating": "3;5;6",
        "confidence": "4;2;4",
        "correctness": "2;2;3",
        "technical_novelty": "2;1;3",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.1889822365046137,
        "corr_rating_correctness": 0.7559289460184545,
        "project": "",
        "github": ""
    },
    {
        "id": "IfNu7Dr-3fQ",
        "title": "Generalized Kernel Thinning",
        "track": "main",
        "status": "Poster",
        "keywords": "coresets;maximum mean discrepancy;Markov chain Monte Carlo;reproducing kernel Hilbert space;thinning;compression",
        "author": "",
        "aff": "Microsoft Research New England; Department of Computer Science, Harvard University and Department of EECS, MIT",
        "rating": "5;6;6;8",
        "confidence": "3;2;3;2",
        "correctness": "4;4;3;4",
        "technical_novelty": "3;3;2;2",
        "empirical_novelty": "2;2;0;2",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 2.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6882472016116854,
        "corr_rating_correctness": 0.13245323570650439,
        "project": "",
        "github": ""
    },
    {
        "id": "Ih0iJBSy4eq",
        "title": "Can Reinforcement Learning Efficiently Find Stackelberg-Nash Equilibria in General-Sum Markov Games?",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5",
        "confidence": "4;3;3;2",
        "correctness": "4;3;3;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "0;3;0;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 1.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "Ih7LAeOYIb0",
        "title": "Iterative Memory Network for Long Sequential User Behavior Modeling in Recommender Systems",
        "track": "main",
        "status": "Reject",
        "keywords": "recommender systems;sequential behavior modeling",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "4;4;4;4",
        "correctness": "3;4;3;3",
        "technical_novelty": "3;2;2;3",
        "empirical_novelty": "2;2;3;4",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "IhkSFe9YqMy",
        "title": "Experience Replay More When It's a Key Transition in Deep Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Experience Replay More;Key Transitions;Sampling;Add Noise to Noise;Deep Reinforcement Learning",
        "author": "",
        "aff": "",
        "rating": "1;1;3;3",
        "confidence": "4;4;4;5",
        "correctness": "1;2;1;3",
        "technical_novelty": "1;2;1;2",
        "empirical_novelty": "2;2;1;2",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.25,
        "correctness_avg": 1.75,
        "technical_novelty_avg": 1.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.30151134457776363,
        "project": "",
        "github": ""
    },
    {
        "id": "Ihxw4h-JnC",
        "title": "Stochastic Induction of Decision Trees with Application to Learning Haar Tree",
        "track": "main",
        "status": "Reject",
        "keywords": "Decision Tree;Stochastic Optimization;Haar Filters;Haar Cascade",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "4;3;4;3",
        "correctness": "2;2;2;2",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "3;2;0;3",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "Iog0djAdbHj",
        "title": "Better Supervisory Signals by Observing Learning Paths",
        "track": "main",
        "status": "Poster",
        "keywords": "Classification;Supervision;Knowledge Distillation",
        "author": "",
        "aff": "UBC; University of Edinburgh; UBC and Amii",
        "rating": "5;6;8;8",
        "confidence": "3;4;4;4",
        "correctness": "2;2;3;3",
        "technical_novelty": "3;3;3;4",
        "empirical_novelty": "2;3;3;4",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 3.75,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.7777777777777777,
        "corr_rating_correctness": 0.9622504486493761,
        "project": "",
        "github": ""
    },
    {
        "id": "IpctgL7khPp",
        "title": "Information-theoretic Online Memory Selection for Continual Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "Task-free continual learning;replay memory;information theoretic;reservoir sampling",
        "author": "",
        "aff": "Google Brain; Baidu Apollo; DeepMind; University of Toronto, Vector Institute",
        "rating": "5;6;8",
        "confidence": "3;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "3;2;3",
        "presentation": "",
        "rating_avg": 6.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.7559289460184545,
        "corr_rating_correctness": 0.18898223650461363,
        "project": "",
        "github": ""
    },
    {
        "id": "IptBMO1AR5g",
        "title": "Regularizing Deep Neural Networks with Stochastic Estimators of Hessian Trace",
        "track": "main",
        "status": "Reject",
        "keywords": "Regularization;Hessian Trace;Stochastic Estimator;Nonlinear Dynamical System;Generalization Error",
        "author": "",
        "aff": "",
        "rating": "3;5;5;8",
        "confidence": "4;3;4;3",
        "correctness": "2;2;4;3",
        "technical_novelty": "3;2;3;4",
        "empirical_novelty": "1;2;2;2",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7001400420140049,
        "corr_rating_correctness": 0.37998029782867415,
        "project": "",
        "github": ""
    },
    {
        "id": "Is5Hpwg2R-h",
        "title": "Targeted Environment Design from Offline Data",
        "track": "main",
        "status": "Reject",
        "keywords": "targeted environment design;offline reinforcement learning;deep learning;adversarial learning",
        "author": "",
        "aff": "",
        "rating": "3;5;6;8",
        "confidence": "5;4;4;4",
        "correctness": "4;3;3;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8006407690254357,
        "corr_rating_correctness": -0.8006407690254357,
        "project": "",
        "github": ""
    },
    {
        "id": "IsHQmuOqRAG",
        "title": "Learning to perceive objects by prediction",
        "track": "main",
        "status": "Reject",
        "keywords": "predictive learning;object-centric representation;3D perception;sensory grounding",
        "author": "",
        "aff": "",
        "rating": "3;5;5;8",
        "confidence": "3;4;4;3",
        "correctness": "4;3;3;3",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.14002800840280097,
        "corr_rating_correctness": -0.7276068751089989,
        "project": "",
        "github": ""
    },
    {
        "id": "ItkxLQU01lD",
        "title": "Convergent Graph Solvers",
        "track": "main",
        "status": "Poster",
        "keywords": "Graph;Graph Neural Network;Fixed point;Implicit model;Implicit function theorem;Convergent",
        "author": "",
        "aff": "KAIST, Daejeon, South Korea",
        "rating": "8;8;8;8",
        "confidence": "4;4;4;5",
        "correctness": "4;4;3;4",
        "technical_novelty": "3;4;3;3",
        "empirical_novelty": "3;0;2;3",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/Junyoungpark/CGS"
    },
    {
        "id": "IvepFxYRDG",
        "title": "Sample Efficient Stochastic Policy Extragradient Algorithm for Zero-Sum Markov Game",
        "track": "main",
        "status": "Poster",
        "keywords": "Two-player Zero-sum Markov game;Entropy regularization;Policy extragradient;Nash equilibrium;Sample complexity",
        "author": "",
        "aff": "Department of ECE, University of Utah, Salt Lake City, UT 84112, USA",
        "rating": "6;6;6;6;6",
        "confidence": "4;4;3;3;3",
        "correctness": "4;4;4;3;4",
        "technical_novelty": "2;3;3;2;3",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.4,
        "correctness_avg": 3.8,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "Ivku4TZgEly",
        "title": "Exploring unfairness in Integrated Gradients based attribution methods",
        "track": "main",
        "status": "Reject",
        "keywords": "Integrated Gradients;Expected Gradients;Explainable AI;Integrated Certainty Gradients;Attribution",
        "author": "",
        "aff": "",
        "rating": "5;5;5",
        "confidence": "3;2;4",
        "correctness": "3;2;4",
        "technical_novelty": "3;3;2",
        "empirical_novelty": "2;2;1",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "IwJPj2MBcIa",
        "title": "Compositional Attention: Disentangling Search and Retrieval",
        "track": "main",
        "status": "Spotlight",
        "keywords": "compositional attention;flexible search and retrieval;better generalization",
        "author": "",
        "aff": "Mila, Universit\u00e9 de Montr\u00e9al",
        "rating": "6;6;8;8",
        "confidence": "3;3;4;3",
        "correctness": "3;3;4;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": "https://github.com/sarthmit/Compositional-Attention"
    },
    {
        "id": "IxCAF8IMatf",
        "title": "A Unified Knowledge Distillation Framework for Deep Directed Graphical Models",
        "track": "main",
        "status": "Reject",
        "keywords": "Deep Directed Graphical Models;Knowledge Distillation;Reparameterization trick;Model compression",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "3;4;4;3",
        "correctness": "3;2;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "Ix_mh42xq5w",
        "title": "PSA-GAN: Progressive Self Attention GANs for Synthetic Time Series",
        "track": "main",
        "status": "Poster",
        "keywords": "Synthetic Time Series;GAN;Generative Modeling;Time Series;Forecasting",
        "author": "",
        "aff": "AWS AI Labs; Technical University of Denmark; Zalando SE",
        "rating": "6;6;6;6",
        "confidence": "4;3;3;5",
        "correctness": "3;4;4;4",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "J1rhANsCY9",
        "title": "Learning Representation from Neural Fisher Kernel with Low-rank Approximation",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "Mila, Universit\u00e9 de Montr\u00e9al; Apple Inc.",
        "rating": "6;6;6",
        "confidence": "4;3;4",
        "correctness": "3;4;3",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "J1uOGgf-bP",
        "title": "Test Time Robustification of Deep Models via Adaptation and Augmentation",
        "track": "main",
        "status": "Reject",
        "keywords": "distribution shift;test time adaptation;data augmentation",
        "author": "",
        "aff": "",
        "rating": "5;5;6;8",
        "confidence": "4;5;4;5",
        "correctness": "3;4;1;3",
        "technical_novelty": "2;2;2;4",
        "empirical_novelty": "2;2;3;4",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.40824829046386296,
        "corr_rating_correctness": -0.18731716231633877,
        "project": "",
        "github": ""
    },
    {
        "id": "J4iSIR9fhY0",
        "title": "Representation Learning for Online and Offline RL in Low-rank MDPs",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Provably sample efficient Reinforcement Learning;PAC bounds;Representation learning;Low-rank MDP",
        "author": "",
        "aff": "Department of Electrical and Computer Engineering, Princeton University, NJ 08544, USA; Department of Computer Science, Cornell University, Ithaca, NY 14850, USA",
        "rating": "5;6;8;8",
        "confidence": "4;4;4;4",
        "correctness": "3;4;3;4",
        "technical_novelty": "2;3;3;4",
        "empirical_novelty": "2;0;0;0",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 0.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.19245008972987526,
        "project": "",
        "github": ""
    },
    {
        "id": "J7FaSJw-xCM",
        "title": "Mutual Information Estimation as a Difference of Entropies for Unsupervised Representation Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;3;3",
        "correctness": "3;2;3;2",
        "technical_novelty": "3;2;4;3",
        "empirical_novelty": "3;2;0;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "J7V_4aauV6B",
        "title": "Understanding and Scheduling Weight Decay",
        "track": "main",
        "status": "Reject",
        "keywords": "Weight Decay;Regularization;Optimization;Deep Learning",
        "author": "",
        "aff": "",
        "rating": "3;3;6;8",
        "confidence": "4;4;2;4",
        "correctness": "3;2;1;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.2721655269759087,
        "corr_rating_correctness": 0.316227766016838,
        "project": "",
        "github": ""
    },
    {
        "id": "J7b4BCtDm4",
        "title": "How to deal with missing data in supervised deep learning?",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "Universit \u00e9 C\u00f4te d\u2019Azur, Inria (Maasai team), Laboratoire J.A. Dieudonn \u00e9, CNRS, France; Department of Applied Mathematics and Computer Science, Technical University of Denmark, Denmark",
        "rating": "5;5;8;8",
        "confidence": "4;3;4;3",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "J8P7g_mDpno",
        "title": "Search Spaces for Neural Model Training",
        "track": "main",
        "status": "Reject",
        "keywords": "search space;sparsity;neural models;deep learning",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "3;3;4;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;2;4;2",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 1.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "J9_7t9m8xRj",
        "title": "Diverse and Consistent Multi-view Networks for Semi-supervised Regression",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;4;3;3",
        "correctness": "2;3;4;4",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6882472016116854,
        "corr_rating_correctness": 0.899228803025897,
        "project": "",
        "github": ""
    },
    {
        "id": "JAJozcf0Kb",
        "title": "Memory-Driven Text-to-Image Generation",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Generative Adversarial Networks;Text-to-Image Generation;Memory Bank;Semi-parametric",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "4;3;3;4",
        "correctness": "2;3;4;3",
        "technical_novelty": "3;2;2;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.40824829046386296,
        "corr_rating_correctness": 0.8660254037844386,
        "project": "",
        "github": ""
    },
    {
        "id": "JBAZe2yN6Ub",
        "title": "A First-Occupancy Representation for Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "successor representation;successor features;generalized policy improvement;GPI",
        "author": "",
        "aff": "Sainsbury Wellcome Centre, UCL; Gatsby Unit, UCL",
        "rating": "5;6;8;8",
        "confidence": "4;4;4;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;2;4;4",
        "empirical_novelty": "2;2;2;4",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9622504486493761,
        "project": "",
        "github": ""
    },
    {
        "id": "JDOpWxBqMw",
        "title": "Variational Perturbations for Visual Feature Attribution",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Explainable AI;Faithfulness;Robustness;Variational inference",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "5;4;3;4",
        "correctness": "3;2;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7071067811865475,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "JEoDctbwCmP",
        "title": "Enforcing physics-based algebraic constraints for inference of PDE models on unstructured grids",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5",
        "confidence": "4;4;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;3;2;2",
        "empirical_novelty": "2;3;2;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "JGO8CvG5S9",
        "title": "Universal Approximation Under Constraints is Possible with Transformers",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Constrained Universal Approximation;Probabilistic Attention;Transformer Networks;Geometric Deep Learning;Measurable Maximum Theorem;Non-Affine Random Projections;Optimal Transport.",
        "author": "",
        "aff": "Universit\u00e4t Z\u00fcrich, Department of Informatics; Universit\u00e4t Basel, Departement Mathematik und Informatik",
        "rating": "6;8;10",
        "confidence": "4;2;4",
        "correctness": "3;3;4",
        "technical_novelty": "3;3;4",
        "empirical_novelty": "1;3;0",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.3333333333333335,
        "empirical_novelty_avg": 1.3333333333333333,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.8660254037844385,
        "project": "",
        "github": ""
    },
    {
        "id": "JHXjK94yH-y",
        "title": "Explore and Control with Adversarial Surprise",
        "track": "main",
        "status": "Reject",
        "keywords": "reinforcement learning;intrinsic motivation;exploration;multi-agent",
        "author": "",
        "aff": "",
        "rating": "3;5;5",
        "confidence": "4;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 4.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9999999999999998,
        "project": "",
        "github": ""
    },
    {
        "id": "JJCjv4dAbyL",
        "title": "Learning Discrete Structured Variational Auto-Encoder using Natural Evolution Strategies",
        "track": "main",
        "status": "Poster",
        "keywords": "structured prediction;derivative-free optimization;variational autoencoder",
        "author": "",
        "aff": "Technion, IIT; Meta AI Research",
        "rating": "6;8;8;8",
        "confidence": "3;4;4;3",
        "correctness": "3;4;4;3",
        "technical_novelty": "3;4;3;3",
        "empirical_novelty": "3;4;2;3",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "JJxiD-kg-oK",
        "title": "Blaschke Product Neural Networks (BPNN): A Physics-Infused Neural Network for Phase Retrieval of Meromorphic Functions",
        "track": "main",
        "status": "Poster",
        "keywords": "Blaschke Product;Neural Network;Phase Retrieval;Metamaterial;Meromorphic Functions",
        "author": "",
        "aff": "Department of Electrical and Computer Engineering, Duke University, Durham, NC 27708, USA",
        "rating": "5;6;6;8",
        "confidence": "3;3;4;3",
        "correctness": "3;3;3;4",
        "technical_novelty": "3;4;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.13245323570650439,
        "corr_rating_correctness": 0.9271726499455306,
        "project": "",
        "github": ""
    },
    {
        "id": "JKRVarUs3A1",
        "title": "Distributed Optimal Margin Distribution Machine",
        "track": "main",
        "status": "Reject",
        "keywords": "Distributed machine learning;margin distribution;classification;kernel learning",
        "author": "",
        "aff": "",
        "rating": "3;3;8;8",
        "confidence": "4;3;4;4",
        "correctness": "3;4;4;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "JLbXkHkLCG6",
        "title": "Imitation Learning from Pixel Observations for Continuous Control",
        "track": "main",
        "status": "Reject",
        "keywords": "imitation learning;optimal transport;GAIL;adversarial learning",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;4;4;3",
        "correctness": "2;3;4;3",
        "technical_novelty": "3;2;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": "https://anonymous.4open.science/r/ImitateFromPixelsICLR-B0EF"
    },
    {
        "id": "JLxrtqUaVe",
        "title": "Integrating Attention Feedback into the Recurrent Neural Network",
        "track": "main",
        "status": "Withdraw",
        "keywords": "recurrent neural network",
        "author": "",
        "aff": "",
        "rating": "1;1;3;5",
        "confidence": "4;4;3;4",
        "correctness": "3;2;3;2",
        "technical_novelty": "2;1;2;3",
        "empirical_novelty": "1;1;2;2",
        "presentation": "",
        "rating_avg": 2.5,
        "confidence_avg": 3.75,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.17407765595569782,
        "corr_rating_correctness": -0.30151134457776363,
        "project": "",
        "github": ""
    },
    {
        "id": "JM2kFbJvvI",
        "title": "Who Is the Strongest Enemy? Towards Optimal and Efficient Evasion Attacks in Deep RL",
        "track": "main",
        "status": "Poster",
        "keywords": "adversarial RL;robustness of RL;evasion attack;optimal attack;observation perturbation",
        "author": "",
        "aff": "University of Maryland, College Park; Sun Yat-sen University",
        "rating": "3;6;8;8",
        "confidence": "2;3;4;3",
        "correctness": "2;4;3;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8638684255813602,
        "corr_rating_correctness": 0.5183210553488161,
        "project": "",
        "github": ""
    },
    {
        "id": "JMri406Cb-",
        "title": "Decoupling Strategy and Surface Realization for Task-oriented Dialogues",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Strategy Optimization;Surface Realization;Task-oriented Dialogue",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5;5;5",
        "confidence": "3;3;4;4;4;3",
        "correctness": "2;3;3;3;2;3",
        "technical_novelty": "3;2;2;3;2;2",
        "empirical_novelty": "3;2;2;3;2;2",
        "presentation": "",
        "rating_avg": 4.333333333333333,
        "confidence_avg": 3.5,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.7071067811865476,
        "corr_rating_correctness": 0.2500000000000001,
        "project": "",
        "github": ""
    },
    {
        "id": "JPkQwEdYn8",
        "title": "Neural Processes with Stochastic Attention: Paying more attention to the context dataset",
        "track": "main",
        "status": "Poster",
        "keywords": "neural processes;stochastic attention;variational inference;information theory",
        "author": "",
        "aff": "KAIST AI",
        "rating": "5;6;6;8",
        "confidence": "4;2;2;4",
        "correctness": "3;4;3;3",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "3;3;2;2",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.2294157338705618,
        "corr_rating_correctness": -0.13245323570650439,
        "project": "",
        "github": ""
    },
    {
        "id": "JQ1RLAEn-BO",
        "title": "Kernel Density Decision Trees",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;5;4;4",
        "correctness": "2;2;4;2",
        "technical_novelty": "3;2;2;2",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "JRrjhY3sJy_",
        "title": "Molecular Graph Generation via Geometric Scattering",
        "track": "main",
        "status": "Withdraw",
        "keywords": "geometric scattering;drug discovery;drug design;graph generation;autoencoder",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "4;4;4;4",
        "correctness": "1;2;3;4",
        "technical_novelty": "2;2;3;4",
        "empirical_novelty": "1;2;3;4",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 4.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9467292624062574,
        "project": "",
        "github": ""
    },
    {
        "id": "JSR-YDImK95",
        "title": "Path Auxiliary Proposal for MCMC in Discrete Space",
        "track": "main",
        "status": "Spotlight",
        "keywords": "",
        "author": "",
        "aff": "Georgia Institute of Technology; Amazon; Google Brain; Siemens",
        "rating": "8;8;8;8",
        "confidence": "5;5;3;5",
        "correctness": "4;4;3;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 4.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "JSsjw8YuG1P",
        "title": "PERSONALIZED LAB TEST RESPONSE PREDICTION WITH KNOWLEDGE AUGMENTATION",
        "track": "main",
        "status": "Reject",
        "keywords": "Lab test responses;Patient Representation;Electronic Health Records",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;4;5;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "0;2;3;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.13245323570650439,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "JTbUTe0B0J1",
        "title": "Network Pruning Spaces",
        "track": "main",
        "status": "Withdraw",
        "keywords": "network pruning;convolutional neural network;deep learning",
        "author": "",
        "aff": "",
        "rating": "3;3;3",
        "confidence": "4;4;4",
        "correctness": "2;2;2",
        "technical_novelty": "2;2;4",
        "empirical_novelty": "2;2;4",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "JV4tkMi4xg",
        "title": "Constrained Discrete Black-Box Optimization using Mixed-Integer Programming",
        "track": "main",
        "status": "Reject",
        "keywords": "discrete blackbox optimization;mixed integer programming",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "4;4;4;4",
        "correctness": "3;4;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;4;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "JVR4JswsEM",
        "title": "A Dot Product Attention Free Transformer",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;3;4;4",
        "correctness": "4;4;3;3",
        "technical_novelty": "2;3;3;4",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "JVWB8QRUOi-",
        "title": "Learning Homophilic Incentives in Sequential Social Dilemmas",
        "track": "main",
        "status": "Reject",
        "keywords": "Multi-Agent Reinforcement Learning;Sequential Social Dilemma;Cooperation Emergence",
        "author": "",
        "aff": "",
        "rating": "3;3;5",
        "confidence": "4;5;3",
        "correctness": "1;3;3",
        "technical_novelty": "4;2;2",
        "empirical_novelty": "4;2;3",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 4.0,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8660254037844387,
        "corr_rating_correctness": 0.5000000000000001,
        "project": "",
        "github": ""
    },
    {
        "id": "JVsvIuMDE0Z",
        "title": "Adaptive Behavior Cloning Regularization for Stable Offline-to-Online Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "5;3;5;4",
        "correctness": "3;4;4;3",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;3;2;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 4.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5222329678670935,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "JXSZuWSPH85",
        "title": "Deep Inverse Reinforcement Learning via Adversarial One-Class Classification",
        "track": "main",
        "status": "Reject",
        "keywords": "inverse reinforcement learning;one-class classification",
        "author": "",
        "aff": "",
        "rating": "3;5;6",
        "confidence": "3;4;2",
        "correctness": "3;3;4",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3273268353539886,
        "corr_rating_correctness": 0.7559289460184545,
        "project": "",
        "github": ""
    },
    {
        "id": "JXhROKNZzOc",
        "title": "SQuant: On-the-Fly Data-Free Quantization via Diagonal Hessian Approximation",
        "track": "main",
        "status": "Poster",
        "keywords": "Data-Free Quantization;Hessian Matrix;Approximation",
        "author": "",
        "aff": "University of Rochester; Shanghai Jiao Tong University, Shanghai Qi Zhi Institute; DAMO Academy, Alibaba Group; Institute for AI Industry Research (AIR), Tsinghua University; Microsoft Research",
        "rating": "6;6;6;8",
        "confidence": "4;4;4;3",
        "correctness": "2;3;3;3",
        "technical_novelty": "3;3;3;4",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": "https://github.com/clevercool/SQuant"
    },
    {
        "id": "JYQYysrNT3M",
        "title": "Reinforcement Learning with Ex-Post Max-Min Fairness",
        "track": "main",
        "status": "Reject",
        "keywords": "Reinforcement learning;fairness;regret minimization;multi-objective optimization;constrained Markov decision processes",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "3;3;3;3",
        "correctness": "3;4;4;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "JYtwGwIL7ye",
        "title": "The Effects of Reward Misspecification: Mapping and Mitigating Misaligned Models",
        "track": "main",
        "status": "Poster",
        "keywords": "reward misspecification;reinforcement learning;reward hacking;alignment;ml safety",
        "author": "",
        "aff": "Caltech; UC Berkeley",
        "rating": "6;6;6;8",
        "confidence": "4;4;4;4",
        "correctness": "3;4;4;4",
        "technical_novelty": "3;3;2;3",
        "empirical_novelty": "2;3;4;4",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "JZrETJlgyq",
        "title": "Exploring Non-Contrastive Representation Learning for Deep Clustering",
        "track": "main",
        "status": "Reject",
        "keywords": "Image Clustering;Representation Learning;Self-supervised Learning",
        "author": "",
        "aff": "",
        "rating": "3;6;6;8",
        "confidence": "5;4;4;3",
        "correctness": "4;3;4;3",
        "technical_novelty": "2;2;3;4",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9901475429766743,
        "corr_rating_correctness": -0.7001400420140049,
        "project": "",
        "github": ""
    },
    {
        "id": "J_2xNmVcY4",
        "title": "Optimizing Neural Networks with Gradient Lexicase Selection",
        "track": "main",
        "status": "Poster",
        "keywords": "deep learning;lexicase selection;optimization;evolutionary algorithms",
        "author": "",
        "aff": "University of Massachusetts Amherst; Amherst College, University of Massachusetts Amherst",
        "rating": "6;6;6;8",
        "confidence": "3;5;4;3",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "1;2;2;4",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5222329678670935,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "J_F_qqCE3Z5",
        "title": "DKM: Differentiable k-Means Clustering Layer for Neural Network Compression",
        "track": "main",
        "status": "Poster",
        "keywords": "Deep learning;neural network;compression",
        "author": "",
        "aff": "Apple",
        "rating": "5;6;6;6",
        "confidence": "4;4;4;4",
        "correctness": "3;2;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "J_PHjw4gvXJ",
        "title": "Improving the Accuracy of Learning Example Weights for Imbalance Classification",
        "track": "main",
        "status": "Poster",
        "keywords": "Imbalance classification;Meta learning;Data weighting.",
        "author": "",
        "aff": "College of Computer Science, Zhejiang University of Technology, Hangzhou, China",
        "rating": "6;6;6;8",
        "confidence": "4;4;3;3",
        "correctness": "4;3;3;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;2;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "JbYk9VrZDS",
        "title": "Federated Learning with Data-Agnostic Distribution Fusion",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Federated Learning;variational inference",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "4;4;5;4",
        "correctness": "3;2;3;4",
        "technical_novelty": "3;2;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 4.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "JeSIUeUSUuR",
        "title": "Variability of Neural Networks and Han-Layer: A Variability-Inspired Model",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;4;4;3",
        "correctness": "2;2;2;3",
        "technical_novelty": "2;2;1;3",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.75,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "JedTK_aOaRa",
        "title": "Private Multi-Winner Voting For Machine Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "multi-label;privacy;voting;confidentiality;differential privacy;disributed collaboration;collaboration",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5;8",
        "confidence": "4;2;2;3;3",
        "correctness": "3;3;4;4;3",
        "technical_novelty": "2;3;3;3;3",
        "empirical_novelty": "3;2;2;2;3",
        "presentation": "",
        "rating_avg": 5.2,
        "confidence_avg": 2.8,
        "correctness_avg": 3.4,
        "technical_novelty_avg": 2.8,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.30066889715147743,
        "corr_rating_correctness": -0.10206207261596574,
        "project": "",
        "github": ""
    },
    {
        "id": "Jep2ykGUdS",
        "title": "DEUP: Direct Epistemic Uncertainty Prediction",
        "track": "main",
        "status": "Reject",
        "keywords": "deep learning;uncertainty estimation",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "3;4;3;4",
        "correctness": "2;4;2;4",
        "technical_novelty": "2;3;3;4",
        "empirical_novelty": "2;3;3;2",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "JfaWawZ8BmX",
        "title": "Anisotropic Random Feature Regression in High Dimensions",
        "track": "main",
        "status": "Poster",
        "keywords": "random feature models;high dimensional asymptotics;generalization;learning curves;double descent;multiple descent;alignment",
        "author": "",
        "aff": "Brain Team, Google Research; Neurosciences Graduate Program, Stanford University",
        "rating": "6;6;6;8",
        "confidence": "4;4;3;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;3;2;4",
        "empirical_novelty": "2;2;3;0",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "JgmY4TUgznC",
        "title": "Few-Shot Multi-task Learning via Implicit regularization",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Few Shot Learning;Learning Instability",
        "author": "",
        "aff": "",
        "rating": "",
        "confidence": "",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Jh9VxCkrEZn",
        "title": "Spatiotemporal Representation Learning on Time Series with Dynamic Graph ODEs",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5;6",
        "confidence": "4;5;5;4;3",
        "correctness": "3;1;2;3;3",
        "technical_novelty": "2;3;2;3;2",
        "empirical_novelty": "2;2;2;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.2,
        "correctness_avg": 2.4,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8451542547285165,
        "corr_rating_correctness": 0.5929270612815711,
        "project": "",
        "github": ""
    },
    {
        "id": "Jjcv9MTqhcq",
        "title": "Rethinking Supervised Pre-Training for Better Downstream Transferring",
        "track": "main",
        "status": "Poster",
        "keywords": "Pre-Training;Contrastive Learning;Representation Learning;Downstream Transferring",
        "author": "",
        "aff": "Alibaba Group; BNRist, THUIBCS, KLISS, BLBCI, School of Software, Tsinghua University",
        "rating": "5;6;6;6",
        "confidence": "4;4;4;4",
        "correctness": "3;2;4;3",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "1;2;3;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "JkVSM0X_4w_",
        "title": "Switch Spaces: Learning Product Spaces with Sparse Gating",
        "track": "main",
        "status": "Withdraw",
        "keywords": "representation learning;product space",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "3;3;3;3",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "3;2;3;2",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "JmPwWxL8F1T",
        "title": "A First-Order Method for Estimating Natural Gradients for Variational Inference with Gaussians and Gaussian Mixture Models",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Variational Inference;Approximate Inference;MORE;VOGN;VIPS;GVA",
        "author": "",
        "aff": "",
        "rating": "3;3;6",
        "confidence": "4;4;4",
        "correctness": "2;2;3",
        "technical_novelty": "2;3;2",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "JmU7lyDxTpc",
        "title": "Multi-scale Feature Learning Dynamics: Insights for Double Descent",
        "track": "main",
        "status": "Reject",
        "keywords": "generalization;neural networks;dynamics;double descent",
        "author": "",
        "aff": "",
        "rating": "5;8;8",
        "confidence": "5;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "JpNH4CW_zl",
        "title": "Multivariate Time Series Forecasting with Latent Graph Inference",
        "track": "main",
        "status": "Reject",
        "keywords": "Time Series Forecasting;Graph Neural Networks;Graph Inference;Multivariate Time Series",
        "author": "",
        "aff": "",
        "rating": "3;5;5",
        "confidence": "5;3;4",
        "correctness": "2;3;3",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;3;0",
        "presentation": "",
        "rating_avg": 4.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8660254037844385,
        "corr_rating_correctness": 0.9999999999999998,
        "project": "",
        "github": ""
    },
    {
        "id": "JprM0p-q0Co",
        "title": "Tackling the Generative Learning Trilemma with Denoising Diffusion GANs",
        "track": "main",
        "status": "Spotlight",
        "keywords": "",
        "author": "",
        "aff": "NVIDIA; The University of Chicago",
        "rating": "8;8;8;8",
        "confidence": "3;4;4;4",
        "correctness": "4;4;4;4",
        "technical_novelty": "4;3;3;3",
        "empirical_novelty": "4;3;4;3",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.75,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "https://nvlabs.github.io/denoising-diffusion-gan",
        "github": "https://github.com/nvlabs/denoising-diffusion-gan"
    },
    {
        "id": "JsfFpJhI4BV",
        "title": "Learning Identity-Preserving Transformations on Data Manifolds",
        "track": "main",
        "status": "Reject",
        "keywords": "manifold learning;unsupervised learning;generative models;lie groups;transport operators;transformation learning",
        "author": "",
        "aff": "",
        "rating": "5;5;6",
        "confidence": "4;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "2;3;2",
        "empirical_novelty": "2;4;2",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9999999999999997,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "Jt8FYFnyTLR",
        "title": "On the Safety of Interpretable Machine Learning: A Maximum Deviation Approach",
        "track": "main",
        "status": "Reject",
        "keywords": "safety;interpretability;explainability",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;4;2;4",
        "correctness": "2;4;3;3",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "3;2;2;1",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.13245323570650439,
        "corr_rating_correctness": 0.6488856845230502,
        "project": "",
        "github": ""
    },
    {
        "id": "JtBRnrlOEFN",
        "title": "Charformer: Fast Character Transformers via Gradient-based Subword Tokenization",
        "track": "main",
        "status": "Poster",
        "keywords": "transformers;NLP;language",
        "author": "",
        "aff": "DeepMind\u2020; Google Research and DeepMind",
        "rating": "5;5;6;6;8",
        "confidence": "4;3;4;4;5",
        "correctness": "2;2;3;3;4",
        "technical_novelty": "2;3;3;3;4",
        "empirical_novelty": "2;3;3;2;4",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.8,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.8,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8660254037844387,
        "corr_rating_correctness": 0.9759000729485333,
        "project": "",
        "github": ""
    },
    {
        "id": "JvGzKO1QLet",
        "title": "Intervention-based Recurrent Casual Model for Non-stationary Video Causal Discovery",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;4;4;5",
        "correctness": "3;4;3;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 4.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "JvPopr9skL0",
        "title": "Efficient Out-of-Distribution Detection via CVAE data Generation",
        "track": "main",
        "status": "Reject",
        "keywords": "Out-of-distribution Detection",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "4;3;4;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "JvVFSmFV8G",
        "title": "Which model to trust: assessing the influence of models on the performance of reinforcement learning algorithms for continuous control tasks",
        "track": "main",
        "status": "Desk Reject",
        "keywords": "reinforcement learning;model-based reinforcement learning;deep learning;bayesian deep learning;gaussian processes;continuous control;model uncertainty",
        "author": "",
        "aff": "",
        "rating": "",
        "confidence": "",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Jvoe8JCGvy",
        "title": "Online MAP Inference and Learning for Nonsymmetric Determinantal Point Processes",
        "track": "main",
        "status": "Reject",
        "keywords": "online algorithms;nonsymmetric determinantal point processes",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "5;4;4;3",
        "correctness": "2;2;3;3",
        "technical_novelty": "1;3;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9733285267845754,
        "corr_rating_correctness": 0.6882472016116854,
        "project": "",
        "github": ""
    },
    {
        "id": "JxFgJbZ-wft",
        "title": "Variational Predictive Routing with Nested Subjective Timescales",
        "track": "main",
        "status": "Poster",
        "keywords": "Hierarchical temporal abstraction;event discovery;hierarchical generative models;variational inference",
        "author": "",
        "aff": "Huawei Technologies, Shenzhen, China; Huawei Technologies, London, UK",
        "rating": "6;6;6;8",
        "confidence": "4;3;5;3",
        "correctness": "3;4;4;4",
        "technical_novelty": "4;3;3;3",
        "empirical_novelty": "0;3;3;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5222329678670935,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "JyI9lc8WxW",
        "title": "Planckian jitter: enhancing the color quality of self-supervised visual representations",
        "track": "main",
        "status": "Reject",
        "keywords": "Contrastive Learning;Self-Supervised Learning;Color Features;Illuminant Invariance",
        "author": "",
        "aff": "",
        "rating": "5;6;6",
        "confidence": "4;2;5",
        "correctness": "2;3;4",
        "technical_novelty": "2;3;2",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 5.666666666666667,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.18898223650461363,
        "corr_rating_correctness": 0.8660254037844385,
        "project": "",
        "github": ""
    },
    {
        "id": "JzFyNx7-SyS",
        "title": "Interpreting Graph Neural Networks via Unrevealed Causal Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Model Explainability;Graph Neural Networks;Structural Casual Model",
        "author": "",
        "aff": "",
        "rating": "3;3;6;6",
        "confidence": "3;4;4;3",
        "correctness": "3;2;3;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896258,
        "project": "",
        "github": ""
    },
    {
        "id": "JzNB0eA2-M4",
        "title": "On the Convergence of the Monte Carlo Exploring Starts Algorithm for Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "reinforcement learning;convergence of reinforcement learning algorithm;monte carlo exploring starts",
        "author": "",
        "aff": "New York University Shanghai",
        "rating": "5;5;8;8",
        "confidence": "4;4;3;4",
        "correctness": "4;3;3;4",
        "technical_novelty": "2;2;4;4",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896258,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "JzwLTPuG0fo",
        "title": "Knowledge-driven Active Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Active Learning;Deep Learning;FOL;Multi-label classification;Object-detection",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3;5",
        "confidence": "3;4;4;4;3",
        "correctness": "3;3;3;3;4",
        "technical_novelty": "2;2;1;2;2",
        "empirical_novelty": "2;2;2;2;2",
        "presentation": "",
        "rating_avg": 3.4,
        "confidence_avg": 3.6,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 1.8,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6123724356957946,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "K-hiHQXEQog",
        "title": "Autoregressive Latent Video Prediction with High-Fidelity Image Generator",
        "track": "main",
        "status": "Reject",
        "keywords": "video prediction;autoregressive models",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5;5",
        "confidence": "4;4;4;4;4",
        "correctness": "2;4;4;4;3",
        "technical_novelty": "2;2;2;1;3",
        "empirical_novelty": "2;2;2;2;3",
        "presentation": "",
        "rating_avg": 3.8,
        "confidence_avg": 4.0,
        "correctness_avg": 3.4,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.2,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.10206207261596574,
        "project": "https://sites.google.com/view/harp-anonymous",
        "github": ""
    },
    {
        "id": "K0E_F0gFDgA",
        "title": "The MultiBERTs: BERT Reproductions for Robustness Analysis",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Pre-trained models;BERT;bootstrapping;hypothesis testing;robustness",
        "author": "",
        "aff": "",
        "rating": "6;6;8;8",
        "confidence": "3;2;4;3",
        "correctness": "3;4;4;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;4;4;4",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.7071067811865475,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "K1m0oSiGasn",
        "title": "Adaptive Region Pooling for Fine-Grained Representation Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Fine-grained representation learning;Re-identification;Pooling operation",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "5;4;5;3",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7608859102526822,
        "corr_rating_correctness": 0.13245323570650439,
        "project": "",
        "github": ""
    },
    {
        "id": "K2JfSnLBD9",
        "title": "C-Planning: An Automatic Curriculum for Learning Goal-Reaching Tasks",
        "track": "main",
        "status": "Poster",
        "keywords": "reinforcement learning;planning;variational inference;curriculum learning;waypoints;subgoals",
        "author": "",
        "aff": "Carnegie Mellon University; UC Berkeley",
        "rating": "6;6;8;8",
        "confidence": "4;4;4;5",
        "correctness": "3;3;3;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "K3bGe_-aMV",
        "title": "Semantically Controllable Generation of Physical Scenes with Explicit Knowledge",
        "track": "main",
        "status": "Reject",
        "keywords": "Deep Generative Models;Knowledge-intergrated Neural Networks;Physical Scene Generation",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "2;4;2;2",
        "correctness": "3;2;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;3;4",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 2.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "K3uRhaKJuZg",
        "title": "Video Forgery Detection Using Multiple Cues on Fusion of EfficientNet and Swin Transformer",
        "track": "main",
        "status": "Reject",
        "keywords": "deepfakes;video forgery detection;high-frequency;texture;optical flow;EfficientNet;Swin Transformer",
        "author": "",
        "aff": "",
        "rating": "3;3;3;8",
        "confidence": "5;5;4;4",
        "correctness": "2;3;3;4",
        "technical_novelty": "1;2;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 4.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "K47zHehHcRc",
        "title": "On the interventional consistency of autoencoders",
        "track": "main",
        "status": "Reject",
        "keywords": "causal representation learning;disentanglement;autoencoders",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "4;3;2;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;4;2;3",
        "empirical_novelty": "2;4;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.058025885318565944,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "K8HF8tTQ-4i",
        "title": "A Step-Wise Weighting Approach for Controllable Text Generation",
        "track": "main",
        "status": "Withdraw",
        "keywords": "language models;controllable text generation;text detoxification",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "3;4;3;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "1;4;3;3",
        "empirical_novelty": "1;4;3;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.6882472016116854,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "K9KiBYAthi9",
        "title": "DMSANET: DUAL MULTI SCALE ATTENTION NETWORK",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "1;1;3;3",
        "confidence": "5;4;5;3",
        "correctness": "3;2;3;3",
        "technical_novelty": "1;1;1;2",
        "empirical_novelty": "0;0;1;2",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 1.25,
        "empirical_novelty_avg": 0.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.30151134457776363,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "KB5onONJIAU",
        "title": "Comparing Distributions by Measuring Differences that Affect Decision Making",
        "track": "main",
        "status": "Oral",
        "keywords": "probability divergence;two sample test;generative model",
        "author": "",
        "aff": "Department of Computer Science, Stanford University",
        "rating": "8;8;8",
        "confidence": "3;3;3",
        "correctness": "3;4;4",
        "technical_novelty": "3;4;3",
        "empirical_novelty": "3;3;4",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 3.3333333333333335,
        "empirical_novelty_avg": 3.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "KBQP4A_J1K",
        "title": "The Neural Data Router: Adaptive Control Flow in Transformers Improves Systematic Generalization",
        "track": "main",
        "status": "Poster",
        "keywords": "transformer;compositionality;systematic generalization;algorithmic reasoning;arithmetic",
        "author": "",
        "aff": "The Swiss AI Lab, IDSIA, University of Lugano (USI) & SUPSI, Lugano, Switzerland; The Swiss AI Lab, IDSIA, University of Lugano (USI) & SUPSI, Lugano, Switzerland and King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia",
        "rating": "8;8;8",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "3;4;3",
        "empirical_novelty": "2;4;3",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.3333333333333335,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/robertcsordas/ndr"
    },
    {
        "id": "KBuOP5HrVQ0",
        "title": "Bayesian Exploration for Lifelong Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5",
        "confidence": "3;4;2",
        "correctness": "2;4;1",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 3.0,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8660254037844387,
        "corr_rating_correctness": -0.7559289460184545,
        "project": "",
        "github": ""
    },
    {
        "id": "KDAEc2nai83",
        "title": "Human-Level Control without Server-Grade Hardware",
        "track": "main",
        "status": "Reject",
        "keywords": "Deep Reinforcement Learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5;6",
        "confidence": "4;4;4;3;4",
        "correctness": "3;2;2;3;3",
        "technical_novelty": "1;2;2;2;2",
        "empirical_novelty": "2;2;2;2;2",
        "presentation": "",
        "rating_avg": 4.4,
        "confidence_avg": 3.8,
        "correctness_avg": 2.6,
        "technical_novelty_avg": 1.8,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.24999999999999994,
        "corr_rating_correctness": 0.2721655269759087,
        "project": "",
        "github": ""
    },
    {
        "id": "KEQl-MZ5fg7",
        "title": "Learning Versatile Neural Architectures by Propagating Network Codes",
        "track": "main",
        "status": "Poster",
        "keywords": "Multitask NAS;Task-Transferable Architecture;Neural Predictor;NAS Benchmark",
        "author": "",
        "aff": "SenseTime Research; University of Hong Kong; ByteDance Inc.; Baidu; Gaoling School of Arti\ufb01cial Intelligence, Renmin University of China",
        "rating": "6;6;8",
        "confidence": "4;5;2",
        "correctness": "4;4;4",
        "technical_novelty": "3;4;3",
        "empirical_novelty": "3;3;4",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 3.3333333333333335,
        "empirical_novelty_avg": 3.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9449111825230679,
        "corr_rating_correctness": 0.0,
        "project": "https://network-propagation.github.io",
        "github": "github.com/dingmyu/NCP1"
    },
    {
        "id": "KFUWHgRYEDF",
        "title": "ScaLA: Speeding-Up Fine-tuning of Pre-trained Transformer Networks via Efficient and Scalable Adversarial Perturbation",
        "track": "main",
        "status": "Reject",
        "keywords": "Efficient Training Methods;Large Batch Optimization;Transformer Networks;BERT",
        "author": "",
        "aff": "",
        "rating": "5;6;6",
        "confidence": "3;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 5.666666666666667,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.4999999999999999,
        "corr_rating_correctness": 0.9999999999999997,
        "project": "",
        "github": ""
    },
    {
        "id": "KGJ2qTzPlJ",
        "title": "Provably Robust Transfer",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Transfer Learning;Robustness;Verification",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "4;3;4;1",
        "correctness": "4;2;3;3",
        "technical_novelty": "1;2;2;3",
        "empirical_novelty": "1;3;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6285393610547089,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "KJHH22zIFxi",
        "title": "Robust and Data-efficient Q-learning by Composite Value-estimation",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Compositional Value-learning;Noise Robustness;Data-efficient Reinforcement Learning;Off-policy Learning;Model-free Reinforcement Learning",
        "author": "",
        "aff": "",
        "rating": "5;5;5;8",
        "confidence": "3;3;4;3",
        "correctness": "3;3;2;3",
        "technical_novelty": "2;3;2;4",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "KJggliHbs8",
        "title": "Node Feature Extraction by Self-Supervised Multi-scale Neighborhood Prediction",
        "track": "main",
        "status": "Poster",
        "keywords": "Self-supervised learning;Graph Neural Networks;Extreme multi-label classification",
        "author": "",
        "aff": "University of Illinois Urbana-Champaign, USA; Amazon, USA; University of California, Los Angeles, USA",
        "rating": "6;6;8",
        "confidence": "4;4;3",
        "correctness": "3;1;4",
        "technical_novelty": "4;3;3",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 3.3333333333333335,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9999999999999998,
        "corr_rating_correctness": 0.7559289460184545,
        "project": "",
        "github": "https://github.com/amzn/pecos/tree/mainline/examples/giant-xrt"
    },
    {
        "id": "KJztlfGPdwW",
        "title": "Rethinking Goal-Conditioned Supervised Learning and Its Connection to Offline RL",
        "track": "main",
        "status": "Poster",
        "keywords": "Goal-conditioned reinforcement learning;offline reinforcement learning;goal-conditioned supervised learning",
        "author": "",
        "aff": "Tencent Robotics X; Tsinghua University; King\u2019s College London; University of Cambridge; Eindhoven University of Technology",
        "rating": "5;6;8",
        "confidence": "3;3;3",
        "correctness": "2;3;4",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 6.333333333333333,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9819805060619659,
        "project": "",
        "github": ""
    },
    {
        "id": "KL5jILuehZ",
        "title": "End-to-End Balancing for Causal Continuous Treatment-Effect Estimation",
        "track": "main",
        "status": "Reject",
        "keywords": "End-to-end learning;Entropy Balancing;Continuous Treatments",
        "author": "",
        "aff": "",
        "rating": "3;6;8;8",
        "confidence": "4;4;4;3",
        "correctness": "3;3;4;4",
        "technical_novelty": "3;4;4;3",
        "empirical_novelty": "2;1;4;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.49374193110101877,
        "corr_rating_correctness": 0.8551861104941366,
        "project": "",
        "github": ""
    },
    {
        "id": "KLaDXLAzzFT",
        "title": "Near-optimal Offline Reinforcement Learning with Linear Representation: Leveraging Variance Information with Pessimism",
        "track": "main",
        "status": "Poster",
        "keywords": "reinforcement learning theory;markov decision process theory",
        "author": "",
        "aff": "Department of Computer Science, University of California, Santa Barbara; Department of Electrical and Computer Engineering, Princeton University",
        "rating": "5;6;6;8",
        "confidence": "3;2;4;4",
        "correctness": "2;3;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;0;3;0",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 1.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.48420012470625223,
        "corr_rating_correctness": 0.7608859102526822,
        "project": "",
        "github": ""
    },
    {
        "id": "KLh86DknDj7",
        "title": "Discovering Classification Rules for Interpretable Learning with Linear Programming",
        "track": "main",
        "status": "Reject",
        "keywords": "Rule generation;linear programming;interpretability",
        "author": "",
        "aff": "",
        "rating": "3;3;6",
        "confidence": "3;2;3",
        "correctness": "2;3;3",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "1;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5,
        "corr_rating_correctness": 0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "KNfuensPHDU",
        "title": "Efficient Certification for Probabilistic Robustness",
        "track": "main",
        "status": "Reject",
        "keywords": "robustness;neural networks;deep learning",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "2;4;4;3",
        "correctness": "2;3;4;3",
        "technical_novelty": "2;1;2;3",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8703882797784891,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "KPEFXR1HdIo",
        "title": "Fine-grained Differentiable Physics: A Yarn-level Model for Fabrics",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "School of Computing, University of Leeds; School of Informatics, University of Edinburgh; Peking University",
        "rating": "6;6;6;6;6;8",
        "confidence": "4;3;4;2;3;4",
        "correctness": "3;4;3;4;4;3",
        "technical_novelty": "3;2;4;3;3;3",
        "empirical_novelty": "3;2;3;3;3;4",
        "presentation": "",
        "rating_avg": 6.333333333333333,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.4000000000000001,
        "corr_rating_correctness": -0.4472135954999579,
        "project": "",
        "github": "https://github.com/realcrane/Fine-grained-Differentiable-Physics-A-Yarn-level-Model-for-Fabrics.git"
    },
    {
        "id": "KSSfF5lMIAg",
        "title": "Model Agnostic Interpretability for Multiple Instance Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "multiple instance learning;interpretability;model-agnostic",
        "author": "",
        "aff": "Agents, Interaction and Complexity Group, Department of Electronics and Computer Science, University of Southampton",
        "rating": "5;5;5;6",
        "confidence": "5;4;2;2",
        "correctness": "2;3;4;3",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "3;3;2;2",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5555555555555555,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/JAEarly/MILLI"
    },
    {
        "id": "KSugKcbNf9",
        "title": "Transformers Can Do Bayesian Inference",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "Charit \u00b4e Berlin; University of Freiburg; University of Freiburg, Bosch Center for Arti\ufb01cial Intelligence",
        "rating": "5;6;8",
        "confidence": "5;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "3;4;3",
        "presentation": "",
        "rating_avg": 6.333333333333333,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 3.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7559289460184544,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/automl/TransformersCanDoBayesianInference"
    },
    {
        "id": "KTF1h2XWKZA",
        "title": "Multi-batch Reinforcement Learning via Sample Transfer and Imitation Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Multi-bacth;batch reinfrocement learning;sample transfer",
        "author": "Put All Your Authors Here, Separated by Commas",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "5;3;4;4",
        "correctness": "3;3;2;3",
        "technical_novelty": "2;1;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "KTPuIsx4pmo",
        "title": "Meta-Imitation Learning by Watching Video Demonstrations",
        "track": "main",
        "status": "Poster",
        "keywords": "Meta-imitation Learning;One-shot Learning;Learning by Watching;Generative Adversarial Networks",
        "author": "",
        "aff": "State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences; School of Arti\ufb01cial Intelligence, University of Chinese Academy of Sciences; School of Arti\ufb01cial Intelligence, University of Chinese Academy of Sciences; Center for Excellence in Brain Science and Intelligence Technology, Chinese Academy of Sciences",
        "rating": "6;8;8;8",
        "confidence": "4;3;3;4",
        "correctness": "4;4;3;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;0;3;3",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "KUmMSZ_r28W",
        "title": "Particle Based Stochastic Policy Optimization",
        "track": "main",
        "status": "Reject",
        "keywords": "reinforcement learning;deep learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "3;4;4;3",
        "correctness": "2;3;4;4",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "0;3;3;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9045340337332909,
        "project": "",
        "github": ""
    },
    {
        "id": "KVYq2Ea90PC",
        "title": "A Study of Face Obfuscation in ImageNet",
        "track": "main",
        "status": "Reject",
        "keywords": "ImageNet;Privacy;Face Obfuscation",
        "author": "",
        "aff": "",
        "rating": "5;5;6",
        "confidence": "5;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "2;1;2",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 1.6666666666666667,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8660254037844385,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "KVhvw16pvi",
        "title": "TAG: Task-based Accumulated Gradients for Lifelong learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Lifelong Learning;Continual Learning;Catastrophic forgetting",
        "author": "",
        "aff": "",
        "rating": "5;5;5;8",
        "confidence": "4;4;3;4",
        "correctness": "4;2;3;4",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.5222329678670935,
        "project": "",
        "github": ""
    },
    {
        "id": "K_PJXdshOao",
        "title": "Pre-training also Transfers Non-robustness",
        "track": "main",
        "status": "Withdraw",
        "keywords": "adversarial robustness;non-robust feature;transfer learning;pre-training",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;3;3;4",
        "correctness": "3;3;2;3",
        "technical_novelty": "2;3;1;3",
        "empirical_novelty": "2;3;3;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "KdWnM6Xj8KX",
        "title": "Regularization for Strategy Exploration in Empirical Game-Theoretic Analysis",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Multi-agent Learning;empirical game-theoretic analysis;policy space response oracle",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;4;3",
        "correctness": "2;2;3;3",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "KdcLdLuIjQT",
        "title": "Goal Randomization for Playing Text-based Games without a Reward Function",
        "track": "main",
        "status": "Reject",
        "keywords": "Text-based games;Deep reinforcement learning;Generalization",
        "author": "",
        "aff": "",
        "rating": "5;5;5",
        "confidence": "4;4;4",
        "correctness": "2;2;4",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "2;0;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "KeBPcg5E3X",
        "title": "Representation Disentanglement in Generative Models with Contrastive Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;5;8",
        "confidence": "3;2;4;3",
        "correctness": "3;3;3;4",
        "technical_novelty": "1;2;2;2",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "KeI9E-gsoB",
        "title": "Learning Curves for Gaussian Process Regression with Power-Law Priors and Targets",
        "track": "main",
        "status": "Poster",
        "keywords": "Gaussian process regression;kernel ridge regression;generalization error;power law;neural tangent kernel",
        "author": "",
        "aff": "MPI MiS; UCLA & MPI MiS; UCLA",
        "rating": "6;6;6;8",
        "confidence": "4;4;2;3",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;2;0;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.17407765595569782,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "Kef8cKdHWpP",
        "title": "DiffSkill: Skill Abstraction from Differentiable Physics for Deformable Object Manipulations with Tools",
        "track": "main",
        "status": "Poster",
        "keywords": "Deformable Object Manipulation;Differentiable Physics",
        "author": "",
        "aff": "MIT BCS, CBMM, CSAIL; MIT; UC San Diego; MIT-IBM Waston AI Lab; Carnegie Mellon University",
        "rating": "6;6;8;10",
        "confidence": "3;3;3;3",
        "correctness": "4;4;4;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;3;2",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "https://xingyu-lin.github.io/diffskill/",
        "github": ""
    },
    {
        "id": "KhLK0sHMgXK",
        "title": "NASPY: Automated Extraction of Automated Machine Learning Models",
        "track": "main",
        "status": "Spotlight",
        "keywords": "",
        "author": "",
        "aff": "Nanyang Technological University; Chongqing University; Zhejiang University",
        "rating": "6;6;8;8",
        "confidence": "4;2;3;3",
        "correctness": "2;3;4;4",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "3;3;4;4",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9045340337332909,
        "project": "",
        "github": ""
    },
    {
        "id": "KjR-3lBYB3y",
        "title": "Learning an Object-Based Memory System",
        "track": "main",
        "status": "Reject",
        "keywords": "Long Term Memory;State Estimation;Robot Learning;Object-Centric Learning",
        "author": "",
        "aff": "",
        "rating": "3;3;3",
        "confidence": "4;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "1;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "KkIE-qePhW",
        "title": "LSP : Acceleration and Regularization of Graph Neural Networks via Locality Sensitive Pruning of Graphs",
        "track": "main",
        "status": "Reject",
        "keywords": "Graph Sparsification;Graph Neural Networks;Pruning Neural Networks",
        "author": "",
        "aff": "",
        "rating": "1;3;3;3;5",
        "confidence": "4;4;4;4;4",
        "correctness": "2;4;3;2;4",
        "technical_novelty": "1;2;2;2;2",
        "empirical_novelty": "1;3;2;2;4",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 1.8,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.7071067811865475,
        "project": "",
        "github": ""
    },
    {
        "id": "KmNHWX9H7Kf",
        "title": "Uniform Generalization Bounds for Overparameterized Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "Information Gain;Effective Dimension;Overparameterized Neural Networks;Neural Tangent Kernel;Random Feature Kernel;RKHS;Mat\u00e9rn;Uniform Error Bounds",
        "author": "",
        "aff": "",
        "rating": "1;3;6;6;6",
        "confidence": "5;4;3;2;2",
        "correctness": "2;2;4;4;4",
        "technical_novelty": "1;1;3;3;4",
        "empirical_novelty": "0;1;4;2;0",
        "presentation": "",
        "rating_avg": 4.4,
        "confidence_avg": 3.2,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 1.4,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9494726616301967,
        "corr_rating_correctness": 0.951661902861773,
        "project": "",
        "github": ""
    },
    {
        "id": "Kmsf3z-vGu",
        "title": "Gradient-based Meta-solving and Its Applications to Iterative Methods for Solving Differential Equations",
        "track": "main",
        "status": "Reject",
        "keywords": "meta-learning;differential equation;iterative method",
        "author": "",
        "aff": "Under double-blind review",
        "rating": "3;5;6;8",
        "confidence": "4;4;3;3",
        "correctness": "3;4;4;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8320502943378437,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "KmtVD97J43e",
        "title": "Synchromesh: Reliable Code Generation from Pre-trained Language Models",
        "track": "main",
        "status": "Poster",
        "keywords": "program synthesis;language models;code generation",
        "author": "",
        "aff": "Stanford University; Microsoft Research, Redmond; X, the moonshot factory",
        "rating": "5;6;8;8",
        "confidence": "4;2;3;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;4;3",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.058025885318565944,
        "corr_rating_correctness": 0.9622504486493761,
        "project": "",
        "github": ""
    },
    {
        "id": "KntaNRo6R48",
        "title": "L0-Sparse Canonical Correlation Analysis",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "Faculty of Engineering, Bar Ilan University, Ramat Gan, Israel; School of Computer Science, Tel Aviv University, Tel Aviv, Israel; School of Medicine, Yale University, New Haven, CT, USA",
        "rating": "6;6;6;6",
        "confidence": "4;5;4;3",
        "correctness": "3;4;3;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;0;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "KoCzLK1Hugc",
        "title": "Adversarial robustness against multiple $l_p$-threat models at the price of one and how to quickly fine-tune robust models to another threat model",
        "track": "main",
        "status": "Reject",
        "keywords": "adversarial robustness;multiple norms;adversarial training;fine-tuning",
        "author": "",
        "aff": "Paper under double-blind review",
        "rating": "3;5;6;6",
        "confidence": "4;5;5;5",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;3;4",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9428090415820632,
        "corr_rating_correctness": 0.9428090415820632,
        "project": "",
        "github": ""
    },
    {
        "id": "KpRpECn3FfK",
        "title": "Graph Convolutional Memory using Topological Priors",
        "track": "main",
        "status": "Withdraw",
        "keywords": "reinforcement learning;memory;graph neural networks;navigation",
        "author": "",
        "aff": "",
        "rating": "3;3;5",
        "confidence": "4;5;4",
        "correctness": "3;3;2",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4999999999999999,
        "corr_rating_correctness": -1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "Kvbr8NicKq",
        "title": "Fast and Reliable Evaluation of Adversarial Robustness with Minimum-Margin Attack",
        "track": "main",
        "status": "Reject",
        "keywords": "adversarial machine learning;evaluation of adversarial robustness",
        "author": "",
        "aff": "",
        "rating": "3;3;5;8",
        "confidence": "4;4;4;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;2;4",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.49374193110101877,
        "project": "",
        "github": ""
    },
    {
        "id": "KwLWsm5idpR",
        "title": "Fair AutoML Through Multi-objective Optimization",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Automated Machine Learning;Machine Learning Fairness;Multi-Objective Optimization;Distributed Computing",
        "author": "",
        "aff": "",
        "rating": "3;5;5",
        "confidence": "4;3;2",
        "correctness": "2;3;3",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 4.333333333333333,
        "confidence_avg": 3.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8660254037844385,
        "corr_rating_correctness": 0.9999999999999998,
        "project": "",
        "github": ""
    },
    {
        "id": "Kwm8I7dU-l5",
        "title": "Graph-Guided Network for Irregularly Sampled Multivariate Time Series",
        "track": "main",
        "status": "Poster",
        "keywords": "time seres;irregular time series;graph neural networks;attention mechanism;time series classification;multivariate time series;representation learning;embeddings",
        "author": "",
        "aff": "Harvard University; MIT Lincoln Laboratory; University of Ljubljana",
        "rating": "5;5;8",
        "confidence": "3;5;4",
        "correctness": "2;2;4",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "3;2;4",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "KxbhdyiPHE",
        "title": "Learning Altruistic Behaviours in Reinforcement Learning without External Rewards",
        "track": "main",
        "status": "Spotlight",
        "keywords": "reinforcement learning;altruistic behavior in AI;multi-agent systems",
        "author": "",
        "aff": "University of Oxford; DeepMind",
        "rating": "6;6;6;8;8",
        "confidence": "4;4;3;3;3",
        "correctness": "3;3;3;4;3",
        "technical_novelty": "3;3;3;4;2",
        "empirical_novelty": "3;3;3;4;3",
        "presentation": "",
        "rating_avg": 6.8,
        "confidence_avg": 3.4,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.2,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6666666666666667,
        "corr_rating_correctness": 0.6123724356957946,
        "project": "",
        "github": ""
    },
    {
        "id": "L01Nn_VJ9i",
        "title": "Back2Future: Leveraging Backfill Dynamics for Improving Real-time Predictions in Future",
        "track": "main",
        "status": "Poster",
        "keywords": "Epidemic Forecasting;Data revisions;Graph Representation learning;Time Series Forecasting",
        "author": "",
        "aff": "College of Computing, Georgia Institute of Technology",
        "rating": "6;8;8",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "3;4;4",
        "empirical_novelty": "3;4;4",
        "presentation": "",
        "rating_avg": 7.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 3.6666666666666665,
        "empirical_novelty_avg": 3.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "L1L2G43k14n",
        "title": "WHY FLATNESS DOES AND DOES NOT CORRELATE WITH GENERALIZATION FOR DEEP NEURAL NETWORKS",
        "track": "main",
        "status": "Reject",
        "keywords": "flatness;Bayesian learning;generalization theory",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5;6",
        "confidence": "4;4;3;4;3",
        "correctness": "2;4;3;3;3",
        "technical_novelty": "2;1;2;3;2",
        "empirical_novelty": "2;2;3;3;3",
        "presentation": "",
        "rating_avg": 4.4,
        "confidence_avg": 3.6,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.6,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.748455199183749,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "L2V-VQ7Npl0",
        "title": "Reward Learning as Doubly Nonparametric Bandits: Optimal Design and Scaling Laws",
        "track": "main",
        "status": "Reject",
        "keywords": "reward learning;Gaussian process bandits;nonparametric learning;reproducing kernel Hilbert spaces",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "3;4;4;2",
        "correctness": "4;4;4;4",
        "technical_novelty": "2;2;3;4",
        "empirical_novelty": "1;2;0;4",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.25,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.30151134457776363,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "L2a_bcarHcF",
        "title": "Linear algebra with transformers",
        "track": "main",
        "status": "Reject",
        "keywords": "Mathematics;Transformers;Computation;Numerical;Linear algebra",
        "author": "",
        "aff": "",
        "rating": "5;5;6;8",
        "confidence": "4;4;4;4",
        "correctness": "3;4;4;4",
        "technical_novelty": "2;2;1;4",
        "empirical_novelty": "2;2;3;4",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.4714045207910316,
        "project": "",
        "github": ""
    },
    {
        "id": "L2jrxKBloq8",
        "title": "Second-Order Rewards For Successor Features",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "4;4;3;3",
        "correctness": "3;3;3;4",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "L3_SsSNMmy",
        "title": "On the Connection between Local Attention and Dynamic Depth-wise Convolution",
        "track": "main",
        "status": "Spotlight",
        "keywords": "local attention;depth-wise convolution;dynamic depth-wise convolution;weight sharing;dynamic weight",
        "author": "",
        "aff": "Microsoft Research Asia; TKLNDST, CS, Nankai Univerisy; Peking University; Baidu Inc.",
        "rating": "8;8;8",
        "confidence": "4;5;4",
        "correctness": "3;3;4",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/Atten4Vis/DemystifyLocalViT"
    },
    {
        "id": "L7wzpQttNO",
        "title": "BDDM: Bilateral Denoising Diffusion Models for Fast and High-Quality Speech Synthesis",
        "track": "main",
        "status": "Poster",
        "keywords": "Speech Synthesis;Vocoder;Generative Model;Diffusion Model",
        "author": "",
        "aff": "Tencent AI Lab, Shenzhen, China; Tencent AI Lab, Bellevue WA, USA",
        "rating": "6;6;8",
        "confidence": "4;3;2",
        "correctness": "3;4;3",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "3;3;2",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8660254037844385,
        "corr_rating_correctness": -0.49999999999999983,
        "project": "",
        "github": "https://github.com/tencent-ailab/bddm"
    },
    {
        "id": "LBv-JtAmm4P",
        "title": "Is Heterophily A Real Nightmare For Graph Neural Networks on Performing Node Classification?",
        "track": "main",
        "status": "Reject",
        "keywords": "Graph Neural Networks;Heterophily;Filterbank;Adaptive Channel Mixing",
        "author": "",
        "aff": "Under double-blind review",
        "rating": "3;5;8;8",
        "confidence": "3;3;3;4",
        "correctness": "2;3;4;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;3;3;4",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5443310539518174,
        "corr_rating_correctness": 0.994936676326182,
        "project": "",
        "github": ""
    },
    {
        "id": "LBvk4QWIUpm",
        "title": "Tighter Sparse Approximation Bounds for ReLU Neural Networks",
        "track": "main",
        "status": "Spotlight",
        "keywords": "neural network;two-layer;infinite-width;approximation;sparse;Radon transform;Fourier transform;ReLU",
        "author": "",
        "aff": "",
        "rating": "6;6;6;8",
        "confidence": "4;2;3;3",
        "correctness": "4;4;4;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;0;0;0",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 0.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "LDAwu17QaJz",
        "title": "MAML is a Noisy Contrastive Learner in Classification",
        "track": "main",
        "status": "Poster",
        "keywords": "Meta learning;contrastive learning;few shot learning",
        "author": "",
        "aff": "National Yang Ming Chiao Tung University, Taiwan; IBM Research",
        "rating": "5;5;8",
        "confidence": "4;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": "https://github.com/IandRover/MAML_noisy_contrasive_learner"
    },
    {
        "id": "LGTmlJ10Kes",
        "title": "Curriculum Discovery through an Encompassing Curriculum Learning Framework",
        "track": "main",
        "status": "Reject",
        "keywords": "curriculum learning;natural language processing",
        "author": "",
        "aff": "",
        "rating": "3;5;6",
        "confidence": "4;4;4",
        "correctness": "3;2;3",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;3;2",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.18898223650461363,
        "project": "",
        "github": ""
    },
    {
        "id": "LI2bhrE_2A",
        "title": "Iterative Refinement Graph Neural Network for Antibody Sequence-Structure Co-design",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Drug Discovery;Antibody Design;Generative Models;Graph Generation",
        "author": "",
        "aff": "CSAIL, Massachusetts Institute of Technology; Eric and Wendy Schmidt Center, Broad Institute of MIT and Harvard",
        "rating": "8;8;8",
        "confidence": "3;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "3;4;3",
        "empirical_novelty": "3;4;4",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.3333333333333335,
        "empirical_novelty_avg": 3.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/wengong-jin/RefineGNN"
    },
    {
        "id": "LK8bvVSw6rn",
        "title": "How to measure deep uncertainty estimation performance and which models are naturally better at providing it",
        "track": "main",
        "status": "Reject",
        "keywords": "non-Bayesian uncertainty estimation;selective prediction;transformer;vision transformer;vit;risk-coverage curve;selective classification;classification with a reject option",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6;8",
        "confidence": "4;3;5;3;3",
        "correctness": "2;3;2;4;4",
        "technical_novelty": "2;1;2;3;3",
        "empirical_novelty": "2;3;2;4;4",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.6,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.2,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.22821773229381925,
        "corr_rating_correctness": 0.6123724356957946,
        "project": "",
        "github": ""
    },
    {
        "id": "LLHwQh9zEb",
        "title": "Permutation invariant graph-to-sequence model for template-free retrosynthesis and reaction prediction",
        "track": "main",
        "status": "Reject",
        "keywords": "retrosynthesis;reaction prediction;graph neural network;Transformer;positional embedding",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "4;4;4;4",
        "correctness": "2;4;3;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;0;2;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "LM17I_oVVPB",
        "title": "A Simple Reward-free Approach to Constrained Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "constrained reinforcement learning;reward-free;reinforcement learning theory;approachability;linear function approximation",
        "author": "",
        "aff": "",
        "rating": "5;5;6",
        "confidence": "3;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "3;2;2",
        "empirical_novelty": "1;0;0",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 0.3333333333333333,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "LNmNWds-q-J",
        "title": "3D Pre-training improves GNNs for Molecular Property Prediction",
        "track": "main",
        "status": "Reject",
        "keywords": "graph neural networks;deep learning;self-supervised learning;molecular representation",
        "author": "",
        "aff": "",
        "rating": "3;5;6;8",
        "confidence": "5;4;3;2",
        "correctness": "3;3;4;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;3;3;2",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9922778767136676,
        "corr_rating_correctness": 0.16012815380508713,
        "project": "",
        "github": ""
    },
    {
        "id": "LOz0xDpw4Y",
        "title": "Learning to Efficiently Sample from Diffusion Probabilistic Models",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;6",
        "confidence": "3;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "2;3;2",
        "empirical_novelty": "2;3;4",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.4999999999999999,
        "corr_rating_correctness": 0.4999999999999999,
        "project": "",
        "github": ""
    },
    {
        "id": "LOzFt62SemS",
        "title": "Object-Region Video Transformers",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Vision Transformers;Video Transformers;Video Understanding",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "5;4;5;4",
        "correctness": "2;3;3;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;0;3;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6882472016116854,
        "corr_rating_correctness": 0.9733285267845754,
        "project": "",
        "github": ""
    },
    {
        "id": "LQCUmLgFlR",
        "title": "On Optimal Early Stopping: Overparametrization versus Underparametrization",
        "track": "main",
        "status": "Reject",
        "keywords": "Early stopping;Overparameterization;Implicit regularization;Generalization;Learning theory",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "4;4;3;3",
        "correctness": "3;4;3;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;3;3;0",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8164965809277259,
        "corr_rating_correctness": 0.40824829046386296,
        "project": "",
        "github": ""
    },
    {
        "id": "LQnyIk5dUA",
        "title": "ZeroSARAH: Efficient Nonconvex Finite-Sum Optimization with Zero Full Gradient Computations",
        "track": "main",
        "status": "Reject",
        "keywords": "nonconvex optimization;distributed optimization;finite-sum optimization;zero full gradient computation;variance reduction",
        "author": "",
        "aff": "",
        "rating": "3;5;5;8",
        "confidence": "5;3;4;2",
        "correctness": "2;3;3;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9393364366277244,
        "corr_rating_correctness": 0.9901475429766743,
        "project": "",
        "github": ""
    },
    {
        "id": "LUpE0A3Q-wz",
        "title": "On Convergence of Federated Averaging Langevin Dynamics",
        "track": "main",
        "status": "Reject",
        "keywords": "federated learning;Langevin dynamics;federated averaging;posterior inference;MCMC",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5;6",
        "confidence": "5;4;3;5;3",
        "correctness": "3;3;3;3;4",
        "technical_novelty": "2;2;2;2;3",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.4,
        "confidence_avg": 4.0,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.2,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5590169943749475,
        "corr_rating_correctness": 0.6666666666666666,
        "project": "",
        "github": ""
    },
    {
        "id": "LWXNlPyggUG",
        "title": "Arbitrary-Depth Universal Approximation Theorems for Operator Neural Networks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "operator neural networks;universal approximation theorems;deep learning;truncation",
        "author": "",
        "aff": "",
        "rating": "1;3;3;5;6",
        "confidence": "5;4;5;4;3",
        "correctness": "3;4;2;4;4",
        "technical_novelty": "1;2;1;3;3",
        "empirical_novelty": "1;0;0;0;3",
        "presentation": "",
        "rating_avg": 3.6,
        "confidence_avg": 4.2,
        "correctness_avg": 3.4,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 0.8,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.858395075278952,
        "corr_rating_correctness": 0.5448623679425841,
        "project": "",
        "github": ""
    },
    {
        "id": "LYpBYvxIY_R",
        "title": "Cost-Sensitive Hierarchical Classification through Layer-wise Abstentions",
        "track": "main",
        "status": "Reject",
        "keywords": "cost-sensitive learning;hierarchical classification;learning to abstain",
        "author": "Anqi Liu",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;3;3;5",
        "correctness": "2;3;3;3",
        "technical_novelty": "1;2;2;2",
        "empirical_novelty": "1;2;3;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.20751433915982243,
        "corr_rating_correctness": 0.9271726499455306,
        "project": "",
        "github": ""
    },
    {
        "id": "LZVXOnSrD0Y",
        "title": "Pareto Frontier Approximation Network (PA-Net) Applied to Multi-objective TSP",
        "track": "main",
        "status": "Reject",
        "keywords": "Robotics;planning;TSP;RL;Multi Objective Optimization;Pareto Optimality",
        "author": "",
        "aff": "",
        "rating": "3;3;6;6",
        "confidence": "4;3;4;3",
        "correctness": "2;4;3;3",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "L_sHGieq1D",
        "title": "Adversarial Style Augmentation for Domain Generalized Urban-Scene Segmentation",
        "track": "main",
        "status": "Reject",
        "keywords": "Domain Generalization;Semantic Segmentation;Adversarial Style Augmentation",
        "author": "",
        "aff": "",
        "rating": "5;5;6;8",
        "confidence": "3;5;5;5",
        "correctness": "2;3;3;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.4714045207910316,
        "corr_rating_correctness": 0.8660254037844386,
        "project": "",
        "github": ""
    },
    {
        "id": "LaONfdIp0B",
        "title": "Theoretical understanding of adversarial reinforcement learning via mean-field optimal control",
        "track": "main",
        "status": "Withdraw",
        "keywords": "adversarial reinforcement learning;mean-field optimal control;generalization",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;5;3;4",
        "correctness": "4;3;3;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "3;2;0;0",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7071067811865475,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "LcF-EEt8cCC",
        "title": "Denoising Likelihood Score Matching for Conditional Score-based Data Generation",
        "track": "main",
        "status": "Poster",
        "keywords": "score-based generative model;conditional sampling",
        "author": "",
        "aff": "National Tsing Hua University; Mediatek Inc.",
        "rating": "6;8;8;8",
        "confidence": "3;5;4;4",
        "correctness": "3;4;3;3",
        "technical_novelty": "2;4;4;3",
        "empirical_novelty": "1;3;4;3",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.816496580927726,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "LczpUPwCnR1",
        "title": "ES-Based Jacobian Enables Faster Bilevel Optimization",
        "track": "main",
        "status": "Reject",
        "keywords": "Evolution Strategies;Computational Complexity;Jacobian Matrix;Stochastic Algorithm;Bilevel Optimization",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;4;3",
        "correctness": "4;3;3;2",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;1;2;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": -0.7071067811865475,
        "project": "",
        "github": ""
    },
    {
        "id": "LdEhiMG9WLO",
        "title": "Revisit Kernel Pruning with Lottery Regulated Grouped Convolutions",
        "track": "main",
        "status": "Poster",
        "keywords": "structured pruning;efficient computing;parallel computing;grouped convolution;lottery ticket;weights shifting",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6;6",
        "confidence": "4;4;4;3;4",
        "correctness": "3;3;3;4;3",
        "technical_novelty": "3;4;3;3;3",
        "empirical_novelty": "3;3;3;2;2",
        "presentation": "",
        "rating_avg": 5.4,
        "confidence_avg": 3.8,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 3.2,
        "empirical_novelty_avg": 2.6,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6123724356957945,
        "corr_rating_correctness": 0.6123724356957945,
        "project": "",
        "github": ""
    },
    {
        "id": "LdVQGdXkkG",
        "title": "Modular Action Concept Grounding in Semantic Video Prediction",
        "track": "main",
        "status": "Withdraw",
        "keywords": "action-conditional video prediction;self-supervised learning;counterfactual generation",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "4;4;3;2",
        "correctness": "4;3;2;3",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8703882797784891,
        "corr_rating_correctness": 0.0,
        "project": "https://iclr-mac.github.io/MAC/",
        "github": "https://github.com/iclr-mac/MAC"
    },
    {
        "id": "LdlwbBP2mlq",
        "title": "Minibatch vs Local SGD with Shuffling: Tight Convergence Bounds and Beyond",
        "track": "main",
        "status": "Oral",
        "keywords": "Local SGD;Minibatch SGD;Shuffling;Without-replacement;Convex Optimization;Stochastic Optimization;Federated Learning;Large Scale Learning;Distributed Learning",
        "author": "",
        "aff": "Univ. of Wisconsin-Madison CS; KAIST AI; MIT EECS",
        "rating": "8;8;8",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "3;3;4",
        "empirical_novelty": "0;3;4",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 3.3333333333333335,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "Le8fg2ppDSv",
        "title": "HydraSum - Disentangling Stylistic Features in Text Summarization using Multi-Decoder Models",
        "track": "main",
        "status": "Reject",
        "keywords": "summarization",
        "author": "",
        "aff": "",
        "rating": "6;6;6;6",
        "confidence": "4;4;4;4",
        "correctness": "4;3;4;3",
        "technical_novelty": "3;3;3;2",
        "empirical_novelty": "2;3;3;2",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "LedObtLmCjS",
        "title": "Bi-linear Value Networks for Multi-goal Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "Multi-goal reinforcement learning;universal value function approximator",
        "author": "",
        "aff": "MIT-IBM Watson AI Lab, Massachusetts Institute Technology; Improbable AI Lab, NSF AI Institute for AI and Fundamental Interactions (IAIFI), MIT-IBM Watson AI Lab, Massachusetts Institute Technology",
        "rating": "6;6;6;8",
        "confidence": "3;4;3;4",
        "correctness": "4;3;3;4",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "3;3;2;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "LgjKqSjDzr",
        "title": "SALT : Sharing Attention between Linear layer and Transformer for tabular dataset",
        "track": "main",
        "status": "Reject",
        "keywords": "Tabular data;Attention matrix;Transformer;Deep learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "3;4;4;4",
        "correctness": "3;2;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "LhObGCkxj4",
        "title": "New Perspective on the Global Convergence of Finite-Sum Optimization",
        "track": "main",
        "status": "Reject",
        "keywords": "non-convex optimization;overparameterized;optimization for deep learning;finite-sum;global minimum",
        "author": "",
        "aff": "",
        "rating": "6;6;6;6",
        "confidence": "4;5;4;2",
        "correctness": "3;3;2;4",
        "technical_novelty": "3;2;2;2",
        "empirical_novelty": "0;0;2;0",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 0.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "LhbD74dsZFL",
        "title": "D$^2$ETR: Decoder-Only DETR with Computationally Efficient Cross-Scale Attention",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;5;4;3",
        "correctness": "2;2;4;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3244428422615251,
        "corr_rating_correctness": 0.48420012470625223,
        "project": "",
        "github": ""
    },
    {
        "id": "LjD1FGIza0I",
        "title": "A Novel Watermarking Framework for Ownership Verification of DNN Architectures",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5;6",
        "confidence": "4;2;4;4;3",
        "correctness": "2;3;3;3;4",
        "technical_novelty": "1;2;3;3;3",
        "empirical_novelty": "1;2;3;0;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.4,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 1.8,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.7499999999999999,
        "project": "",
        "github": ""
    },
    {
        "id": "Lkx3Ta9rOSq",
        "title": "A Unified Framework for Multi-distribution Density Ratio Estimation",
        "track": "main",
        "status": "Withdraw",
        "keywords": "multi-distribution density ratio estimation;Bregman divergence;proper scoring rules",
        "author": "",
        "aff": "",
        "rating": "3;3;6;6",
        "confidence": "4;4;3;3",
        "correctness": "3;4;4;2",
        "technical_novelty": "2;2;4;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": -0.3015113445777637,
        "project": "",
        "github": ""
    },
    {
        "id": "Lm8T39vLDTE",
        "title": "Autoregressive Diffusion Models",
        "track": "main",
        "status": "Poster",
        "keywords": "diffusion;autoregressive models;lossless compression",
        "author": "",
        "aff": "Google Research",
        "rating": "5;6;6;8",
        "confidence": "3;3;3;4",
        "correctness": "4;4;4;4",
        "technical_novelty": "2;3;3;4",
        "empirical_novelty": "2;2;4;4",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.25,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9271726499455306,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "Ln5BeHxhVA3",
        "title": "FLBoost: On-the-Fly Fine-tuning Boosts Federated Learning via Data-free Distillation",
        "track": "main",
        "status": "Withdraw",
        "keywords": "federated learning;adversarial learning;on-the-fly fine-tuning",
        "author": "",
        "aff": "",
        "rating": "3;5;5",
        "confidence": "5;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 4.333333333333333,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9999999999999997,
        "corr_rating_correctness": 0.49999999999999983,
        "project": "",
        "github": ""
    },
    {
        "id": "Lr1iAFrtMcZ",
        "title": "Tuning Confidence Bound for Stochastic Bandits with Bandit Distance",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Multi-Armed Bandits;Stochastic Bandits;Upper Confidence Bound;Exploration-Exploitation Trade-off",
        "author": "Xinyu Zhang",
        "aff": "",
        "rating": "1;3;5;5",
        "confidence": "5;3;4;5",
        "correctness": "2;3;3;3",
        "technical_novelty": "1;2;2;3",
        "empirical_novelty": "0;2;2;3",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.0909090909090909,
        "corr_rating_correctness": 0.8703882797784891,
        "project": "",
        "github": ""
    },
    {
        "id": "LsLW5JE7qtV",
        "title": "Learning to Learn across Diverse Data Biases in Deep Face Recognition",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Imbalanced data classification;long-tailed classification;face recognition",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5;8",
        "confidence": "4;3;4;4;4",
        "correctness": "3;3;3;3;4",
        "technical_novelty": "2;3;3;3;3",
        "empirical_novelty": "2;2;2;2;3",
        "presentation": "",
        "rating_avg": 5.2,
        "confidence_avg": 3.8,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.8,
        "empirical_novelty_avg": 2.2,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0625,
        "corr_rating_correctness": 0.875,
        "project": "",
        "github": ""
    },
    {
        "id": "LtI14EpWKH",
        "title": "Tessellated 2D Convolution Networks: A Robust Defence against Adversarial Attacks",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;5;3",
        "correctness": "2;2;4;3",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "1;2;3;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9045340337332909,
        "project": "",
        "github": ""
    },
    {
        "id": "LtKcMgGOeLt",
        "title": "When Vision Transformers Outperform ResNets without Pre-training or Strong Data Augmentations",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Vision Transformers;Optimization",
        "author": "",
        "aff": "Department of Computer Science, UCLA; Google Research",
        "rating": "5;6;8;8;8",
        "confidence": "4;4;5;4;4",
        "correctness": "4;3;3;3;3",
        "technical_novelty": "2;3;3;2;4",
        "empirical_novelty": "3;3;3;4;4",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 4.2,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.8,
        "empirical_novelty_avg": 3.4,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3952847075210474,
        "corr_rating_correctness": -0.7905694150420949,
        "project": "",
        "github": "https://github.com/google-research/vision_transformer"
    },
    {
        "id": "LtXNu_mJdJI",
        "title": "Mutual Information Continuity-constrained Estimator",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "1;3;5;6",
        "confidence": "5;2;4;3",
        "correctness": "1;3;2;4",
        "technical_novelty": "1;2;2;3",
        "empirical_novelty": "1;2;2;4",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 3.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.40755575681770734,
        "corr_rating_correctness": 0.7568892626614565,
        "project": "",
        "github": ""
    },
    {
        "id": "Ltkwl64I91",
        "title": "Invariance-Guided Feature Evolution for Few-Shot Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Few-shot learning;Invariance loss",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;4;4;5",
        "correctness": "3;3;2;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.6622661785325219,
        "corr_rating_correctness": 0.3244428422615251,
        "project": "",
        "github": ""
    },
    {
        "id": "Lv-G9XqLRRy",
        "title": "Restricted Category Removal from Model Representations using Limited Data",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "4;4;4;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "3;2;4;2",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "Lwclw6u3Pcw",
        "title": "Characterizing and Measuring the Similarity of Neural Networks with Persistent Homology",
        "track": "main",
        "status": "Reject",
        "keywords": "Neural Networks;Topological Data Analysis;similarity;Persistent Homology",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;3;4;5",
        "correctness": "2;3;3;1",
        "technical_novelty": "2;3;2;2",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 4.0,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.17407765595569782,
        "project": "",
        "github": ""
    },
    {
        "id": "Lwr8We4MIxn",
        "title": "A Biologically Interpretable Graph Convolutional Network to Link Genetic Risk Pathways and Imaging Phenotypes of Disease",
        "track": "main",
        "status": "Poster",
        "keywords": "Imaging-genetics;Hierarchical Graph Convolution;Gene Ontology;Bayesian Feature Selection;Schizophrenia",
        "author": "",
        "aff": "Lieber Institute for Brain Development, USA; Department of Basic Medical Sciences, University of Bari Aldo Moro, Italy; Department of Electrical and Computer Engineering, Johns Hopkins University, USA",
        "rating": "5;6;6;8",
        "confidence": "5;4;2;4",
        "correctness": "2;2;4;3",
        "technical_novelty": "1;3;3;3",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.15789473684210528,
        "corr_rating_correctness": 0.3458572319330373,
        "project": "",
        "github": ""
    },
    {
        "id": "Ly6_LGwoi_V",
        "title": "Target Layer Regularization for Continual Learning Using Cramer-Wold Generator",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Continual learning;Cramer-Wold distance;regularization",
        "author": "",
        "aff": "",
        "rating": "1;3;3;3",
        "confidence": "3;5;4;4",
        "correctness": "2;3;3;4",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "1;1;1;2",
        "presentation": "",
        "rating_avg": 2.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.816496580927726,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "LzBBxCg-xpa",
        "title": "NViT: Vision Transformer Compression and Parameter Redistribution",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Vision transformer;structual pruning;latency aware;novel architecture",
        "author": "",
        "aff": "",
        "rating": "5;6;6;8",
        "confidence": "4;3;3;3",
        "correctness": "2;4;3;3",
        "technical_novelty": "3;3;3;2",
        "empirical_novelty": "3;3;2;2",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6622661785325219,
        "corr_rating_correctness": 0.3244428422615251,
        "project": "",
        "github": ""
    },
    {
        "id": "LzQQ89U1qm_",
        "title": "Anomaly Transformer: Time Series Anomaly Detection with Association Discrepancy",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Time series anomaly detection;Transformers;Anomaly attention;Association discrepancy",
        "author": "",
        "aff": "",
        "rating": "6;8;8;8",
        "confidence": "4;4;4;5",
        "correctness": "3;3;3;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 4.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "M-9bPO0M2K5",
        "title": "MetaBalance: High-Performance Neural Networks for Class-Imbalanced Data",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "5;5;4;4",
        "correctness": "3;2;3;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;1;3;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 4.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9622504486493761,
        "corr_rating_correctness": 0.5555555555555555,
        "project": "",
        "github": ""
    },
    {
        "id": "M2sNIiCC6C",
        "title": "Self-supervised regression learning using domain knowledge: Applications to improving self-supervised image denoising",
        "track": "main",
        "status": "Reject",
        "keywords": "Self-supervised learning;Regression;Image denoising;Deep learning",
        "author": "",
        "aff": "",
        "rating": "3;6;6",
        "confidence": "5;2;3",
        "correctness": "3;3;4",
        "technical_novelty": "1;3;3",
        "empirical_novelty": "1;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.944911182523068,
        "corr_rating_correctness": 0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "M34fCMVKxn",
        "title": "Unsupervised Image Decomposition with Phase-Correlation Networks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;4;5;2",
        "correctness": "3;4;3;3",
        "technical_novelty": "3;2;3;2",
        "empirical_novelty": "3;1;0;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9271726499455306,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "M5hiCgL7qt",
        "title": "The NTK Adversary: An Approach to Adversarial Attacks without any Model Access",
        "track": "main",
        "status": "Reject",
        "keywords": "Adversarial Attack;Neural Tangent Kernel;Adversarial Examples",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5;5",
        "confidence": "4;3;4;5;4",
        "correctness": "1;3;3;3;3",
        "technical_novelty": "2;2;2;2;3",
        "empirical_novelty": "2;2;2;2;2",
        "presentation": "",
        "rating_avg": 3.8,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6,
        "technical_novelty_avg": 2.2,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.6454972243679028,
        "corr_rating_correctness": 0.40824829046386296,
        "project": "",
        "github": ""
    },
    {
        "id": "M6M8BEmd6dq",
        "title": "PEARL: Data Synthesis via Private Embeddings and Adversarial Reconstruction Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "Differential Privacy;Generative Model",
        "author": "",
        "aff": "LINE Corporation",
        "rating": "6;6;8",
        "confidence": "3;3;4",
        "correctness": "3;3;4",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9999999999999998,
        "corr_rating_correctness": 0.9999999999999998,
        "project": "",
        "github": ""
    },
    {
        "id": "M6jm8fRG5eq",
        "title": "Decentralized Cooperative Multi-Agent Reinforcement Learning with Exploration",
        "track": "main",
        "status": "Reject",
        "keywords": "decentralized control;decentralized learning;game theory;reinforcement learning;reinforcement learning theory",
        "author": "",
        "aff": "",
        "rating": "3;6;6;8",
        "confidence": "4;2;4;2",
        "correctness": "2;3;3;1",
        "technical_novelty": "3;3;3;4",
        "empirical_novelty": "1;3;3;4",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.0,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7001400420140049,
        "corr_rating_correctness": -0.2955402316445243,
        "project": "",
        "github": ""
    },
    {
        "id": "M752z9FKJP",
        "title": "Learning Strides in Convolutional Neural Networks",
        "track": "main",
        "status": "Oral",
        "keywords": "Strides;Convolutional neural networks;Downsampling;Spectral representations;Fourier",
        "author": "",
        "aff": "ENS, INRIA, INSERM, UPEC, PSL Research University; Google Research",
        "rating": "8;8;8;8",
        "confidence": "4;4;3;4",
        "correctness": "3;4;4;4",
        "technical_novelty": "3;4;3;3",
        "empirical_novelty": "3;4;4;3",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "MACKPM_haAu",
        "title": "Adversarial Attack by Limited Point Cloud Surface Modifications",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Adversarial Attack;3D Point Cloud;Step-Size  Scheduling",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "5;4;4;4",
        "correctness": "2;2;3;4",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;1;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.8703882797784891,
        "project": "",
        "github": ""
    },
    {
        "id": "MAYipnUpHHD",
        "title": "Reinforcement Learning for Adaptive Mesh Refinement",
        "track": "main",
        "status": "Reject",
        "keywords": "reinforcement learning;adaptive mesh refinement;finite element method",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5;6",
        "confidence": "3;3;3;4;3",
        "correctness": "4;3;3;1;3",
        "technical_novelty": "2;2;4;3;3",
        "empirical_novelty": "2;3;0;2;3",
        "presentation": "",
        "rating_avg": 5.2,
        "confidence_avg": 3.2,
        "correctness_avg": 2.8,
        "technical_novelty_avg": 2.8,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.25000000000000006,
        "corr_rating_correctness": 0.10206207261596575,
        "project": "",
        "github": ""
    },
    {
        "id": "MDT30TEtaVY",
        "title": "Set Norm and Equivariant Skip Connections: Putting the Deep in Deep Sets",
        "track": "main",
        "status": "Reject",
        "keywords": "deep learning;permutation invariance;normalization;residual connections",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;4;4;4",
        "correctness": "2;2;4;4",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.6882472016116854,
        "project": "",
        "github": ""
    },
    {
        "id": "MEpKGLsY8f",
        "title": "Meta Discovery: Learning to Discover Novel Classes given Very Limited Data",
        "track": "main",
        "status": "Spotlight",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "8;8;8;8",
        "confidence": "3;5;3;4",
        "correctness": "4;4;4;4",
        "technical_novelty": "3;4;3;4",
        "empirical_novelty": "3;4;4;3",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.75,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 3.5,
        "empirical_novelty_avg": 3.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "MGIg_Q4QtW2",
        "title": "RAR: Region-Aware Point Cloud Registration",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3;5",
        "confidence": "2;4;4;4;3",
        "correctness": "3;3;2;2;2",
        "technical_novelty": "2;3;2;3;2",
        "empirical_novelty": "2;1;3;2;2",
        "presentation": "",
        "rating_avg": 3.4,
        "confidence_avg": 3.4,
        "correctness_avg": 2.4,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.25000000000000006,
        "corr_rating_correctness": -0.4082482904638631,
        "project": "",
        "github": ""
    },
    {
        "id": "MIX3fJkl_1",
        "title": "NeuPL: Neural Population Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "Multi-Agent Learning;Game Theory;Population Learning",
        "author": "",
        "aff": "",
        "rating": "8;8;8;8",
        "confidence": "4;4;3;3",
        "correctness": "3;3;3;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "MMAeCXIa89",
        "title": "$\\pi$BO: Augmenting Acquisition Functions with User Beliefs for Bayesian Optimization",
        "track": "main",
        "status": "Poster",
        "keywords": "Bayesian Optimization;Hyperparameter Optimization;Meta-Learning",
        "author": "",
        "aff": "Lund University & Stanford University; Leibniz University Hannover; Federal University of Minas Gerais; Lund University; University of Freiburg; University of Freiburg & Bosch Center for Arti\ufb01cial Intelligence",
        "rating": "6;8;8;8",
        "confidence": "4;5;4;5",
        "correctness": "2;4;4;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 4.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "MOm8xik_TmO",
        "title": "Isotropic Contextual Representations through Variational Regularization",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "4;4;4;3",
        "correctness": "2;2;2;3",
        "technical_novelty": "3;2;2;4",
        "empirical_novelty": "2;1;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.75,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7777777777777777,
        "corr_rating_correctness": 0.7777777777777777,
        "project": "",
        "github": ""
    },
    {
        "id": "MP904TiHqJ-",
        "title": "Provably convergent quasistatic dynamics for mean-field two-player zero-sum games",
        "track": "main",
        "status": "Poster",
        "keywords": "quasistatic;minimax optimization;mixed Nash equilibrium;mean-field formulation",
        "author": "",
        "aff": "Department of Mathematics, Stanford University, Stanford, CA 94305, USA",
        "rating": "6;6;6;6",
        "confidence": "3;5;4;3",
        "correctness": "4;4;4;2",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "MPoQtFC588n",
        "title": "RMNet: Equivalently Removing Residual Connection from Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "Efficient Network;Residual Connection",
        "author": "",
        "aff": "",
        "rating": "3;6;6;8",
        "confidence": "5;5;2;5",
        "correctness": "2;3;3;4",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;3;2;4",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 4.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.08084520834544433,
        "corr_rating_correctness": 0.9901475429766743,
        "project": "",
        "github": ""
    },
    {
        "id": "MQ12ln81Jje",
        "title": "RankedDrop: Enhancing Deep Graph Convolutional Networks Training",
        "track": "main",
        "status": "Withdraw",
        "keywords": "graph neural network;graph convolutional network;PageRank selection;spatial-aware selection;deep learning",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "5;5;5;4",
        "correctness": "3;4;3;3",
        "technical_novelty": "2;1;2;2",
        "empirical_novelty": "2;1;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "MQ2sAGunyBP",
        "title": "R4D: Utilizing Reference Objects for Long-Range Distance Estimation",
        "track": "main",
        "status": "Poster",
        "keywords": "Self-driving;distance estimation;long-range objects",
        "author": "",
        "aff": "Waymo LLC",
        "rating": "5;6;6;8",
        "confidence": "3;3;5;3",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.13245323570650439,
        "corr_rating_correctness": -0.13245323570650439,
        "project": "https://waymo.com/open/download",
        "github": ""
    },
    {
        "id": "MQRDLiWCSh",
        "title": "Towards Scaling Robustness Verification of Semantic Features via Proof Velocity",
        "track": "main",
        "status": "Withdraw",
        "keywords": "neural network robustness;local robustness;semantic features;verification of neural networks",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "5;5;4;4",
        "correctness": "3;2;2;3",
        "technical_novelty": "2;1;2;2",
        "empirical_novelty": "3;1;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "MQuxKr2F1Xw",
        "title": "Multi-Trigger-Key: Towards Multi-Task Privacy-Preserving In Deep Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "2;3;3;4",
        "correctness": "3;3;3;1",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "2;3;2;1",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "MR7XubKUFB",
        "title": "Adversarial Retriever-Ranker for Dense Text Retrieval",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "Microsoft Research Asia; College of Computer Science, Sichuan University; Microsoft Azure AI",
        "rating": "5;6;6;8",
        "confidence": "4;4;4;5",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "0;2;2;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9271726499455306,
        "corr_rating_correctness": 0.9271726499455306,
        "project": "",
        "github": "https://github.com/microsoft/AR2"
    },
    {
        "id": "MRGFutr0p5e",
        "title": "Graph Barlow Twins: A self-supervised representation learning framework for graphs",
        "track": "main",
        "status": "Reject",
        "keywords": "graph representation learning;self-supervised learning",
        "author": "",
        "aff": "",
        "rating": "3;5;6",
        "confidence": "5;5;5",
        "correctness": "4;4;3",
        "technical_novelty": "1;2;3",
        "empirical_novelty": "1;1;3",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 5.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.7559289460184545,
        "project": "",
        "github": ""
    },
    {
        "id": "MSgB8D4Hy51",
        "title": "Post-Training Detection of Backdoor Attacks for Two-Class and Multi-Attack Scenarios",
        "track": "main",
        "status": "Poster",
        "keywords": "backdoor;Trojan;adversarial learning;deep neural network",
        "author": "",
        "aff": "School of EECS, Pennsylvania State University",
        "rating": "5;6;8;8",
        "confidence": "4;2;3;3",
        "correctness": "2;3;4;3",
        "technical_novelty": "2;2;4;3",
        "empirical_novelty": "2;2;4;3",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.2721655269759087,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": "https://github.com/zhenxianglance/2ClassBADetection"
    },
    {
        "id": "MSwEFaztwkE",
        "title": "Learning Weakly-supervised Contrastive Representations",
        "track": "main",
        "status": "Poster",
        "keywords": "Self-supervised Learning;Weakly Supervised Learning;Learning with Auxiliary Information;Clustering-based Representation Learning",
        "author": "",
        "aff": "Carnegie Mellon University",
        "rating": "5;5;6;8",
        "confidence": "4;4;4;3",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9428090415820632,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/Crazy-Jack/Cl-InfoNCE"
    },
    {
        "id": "MTex8qKavoS",
        "title": "MetaShift: A Dataset of Datasets for Evaluating Contextual Distribution Shifts and Training Conflicts",
        "track": "main",
        "status": "Poster",
        "keywords": "benchmark dataset;distribution shift;out-of-domain generalization",
        "author": "",
        "aff": "",
        "rating": "6;6;6",
        "confidence": "3;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "MTsBazXmX00",
        "title": "Target Propagation via Regularized Inversion",
        "track": "main",
        "status": "Reject",
        "keywords": "Target propagation;differentiable programming;recurrent neural networks",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "3;4;3;3",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;3;2;2",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.13245323570650439,
        "corr_rating_correctness": 0.6622661785325219,
        "project": "",
        "github": ""
    },
    {
        "id": "MUpxS9vDbZr",
        "title": "Why Should I Trust You, Bellman? Evaluating the Bellman Objective with Off-Policy Data",
        "track": "main",
        "status": "Reject",
        "keywords": "reinforcement learning;off-policy reinforcement learning;off-policy evaluation;deep reinforcement learning",
        "author": "",
        "aff": "",
        "rating": "3;6;6;8",
        "confidence": "5;4;3;4",
        "correctness": "3;4;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;3;0",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5940885257860046,
        "corr_rating_correctness": 0.8892972917998875,
        "project": "",
        "github": ""
    },
    {
        "id": "MWQCPYSJRN",
        "title": "Generative Negative Replay for Continual Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Continual Learning;Generative replay;Lifelong learning",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "5;4;4;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "3;2;2;3",
        "empirical_novelty": "1;2;3;0",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9271726499455306,
        "corr_rating_correctness": 0.9271726499455306,
        "project": "",
        "github": ""
    },
    {
        "id": "MXEl7i-iru",
        "title": "GraphENS: Neighbor-Aware Ego Network Synthesis for Class-Imbalanced Node Classification",
        "track": "main",
        "status": "Poster",
        "keywords": "Deep learning;Node classification;Class imbalance;Data Augmentation",
        "author": "",
        "aff": "Korea Advanced Institute of Science and Technology (KAIST), AITRICS; Korea Advanced Institute of Science and Technology (KAIST)",
        "rating": "6;6;6;8",
        "confidence": "4;4;4;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;4;3;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "MXdFBmHT4C",
        "title": "Differentiable Expectation-Maximization for Set Representation Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "Representation learning;Bayesian models;Mixture estimation;Optimal transport;Attention",
        "author": "",
        "aff": "Samsung AI Center Cambridge, UK",
        "rating": "6;6;6;8",
        "confidence": "2;4;2;3",
        "correctness": "4;3;3;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;3;2",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 2.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.17407765595569782,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "MXrIVw-F_a4",
        "title": "FLOAT: FAST LEARNABLE ONCE-FOR-ALL ADVERSARIAL TRAINING FOR TUNABLE TRADE-OFF BETWEEN ACCURACY AND ROBUSTNESS",
        "track": "main",
        "status": "Reject",
        "keywords": "Once-for-all adversarial training;in-situ robustness-accuracy trade-off;parameter-efficient in-situ calibration",
        "author": "",
        "aff": "",
        "rating": "3;5;6;8",
        "confidence": "3;4;4;5",
        "correctness": "2;3;3;4",
        "technical_novelty": "1;1;2;3",
        "empirical_novelty": "2;1;4;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9805806756909202,
        "corr_rating_correctness": 0.9805806756909202,
        "project": "",
        "github": ""
    },
    {
        "id": "M_o5E088xO5",
        "title": "PROMISSING: Pruning Missing Values in Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "Neural Networks;Missing Values;Data Imputation",
        "author": "",
        "aff": "",
        "rating": "3;3;6;6;6",
        "confidence": "5;5;5;4;4",
        "correctness": "2;2;3;3;3",
        "technical_novelty": "1;3;4;4;4",
        "empirical_novelty": "1;2;2;3;3",
        "presentation": "",
        "rating_avg": 4.8,
        "confidence_avg": 4.6,
        "correctness_avg": 2.6,
        "technical_novelty_avg": 3.2,
        "empirical_novelty_avg": 2.2,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6666666666666665,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "MbmwYwhD0Vy",
        "title": "A Novel Convergence Analysis for the Stochastic Proximal Point Algorithm",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;4;3",
        "correctness": "1;1;4;3",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "2;2;3;1",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.9622504486493763,
        "project": "",
        "github": ""
    },
    {
        "id": "Mdn3eM7VHFn",
        "title": "Grounding Language Representation with Visual Object Information via Cross Modal Pretraining",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Grounded Language Learning;Language Model",
        "author": "",
        "aff": "",
        "rating": "3;5;5",
        "confidence": "5;4;4",
        "correctness": "3;2;3",
        "technical_novelty": "1;2;2",
        "empirical_novelty": "1;3;2",
        "presentation": "",
        "rating_avg": 4.333333333333333,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 1.6666666666666667,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9999999999999997,
        "corr_rating_correctness": -0.49999999999999983,
        "project": "",
        "github": "https://github.com/... (the link is hidden now due to double-blind review)"
    },
    {
        "id": "MeMMmuWRXsy",
        "title": "Robust Robotic Control from Pixels using Contrastive Recurrent State-Space Models",
        "track": "main",
        "status": "Reject",
        "keywords": "contrastive learning;model-based RL;distractions;predictive coding",
        "author": "",
        "aff": "",
        "rating": "3;5;5",
        "confidence": "5;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "1;2;3",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 4.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8660254037844385,
        "corr_rating_correctness": 0.49999999999999983,
        "project": "",
        "github": ""
    },
    {
        "id": "MeeQkFYVbzW",
        "title": "Adversarial Unlearning of Backdoors via Implicit Hypergradient",
        "track": "main",
        "status": "Poster",
        "keywords": "backdoor defense;backdoor removal;backdoor;minimax;implicit hypergradient",
        "author": "",
        "aff": "",
        "rating": "6;6;6;6",
        "confidence": "3;3;3;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "Mh40mAxxAUz",
        "title": "Bounding Membership Inference",
        "track": "main",
        "status": "Reject",
        "keywords": "differential privacy;membership inference",
        "author": "",
        "aff": "",
        "rating": "3;6;6;8",
        "confidence": "4;3;2;3",
        "correctness": "4;4;3;4",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;2;2;0",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5940885257860046,
        "corr_rating_correctness": -0.08084520834544431,
        "project": "",
        "github": ""
    },
    {
        "id": "Mi9xQBeZxY5",
        "title": "Towards Feature Overcorrelation in Deeper Graph Neural Networks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Graph Neural Networks;Feature Overcorrelation",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5;5",
        "confidence": "4;4;5;4;5",
        "correctness": "3;3;3;3;3",
        "technical_novelty": "2;2;3;2;3",
        "empirical_novelty": "2;0;2;2;3",
        "presentation": "",
        "rating_avg": 4.6,
        "confidence_avg": 4.4,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 1.8,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.4082482904638632,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "MjbdO3_ihp",
        "title": "Iterative Bilinear Temporal-Spectral Fusion for Unsupervised Representation Learning in Time Series",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Time Series;Unsupervised Learning;Representation Learning",
        "author": "",
        "aff": "",
        "rating": "6;6;6;6;8",
        "confidence": "4;4;4;4;5",
        "correctness": "4;3;3;3;3",
        "technical_novelty": "3;3;2;2;3",
        "empirical_novelty": "3;0;2;3;3",
        "presentation": "",
        "rating_avg": 6.4,
        "confidence_avg": 4.2,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 2.2,
        "presentation_avg": 0,
        "corr_rating_confidence": 1.0,
        "corr_rating_correctness": -0.2500000000000001,
        "project": "",
        "github": ""
    },
    {
        "id": "MkTPtnjeYTV",
        "title": "On the Optimal Memorization Power of ReLU Neural Networks",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Expressivness;Memorization;Theory;VC-dimension;Deep learning theory",
        "author": "",
        "aff": "Department of Computer Science, Weizmann Institute of Science",
        "rating": "8;8;8",
        "confidence": "4;5;5",
        "correctness": "4;4;3",
        "technical_novelty": "4;3;4",
        "empirical_novelty": "3;0;0",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 3.6666666666666665,
        "empirical_novelty_avg": 1.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "MljXVdp4A3N",
        "title": "Know Your Action Set: Learning Action Relations for Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "reinforcement learning;varying action space;relational reasoning",
        "author": "",
        "aff": "Korea Advanced Institute of Science and Technology (KAIST); NAVER CLOVA; University of Southern California (USC)",
        "rating": "6;8;8;8",
        "confidence": "3;5;4;3",
        "correctness": "3;3;3;4",
        "technical_novelty": "3;3;3;2",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5222329678670935,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "https://sites.google.com/view/varyingaction",
        "github": "https://github.com/clvrai/agile"
    },
    {
        "id": "Mlwe37htstv",
        "title": "Efficient Wasserstein and Sinkhorn Policy Optimization",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;6;6;6",
        "confidence": "4;4;3;3",
        "correctness": "3;4;3;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "MmC5WTB-z7",
        "title": "A HYPOTHESIS FOR THE COGNITIVE DIFFICULTY OF IMAGES",
        "track": "main",
        "status": "Withdraw",
        "keywords": "cognitive difficulty;multi-variate interaction",
        "author": "",
        "aff": "",
        "rating": "1;1;3",
        "confidence": "4;5;4",
        "correctness": "1;1;3",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "1;1;2",
        "presentation": "",
        "rating_avg": 1.6666666666666667,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 1.6666666666666667,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.3333333333333333,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4999999999999999,
        "corr_rating_correctness": 0.9999999999999998,
        "project": "",
        "github": ""
    },
    {
        "id": "MmXeLCOXL4R",
        "title": "Convolutional Networks on Enhanced Message-Passing Graph Improve Semi-Supervised Classification with Few Labels",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Shallow Graph Networks;Multi-Channel Message Aggregation;Data Augmentation;Over-Smoothing;Overfitting",
        "author": "",
        "aff": "",
        "rating": "3;3;5",
        "confidence": "5;4;3",
        "correctness": "2;2;3",
        "technical_novelty": "1;1;2",
        "empirical_novelty": "1;2;2",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 4.0,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 1.3333333333333333,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8660254037844387,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "MmujBClawFo",
        "title": "Attention: Self-Expression Is All You Need",
        "track": "main",
        "status": "Reject",
        "keywords": "Self-attention;sparse representation;subspace clustering",
        "author": "",
        "aff": "",
        "rating": "5;5;5",
        "confidence": "4;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;0;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "Mng8CQ9eBW",
        "title": "BadPre: Task-agnostic Backdoor Attacks to Pre-trained NLP Foundation Models",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "Chongqing University; Computer Center of Peking University & Peng Cheng Laboratory; Shannon.AI & Zhejiang University; Shannon.AI; Nanyang Technological University",
        "rating": "3;5;8;8",
        "confidence": "5;3;4;4",
        "correctness": "2;3;4;3",
        "technical_novelty": "1;3;1;3",
        "empirical_novelty": "2;3;3;4",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.8333333333333334,
        "project": "",
        "github": ""
    },
    {
        "id": "Mo9R9oqzPo",
        "title": "New Definitions and Evaluations for Saliency Methods: Staying Intrinsic and Sound",
        "track": "main",
        "status": "Reject",
        "keywords": "saliency;masking based methods",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "3;4;2;3",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9271726499455306,
        "project": "",
        "github": ""
    },
    {
        "id": "MpJjrfSJ-Xs",
        "title": "Cross-Domain Cross-Set Few-Shot Learning via Learning Compact and Aligned Representations",
        "track": "main",
        "status": "Withdraw",
        "keywords": "few-shot learning;representation learning;domain alignment",
        "author": "",
        "aff": "",
        "rating": "3;3;5",
        "confidence": "4;5;4",
        "correctness": "3;2;3",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;0;2",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.3333333333333333,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4999999999999999,
        "corr_rating_correctness": 0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "MqEcDNQwOSA",
        "title": "Reconstructing Word Embeddings via Scattered $k$-Sub-Embedding",
        "track": "main",
        "status": "Reject",
        "keywords": "word embedding;natural language understanding;weight sharing;contextual embedding",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "4;5;5;4",
        "correctness": "2;2;2;3",
        "technical_novelty": "2;1;2;2",
        "empirical_novelty": "2;1;2;1",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.5,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "MsHnJPaBUZE",
        "title": "iFlood: A Stable and Effective Regularizer",
        "track": "main",
        "status": "Poster",
        "keywords": "overfitting;regularizer",
        "author": "",
        "aff": "Alibaba Group; ETH Z\u00fcrich",
        "rating": "6;6;6;6",
        "confidence": "4;4;4;4",
        "correctness": "3;4;3;3",
        "technical_novelty": "3;4;4;3",
        "empirical_novelty": "2;3;3;2",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "Mspk_WYKoEH",
        "title": "From Stars to Subgraphs: Uplifting Any GNN with Local Structure Awareness",
        "track": "main",
        "status": "Poster",
        "keywords": "Graph Neural Networks;Expressiveness;Message Passing Neural Network;Graph Classification",
        "author": "",
        "aff": "Carnegie Mellon Uni.; Michigan State Uni.; Snap Inc.",
        "rating": "6;6;6;8",
        "confidence": "4;5;5;4",
        "correctness": "1;3;3;4",
        "technical_novelty": "3;3;2;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 4.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.6622661785325219,
        "project": "",
        "github": ""
    },
    {
        "id": "Muwg-ncP_ec",
        "title": "Exact Stochastic Newton Method for Deep Learning: the feedforward networks case.",
        "track": "main",
        "status": "Reject",
        "keywords": "Deep Learning;Second-order Optimization;Newton Method;Sifrian;Hessian;Exact Stochastic Newton;Saddle-Free Newton;Non-Convex Optimization",
        "author": "",
        "aff": "",
        "rating": "3;3;3;6",
        "confidence": "4;3;4;2",
        "correctness": "2;2;3;4",
        "technical_novelty": "1;2;1;2",
        "empirical_novelty": "2;2;1;2",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 3.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 1.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8703882797784892,
        "corr_rating_correctness": 0.8703882797784892,
        "project": "",
        "github": ""
    },
    {
        "id": "MvO2t0vbs4-",
        "title": "Wisdom of Committees: An Overlooked Approach To Faster and More Accurate Models",
        "track": "main",
        "status": "Poster",
        "keywords": "Ensemble;Cascade;Efficiency",
        "author": "",
        "aff": "Google Research, Carnegie Mellon University; Carnegie Mellon University; Google Research",
        "rating": "6;6;6",
        "confidence": "3;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "2;3;2",
        "empirical_novelty": "3;3;2",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "Mvf5zr2qs6",
        "title": "Bias Decay Matters : Improving Large Batch Optimization with Connectivity Sharpness",
        "track": "main",
        "status": "Withdraw",
        "keywords": "large batch optimization;sharpness/flatness",
        "author": "",
        "aff": "",
        "rating": "3;3;3;6",
        "confidence": "4;3;4;3",
        "correctness": "2;3;2;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.8703882797784892,
        "project": "",
        "github": ""
    },
    {
        "id": "MvtLspSX324",
        "title": "Go with the Flow: the distribution of information processing in multi-path networks",
        "track": "main",
        "status": "Reject",
        "keywords": "Deep Learning;Multi-path Networks;Similarity of Representations;Regression Probe;Centered Kernel Alignment",
        "author": "",
        "aff": "",
        "rating": "3;3;5",
        "confidence": "5;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "1;2;2",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 1.6666666666666667,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5000000000000001,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "N0n_QyQ5lBF",
        "title": "Unsupervised Vision-Language Grammar Induction with Shared Structure Modeling",
        "track": "main",
        "status": "Oral",
        "keywords": "Grammar Induction;Vision-Language Matching;Unsupervised Learning",
        "author": "",
        "aff": "Department of Electrical Engineering, KU Leuven; Beijing Institute for General Arti\ufb01cial Intelligence, Beijing, China",
        "rating": "8;8;8",
        "confidence": "3;3;5",
        "correctness": "3;3;3",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/bobwan1995/cliora.git"
    },
    {
        "id": "N0uJGWDw21d",
        "title": "Bag of Instances Aggregation Boosts Self-supervised Distillation",
        "track": "main",
        "status": "Poster",
        "keywords": "Self-supervised learning;knowledge distillation;instance bagging",
        "author": "",
        "aff": "School of EIC, Huazhong University of Science & Technology; Huawei Inc.; Institute of Arti\ufb01cial Intelligence, Huazhong University of Science & Technology, Huawei Inc.; Shanghai Jiao Tong University; Shanghai Jiao Tong University, Huawei Inc.",
        "rating": "6;6;6;8",
        "confidence": "5;4;5;3",
        "correctness": "3;4;4;4",
        "technical_novelty": "4;3;3;3",
        "empirical_novelty": "3;3;2;4",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 4.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8703882797784891,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": "https://github.com/haohang96/bingo"
    },
    {
        "id": "N1WI0vJLER",
        "title": "Parallel Training of GRU Networks with a Multi-Grid Solver for Long Sequences",
        "track": "main",
        "status": "Poster",
        "keywords": "GRU;MGRIT;parallel-in-time;distributed machine learning",
        "author": "",
        "aff": "Korea Aerospace University; Sandia National Laboratories",
        "rating": "6;6;6;8",
        "confidence": "4;4;3;2",
        "correctness": "4;4;3;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "0;2;3;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8703882797784891,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "N2nJzgb_ldR",
        "title": "FastRPB: a Scalable Relative Positional Encoding for Long Sequence Tasks",
        "track": "main",
        "status": "Reject",
        "keywords": "transformer;linear transformer;long sequences;fast Fourier transform;positional encoding;long range arena",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;2;4;3",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;3;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5222329678670935,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "N3KYKkSvciP",
        "title": "Understanding Square Loss in Training Overparametrized Neural Network Classifiers",
        "track": "main",
        "status": "Reject",
        "keywords": "classification;square loss;neural tangent kernel;convergence rate",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6;6",
        "confidence": "3;2;4;4;3",
        "correctness": "2;3;3;4;3",
        "technical_novelty": "1;3;3;3;3",
        "empirical_novelty": "0;2;3;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.2,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 2.2,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.24397501823713333,
        "corr_rating_correctness": 0.8660254037844387,
        "project": "",
        "github": ""
    },
    {
        "id": "N3fJsZ7ghc",
        "title": "Deep Encryption: Protecting Pre-Trained Neural Networks with Confusion Neurons",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Encryption;Confusion Neurons",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;5;3;4",
        "correctness": "2;2;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;1;3;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7071067811865475,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "N4KRX61-_1d",
        "title": "A Hierarchical Bayesian Approach to Inverse Reinforcement Learning with Symbolic Reward Machines",
        "track": "main",
        "status": "Reject",
        "keywords": "Reward Machines;Finite State Automata;Finite State Transducers;Inverse Reinforcement Learning;Reinforcement Learning",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "4;2;4;3",
        "correctness": "2;3;3;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.30151134457776363,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "N7WQ5SLlPrJ",
        "title": "Measure Twice, Cut Once: Quantifying Bias and Fairness in Deep Neural Networks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Interpretable AI;AI Fairness;Pruning;Compression;Knowledge Distillation;Image Recognition",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;4;4",
        "correctness": "3;2;3;3",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "N8MaByOzUfb",
        "title": "New Insights on Reducing Abrupt Representation Change in Online Continual Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "continual learning",
        "author": "",
        "aff": "McGill University, Mila, Facebook AI Research; KU Leuven; Toyota Motor Europe; Concordia University, Mila",
        "rating": "3;5;6;8",
        "confidence": "5;2;4;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "2;2;2;4",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.19088542889273336,
        "corr_rating_correctness": 0.8006407690254357,
        "project": "",
        "github": "www.github.com/pclucas14/AML"
    },
    {
        "id": "N9W24a4zU",
        "title": "Steerable Partial Differential Operators for Equivariant Neural Networks",
        "track": "main",
        "status": "Poster",
        "keywords": "partial differential operators;equivariance;deep learning;steerability",
        "author": "",
        "aff": "University of Amsterdam",
        "rating": "6;6;8",
        "confidence": "3;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "3;3;4",
        "empirical_novelty": "3;2;3",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 3.3333333333333335,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "NB0czpQ3-m",
        "title": "RoMA: a Method for Neural Network Robustness Measurement and Assessment",
        "track": "main",
        "status": "Reject",
        "keywords": "Neuran Network;Robustness;Safety Critical Software;Categorial Robustness",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;5;2;4",
        "correctness": "2;2;3;3",
        "technical_novelty": "2;1;3;2",
        "empirical_novelty": "0;1;3;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.75,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.13245323570650439,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "NCwIM2Q8ah6",
        "title": "MDFL: A UNIFIED FRAMEWORK WITH META-DROPOUT FOR FEW-SHOT LEARNING",
        "track": "main",
        "status": "Reject",
        "keywords": "Few-shot learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "3;4;4;3",
        "correctness": "1;2;3;3",
        "technical_novelty": "1;1;2;3",
        "empirical_novelty": "1;1;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9045340337332909,
        "project": "",
        "github": ""
    },
    {
        "id": "NE8B5RQkau",
        "title": "Self-Distilled Pruning Of Neural Networks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "pruning;knowledge distillation;compression;transformers;neural networks;language models",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6;6",
        "confidence": "4;4;3;4;3",
        "correctness": "2;3;3;3;1",
        "technical_novelty": "2;2;3;2;2",
        "empirical_novelty": "2;2;3;3;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6,
        "correctness_avg": 2.4,
        "technical_novelty_avg": 2.2,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.372677996249965,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "NH29920YEmj",
        "title": "Who Is Your Right Mixup Partner in Positive and Unlabeled Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "Positive and Unlabeled Learning;Mixup;Heuristic",
        "author": "",
        "aff": "College of Computer Science, Chongqing University, China; College of Computer Science and Technology, Jilin University, China",
        "rating": "6;6;8;8",
        "confidence": "4;4;4;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "NHHM1jjrH1",
        "title": "An Optimization Perspective on Realizing Backdoor Injection Attacks on Deep Neural Networks in Hardware",
        "track": "main",
        "status": "Reject",
        "keywords": "targeted attack;bit-flip;weight attack;backdoor;trojan",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5",
        "confidence": "3;4;5;3",
        "correctness": "4;2;4;3",
        "technical_novelty": "3;3;3;2",
        "empirical_novelty": "3;3;2;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "NJTRDt9TPb",
        "title": "Diverse Imitation Learning via Self-OrganizingGenerative Models",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;6;6",
        "confidence": "4;3;3",
        "correctness": "2;3;3",
        "technical_novelty": "1;2;2",
        "empirical_novelty": "3;2;4",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 1.6666666666666667,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "NK5hHymegzo",
        "title": "On the One-sided Convergence of Adam-type Algorithms in Non-convex Non-concave Min-max Optimization",
        "track": "main",
        "status": "Reject",
        "keywords": "Optimization;GAN;Convergence",
        "author": "",
        "aff": "Paper under double-blind review",
        "rating": "3;5;5;6",
        "confidence": "5;4;4;3",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;2;4",
        "empirical_novelty": "2;2;2;4",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9733285267845754,
        "corr_rating_correctness": 0.9271726499455306,
        "project": "",
        "github": ""
    },
    {
        "id": "NMEceG4v69Y",
        "title": "CycleMLP: A MLP-like Architecture for Dense Prediction",
        "track": "main",
        "status": "Oral",
        "keywords": "MLP;Dense Prediction",
        "author": "",
        "aff": "The University of Hong Kong; The University of Hong Kong, Shanghai AI Laboratory, Shanghai, China; SenseTime Research",
        "rating": "6;8;8;8",
        "confidence": "4;3;3;4",
        "correctness": "3;4;3;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": "https://github.com/ShoufaChen/CycleMLP"
    },
    {
        "id": "NMSugaVzIT",
        "title": "Inductive Bias of Multi-Channel Linear Convolutional Networks with Bounded Weight Norm",
        "track": "main",
        "status": "Desk Reject",
        "keywords": "minimizing parameter l2 norm;representation cost;implicit bias",
        "author": "",
        "aff": "",
        "rating": "",
        "confidence": "",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "NOApNZTiTNU",
        "title": "Aggressive Q-Learning with Ensembles: Achieving Both High Sample Efficiency and High Asymptotic Performance",
        "track": "main",
        "status": "Reject",
        "keywords": "deep reinforcement learning;off-policy;model-free;sample efficiency;ensembles",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5;6",
        "confidence": "4;4;4;4;4",
        "correctness": "3;3;4;3;3",
        "technical_novelty": "3;2;2;3;2",
        "empirical_novelty": "2;2;3;2;2",
        "presentation": "",
        "rating_avg": 4.4,
        "confidence_avg": 4.0,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 2.2,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.25000000000000006,
        "project": "",
        "github": ""
    },
    {
        "id": "NP9T_pViXU",
        "title": "VIMPAC: Video Pre-Training via Masked Token Prediction and Contrastive Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "video;self-supervised learning;representation learning;pre-training;action recognition",
        "author": "",
        "aff": "",
        "rating": "5;5;5",
        "confidence": "4;4;5",
        "correctness": "3;3;3",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "NPJ5zWk_IQj",
        "title": "Translating Robot Skills: Learning Unsupervised Skill Correspondences Across Robots",
        "track": "main",
        "status": "Reject",
        "keywords": "Robot Skills;Unsupervised Correspondences;Unsupervised Learning;Alignment;Density Matching;Skill Learning;Robot Learning;Transfer Learning;Skill Transfer",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "4;3;4;3",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.40824829046386296,
        "corr_rating_correctness": 0.9428090415820632,
        "project": "https://sites.google.com/view/translatingrobotskills/home",
        "github": ""
    },
    {
        "id": "NQrx8EYMboO",
        "title": "Task-Agnostic Graph Neural Explanations",
        "track": "main",
        "status": "Reject",
        "keywords": "Explainability;interpretability;graph neural networks;self-supervised learning",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "5;5;3;3",
        "correctness": "4;3;4;3",
        "technical_novelty": "3;3;3;2",
        "empirical_novelty": "3;2;3;2",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "NRAZXJ9q3z",
        "title": "CDPS: Constrained DTW-Preserving Shapelets",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Shapelets;Representational Learning;Clustering;Constrained Clustering;Constrained Learning",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "4;5;5;4",
        "correctness": "2;2;2;2",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.5,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "Not provided",
        "github": "Not provided"
    },
    {
        "id": "NRX9QZ6yqt",
        "title": "Memory Augmented Optimizers for Deep Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "Optimization for Deep learning;Memory augmented Optimizers",
        "author": "",
        "aff": "Mila - Quebec AI Institute, Canada; McGill University, Canada; \u00c9cole Polytechnique de Montr\u00e9al, Canada",
        "rating": "5;6;6;8",
        "confidence": "4;4;3;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "3;4;3;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.13245323570650439,
        "corr_rating_correctness": 0.6882472016116854,
        "project": "",
        "github": ""
    },
    {
        "id": "NUzrPpDjWp",
        "title": "Large-Scale Adversarial Attacks on Graph Neural Networks via Graph Coarsening",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Graph Neural Network;Adversarial Attacks;Graph Coarsening",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;5;4;4",
        "correctness": "2;2;3;3",
        "technical_novelty": "3;1;2;3",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "NX0nX7TE4lc",
        "title": "DIVERSIFY to Generalize: Learning Generalized Representations for Time Series Classification",
        "track": "main",
        "status": "Reject",
        "keywords": "Time series classification;domain generalization",
        "author": "",
        "aff": "",
        "rating": "6;6;8",
        "confidence": "4;3;4",
        "correctness": "2;3;4",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "2;3;0",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.49999999999999983,
        "corr_rating_correctness": 0.8660254037844385,
        "project": "",
        "github": ""
    },
    {
        "id": "NYBmJN4MyZ",
        "title": "Safe Neurosymbolic Learning with Differentiable Symbolic Execution",
        "track": "main",
        "status": "Poster",
        "keywords": "Verified Learning;Neurosymbolic Programs;Safe Learning;Symbolic Execution",
        "author": "",
        "aff": "The University of Texas at Austin",
        "rating": "6;6;8",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "4;3;4",
        "empirical_novelty": "3;2;0",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.6666666666666665,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/cxyang1997/DSE"
    },
    {
        "id": "NZQ8aTScT1-",
        "title": "Eigenspace Restructuring: a Principle of Space and Frequency in Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "neural network gaussian process;neural tangent kernels;eigenstructure;space and frequency;convolutional networks;spherical harmonics;hierarchical locality;over-parameterized networks",
        "author": "",
        "aff": "Under double-blind review",
        "rating": "3;5;5;5",
        "confidence": "3;3;2;3",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "3;3;2;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 2.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "NblYkw2U2Yg",
        "title": "A Generalised Inverse Reinforcement Learning Framework",
        "track": "main",
        "status": "Reject",
        "keywords": "IRL",
        "author": "",
        "aff": "",
        "rating": "5;5;6",
        "confidence": "3;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4999999999999999,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "Nct9j3BVswZ",
        "title": "Self-Supervise, Refine, Repeat: Improving Unsupervised Anomaly Detection",
        "track": "main",
        "status": "Reject",
        "keywords": "Anomaly detection;Data refinement;Iterative training",
        "author": "",
        "aff": "",
        "rating": "5;6;6;6",
        "confidence": "4;5;5;5",
        "correctness": "3;4;4;3",
        "technical_novelty": "3;3;3;2",
        "empirical_novelty": "3;3;2;4",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 4.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 1.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "NdOoQnYPj_",
        "title": "BAM: Bayes with Adaptive Memory",
        "track": "main",
        "status": "Poster",
        "keywords": "Bayesian learning;online learning",
        "author": "",
        "aff": "Department of Electrical and Computer Engineering, Stony Brook University; Department of Computer Science, New York University; Department of Computer Science, University of Washington",
        "rating": "5;6;8;8",
        "confidence": "4;4;3;3",
        "correctness": "3;4;4;4",
        "technical_novelty": "3;2;4;4",
        "empirical_novelty": "2;2;4;0",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9622504486493761,
        "corr_rating_correctness": 0.7777777777777777,
        "project": "",
        "github": ""
    },
    {
        "id": "Ndffz5uo6H",
        "title": "Updater-Extractor Architecture for Inductive World State Representations",
        "track": "main",
        "status": "Withdraw",
        "keywords": "transformers;long-term-memory;sequential processing;lifelong learning",
        "author": "",
        "aff": "",
        "rating": "1;3;3",
        "confidence": "4;4;3",
        "correctness": "4;3;3",
        "technical_novelty": "1;2;2",
        "empirical_novelty": "1;2;2",
        "presentation": "",
        "rating_avg": 2.3333333333333335,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 1.6666666666666667,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5,
        "corr_rating_correctness": -1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "NeRrtif_hfa",
        "title": "Better state exploration using action sequence equivalence",
        "track": "main",
        "status": "Reject",
        "keywords": "Reinforcement learning;priors;structure;exploration",
        "author": "",
        "aff": "",
        "rating": "5;5;8",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "2;3;4",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "Nfl-iXa-y7R",
        "title": "Pixelated Butterfly: Simple and Efficient Sparse training for Neural Network Models",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Sparse training;butterfly;low-rank;Lottery Tickets;Block sparsity;Hashing;Transformer;ViT;MLP-Mixer",
        "author": "",
        "aff": "",
        "rating": "6;8;8;8",
        "confidence": "3;4;4;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "3;3;4;3",
        "empirical_novelty": "3;3;0;3",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "Ng8wWGXXIXh",
        "title": "On Invariance Penalties for Risk Minimization",
        "track": "main",
        "status": "Reject",
        "keywords": "domain generalization;out-of-distribution generalization;invariant risk minimization;invariant representation learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "5;4;3;4",
        "correctness": "4;3;4;3",
        "technical_novelty": "2;1;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5443310539518174,
        "corr_rating_correctness": -0.19245008972987526,
        "project": "",
        "github": ""
    },
    {
        "id": "NgmcJ66xQz_",
        "title": "Divide and Explore: Multi-Agent Separate Exploration with Shared Intrinsic Motivations",
        "track": "main",
        "status": "Reject",
        "keywords": "Deep Reinforcement Learning;Exploration;Intrinsic Motivation;Distributed Learning",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;5;4;4",
        "correctness": "2;4;3;3",
        "technical_novelty": "1;2;3;1",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 4.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "Nh7CtbyoqV5",
        "title": "Normalization of Language Embeddings for Cross-Lingual Alignment",
        "track": "main",
        "status": "Poster",
        "keywords": "cross-lingual word embeddings;natural language processing",
        "author": "",
        "aff": "University of Utah; Visa Research",
        "rating": "3;5;6;8;8",
        "confidence": "4;4;4;4;4",
        "correctness": "3;2;4;4;4",
        "technical_novelty": "2;2;3;3;3",
        "empirical_novelty": "2;3;2;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.4,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 2.6,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.6588078458684125,
        "project": "",
        "github": ""
    },
    {
        "id": "NkZq4OEYN-",
        "title": "Sound Adversarial Audio-Visual Navigation",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "Beijing National Research Center for Information Science and Technology (BNRist), State Key Lab on Intelligent Technology and Systems, Department of Computer Science and Technology, Tsinghua University; JD Explore Academy, JD.com; Institute for AI Industry Research (AIR), Tsinghua University; UT Austin",
        "rating": "6;8;8",
        "confidence": "3;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "3;4;3",
        "presentation": "",
        "rating_avg": 7.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9999999999999998,
        "corr_rating_correctness": -0.49999999999999983,
        "project": "https://yyf17.github.io/SAAVN",
        "github": ""
    },
    {
        "id": "NlObxR0rosG",
        "title": "Practical Integration via Separable Bijective Networks",
        "track": "main",
        "status": "Poster",
        "keywords": "integration;flow;likelihood;classification;regression;out of distribution;regularization",
        "author": "",
        "aff": "The Johns Hopkins University Applied Physics Laboratory; Department of Computer Science, Duke University; Department of Computer Science, The University of North Carolina",
        "rating": "1;6;6;8",
        "confidence": "3;4;4;2",
        "correctness": "3;3;4;3",
        "technical_novelty": "1;3;3;3",
        "empirical_novelty": "1;3;3;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.14574100933227221,
        "corr_rating_correctness": 0.16744367165578428,
        "project": "",
        "github": ""
    },
    {
        "id": "Nn4BjABPRPN",
        "title": "Encoding Event-Based Gesture Data With a Hybrid SNN Guided Variational Auto-encoder",
        "track": "main",
        "status": "Reject",
        "keywords": "Neuromorphic Computing;Variational Auto-encoders;Representation Learning;Spiking Neural Networks;Self-supervised Learning",
        "author": "",
        "aff": "",
        "rating": "1;3;3;6",
        "confidence": "4;3;3;4",
        "correctness": "1;2;3;3",
        "technical_novelty": "2;3;2;2",
        "empirical_novelty": "1;2;3;3",
        "presentation": "",
        "rating_avg": 3.25,
        "confidence_avg": 3.5,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.14002800840280097,
        "corr_rating_correctness": 0.8021806287494232,
        "project": "",
        "github": ""
    },
    {
        "id": "NoB8YgRuoFU",
        "title": "PI3NN: Out-of-distribution-aware Prediction Intervals from Three Neural Networks",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "Computer Science and Mathematics Division, Oak Ridge National Laboratory; Computational Sciences and Engineering Division, Oak Ridge National Laboratory",
        "rating": "5;5;6;6",
        "confidence": "3;3;4;4",
        "correctness": "4;3;3;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 1.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "NoE4RfaOOa",
        "title": "Where can quantum kernel methods make a big difference?",
        "track": "main",
        "status": "Reject",
        "keywords": "Kernel;Quantum;Classification",
        "author": "",
        "aff": "",
        "rating": "1;1;3;5",
        "confidence": "4;5;2;4",
        "correctness": "1;1;2;2",
        "technical_novelty": "1;1;2;3",
        "empirical_novelty": "2;2;4;3",
        "presentation": "",
        "rating_avg": 2.5,
        "confidence_avg": 3.75,
        "correctness_avg": 1.5,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3458572319330373,
        "corr_rating_correctness": 0.9045340337332909,
        "project": "",
        "github": ""
    },
    {
        "id": "NoxVNArZTeW",
        "title": "Adversarial Fairness Network",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Fairness;Machine Learning",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;4;4;5",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 4.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "NqDLrS73nG",
        "title": "Transliteration: A Simple Technique For Improving Multilingual Language Modeling",
        "track": "main",
        "status": "Reject",
        "keywords": "Multilingual Language Model;Natural Language Processing;Transliteration;Underrepresented Language Modeling",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5;6",
        "confidence": "5;3;4;4;4",
        "correctness": "3;2;3;3;3",
        "technical_novelty": "2;1;1;2;2",
        "empirical_novelty": "2;2;2;2;3",
        "presentation": "",
        "rating_avg": 4.4,
        "confidence_avg": 4.0,
        "correctness_avg": 2.8,
        "technical_novelty_avg": 1.6,
        "empirical_novelty_avg": 2.2,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5833333333333335,
        "project": "",
        "github": ""
    },
    {
        "id": "NrB52z3eOTY",
        "title": "Effective Uncertainty Estimation with Evidential Models for Open-World Recognition",
        "track": "main",
        "status": "Reject",
        "keywords": "deep learning;uncertainty estimation;evidential models;misclassification detection;out-of-distribution detection;confidence learning",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "3;4;5;3",
        "correctness": "1;2;3;3",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "1;3;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.75,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.20751433915982243,
        "corr_rating_correctness": 0.899228803025897,
        "project": "",
        "github": ""
    },
    {
        "id": "NrkAAcMpRoT",
        "title": "C-MinHash: Improving Minwise Hashing with Circulant Permutation",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;6;8",
        "confidence": "4;4;4;3",
        "correctness": "4;4;3;4",
        "technical_novelty": "3;3;3;4",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9428090415820632,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "NsyO8nGpaGG",
        "title": "Comparing Human and Machine Bias in Face Recognition",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5",
        "confidence": "3;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "1;2;2",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 4.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 1.6666666666666667,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9999999999999998,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "NudBMY-tzDr",
        "title": "Natural Language Descriptions of Deep Visual Features",
        "track": "main",
        "status": "Oral",
        "keywords": "",
        "author": "",
        "aff": "MIT CSAIL; Northeastern University; Allegheny College",
        "rating": "8;8;8",
        "confidence": "4;4;3",
        "correctness": "3;4;4",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "3;4;3",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "http://milan.csail.mit.edu/",
        "github": ""
    },
    {
        "id": "Nus6fOfh1HW",
        "title": "On the Relationship between Heterophily and Robustness of Graph Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "graph neural networks;adversarial attacks;heterophily;structural perturbation;robustness;relation",
        "author": "",
        "aff": "",
        "rating": "5;5;6;8",
        "confidence": "4;3;4;4",
        "correctness": "4;2;3;4",
        "technical_novelty": "2;3;2;2",
        "empirical_novelty": "2;2;3;4",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.4714045207910316,
        "corr_rating_correctness": 0.4923659639173309,
        "project": "",
        "github": ""
    },
    {
        "id": "NuzF7PHTKRw",
        "title": "EAT-C: Environment-Adversarial sub-Task Curriculum for Efficient Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "reinforcement learning;curriculum learning;sub-tasks;adversarial environment;path planning",
        "author": "",
        "aff": "Under Review at ICLR 2022",
        "rating": "5;6;6;6",
        "confidence": "4;4;3;3",
        "correctness": "3;4;3;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "NyJ2KIN8P17",
        "title": "Neural Program Synthesis with Query",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "SKL of Computer Architecture, Institute of Computing Technology, CAS; University of Science and Technology of China; SKL of Computer Architecture, Institute of Computing Technology, CAS; SKL of Computer Architecture, Institute of Computing Technology, CAS; University of Chinese Academy of Sciences; SKL of Computer Architecture, Institute of Computing Technology, CAS; Corresponding author",
        "rating": "3;3;8",
        "confidence": "4;5;4",
        "correctness": "3;2;4",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "0;1;3",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 1.3333333333333333,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5,
        "corr_rating_correctness": 0.8660254037844387,
        "project": "",
        "github": ""
    },
    {
        "id": "O-l4bthTxno",
        "title": "Not All Regions are Worthy to be Distilled: Region-aware Knowledge Distillation Towards Efficient Image-to-Image Translation",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Knowledge Distillation;Image-to-Image Translation;GAN;CycleGAN;Pix2Pix",
        "author": "",
        "aff": "",
        "rating": "3;5;6",
        "confidence": "5;5;4",
        "correctness": "4;3;3",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "3;2;3",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7559289460184544,
        "corr_rating_correctness": -0.9449111825230683,
        "project": "",
        "github": "To be released soon"
    },
    {
        "id": "O-r8LOR-CCA",
        "title": "Open-World Semi-Supervised Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "deep learning;semi-supervised learning;novel class discovery;clustering",
        "author": "",
        "aff": "Department of Computer Science, Stanford University",
        "rating": "6;6;6;6;6",
        "confidence": "4;5;3;5;4",
        "correctness": "4;3;4;3;3",
        "technical_novelty": "2;4;2;3;2",
        "empirical_novelty": "3;3;0;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.2,
        "correctness_avg": 3.4,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "O0g6uPDLW7",
        "title": "On the Adversarial Robustness of Vision Transformers",
        "track": "main",
        "status": "Reject",
        "keywords": "vision transformer (ViT);adversarial robustness",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5",
        "confidence": "4;3;5;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "3;2;2;2",
        "empirical_novelty": "3;3;2;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "O17RRqiZc5x",
        "title": "Adjoined Networks: A Training Paradigm with Applications to Network Compression",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Deep Neural Network;Compression;Knowledge Distillation",
        "author": "",
        "aff": "",
        "rating": "3;3;6;6",
        "confidence": "5;4;4;4",
        "correctness": "2;3;2;4",
        "technical_novelty": "1;2;3;3",
        "empirical_novelty": "1;0;3;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896258,
        "corr_rating_correctness": 0.3015113445777637,
        "project": "",
        "github": ""
    },
    {
        "id": "O1DEtITim__",
        "title": "Learning Pruning-Friendly Networks via Frank-Wolfe: One-Shot, Any-Sparsity, And No Retraining",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Pruning;Frank-Wolfe",
        "author": "",
        "aff": "University of Science and Technology of China; University of Texas at Austin",
        "rating": "5;6;6;8",
        "confidence": "4;4;3;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;3;3;4",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.13245323570650439,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/VITA-Group/SFW-Once-for-All-Pruning"
    },
    {
        "id": "O2s9k4h0x7L",
        "title": "A Deep Latent Space Model for Directed Graph Representation Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "graph representation learning;directed graph;latent space model;variational autoencoder",
        "author": "",
        "aff": "",
        "rating": "3;3;6;6",
        "confidence": "4;3;4;3",
        "correctness": "2;3;4;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.7071067811865476,
        "project": "",
        "github": ""
    },
    {
        "id": "O476oWmiNNp",
        "title": "Anti-Oversmoothing in Deep Vision Transformers via the Fourier Domain Analysis: From Theory to Practice",
        "track": "main",
        "status": "Poster",
        "keywords": "Deep ViT;Spectral Analysis;Attention Collapse;Patch Diversity",
        "author": "",
        "aff": "Department of Electrical and Computer Engineering, The University of Texas at Austin",
        "rating": "6;6;6",
        "confidence": "4;5;2",
        "correctness": "3;2;3",
        "technical_novelty": "3;3;2",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/VITA-Group/ViT-Anti-Oversmoothing"
    },
    {
        "id": "O4dxuEsIo9S",
        "title": "Spending Your Winning Lottery Better After Drawing It",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Lottery Ticket Hypothesis;Sparse Network Optimization;Sparse Training",
        "author": "",
        "aff": "",
        "rating": "3;3;6;8",
        "confidence": "3;5;3;4",
        "correctness": "2;2;3;4",
        "technical_novelty": "1;2;2;3",
        "empirical_novelty": "1;2;0;4",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.1421338109037403,
        "corr_rating_correctness": 0.994936676326182,
        "project": "",
        "github": ""
    },
    {
        "id": "O50443AsCP",
        "title": "TAPEX: Table Pre-training via Learning a Neural SQL Executor",
        "track": "main",
        "status": "Poster",
        "keywords": "table pre-training;sythetic pre-training;SQL execution;table-based question answering;table-based fact verification",
        "author": "",
        "aff": "Microsoft Research Asia; Microsoft Azure AI; Xi\u2019an Jiaotong University; Beihang University",
        "rating": "6;8;8;8",
        "confidence": "3;4;5;4",
        "correctness": "1;4;4;4",
        "technical_novelty": "3;3;3;4",
        "empirical_novelty": "3;4;3;3",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.816496580927726,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": "https://github.com/microsoft/Table-Pretraining"
    },
    {
        "id": "O5Wr-xX0U2y",
        "title": "Deep Reinforcement Learning for Equal Risk Option Pricing and Hedging under Dynamic Expectile Risk Measures",
        "track": "main",
        "status": "Reject",
        "keywords": "Deep reinforcement learning;risk averse Markov decision processes;expectile risk measures;derivative pricing",
        "author": "",
        "aff": "Under double-blind review",
        "rating": "5;6;6",
        "confidence": "4;2;4",
        "correctness": "3;3;3",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 5.666666666666667,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4999999999999999,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "O9DAoNnYVlM",
        "title": "Federated Learning via Plurality Vote",
        "track": "main",
        "status": "Reject",
        "keywords": "Federated Learning via Plurality Vote",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "3;4;3;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.19245008972987526,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "OBwsUF4nFye",
        "title": "Private Multi-Task Learning: Formulation and Applications to Federated Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "privacy preserving machine learning;large scale machine learning;multi-task learning",
        "author": "",
        "aff": "",
        "rating": "3;3;6",
        "confidence": "3;4;2",
        "correctness": "3;4;3",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "3;2;0",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8660254037844387,
        "corr_rating_correctness": -0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "OCgCYv7KGZe",
        "title": "Auto-Encoding Inverse Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Adversarial Imitation Learning;Inverse Reinforcement Learning;Auto-Encoding",
        "author": "",
        "aff": "",
        "rating": "3;5;6;8",
        "confidence": "3;3;4;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;2;3;4",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8320502943378437,
        "corr_rating_correctness": 0.8320502943378437,
        "project": "",
        "github": ""
    },
    {
        "id": "OD_dnx57ksK",
        "title": "Momentum Conserving Lagrangian Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;4;5;3",
        "correctness": "4;4;4;4",
        "technical_novelty": "1;2;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.816496580927726,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "ODdaICh-7dK",
        "title": "Neural Latent Traversal with Semantic Constraints",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;5;4;3",
        "correctness": "2;4;3;3",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;2;0;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3244428422615251,
        "corr_rating_correctness": 0.6488856845230502,
        "project": "",
        "github": ""
    },
    {
        "id": "ODnCiZujily",
        "title": "DeepSplit: Scalable Verification of Deep Neural Networks via Operator Splitting",
        "track": "main",
        "status": "Reject",
        "keywords": "neural network verification;operator splitting;ADMM",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5;8",
        "confidence": "5;4;4;3;5",
        "correctness": "2;3;3;3;4",
        "technical_novelty": "2;2;2;2;4",
        "empirical_novelty": "2;2;2;3;3",
        "presentation": "",
        "rating_avg": 4.8,
        "confidence_avg": 4.2,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.1749635530559413,
        "corr_rating_correctness": 0.8625819491779426,
        "project": "",
        "github": ""
    },
    {
        "id": "OGbbY4qmir5",
        "title": "Neurally boosted supervised spectral clustering",
        "track": "main",
        "status": "Reject",
        "keywords": "Supervised Node Classification;Spectral Embedding;Social Graphs;Neural Models",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5;8",
        "confidence": "4;4;4;3;4",
        "correctness": "4;3;3;4;4",
        "technical_novelty": "1;2;2;3;4",
        "empirical_novelty": "0;2;2;3;4",
        "presentation": "",
        "rating_avg": 4.8,
        "confidence_avg": 3.8,
        "correctness_avg": 3.6,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 2.2,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.05455447255899811,
        "corr_rating_correctness": 0.3563483225498992,
        "project": "",
        "github": ""
    },
    {
        "id": "OIs3SxU5Ynl",
        "title": "VAE Approximation Error: ELBO and Exponential Families",
        "track": "main",
        "status": "Spotlight",
        "keywords": "",
        "author": "",
        "aff": "Dresden University of Technology; Czech Technical University in Prague",
        "rating": "6;8;8;8",
        "confidence": "3;3;3;4",
        "correctness": "4;4;3;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;4;3;3",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "OJm3HZuj4r7",
        "title": "Convergent and Efficient Deep Q Learning Algorithm",
        "track": "main",
        "status": "Poster",
        "keywords": "DQN;reinforcement learning;convergence",
        "author": "",
        "aff": "Department of Physics and Institute for Physics of Intelligence, University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo 113-0033, Japan; RIKEN Center for Emergent Matter Science (CEMS), Wako, Saitama 351-0198, Japan; Department of Physics and Institute for Physics of Intelligence, University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo 113-0033, Japan",
        "rating": "6;6;10",
        "confidence": "3;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 7.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "OKhFyMVz6t7",
        "title": "Deconfounding to Explanation Evaluation in Graph Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "Graph Neural Networks;Explanation Evaluation;Out-of-distribution;front-door Adjustment",
        "author": "",
        "aff": "",
        "rating": "6;8;8;8",
        "confidence": "3;4;4;3",
        "correctness": "4;3;3;4",
        "technical_novelty": "4;3;4;4",
        "empirical_novelty": "3;3;4;4",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.75,
        "empirical_novelty_avg": 3.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "OM_lYiHXiCL",
        "title": "AEVA: Black-box Backdoor Detection Using Adversarial Extreme Value Analysis",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "Department of Computer Science, The University of Texas at Dallas",
        "rating": "6;6;8;8",
        "confidence": "4;4;4;4",
        "correctness": "3;4;3;4",
        "technical_novelty": "3;2;3;4",
        "empirical_novelty": "3;2;3;4",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "OMxLn4t03FG",
        "title": "Training Multi-Layer Over-Parametrized Neural Network in Subquadratic Time",
        "track": "main",
        "status": "Reject",
        "keywords": "Deep learning;optimization;over-parametrization",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "4;3;4;4",
        "correctness": "2;4;4;4",
        "technical_novelty": "3;3;3;2",
        "empirical_novelty": "0;0;1;0",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 0.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "ONTz_GFWkFR",
        "title": "A Sampling-Free Approximation of Gaussian Variational Auto-Encoders",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;5;8",
        "confidence": "5;5;4;3",
        "correctness": "4;3;4;2",
        "technical_novelty": "2;2;2;4",
        "empirical_novelty": "2;2;2;0",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8703882797784892,
        "corr_rating_correctness": -0.8703882797784892,
        "project": "",
        "github": ""
    },
    {
        "id": "OOaY4GZIJ7",
        "title": "Efficient Semi-Discrete Optimal Transport Using the Maximum Relative Error between Distributions",
        "track": "main",
        "status": "Withdraw",
        "keywords": "optimal transport",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;3;4;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "OQL_tkK1vqO",
        "title": "ZARTS: On Zero-order Optimization for Neural Architecture Search",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "6;6;6",
        "confidence": "4;4;5",
        "correctness": "4;3;3",
        "technical_novelty": "2;4;4",
        "empirical_novelty": "2;3;0",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.3333333333333335,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "OQo6Tuyo0ih",
        "title": "Interpretable Multi-hop Reasoning for Forecasting Future Links on Temporal Knowledge Graphs",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Temporal knowledge graphs;Forecasting;Question matching degree;Answer completing level;Path confidence",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5;6",
        "confidence": "4;4;5;4;2",
        "correctness": "3;2;3;3;2",
        "technical_novelty": "2;2;2;2;3",
        "empirical_novelty": "2;2;2;2;3",
        "presentation": "",
        "rating_avg": 4.4,
        "confidence_avg": 3.8,
        "correctness_avg": 2.6,
        "technical_novelty_avg": 2.2,
        "empirical_novelty_avg": 2.2,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.44226898133585163,
        "corr_rating_correctness": -0.06804138174397723,
        "project": "",
        "github": ""
    },
    {
        "id": "OT3mLgR8Wg8",
        "title": "IFR-Explore: Learning Inter-object Functional Relationships in 3D Indoor Scenes",
        "track": "main",
        "status": "Poster",
        "keywords": "Inter-object Functional Relationship;Learning Interactive Policy for Exploration;Interactive Perception;3D Scene Understanding",
        "author": "",
        "aff": "Stanford University; Tsinghua University",
        "rating": "6;6;6;8",
        "confidence": "4;3;3;4",
        "correctness": "3;4;4;4",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "OUz_9TiTv9j",
        "title": "A Zest of LIME: Towards Architecture-Independent Model Distances",
        "track": "main",
        "status": "Poster",
        "keywords": "model distance;model stealing;machine unlearning;fairwashing",
        "author": "",
        "aff": "Vector Institute and The Alan Turing Institute; University of Toronto and Vector Institute; University of Toronto",
        "rating": "3;6;6;8",
        "confidence": "4;4;3;3",
        "correctness": "3;4;3;3",
        "technical_novelty": "1;2;3;4",
        "empirical_novelty": "2;3;3;4",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7001400420140049,
        "corr_rating_correctness": 0.08084520834544431,
        "project": "",
        "github": "https://github.com/cleverhans-lab/Zest-Model-Distance"
    },
    {
        "id": "OVShHe8Ce0",
        "title": "SAU: Smooth activation function using convolution with approximate identities",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Deep Learning;Neural Networks;Parametric activation function.",
        "author": "",
        "aff": "",
        "rating": "3;3;3;8",
        "confidence": "3;4;4;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "0;2;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "OVV_wIPf1e",
        "title": "Causal-TGAN: Causally-Aware Synthetic Tabular Data Generative Adversarial Network",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Tabular Data Generation;Generative Adversarial Networks;Causality",
        "author": "",
        "aff": "",
        "rating": "1;3;3;3",
        "confidence": "5;4;4;4",
        "correctness": "4;4;3;3",
        "technical_novelty": "1;1;2;2",
        "empirical_novelty": "2;1;2;2",
        "presentation": "",
        "rating_avg": 2.5,
        "confidence_avg": 4.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 1.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "OWZVD-l-ZrC",
        "title": "Reward Uncertainty for Exploration in Preference-based Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "University of California, Berkeley",
        "rating": "5;6;6;6",
        "confidence": "4;3;4;4",
        "correctness": "3;3;2;3",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;3;3;2",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "OXRZeMmOI7a",
        "title": "Topological Experience Replay",
        "track": "main",
        "status": "Poster",
        "keywords": "Deep reinforcement learning;experience replay",
        "author": "",
        "aff": "Aalto University; Improbable AI Lab, Massachusetts Institute of Technology",
        "rating": "5;6;8;8",
        "confidence": "4;5;4;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;3;4;2",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.5555555555555555,
        "project": "",
        "github": ""
    },
    {
        "id": "OY1A8ejQgEX",
        "title": "Mention Memory: incorporating textual knowledge into Transformers through entity mention attention",
        "track": "main",
        "status": "Poster",
        "keywords": "NLP;Entities and Relations;Memory",
        "author": "",
        "aff": "Google; University of Southern California",
        "rating": "6;8;8;8",
        "confidence": "4;4;4;4",
        "correctness": "4;4;3;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;3;4",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": "https://github.com/google-research/language/tree/master/language/mentionmemory"
    },
    {
        "id": "OZ_2rF2D4Nw",
        "title": "Kokoyi: Executable LaTeX for End-to-end Deep Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;6",
        "confidence": "3;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "3;2;4",
        "empirical_novelty": "2;2;4",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.4999999999999999,
        "corr_rating_correctness": 0.4999999999999999,
        "project": "",
        "github": ""
    },
    {
        "id": "O_OJoU4_yj",
        "title": "Stabilized Self-training with Negative Sampling on Few-labeled Graph Data",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "1;3;3;5;5",
        "confidence": "4;4;5;4;4",
        "correctness": "2;2;2;3;3",
        "technical_novelty": "1;2;1;3;2",
        "empirical_novelty": "0;0;1;3;0",
        "presentation": "",
        "rating_avg": 3.4,
        "confidence_avg": 4.2,
        "correctness_avg": 2.4,
        "technical_novelty_avg": 1.8,
        "empirical_novelty_avg": 0.8,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.13363062095621217,
        "corr_rating_correctness": 0.8728715609439696,
        "project": "",
        "github": ""
    },
    {
        "id": "OcKMT-36vUs",
        "title": "A Loss Curvature Perspective on Training Instabilities of Deep Learning Models",
        "track": "main",
        "status": "Poster",
        "keywords": "Optimization;Deep Learning;Training Instability;Curvature;Loss Landscape;Hessian",
        "author": "",
        "aff": "; Google",
        "rating": "5;6;8;8",
        "confidence": "4;4;3;4",
        "correctness": "3;4;4;4",
        "technical_novelty": "2;3;2;1",
        "empirical_novelty": "2;3;3;4",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5555555555555555,
        "corr_rating_correctness": 0.7777777777777777,
        "project": "",
        "github": ""
    },
    {
        "id": "OcvjQ3yqgTG",
        "title": "ImpressLearn: Continual Learning via Combined Task Impressions",
        "track": "main",
        "status": "Reject",
        "keywords": "Catastrophic forgetting;Continual learning;Neural networks;Masking",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;5;3;3",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9045340337332909,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "OdTx-22f6H",
        "title": "Utilizing Attention, Linked Blocks, And Pyramid Pooling To Propel Brain Tumor Segmentation In 3D",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Computer Vision;Deep Learning;3D Semantic Segmentation;Medical Imaging",
        "author": "",
        "aff": "Paper under double-blind review",
        "rating": "1;1;1;3;3",
        "confidence": "5;5;5;3;5",
        "correctness": "3;1;1;3;1",
        "technical_novelty": "1;1;1;1;1",
        "empirical_novelty": "1;1;1;1;1",
        "presentation": "",
        "rating_avg": 1.8,
        "confidence_avg": 4.6,
        "correctness_avg": 1.8,
        "technical_novelty_avg": 1.0,
        "empirical_novelty_avg": 1.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6123724356957945,
        "corr_rating_correctness": 0.16666666666666669,
        "project": "",
        "github": ""
    },
    {
        "id": "OdnNBNIdFul",
        "title": "A Closer Look at Loss Weighting in Multi-Task Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "5;3;3;3",
        "correctness": "3;3;4;2",
        "technical_novelty": "3;3;4;3",
        "empirical_novelty": "3;3;4;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9428090415820632,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "Odu6pOBshzQ",
        "title": "Sublinear Least-Squares Value Iteration via Locality Sensitive Hashing",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;4;2;3",
        "correctness": "4;3;3;3",
        "technical_novelty": "2;2;2;4",
        "empirical_novelty": "0;0;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.48420012470625223,
        "corr_rating_correctness": -0.9271726499455306,
        "project": "",
        "github": ""
    },
    {
        "id": "OgCcfc1m0TO",
        "title": "Learning to Prompt for Vision-Language Models",
        "track": "main",
        "status": "Reject",
        "keywords": "vision-language models;prompt learning;computer vision;transfer learning",
        "author": "",
        "aff": "Under double-blind review",
        "rating": "1;5;5;6",
        "confidence": "5;3;4;5",
        "correctness": "3;4;3;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3532809023904868,
        "corr_rating_correctness": 0.22549380840084865,
        "project": "",
        "github": ""
    },
    {
        "id": "Oh1r2wApbPv",
        "title": "Contextualized Scene Imagination for Generative Commonsense Reasoning",
        "track": "main",
        "status": "Poster",
        "keywords": "Commonsense reasoning;constrained text generation;knowledge representation",
        "author": "",
        "aff": "Department of Computer Science, University of California, San Diego; Department of Computer Science, University of Southern California; Information Sciences Institute, University of Southern California",
        "rating": "6;6;8;8",
        "confidence": "4;4;4;3",
        "correctness": "4;3;4;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;4;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/wangpf3/imagine-and-verbalize"
    },
    {
        "id": "OhmG-MzmC2v",
        "title": "User-Entity Differential Privacy in Learning Natural Language Models",
        "track": "main",
        "status": "Withdraw",
        "keywords": "differential privacy;natural language models",
        "author": "",
        "aff": "",
        "rating": "3;5;5",
        "confidence": "3;4;3",
        "correctness": "3;4;2",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 4.333333333333333,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.49999999999999983,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "OhytAdNSzO-",
        "title": "An Investigation on Hardware-Aware Vision Transformer Scaling",
        "track": "main",
        "status": "Reject",
        "keywords": "Model Scaling;Vision Transformer",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "3;3;3;5",
        "correctness": "4;3;3;3",
        "technical_novelty": "2;1;2;3",
        "empirical_novelty": "3;3;3;4",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.7777777777777777,
        "corr_rating_correctness": -0.5555555555555555,
        "project": "",
        "github": ""
    },
    {
        "id": "OjFh4rBdrAP",
        "title": "A Two-Stage Framework to Generate Video Chapter",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Video Chapter Generation;High-level Video Understanding;MultiModal Machine Learning",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;5;3;5",
        "correctness": "3;2;4;3",
        "technical_novelty": "2;2;1;3",
        "empirical_novelty": "2;2;1;4",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5222329678670935,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "OjPmfr9GkVv",
        "title": "Enhancing Cross-lingual Transfer by Manifold Mixup",
        "track": "main",
        "status": "Poster",
        "keywords": "cross-lingual transfer;cross-lingual understanding;manifold mixup",
        "author": "",
        "aff": "University of California, Santa Barbara; ByteDance AI Lab",
        "rating": "5;6;8;8",
        "confidence": "3;4;5;4",
        "correctness": "3;4;4;4",
        "technical_novelty": "3;4;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.816496580927726,
        "corr_rating_correctness": 0.7777777777777777,
        "project": "",
        "github": "https://github.com/yhy1117/X-Mixup"
    },
    {
        "id": "OkB0tlodmH",
        "title": "Q-learning for real time control of heterogeneous microagent collectives",
        "track": "main",
        "status": "Reject",
        "keywords": "q-learning;reinforcement learning;microsystems;closed-loop control;optical control",
        "author": "",
        "aff": "",
        "rating": "3;3;6",
        "confidence": "2;4;2",
        "correctness": "3;3;4",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5000000000000001,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "OnpFa95RVqs",
        "title": "Surrogate NAS Benchmarks: Going Beyond the Limited Search Spaces of Tabular NAS Benchmarks",
        "track": "main",
        "status": "Poster",
        "keywords": "neural architecture search;AutoML;benchmarking;surrogate model",
        "author": "",
        "aff": "University of Freiburg, Bosch Center for AI; University of Freiburg; University of Mannheim",
        "rating": "3;5;8;8",
        "confidence": "5;4;4;5",
        "correctness": "2;3;4;4",
        "technical_novelty": "2;2;4;4",
        "empirical_novelty": "2;2;4;4",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.23570226039551587,
        "corr_rating_correctness": 0.994936676326182,
        "project": "",
        "github": "https://github.com/... (Please note that the actual GitHub link is not provided in the text)"
    },
    {
        "id": "Opmqtk_GvYL",
        "title": "MetaMorph: Learning Universal Controllers with Transformers",
        "track": "main",
        "status": "Poster",
        "keywords": "RL;Modular Robots;Transformers",
        "author": "",
        "aff": "Stanford University; Stanford University, Stanford Institute for Human-Centered Arti\ufb01cial Intelligence; Stanford University, NVIDIA Corporation",
        "rating": "6;6;8;8;8",
        "confidence": "5;5;4;4;4",
        "correctness": "3;3;3;3;3",
        "technical_novelty": "2;3;3;3;3",
        "empirical_novelty": "3;3;3;2;3",
        "presentation": "",
        "rating_avg": 7.2,
        "confidence_avg": 4.4,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.8,
        "empirical_novelty_avg": 2.8,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "OqHtVOo-zy",
        "title": "Estimating Instance-dependent Label-noise Transition Matrix using DNNs",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5;8",
        "confidence": "5;4;4;4",
        "correctness": "2;2;3;4",
        "technical_novelty": "1;2;3;4",
        "empirical_novelty": "2;4;3;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.49374193110101877,
        "corr_rating_correctness": 0.9945577827230725,
        "project": "",
        "github": ""
    },
    {
        "id": "OqcZu8JIIzS",
        "title": "Pareto Policy Pool for Model-based Offline Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "model-based offline RL;Pareto front;multi-objective optimization;policy pool;model return-uncertainty trade-off",
        "author": "",
        "aff": "Department of Computer Science and Engineering, Southern University of Science and Technology; University of Washington, Seattle; Australian Arti\ufb01cial Intelligence Institute, University of Technology Sydney",
        "rating": "5;6;8;8",
        "confidence": "3;3;4;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "3;0;3;3",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9622504486493761,
        "corr_rating_correctness": 0.5555555555555555,
        "project": "",
        "github": ""
    },
    {
        "id": "OqlohL9sVO",
        "title": "Deep Fusion of Multi-attentive Local and Global Features with Higher Efficiency for Image Retrieval",
        "track": "main",
        "status": "Reject",
        "keywords": "Image retrieval;Homography learning;Attention;Intermediate supervision",
        "author": "",
        "aff": "",
        "rating": "1;3;5;6",
        "confidence": "5;5;5;3",
        "correctness": "2;2;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 4.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.676481425202546,
        "corr_rating_correctness": 0.911322376865767,
        "project": "",
        "github": ""
    },
    {
        "id": "Osoo_n9cMZ3",
        "title": "CRAFTING BETTER CONTRASTIVE VIEWS FOR SIAMESE REPRESENTATION LEARNING",
        "track": "main",
        "status": "Withdraw",
        "keywords": "contrastive learning;data augmentation;Siamese representation learning",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "5;4;5;3",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;3;2;2",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4923659639173309,
        "corr_rating_correctness": 0.4714045207910316,
        "project": "",
        "github": ""
    },
    {
        "id": "OtEDS2NWhqa",
        "title": "Using Graph Representation Learning with Schema Encoders to Measure the Severity of Depressive Symptoms",
        "track": "main",
        "status": "Poster",
        "keywords": "Graph neural networks sentiment analysis node-embedding algorithm  diagnostic prediction task",
        "author": "",
        "aff": "School of Computing, University of Leeds, UK",
        "rating": "5;6;8",
        "confidence": "4;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 6.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.944911182523068,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "Ow1C7s3UcY",
        "title": "Vitruvion: A Generative Model of Parametric CAD Sketches",
        "track": "main",
        "status": "Poster",
        "keywords": "generative modeling;CAD;transformers;design;geometric constraints",
        "author": "",
        "aff": "New York University, Flatiron Institute; Princeton University",
        "rating": "6;8;8;8",
        "confidence": "4;4;4;4",
        "correctness": "3;4;4;4",
        "technical_novelty": "2;4;3;3",
        "empirical_novelty": "3;0;3;0",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "Oxdln9khkxv",
        "title": "Learning the Representation of Behavior Styles with Imitation Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Imitation Learning;Behavior Style",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;4;3",
        "correctness": "3;2;3;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;1;3;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "Oxeka7Z7Hor",
        "title": "Gaussian Mixture Convolution Networks",
        "track": "main",
        "status": "Poster",
        "keywords": "deep learning architecture;gaussian convolution;gaussian mixture;3d",
        "author": "",
        "aff": "\u2020TU Wien; \u2021Ulm University",
        "rating": "5;6;6;8",
        "confidence": "3;4;3;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "3;3;4;4",
        "empirical_novelty": "3;3;0;2",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.6882472016116854,
        "corr_rating_correctness": 0.9271726499455306,
        "project": "",
        "github": ""
    },
    {
        "id": "OxgLa0VEyg-",
        "title": "Loss Function Learning for Domain Generalization by Implicit Gradient",
        "track": "main",
        "status": "Reject",
        "keywords": "meta-learning;loss function learning;Domain Generalisation",
        "author": "",
        "aff": "",
        "rating": "3;6;6;8",
        "confidence": "4;3;4;3",
        "correctness": "2;3;3;4",
        "technical_novelty": "3;4;2;3",
        "empirical_novelty": "3;3;2;4",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7001400420140049,
        "corr_rating_correctness": 0.9901475429766743,
        "project": "",
        "github": ""
    },
    {
        "id": "Oy9WeuZD51",
        "title": "A Statistical Framework for Efficient Out of Distribution Detection in Deep Neural Networks",
        "track": "main",
        "status": "Poster",
        "keywords": "out of distribution;DNNs;p-value;hypothesis testing;inductive conformal predictor",
        "author": "",
        "aff": "",
        "rating": "3;5;8;8",
        "confidence": "5;5;3;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;3;4",
        "empirical_novelty": "2;2;3;4",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9428090415820635,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "OzXAw20k_H",
        "title": "Deep Learning of Intrinsically Motivated Options in the Arcade Learning Environment",
        "track": "main",
        "status": "Reject",
        "keywords": "reinforcement learning;intrinsic motivation;auxiliary task learning;options;atari",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;2;3;4",
        "correctness": "2;3;2;2",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.25,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5222329678670935,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "OzyXtIZAzFv",
        "title": "Task-Induced Representation Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "representation learning;reinforcement learning;transfer learning;visually complex observations",
        "author": "",
        "aff": "University of Oxford; Korea Advanced Institute of Science and Technology; University of Southern California",
        "rating": "5;6;6;6",
        "confidence": "4;4;4;5",
        "correctness": "3;3;3;4",
        "technical_novelty": "1;2;2;2",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "http://clvrai.com/tarp",
        "github": ""
    },
    {
        "id": "P-gDXxGYCib",
        "title": "Feature Selection in the Contrastive Analysis Setting",
        "track": "main",
        "status": "Reject",
        "keywords": "Feature selection;contrastive analysis;computational biology",
        "author": "",
        "aff": "",
        "rating": "3;5;5;8",
        "confidence": "4;2;4;4",
        "correctness": "2;2;3;4",
        "technical_novelty": "1;2;2;3",
        "empirical_novelty": "1;2;1;2",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.08084520834544431,
        "corr_rating_correctness": 0.8866206949335731,
        "project": "",
        "github": ""
    },
    {
        "id": "P-pPW1nxf1r",
        "title": "HTLM: Hyper-Text Pre-Training and Prompting of Language Models",
        "track": "main",
        "status": "Poster",
        "keywords": "prompting;nlp;representational learning;priming",
        "author": "",
        "aff": "",
        "rating": "6;6;6;8",
        "confidence": "4;4;3;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;3;3;4",
        "empirical_novelty": "3;3;2;4",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "P07dq7iSAGr",
        "title": "Explaining Point Processes by Learning Interpretable Temporal Logic Rules",
        "track": "main",
        "status": "Poster",
        "keywords": "Temporal Point Process;Temporal Logic Rules;Explainable Models",
        "author": "",
        "aff": "CUHK, Shenzhen; Shenzhen Institute of Artificial Intelligence and Robotics for Society; Shanghai Jiao Tong University; MoE Key Lab of Artificial Intelligence; SJTU-Yale Joint Center for Biostatistics and Data Science; National Center for Translational Medicine; MBZUAI; BioMap; Shanghai Jiao Tong University; Antai College of Economics and Management; Data-Driven Management Decision Making Lab; MBZUAI; Microsoft Research",
        "rating": "6;6;6;8",
        "confidence": "4;2;2;3",
        "correctness": "3;3;4;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;3;4",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 2.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.17407765595569782,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": "https://github.com/FengMingquan-sjtu/Logic_Point_Processes_ICLR"
    },
    {
        "id": "P0EholD6_G",
        "title": "On Hard Episodes in Meta-Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "meta-learning;few-shot learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;4;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "P1QUVhOtEFP",
        "title": "Topologically Regularized Data Embeddings",
        "track": "main",
        "status": "Poster",
        "keywords": "Embedding;Dimensionality Reduction;Topological Data Analysis;Persistent Homology;Optimization;Regularization",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;3;2;3",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;3;0",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6488856845230502,
        "corr_rating_correctness": 0.6882472016116854,
        "project": "",
        "github": ""
    },
    {
        "id": "P1zfguZHowl",
        "title": "Robust Losses for Learning Value Functions",
        "track": "main",
        "status": "Reject",
        "keywords": "Reinforcement Learning",
        "author": "",
        "aff": "",
        "rating": "5;6;6;8",
        "confidence": "2;2;2;4",
        "correctness": "4;4;3;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;4",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 2.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9271726499455306,
        "corr_rating_correctness": 0.13245323570650439,
        "project": "",
        "github": ""
    },
    {
        "id": "P3Bh01hBYTH",
        "title": "X-model: Improving Data Efficiency in Deep Learning with A Minimax Model",
        "track": "main",
        "status": "Poster",
        "keywords": "Data Efficiency;Deep Learning;Minimax Model",
        "author": "",
        "aff": "School of Software, BNRist, Tsinghua University, China",
        "rating": "6;6;8",
        "confidence": "4;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.49999999999999983,
        "project": "",
        "github": ""
    },
    {
        "id": "P3SQi2EWeR",
        "title": "Integrating Large Circular Kernels into CNNs through Neural Architecture Search",
        "track": "main",
        "status": "Withdraw",
        "keywords": "circular kernel;Convolutional Neural Network;Neural Architecture Search;operation space;large kernel",
        "author": "",
        "aff": "",
        "rating": "1;3;5;6",
        "confidence": "4;4;3;3",
        "correctness": "2;2;3;3",
        "technical_novelty": "1;3;2;3",
        "empirical_novelty": "1;2;2;3",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 3.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.911322376865767,
        "corr_rating_correctness": 0.911322376865767,
        "project": "",
        "github": ""
    },
    {
        "id": "P6OUJ2XziC",
        "title": "NeuRL: Closed-form Inverse Reinforcement Learning for Neural Decoding",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Inverse Reinforcement Learning;Neural Decoding;Computational Biology",
        "author": "",
        "aff": "",
        "rating": "3;5;5",
        "confidence": "4;4;3",
        "correctness": "2;3;3",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 4.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.49999999999999983,
        "corr_rating_correctness": 0.9999999999999998,
        "project": "",
        "github": ""
    },
    {
        "id": "P7FLfMLTSEX",
        "title": "The Spectral Bias of Polynomial Neural Networks",
        "track": "main",
        "status": "Poster",
        "keywords": "Deep Neural Networks;Polynomials;Spectral Bias;Neural Tangent Kernel;Deep Image Prior;Infinite Width;Mercer Decomposition",
        "author": "",
        "aff": "University of Illinois at Urbana-Champaign; EPFL, Switzerland; Univ. Grenoble-Alpes, Inria",
        "rating": "5;6;6;6;8",
        "confidence": "4;3;2;3;3",
        "correctness": "3;4;3;3;4",
        "technical_novelty": "2;2;3;3;3",
        "empirical_novelty": "3;3;2;2;2",
        "presentation": "",
        "rating_avg": 6.2,
        "confidence_avg": 3.0,
        "correctness_avg": 3.4,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3227486121839514,
        "corr_rating_correctness": 0.6666666666666667,
        "project": "",
        "github": ""
    },
    {
        "id": "P7OVkHEoHOZ",
        "title": "Hindsight Foresight Relabeling for Meta-Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "Reinforcement Learning;Meta-Learning",
        "author": "",
        "aff": "University of Illinois at Urbana-Champaign",
        "rating": "5;6;6;8",
        "confidence": "3;5;4;3",
        "correctness": "4;4;4;3",
        "technical_novelty": "3;3;2;2",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.20751433915982243,
        "corr_rating_correctness": -0.9271726499455306,
        "project": "",
        "github": "https://www.github.com/michaelwan11/hfr"
    },
    {
        "id": "P9TDsg-AoEK",
        "title": "Zero-Shot Dense Retrieval with Momentum Adversarial Domain Invariant Representation",
        "track": "main",
        "status": "Withdraw",
        "keywords": "dense retrieval;zero-shot;unsupervised domain adaptation",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;4;5;3",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "PC8u74o7xc2",
        "title": "Embedding models through the lens of Stable Coloring",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;3;3;4",
        "correctness": "3;3;2;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "1;0;0;0",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 0.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "PDYs7Z2XFGv",
        "title": "Omni-Scale CNNs: a simple and effective kernel size configuration for time series classification",
        "track": "main",
        "status": "Poster",
        "keywords": "Time series classification",
        "author": "",
        "aff": "University of Washington, Seattle; Australian Arti\ufb01cial Intelligence Institute, University of Technology Sydney",
        "rating": "6;6;8",
        "confidence": "3;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "3;2;3",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.49999999999999983,
        "corr_rating_correctness": 0.9999999999999998,
        "project": "",
        "github": "https://github.com/Wensi-Tang/OS-CNN"
    },
    {
        "id": "PGGjnBiQ84G",
        "title": "Learning Surface Parameterization for Document Image Unwarping",
        "track": "main",
        "status": "Reject",
        "keywords": "implicit functions;texture mapping;surface parameterization",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "4;4;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;2;3;2",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "PHugX0j2xcE",
        "title": "Predictive Maintenance for Optical Networks in Robust Collaborative Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "predictive maintenance;federated learning;machine learning;anomaly detection;multi-party computation;autoencoder",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;4;4;3",
        "correctness": "2;2;3;2",
        "technical_novelty": "2;2;1;2",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.75,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "PIExE5KjaVL",
        "title": "Safety-aware Policy Optimisation for Autonomous Racing",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Safe Reinforcement Learning;Hamilton-Jacobi Reachability;Autonomous Driving",
        "author": "",
        "aff": "",
        "rating": "3;3;5;8",
        "confidence": "4;4;2;2",
        "correctness": "2;3;3;4",
        "technical_novelty": "2;2;2;4",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8551861104941366,
        "corr_rating_correctness": 0.8638684255813602,
        "project": "",
        "github": ""
    },
    {
        "id": "PKdNRKjwL4",
        "title": "DAIR: Data Augmented Invariant Regularization",
        "track": "main",
        "status": "Withdraw",
        "keywords": "data augmentation;domain shift;adversarial training",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "3;4;3;4",
        "correctness": "3;4;3;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;0",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "PLDOnFoVm4",
        "title": "Reinforcement Learning under a Multi-agent Predictive State Representation Model: Method and Theory",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Multi-agent Reinforcement Learning;Predictive State Representation;Dynamic Interaction Graph",
        "author": "",
        "aff": "University of Maryland, College Park; Northwestern University; Yale University",
        "rating": "8;8;8",
        "confidence": "3;3;3",
        "correctness": "3;4;4",
        "technical_novelty": "4;4;3",
        "empirical_novelty": "3;0;4",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 3.6666666666666665,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "PO-32ODWng",
        "title": "Improving the Post-hoc Calibration of Modern Neural Networks with Probe Scaling",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Calibration;Probes;Generalization;Temperature Scaling;Post-processing",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "4;4;4;4",
        "correctness": "2;3;2;2",
        "technical_novelty": "2;2;2;1",
        "empirical_novelty": "2;2;2;1",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "POTMtpYI1xH",
        "title": "Discovering Latent Concepts Learned in BERT",
        "track": "main",
        "status": "Poster",
        "keywords": "interpretation;BERT;NLP",
        "author": "",
        "aff": "Qatar Computing Research Institute, HBKU Research Complex, Doha 5825, Qatar; School of Engineering and Science, Steven Institute of Technology, Hoboken, NJ 07030, USA",
        "rating": "5;5;8;8",
        "confidence": "4;2;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896258,
        "corr_rating_correctness": 0.0,
        "project": "https://neurox.qcri.org/projects/bert-concept-net.html",
        "github": ""
    },
    {
        "id": "POvMvLi91f",
        "title": "DR3: Value-Based Deep Reinforcement Learning Requires Explicit Regularization",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Q-learning;offline RL;regularization",
        "author": "",
        "aff": "UC Berkeley, Google Research; MILA; Google Research; Stanford University; Google Research, MILA",
        "rating": "6;6;8;8",
        "confidence": "3;4;3;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "3;3;3;4",
        "empirical_novelty": "3;3;3;2",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "POxF-LEqnF",
        "title": "You Mostly Walk Alone: Analyzing Feature Attribution in Trajectory Prediction",
        "track": "main",
        "status": "Poster",
        "keywords": "Feature Attribution;Shapley values;Trajectory Prediction;Causality",
        "author": "",
        "aff": "Amazon, Max Planck Institute for Intelligent Systems T\u00a8ubingen; Amazon; Amazon, University of Freiburg; Max Planck Institute for Intelligent Systems T\u00a8ubingen, University of Cambridge",
        "rating": "5;6;8;8;10",
        "confidence": "4;4;4;4;5",
        "correctness": "3;4;4;4;4",
        "technical_novelty": "3;3;3;2;4",
        "empirical_novelty": "3;3;3;4;4",
        "presentation": "",
        "rating_avg": 7.4,
        "confidence_avg": 4.2,
        "correctness_avg": 3.8,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.4,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.7456011350793259,
        "corr_rating_correctness": 0.6882472016116856,
        "project": "",
        "github": ""
    },
    {
        "id": "PQQp7AJwz3",
        "title": "Particle Stochastic Dual Coordinate Ascent: Exponential convergent algorithm for mean field neural network optimization",
        "track": "main",
        "status": "Poster",
        "keywords": "Neural Network Optimization;Mean field Regime;Overparameterization",
        "author": "",
        "aff": "University of Tokyo; Kyushu Institute of Technology, JST PRESTO, RIKEN AIP; University of Toronto, Vector Institute; University of Tokyo, RIKEN AIP",
        "rating": "6;6;6;8",
        "confidence": "4;4;2;3",
        "correctness": "4;4;3;3",
        "technical_novelty": "3;3;3;4",
        "empirical_novelty": "0;3;0;0",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 0.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.17407765595569782,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "PQTW3iG4sC-",
        "title": "On feature learning in neural networks with global convergence guarantees",
        "track": "main",
        "status": "Poster",
        "keywords": "neural networks;feature learning;gradient descent;global convergence",
        "author": "",
        "aff": "Courant Institute of Mathematical Sciences, New York University, New York, NY 10012, USA; Courant Institute of Mathematical Sciences and Center for Data Science, New York University, New York, NY 10012, USA",
        "rating": "3;6;8;8",
        "confidence": "4;3;2;4",
        "correctness": "1;4;4;3",
        "technical_novelty": "1;2;3;3",
        "empirical_novelty": "1;2;1;0",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.47886115464444223,
        "corr_rating_correctness": 0.7980074688861063,
        "project": "",
        "github": ""
    },
    {
        "id": "PQTkBlcrRs",
        "title": "AutoML to generate ensembles of deep neural networks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Deep Learning;Ensemble;AutoML",
        "author": "",
        "aff": "",
        "rating": "1;3;3;3",
        "confidence": "5;4;5;3",
        "correctness": "2;3;2;3",
        "technical_novelty": "1;2;2;1",
        "empirical_novelty": "1;2;1;1",
        "presentation": "",
        "rating_avg": 2.5,
        "confidence_avg": 4.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 1.5,
        "empirical_novelty_avg": 1.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5222329678670935,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "PRZoSmCinhf",
        "title": "Constrained Policy Optimization via Bayesian World Models",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Reinforcement learning;Constrained Markov decision processes;Constrained policy optimization;Bayesian model-based RL",
        "author": "",
        "aff": "ETH Zurich",
        "rating": "6;8;8;8",
        "confidence": "4;4;3;4",
        "correctness": "3;4;4;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "3;4;3;3",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "PTRo58zPt3P",
        "title": "Inductive Relation Prediction Using Analogy Subgraph Embeddings",
        "track": "main",
        "status": "Poster",
        "keywords": "Link Prediction;Relation Modelling;Heterogeneous Graphs;Knowledge Graphs",
        "author": "",
        "aff": "Amazon; Shanghai Jiao Tong University",
        "rating": "8;8;8;8;8",
        "confidence": "4;5;4;5;3",
        "correctness": "4;4;4;4;3",
        "technical_novelty": "2;3;3;4;3",
        "empirical_novelty": "2;0;2;4;3",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 4.2,
        "correctness_avg": 3.8,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.2,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "PU3VGS93gxD",
        "title": "Sample Complexity of Deep Active Learning",
        "track": "main",
        "status": "Desk Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "",
        "confidence": "",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "PUrOJvOuSM1",
        "title": "A2B-GAN: Utilizing Unannotated Anomalous Images for Anomaly Detection in Medical Image Analysis",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Anomaly detection;novelty detection;image-to-image translation;generative adversarial network;medical image analysis",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "5;4;5;4",
        "correctness": "2;2;2;2",
        "technical_novelty": "2;2;1;2",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.5,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "Available upon paper decision"
    },
    {
        "id": "PVB_t0HCMVC",
        "title": "Towards Defending Multiple $\\ell_p$-Norm Bounded Adversarial Perturbations via Gated Batch Normalization",
        "track": "main",
        "status": "Withdraw",
        "keywords": "adversarial examples;multiple $\\ell_p$-norm bounded adversarial peturbations;adversarial robustness",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;5;3;5",
        "correctness": "2;3;3;3",
        "technical_novelty": "3;3;3;2",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.30151134457776363,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": "https://anonymous.4open.science/r/GBN-625C/"
    },
    {
        "id": "PVJ6j87gOHz",
        "title": "CoMPS: Continual Meta Policy Search",
        "track": "main",
        "status": "Poster",
        "keywords": "Reinforcement Learning",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6;6",
        "confidence": "4;2;3;4;3",
        "correctness": "3;3;3;4;3",
        "technical_novelty": "2;2;1;4;2",
        "empirical_novelty": "2;2;3;4;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.2,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.2,
        "empirical_novelty_avg": 2.8,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.24397501823713333,
        "corr_rating_correctness": 0.4564354645876385,
        "project": "",
        "github": ""
    },
    {
        "id": "PZoy8i_Dp6",
        "title": "Attention-based Feature Aggregation",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Deep Learning;Object Detection;Instance Segmentation;Attention",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "5;4;3;3",
        "correctness": "3;4;4;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;0;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5222329678670935,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "PaQhL90tLmX",
        "title": "Robust Deep Neural Networks for Heterogeneous Tabular Data",
        "track": "main",
        "status": "Reject",
        "keywords": "Deep Learning;Deep Neural Networks;Tabular Data;Gradient Boosted Decision Trees",
        "author": "",
        "aff": "",
        "rating": "3;5;6",
        "confidence": "4;5;4",
        "correctness": "3;3;3",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.18898223650461357,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "Available"
    },
    {
        "id": "PeG-8G5ua3W",
        "title": "Normalized Attention Without Probability Cage",
        "track": "main",
        "status": "Reject",
        "keywords": "Attention;Transformers;Neural Architecture;Aggregators",
        "author": "",
        "aff": "",
        "rating": "5;6;6;8",
        "confidence": "3;3;3;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "3;3;3;4",
        "empirical_novelty": "2;4;3;4",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9271726499455306,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "Pfj3SXBCbVQ",
        "title": "On the Effectiveness of Quasi Character-Level Models for Machine Translation",
        "track": "main",
        "status": "Reject",
        "keywords": "Deep learning;Neural Machine Translation;Subword-level vocabulary",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "5;5;5;4",
        "correctness": "2;3;1;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "3;2;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.75,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.5222329678670935,
        "project": "",
        "github": ""
    },
    {
        "id": "PgNEYaIc81Q",
        "title": "ComPhy: Compositional Physical Reasoning of Objects and Events from Videos",
        "track": "main",
        "status": "Poster",
        "keywords": "Compositional;Intutive Physics;Video Reasoning;Neural-Symbolic",
        "author": "",
        "aff": "MIT BCS, CBMM, CSAIL; MIT; The University of Hong Kong; Harvard University; MIT-IBM Watson AI Lab",
        "rating": "3;5;6;6",
        "confidence": "4;4;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "1;2;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "https://comphyreasoning.github.io",
        "github": ""
    },
    {
        "id": "PiDkqc9saaL",
        "title": "Lower Bounds on the Robustness of Fixed Feature Extractors to Test-time Adversaries",
        "track": "main",
        "status": "Reject",
        "keywords": "robustness;lower bounds",
        "author": "",
        "aff": "",
        "rating": "5;6;6;6;8",
        "confidence": "4;3;3;3;3",
        "correctness": "3;3;3;3;4",
        "technical_novelty": "3;3;3;2;3",
        "empirical_novelty": "3;3;2;2;3",
        "presentation": "",
        "rating_avg": 6.2,
        "confidence_avg": 3.2,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.8,
        "empirical_novelty_avg": 2.6,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6123724356957947,
        "corr_rating_correctness": 0.9185586535436918,
        "project": "",
        "github": ""
    },
    {
        "id": "PilZY3omXV2",
        "title": "CoST: Contrastive Learning of Disentangled Seasonal-Trend Representations for Time Series Forecasting",
        "track": "main",
        "status": "Poster",
        "keywords": "Time Series;Representation Learning;Forecasting;Self-Supervised Learning",
        "author": "",
        "aff": "",
        "rating": "5;6;6;8",
        "confidence": "4;4;4;3",
        "correctness": "3;4;4;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9271726499455306,
        "corr_rating_correctness": 0.6622661785325219,
        "project": "",
        "github": ""
    },
    {
        "id": "PlFtf_pnkZu",
        "title": "Examining Scaling and Transfer of Language Model Architectures for Machine Translation",
        "track": "main",
        "status": "Reject",
        "keywords": "language modeling;machine translation;prefixlm;causallm;model scaling;zero-shot transfer",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "5;4;4;4",
        "correctness": "4;3;3;3",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9428090415820632,
        "corr_rating_correctness": -0.9428090415820632,
        "project": "",
        "github": ""
    },
    {
        "id": "PlKWVd2yBkY",
        "title": "Pseudo Numerical Methods for Diffusion Models on Manifolds",
        "track": "main",
        "status": "Poster",
        "keywords": "diffusion model;generative model;numerical method;manifold",
        "author": "",
        "aff": "Zhejiang University",
        "rating": "5;5;6;8",
        "confidence": "3;2;2;3",
        "correctness": "3;3;3;4",
        "technical_novelty": "3;3;2;3",
        "empirical_novelty": "4;3;3;4",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 2.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.40824829046386296,
        "corr_rating_correctness": 0.9428090415820632,
        "project": "",
        "github": "https://github.com/luping-liu/PNDM"
    },
    {
        "id": "PnraKzlFvp",
        "title": "Automated hypothesis generation via Evolutionary Abduction",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Causal inference;abduction;evolutionary computation;learning",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "3;4;4;4",
        "correctness": "3;3;2;2",
        "technical_novelty": "2;2;3;1",
        "empirical_novelty": "3;2;2;1",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "Pobz_8y2Q2_",
        "title": "BANANA: a Benchmark for the Assessment of Neural Architectures for Nucleic Acids",
        "track": "main",
        "status": "Reject",
        "keywords": "bioinformatics;language modeling;natural language processing;dataset;benchmark;dna;rna",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5;5",
        "confidence": "4;4;3;4;4",
        "correctness": "2;2;3;2;3",
        "technical_novelty": "2;1;2;1;1",
        "empirical_novelty": "2;1;3;3;3",
        "presentation": "",
        "rating_avg": 4.2,
        "confidence_avg": 3.8,
        "correctness_avg": 2.4,
        "technical_novelty_avg": 1.4,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.40824829046386296,
        "corr_rating_correctness": 0.6666666666666667,
        "project": "",
        "github": ""
    },
    {
        "id": "Ps_m_Uwcu-E",
        "title": "Layer-wise Adaptive Model Aggregation for Scalable Federated Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "federated learning;model aggregation;neural network",
        "author": "",
        "aff": "",
        "rating": "5;5;5;8",
        "confidence": "5;5;4;3",
        "correctness": "3;1;3;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 4.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8703882797784892,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "PtSAD3caaA2",
        "title": "Maximum Entropy RL (Provably) Solves Some Robust RL Problems",
        "track": "main",
        "status": "Poster",
        "keywords": "reinforcement learning;robustness;maximum entropy",
        "author": "",
        "aff": "UC Berkeley, Google Brain; Carnegie Mellon University, Google Brain",
        "rating": "5;6;6;8",
        "confidence": "3;5;3;3",
        "correctness": "2;4;3;3",
        "technical_novelty": "2;3;3;4",
        "empirical_novelty": "2;3;3;2",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.13245323570650439,
        "corr_rating_correctness": 0.3244428422615251,
        "project": "",
        "github": ""
    },
    {
        "id": "PtuQ8bk9xF5",
        "title": "Learning to Act with Affordance-Aware Multimodal Neural SLAM",
        "track": "main",
        "status": "Reject",
        "keywords": "Language-Guided Task Completion;Multimodal learning;Neural SLAM.",
        "author": "",
        "aff": "",
        "rating": "3;5;5",
        "confidence": "4;4;3",
        "correctness": "2;4;3",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 4.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.49999999999999983,
        "corr_rating_correctness": 0.8660254037844385,
        "project": "",
        "github": ""
    },
    {
        "id": "Py8WbvKH_wv",
        "title": "DRIBO: Robust Deep Reinforcement Learning via Multi-View Information Bottleneck",
        "track": "main",
        "status": "Reject",
        "keywords": "Representation Learning;Deep Reinforcement Learning;Information Bottleneck",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "5;3;4;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;3;2",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "PyBp6nFfzuj",
        "title": "UNCERTAINTY QUANTIFICATION USING VARIATIONAL INFERENCE FOR BIOMEDICAL IMAGE SEGMENTATION",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "1;1;1;1",
        "confidence": "5;4;5;3",
        "correctness": "4;2;1;3",
        "technical_novelty": "1;1;1;1",
        "empirical_novelty": "1;1;1;2",
        "presentation": "",
        "rating_avg": 1.0,
        "confidence_avg": 4.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 1.0,
        "empirical_novelty_avg": 1.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "PzcvxEMzvQC",
        "title": "GeoDiff: A Geometric Diffusion Model for Molecular Conformation Generation",
        "track": "main",
        "status": "Oral",
        "keywords": "molecular conformation generation;deep generative models;diffusion probabilistic models",
        "author": "",
        "aff": "Stanford University; Mila - Qu\u00e9bec AI Institute, Universit\u00e9 de Montr\u00e9al; Mila - Qu\u00e9bec AI Institute, HEC Montr\u00e9al, CIFAR AI Research Chair",
        "rating": "6;8;8",
        "confidence": "3;3;5",
        "correctness": "3;4;3",
        "technical_novelty": "3;4;4",
        "empirical_novelty": "3;4;0",
        "presentation": "",
        "rating_avg": 7.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.6666666666666665,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5,
        "corr_rating_correctness": 0.49999999999999983,
        "project": "",
        "github": "https://github.com/MinkaiXu/GeoDiff"
    },
    {
        "id": "Q0n61rV89bi",
        "title": "LEARNING PHONEME-LEVEL DISCRETE SPEECH REPRESENTATION WITH WORD-LEVEL SUPERVISION",
        "track": "main",
        "status": "Withdraw",
        "keywords": "discrete speech representation;self-supervised learning;mutual information",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "2;4;3;3",
        "correctness": "4;3;3;3",
        "technical_novelty": "4;2;2;2",
        "empirical_novelty": "4;2;2;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "Q1XWSM8ftl",
        "title": "Learning rate optimization through step sampling",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Learning Rate Optimization;Hyper-parameter tuning;LR Search;Training Efficiency",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "3;4;4;4",
        "correctness": "2;2;2;2",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "Q1foAP0IL4x",
        "title": "Noisy Adversarial Training",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Adversarial Training;Adversarial;Adversarial Defence;Decision Space",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "5;4;4;4",
        "correctness": "2;2;3;3",
        "technical_novelty": "3;2;2;2",
        "empirical_novelty": "2;2;2;0",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "Q1gackXQrSV",
        "title": "Language Modulated Detection and Detection Modulated Language Grounding in 2D and 3D Scenes",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Language Grounding;Modulated Object Detection;Attention;Vision and Language",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "2;4;3;3",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "3;3;2;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "Q42O1Qaho5N",
        "title": "$G^3$: Representation Learning and Generation for Geometric Graphs",
        "track": "main",
        "status": "Reject",
        "keywords": "Deep Learning;Generative Models;Graph Neural Networks",
        "author": "",
        "aff": "",
        "rating": "3;5;8;8",
        "confidence": "3;2;4;4",
        "correctness": "3;4;4;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.7106690545187014,
        "corr_rating_correctness": 0.8164965809277261,
        "project": "",
        "github": ""
    },
    {
        "id": "Q42f0dfjECO",
        "title": "Differentially Private Fine-tuning of Language Models",
        "track": "main",
        "status": "Poster",
        "keywords": "differential privacy;large language models;fine-tuning",
        "author": "",
        "aff": "Microsoft Research Asia; Sun Yat-sen University\u2020, Microsoft Research Asia; Microsoft Research, University of Washington; Cheriton School of Computer Science, University of Waterloo; Microsoft; Microsoft Research",
        "rating": "6;6;6;8",
        "confidence": "4;5;4;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "3;2;2;2",
        "empirical_novelty": "3;2;4;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 4.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "Q5uh1Nvv5dm",
        "title": "AdaMatch: A Unified Approach to Semi-Supervised Learning and Domain Adaptation",
        "track": "main",
        "status": "Poster",
        "keywords": "unsupervised domain adaptation;semi-supervised learning;semi-supervised domain adaptation",
        "author": "",
        "aff": "Google Research",
        "rating": "5;6;6;8",
        "confidence": "4;4;4;5",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "3;3;4;0",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9271726499455306,
        "corr_rating_correctness": 0.9271726499455306,
        "project": "",
        "github": "https://github.com/google-research/adamatch"
    },
    {
        "id": "Q76Y7wkiji",
        "title": "Boosting the Certified Robustness of L-infinity Distance Nets",
        "track": "main",
        "status": "Poster",
        "keywords": "Adversarial Robustness;Certified Defense;Lipschitz Network",
        "author": "",
        "aff": "",
        "rating": "5;6;6;8",
        "confidence": "3;4;4;4",
        "correctness": "3;4;3;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;4;4;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.6622661785325219,
        "corr_rating_correctness": -0.13245323570650439,
        "project": "",
        "github": ""
    },
    {
        "id": "Q83vFlie_Pr",
        "title": "Bandit Learning with Joint Effect of Incentivized Sampling, Delayed Sampling Feedback, and Self-Reinforcing User Preferences",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;6;6;6",
        "confidence": "4;3;4;4",
        "correctness": "3;4;4;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "3;2;3;0",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "Q8OjAGkxwP5",
        "title": "Limitations of Active Learning With Deep Transformer Language Models",
        "track": "main",
        "status": "Reject",
        "keywords": "Active Learning;Machine Learning;Natural Language Processing",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6;6",
        "confidence": "3;4;3;4;3",
        "correctness": "3;2;3;3;4",
        "technical_novelty": "3;1;2;2;3",
        "empirical_novelty": "2;2;3;2;2",
        "presentation": "",
        "rating_avg": 5.6,
        "confidence_avg": 3.4,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.2,
        "empirical_novelty_avg": 2.2,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.16666666666666666,
        "corr_rating_correctness": 0.6454972243679027,
        "project": "",
        "github": ""
    },
    {
        "id": "QCeFEThVn3",
        "title": "GraphEBM: Towards Permutation Invariant and Multi-Objective Molecular Graph Generation",
        "track": "main",
        "status": "Reject",
        "keywords": "molecular graph generation;energy-based models;permutation invariance;multi-objective",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "3;4;4;3",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "3;3;2;2",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.19245008972987526,
        "corr_rating_correctness": 0.9622504486493761,
        "project": "",
        "github": ""
    },
    {
        "id": "QDDVxweQJy0",
        "title": "Proving Theorems using Incremental Learning and Hindsight Experience Replay",
        "track": "main",
        "status": "Reject",
        "keywords": "theorem proving;incremental learning;hindsight experience replay;transformers",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6;8",
        "confidence": "4;5;3;4;4",
        "correctness": "3;3;3;3;3",
        "technical_novelty": "2;2;2;2;3",
        "empirical_novelty": "2;3;3;3;3",
        "presentation": "",
        "rating_avg": 5.4,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.2,
        "empirical_novelty_avg": 2.8,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "QDdJhACYrlX",
        "title": "THOMAS: Trajectory Heatmap Output with learned Multi-Agent Sampling",
        "track": "main",
        "status": "Poster",
        "keywords": "Trajectory prediction;Multi-agent;Motion forecasting;Motion estimation;Autonomous driving",
        "author": "",
        "aff": "",
        "rating": "6;6;6;6",
        "confidence": "5;4;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "3;2;2;2",
        "empirical_novelty": "2;2;0;2",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "QEBHPRodWYE",
        "title": "InstaHide\u2019s Sample Complexity When Mixing Two Private Images",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;6",
        "confidence": "3;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "0;0;3",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 1.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.4999999999999999,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "QFNIpIrkANz",
        "title": "Learning Invariant Reward Functions through Trajectory Interventions",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5;8",
        "confidence": "4;4;4;3",
        "correctness": "2;4;3;3",
        "technical_novelty": "2;2;3;4",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9169493006161777,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "QJWVP4CTmW4",
        "title": "Ada-NETS: Face Clustering via Adaptive Neighbour Discovery in the Structure Space",
        "track": "main",
        "status": "Poster",
        "keywords": "Face Clustering;Graph Convolutional Networks (GCN);Computer Vision",
        "author": "",
        "aff": "Alibaba Group; Central South University",
        "rating": "3;6;6;8",
        "confidence": "4;4;5;4",
        "correctness": "4;3;2;4",
        "technical_novelty": "2;3;3;4",
        "empirical_novelty": "3;2;3;4",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.08084520834544431,
        "corr_rating_correctness": -0.1266600992762247,
        "project": "",
        "github": "https://github.com/damo-cv/Ada-NETS"
    },
    {
        "id": "QJb1-8NH2Ux",
        "title": "Detecting Adversarial Examples Is (Nearly) As Hard As Classifying Them",
        "track": "main",
        "status": "Reject",
        "keywords": "Adversarial Examples;Detection;Hardness Reductions",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;4;4;4",
        "correctness": "2;3;3;4",
        "technical_novelty": "2;3;4;3",
        "empirical_novelty": "1;3;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9733285267845754,
        "project": "",
        "github": ""
    },
    {
        "id": "QJeN_cqtxvC",
        "title": "DistProp: A Scalable Approach to Lagrangian Training via Distributional Approximation",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "3;3;3;3",
        "correctness": "2;2;2;2",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "1;2;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "QKEkEFpKBBv",
        "title": "DNBP: Differentiable Nonparametric Belief Propagation",
        "track": "main",
        "status": "Reject",
        "keywords": "Belief Propagation;Bayesian Inference;Nonparametric Inference",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "4;3;4;2",
        "correctness": "4;2;3;3",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "https://sites.google.com/view/diff-nbp",
        "github": ""
    },
    {
        "id": "QNW1OrjynpT",
        "title": "Short-term memory in neural language models",
        "track": "main",
        "status": "Reject",
        "keywords": "short-term memory;language models;transformer;lstm;GPT-2",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6;6",
        "confidence": "4;4;4;3;4",
        "correctness": "2;3;3;3;3",
        "technical_novelty": "2;2;2;3;3",
        "empirical_novelty": "2;2;3;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.8,
        "correctness_avg": 2.8,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 2.6,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4564354645876385,
        "corr_rating_correctness": 0.9128709291752771,
        "project": "",
        "github": ""
    },
    {
        "id": "QRX0nCX_gk",
        "title": "Multimeasurement Generative Models",
        "track": "main",
        "status": "Poster",
        "keywords": "energy based models;Langevin MCMC;score matching;denoising autoencoders;empirical Bayes",
        "author": "",
        "aff": "NNAISENSE Inc.; NNAISENSE Inc. and Redwood Center, UC Berkeley",
        "rating": "6;6;8",
        "confidence": "3;4;4",
        "correctness": "3;4;1",
        "technical_novelty": "3;3;1",
        "empirical_novelty": "3;2;3",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.49999999999999983,
        "corr_rating_correctness": -0.9449111825230679,
        "project": "",
        "github": ""
    },
    {
        "id": "QWc35QxXPzZ",
        "title": "The Power of Exploiter: Provable Multi-Agent RL in Large State Spaces",
        "track": "main",
        "status": "Desk Reject",
        "keywords": "theoretical reinforcement learning;Markov games with general function approximation",
        "author": "",
        "aff": "Paper under double-blind review",
        "rating": "",
        "confidence": "",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "QXLWz6AguS",
        "title": "Modular Lagrangian Neural Networks: Designing Structures of Networks with Physical Inductive Biases",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Representation Learning;Physical Inductive Bias;Lagrangian Mechanics;Dynamics;Extrapolation",
        "author": "",
        "aff": "",
        "rating": "1;3;3;3",
        "confidence": "5;3;3;4",
        "correctness": "2;2;3;2",
        "technical_novelty": "1;2;2;2",
        "empirical_novelty": "1;2;2;2",
        "presentation": "",
        "rating_avg": 2.5,
        "confidence_avg": 3.75,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8703882797784891,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "QZTymB-n-Wz",
        "title": "Effective Certification of Monotone Deep Equilibrium Models",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Deep Equilibrium Models;Certified Robustness;Convex Relaxations",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "5;4;4;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;2;2;4",
        "empirical_novelty": "2;2;0;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5555555555555555,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "Qaw16njk6L",
        "title": "NASViT: Neural Architecture Search for Efficient Vision Transformers with Gradient Conflict aware Supernet Training",
        "track": "main",
        "status": "Poster",
        "keywords": "vision transformer;gradient conflict;neural architecture search",
        "author": "",
        "aff": "University of Texas at Austin; Meta Reality Labs",
        "rating": "5;6;6;6;8",
        "confidence": "5;5;3;4;4",
        "correctness": "3;4;3;3;3",
        "technical_novelty": "3;4;3;4;3",
        "empirical_novelty": "3;3;3;3;3",
        "presentation": "",
        "rating_avg": 6.2,
        "confidence_avg": 4.2,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 3.4,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3273268353539886,
        "corr_rating_correctness": -0.10206207261596578,
        "project": "",
        "github": "https://github.com/facebookresearch/NASViT"
    },
    {
        "id": "Qb07sqX7dVl",
        "title": "Label Augmentation with Reinforced Labeling for Weak Supervision",
        "track": "main",
        "status": "Reject",
        "keywords": "weak supervision;data programming",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;5;5;4",
        "correctness": "3;2;2;3",
        "technical_novelty": "3;2;2;2",
        "empirical_novelty": "1;1;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "QbFfqWAEmMr",
        "title": "LASSO: Latent Sub-spaces Orientation for Domain Generalization",
        "track": "main",
        "status": "Reject",
        "keywords": "Domain generalization;Image Classification;machine learning;deep learning",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6;6",
        "confidence": "3;4;5;4;4",
        "correctness": "2;3;3;4;3",
        "technical_novelty": "3;3;2;3;3",
        "empirical_novelty": "2;0;2;3;3",
        "presentation": "",
        "rating_avg": 5.6,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.8,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.6454972243679027,
        "corr_rating_correctness": 0.6454972243679027,
        "project": "",
        "github": ""
    },
    {
        "id": "QdcbUq0-tYM",
        "title": "Universal Controllers with Differentiable Physics for Online System Identification",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "Paper under double-blind review",
        "rating": "5;5;5;6",
        "confidence": "4;4;2;4",
        "correctness": "2;4;4;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": -0.17407765595569782,
        "project": "",
        "github": ""
    },
    {
        "id": "QevkqHTK3DJ",
        "title": "Compressing Transformer-Based Sequence to Sequence Models With Pre-trained Autoencoders for Text Summarization",
        "track": "main",
        "status": "Reject",
        "keywords": "Transformer;Automatic Text Summarization;sequence-to-sequence;Compression",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;4;3;3",
        "correctness": "3;2;2;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "Qg2vi4ZbHM9",
        "title": "StyleAlign: Analysis and Applications of Aligned StyleGAN Models",
        "track": "main",
        "status": "Oral",
        "keywords": "StyleGAN;transfer learning;fine tuning;model alignment;image-to-image translation;image morphing",
        "author": "",
        "aff": "Adobe Research; The Hebrew University; Tel-Aviv University",
        "rating": "6;8;8;8",
        "confidence": "5;4;4;4",
        "correctness": "3;4;3;4",
        "technical_novelty": "2;2;3;4",
        "empirical_novelty": "3;4;3;4",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 4.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "QguFu30t0d",
        "title": "FedGEMS: Federated Learning of Larger Server Models via Selective Knowledge Fusion",
        "track": "main",
        "status": "Reject",
        "keywords": "Federated Learning;Knowledge Distillation",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "4;4;4;3",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4714045207910316,
        "corr_rating_correctness": 0.9428090415820632,
        "project": "",
        "github": ""
    },
    {
        "id": "QhHMf5J5Jom",
        "title": "A Scaling Law for Syn-to-Real Transfer: How Much Is Your Pre-training Effective?",
        "track": "main",
        "status": "Reject",
        "keywords": "Transfer learning;Computer vision;Scaling law;Pre-training;Synthetic-to-real",
        "author": "",
        "aff": "",
        "rating": "3;5;6",
        "confidence": "3;3;3",
        "correctness": "2;3;3",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "1;2;3",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 3.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9449111825230683,
        "project": "",
        "github": ""
    },
    {
        "id": "QiM-fYm3gb7",
        "title": "McXai: Local model-agnostic explanation as two games",
        "track": "main",
        "status": "Withdraw",
        "keywords": "explainable AI;reinforcement learning;Monte Carlo tree search",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "3;4;3;4",
        "correctness": "3;2;2;2",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.5,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "QjOQkpzKbNk",
        "title": "Distilling GANs with Style-Mixed Triplets for X2I Translation with Limited Data",
        "track": "main",
        "status": "Poster",
        "keywords": "Transfer learning;image synthesis;limited data.",
        "author": "",
        "aff": "College of Computer Science, Nankai University, China; Computer Vision Center, Universitat Aut `onoma de Barcelona, Spain; School of Computer Science and Engineering, Tianjin University of Technology, China; Huawei Kirin Solution, China",
        "rating": "5;6;8",
        "confidence": "4;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 6.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.18898223650461363,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/yaxingwang/KDIT"
    },
    {
        "id": "QkRV50TZyP",
        "title": "Beyond ImageNet Attack: Towards Crafting Adversarial Examples for Black-box Domains",
        "track": "main",
        "status": "Poster",
        "keywords": "practice black-box attack;cross-domain transferability",
        "author": "",
        "aff": "University of Electronic Science and Technology of China, China; Alibaba Group, China",
        "rating": "6;6;8",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "3;3;2",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/Alibaba-AAIG/Beyond-ImageNet-Attack"
    },
    {
        "id": "QkfMWTl520U",
        "title": "When do Convolutional Neural Networks Stop Learning?",
        "track": "main",
        "status": "Reject",
        "keywords": "Deep Learning;Convolutional Neural Network;CNN;Epoch;Training;Data",
        "author": "",
        "aff": "",
        "rating": "1;3;5;5",
        "confidence": "5;4;4;5",
        "correctness": "1;2;3;2",
        "technical_novelty": "1;3;2;3",
        "empirical_novelty": "1;2;2;3",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.5,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.30151134457776363,
        "corr_rating_correctness": 0.8528028654224417,
        "project": "",
        "github": "https://github.com/PaperUnderReviewDeepLearning/Optimization"
    },
    {
        "id": "QmKblFEgQJ",
        "title": "DIGRAC: Digraph Clustering Based on Flow Imbalance",
        "track": "main",
        "status": "Reject",
        "keywords": "flow imbalance;directed networks;graph neural networks;clustering;directed stochastic block models",
        "author": "",
        "aff": "",
        "rating": "3;5;5",
        "confidence": "3;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 4.333333333333333,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.49999999999999983,
        "corr_rating_correctness": 0.49999999999999983,
        "project": "",
        "github": ""
    },
    {
        "id": "QuObT9BTWo",
        "title": "Pareto Set Learning for Neural Multi-Objective Combinatorial Optimization",
        "track": "main",
        "status": "Poster",
        "keywords": "Multiobjective Combinatorial Optimization;Combinatorial Optimization;Neural Combinatorial Optimization;Multiobjective Optimization",
        "author": "",
        "aff": "Department of Computer Science, City University of Hong Kong",
        "rating": "6;6;6;8",
        "confidence": "4;2;3;3",
        "correctness": "3;4;3;4",
        "technical_novelty": "3;3;3;4",
        "empirical_novelty": "4;3;3;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "Qu_XudmGajz",
        "title": "Structured Uncertainty in the Observation Space of Variational Autoencoders",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "4;4;4;4",
        "correctness": "2;4;4;3",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "3;2;3;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.7385489458759963,
        "project": "",
        "github": ""
    },
    {
        "id": "QvTH9nN2Io",
        "title": "Relative Entropy Gradient Sampler for Unnormalized Distributions",
        "track": "main",
        "status": "Reject",
        "keywords": "Density ratio estimation;gradient flow;neural networks;particles;velocity fields",
        "author": "",
        "aff": "",
        "rating": "1;3;5;5",
        "confidence": "5;4;3;4",
        "correctness": "2;3;1;3",
        "technical_novelty": "2;3;2;2",
        "empirical_novelty": "2;2;4;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.0,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8528028654224417,
        "corr_rating_correctness": -0.0909090909090909,
        "project": "",
        "github": ""
    },
    {
        "id": "Qx0EswNY_bW",
        "title": "Modeling Variable Space with Residual Tensor Networks for Multivariate Time Series",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Multivariate Time Series;Variable Space;Tensor Network;N-Order Residual Connection",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "3;3;4;3",
        "correctness": "3;2;2;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;1;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "QyX0pa4CDRM",
        "title": "Continual Learning via Low-Rank Network Updates",
        "track": "main",
        "status": "Withdraw",
        "keywords": "continual learning;low-rank networks;rank-one update;multitask learning;task-incremental learning",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;4;5;4",
        "correctness": "4;2;3;3",
        "technical_novelty": "3;1;2;3",
        "empirical_novelty": "2;1;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "Qycd9j5Qp9J",
        "title": "Understanding the Variance Collapse of SVGD in High Dimensions",
        "track": "main",
        "status": "Poster",
        "keywords": "Stein Variational Gradient Descent;Approximate Inference;Particle-based Variational Inference",
        "author": "",
        "aff": "University of Tokyo, RIKEN AIP; Tsinghua University; University of Toronto, Vector Institute",
        "rating": "6;6;6;8",
        "confidence": "4;3;3;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "QymmlaKpp_8",
        "title": "Inductive-Biases for Contrastive Learning of Disentangled Representations",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5",
        "confidence": "3;5;3",
        "correctness": "3;3;3",
        "technical_novelty": "2;2;4",
        "empirical_novelty": "4;1;2",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5000000000000001,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "R-I5CUDOAp7",
        "title": "STORM: Sketch Toward Online Risk Minimization",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "3;4;3;4",
        "correctness": "4;3;2;3",
        "technical_novelty": "1;3;2;3",
        "empirical_novelty": "1;0;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.6882472016116854,
        "corr_rating_correctness": -0.6488856845230502,
        "project": "",
        "github": ""
    },
    {
        "id": "R-piejobttn",
        "title": "Mixture Representation Learning with Coupled Autoencoders",
        "track": "main",
        "status": "Reject",
        "keywords": "Mixture representation;high-dimensional categorical variable;unsupervised learning;constrained variational framework;neuronal diversity;single-cell RNA sequencing;cell types",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5;8",
        "confidence": "3;4;5;4;4",
        "correctness": "4;2;2;3;4",
        "technical_novelty": "2;3;3;2;3",
        "empirical_novelty": "2;3;2;2;3",
        "presentation": "",
        "rating_avg": 5.6,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5590169943749475,
        "project": "",
        "github": ""
    },
    {
        "id": "R0AzpCND-M_",
        "title": "Model-Agnostic Meta-Attack: Towards Reliable Evaluation of Adversarial Robustness",
        "track": "main",
        "status": "Reject",
        "keywords": "Adversarial attacks;robust evaluation",
        "author": "",
        "aff": "",
        "rating": "3;6;6",
        "confidence": "3;2;4",
        "correctness": "3;4;4",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "R0xRE2MU2uA",
        "title": "Graph Piece: Efficiently Generating High-Quality Molecular Graphs with Substructures",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "4;4;4;3",
        "correctness": "3;2;4;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7777777777777777,
        "corr_rating_correctness": 0.8703882797784892,
        "project": "",
        "github": ""
    },
    {
        "id": "R11xJsRjA-W",
        "title": "The Connection between Out-of-Distribution Generalization and Privacy of ML Models",
        "track": "main",
        "status": "Reject",
        "keywords": "membership inference attacks;privacy attacks;model privacy;out-of-distribution generalization;domain generalization",
        "author": "",
        "aff": "",
        "rating": "1;3;5;5",
        "confidence": "4;4;3;3",
        "correctness": "2;2;3;3",
        "technical_novelty": "1;2;3;2",
        "empirical_novelty": "1;3;2;3",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9045340337332909,
        "corr_rating_correctness": 0.9045340337332909,
        "project": "",
        "github": ""
    },
    {
        "id": "R2AN-rz4j_X",
        "title": "Continual Learning in Deep Networks: an Analysis of the Last Layer",
        "track": "main",
        "status": "Reject",
        "keywords": "Continual Learning;Linear Models",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;4;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;2;1",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "R2aCiGQ9Qc",
        "title": "Two Sides of the Same Coin: Heterophily and Oversmoothing in Graph Convolutional Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "graph convolutional neural networks;node classification;heterophily;oversmoothing",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "3;5;3;3",
        "correctness": "2;2;3;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;0;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.8164965809277259,
        "project": "",
        "github": ""
    },
    {
        "id": "R332S76RjxS",
        "title": "A global convergence theory for deep ReLU implicit networks via over-parameterization",
        "track": "main",
        "status": "Poster",
        "keywords": "Deep learning;Deep implicit learning;deep equilibrium model;gradient descent;stochastic gradient descent;over-parameterization",
        "author": "",
        "aff": "Department of Computer Science, Iowa State University; Dept. of Electrical and Computer Engineering, The Ohio State University; Department of Mathematics, Iowa State University",
        "rating": "3;6;8;8",
        "confidence": "4;2;3;3",
        "correctness": "3;4;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "0;0;0;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 0.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5183210553488161,
        "corr_rating_correctness": 0.9169493006161777,
        "project": "",
        "github": ""
    },
    {
        "id": "R3Y9yq49seb",
        "title": "Wavelet Feature Maps Compression for Low Bandwidth Convolutional Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "Convolutional Neural Networks;Quantization;Wavelet Transform",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "4;4;4;4",
        "correctness": "3;3;2;3",
        "technical_novelty": "1;2;2;3",
        "empirical_novelty": "2;2;4;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "R3zqNwzAVsC",
        "title": "Learning an Ethical Module for Bias Mitigation of pre-trained Models",
        "track": "main",
        "status": "Reject",
        "keywords": "Deep Learning;Bias;Fairness;Facial Recognition.",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5",
        "confidence": "4;4;3;3",
        "correctness": "4;3;3;3",
        "technical_novelty": "4;2;3;4",
        "empirical_novelty": "4;2;3;4",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "R5sVzzXhW8n",
        "title": "Demystifying How Self-Supervised Features Improve Training from Noisy Labels",
        "track": "main",
        "status": "Reject",
        "keywords": "Learning with noisy labels;Self-Supervised Learning",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "2;4;4;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "R612wi_C-7w",
        "title": "Stable cognitive maps for Path Integration emerge from fusing visual and proprioceptive sensors",
        "track": "main",
        "status": "Reject",
        "keywords": "RNNs",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5;5",
        "confidence": "3;4;4;2;3",
        "correctness": "2;2;1;2;2",
        "technical_novelty": "2;2;2;2;2",
        "empirical_novelty": "2;1;3;1;3",
        "presentation": "",
        "rating_avg": 4.2,
        "confidence_avg": 3.2,
        "correctness_avg": 1.8,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3273268353539886,
        "corr_rating_correctness": -0.4082482904638631,
        "project": "",
        "github": ""
    },
    {
        "id": "R6hvtDTQmb",
        "title": "Adapting Stepsizes by Momentumized Gradients Improves Optimization and Generalization",
        "track": "main",
        "status": "Reject",
        "keywords": "Deep Learning Optimizer;Neural Network Optimization;Neural Network Generalization",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "5;5;3;2",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.5555555555555555,
        "project": "",
        "github": "https://anonymous.4open.science/r/AdaMomentum_experiments-6D9B"
    },
    {
        "id": "R79ZGjHhv6p",
        "title": "Toward Faithful Case-based Reasoning through Learning Prototypes in a Nearest Neighbor-friendly Space.",
        "track": "main",
        "status": "Poster",
        "keywords": "case-based reasoning;interpretable machine learning;explainable artificial intelligence;xai;prototype learning",
        "author": "",
        "aff": "School of Computer Science, Carleton University, Ottawa, ON, Canada",
        "rating": "6;6;8",
        "confidence": "4;3;4",
        "correctness": "4;3;4",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "3;1;3",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.49999999999999983,
        "corr_rating_correctness": 0.49999999999999983,
        "project": "",
        "github": ""
    },
    {
        "id": "R7APxKhg8dt",
        "title": "CoSe-Co: Text Conditioned Generative CommonSense Contextualizer",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Language Model;Commonsense;Knowledge Graph;Task Agnostic;Novel Sentence-to-Path Dataset",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "3;4;3;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;3;1;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "R7vPG65hcs",
        "title": "Ambiguity Adaptive Inference and Single-shot based Channel Pruning for Satellite Processing Environments",
        "track": "main",
        "status": "Withdraw",
        "keywords": "ambiguity;inference;single-shot channel pruning;satellite on-board processing",
        "author": "",
        "aff": "",
        "rating": "1;1;6",
        "confidence": "4;4;3",
        "correctness": "1;1;3",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "1;1;3",
        "presentation": "",
        "rating_avg": 2.6666666666666665,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 1.6666666666666667,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9999999999999998,
        "corr_rating_correctness": 0.9999999999999998,
        "project": "",
        "github": ""
    },
    {
        "id": "R8sQPpGCv0",
        "title": "Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "Facebook AI Research; Paul G. Allen School of Computer Science & Engineering, University of Washington",
        "rating": "6;8;8;8",
        "confidence": "4;4;5;4",
        "correctness": "3;4;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 4.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": "https://github.com/ofirpress/attention_with_linear_biases"
    },
    {
        "id": "R9Ht8RZK3qY",
        "title": "FED-$\\chi^2$: Secure Federated Correlation Test",
        "track": "main",
        "status": "Reject",
        "keywords": "Federated Analytics;Hypothesis Test",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "2;2;2;2",
        "correctness": "2;3;3;3",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "3;2;0;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 2.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "RA-zVvZLYIy",
        "title": "MLP-based architecture with variable length input for automatic speech recognition",
        "track": "main",
        "status": "Reject",
        "keywords": "MLP;automatic speech recognition",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "4;3;2;3",
        "correctness": "2;3;3;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8660254037844386,
        "corr_rating_correctness": 0.8660254037844386,
        "project": "",
        "github": ""
    },
    {
        "id": "RAW9tCdVxLj",
        "title": "Zero-CL: Instance and Feature decorrelation for negative-free symmetric contrastive learning",
        "track": "main",
        "status": "Poster",
        "keywords": "Self supervised learning;representation learning",
        "author": "",
        "aff": "Shanghai Jiao Tong University, SenseTime Research; Shanghai Jiao Tong University; SenseTime Research",
        "rating": "5;6;6;8",
        "confidence": "4;4;2;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3458572319330373,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "RAoBtzlwtCC",
        "title": "Provable Federated Adversarial Learning via Min-max Optimization",
        "track": "main",
        "status": "Reject",
        "keywords": "Federated Learning;Adversarial Training;Optimization;Non-Convex",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5;5",
        "confidence": "3;3;3;3;3",
        "correctness": "3;3;4;3;4",
        "technical_novelty": "2;2;2;3;2",
        "empirical_novelty": "0;2;0;0;0",
        "presentation": "",
        "rating_avg": 3.8,
        "confidence_avg": 3.0,
        "correctness_avg": 3.4,
        "technical_novelty_avg": 2.2,
        "empirical_novelty_avg": 0.4,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.16666666666666663,
        "project": "",
        "github": ""
    },
    {
        "id": "RB_2cor6d-w",
        "title": "Towards Physical, Imperceptible Adversarial Attacks via Adversarial Programs",
        "track": "main",
        "status": "Reject",
        "keywords": "Adversarial Attacks;Adversarial Patches;Adversarial Programs;Program Synthesis",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6;6",
        "confidence": "5;4;4;5;4",
        "correctness": "3;3;3;4;3",
        "technical_novelty": "2;2;2;2;3",
        "empirical_novelty": "1;1;2;2;3",
        "presentation": "",
        "rating_avg": 4.6,
        "confidence_avg": 4.4,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.2,
        "empirical_novelty_avg": 1.8,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.06019292654288455,
        "corr_rating_correctness": 0.5160468465421401,
        "project": "",
        "github": ""
    },
    {
        "id": "RCZqv9NXlZ",
        "title": "Offline Reinforcement Learning with Value-based Episodic Memory",
        "track": "main",
        "status": "Poster",
        "keywords": "Reinforcement Learning;Offline Learning;Episodic Memory Control",
        "author": "",
        "aff": "Institute for Interdisciplinary Information Sciences, Tsinghua University; Department of Automation, Tsinghua University",
        "rating": "5;6;6;8;8;8",
        "confidence": "3;5;3;4;4;4",
        "correctness": "4;3;3;4;4;3",
        "technical_novelty": "3;3;2;3;3;2",
        "empirical_novelty": "3;3;3;2;3;0",
        "presentation": "",
        "rating_avg": 6.833333333333333,
        "confidence_avg": 3.8333333333333335,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3664631325590232,
        "corr_rating_correctness": 0.13736056394868904,
        "project": "",
        "github": "https://github.com/YiqinYang/VEM"
    },
    {
        "id": "RCyHECZIUFb",
        "title": "Explaining Knowledge Graph Embedding via Latent Rule Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "knowledge graph embedding;explainable AI;rule learning",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "3;4;5;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.7071067811865475,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "RDlLMjLJXdq",
        "title": "Learning Temporally Causal Latent Processes from General Temporal Data",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "Southeast University, Nanjing, China; Carnegie Mellon University, Pittsburgh PA, USA; Rice University, Houston TX, USA; Mohamed bin Zayed University of Artificial Intelligence, Abu Dhabi, United Arab Emirates",
        "rating": "6;6;6;8",
        "confidence": "2;3;3;3",
        "correctness": "3;4;4;3",
        "technical_novelty": "3;3;3;4",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 2.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": "https://github.com/weirayao/leap"
    },
    {
        "id": "RFGkzxMFqby",
        "title": "Adversarially Trained Models with Test-Time Covariate Shift Adaptation",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Adversarial Training;Certified Robustness",
        "author": "",
        "aff": "",
        "rating": "3;6;8",
        "confidence": "4;3;3",
        "correctness": "2;4;4",
        "technical_novelty": "2;3;4",
        "empirical_novelty": "2;2;4",
        "presentation": "",
        "rating_avg": 5.666666666666667,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9176629354822472,
        "corr_rating_correctness": 0.9176629354822472,
        "project": "",
        "github": ""
    },
    {
        "id": "RGrj2uWTLWY",
        "title": "PI-GNN: Towards Robust Semi-Supervised Node Classification against Noisy Labels",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;4;3;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "RJkAHKp7kNZ",
        "title": "Vision-Based Manipulators Need to Also See from Their Hands",
        "track": "main",
        "status": "Oral",
        "keywords": "reinforcement learning;observation space;out-of-distribution generalization;visuomotor control;robotics;manipulation",
        "author": "",
        "aff": "Stanford University",
        "rating": "8;8;8",
        "confidence": "4;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "3;2;4",
        "empirical_novelty": "3;2;4",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "https://sites.google.com/view/seeing-from-hands",
        "github": ""
    },
    {
        "id": "RLtqs6pzj1-",
        "title": "Deep Ensembling with No Overhead for either Training or Testing: The All-Round Blessings of Dynamic Sparsity",
        "track": "main",
        "status": "Poster",
        "keywords": "efficient ensemble;FreeTickets;dynamic sparse training;deep ensemble;dynamic sparsity",
        "author": "",
        "aff": "Eindhoven University of Technology, University of Twente; University of Texas at Austin; Eindhoven University of Technology; University of Twente",
        "rating": "5;6;6;6",
        "confidence": "4;4;4;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "3;2;2;4",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": "https://github.com/VITA-Group/FreeTickets"
    },
    {
        "id": "RMv-5wMMrE3",
        "title": "Cell2State: Learning Cell State Representations From Barcoded Single-Cell Gene-Expression Transitions",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "3;4;4;5",
        "correctness": "3;1;3;3",
        "technical_novelty": "2;3;3;4",
        "empirical_novelty": "2;0;2;4",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 4.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.816496580927726,
        "corr_rating_correctness": 0.5555555555555555,
        "project": "",
        "github": ""
    },
    {
        "id": "RNf9AgtRtL",
        "title": "Continuous Control With Ensemble Deep Deterministic Policy Gradients",
        "track": "main",
        "status": "Reject",
        "keywords": "deep learning;reinforcement learning;ensemble learning;MuJoCo;continuous control;stable performance;deterministic policy gradient",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6;6",
        "confidence": "2;4;3;4;5",
        "correctness": "2;3;4;3;3",
        "technical_novelty": "2;2;2;2;3",
        "empirical_novelty": "3;2;2;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.2,
        "empirical_novelty_avg": 2.6,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8951435925492911,
        "corr_rating_correctness": 0.5773502691896258,
        "project": "",
        "github": "https://github.com/ed2-paper/ED2"
    },
    {
        "id": "RNnKhz25N1O",
        "title": "Low-Cost Algorithmic Recourse for Users With Uncertain Cost Functions",
        "track": "main",
        "status": "Reject",
        "keywords": "Explainability;Interpretability;Counterfactuals;Algorithmic Recourse;Black-box Models;Machine Learning;Accountability;Consumer Protection;Adverse Action Notices",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "3;3;3;2",
        "correctness": "2;2;3;3",
        "technical_novelty": "3;2;3;4",
        "empirical_novelty": "3;2;2;4",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 2.75,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7777777777777777,
        "corr_rating_correctness": 0.9622504486493761,
        "project": "",
        "github": ""
    },
    {
        "id": "ROpoUxw23oP",
        "title": "Differentiable Hyper-parameter Optimization",
        "track": "main",
        "status": "Reject",
        "keywords": "Hyper-parameter Optimization",
        "author": "",
        "aff": "",
        "rating": "1;3;3;5",
        "confidence": "5;4;5;3",
        "correctness": "3;3;1;2",
        "technical_novelty": "1;2;1;2",
        "empirical_novelty": "1;2;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.25,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 1.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8528028654224418,
        "corr_rating_correctness": -0.4264014327112209,
        "project": "",
        "github": ""
    },
    {
        "id": "ROteIE-4A6W",
        "title": "MA-CLIP: Towards Modality-Agnostic Contrastive Language-Image Pre-training",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;8",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "2;2;4",
        "empirical_novelty": "2;2;4",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.1147078669352809,
        "project": "",
        "github": ""
    },
    {
        "id": "RQ3xUXjZWMO",
        "title": "Implicit Jacobian regularization weighted with impurity of probability output",
        "track": "main",
        "status": "Reject",
        "keywords": "deep learning;gradient descent;implicit bias;implicit regularization;Hessian;sharpness",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;5;3",
        "correctness": "2;3;4;2",
        "technical_novelty": "1;2;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.30151134457776363,
        "project": "",
        "github": ""
    },
    {
        "id": "RQ428ZptQfU",
        "title": "A Deep Variational Approach to Clustering Survival Data",
        "track": "main",
        "status": "Poster",
        "keywords": "survival analysis;clustering;healthcare;variational autoencoders;deep generative models",
        "author": "",
        "aff": "University Children\u2019s Hospital Basel; Politecnico di Milano; CADS, Human Technopole; St. Gallen Cantonal Hospital; University of Z\u00fcrich; ETH Z\u00fcrich; University Hospital Basel",
        "rating": "6;8;8;8",
        "confidence": "4;3;4;2",
        "correctness": "3;4;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "3;4;4;3",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5222329678670935,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "RQIvNJDHwy",
        "title": "Improving Neural Network Generalization via Promoting Within-Layer Diversity",
        "track": "main",
        "status": "Reject",
        "keywords": "deep learning;regularization;overfitting;learning theory;neural network",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5;5",
        "confidence": "4;3;3;4;4",
        "correctness": "3;3;3;3;3",
        "technical_novelty": "2;2;2;3;2",
        "empirical_novelty": "2;2;2;3;2",
        "presentation": "",
        "rating_avg": 4.2,
        "confidence_avg": 3.6,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.2,
        "empirical_novelty_avg": 2.2,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.16666666666666663,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "RQLLzMCefQu",
        "title": "Provably Filtering Exogenous Distractors using Multistep Inverse Dynamics",
        "track": "main",
        "status": "Oral",
        "keywords": "Reinforcement Learning Theory;Invariant Representation;Rich Observation Reinforcement Learning;Exogenous Noise;Inverse Dynamics",
        "author": "",
        "aff": "Google; Microsoft Research, New York, NY",
        "rating": "8;8;8;8",
        "confidence": "5;3;3;2",
        "correctness": "4;4;3;4",
        "technical_novelty": "3;3;2;3",
        "empirical_novelty": "3;3;3;2",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "RRGVCN8kjim",
        "title": "Sparse DETR: Efficient End-to-End Object Detection with Learnable Sparsity",
        "track": "main",
        "status": "Poster",
        "keywords": "Transformer Query Sparsification Mechanism;Efficient End-to-End Object Detection",
        "author": "",
        "aff": "Lunit; KakaoBrain",
        "rating": "5;6;8;8",
        "confidence": "5;5;5;5",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;3;4;3",
        "empirical_novelty": "2;3;4;3",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 5.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5555555555555555,
        "project": "",
        "github": "https://github.com/kakaobrain/sparse-detr"
    },
    {
        "id": "RRj7DcsPjT",
        "title": "Revisiting Layer-wise Sampling in Fast Training for Graph Convolutional Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "GCN;efficient GCN;sampling",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "5;3;4;2",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9233805168766388,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "RSd79AULOu",
        "title": "Fairness-aware Federated Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Learning Theory",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;4;4;2",
        "correctness": "2;3;2;3",
        "technical_novelty": "1;2;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "RShaMexjc-x",
        "title": "Semi-relaxed Gromov-Wasserstein divergence and applications on graphs",
        "track": "main",
        "status": "Poster",
        "keywords": "Optimal Transport;Graph Learning",
        "author": "",
        "aff": "MSI3; Univ. Lyon, Inria, CNRS, ENS de Lyon, LIP UMR 5668; Univ. C \u02c6ote d\u2019Azur, Inria, Maasai, CNRS, LJAD; Univ. Bretagne-Suf, CNRS, IRISA; IP Paris, CMAP, UMR 7641",
        "rating": "5;6;6;8",
        "confidence": "3;2;4;4",
        "correctness": "4;3;3;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.48420012470625223,
        "corr_rating_correctness": 0.2294157338705618,
        "project": "",
        "github": ""
    },
    {
        "id": "RVdN1-eDZ1b",
        "title": "Plug-In Inversion: Model-Agnostic Inversion for Vision with Data Augmentations",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "4;4;3;4",
        "correctness": "2;3;4;3",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "1;2;3;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4714045207910316,
        "corr_rating_correctness": 0.8660254037844386,
        "project": "",
        "github": ""
    },
    {
        "id": "RW_GTtTfHJ6",
        "title": "Causal Reinforcement Learning using Observational and Interventional Data",
        "track": "main",
        "status": "Reject",
        "keywords": "reinforcement learning;causality;confounding",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "3;3;4;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;3;2;2",
        "empirical_novelty": "2;3;2;1",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "RXQ-FPbQYVn",
        "title": "Anti-Concentrated Confidence Bonuses For Scalable Exploration",
        "track": "main",
        "status": "Poster",
        "keywords": "deep reinforcement learning;reinforcement learning;bandits;exploration",
        "author": "",
        "aff": "Microsoft Research NYC; Microsoft Research NYC, Harvard University",
        "rating": "5;6;8",
        "confidence": "3;4;4",
        "correctness": "2;4;4",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "2;3;4",
        "presentation": "",
        "rating_avg": 6.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.7559289460184545,
        "corr_rating_correctness": 0.7559289460184546,
        "project": "",
        "github": ""
    },
    {
        "id": "RYTBAtyXqJ",
        "title": "Cartoon Explanations of Image Classifiers",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Explainable AI;Image Classification;Wavelets",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "3;4;4;4",
        "correctness": "2;2;4;3",
        "technical_novelty": "2;2;3;4",
        "empirical_novelty": "1;2;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5555555555555555,
        "corr_rating_correctness": 0.7543365091413573,
        "project": "",
        "github": ""
    },
    {
        "id": "RbVp8ieInU7",
        "title": "Low-rank Matrix Recovery with Unknown Correspondence",
        "track": "main",
        "status": "Reject",
        "keywords": "low-rank matrix recovery;optimal transport;min-max optimization;permutation matrix",
        "author": "",
        "aff": "",
        "rating": "5;6;8;10",
        "confidence": "3;5;3;3",
        "correctness": "3;3;4;4",
        "technical_novelty": "3;3;3;4",
        "empirical_novelty": "3;3;3;4",
        "presentation": "",
        "rating_avg": 7.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3758230140014144,
        "corr_rating_correctness": 0.911322376865767,
        "project": "",
        "github": ""
    },
    {
        "id": "RdJVFCHjUMI",
        "title": "An Explanation of In-context Learning as Implicit Bayesian Inference",
        "track": "main",
        "status": "Poster",
        "keywords": "in-context learning;language modeling;pre-training;GPT-3",
        "author": "",
        "aff": "Stanford University",
        "rating": "6;6;6;6",
        "confidence": "4;3;3;4",
        "correctness": "4;4;3;3",
        "technical_novelty": "3;3;4;4",
        "empirical_novelty": "2;3;2;4",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/"
    },
    {
        "id": "Rf58LPCwJj0",
        "title": "Optimal Representations for Covariate Shift",
        "track": "main",
        "status": "Poster",
        "keywords": "distribution shift;domain generalization;representation learning;self-supervised learning;invariance;robustness",
        "author": "",
        "aff": "University of Toronto & Vector Institute",
        "rating": "5;6;8",
        "confidence": "3;3;3",
        "correctness": "3;4;4",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 6.333333333333333,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.7559289460184545,
        "project": "",
        "github": "https://github.com/ryoungj/optdom"
    },
    {
        "id": "RftryyYyjiG",
        "title": "Exploring extreme parameter compression for pre-trained language models",
        "track": "main",
        "status": "Poster",
        "keywords": "pre-trained language models;tensor decomposition;compression;BERT",
        "author": "",
        "aff": "Huawei Noah\u2019s Ark Lab; University of Padua; Tsinghua University",
        "rating": "5;6;6;6",
        "confidence": "4;4;5;4",
        "correctness": "2;2;3;3",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "1;3;2;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 4.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": "https://github.com/twinkle0331/Xcompression"
    },
    {
        "id": "Rh3khfuQUYk",
        "title": "Iterative Decoding for Compositional Generalization in Transformers",
        "track": "main",
        "status": "Reject",
        "keywords": "compositional generalization;transformer;compositionality;deep learning;NLP",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;4;4;5",
        "correctness": "3;2;3;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "1;0;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 1.0,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "RhB1AdoFfGE",
        "title": "Sample and Computation Redistribution for Efficient Face Detection",
        "track": "main",
        "status": "Poster",
        "keywords": "efficient face detection;computation redistribution;sample redistribution",
        "author": "",
        "aff": "Imperial College London; InsightFace; Huawei",
        "rating": "6;6;8;8",
        "confidence": "3;3;3;3",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;2;4;3",
        "empirical_novelty": "3;3;4;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": "https://github.com/deepinsight/insightface/tree/master/detection/scrfd"
    },
    {
        "id": "Rivn22SJjg9",
        "title": "Contrastive Embeddings for Neural Architectures",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5",
        "confidence": "3;4;4",
        "correctness": "3;4;2",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "3;3;2",
        "presentation": "",
        "rating_avg": 4.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9999999999999998,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "Rj-x5_ej6B",
        "title": "Partial Information as Full: Reward Imputation with Sketching in Bandits",
        "track": "main",
        "status": "Reject",
        "keywords": "reward imputation;bandit;sketching;regret analysis",
        "author": "",
        "aff": "",
        "rating": "5;5;6",
        "confidence": "4;4;4",
        "correctness": "2;3;4",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.8660254037844385,
        "project": "",
        "github": ""
    },
    {
        "id": "Rj2qQDm_rxe",
        "title": "KIMERA: Injecting Domain Knowledge into Vacant Transformer Heads",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Transformer;Domain Adaption;Medical;Clinical;Attention",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "4;5;4;3",
        "correctness": "3;3;4;3",
        "technical_novelty": "3;3;3;2",
        "empirical_novelty": "3;3;4;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7071067811865475,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "RjMtFbmETG",
        "title": "Resmax: An Alternative Soft-Greedy Operator for Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "exploration;reinforcement learning;action-value methods;soft-greedy operator;softmax;mellowmax;epsilon-greedy;suboptimality gap",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "4;3;4;5",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.28867513459481287,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "RmzNH3A1cWc",
        "title": "Hardware-Aware Network Transformation",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Model Compression;NAS;Neural Network Acceleration",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;3;4;4",
        "correctness": "1;3;4;3",
        "technical_novelty": "3;3;2;3",
        "empirical_novelty": "1;2;3;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.13245323570650439,
        "corr_rating_correctness": 0.7894736842105263,
        "project": "",
        "github": ""
    },
    {
        "id": "Rnk6NRGudTa",
        "title": "Parameterizing Activation Functions for Adversarial Robustness",
        "track": "main",
        "status": "Withdraw",
        "keywords": "activation functions;adversarial training",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;4;5;4",
        "correctness": "2;3;3;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "1;3;3;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 4.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "Ro_zAjZppv",
        "title": "Tracking the risk of a deployed model and detecting harmful distribution shifts",
        "track": "main",
        "status": "Poster",
        "keywords": "Distribution shift;sequential testing",
        "author": "",
        "aff": "Department of Statistics & Data Science, Machine Learning Department, Carnegie Mellon University",
        "rating": "6;6;6;8;8",
        "confidence": "2;3;3;3;4",
        "correctness": "4;4;3;4;4",
        "technical_novelty": "3;2;2;4;2",
        "empirical_novelty": "3;2;2;3;4",
        "presentation": "",
        "rating_avg": 6.8,
        "confidence_avg": 3.0,
        "correctness_avg": 3.8,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 2.8,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.6454972243679028,
        "corr_rating_correctness": 0.408248290463863,
        "project": "",
        "github": ""
    },
    {
        "id": "RriDjddCLN",
        "title": "Language-driven Semantic Segmentation",
        "track": "main",
        "status": "Poster",
        "keywords": "language-driven;semantic segmentation;zero-shot;transformer",
        "author": "",
        "aff": "Intel Labs; University of Copenhagen; Cornell University, Cornell Tech; Cornell University; Apple",
        "rating": "5;6;8",
        "confidence": "4;3;3",
        "correctness": "2;4;4",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 6.333333333333333,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7559289460184545,
        "corr_rating_correctness": 0.7559289460184546,
        "project": "",
        "github": "https://github.com/isl-org/lang-seg"
    },
    {
        "id": "Rty5g9imm7H",
        "title": "Transformer Embeddings of Irregularly Spaced Events and Their Participants",
        "track": "main",
        "status": "Poster",
        "keywords": "irregular time series;generative Transformers;neuro-symbolic architectures;logic programming",
        "author": "",
        "aff": "Dept. of Computer Science, Johns Hopkins University; Toyota Tech. Institute at Chicago; Dept. of Computer Science, Columbia University",
        "rating": "3;5;5;6",
        "confidence": "3;4;2;3",
        "correctness": "4;3;2;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.6488856845230502,
        "project": "",
        "github": ""
    },
    {
        "id": "RuC5ilX2m6O",
        "title": "Local Patch AutoAugment with Multi-Agent Collaboration",
        "track": "main",
        "status": "Reject",
        "keywords": "Automatic Data Augmentation;Multi-Agent Reinforcement Learning",
        "author": "",
        "aff": "",
        "rating": "5;6;6;6",
        "confidence": "4;4;3;3",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "RunqFdkPuS",
        "title": "Self-Supervised Modality-Invariant and Modality-Specific Feature Learning for 3D Objects",
        "track": "main",
        "status": "Withdraw",
        "keywords": "3D Representation Learning;3D Self-supervised Learning",
        "author": "",
        "aff": "",
        "rating": "3;5;6",
        "confidence": "5;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "0;2;3",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9819805060619659,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "Rupm2vTg1pe",
        "title": "The Infinite Contextual Graph Markov Model",
        "track": "main",
        "status": "Reject",
        "keywords": "graph neurals networks;graph classification;probabilistic models",
        "author": "",
        "aff": "",
        "rating": "5;5;5;8",
        "confidence": "2;3;4;3",
        "correctness": "3;3;4;4",
        "technical_novelty": "3;3;2;4",
        "empirical_novelty": "2;2;2;4",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "Rx9luEzcSoy",
        "title": "Lottery Image Prior",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "6;6;6;8",
        "confidence": "4;3;4;5",
        "correctness": "3;3;3;3",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.816496580927726,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "Rx_nbGdtRQD",
        "title": "Coherent and Consistent Relational Transfer Learning with Autoencoders",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;6;8",
        "confidence": "3;4;4;4",
        "correctness": "2;2;4;4",
        "technical_novelty": "2;2;3;4",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8006407690254357,
        "corr_rating_correctness": 0.8320502943378437,
        "project": "",
        "github": ""
    },
    {
        "id": "RxplU3vmBx",
        "title": "Looking Back on Learned Experiences For Class/task Incremental Learning",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Deepl Learning;Class Incremental learning;Continual learning;Experiences",
        "author": "",
        "aff": "Center for Machine Vision and Signal Analysis, University of Oulu, Finland; School of Computer Science, Institute for Research in Fundamental Sciences (IPM)",
        "rating": "6;6;8",
        "confidence": "3;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "2;3;2",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.49999999999999983,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/MozhganPourKeshavarz/Cost-Free-Incremental-Learning"
    },
    {
        "id": "Rz9QJ75IPoi",
        "title": "Scale-Invariant Teaching for Semi-Supervised Object Detection",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Semi-Supervised Learning;Object Detection",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "4;4;5;4",
        "correctness": "3;4;3;4",
        "technical_novelty": "3;1;2;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 4.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "RzXb6a3H3rs",
        "title": "Learning to Prompt for Continual Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Continual learning;Prompt-based learning",
        "author": "",
        "aff": "",
        "rating": "3;5;5",
        "confidence": "3;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 4.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9999999999999998,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "S-oyLlQ1i-7",
        "title": "Geon3D: Exploiting 3D Shape Bias towards Building Robust Machine Vision",
        "track": "main",
        "status": "Withdraw",
        "keywords": "robustness;common corruptions;adversarial examples;robust vision;vision science",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;3;4;3",
        "correctness": "2;3;2;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.5222329678670935,
        "project": "",
        "github": ""
    },
    {
        "id": "S-sYYe0P0Hd",
        "title": "SynCLR: A Synthesis Framework for Contrastive Learning of out-of-domain Speech Representations",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Contrastive learning;Domain generalization;Speech Synthesis;Diffusion Probabilistic Models",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;5;4;4",
        "correctness": "3;1;3;3",
        "technical_novelty": "3;1;3;3",
        "empirical_novelty": "3;1;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "S0NsaRIxvQ",
        "title": "Adversarial Style Transfer for Robust Policy Optimization in Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Deep Reinforcement Learning;Generalization in Reinforcement Learning",
        "author": "",
        "aff": "",
        "rating": "5;5;6;8",
        "confidence": "5;3;3;5",
        "correctness": "3;3;4;4",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.40824829046386296,
        "corr_rating_correctness": 0.8164965809277259,
        "project": "",
        "github": ""
    },
    {
        "id": "S2-p6QiTIxZ",
        "title": "Active Learning: Sampling in the Least Probable Disagreement Region",
        "track": "main",
        "status": "Withdraw",
        "keywords": "machine learning;active learning;uncertainty;hypothesis perturbation;disagreement region",
        "author": "",
        "aff": "",
        "rating": "1;5;5;5",
        "confidence": "4;3;3;4",
        "correctness": "1;3;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "S2pNPZM-w-f",
        "title": "Input Convex Graph Neural Networks: An Application to Optimal Control and Design Optimization",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Graph;Graph Neural Network;Convex;Input-convex;Implicit function theorem.",
        "author": "",
        "aff": "",
        "rating": "5;5;6",
        "confidence": "2;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.4999999999999999,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "S352vriz3G",
        "title": "Icy: A benchmark for measuring compositional inductive bias of emergent communication models",
        "track": "main",
        "status": "Withdraw",
        "keywords": "emergent communication;compositionality;metrics;language model",
        "author": "",
        "aff": "Under double-blind review",
        "rating": "3;3;5;5",
        "confidence": "4;3;3;4",
        "correctness": "2;3;2;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;4",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "S3qhbZwzq3H",
        "title": "Value-aware transformers for 1.5d data",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;6;6",
        "confidence": "5;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8660254037844387,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "S5qdnMhf7R",
        "title": "Lightweight Convolutional Neural Networks By Hypercomplex Parameterization",
        "track": "main",
        "status": "Reject",
        "keywords": "Hypercomplex Neural Networks;Lightweight Neural Networks;Quaternion Neural Networks;Parameterized Hypercomplex Convolutions;Hypercomplex Representation Learning",
        "author": "",
        "aff": "",
        "rating": "5;5;6;8",
        "confidence": "4;2;4;5",
        "correctness": "3;2;4;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.7492686492653551,
        "corr_rating_correctness": 0.28867513459481287,
        "project": "",
        "github": ""
    },
    {
        "id": "S6eHczgYpnu",
        "title": "Fast and Sample-Efficient Domain Adaptation for Autoencoder-Based End-to-End Communication",
        "track": "main",
        "status": "Reject",
        "keywords": "domain adaptation;small target dataset;communication autoencoders;mixture density networks;wireless channel",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5;6",
        "confidence": "3;4;4;3;4",
        "correctness": "3;2;3;2;3",
        "technical_novelty": "2;2;2;2;3",
        "empirical_novelty": "2;2;2;2;2",
        "presentation": "",
        "rating_avg": 4.4,
        "confidence_avg": 3.6,
        "correctness_avg": 2.6,
        "technical_novelty_avg": 2.2,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.2721655269759087,
        "corr_rating_correctness": 0.2721655269759087,
        "project": "",
        "github": ""
    },
    {
        "id": "S7vWxSkqv_M",
        "title": "Evaluating Predictive Distributions: Does Bayesian Deep Learning Work?",
        "track": "main",
        "status": "Reject",
        "keywords": "Deep Learning;Bayesian;Uncertainty;Testbed;Opensource Code",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "4;3;4;4",
        "correctness": "4;3;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;3;4",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": "https://anonymous.4open.science/r/neural-testbed-B839"
    },
    {
        "id": "S874XAIpkR-",
        "title": "RvS: What is Essential for Offline RL via Supervised Learning?",
        "track": "main",
        "status": "Poster",
        "keywords": "reinforcement learning;deep reinforcement learning;offline reinforcement learning",
        "author": "",
        "aff": "Carnegie Mellon University; UC Berkeley",
        "rating": "5;6;6;8",
        "confidence": "3;2;3;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;3;2;1",
        "empirical_novelty": "2;3;3;2",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.6488856845230502,
        "corr_rating_correctness": 0.9271726499455306,
        "project": "",
        "github": "https://github.com/scottemmons/rvs"
    },
    {
        "id": "SC6JbEviuD0",
        "title": "White Paper Assistance: A Step Forward Beyond the Shortcut Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Shortcut Learning;Bias;Classification;Imbalanced Classification;Robustness",
        "author": "",
        "aff": "",
        "rating": "1;3;5;8",
        "confidence": "5;3;3;4",
        "correctness": "1;3;3;3",
        "technical_novelty": "1;2;1;4",
        "empirical_novelty": "1;2;3;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.75,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.32063022053099893,
        "corr_rating_correctness": 0.7255892438417318,
        "project": "",
        "github": ""
    },
    {
        "id": "SCSonHu4p0W",
        "title": "Knowledge Based Multilingual Language Model",
        "track": "main",
        "status": "Reject",
        "keywords": "Language Model;Knowledge;Multilingual",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5;5",
        "confidence": "4;5;3;3;4",
        "correctness": "3;2;3;4;3",
        "technical_novelty": "2;3;3;2;2",
        "empirical_novelty": "3;1;3;3;2",
        "presentation": "",
        "rating_avg": 4.2,
        "confidence_avg": 3.8,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7637626158259733,
        "corr_rating_correctness": 0.6454972243679028,
        "project": "",
        "github": ""
    },
    {
        "id": "SCn0mgEIwh",
        "title": "Learnability and Expressiveness in Self-Supervised Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Self-supervised Learning;Learnability;Intrinsic Dimension;Representation Learning",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5",
        "confidence": "3;3;4;3",
        "correctness": "3;3;3;2",
        "technical_novelty": "3;2;2;2",
        "empirical_novelty": "3;2;0;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "SDkZ6jDCNpB",
        "title": "Latent Feature Disentanglement For Visual Domain Generalization",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Domain Generalization;latent disentanglement;Image classification;Image to Image translation",
        "author": "",
        "aff": "",
        "rating": "3;5;5",
        "confidence": "4;4;3",
        "correctness": "3;4;4",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 4.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.49999999999999983,
        "corr_rating_correctness": 0.9999999999999998,
        "project": "",
        "github": ""
    },
    {
        "id": "SF9o3-yP1WR",
        "title": "Robust and Personalized Federated Learning with Spurious Features: an Adversarial Approach",
        "track": "main",
        "status": "Reject",
        "keywords": "federated learning;personalization;spurious features",
        "author": "",
        "aff": "",
        "rating": "3;3;6",
        "confidence": "4;4;3",
        "correctness": "3;2;4",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "0;2;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.8660254037844387,
        "project": "",
        "github": ""
    },
    {
        "id": "SFgkP_PZvL",
        "title": "PNODE: A memory-efficient neural ODE framework based on high-level adjoint differentiation",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5",
        "confidence": "4;4;4",
        "correctness": "2;3;3",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 4.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9999999999999998,
        "project": "",
        "github": ""
    },
    {
        "id": "SGOma2sAF7Q",
        "title": "LCS: Learning Compressible Subspaces for Adaptive Network Compression at Inference Time",
        "track": "main",
        "status": "Reject",
        "keywords": "network subspace;compression;post-training;pruning;quantization;efficient",
        "author": "",
        "aff": "",
        "rating": "3;3;3;8",
        "confidence": "4;4;4;4",
        "correctness": "3;2;3;3",
        "technical_novelty": "1;2;3;3",
        "empirical_novelty": "2;1;3;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "SHbhHHfePhP",
        "title": "Equivariant Graph Mechanics Networks with Constraints",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "Department of Computer Science and Engineering, University of Texas at Arlington; Institute for AI Industry Research (AIR), Tsinghua University; Beijing National Research Center for Information Science and Technology (BNRist), Department of Computer Science and Technology, Tsinghua University; Tencent AI Lab",
        "rating": "5;6;8;8",
        "confidence": "2;4;4;3",
        "correctness": "4;4;4;4",
        "technical_novelty": "1;3;3;2",
        "empirical_novelty": "1;2;3;3",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 3.25,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5222329678670935,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "SHnXjI3vTJ",
        "title": "Self-Supervised Prime-Dual Networks for Few-Shot Image Classification",
        "track": "main",
        "status": "Reject",
        "keywords": "few-shot learning;prime-dual network;self-supervision",
        "author": "",
        "aff": "",
        "rating": "5;6;6;6;6",
        "confidence": "3;3;3;3;4",
        "correctness": "2;4;3;3;2",
        "technical_novelty": "2;2;3;3;3",
        "empirical_novelty": "3;3;3;3;3",
        "presentation": "",
        "rating_avg": 5.8,
        "confidence_avg": 3.2,
        "correctness_avg": 2.8,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.2500000000000001,
        "corr_rating_correctness": 0.5345224838248488,
        "project": "",
        "github": ""
    },
    {
        "id": "SIKV0_MrZlr",
        "title": "Auto-Transfer: Learning to Route Transferable Representations",
        "track": "main",
        "status": "Poster",
        "keywords": "Feature routing;Transferable Representations",
        "author": "",
        "aff": "IBM Research, Yorktown Heights; Rensselaer Polytechnic Institute, New York",
        "rating": "6;6;6;6",
        "confidence": "5;5;3;4",
        "correctness": "2;3;2;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;2;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/IBM/auto-transfer"
    },
    {
        "id": "SK1nec-Ehd",
        "title": "PulseImpute: A Novel Benchmark Task and Architecture for Imputation of Physiological Signals",
        "track": "main",
        "status": "Withdraw",
        "keywords": "missingness;imputation;mHealth;sensors;transformer;self-attention",
        "author": "",
        "aff": "",
        "rating": "",
        "confidence": "",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "SLz5sZjacp",
        "title": "Evaluating Disentanglement of Structured Representations",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "(No affiliation provided in the text)",
        "rating": "6;6;6",
        "confidence": "5;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "4;3;3",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.3333333333333335,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "(Not provided in the text)",
        "github": "(Not provided in the text)"
    },
    {
        "id": "SN2bkl9f69",
        "title": "Multi-Tailed, Multi-Headed, Spatial Dynamic Memory refined Text-to-Image Synthesis",
        "track": "main",
        "status": "Reject",
        "keywords": "Text-to-Image Generation;Computer Vision",
        "author": "",
        "aff": "",
        "rating": "5;5;6",
        "confidence": "4;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9999999999999997,
        "project": "",
        "github": ""
    },
    {
        "id": "SS8F6tFX3-",
        "title": "Evaluating Model-Based Planning and Planner Amortization for Continuous Control",
        "track": "main",
        "status": "Poster",
        "keywords": "Model-based Reinforcement Learning;Planning;Robotics;Model Predictive Control;Learning",
        "author": "",
        "aff": "Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany and Computational and Biological Learning Group, University of Cambridge; Facebook Reality Labs; DeepMind",
        "rating": "6;6;6;8",
        "confidence": "4;3;4;4",
        "correctness": "3;4;4;4",
        "technical_novelty": "2;1;2;3",
        "empirical_novelty": "2;2;3;4",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "STFJBXDTSlT",
        "title": "Identity-Disentangled Adversarial Augmentation for Self-supervised Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "identity disentanglement;contrastive learning;data augmentation;self-supervised learning",
        "author": "",
        "aff": "Affiliation not provided",
        "rating": "5;5;5;6;6",
        "confidence": "4;3;4;4;2",
        "correctness": "3;2;3;4;4",
        "technical_novelty": "3;3;3;4;3",
        "empirical_novelty": "2;3;3;4;3",
        "presentation": "",
        "rating_avg": 5.4,
        "confidence_avg": 3.4,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 3.2,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.408248290463863,
        "corr_rating_correctness": 0.8728715609439693,
        "project": "",
        "github": ""
    },
    {
        "id": "SUIK1esNljC",
        "title": "AutoDrop: Training Deep Learning Models with Automatic Learning Rate Drop",
        "track": "main",
        "status": "Withdraw",
        "keywords": "deep learning optimization;automatic learning rate drop;schedules of the hyperparameters",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "4;4;4;4",
        "correctness": "3;3;1;2",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "3;2;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "SVcEx6SC_NL",
        "title": "Adversarial Robustness as a Prior for Learned Representations",
        "track": "main",
        "status": "Reject",
        "keywords": "adversarial robustness;representation learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;5;4;2",
        "correctness": "4;3;4;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6882472016116854,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/cantankerousdolphin/robust-learned-representations"
    },
    {
        "id": "SVey0ddzC4",
        "title": "Connecting Graph Convolution and Graph PCA",
        "track": "main",
        "status": "Reject",
        "keywords": "Graph Convolutional Network;graph regularization;GNN initialization;graph-based PCA",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "4;5;4;3",
        "correctness": "4;3;2;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;4;2",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.816496580927726,
        "corr_rating_correctness": 0.5222329678670935,
        "project": "",
        "github": ""
    },
    {
        "id": "SVwbKmEg7M",
        "title": "Unsupervised Neural Machine Translation with Generative Language Models Only",
        "track": "main",
        "status": "Reject",
        "keywords": "unsupervised;machine translation;language modeling;few-shot learning",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "5;3;3;4",
        "correctness": "3;3;1;3",
        "technical_novelty": "1;3;2;3",
        "empirical_novelty": "0;3;2;0",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.75,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6225430174794673,
        "corr_rating_correctness": -0.13245323570650439,
        "project": "",
        "github": ""
    },
    {
        "id": "SYB4WrJql1n",
        "title": "On the Existence of Universal Lottery Tickets",
        "track": "main",
        "status": "Poster",
        "keywords": "theory;deep learning;lottery tickets;universality",
        "author": "",
        "aff": "MIT CSAIL; CISPA Helmholtz Center for Information Security; Harvard T.H. Chan School of Public Health",
        "rating": "6;6;6;8",
        "confidence": "3;3;2;4",
        "correctness": "4;3;3;4",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "0;3;0;2",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.816496580927726,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "SYuJXrXq8tw",
        "title": "Sparsity Winning Twice: Better Robust Generalization from More Efficient Training",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "University of Texas at Austin; University of Science and Technology of China; University of California, Irvine",
        "rating": "5;6;8;8",
        "confidence": "3;4;4;4",
        "correctness": "3;4;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;4;4;4",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.7777777777777777,
        "corr_rating_correctness": 0.7777777777777777,
        "project": "",
        "github": "https://github.com/VITA-Group/Sparsity-Win-Robust-Generalization"
    },
    {
        "id": "SZRqWWB4AAh",
        "title": "SABAL: Sparse Approximation-based Batch Active Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "active learning;Bayesian active learning;batch active learning",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5",
        "confidence": "4;4;4;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "3;3;4;3",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "SaKO6z6Hl0c",
        "title": "Unsupervised Semantic Segmentation by Distilling Feature Correspondences",
        "track": "main",
        "status": "Poster",
        "keywords": "Unsupervised Semantic Segmentation;Unsupervised Learning;Deep Features;Contrastive Learning;Visual Transformers;Cocostuff;Cityscapes;Semantic Segmentation",
        "author": "",
        "aff": "MIT, Microsoft; MIT; MIT, Google; Cornell University, Google; Cornell University",
        "rating": "6;6;8;8",
        "confidence": "2;4;4;4",
        "correctness": "3;4;3;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "SawkGZ3oR2J",
        "title": "Accelerating Federated Split Learning via Local-Loss-Based Training",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Federated Learning;Split Learning",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "4;4;4;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;3;4",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9428090415820632,
        "project": "",
        "github": ""
    },
    {
        "id": "Sb4hTI15hUZ",
        "title": "Data-oriented Scene Recognition",
        "track": "main",
        "status": "Reject",
        "keywords": "data-oriented design;computer vision;scene recognition;image recognition",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;4;4;4",
        "correctness": "2;1;2;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;1;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.0,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "SbV8J9JHb6",
        "title": "Soteria: In search of efficient neural networks for private inference",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5",
        "confidence": "2;3;4",
        "correctness": "2;3;3",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "3;2;3",
        "presentation": "",
        "rating_avg": 4.333333333333333,
        "confidence_avg": 3.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8660254037844385,
        "corr_rating_correctness": 0.9999999999999998,
        "project": "",
        "github": ""
    },
    {
        "id": "SgEhFeRyzEZ",
        "title": "Convergence Analysis and Implicit Regularization of Feedback Alignment for Deep Linear Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "feedback alignement;optimization;convergence guarantees;implicit regularization",
        "author": "",
        "aff": "",
        "rating": "5;5;5;8",
        "confidence": "4;3;3;5",
        "correctness": "4;4;4;4",
        "technical_novelty": "3;2;2;4",
        "empirical_novelty": "2;0;2;0",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.75,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 1.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8703882797784892,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "ShtJLsF7cbb",
        "title": "Time-aware Relational Graph Attention Network for Temporal Knowledge Graph Embeddings",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Temporal Attention;Temporal Knowledge Graph Reasoning;Knowledge Graph Completion;Entity Alignment",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "3;4;3;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;1;1;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.6882472016116854,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "SidzxAb9k30",
        "title": "Near-Optimal Reward-Free Exploration for Linear Mixture MDPs with Plug-in Solver",
        "track": "main",
        "status": "Spotlight",
        "keywords": "reward-free exploration;model-based reinforcement learning;learning theory",
        "author": "",
        "aff": "",
        "rating": "6;8;8",
        "confidence": "3;3;2",
        "correctness": "3;4;3",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "3;1;0",
        "presentation": "",
        "rating_avg": 7.333333333333333,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 1.3333333333333333,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.49999999999999983,
        "corr_rating_correctness": 0.49999999999999983,
        "project": "",
        "github": ""
    },
    {
        "id": "SjGRJ4vSZlP",
        "title": "Near-Optimal Algorithms for Autonomous Exploration and Multi-Goal Stochastic Shortest Path",
        "track": "main",
        "status": "Reject",
        "keywords": "Reinforcement learning theory;autonomous exploration",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "3;3;3;3",
        "correctness": "3;2;3;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "1;0;3;0",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 1.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "SlxSY2UZQT",
        "title": "Label-Efficient Semantic Segmentation with Diffusion Models",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "6;8;8",
        "confidence": "4;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 7.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.49999999999999983,
        "corr_rating_correctness": -0.9999999999999998,
        "project": "",
        "github": ""
    },
    {
        "id": "Snqhqz4LdK",
        "title": "Generating Realistic 3D Molecules with an Equivariant Conditional Likelihood Model",
        "track": "main",
        "status": "Reject",
        "keywords": "Generative Models;Molecular Graphs;3D Molecules;Drug Discovery;Equivariance",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;4;3;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "1;2;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6882472016116854,
        "corr_rating_correctness": 0.0
    },
    {
        "id": "So6YAqnqgMj",
        "title": "EigenGame Unloaded: When playing games is better than optimizing",
        "track": "main",
        "status": "Poster",
        "keywords": "pca;principal components analysis;nash;games;eigendecomposition;svd;singular value decomposition",
        "author": "",
        "aff": "",
        "rating": "5;5;8;8",
        "confidence": "3;3;4;3",
        "correctness": "4;4;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.25,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896258,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "SoiF5R9z6zQ",
        "title": "Sparse Fuse Dense: Towards High Quality 3D Detection With Depth Completion",
        "track": "main",
        "status": "Withdraw",
        "keywords": "computer vision;3d detection;multi-modal;point clouds",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6;6",
        "confidence": "4;3;3;4;4",
        "correctness": "3;3;2;4;3",
        "technical_novelty": "3;3;2;2;3",
        "empirical_novelty": "4;2;3;2;3",
        "presentation": "",
        "rating_avg": 5.4,
        "confidence_avg": 3.6,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 2.8,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.6666666666666665,
        "corr_rating_correctness": 0.6454972243679027,
        "project": "",
        "github": ""
    },
    {
        "id": "Sq0-tgDyHe4",
        "title": "Local Feature Swapping for Generalization in Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "Reinforcement learning;Generalization;Regularization",
        "author": "",
        "aff": "",
        "rating": "6;8;8;8;8",
        "confidence": "4;4;4;4;3",
        "correctness": "3;4;3;3;4",
        "technical_novelty": "2;3;4;2;3",
        "empirical_novelty": "3;3;3;3;3",
        "presentation": "",
        "rating_avg": 7.6,
        "confidence_avg": 3.8,
        "correctness_avg": 3.4,
        "technical_novelty_avg": 2.8,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.2500000000000001,
        "corr_rating_correctness": 0.408248290463863,
        "project": "",
        "github": ""
    },
    {
        "id": "Sqv6rs_TRV",
        "title": "WHAT TO DO IF SPARSE REPRESENTATION LEARNING FAILS UNEXPECTEDLY?",
        "track": "main",
        "status": "Reject",
        "keywords": "Physical neural network;extrapolation",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5;6",
        "confidence": "4;3;3;3;4",
        "correctness": "2;2;2;2;4",
        "technical_novelty": "2;3;3;2;3",
        "empirical_novelty": "2;2;2;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.4,
        "correctness_avg": 2.4,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3227486121839514,
        "corr_rating_correctness": 0.7905694150420948,
        "project": "",
        "github": ""
    },
    {
        "id": "Srb756cmzyw",
        "title": "Learning Better Visual Representations for Weakly-Supervised Object Detection Using Natural Language Supervision",
        "track": "main",
        "status": "Withdraw",
        "keywords": "weakly-supervised object detection;vision and language;representation learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;3;4",
        "correctness": "3;4;2;3",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;1;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": -0.7071067811865475,
        "project": "",
        "github": ""
    },
    {
        "id": "SsHBkfeRF9L",
        "title": "Neural graphical modelling in continuous-time: consistency guarantees and algorithms",
        "track": "main",
        "status": "Poster",
        "keywords": "Dynamical systems;graphical modelling;structure learning",
        "author": "",
        "aff": "",
        "rating": "5;5;8",
        "confidence": "4;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "SsPCtEY6yCl",
        "title": "On the Uncomputability of Partition Functions in Energy-Based Sequence Models",
        "track": "main",
        "status": "Spotlight",
        "keywords": "energy-based models;turing completeness;model capacity;sequence models;autoregressive models;partition function;parameter estimation;model selection",
        "author": "Chu-Cheng Lin & Arya D. McCarthy",
        "aff": "",
        "rating": "6;6;8;8",
        "confidence": "3;3;3;4",
        "correctness": "4;4;4;3",
        "technical_novelty": "2;3;4;3",
        "empirical_novelty": "0;0;1;2",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 0.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "St-53J9ZARf",
        "title": "Deep AutoAugment",
        "track": "main",
        "status": "Poster",
        "keywords": "automated machine learning;data augmentation",
        "author": "",
        "aff": "",
        "rating": "5;6;8;8",
        "confidence": "5;5;4;3",
        "correctness": "2;3;4;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 4.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8703882797784892,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "St6eyiTEHnG",
        "title": "Consistent Counterfactuals for Deep Models",
        "track": "main",
        "status": "Poster",
        "keywords": "deep models;deep networks;explainability;counterfactual explanations;consistency;consistent predictions;model duplicity;random initialization",
        "author": "",
        "aff": "",
        "rating": "3;6;6;6",
        "confidence": "3;4;4;3",
        "correctness": "2;3;4;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "SuKTLF9stD",
        "title": "Data-Efficient Augmentation for Training Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "Data Augmentation;Neural Network;Coresets",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "3;4;3;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "3;2;3;4",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5555555555555555,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "SvFQBlffMB",
        "title": "Pseudo Knowledge Distillation: Towards Learning Optimal Instance-specific Label Smoothing Regularization",
        "track": "main",
        "status": "Reject",
        "keywords": "Knowledge Distillation;Label Smoothing;Supervised Learning;Image Classification;Natural Language Understanding",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "3;4;3;3",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;4;2;3",
        "empirical_novelty": "2;3;2;2",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "SwIp410B6aQ",
        "title": "On the Role of Neural Collapse in Transfer Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "6;6;6;6;8",
        "confidence": "4;3;3;3;3",
        "correctness": "4;3;3;4;3",
        "technical_novelty": "2;1;3;3;3",
        "empirical_novelty": "3;3;2;3;3",
        "presentation": "",
        "rating_avg": 6.4,
        "confidence_avg": 3.2,
        "correctness_avg": 3.4,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 2.8,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.2500000000000001,
        "corr_rating_correctness": -0.408248290463863,
        "project": "",
        "github": ""
    },
    {
        "id": "T-uEidE-Xpv",
        "title": "Contrastive Mutual Information Maximization for Binary Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "network compression;network binarization;contrastive learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "5;5;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "3;2;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 4.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9622504486493761,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "T0B9AoM_bFg",
        "title": "Improving Mutual Information Estimation with Annealed and Energy-Based Bounds",
        "track": "main",
        "status": "Poster",
        "keywords": "mutual information estimation;annealed importance sampling;energy-based models",
        "author": "",
        "aff": "",
        "rating": "6;8;8",
        "confidence": "4;5;4",
        "correctness": "4;4;4",
        "technical_novelty": "4;3;3",
        "empirical_novelty": "3;3;4",
        "presentation": "",
        "rating_avg": 7.333333333333333,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 3.3333333333333335,
        "empirical_novelty_avg": 3.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.4999999999999999,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "T0GpzBQ1Fg6",
        "title": "Step-unrolled Denoising Autoencoders for Text Generation",
        "track": "main",
        "status": "Poster",
        "keywords": "generative models;text generation;denoising autoencoders",
        "author": "",
        "aff": "",
        "rating": "5;6;6;8",
        "confidence": "4;3;4;3",
        "correctness": "4;4;3;3",
        "technical_novelty": "2;4;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6882472016116854,
        "corr_rating_correctness": -0.6882472016116854,
        "project": "",
        "github": ""
    },
    {
        "id": "T1A11E__Az",
        "title": "Few-Shot Classification with Task-Adaptive Semantic Feature Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "few-shot learning;task-adaptive semantic feature learning;feature concatenation;feature fusion.",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "3;3;4;4",
        "correctness": "2;3;4;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 1.0,
        "corr_rating_correctness": 0.7071067811865475,
        "project": "",
        "github": ""
    },
    {
        "id": "T2F5aBbSEUQ",
        "title": "Dataset Condensation with Distribution Matching",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Dataset Condensation;Data-efficient Learning;Distribution Matching;Continual Learning;Neural Architecture Search",
        "author": "",
        "aff": "",
        "rating": "3;5;8",
        "confidence": "4;3;4",
        "correctness": "2;3;4",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "3;2;3",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.1147078669352809,
        "corr_rating_correctness": 0.9933992677987828,
        "project": "",
        "github": ""
    },
    {
        "id": "T3_cV3-zbg",
        "title": "ENHANCE THE DYNAMIC REGRET VIA OPTIMISM",
        "track": "main",
        "status": "Withdraw",
        "keywords": "online convex optimization;dynamic regret upper bound;normalized exponentiated gradient;adaptive trick",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3;5",
        "confidence": "4;4;4;5;4",
        "correctness": "3;4;4;3;4",
        "technical_novelty": "1;1;2;2;2",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.4,
        "confidence_avg": 4.2,
        "correctness_avg": 3.6,
        "technical_novelty_avg": 1.6,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.25,
        "corr_rating_correctness": 0.4082482904638631,
        "project": "",
        "github": ""
    },
    {
        "id": "T4-65DNlDij",
        "title": "Deep Attentive Variational Inference",
        "track": "main",
        "status": "Poster",
        "keywords": "variational inference;approximate inference;deep probabilistic models;deep probabilistic learning;variational autoencoder;probabilistic methods for deep learning;attention",
        "author": "",
        "aff": "",
        "rating": "6;8;8;8",
        "confidence": "3;4;3;3",
        "correctness": "3;3;3;4",
        "technical_novelty": "3;3;3;2",
        "empirical_novelty": "3;4;3;3",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "T6lAFguUbw",
        "title": "Modeling Bounded Rationality in Multi-Agent Simulations Using Rationally Inattentive Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Reinforcement Learning;Multi-Agent Reinforcement Learning;Bounded Rationality;Rational Inattention;Simulations",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;2;2;3",
        "correctness": "3;4;4;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;3;0;4",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 2.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6225430174794673,
        "corr_rating_correctness": 0.9271726499455306,
        "project": "",
        "github": ""
    },
    {
        "id": "T73sfhfzk07",
        "title": "GRODIN: Improved Large-Scale Out-of-Domain detection via Back-propagation",
        "track": "main",
        "status": "Reject",
        "keywords": "Out of distribution;deep learning;gradient;backpropagation",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;5;4;4",
        "correctness": "2;3;3;2",
        "technical_novelty": "2;1;1;2",
        "empirical_novelty": "2;1;1;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 1.5,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "T8BnDXDTcFZ",
        "title": "Accelerating Training of Deep Spiking Neural Networks with Parameter Initialization",
        "track": "main",
        "status": "Reject",
        "keywords": "spiking neural networks;back-propagationthrough time;parameter initialization",
        "author": "",
        "aff": "",
        "rating": "5;6;6;6",
        "confidence": "4;5;4;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "T8vZHIRTrY",
        "title": "Understanding Domain Randomization for Sim-to-real Transfer",
        "track": "main",
        "status": "Spotlight",
        "keywords": "domain randomization;sim-to-real transfer;learning theory",
        "author": "",
        "aff": "",
        "rating": "5;8;8;10",
        "confidence": "2;2;2;3",
        "correctness": "4;4;1;3",
        "technical_novelty": "2;4;1;3",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 7.75,
        "confidence_avg": 2.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.7276068751089989,
        "corr_rating_correctness": -0.34299717028501764,
        "project": "",
        "github": ""
    },
    {
        "id": "T8wHz4rnuGL",
        "title": "RotoGrad: Gradient Homogenization in Multitask Learning",
        "track": "main",
        "status": "Spotlight",
        "keywords": "multitask learning;conflicting gradients;negative transfer",
        "author": "Adri\u00e1n Javaloy and Isabel Valera",
        "aff": "",
        "rating": "8;8;8;8",
        "confidence": "4;3;4;4",
        "correctness": "4;4;3;4",
        "technical_novelty": "3;3;4;4",
        "empirical_novelty": "3;3;4;3",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.5,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "TBWA6PLJZQm",
        "title": "Learning with Noisy Labels Revisited: A Study Using Real-World Human Annotations",
        "track": "main",
        "status": "Poster",
        "keywords": "Learning with noisy labels;benchmark;real-world label noise;human annotations",
        "author": "",
        "aff": "",
        "rating": "6;6;8;8",
        "confidence": "5;5;4;5",
        "correctness": "3;3;4;4",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "3;2;4;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 4.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "TBpg4PnXhYH",
        "title": "SPIRAL: Self-supervised Perturbation-Invariant Representation Learning for Speech Pre-Training",
        "track": "main",
        "status": "Poster",
        "keywords": "Speech Representation Learning;Speech Pre-training;Speech Recognition;Self-supervised Representation Learning",
        "author": "",
        "aff": "",
        "rating": "6;6;8;8;8",
        "confidence": "4;3;3;4;5",
        "correctness": "3;3;4;4;4",
        "technical_novelty": "2;3;3;3;3",
        "empirical_novelty": "4;3;3;3;3",
        "presentation": "",
        "rating_avg": 7.2,
        "confidence_avg": 3.8,
        "correctness_avg": 3.6,
        "technical_novelty_avg": 2.8,
        "empirical_novelty_avg": 3.2,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3273268353539886,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "TCl7CbQ29hH",
        "title": "CPT: Colorful Prompt Tuning for Pre-trained Vision-Language Models",
        "track": "main",
        "status": "Reject",
        "keywords": "Pretrained Vision-language Models;Prompt Tuning;Visual Grounding",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "4;4;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "TD-5kgf13mH",
        "title": "Sparse MoEs meet Efficient Ensembles",
        "track": "main",
        "status": "Reject",
        "keywords": "Ensembles;Sparse MoEs;Robustness;Uncertainty Calibration;OOD detection;Efficient Ensembles;Large scale;Computer vision",
        "author": "",
        "aff": "",
        "rating": "3;5;6",
        "confidence": "5;5;3",
        "correctness": "3;4;4",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "2;1;3",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7559289460184545,
        "corr_rating_correctness": 0.9449111825230683,
        "project": "",
        "github": ""
    },
    {
        "id": "TEKnz3B1jGF",
        "title": "Visio-Linguistic Brain Encoding",
        "track": "main",
        "status": "Withdraw",
        "keywords": "fMRI encoding;Vision Transformers;Multi-Modal Transformers",
        "author": "",
        "aff": "",
        "rating": "1;3;3;3",
        "confidence": "5;4;5;3",
        "correctness": "2;2;2;3",
        "technical_novelty": "1;2;1;2",
        "empirical_novelty": "2;3;4;2",
        "presentation": "",
        "rating_avg": 2.5,
        "confidence_avg": 4.25,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 1.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5222329678670935,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "TEt7PsVZux6",
        "title": "I-PGD-AT: Efficient Adversarial Training via Imitating Iterative PGD Attack",
        "track": "main",
        "status": "Reject",
        "keywords": "Single-step Adversarial Training;Catastrophic Overfitting;Adversarial Robustness;Adversarial Example",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "5;5;4;4",
        "correctness": "3;4;3;3",
        "technical_novelty": "2;2;4;4",
        "empirical_novelty": "2;2;4;0",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8164965809277259,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "TFzHbrMveuZ",
        "title": "Knowledge Graph Completion as Tensor Decomposition: A Genreal Form and Tensor N-rank Regularization",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Knowledge Graph;Tensor Decomposition;Low-rank Tensor Completion",
        "author": "",
        "aff": "",
        "rating": "3;3;6",
        "confidence": "3;4;3",
        "correctness": "4;3;3",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5,
        "corr_rating_correctness": -0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "TGfj2P_410X",
        "title": "On the Effect of Input Perturbations for Graph Neural Networks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "graph neural networks",
        "author": "",
        "aff": "",
        "rating": "",
        "confidence": "",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "TH7crDRRND",
        "title": "Revisiting Locality-Sensitive Binary Codes from Random Fourier Features",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "3;3;4;2",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;1;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.4714045207910316,
        "project": "",
        "github": ""
    },
    {
        "id": "THMafOyRVpE",
        "title": "Fully Online Meta-Learning Without Task Boundaries",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;6;6;6",
        "confidence": "3;4;3;5",
        "correctness": "3;2;3;2",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.75,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5222329678670935,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "TIdIXIpzhoI",
        "title": "Progressive Distillation for Fast Sampling of Diffusion Models",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Diffusion Models;Generative Models;fast sampling",
        "author": "",
        "aff": "",
        "rating": "8;8;8;8",
        "confidence": "4;4;3;4",
        "correctness": "4;3;4;4",
        "technical_novelty": "3;3;3;4",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "TJF4wbKTxJf",
        "title": "Learning Lightweight Neural Networks via Channel-Split Recurrent Convolution",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;3;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "3;2;2;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "TKMJ9eqtpgP",
        "title": "DiffusionCLIP: Text-guided Image Manipulation Using Diffusion Models",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Diffusion models;CLIP;Image manipulation;Image to image translation",
        "author": "",
        "aff": "",
        "rating": "3;3;5",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "TKrlyiqKWB",
        "title": "Prototype Based Classification from Hierarchy to Fairness",
        "track": "main",
        "status": "Reject",
        "keywords": "prototypes;fairness;hierarchy;neural network;encoding",
        "author": "",
        "aff": "",
        "rating": "3;3;6;6",
        "confidence": "3;3;4;3",
        "correctness": "2;2;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896258,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "TLgW66V2CbP",
        "title": "Self-Supervised Learning by Estimating Twin Class Distributions",
        "track": "main",
        "status": "Withdraw",
        "keywords": "self-supervised learning;unsupervised learning;representation learning",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "5;5;4;4",
        "correctness": "3;4;3;3",
        "technical_novelty": "1;3;2;2",
        "empirical_novelty": "1;0;2;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 4.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "TLnReGgZEdW",
        "title": "Generalization in Deep RL for TSP Problems via Equivariance and Local Search",
        "track": "main",
        "status": "Reject",
        "keywords": "Deep Reinforcemenet Learning;Travelling salesman problem;Curriculum Learning;Equivariance;Local Search",
        "author": "",
        "aff": "",
        "rating": "5;6;6;8",
        "confidence": "4;4;4;5",
        "correctness": "3;3;3;3",
        "technical_novelty": "3;2;2;3",
        "empirical_novelty": "3;3;2;2",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 4.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9271726499455306,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "TN-W4p7H2pK",
        "title": "Conditional Generative Quantile Networks via Optimal Transport and Convex Potentials",
        "track": "main",
        "status": "Reject",
        "keywords": "Optimal Transport;Generative Models;Quantile Functions;Time-Series Forecasting;Image Generation",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "2;4;4;4",
        "correctness": "2;4;3;4",
        "technical_novelty": "3;1;1;3",
        "empirical_novelty": "2;2;1;3",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.5222329678670935,
        "project": "",
        "github": ""
    },
    {
        "id": "TNBTpPO0QX",
        "title": "Monotone deep Boltzmann machines",
        "track": "main",
        "status": "Reject",
        "keywords": "Deep Boltzmann machine;mean-field inference;deep equilibrium model",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;4;5;4",
        "correctness": "4;4;4;4",
        "technical_novelty": "4;2;3;3",
        "empirical_novelty": "1;2;2;0",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.25,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 1.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.13245323570650439,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "TNmJgFmz2k",
        "title": "Leveraging Relational Information for Learning Weakly Disentangled Representations",
        "track": "main",
        "status": "Withdraw",
        "keywords": "representation learning;disentangled representations;generative models",
        "author": "",
        "aff": "",
        "rating": "3;3;5",
        "confidence": "4;4;3",
        "correctness": "2;3;4",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.8660254037844387,
        "project": "",
        "github": ""
    },
    {
        "id": "TNxKD3z_tPZ",
        "title": "Persistent Homology Captures the Generalization of Neural Networks Without A Validation Set",
        "track": "main",
        "status": "Reject",
        "keywords": "Neural Networks;Topological Data Analysis;learning;evolution;Persistent Homology",
        "author": "",
        "aff": "",
        "rating": "1;3;3;3",
        "confidence": "4;4;5;4",
        "correctness": "1;1;2;1",
        "technical_novelty": "1;3;3;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 2.5,
        "confidence_avg": 4.25,
        "correctness_avg": 1.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "TQ75Md-FqQp",
        "title": "Efficient and Modular Implicit Differentiation",
        "track": "main",
        "status": "Reject",
        "keywords": "implicit differentiation;bilevel optimization;autodiff;jax",
        "author": "",
        "aff": "",
        "rating": "3;8;10",
        "confidence": "4;3;3",
        "correctness": "4;3;4",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9607689228305227,
        "corr_rating_correctness": -0.24019223070763068,
        "project": "",
        "github": ""
    },
    {
        "id": "TSlidmTs80",
        "title": "Knowledge-driven Scene Priors for Semantic Audio-Visual Embodied Navigation",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Scene Priors;Modular Training;Reinforcement Learning;Audio-Visual;Robot Navigation;Embodied",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5;5",
        "confidence": "3;4;4;3;4",
        "correctness": "3;2;2;4;4",
        "technical_novelty": "2;3;3;2;3",
        "empirical_novelty": "2;2;3;2;4",
        "presentation": "",
        "rating_avg": 4.2,
        "confidence_avg": 3.6,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 2.6,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.16666666666666663,
        "corr_rating_correctness": 0.45643546458763845,
        "project": "",
        "github": ""
    },
    {
        "id": "TTnjervir3J",
        "title": "DATA-DRIVEN EVALUATION OF TRAINING ACTION SPACE FOR REINFORCEMENT LEARNING",
        "track": "main",
        "status": "Reject",
        "keywords": "Reinforcement Learning;Action Selection;Cost Optimization;Shapely",
        "author": "",
        "aff": "",
        "rating": "1;1;3;3",
        "confidence": "4;4;4;3",
        "correctness": "2;1;2;3",
        "technical_novelty": "2;1;1;3",
        "empirical_novelty": "2;1;2;3",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.7071067811865475,
        "project": "",
        "github": ""
    },
    {
        "id": "TVHS5Y4dNvM",
        "title": "Patches Are All You Need?",
        "track": "main",
        "status": "Reject",
        "keywords": "computer vision;vision transformer;mixer;patch embeddings;convolution;convolutional neural network",
        "author": "",
        "aff": "",
        "rating": "5;5;8",
        "confidence": "4;5;4",
        "correctness": "3;2;3",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5,
        "corr_rating_correctness": 0.5,
        "project": "",
        "github": "https://github.com/tmp-iclr/convmixer"
    },
    {
        "id": "TVs3zZOOZ8t",
        "title": "Continuous Deep Q-Learning in Optimal Control Problems: Normalized Advantage Functions Analysis",
        "track": "main",
        "status": "Reject",
        "keywords": "continuous reinforcement learning;deep q-learning;optimal control problems;normalized advantage functions",
        "author": "",
        "aff": "Paper under double-blind review",
        "rating": "3;3;3",
        "confidence": "4;5;2",
        "correctness": "4;3;3",
        "technical_novelty": "2;1;2",
        "empirical_novelty": "2;0;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 1.6666666666666667,
        "empirical_novelty_avg": 1.3333333333333333,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "TW7d65uYu5M",
        "title": "VOS: Learning What You Don't Know by Virtual Outlier Synthesis",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "Department of Computer Sciences, University of Wisconsin - Madison",
        "rating": "5;6;8;8",
        "confidence": "5;3;3;5",
        "correctness": "4;4;3;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.19245008972987526,
        "corr_rating_correctness": -0.5555555555555555,
        "project": "",
        "github": "https://github.com/deeplearning-wisc/vos"
    },
    {
        "id": "TWANKAJ1ZCr",
        "title": "Learn Together, Stop Apart: a Novel Approach to Ensemble Pruning",
        "track": "main",
        "status": "Reject",
        "keywords": "ensemble;boosting;regularization;clusterization",
        "author": "",
        "aff": "",
        "rating": "5;5;6",
        "confidence": "5;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "3;0;3",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4999999999999999,
        "corr_rating_correctness": -0.4999999999999999,
        "project": "",
        "github": ""
    },
    {
        "id": "TWTTKlwrUP0",
        "title": "Generating High-Fidelity Privacy-Conscious Synthetic Patient Data for Causal Effect Estimation with Multiple Treatments",
        "track": "main",
        "status": "Reject",
        "keywords": "synthetic data;causal inference;EHR;healthcare;deep generative modeling;treatment effects;model validation;observational patient data;patient privacy",
        "author": "",
        "aff": "",
        "rating": "3;3;5",
        "confidence": "5;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "TXqemS7XEH",
        "title": "M6-10T: A Sharing-Delinking Paradigm for Efficient Multi-Trillion Parameter Pretraining",
        "track": "main",
        "status": "Reject",
        "keywords": "Extreme-Scale Pretraining;Language Modeling;Natural Language Processing",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5;6",
        "confidence": "5;4;4;4;4",
        "correctness": "2;4;2;4;3",
        "technical_novelty": "3;2;3;3;2",
        "empirical_novelty": "2;1;2;3;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.2,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.39528470752104744,
        "corr_rating_correctness": 0.35355339059327373,
        "project": "",
        "github": ""
    },
    {
        "id": "TXsjU8BaibT",
        "title": "Trigger Hunting with a Topological Prior for Trojan Detection",
        "track": "main",
        "status": "Poster",
        "keywords": "Trojan detection;diversity loss;topological prior",
        "author": "",
        "aff": "Stony Brook University; SRI International",
        "rating": "5;5;8;8",
        "confidence": "5;4;3;3",
        "correctness": "3;2;3;3",
        "technical_novelty": "3;3;3;4",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9045340337332909,
        "corr_rating_correctness": 0.5773502691896258,
        "project": "",
        "github": ""
    },
    {
        "id": "TYqb6EXphrr",
        "title": "Space Time Recurrent Memory Network",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "5;5;5;4",
        "correctness": "3;2;2;4",
        "technical_novelty": "2;2;1;2",
        "empirical_novelty": "2;1;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.8703882797784891,
        "project": "",
        "github": ""
    },
    {
        "id": "TYw3-OlrRm-",
        "title": "Network Augmentation for Tiny Deep Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "Tiny Deep Learning",
        "author": "",
        "aff": "MIT-IBM Watson AI Lab; Massachusetts Institute of Technology",
        "rating": "3;6;6;8",
        "confidence": "4;3;5;4",
        "correctness": "2;3;3;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;3;0;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9901475429766743,
        "project": "https://tinyml.mit.edu",
        "github": ""
    },
    {
        "id": "TZeArecH2Nf",
        "title": "Bridging Recommendation and Marketing via Recurrent Intensity Modeling",
        "track": "main",
        "status": "Poster",
        "keywords": "Recommender systems;marketing;push notifications;temporal point processes;sequence models",
        "author": "",
        "aff": "AWS AI Labs",
        "rating": "5;6;8",
        "confidence": "4;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "2;3;4",
        "empirical_novelty": "2;3;2",
        "presentation": "",
        "rating_avg": 6.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.944911182523068,
        "corr_rating_correctness": 0.944911182523068,
        "project": "",
        "github": "https://github.com/awslabs/recurrent-intensity-model-experiments"
    },
    {
        "id": "T_8wHvOkEi9",
        "title": "Self-Organized Polynomial-time Coordination Graphs",
        "track": "main",
        "status": "Reject",
        "keywords": "Multi-Agent Reinforcement Learning;Coordination Graphs;Polynomial-time DCOP",
        "author": "",
        "aff": "",
        "rating": "3;3;8",
        "confidence": "4;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "2;0;3",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9999999999999998,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "T__V3uLix7V",
        "title": "RegionViT: Regional-to-Local Attention for Vision Transformers",
        "track": "main",
        "status": "Poster",
        "keywords": "vision transformer;image recognition;multi-scale feature",
        "author": "",
        "aff": "MIT-IBM Watson AI Lab",
        "rating": "6;6;6;6",
        "confidence": "3;4;3;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "3;3;2;3",
        "empirical_novelty": "3;3;2;2",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/IBM/RegionViT"
    },
    {
        "id": "T_p1vd88T87",
        "title": "Neural Implicit Representations for Physical Parameter Inference from a Single Video",
        "track": "main",
        "status": "Reject",
        "keywords": "neural implicit representations;physics learning;video interpretation;physical parameter estimation",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5;6",
        "confidence": "3;4;3;3;2",
        "correctness": "3;2;3;3;3",
        "technical_novelty": "2;2;2;3;4",
        "empirical_novelty": "2;1;2;3;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 2.8,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 2.2,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7499999999999999,
        "corr_rating_correctness": 0.39528470752104744,
        "project": "",
        "github": ""
    },
    {
        "id": "T_p2GaXuGeA",
        "title": "Local Calibration: Metrics and Recalibration",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5;6",
        "confidence": "5;4;4;5;4",
        "correctness": "3;3;4;3;4",
        "technical_novelty": "2;2;2;2;4",
        "empirical_novelty": "2;2;2;2;4",
        "presentation": "",
        "rating_avg": 5.2,
        "confidence_avg": 4.4,
        "correctness_avg": 3.4,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.408248290463863,
        "corr_rating_correctness": 0.6123724356957947,
        "project": "",
        "github": ""
    },
    {
        "id": "T_uSMSAlgoy",
        "title": "On the Latent Holes \ud83e\uddc0 of VAEs for Text Generation",
        "track": "main",
        "status": "Reject",
        "keywords": "Latent Discontinuity;Variational Auto-Encoder;Natural Language Generation;Generative Model",
        "author": "",
        "aff": "",
        "rating": "3;3;6",
        "confidence": "4;3;3",
        "correctness": "2;2;3",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "Te5ytkqsnl",
        "title": "Missingness Bias in Model Debugging",
        "track": "main",
        "status": "Poster",
        "keywords": "model debugging;vision transformers;missingness",
        "author": "",
        "aff": "Massachusetts Institute of Technology; Microsoft Research",
        "rating": "5;5;6",
        "confidence": "5;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4999999999999999,
        "corr_rating_correctness": -0.4999999999999999,
        "project": "",
        "github": "https://github.com/madrylab/missingness"
    },
    {
        "id": "TfhfZLQ2EJO",
        "title": "SURF: Semi-supervised Reward Learning with Data Augmentation for Feedback-efficient Preference-based Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "preference-based reinforcement learning;human-in-the-loop reinforcement learning;deep reinforcement learning;semi-supervised learning",
        "author": "",
        "aff": "KAIST; UC Berkeley; University of Michigan, LG AI Research",
        "rating": "6;6;6",
        "confidence": "4;3;4",
        "correctness": "3;4;3",
        "technical_novelty": "3;3;2",
        "empirical_novelty": "3;3;2",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "TfwF7pqwqdm",
        "title": "On the exploitative behavior of adversarial training against adversarial attacks",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5;5",
        "confidence": "4;4;4;4;3",
        "correctness": "2;2;2;3;3",
        "technical_novelty": "2;2;3;3;2",
        "empirical_novelty": "2;2;3;3;2",
        "presentation": "",
        "rating_avg": 4.2,
        "confidence_avg": 3.8,
        "correctness_avg": 2.4,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.408248290463863,
        "corr_rating_correctness": 0.6666666666666667,
        "project": "",
        "github": ""
    },
    {
        "id": "Ti2i204vZON",
        "title": "Learning Representations for Pixel-based Control: What Matters and Why?",
        "track": "main",
        "status": "Reject",
        "keywords": "Reinforcement Learning;Representation Learning;Pixel-based Control",
        "author": "",
        "aff": "",
        "rating": "3;3;6;6",
        "confidence": "4;4;3;3",
        "correctness": "3;2;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.5773502691896258,
        "project": "",
        "github": ""
    },
    {
        "id": "TlPNpabaoV",
        "title": "On the Efficiency of Deep Neural Networks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Deep learning;Neural networks;Computation Efficiency;Weight pruning;Overfitting;Softmax;Log likelihood ratio (LLR)",
        "author": "",
        "aff": "",
        "rating": "1;3;3;5",
        "confidence": "4;3;4;4",
        "correctness": "2;2;2;3",
        "technical_novelty": "1;2;2;3",
        "empirical_novelty": "1;2;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "To-R742x7se",
        "title": "Learning Distributionally Robust Models at Scale via Composite Optimization",
        "track": "main",
        "status": "Poster",
        "keywords": "Composite Optimization;Distributionally Robust Optimization",
        "author": "",
        "aff": "Wyze Labs Inc.; Yale Institute for Network Science, Yale University; Department of Computer Science & Engineering, The Pennsylvania State University",
        "rating": "5;6;8",
        "confidence": "2;2;4",
        "correctness": "4;4;4",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;2;4",
        "presentation": "",
        "rating_avg": 6.333333333333333,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.944911182523068,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "TpJMvo0_pu-",
        "title": "Curriculum learning as a tool to uncover learning principles in the brain",
        "track": "main",
        "status": "Poster",
        "keywords": "curriculum learning;neuroscience",
        "author": "",
        "aff": "Friedman Brain Institute, Icahn School of Medicine at Mount Sinai, New York, NY 10029, USA; Department of Neuroscience, Zuckerman Institute, Columbia University, New York, NY 10027, USA",
        "rating": "5;6;6;8",
        "confidence": "4;4;3;3",
        "correctness": "2;3;3;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;3;4;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6882472016116854,
        "corr_rating_correctness": 0.9733285267845754,
        "project": "",
        "github": ""
    },
    {
        "id": "TqNsv1TuCX9",
        "title": "Axiomatic Explanations for Visual Search, Retrieval, and Similarity Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "Model Interpretability;Shapley Values;Search Engines;Information Retrieval;Visual Search;Similarity Learning;Metric Learning;Black-box explanations",
        "author": "",
        "aff": "MIT, Google; MIT; Microsoft",
        "rating": "6;6;6",
        "confidence": "4;5;2",
        "correctness": "3;3;4",
        "technical_novelty": "4;3;3",
        "empirical_novelty": "3;2;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.3333333333333335,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "TrjbxzRcnf-",
        "title": "Memorizing Transformers",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Transformer;architecture;memorization.",
        "author": "",
        "aff": "Google",
        "rating": "5;6;6;8",
        "confidence": "4;4;4;5",
        "correctness": "3;4;4;3",
        "technical_novelty": "2;2;2;4",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 4.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9271726499455306,
        "corr_rating_correctness": -0.2294157338705618,
        "project": "",
        "github": ""
    },
    {
        "id": "TscS0R8QzfG",
        "title": "PDAML: A Pseudo Domain Adaptation Paradigm for Subject-independent EEG-based Emotion Recognition",
        "track": "main",
        "status": "Reject",
        "keywords": "aBCIs;EEG-based emotion recognition;domain adaptation;domain generalization;meta-learning;adversarial learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;5;5;5",
        "correctness": "2;3;3;3",
        "technical_novelty": "3;1;2;2",
        "empirical_novelty": "2;1;3;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "Tu6SpFYWTA",
        "title": "Antonymy-Synonymy Discrimination through the Repelling Parasiamese Neural Network",
        "track": "main",
        "status": "Reject",
        "keywords": "antitransitivity;parasiamese network;antonymy-synonymy discrimination",
        "author": "",
        "aff": "",
        "rating": "3;6;6",
        "confidence": "4;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "2;3;2",
        "empirical_novelty": "2;3;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "TuR3pmKgERp",
        "title": "Hyperspherical embedding for novel class classification",
        "track": "main",
        "status": "Reject",
        "keywords": "Metric Learning;open set;deep learning",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "4;4;4;3",
        "correctness": "3;3;2;3",
        "technical_novelty": "2;1;2;2",
        "empirical_novelty": "1;2;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "Tubzedlc4P",
        "title": "A Statistical Manifold Framework for Point Cloud Data",
        "track": "main",
        "status": "Reject",
        "keywords": "Riemannian Geometry;Point Cloud;Autoencoders",
        "author": "",
        "aff": "",
        "rating": "3;5;6;8",
        "confidence": "5;4;3;3",
        "correctness": "4;4;3;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9198662110077999,
        "corr_rating_correctness": -0.16012815380508713,
        "project": "",
        "github": ""
    },
    {
        "id": "TvMrYbWpa7",
        "title": "Instance-Adaptive Video Compression: Improving Neural Codecs by Training on the Test Set",
        "track": "main",
        "status": "Reject",
        "keywords": "Instance-Adaptive Video Compression: Improving Neural Codecs by Training on the Test Set",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "5;4;4;4",
        "correctness": "4;3;4;3",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "3;3;3;2",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 4.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "TxIXgcP3yp-",
        "title": "Decouple and Reconstruct: Mining Discriminative Features for Cross-domain Object Detection",
        "track": "main",
        "status": "Reject",
        "keywords": "domain adaptation;object detection;discriminative feature mining",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5",
        "confidence": "3;3;4;2",
        "correctness": "4;2;2;3",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "4;2;2;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "TySnJ-0RdKI",
        "title": "Backdoor Defense via Decoupling the Training Process",
        "track": "main",
        "status": "Poster",
        "keywords": "Backdoor Defense;Backdoor Learning",
        "author": "",
        "aff": "School of Cyber Science and Technology, Zhejiang University; Tsinghua Shenzhen International Graduate School, Tsinghua University; School of Data Science, Shenzhen Research Institute of Big Data, The Chinese University of Hong Kong, Shenzhen",
        "rating": "6;6;6;8",
        "confidence": "5;4;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 4.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/SCLBD/DBD"
    },
    {
        "id": "TytZk4tWO5",
        "title": "Reference-Limited Compositional Learning: A Realistic Assessment for Human-level Compositional Generalization",
        "track": "main",
        "status": "Withdraw",
        "keywords": "compositional learning;few-shot;few referential compositions",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5",
        "confidence": "4;4;3;4",
        "correctness": "3;3;2;2",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;3;2;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "U-GB_gONqbo",
        "title": "Scalable Hierarchical Embeddings of Complex Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "Graph Representation Learning;Latent Space Model;Complex Networks;Scalable Network embeddings;Link prediction;Low dimension graph representations",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;4;3;4",
        "correctness": "4;4;3;2",
        "technical_novelty": "2;3;2;2",
        "empirical_novelty": "2;3;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": -0.8703882797784891,
        "project": "",
        "github": ""
    },
    {
        "id": "U-_89RnR8F",
        "title": "Meaningfully Explaining Model Mistakes Using Conceptual Counterfactuals",
        "track": "main",
        "status": "Reject",
        "keywords": "interpretability;concept-based explanations;counterfactual explanations",
        "author": "",
        "aff": "",
        "rating": "5;6;6;6",
        "confidence": "4;4;4;4",
        "correctness": "4;4;3;3",
        "technical_novelty": "3;3;4;3",
        "empirical_novelty": "2;3;2;2",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "Not provided",
        "github": "Not provided"
    },
    {
        "id": "U0k7XNTiFEq",
        "title": "Deep Learning without Shortcuts: Shaping the Kernel with Tailored Rectifiers",
        "track": "main",
        "status": "Poster",
        "keywords": "Neural Network Training;Kernel Approximation for Neural Networks;Neural Network Initialization;Generalization",
        "author": "",
        "aff": "DeepMind; University of Toronto, Vector Institute",
        "rating": "6;6;6;6",
        "confidence": "4;3;2;3",
        "correctness": "3;4;4;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "U1edbV4kNu_",
        "title": "SWARM Parallelism: Training Large Models Can Be Surprisingly Communication-Efficient",
        "track": "main",
        "status": "Reject",
        "keywords": "distributed training;model-parallel;model parallelism;pipeline;fault tolerance;communication efficiency;volunteer computing",
        "author": "",
        "aff": "",
        "rating": "3;6;6;6",
        "confidence": "5;4;5;4",
        "correctness": "2;3;3;4",
        "technical_novelty": "3;4;3;4",
        "empirical_novelty": "0;3;2;2",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 4.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "U4uFaLyg7PV",
        "title": "T-WaveNet: A Tree-Structured Wavelet Neural Network for Time Series Signal Analysis",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "Department of Computer Science & Engineering, The Chinese University of Hong Kong; School of Nursing, The Hong Kong Polytechnic University",
        "rating": "6;6;6;8",
        "confidence": "4;3;2;3",
        "correctness": "3;3;3;4",
        "technical_novelty": "3;3;3;4",
        "empirical_novelty": "3;0;3;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "U8pbd00cCWB",
        "title": "Differentiable Gradient Sampling for Learning Implicit 3D Scene Reconstructions from a Single Image",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "UC Berkeley",
        "rating": "5;6;6;8",
        "confidence": "5;4;4;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;4;3;4",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6622661785325219,
        "corr_rating_correctness": 0.9271726499455306,
        "project": "",
        "github": "https://github.com/zhusz/ICLR22-DGS"
    },
    {
        "id": "U9zTUXVdoIr",
        "title": "GSmooth: Certified Robustness against Semantic Transformations via Generalized Randomized Smoothing",
        "track": "main",
        "status": "Reject",
        "keywords": "Randomized Smoothing;Adversarial Robustness;Semantic Transformations;Machine Learning",
        "author": "",
        "aff": "",
        "rating": "3;5;8;8",
        "confidence": "3;3;5;4",
        "correctness": "2;4;3;3",
        "technical_novelty": "3;2;4;3",
        "empirical_novelty": "2;3;4;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8528028654224419,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "UECzHrGio7i",
        "title": "Robust Imitation Learning from Corrupted Demonstrations",
        "track": "main",
        "status": "Reject",
        "keywords": "Robust Estimation;Imitation Learning;Reinforcement Learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;3;3",
        "correctness": "2;2;3;4",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.9045340337332909,
        "project": "",
        "github": ""
    },
    {
        "id": "UF5cHSBycOt",
        "title": "Learning to Pool in Graph Neural Networks for Extrapolation",
        "track": "main",
        "status": "Reject",
        "keywords": "Graph Neural Network;Pooling;Extrapolation",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;4;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "1;2;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "UFYYol-bRq",
        "title": "ANCER: Anisotropic Certification via Sample-wise Volume Maximization",
        "track": "main",
        "status": "Reject",
        "keywords": "randomized smoothing;anisotropic certification;deep neural network certification;certified defenses",
        "author": "",
        "aff": "",
        "rating": "5;6;6;8",
        "confidence": "4;5;3;4",
        "correctness": "3;4;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.6622661785325219,
        "project": "",
        "github": ""
    },
    {
        "id": "UGINpaICVOt",
        "title": "Neural networks with trainable matrix activation functions",
        "track": "main",
        "status": "Reject",
        "keywords": "neural networks;trainable activation function;function approximation;image classification",
        "author": "",
        "aff": "",
        "rating": "1;1;3;3;3",
        "confidence": "4;4;5;3;4",
        "correctness": "2;3;2;1;2",
        "technical_novelty": "2;1;2;1;2",
        "empirical_novelty": "1;1;1;1;1",
        "presentation": "",
        "rating_avg": 2.2,
        "confidence_avg": 4.0,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 1.6,
        "empirical_novelty_avg": 1.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.6454972243679028,
        "project": "",
        "github": ""
    },
    {
        "id": "UI4K-I2ypG",
        "title": "A Survey on Evidential Deep Learning For Single-Pass Uncertainty Estimation",
        "track": "main",
        "status": "Reject",
        "keywords": "uncertainty estimation;prior networks;posterior networks;conjugate priors;classification;regression;evidential deep learning;dirichlet",
        "author": "",
        "aff": "",
        "rating": "1;3;5;5",
        "confidence": "3;4;4;4",
        "correctness": "4;3;4;3",
        "technical_novelty": "1;1;1;2",
        "empirical_novelty": "0;0;1;0",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 1.25,
        "empirical_novelty_avg": 0.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8703882797784891,
        "corr_rating_correctness": -0.30151134457776363,
        "project": "",
        "github": ""
    },
    {
        "id": "UIQxciuYcon",
        "title": "Revisiting Contrastive Learning through the Lens of Neighborhood Component Analysis: an Integrated Framework",
        "track": "main",
        "status": "Withdraw",
        "keywords": "representation learning",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5;6",
        "confidence": "4;4;4;5;3",
        "correctness": "3;3;2;2;3",
        "technical_novelty": "2;2;3;2;3",
        "empirical_novelty": "1;2;3;2;3",
        "presentation": "",
        "rating_avg": 4.8,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 2.2,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3227486121839514,
        "corr_rating_correctness": -0.16666666666666663,
        "project": "",
        "github": ""
    },
    {
        "id": "UJ9_wmscwk",
        "title": "Learning Graph Representations for Influence Maximization",
        "track": "main",
        "status": "Reject",
        "keywords": "influence maximization;graph neural networks",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "4;4;3;2",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.986440050415621,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "ULfq0qR25dY",
        "title": "Maximum n-times Coverage for Vaccine Design",
        "track": "main",
        "status": "Poster",
        "keywords": "computational biology;vaccine design;COVID-19;maximum n-times coverage;combinatorial optimization;integer linear programming",
        "author": "",
        "aff": "Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology",
        "rating": "6;6;6;8",
        "confidence": "3;3;4;3",
        "correctness": "3;3;2;4",
        "technical_novelty": "3;3;3;2",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "UMQ4PFd35i",
        "title": "Time Delay Estimation of Traffic Congestion Based on Statistical Causality",
        "track": "main",
        "status": "Withdraw",
        "keywords": "time delay estimation;transfer entropy;traffic congestion",
        "author": "",
        "aff": "",
        "rating": "3;3;6",
        "confidence": "4;4;3",
        "correctness": "4;3;3",
        "technical_novelty": "1;2;3",
        "empirical_novelty": "1;2;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": -0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "UMfhoMtIaP5",
        "title": "Provably Robust Adversarial Examples",
        "track": "main",
        "status": "Poster",
        "keywords": "Adversarial attacks;Robustness Certification;Abstract Interpretation;Deep Learning",
        "author": "",
        "aff": "University of Illinois, Urbana Champaign; ETH Zurich",
        "rating": "6;6;8",
        "confidence": "4;3;5",
        "correctness": "3;3;4",
        "technical_novelty": "2;3;4",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8660254037844385,
        "corr_rating_correctness": 0.9999999999999998,
        "project": "",
        "github": ""
    },
    {
        "id": "UORhn0DGIT",
        "title": "Heterogeneous Wasserstein Discrepancy for Incomparable Distributions",
        "track": "main",
        "status": "Reject",
        "keywords": "Optimal transport;Wasserstein distance;Incomprable distributions;Generative models",
        "author": "",
        "aff": "",
        "rating": "3;3;6",
        "confidence": "5;3;3",
        "correctness": "3;2;4",
        "technical_novelty": "1;2;3",
        "empirical_novelty": "2;0;0",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 0.6666666666666666,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5000000000000001,
        "corr_rating_correctness": 0.8660254037844387,
        "project": "",
        "github": ""
    },
    {
        "id": "UOj0MV__Cr",
        "title": "A Two-Stage Neural-Filter Pareto Front Extractor and the need for Benchmarking",
        "track": "main",
        "status": "Reject",
        "keywords": "Pareto Optimality;Neural nets;Pareto Filter;Interpretability;Benchmarking",
        "author": "",
        "aff": "",
        "rating": "3;3;3;6",
        "confidence": "4;5;4;3",
        "correctness": "2;2;2;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;1;1;3",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 4.0,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.816496580927726,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "UPJ4Hvu6pu",
        "title": "Adaptive Early-Learning Correction for Segmentation from Noisy Annotations",
        "track": "main",
        "status": "Withdraw",
        "keywords": "semantic segmentation;segmentation from noisy annotations;weakly supervised semantic segmentation",
        "author": "Author",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;5;3;3",
        "correctness": "2;3;3;3",
        "technical_novelty": "3;3;2;2",
        "empirical_novelty": "2;3;2;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.17407765595569782,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "UPwD79EleQ",
        "title": "Cyclic Test Time Augmentation with Entropy Weight Method",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Data Augmentation;Test Time Augmentation;Uncertainty Estimation",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "3;5;2;3",
        "correctness": "2;3;3;3",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6882472016116854,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "UQBEkRO0_-M",
        "title": "Softmax Gradient Tampering: Decoupling the Backward Pass for Improved Fitting",
        "track": "main",
        "status": "Reject",
        "keywords": "gradient tampering;smoothing;softmax;prediction;image classification;neural networks",
        "author": "",
        "aff": "",
        "rating": "1;3;3;5",
        "confidence": "3;4;4;4",
        "correctness": "2;3;2;2",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "1;2;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.816496580927726,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "UQQgMRq58O",
        "title": "Understanding Generalized Label Smoothing when Learning with Noisy Labels",
        "track": "main",
        "status": "Reject",
        "keywords": "Learning with noisy labels;label smoothing;model confidence",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;3;4;5",
        "correctness": "2;3;4;3",
        "technical_novelty": "1;2;3;2",
        "empirical_novelty": "1;2;4;1",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "URNZQmbxpwh",
        "title": "Fishr: Invariant Gradient Variances for Out-of-distribution Generalization",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Deep Learning;Computer Vision;Domain Generalization",
        "author": "",
        "aff": "",
        "rating": "3;5;8;8",
        "confidence": "5;4;4;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;2;4;2",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8164965809277261,
        "corr_rating_correctness": 0.5443310539518174,
        "project": "",
        "github": "https://anonymous.4open.science/r/fishr-anonymous-EBB6/"
    },
    {
        "id": "US2rTP5nm_",
        "title": "EntQA: Entity Linking as Question Answering",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Entity linking;open-domain question answering;dense retrieval;reading comprehension;information extraction;natural language processing",
        "author": "",
        "aff": "Department of Computer Science, Rutgers University",
        "rating": "8;8;8",
        "confidence": "4;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "2;3;2",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "USC0-nvGPK",
        "title": "Information Gain Propagation: a New Way to Graph Active Learning with Soft Labels",
        "track": "main",
        "status": "Poster",
        "keywords": "Active Learning;Graph;Information Gain",
        "author": "",
        "aff": "School of CS, Peking University; National Engineering Laboratory for Big Data Analysis and Applications; Institute of Computational Social Science, Peking University (Qingdao), China; School of CS, Peking University; Apple; School of CS, Peking University; National Engineering Laboratory for Big Data Analysis and Applications",
        "rating": "1;5;6;8",
        "confidence": "4;4;4;5",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;3;3;4",
        "empirical_novelty": "2;0;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.6793662204867574,
        "corr_rating_correctness": 0.6793662204867574,
        "project": "",
        "github": ""
    },
    {
        "id": "USIgIY6TNDe",
        "title": "Graph-based Nearest Neighbor Search in Hyperbolic Spaces",
        "track": "main",
        "status": "Poster",
        "keywords": "similarity search;nearest neighbor search;hyperbolic space;graph-based nearest neighbor search",
        "author": "",
        "aff": "Universit\u00e9 de Neuch\u00e2tel, Neuch\u00e2tel, Switzerland; Yandex Research, Moscow, Russia; MIPT, Moscow, Russia; IITP RAS; MIPT, Moscow, Russia",
        "rating": "5;6;6;6;6",
        "confidence": "4;4;3;4;3",
        "correctness": "4;4;3;3;4",
        "technical_novelty": "2;3;3;3;3",
        "empirical_novelty": "2;3;0;1;3",
        "presentation": "",
        "rating_avg": 5.8,
        "confidence_avg": 3.6,
        "correctness_avg": 3.6,
        "technical_novelty_avg": 2.8,
        "empirical_novelty_avg": 1.8,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.408248290463863,
        "corr_rating_correctness": -0.408248290463863,
        "project": "",
        "github": ""
    },
    {
        "id": "UTTrevGchy",
        "title": "Learning Diverse Options via InfoMax Termination Critic",
        "track": "main",
        "status": "Reject",
        "keywords": "reinforcement learning;hierachical reinforcement learning;options;life long reinforcement learning;skill transfer",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "4;3;4;4",
        "correctness": "4;3;2;3",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": -0.7071067811865475,
        "project": "",
        "github": ""
    },
    {
        "id": "UTdxT0g6ZuC",
        "title": "Automatic Forecasting via Meta-Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Forecasting Model Selection;Time-series Forecasting;Meta-features",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "3;4;3;3",
        "correctness": "3;2;2;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;4;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5555555555555555,
        "corr_rating_correctness": 0.19245008972987526,
        "project": "",
        "github": ""
    },
    {
        "id": "UVtVRcurOYv",
        "title": "KGRefiner: Knowledge Graph Refinement for Improving Accuracy of Translational Link Prediction Methods",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Knowledge Graph Embedding;Link Prediction;Representation Learning",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3;5",
        "confidence": "4;5;4;4;3",
        "correctness": "2;2;2;3;2",
        "technical_novelty": "2;2;1;2;2",
        "empirical_novelty": "2;2;1;3;2",
        "presentation": "",
        "rating_avg": 3.4,
        "confidence_avg": 4.0,
        "correctness_avg": 2.2,
        "technical_novelty_avg": 1.8,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7905694150420948,
        "corr_rating_correctness": -0.25,
        "project": "",
        "github": ""
    },
    {
        "id": "UXrVIKDbsb_",
        "title": "Unleash the Potential of Adaptation Models via Dynamic Domain Labels",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Adversarial Domain Adaptation;Dynamic Domain Labels",
        "author": "",
        "aff": "",
        "rating": "3;5;5",
        "confidence": "5;5;3",
        "correctness": "1;3;3",
        "technical_novelty": "1;3;3",
        "empirical_novelty": "2;3;2",
        "presentation": "",
        "rating_avg": 4.333333333333333,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.49999999999999983,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "UXwlFxVWks",
        "title": "Divergent representations of ethological visual inputs emerge from supervised, unsupervised, and reinforcement learning",
        "track": "main",
        "status": "Reject",
        "keywords": "reinforcement learning;transfer learning;representations;dimensionality;sparsity;RSA",
        "author": "",
        "aff": "",
        "rating": "3;3;3;6",
        "confidence": "4;4;3;3",
        "correctness": "3;4;2;3",
        "technical_novelty": "3;1;1;3",
        "empirical_novelty": "2;2;2;4",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "UYDtmk6BMf5",
        "title": "Decomposing Texture and Semantics for Out-of-distribution Detection",
        "track": "main",
        "status": "Reject",
        "keywords": "Out-of-distribution detection;Fourier analysis;Normailzing flow model",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "4;4;3;3",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8164965809277259,
        "corr_rating_correctness": 0.8164965809277259,
        "project": "",
        "github": ""
    },
    {
        "id": "UYfK9egx2I",
        "title": "A General Framework for Defending against Backdoor Attacks via Influence Graph",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "Shannon.AI, Zhejiang University; Peking University; Shannon.AI; Tsinghua University; Nanyang Technological University; Zhejiang University",
        "rating": "",
        "confidence": "",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "UYneFzXSJWh",
        "title": "Fine-Tuning can Distort Pretrained Features and Underperform Out-of-Distribution",
        "track": "main",
        "status": "Oral",
        "keywords": "fine-tuning theory;transfer learning theory;fine-tuning;distribution shift;implicit regularization",
        "author": "",
        "aff": "Stanford University, Computer Science Department",
        "rating": "8;8;8;8",
        "confidence": "3;4;4;3",
        "correctness": "3;3;4;4",
        "technical_novelty": "3;3;3;2",
        "empirical_novelty": "3;2;0;3",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "U_Jog0t3fAu",
        "title": "Iterative Sketching and its Application to Federated Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Federated learning;optimization;sketching;differential privacy",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;3;3;4",
        "correctness": "3;2;4;3",
        "technical_novelty": "1;2;2;3",
        "empirical_novelty": "0;0;2;0",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 0.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.7071067811865475,
        "project": "",
        "github": ""
    },
    {
        "id": "UajXTGRjuKB",
        "title": "Sampling Before Training: Rethinking the Effect of Edges in the Process of Training Graph Neural Networks",
        "track": "main",
        "status": "Desk Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "",
        "confidence": "",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "UarYhFFxQ2B",
        "title": "Towards Robust Active Feature Acquisition",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "1;3;3;5",
        "confidence": "3;5;3;3",
        "correctness": "2;2;3;4",
        "technical_novelty": "1;2;2;3",
        "empirical_novelty": "1;2;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.8528028654224418,
        "project": "",
        "github": ""
    },
    {
        "id": "Ub1BQTKiwqg",
        "title": "Learning sparse DNNs with soft thresholding of weights during training",
        "track": "main",
        "status": "Reject",
        "keywords": "pruning;sparse;DNN",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "4;4;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "3;2;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "UcDUxjPYWSr",
        "title": "Transform2Act: Learning a Transform-and-Control Policy for Efficient Agent Design",
        "track": "main",
        "status": "Oral",
        "keywords": "Agent Design;Morphology Optimization;Reinforcement Learning",
        "author": "",
        "aff": "Cornell University; Carnegie Mellon University",
        "rating": "8;8;8;8",
        "confidence": "4;4;5;4",
        "correctness": "3;4;4;3",
        "technical_novelty": "4;3;3;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "https://sites.google.com/view/transform2act",
        "github": "Not provided"
    },
    {
        "id": "Ucx3DQbC9GH",
        "title": "What Makes Better Augmentation Strategies? Augment Difficult but Not too Different",
        "track": "main",
        "status": "Poster",
        "keywords": "NLP;data augmentation;learning augmentation policy;text classification",
        "author": "",
        "aff": "University of Minnesota (UMN); Korea Advanced Institute of Science and Technology (KAIST); Pohang University of Science and Technology (POSTECH)",
        "rating": "6;6;6;8",
        "confidence": "5;3;4;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;2;2;4",
        "empirical_novelty": "3;3;3;4",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "Ud7G0LtrHVD",
        "title": "Are Vision Transformers Robust to Patch-wise Perturbations?",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Vision Transformer;Adversarial Robustness",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;3;4",
        "correctness": "4;2;2;3",
        "technical_novelty": "3;2;2;2",
        "empirical_novelty": "3;1;2;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": -0.30151134457776363,
        "project": "",
        "github": ""
    },
    {
        "id": "UdxJ2fJx7N0",
        "title": "Minimax Optimization with Smooth Algorithmic Adversaries",
        "track": "main",
        "status": "Poster",
        "keywords": "Minimax optimization;two player zero sum games;generative adversarial networks;adversarial training",
        "author": "",
        "aff": "Google Research, India; Princeton University; University of Washington, Seattle",
        "rating": "6;6;8;8",
        "confidence": "5;4;4;3",
        "correctness": "3;3;4;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7071067811865475,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "UeE41VsK1KJ",
        "title": "Subjective Learning for Open-Ended Data",
        "track": "main",
        "status": "Reject",
        "keywords": "Open-ended data;machine learning;supervised learning;data conflict",
        "author": "",
        "aff": "",
        "rating": "5;6;6;8",
        "confidence": "3;2;3;3",
        "correctness": "4;3;3;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 2.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.13245323570650439,
        "corr_rating_correctness": 0.2294157338705618,
        "project": "",
        "github": ""
    },
    {
        "id": "UeRmyymo3kb",
        "title": "GARNET: A Spectral Approach to Robust and Scalable Graph Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "graph neural networks;adversarial robustness;low-rank approximation;spectral graph theory",
        "author": "",
        "aff": "",
        "rating": "3;5;6",
        "confidence": "4;4;4",
        "correctness": "2;3;3",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "2;2;4",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9449111825230683,
        "project": "",
        "github": ""
    },
    {
        "id": "Ug-bgjgSlKV",
        "title": "Finding an Unsupervised Image Segmenter in each of your Deep Generative Models",
        "track": "main",
        "status": "Poster",
        "keywords": "unsupervised;generative;deep learning;segmentation;object segmentation",
        "author": "",
        "aff": "University of Oxford",
        "rating": "5;6;6;8",
        "confidence": "3;3;3;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;3;3;4",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9271726499455306,
        "corr_rating_correctness": 0.9271726499455306,
        "project": "",
        "github": ""
    },
    {
        "id": "UgBo_nhiHl",
        "title": "Gradient Boosting Neural Networks: GrowNet",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Deep Neural Networks;Gradient Boosting classifiers;NN architecture optimization",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "4;4;5;4",
        "correctness": "3;2;3;2",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "UgNQM-LcVpN",
        "title": "A Modulation Layer to Increase Neural Network Robustness Against Data Quality Issues",
        "track": "main",
        "status": "Reject",
        "keywords": "missing data;modulation;DNN layer;neuromodulation;robustness",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "5;3;5;4",
        "correctness": "3;3;1;2",
        "technical_novelty": "2;2;2;1",
        "empirical_novelty": "2;2;1;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.25,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "UjynxfqnGWG",
        "title": "Inductive Biases and Variable Creation in Self-Attention Mechanisms",
        "track": "main",
        "status": "Reject",
        "keywords": "transformers;attention",
        "author": "",
        "aff": "",
        "rating": "3;5;6;8",
        "confidence": "3;4;3;4",
        "correctness": "3;4;3;4",
        "technical_novelty": "3;4;3;4",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5547001962252291,
        "corr_rating_correctness": 0.5547001962252291,
        "project": "",
        "github": ""
    },
    {
        "id": "UkgBSwjxwe",
        "title": "Neuro-Symbolic Forward Reasoning",
        "track": "main",
        "status": "Reject",
        "keywords": "neuro-symbolic AI;differentiable logic;object-centric reasoning",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;3;4;4",
        "correctness": "2;4;2;4",
        "technical_novelty": "2;2;3;1",
        "empirical_novelty": "2;1;0;1",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "Ul3o26VB6KZ",
        "title": "Spiking Graph Convolutional Networks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Graph;spike;energy;neural network",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "5;2;3;4",
        "correctness": "2;1;3;3",
        "technical_novelty": "1;2;3;2",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9045340337332909,
        "project": "",
        "github": ""
    },
    {
        "id": "Ulj0tR-k7q",
        "title": "On strong convergence of the two-tower model for recommender system",
        "track": "main",
        "status": "Desk Reject",
        "keywords": "Artificial neural networks;Collaborative filtering;Empirical process;Recommender system;Two-tower model",
        "author": "",
        "aff": "Paper under double-blind review",
        "rating": "",
        "confidence": "",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "UoNqm70g9HY",
        "title": "Equivalent Distance Geometry Error for Molecular Conformation Comparison",
        "track": "main",
        "status": "Reject",
        "keywords": "molecule;molecular conformation;loss function",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "5;5;4;3",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "3;0;2;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9045340337332909,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "Uozyxz3eKY",
        "title": "DM-CT: Consistency Training with Data and Model Perturbation",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "5;4;4;4",
        "correctness": "4;2;4;3",
        "technical_novelty": "2;2;1;2",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": -0.17407765595569782,
        "project": "",
        "github": ""
    },
    {
        "id": "UquMPXFTpgp",
        "title": "Cluster Tree for Nearest Neighbor Search",
        "track": "main",
        "status": "Desk Reject",
        "keywords": "Nearest neighbor search;tree algorithms;graph cuts;random projections",
        "author": "",
        "aff": "",
        "rating": "",
        "confidence": "",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "UseMOjWENv",
        "title": "MIDI-DDSP: Detailed Control of Musical Performance via Hierarchical Modeling",
        "track": "main",
        "status": "Oral",
        "keywords": "Audio Synthesis;Generative Model;Hierarchical;DDSP;Music;Audio;Structured Models",
        "author": "",
        "aff": "Mila, Quebec Arti\ufb01cial Intelligence Institute, Universit \u00b4e de Montr \u00b4eal; Northwestern University; Google Brain; New York University",
        "rating": "8;8;8",
        "confidence": "4;3;5",
        "correctness": "4;3;4",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "4;3;4",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "https://midi-ddsp.github.io/",
        "github": "https://github.com/magenta/midi-ddsp"
    },
    {
        "id": "UtGtoS4CYU",
        "title": "Measuring CLEVRness: Black-box Testing of Visual Reasoning Models",
        "track": "main",
        "status": "Poster",
        "keywords": "Visual Reasoning;Visual Question Answering;Black Box Testing;Computer Vision",
        "author": "",
        "aff": "University of Warsaw, Warsaw, Poland; University of Warsaw, Google, Oxford, U.K.; DeepMind, London, U.K.",
        "rating": "6;6;6",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "3;3;2",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "UvNXZgJAOAP",
        "title": "Sharp Attention for Sequence to Sequence Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Attention mechanism;sequence to sequence learning;reinforcement learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "4;4;3;4",
        "correctness": "3;2;3;3",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.5555555555555555,
        "project": "",
        "github": ""
    },
    {
        "id": "UxBH9j8IE_H",
        "title": "Revisiting the Lottery Ticket Hypothesis: A Ramanujan Graph Perspective",
        "track": "main",
        "status": "Reject",
        "keywords": "Deep Neural Networks;Network Pruning;Ramanujan Graphs;Eigenvalue bounds;Spectral Gap",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "5;3;3;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;2;4",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "UxTR9Z2DW8R",
        "title": "Reinforcement Learning State Estimation for High-Dimensional Nonlinear Systems",
        "track": "main",
        "status": "Reject",
        "keywords": "Reinforcement learning;partial differential equation;reduced order modeling;closure models;state prediction;state estimation;dynamic mode decomposition.",
        "author": "",
        "aff": "",
        "rating": "3;3;5;8",
        "confidence": "4;3;4;4",
        "correctness": "3;3;1;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.49374193110101877,
        "corr_rating_correctness": 0.3083035200691658,
        "project": "",
        "github": ""
    },
    {
        "id": "Uxppuphg5ZL",
        "title": "Constraint-based graph network simulator",
        "track": "main",
        "status": "Reject",
        "keywords": "Physical simulations;graph neural network",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;3;4;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.13245323570650439,
        "corr_rating_correctness": 0.13245323570650439,
        "project": "",
        "github": ""
    },
    {
        "id": "Uy6YEI9-6v",
        "title": "Object-Centric Neural Scene Rendering",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5",
        "confidence": "4;3;3;4",
        "correctness": "4;3;3;2",
        "technical_novelty": "3;3;2;2",
        "empirical_novelty": "1;2;2;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "UyBxDoukIB",
        "title": "Teamwork makes von Neumann work:Min-Max Optimization in Two-Team Zero-Sum Games",
        "track": "main",
        "status": "Reject",
        "keywords": "Min-max Optimization;Non-convex Optimization;Multi-agent learning;Multi-agent GANs;Game Theory;Duality Gap",
        "author": "",
        "aff": "",
        "rating": "3;6;6;6",
        "confidence": "4;4;3;4",
        "correctness": "4;3;3;4",
        "technical_novelty": "1;2;2;3",
        "empirical_novelty": "1;2;2;0",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "UzOEYQM-xTg",
        "title": "Robust Long-Tailed Learning under Label Noise",
        "track": "main",
        "status": "Withdraw",
        "keywords": "weakly-supervised learning;long-tailed learning;learning with noisy labels;semi-supervised learning;multi-label learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5",
        "confidence": "4;4;5",
        "correctness": "3;2;3",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 1.0,
        "corr_rating_correctness": 0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "V09OhBn8iR",
        "title": "Mitigating Dataset Bias Using Per-Sample Gradients From A Biased Classifier",
        "track": "main",
        "status": "Reject",
        "keywords": "dataset bias;debiasing;representation bias",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "4;4;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "3;3;2;2",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "V0A5g83gdQ_",
        "title": "Tuformer: Data-driven Design of Transformers for Improved Generalization or Efficiency",
        "track": "main",
        "status": "Poster",
        "keywords": "Attention Modules;Transformers;Data-driven Model Design;Trainable Heads;Expressive Power;Tensor Methods.",
        "author": "",
        "aff": "Department of Computer Science, University of Maryland, College Park, MD 20740, USA",
        "rating": "5;5;6;6",
        "confidence": "4;4;4;4",
        "correctness": "3;2;3;2",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;2;2",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 4.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/umd-huang-lab/tuformer"
    },
    {
        "id": "V0LnyelKACB",
        "title": "Accelerating HEP simulations with Neural Importance Sampling",
        "track": "main",
        "status": "Reject",
        "keywords": "Importance Sampling;Normalizing Flows;High-Energy-Physics",
        "author": "",
        "aff": "Paper under double-blind review",
        "rating": "3;3;3;5",
        "confidence": "3;4;3;4",
        "correctness": "4;4;3;4",
        "technical_novelty": "1;2;1;2",
        "empirical_novelty": "2;2;1;3",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 1.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "V1MBgNBx5E",
        "title": "Mask and Understand: Evaluating the Importance of Parameters",
        "track": "main",
        "status": "Withdraw",
        "keywords": "influence function;interpretability;model pruning;feature importance ranking",
        "author": "",
        "aff": "",
        "rating": "1;3;8",
        "confidence": "5;5;5",
        "correctness": "1;3;4",
        "technical_novelty": "1;2;4",
        "empirical_novelty": "1;2;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 5.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9078412990032039,
        "project": "",
        "github": ""
    },
    {
        "id": "V2WidtMGSRG",
        "title": "Provable Identifiability of ReLU Neural Networks via Lasso Regularization",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Lasso;nonlinear regression;model selection",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "3;3;3;2",
        "correctness": "2;3;4;4",
        "technical_novelty": "1;3;3;3",
        "empirical_novelty": "1;2;3;0",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 2.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6622661785325219,
        "corr_rating_correctness": 0.899228803025897,
        "project": "",
        "github": ""
    },
    {
        "id": "V37YFd_fFgN",
        "title": "Leveraging Redundancy in Attention with Reuse Transformers",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Transformers;attention;redundancy;reuse;efficient",
        "author": "",
        "aff": "",
        "rating": "1;5;6",
        "confidence": "5;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "1;3;3",
        "empirical_novelty": "1;2;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9819805060619656,
        "corr_rating_correctness": 0.654653670707977,
        "project": "",
        "github": ""
    },
    {
        "id": "V3C8p78sDa",
        "title": "Exploring the Limits of Large Scale Pre-training",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Scaling law;Pre-training;Transfer learning;Large Scale;Vision Transformer;Few Shot;Empirical Investigation",
        "author": "",
        "aff": "Google Research",
        "rating": "6;8;8;8",
        "confidence": "3;3;3;3",
        "correctness": "4;4;3;4",
        "technical_novelty": "3;3;2;2",
        "empirical_novelty": "3;3;3;4",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "V3NZqmGA6yk",
        "title": "Beyond Pixels: A Sample Based Method for understanding the decisions of Neural Networks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Machine Learning Interpretability;Bias;ImageNet;AlexNet;ResNet;VGG-16;Inception;CNNs;MNIST",
        "author": "",
        "aff": "",
        "rating": "1;3;3;3",
        "confidence": "3;2;4;3",
        "correctness": "2;3;3;2",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 2.5,
        "confidence_avg": 3.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "V70cjLuGACn",
        "title": "Closed-loop Control for Online Continual Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Continual Learnig;Reinforcement learning;Class-incremental Continual Learning;Online Learning",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;4;4;4",
        "correctness": "2;3;4;3",
        "technical_novelty": "3;2;2;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.6488856845230502,
        "project": "",
        "github": ""
    },
    {
        "id": "V7eSbSAz-O8",
        "title": "Benchmarking Machine Learning Robustness in Covid-19 Spike Sequence Classification",
        "track": "main",
        "status": "Reject",
        "keywords": "COVID-19;Sequence Classification;Spike Sequences;k-mers;Deep Learning",
        "author": "",
        "aff": "",
        "rating": "1;1;3",
        "confidence": "5;4;5",
        "correctness": "2;1;2",
        "technical_novelty": "2;1;1",
        "empirical_novelty": "2;2;1",
        "presentation": "",
        "rating_avg": 1.6666666666666667,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 1.6666666666666667,
        "technical_novelty_avg": 1.3333333333333333,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.4999999999999999,
        "corr_rating_correctness": 0.4999999999999999,
        "project": "",
        "github": ""
    },
    {
        "id": "V8UTvwzUOcX",
        "title": "Biased Multi-Domain Adversarial Training",
        "track": "main",
        "status": "Withdraw",
        "keywords": "adversarial training;adversarial robustness",
        "author": "",
        "aff": "",
        "rating": "5;5;5",
        "confidence": "4;3;4",
        "correctness": "3;4;3",
        "technical_novelty": "3;2;2",
        "empirical_novelty": "3;2;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "VABfTTrrOv",
        "title": "Conjugation Invariant Learning with Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "Learning under group actions;Neural networks;Group representations;Characters;Class functions",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3;5",
        "confidence": "1;4;4;4;2",
        "correctness": "3;3;4;4;4",
        "technical_novelty": "2;2;2;3;4",
        "empirical_novelty": "2;1;1;2;1",
        "presentation": "",
        "rating_avg": 3.4,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 1.4,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3952847075210474,
        "corr_rating_correctness": 0.4082482904638631,
        "project": "",
        "github": ""
    },
    {
        "id": "VAmkgdMztWs",
        "title": "Network robustness as a mathematical property: training, evaluation and attack",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "Paper under double-blind review",
        "rating": "1;1;3",
        "confidence": "4;5;3",
        "correctness": "2;1;4",
        "technical_novelty": "1;2;1",
        "empirical_novelty": "1;2;2",
        "presentation": "",
        "rating_avg": 1.6666666666666667,
        "confidence_avg": 4.0,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 1.3333333333333333,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8660254037844385,
        "corr_rating_correctness": 0.9449111825230679,
        "project": "",
        "github": ""
    },
    {
        "id": "VBZJ_3tz-t",
        "title": "The Unreasonable Effectiveness of Random Pruning: Return of the Most Naive Baseline for Sparse Training",
        "track": "main",
        "status": "Poster",
        "keywords": "random pruning;sparse training;static sparse training;layer-wise sparsities;dynamic sparse training",
        "author": "",
        "aff": "University of Texas at Austin; JD Explore Academy; Eindhoven University of Technology; University of Twente",
        "rating": "6;6;6;8",
        "confidence": "5;5;4;4",
        "correctness": "4;3;4;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "3;2;3;4",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 4.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": "https://github.com/VITA-Group/Random_Pruning"
    },
    {
        "id": "VCD05OEn7r",
        "title": "CAGE: Probing Causal Relationships in Deep Generative Models",
        "track": "main",
        "status": "Reject",
        "keywords": "Generative Models;Causality",
        "author": "",
        "aff": "",
        "rating": "3;3;6;6",
        "confidence": "4;4;4;4",
        "correctness": "2;3;4;3",
        "technical_novelty": "3;1;3;4",
        "empirical_novelty": "3;0;3;4",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.7071067811865476,
        "project": "",
        "github": ""
    },
    {
        "id": "VDdDvnwFoyM",
        "title": "TimeVAE: A Variational Auto-Encoder for Multivariate Time Series Generation",
        "track": "main",
        "status": "Reject",
        "keywords": "VAE;Variational Auto Encoder;Time Series;Data Generation;GAN;Generative Adversarial Network",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "4;4;4;4",
        "correctness": "4;3;3;3",
        "technical_novelty": "3;2;1;3",
        "empirical_novelty": "3;2;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "VFBjuF8HEp",
        "title": "Learning Fast Samplers for Diffusion Models by Differentiating Through Sample Quality",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "Google Research, Brain Team",
        "rating": "6;6;6;8",
        "confidence": "4;4;4;3",
        "correctness": "4;3;3;4",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "4;2;3;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "VFDDn-7_NRZ",
        "title": "Sliced Recursive Transformer",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Recursive Operation;Vision Transformer;Efficient Model;Approximating Self-Attention;Sliced Group Self-Attention",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5;6",
        "confidence": "4;4;3;4;4",
        "correctness": "2;3;3;2;3",
        "technical_novelty": "2;3;2;2;2",
        "empirical_novelty": "2;2;2;2;2",
        "presentation": "",
        "rating_avg": 4.8,
        "confidence_avg": 3.8,
        "correctness_avg": 2.6,
        "technical_novelty_avg": 2.2,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.10206207261596575,
        "corr_rating_correctness": 0.6666666666666667,
        "project": "",
        "github": ""
    },
    {
        "id": "VGnOJhd5Q1q",
        "title": "Sparse Attention with Learning to Hash",
        "track": "main",
        "status": "Poster",
        "keywords": "Sparse Attention;Transformer;Learning-to-Hash;Natural Language Processing",
        "author": "",
        "aff": "Brookhaven National Laboratory; Language Technologies Institute, Carnegie Mellon University",
        "rating": "5;6;8",
        "confidence": "5;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 6.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3273268353539886,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "VINWzIM6_6",
        "title": "Contrastive Representation Learning for 3D Protein Structures",
        "track": "main",
        "status": "Reject",
        "keywords": "representation learning;structural bioinformatics;proteins",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "3;4;4;4",
        "correctness": "2;4;4;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9428090415820632,
        "corr_rating_correctness": 0.7385489458759963,
        "project": "",
        "github": ""
    },
    {
        "id": "VKtGrkUvCR",
        "title": "Only tails matter: Average-Case Universality and Robustness in the Convex Regime",
        "track": "main",
        "status": "Reject",
        "keywords": "optimization;average-case;first-order;random matrix theory;nesterov",
        "author": "",
        "aff": "",
        "rating": "5;5;5;8",
        "confidence": "3;4;4;4",
        "correctness": "4;4;3;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "VLgmhQDVBV",
        "title": "Implicit Bias of MSE Gradient Optimization in Underparameterized Neural Networks",
        "track": "main",
        "status": "Poster",
        "keywords": "underparameterized regime;spectral bias;neural tangent kernel;implicit bias;implicit regularization;gradient flow",
        "author": "",
        "aff": "UCLA Departments of Mathematics and Statistics and MPI MIS; UCLA Departments of Mathematics",
        "rating": "5;6;6;8",
        "confidence": "3;3;3;3",
        "correctness": "4;4;4;4",
        "technical_novelty": "3;3;2;3",
        "empirical_novelty": "0;0;0;4",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 1.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "VMuenFh7IpP",
        "title": "What Doesn't Kill You Makes You Robust(er): How to Adversarially Train against Data Poisoning",
        "track": "main",
        "status": "Reject",
        "keywords": "Data Poisoning;Poisoning Defenses;Adversarial Training;Empirical Defenses;Robustness;Security",
        "author": "",
        "aff": "",
        "rating": "3;6;6;8",
        "confidence": "4;2;3;3",
        "correctness": "2;4;4;3",
        "technical_novelty": "2;3;3;4",
        "empirical_novelty": "2;3;2;4",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5940885257860046,
        "corr_rating_correctness": 0.5488604301969737,
        "project": "",
        "github": ""
    },
    {
        "id": "VNXYZjGcsty",
        "title": "Chaining Data - A Novel Paradigm in Artificial Intelligence Exemplified with NMF based Clustering",
        "track": "main",
        "status": "Reject",
        "keywords": "NMF;clustering;linking data;chaining data",
        "author": "",
        "aff": "",
        "rating": "3;5;5",
        "confidence": "4;4;4",
        "correctness": "2;3;3",
        "technical_novelty": "2;3;2",
        "empirical_novelty": "1;2;2",
        "presentation": "",
        "rating_avg": 4.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9999999999999998,
        "project": "",
        "github": ""
    },
    {
        "id": "VNdFPD5wqjh",
        "title": "Generalizable Person Re-identification Without Demographics",
        "track": "main",
        "status": "Reject",
        "keywords": "Generalizable Person Re-Identification;Distributionally robust optimization",
        "author": "",
        "aff": "",
        "rating": "3;5;6;8",
        "confidence": "4;4;3;4",
        "correctness": "2;2;3;4",
        "technical_novelty": "2;2;3;4",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.16012815380508713,
        "corr_rating_correctness": 0.9198662110077999,
        "project": "",
        "github": ""
    },
    {
        "id": "VNqaB1g9393",
        "title": "Decoupled Adaptation for Cross-Domain Object Detection",
        "track": "main",
        "status": "Poster",
        "keywords": "Object Detection;Domain Adaptation;Object Localization;Deep Learning;Transfer Learning",
        "author": "",
        "aff": "School of Software, BNRist, Tsinghua University, China",
        "rating": "6;8;8;8",
        "confidence": "4;3;3;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "3;3;4;4",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 3.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "VO7bAwdWRjg",
        "title": "Fourier Features in Reinforcement Learning with Neural Networks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Deep Reinforcement Learning;Fourier features;interference;sparsity;expressiveness;preprocessing",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "3;4;4;4",
        "correctness": "2;2;2;4",
        "technical_novelty": "2;1;2;2",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.75,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "VPjw9KPWRSK",
        "title": "Self-Supervised Inference in State-Space Models",
        "track": "main",
        "status": "Poster",
        "keywords": "self-supervision;inference;state-space model;Kalman filter;recurrent neural network",
        "author": "",
        "aff": "AI4Science, AMLab, University of Amsterdam, The Netherlands; AI4Science, AMLab, Anton Pannekoek Institute, University of Amsterdam, The Netherlands",
        "rating": "6;6;6;8",
        "confidence": "4;3;3;3",
        "correctness": "4;4;3;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "VQhFC3Ki5C",
        "title": "DEEP GRAPH TREE NETWORKS",
        "track": "main",
        "status": "Reject",
        "keywords": "graph tree networks;graph tree convolution networks;graph tree attention networks;GNNs",
        "author": "",
        "aff": "",
        "rating": "1;5;5;6",
        "confidence": "5;4;4;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "1;2;2;3",
        "empirical_novelty": "1;2;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9771398364036774,
        "corr_rating_correctness": 0.5261522196019801,
        "project": "",
        "github": ""
    },
    {
        "id": "VQyHD2R3Aq",
        "title": "SPIDE: A Purely Spike-based Method for Training Feedback Spiking Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "spiking neural network;equilibrium state;spike-based training method;neuromorphic engineering",
        "author": "",
        "aff": "",
        "rating": "5;5;6",
        "confidence": "3;2;4",
        "correctness": "3;3;3",
        "technical_novelty": "3;2;2",
        "empirical_novelty": "3;3;2",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8660254037844385,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "VSu5WrtLK3q",
        "title": "A Geometric Perspective on Variational Autoencoders",
        "track": "main",
        "status": "Reject",
        "keywords": "Variational Autoencoders;Riemannian geometry",
        "author": "",
        "aff": "",
        "rating": "6;6;6;6;8",
        "confidence": "4;3;3;3;3",
        "correctness": "2;3;4;3;4",
        "technical_novelty": "3;4;2;2;4",
        "empirical_novelty": "2;3;2;2;4",
        "presentation": "",
        "rating_avg": 6.4,
        "confidence_avg": 3.2,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.6,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.2500000000000001,
        "corr_rating_correctness": 0.5345224838248488,
        "project": "",
        "github": ""
    },
    {
        "id": "VTGygqhwRXX",
        "title": "An Optics Controlling Environment and Reinforcement Learning Benchmarks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Reinforcement learning;Optical simulation;Machine Learning for Optics",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5;6",
        "confidence": "3;3;3;4;2",
        "correctness": "4;2;2;3;3",
        "technical_novelty": "2;3;2;3;2",
        "empirical_novelty": "2;3;2;0;0",
        "presentation": "",
        "rating_avg": 4.4,
        "confidence_avg": 3.0,
        "correctness_avg": 2.8,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 1.4,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.2635231383473649,
        "corr_rating_correctness": -0.13363062095621214,
        "project": "",
        "github": ""
    },
    {
        "id": "VTNjxbFRKly",
        "title": "Why Propagate Alone? Parallel Use of Labels and Features on Graphs",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "Amazon; Shanghai Jiao Tong University; University of Maryland; Fudan University",
        "rating": "5;5;5;6;8",
        "confidence": "4;4;3;4;2",
        "correctness": "4;3;3;3;4",
        "technical_novelty": "3;3;2;3;4",
        "empirical_novelty": "2;3;2;1;3",
        "presentation": "",
        "rating_avg": 5.8,
        "confidence_avg": 3.4,
        "correctness_avg": 3.4,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.2,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7717436331412899,
        "corr_rating_correctness": 0.4900980294098034,
        "project": "",
        "github": ""
    },
    {
        "id": "VUcI0pKic8l",
        "title": "Attacking Perceptual Similarity Metrics",
        "track": "main",
        "status": "Withdraw",
        "keywords": "perceptual similarity metrics;computer vision;adversarial robustness;image quality assessment;transferable adversarial examples",
        "author": "",
        "aff": "",
        "rating": "3;3;5;8",
        "confidence": "4;3;5;4",
        "correctness": "4;4;2;4",
        "technical_novelty": "3;2;2;2",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.34554737023254406,
        "corr_rating_correctness": -0.07053456158585983,
        "project": "",
        "github": ""
    },
    {
        "id": "VXqNHWh3LL",
        "title": "Shift-tolerant Perceptual Similarity Metric",
        "track": "main",
        "status": "Reject",
        "keywords": "Computer Vision;Perceptual Similarity Metric;Image Quality Assessment;Robustness;Convolutional Neural Networks;Anti-aliasing",
        "author": "",
        "aff": "",
        "rating": "3;6;8",
        "confidence": "5;5;4",
        "correctness": "2;3;4",
        "technical_novelty": "2;1;2",
        "empirical_novelty": "2;3;4",
        "presentation": "",
        "rating_avg": 5.666666666666667,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 1.6666666666666667,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8029550685469661,
        "corr_rating_correctness": 0.9933992677987828,
        "project": "",
        "github": ""
    },
    {
        "id": "VZAgsLaP3or",
        "title": "Practical No-box Adversarial Attacks with Training-free Hybrid Image Transformation",
        "track": "main",
        "status": "Reject",
        "keywords": "no-box attack;training-free;hybrid image transformation",
        "author": "",
        "aff": "",
        "rating": "3;5;8;8",
        "confidence": "5;4;4;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "1;2;2;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8164965809277261,
        "corr_rating_correctness": 0.5443310539518174,
        "project": "",
        "github": ""
    },
    {
        "id": "VZC5Lzyl0le",
        "title": "Automated Mobile Attention KPConv Networks via A Wide & Deep Predictor",
        "track": "main",
        "status": "Reject",
        "keywords": "3D Point Cloud Classification and segmentation;Neural Architecture Search",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "5;2;4;3",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5477225575051661,
        "corr_rating_correctness": 0.4714045207910316,
        "project": "",
        "github": ""
    },
    {
        "id": "Vc5wUmpwR7x",
        "title": "Minimizing Memorization in Meta-learning: A Causal Perspective",
        "track": "main",
        "status": "Withdraw",
        "keywords": "meta-learning;causality;intervention;memorization;overfitting",
        "author": "",
        "aff": "",
        "rating": "6;6;6;8",
        "confidence": "4;4;3;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;2;2",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "VdYTmPf6BZ-",
        "title": "Adversarial Robustness via Adaptive Label Smoothing",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3;5",
        "confidence": "4;4;4;4;4",
        "correctness": "1;2;3;2;4",
        "technical_novelty": "1;3;2;2;2",
        "empirical_novelty": "1;0;2;1;3",
        "presentation": "",
        "rating_avg": 3.4,
        "confidence_avg": 4.0,
        "correctness_avg": 2.4,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.4,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.7844645405527362,
        "project": "",
        "github": ""
    },
    {
        "id": "Ve0Wth3ptT_",
        "title": "DEGREE: Decomposition Based Explanation for Graph Neural Networks",
        "track": "main",
        "status": "Poster",
        "keywords": "XAI;GNN",
        "author": "",
        "aff": "Department of Computer Science, University of Georgia; Department of Computer Science, Rice University; Department of Computer Science and Engineering, Texas A&M University",
        "rating": "6;6;6;8",
        "confidence": "3;3;3;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "3;3;2;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 1.0,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "VgxHf-qUZ3D",
        "title": "Self-evolutionary optimization for Pareto front learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Pareto optimal;Multi-objective optimization;Multi-task learning;Evolutionary strategy",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "3;4;4;2",
        "correctness": "2;3;2;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "1;2;3;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5222329678670935,
        "corr_rating_correctness": 0.5222329678670935,
        "project": "",
        "github": ""
    },
    {
        "id": "VimqQq-i_Q",
        "title": "What Do We Mean by Generalization in Federated Learning?",
        "track": "main",
        "status": "Poster",
        "keywords": "Federated Learning;generalization;heterogeneity",
        "author": "",
        "aff": "Stanford University; Google Research",
        "rating": "6;6;6;8",
        "confidence": "3;4;3;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;2;3;4",
        "empirical_novelty": "2;2;2;4",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "Vjki79-619-",
        "title": "Proving the Lottery Ticket Hypothesis for Convolutional Neural Networks",
        "track": "main",
        "status": "Poster",
        "keywords": "lottery ticket hypothesis;convolutional neural network;network pruning;random subset sum;random neural network",
        "author": "",
        "aff": "Inria Paris, IRIF, Paris, France; Inria Sophia Antipolis, Sophia Antipolis, France",
        "rating": "5;6;8;8",
        "confidence": "4;2;3;4",
        "correctness": "4;4;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "0;0;2;2",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 3.25,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 1.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.058025885318565944,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "VjoSeYLAiZN",
        "title": "A NEW BACKBONE FOR HYPERSPECTRAL IMAGE RECONSTRUCTION",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;4;3;3",
        "correctness": "2;2;3;3",
        "technical_novelty": "1;3;2;3",
        "empirical_novelty": "3;0;3;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6882472016116854,
        "corr_rating_correctness": 0.6882472016116854,
        "project": "",
        "github": ""
    },
    {
        "id": "VnurXbqxr0B",
        "title": "STRIC: Stacked Residuals of Interpretable Components for Time Series Anomaly Detection",
        "track": "main",
        "status": "Reject",
        "keywords": "Anomaly Detection;Time-Series forecasting;Residual Temporal Convolutional Networks",
        "author": "",
        "aff": "Paper under double-blind review",
        "rating": "5;5;6",
        "confidence": "5;4;4",
        "correctness": "3;2;3",
        "technical_novelty": "3;2;4",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4999999999999999,
        "corr_rating_correctness": 0.4999999999999999,
        "project": "",
        "github": ""
    },
    {
        "id": "Vog_3GXsgmb",
        "title": "Discovering Nonlinear PDEs from Scarce Data with Physics-encoded Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "Data-driven equation discovery;dynamical system modeling;physics-encoded learning",
        "author": "",
        "aff": "Renmin University of China; Northeastern University",
        "rating": "5;5;5;6;6",
        "confidence": "5;5;4;2;3",
        "correctness": "2;3;3;3;4",
        "technical_novelty": "2;3;2;3;3",
        "empirical_novelty": "2;2;2;3;0",
        "presentation": "",
        "rating_avg": 5.4,
        "confidence_avg": 3.8,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 1.8,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.910182054618206,
        "corr_rating_correctness": 0.6454972243679027,
        "project": "",
        "github": ""
    },
    {
        "id": "VppWsjXgBY6",
        "title": "TLDR: Twin Learning for Dimensionality Reduction",
        "track": "main",
        "status": "Withdraw",
        "keywords": "dimensionality reduction;manifold learning;image retrieval;document retrieval;PCA",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "4;5;4;3",
        "correctness": "4;3;3;4",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;3;4",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.816496580927726,
        "corr_rating_correctness": 0.19245008972987526,
        "project": "",
        "github": ""
    },
    {
        "id": "Vq_QHT5kcAK",
        "title": "Greedy Bayesian Posterior Approximation with Deep Ensembles",
        "track": "main",
        "status": "Reject",
        "keywords": "Bayesian posterior;deep ensembles;submodular optimization",
        "author": "",
        "aff": "",
        "rating": "3;6;6",
        "confidence": "4;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "2;2;4",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.0,
        "project": "Not provided",
        "github": "Not provided"
    },
    {
        "id": "VqzXzA9hjaX",
        "title": "Optimizer Amalgamation",
        "track": "main",
        "status": "Poster",
        "keywords": "Learning to Optimize;Knowledge Amalgamation;Stability-Aware Training",
        "author": "",
        "aff": "",
        "rating": "6;6;6;6",
        "confidence": "4;3;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "Vr_BTpw3wz",
        "title": "Hindsight: Posterior-guided training of retrievers for improved open-ended generation",
        "track": "main",
        "status": "Poster",
        "keywords": "retrieval;generation;retrieval-augmented generation;open-ended generation;informative conversations;free-form QA;posterior distribution;ELBo",
        "author": "",
        "aff": "Stanford University",
        "rating": "6;6;8;8",
        "confidence": "3;4;4;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "3;2;3;4",
        "empirical_novelty": "2;2;2;0",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "VrjOFfcnSV8",
        "title": "Entroformer: A Transformer-based Entropy Model for Learned Image Compression",
        "track": "main",
        "status": "Poster",
        "keywords": "Image compression;Entropy Model;Global Dependencies",
        "author": "",
        "aff": "Alibaba Group, Bellevue, WA, 98004, USA; Alibaba Group, Hangzhou, China",
        "rating": "6;6;8",
        "confidence": "4;5;3",
        "correctness": "3;3;4",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8660254037844385,
        "corr_rating_correctness": 0.9999999999999998,
        "project": "",
        "github": "https://github.com/damo-cv/entroformer"
    },
    {
        "id": "Vs5NK44aP9P",
        "title": "Encoding Weights of Irregular Sparsity for Fixed-to-Fixed Model Compression",
        "track": "main",
        "status": "Poster",
        "keywords": "Sparse Neural Network;Fixed-to-fixed data compression;Unstructured Pruning",
        "author": "",
        "aff": "NAVER CLOVA; Samsung Research",
        "rating": "5;6;6;8",
        "confidence": "3;4;3;3",
        "correctness": "4;3;3;4",
        "technical_novelty": "2;3;4;3",
        "empirical_novelty": "2;3;4;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.13245323570650439,
        "corr_rating_correctness": 0.2294157338705618,
        "project": "",
        "github": ""
    },
    {
        "id": "Vt1lpp5Vebd",
        "title": "Maximum Likelihood Estimation for Multimodal Learning with Missing Modality",
        "track": "main",
        "status": "Reject",
        "keywords": "multimodal learning;missing modality;maximum likelihood estimation",
        "author": "",
        "aff": "",
        "rating": "3;3;3",
        "confidence": "4;4;4",
        "correctness": "3;3;2",
        "technical_novelty": "3;2;2",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "VuEqOs9Yp7Q",
        "title": "Temporal Action Localization with Global Segmentation Mask Transformers",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Temporal Action Localization;Transformer;Global Contextual Learning;Self-attention Learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "5;5;4;3",
        "correctness": "3;3;2;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.986440050415621,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "VuW5ojKGI43",
        "title": "Protecting Your NLG Models with Semantic and Robust Watermarks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;6",
        "confidence": "3;3;4",
        "correctness": "2;3;3",
        "technical_novelty": "3;2;4",
        "empirical_novelty": "4;2;3",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9999999999999997,
        "corr_rating_correctness": 0.4999999999999999,
        "project": "",
        "github": ""
    },
    {
        "id": "Vvb-eicR8N",
        "title": "Learning-Augmented Sketches for Hessians",
        "track": "main",
        "status": "Reject",
        "keywords": "least squares;convex optimization;iterative Hessian sketch;subspace embedding;learning-augmented sketch",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5",
        "confidence": "3;3;3;3",
        "correctness": "4;4;4;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "Vvmj4zGU_z3",
        "title": "To Smooth or not to Smooth? On Compatibility between Label Smoothing and Knowledge Distillation",
        "track": "main",
        "status": "Withdraw",
        "keywords": "label smoothing;knowledge distillation;systematic diffusion;semantically similar classes",
        "author": "",
        "aff": "",
        "rating": "5;6;6;6",
        "confidence": "3;4;3;4",
        "correctness": "4;3;4;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;0;4",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "VwSHZgruNEc",
        "title": "Safe Opponent-Exploitation Subgame Refinement",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;6;8",
        "confidence": "4;4;3;4",
        "correctness": "4;4;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;2;4",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.16012815380508713,
        "corr_rating_correctness": -0.8320502943378437,
        "project": "",
        "github": ""
    },
    {
        "id": "Vx8l4vwv94",
        "title": "JOINTLY LEARNING TOPIC SPECIFIC WORD AND DOCUMENT EMBEDDING",
        "track": "main",
        "status": "Reject",
        "keywords": "Language modeling \u00b7Document embedding \u00b7Natural language processing \u00b7Machine learning",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;5;4;4",
        "correctness": "2;2;3;4",
        "technical_novelty": "2;1;1;2",
        "empirical_novelty": "2;1;1;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 1.5,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.8703882797784891,
        "project": "",
        "github": ""
    },
    {
        "id": "Vy5WbmrVPaD",
        "title": "Pretext Tasks Selection for Multitask Self-Supervised Speech Representation Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Self-Supervised Learning;Speech Processing;Representation Learning",
        "author": "",
        "aff": "",
        "rating": "3;3;6",
        "confidence": "3;5;3",
        "correctness": "2;2;3",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5000000000000001,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "VyZRObZ19kt",
        "title": "Learned Index with Dynamic $\\epsilon$",
        "track": "main",
        "status": "Reject",
        "keywords": "Learned Index;Dynamic $\\epsilon$",
        "author": "",
        "aff": "",
        "rating": "3;3;8",
        "confidence": "3;4;3",
        "correctness": "3;2;3",
        "technical_novelty": "2;3;2",
        "empirical_novelty": "3;2;2",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5000000000000001,
        "corr_rating_correctness": 0.5000000000000001,
        "project": "",
        "github": ""
    },
    {
        "id": "Vzh1BFUCiIX",
        "title": "ExT5: Towards Extreme Multi-Task Scaling for Transfer Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "Natural Language Processing;Transfer Learning;Multi-task Learning",
        "author": "",
        "aff": "Carnegie Mellon University (CMU); Not provided; Google Research, previously DeepMind; Google Research",
        "rating": "5;6;8;8",
        "confidence": "4;4;5;4",
        "correctness": "3;4;4;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;3;3;4",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 4.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5555555555555555,
        "corr_rating_correctness": 0.7777777777777777,
        "project": "",
        "github": ""
    },
    {
        "id": "W08IqLMlMer",
        "title": "Offline Pre-trained Multi-Agent Decision Transformer",
        "track": "main",
        "status": "Reject",
        "keywords": "Multi-Agent Reinforcement Learning;Offline Reinforcement Learning;Machine Learning",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "5;4;4;3",
        "correctness": "3;3;1;3",
        "technical_novelty": "1;2;2;2",
        "empirical_novelty": "3;2;0;3",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.816496580927726,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "W0KJGRBH60o",
        "title": "Dynamic Differential-Privacy Preserving SGD",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Differential Privacy;Deep Learning;DP-SGD",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;3;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "W2gO9bYYG5P",
        "title": "Can Vision Transformers Perform Convolution?",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Vision Transformers;CNN;expressive power;multi-head self-attention",
        "author": "",
        "aff": "",
        "rating": "1;3;5",
        "confidence": "5;5;4",
        "correctness": "1;4;3",
        "technical_novelty": "2;3;2",
        "empirical_novelty": "1;3;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8660254037844385,
        "corr_rating_correctness": 0.6546536707079771,
        "project": "",
        "github": ""
    },
    {
        "id": "W3-hiLnUYl",
        "title": "On the Practicality of Deterministic Epistemic Uncertainty",
        "track": "main",
        "status": "Reject",
        "keywords": "uncertainty;epistemic uncertainty;uncertainty calibration",
        "author": "",
        "aff": "",
        "rating": "3;5;5;8",
        "confidence": "4;4;4;5",
        "correctness": "1;3;3;4",
        "technical_novelty": "2;1;1;4",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8892972917998875,
        "corr_rating_correctness": 0.9316142209946916,
        "project": "",
        "github": ""
    },
    {
        "id": "W5PbuwQFzZx",
        "title": "Locality-Based Mini Batching for Graph Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "GNN;graph neural network;graphs;scalability;batching;local clustering",
        "author": "",
        "aff": "",
        "rating": "5;5;6",
        "confidence": "4;4;4",
        "correctness": "2;3;4",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "3;3;2",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.8660254037844385,
        "project": "",
        "github": ""
    },
    {
        "id": "W6BpshgRi0q",
        "title": "Ask2Mask: Guided Data Selection for Masked Speech Modeling",
        "track": "main",
        "status": "Reject",
        "keywords": "Masked speech modeling (MSM);Data selection;Self-supervision;ASR;Speech recognition",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;5;4;5",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "2;3;2;2",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.6882472016116854,
        "corr_rating_correctness": 0.6622661785325219,
        "project": "",
        "github": ""
    },
    {
        "id": "W6lWkLqOss",
        "title": "Class-Weighted Evaluation Metrics for Imbalanced Data Classification",
        "track": "main",
        "status": "Reject",
        "keywords": "Imbalanced data classification;Evaluation metrics;Log parsing;Sentiment analysis;URL classification",
        "author": "",
        "aff": "",
        "rating": "1;3;6;6",
        "confidence": "5;5;4;3",
        "correctness": "2;4;3;3",
        "technical_novelty": "1;2;3;3",
        "empirical_novelty": "2;1;2;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8528028654224419,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "W9G_ImpHlQd",
        "title": "How to Robustify Black-Box ML Models? A Zeroth-Order Optimization Perspective",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Zeroth-Order Optimization;Black-Box Defense;Gradient-Free;Adversarial Robustness;Certified Defense",
        "author": "",
        "aff": "Michigan State University; University of Minnesota; UC Santa Barbara; JD AI Research",
        "rating": "8;8;8;8",
        "confidence": "3;4;5;4",
        "correctness": "3;4;3;3",
        "technical_novelty": "3;4;4;3",
        "empirical_novelty": "3;3;4;3",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.5,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/damon-demon/Black-Box-Defense"
    },
    {
        "id": "WAid50QschI",
        "title": "Sparse Communication via Mixed Distributions",
        "track": "main",
        "status": "Oral",
        "keywords": "",
        "author": "",
        "aff": "IvI, University of Amsterdam; Unbabel; Instituto de Telecomunica\u00e7\u00f5es, Instituto Superior T\u00e9cnico (Lisbon ELLIS Unit); ILLC, University of Amsterdam",
        "rating": "6;8;8;8",
        "confidence": "2;3;3;5",
        "correctness": "2;4;4;4",
        "technical_novelty": "3;3;4;4",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.5,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.6622661785325219,
        "corr_rating_correctness": 1.0,
        "project": "Not provided",
        "github": "Not provided"
    },
    {
        "id": "WDBo7y8lcJm",
        "title": "Teacher's pet: understanding and mitigating biases in distillation",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "5;5;4;5",
        "correctness": "3;4;3;4",
        "technical_novelty": "2;2;3;4",
        "empirical_novelty": "2;2;3;4",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4714045207910316,
        "corr_rating_correctness": 0.40824829046386296,
        "project": "",
        "github": ""
    },
    {
        "id": "WE4qe9xlnQw",
        "title": "A Program to Build E(N)-Equivariant Steerable CNNs",
        "track": "main",
        "status": "Poster",
        "keywords": "equivariance;3D;geometric deep learning;isometries;steerable CNN",
        "author": "",
        "aff": "University of Amsterdam; Qualcomm AI Research\u2217, University of Amsterdam",
        "rating": "6;6;6;8",
        "confidence": "2;3;3;2",
        "correctness": "3;4;4;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;2;3;2",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 2.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "WGhT5zCamoC",
        "title": "Seq2Tok: Deep Sequence Tokenizer for Retrieval",
        "track": "main",
        "status": "Withdraw",
        "keywords": "sequence representation learning;audio search;music retrieval",
        "author": "",
        "aff": "",
        "rating": "1;3;5;5",
        "confidence": "4;3;3;3",
        "correctness": "2;3;2;3",
        "technical_novelty": "1;2;2;3",
        "empirical_novelty": "1;2;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8703882797784891,
        "corr_rating_correctness": 0.30151134457776363,
        "project": "",
        "github": ""
    },
    {
        "id": "WH6u2SvlLp4",
        "title": "Learning Prototype-oriented Set Representations for Meta-Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "Summary Networks;Distribution Matching;Optimal Transport;Few-shot Classification;Meta Generative Models",
        "author": "",
        "aff": "The Chinese University of Hong Kong, Shenzhen; Georgia Institute of Technology; The University of Texas at Austin; Xidian University",
        "rating": "6;6;6;8",
        "confidence": "4;2;3;3",
        "correctness": "4;3;4;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "WHA8009laxu",
        "title": "Federated Learning from Only Unlabeled Data with Class-conditional-sharing Clients",
        "track": "main",
        "status": "Poster",
        "keywords": "unsupervised federated learning;unlabeled data;class prior shift",
        "author": "",
        "aff": "The University of Tokyo; RIKEN; The Chinese University of Hong Kong; The University of British Columbia",
        "rating": "6;8;8;8",
        "confidence": "2;3;4;4",
        "correctness": "3;4;4;3",
        "technical_novelty": "3;3;4;3",
        "empirical_novelty": "2;3;4;3",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8703882797784891,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": "https://github.com/lunanbit/FedUL"
    },
    {
        "id": "WIJVRV7jnTX",
        "title": "Calibrated ensembles - a simple way to mitigate ID-OOD accuracy tradeoffs",
        "track": "main",
        "status": "Reject",
        "keywords": "distribution shift;calibration;ensembles",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "4;3;4;3",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "WKWAkkXGpWN",
        "title": "Efficient Training and Inference of Hypergraph Reasoning Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "Relational Rule Induction;Hypergraph Network;Efficient Learning",
        "author": "",
        "aff": "",
        "rating": "3;3;6;6;6",
        "confidence": "3;4;3;4;3",
        "correctness": "1;3;3;3;3",
        "technical_novelty": "3;2;2;3;3",
        "empirical_novelty": "2;1;2;3;3",
        "presentation": "",
        "rating_avg": 4.8,
        "confidence_avg": 3.4,
        "correctness_avg": 2.6,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 2.2,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.16666666666666669,
        "corr_rating_correctness": 0.6123724356957944,
        "project": "",
        "github": ""
    },
    {
        "id": "WLEx3Jo4QaB",
        "title": "Graph Condensation for Graph Neural Networks",
        "track": "main",
        "status": "Poster",
        "keywords": "data-efficient learning;graph generation;graph neural networks",
        "author": "",
        "aff": "Snap Inc.; Michigan State University; Carnegie Mellon University; UCLA",
        "rating": "5;6;6;6",
        "confidence": "4;4;3;4",
        "correctness": "4;3;3;3",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "4;2;3;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": -1.0,
        "project": "",
        "github": "https://github.com/ChandlerBang/GCond"
    },
    {
        "id": "WLZ_2JjCz2a",
        "title": "Sparse Unbalanced GAN Training with In-Time Over-Parameterization",
        "track": "main",
        "status": "Withdraw",
        "keywords": "sparse unbalance GAN training;GAN training;dynamic sparse training;sparse training;bigGAN",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "4;3;3;3",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5555555555555555,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "WN2Sup7qLdw",
        "title": "Multi-Resolution Continuous Normalizing Flows",
        "track": "main",
        "status": "Reject",
        "keywords": "Normalizing flows;generative models;neural ode;continuous normalizing flows;computer vision",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5;6",
        "confidence": "4;3;3;4;4",
        "correctness": "2;2;3;3;3",
        "technical_novelty": "2;2;2;2;4",
        "empirical_novelty": "2;2;2;2;4",
        "presentation": "",
        "rating_avg": 4.4,
        "confidence_avg": 3.6,
        "correctness_avg": 2.6,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.2721655269759087,
        "corr_rating_correctness": 0.9525793444156803,
        "project": "",
        "github": ""
    },
    {
        "id": "WNTscnQd1s",
        "title": "Sparsistent Model Discovery",
        "track": "main",
        "status": "Reject",
        "keywords": "model discovery;sparse regression;sparsistency;physics informed deep learning;partial differential equations",
        "author": "",
        "aff": "Paper under double-blind review",
        "rating": "3;3;5;5",
        "confidence": "3;4;3;3",
        "correctness": "4;2;3;2",
        "technical_novelty": "2;3;2;2",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": -0.30151134457776363,
        "project": "https://anonymous.4open.science/r/sparsistent_model_disco-56F8/",
        "github": ""
    },
    {
        "id": "WPI2vbkAl3Q",
        "title": "Learning Curves for SGD on Structured Features",
        "track": "main",
        "status": "Poster",
        "keywords": "Stochastic Gradient Descent;Generalization",
        "author": "",
        "aff": "John A. Paulson School of Engineering and Applied Sciences, Center for Brain Science, Harvard University, Cambridge, MA 02138, USA",
        "rating": "5;5;6;8",
        "confidence": "3;4;4;3",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;0;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.40824829046386296,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "WQIdU90Gsu",
        "title": "Compound Multi-branch Feature Fusion for Real Image Restoration",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "1;3;3;3;6",
        "confidence": "5;4;4;5;4",
        "correctness": "2;3;2;2;3",
        "technical_novelty": "2;2;2;2;2",
        "empirical_novelty": "1;2;2;2;3",
        "presentation": "",
        "rating_avg": 3.2,
        "confidence_avg": 4.4,
        "correctness_avg": 2.4,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6123724356957946,
        "corr_rating_correctness": 0.6634034720037775,
        "project": "",
        "github": "https://github.com/publish_after_accepting/CMFNet"
    },
    {
        "id": "WQVouCWioh",
        "title": "Design in the Dark: Learning Deep Generative Models for De Novo Protein Design",
        "track": "main",
        "status": "Reject",
        "keywords": "generative models;sequence design;language models;proteins",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5;5",
        "confidence": "5;4;4;4;3",
        "correctness": "1;3;2;3;3",
        "technical_novelty": "2;2;2;2;3",
        "empirical_novelty": "1;2;2;2;2",
        "presentation": "",
        "rating_avg": 3.8,
        "confidence_avg": 4.0,
        "correctness_avg": 2.4,
        "technical_novelty_avg": 2.2,
        "empirical_novelty_avg": 1.8,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6454972243679028,
        "corr_rating_correctness": 0.6123724356957946,
        "project": "",
        "github": ""
    },
    {
        "id": "WQX6Zel-ZS1",
        "title": "Camera Bias Regularization for Person Re-identification",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Person Re-identification;Image Retrieval",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;4;4;4",
        "correctness": "3;4;3;3",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;0;3;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "WQc075jmBmf",
        "title": "CodeTrek: Flexible Modeling of Code using an Extensible Relational Representation",
        "track": "main",
        "status": "Poster",
        "keywords": "relational database;code representation;knowledge graph reasoning;program understanding",
        "author": "",
        "aff": "Simon Fraser University; Google Research; University of Pennsylvania",
        "rating": "5;5;5;8",
        "confidence": "5;4;5;5",
        "correctness": "3;2;4;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 4.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.5222329678670935,
        "project": "",
        "github": ""
    },
    {
        "id": "WRORN3GUCu",
        "title": "VISCOS Flows: Variational Schur Conditional Sampling with Normalizing Flows",
        "track": "main",
        "status": "Reject",
        "keywords": "Normalizing Flows;Conditional Sampling;Implicit Methods",
        "author": "",
        "aff": "",
        "rating": "3;3;5",
        "confidence": "3;4;3",
        "correctness": "4;4;3",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "0;1;1",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 0.6666666666666666,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5,
        "corr_rating_correctness": -1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "WTXMNULQ3Uu",
        "title": "Generating Scenes with Latent Object Models",
        "track": "main",
        "status": "Reject",
        "keywords": "deep generative models;slots;scene generation;object-centric;VAEs",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "4;5;4;4",
        "correctness": "1;2;3;3",
        "technical_novelty": "2;1;3;3",
        "empirical_novelty": "2;2;4;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 4.25,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5555555555555555,
        "corr_rating_correctness": 0.8703882797784892,
        "project": "",
        "github": ""
    },
    {
        "id": "WVX0NNVBBkV",
        "title": "Robust Learning Meets Generative Models: Can Proxy Distributions Improve Adversarial Robustness?",
        "track": "main",
        "status": "Poster",
        "keywords": "adversarial robustness;certified adversarial robustness;adversarial attacks;generative models;proxy distribution",
        "author": "",
        "aff": "Princeton University; Caltech; Purdue University",
        "rating": "6;6;8;8",
        "confidence": "3;4;4;3",
        "correctness": "4;4;4;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.5,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/inspire-group/proxy-distributions"
    },
    {
        "id": "WXwg_9eRQ0T",
        "title": "MergeBERT: Program Merge Conflict Resolution via Neural Transformers",
        "track": "main",
        "status": "Reject",
        "keywords": "Software evolution;program merge;ml4code",
        "author": "",
        "aff": "",
        "rating": "3;6;6",
        "confidence": "4;4;4",
        "correctness": "3;3;2",
        "technical_novelty": "2;3;2",
        "empirical_novelty": "2;3;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "WXy4C-RjET",
        "title": "Logit Attenuating Weight Normalization",
        "track": "main",
        "status": "Reject",
        "keywords": "deep learning;gradient methods;stochastic optimization;generalization gap;imagenet;adam;large batch training",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "5;4;4;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.816496580927726,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "WYDzDksK5b",
        "title": "DiBB: Distributing Black-Box Optimization",
        "track": "main",
        "status": "Reject",
        "keywords": "Black Box Optimization;Distributed Computing;Evolutionary Computation",
        "author": "",
        "aff": "",
        "rating": "3;3;3;6",
        "confidence": "4;3;4;3",
        "correctness": "3;3;2;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "WZ3yjh8coDg",
        "title": "An Unconstrained Layer-Peeled Perspective on Neural Collapse",
        "track": "main",
        "status": "Poster",
        "keywords": "neural collapse;uncostrained model;implicit regularization",
        "author": "",
        "aff": "Stanford University; Harvard University; Peking University; University of Pennsylvania",
        "rating": "6;6;8;8",
        "confidence": "4;3;3;4",
        "correctness": "4;3;4;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "WZR7ckBkzPY",
        "title": "Variational Wasserstein gradient flow",
        "track": "main",
        "status": "Reject",
        "keywords": "Wasserstein gradient flow;JKO;f-divergence",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "5;4;4;4",
        "correctness": "2;4;4;3",
        "technical_novelty": "2;2;1;2",
        "empirical_novelty": "2;2;3;1",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": -0.17407765595569782,
        "project": "",
        "github": ""
    },
    {
        "id": "WZeI0Vro15y",
        "title": "Generative Posterior Networks for Approximately Bayesian Epistemic Uncertainty Estimation",
        "track": "main",
        "status": "Reject",
        "keywords": "Uncertainty;Bayesian;Neural Networks;Generative Models",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "2;4;4;3",
        "correctness": "2;3;3;4",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.6225430174794673,
        "corr_rating_correctness": 0.9733285267845754,
        "project": "",
        "github": ""
    },
    {
        "id": "WcZUevpX3H3",
        "title": "Personalized Neural Architecture Search for Federated Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Personalized Learning;Federated Learning",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;4;4;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "Wf5EN11MvQ3",
        "title": "Free Hyperbolic Neural Networks with Limited Radii",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Geometric deep learning;Hyperbolic neural network;Vanishing gradient problem",
        "author": "",
        "aff": "",
        "rating": "3;5;5;8",
        "confidence": "4;3;4;3",
        "correctness": "4;3;3;4",
        "technical_novelty": "1;2;2;3",
        "empirical_novelty": "1;3;2;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7001400420140049,
        "corr_rating_correctness": 0.14002800840280097,
        "project": "",
        "github": ""
    },
    {
        "id": "WfvgGBcgbE7",
        "title": "Model Zoo: A Growing Brain That Learns Continually",
        "track": "main",
        "status": "Poster",
        "keywords": "Continual Learning;Learning Theory",
        "author": "",
        "aff": "University of Pennsylvania",
        "rating": "5;6;6;8",
        "confidence": "4;4;5;3",
        "correctness": "2;3;3;4",
        "technical_novelty": "4;3;2;3",
        "empirical_novelty": "4;3;2;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6488856845230502,
        "corr_rating_correctness": 0.9733285267845754,
        "project": "",
        "github": ""
    },
    {
        "id": "WlPPBKnOB4w",
        "title": "One Stage Autoencoders for Multi-Domain Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "energy-based models;probabilistic models;autoencoders;optimization;learning representations;unsupervised learning",
        "author": "",
        "aff": "",
        "rating": "1;1;3;3",
        "confidence": "4;2;3;3",
        "correctness": "1;2;3;3",
        "technical_novelty": "1;2;3;2",
        "empirical_novelty": "0;1;1;2",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.0,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9045340337332909,
        "project": "",
        "github": ""
    },
    {
        "id": "Wm3EA5OlHsG",
        "title": "Scene Transformer: A unified architecture for predicting future trajectories of multiple agents",
        "track": "main",
        "status": "Poster",
        "keywords": "trajectory prediction;motion forecasting;multi-task learning;attention;autonomous vehicles",
        "author": "",
        "aff": "Waymo; Google Research, Brain Team",
        "rating": "5;6;8;8",
        "confidence": "5;5;5;4",
        "correctness": "3;4;3;4",
        "technical_novelty": "2;2;3;4",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 4.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5555555555555555,
        "corr_rating_correctness": 0.19245008972987526,
        "project": "",
        "github": ""
    },
    {
        "id": "WnOLO1f50MH",
        "title": "Exploiting Redundancy: Separable Group Convolutional Networks on Lie Groups",
        "track": "main",
        "status": "Reject",
        "keywords": "Group equivariance;separable convolutions;group equivariant neural networks",
        "author": "",
        "aff": "",
        "rating": "5;5;6;8",
        "confidence": "4;5;3;3",
        "correctness": "4;2;4;4",
        "technical_novelty": "2;2;4;3",
        "empirical_novelty": "2;1;1;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7385489458759963,
        "corr_rating_correctness": 0.4714045207910316,
        "project": "",
        "github": ""
    },
    {
        "id": "WqoBaaPHS-",
        "title": "Top-label calibration and multiclass-to-binary reductions",
        "track": "main",
        "status": "Poster",
        "keywords": "calibration;multiclass;uncertainty quantification;distribution-free;histogram binning",
        "author": "",
        "aff": "Carnegie Mellon University",
        "rating": "5;5;6;8",
        "confidence": "3;4;3;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;3;4;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.40824829046386296,
        "corr_rating_correctness": 0.9428090415820632,
        "project": "",
        "github": "https://github.com/aigen/df-posthoc-calibration"
    },
    {
        "id": "Wsif-S7ggTM",
        "title": "Cross-Stage Transformer for Video Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Transformer;video recognition",
        "author": "",
        "aff": "",
        "rating": "3;3;3;6",
        "confidence": "5;4;4;5",
        "correctness": "2;4;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 4.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "WtPHnvDUk5X",
        "title": "GANet: Glyph-Attention Network for Few-Shot Font Generation",
        "track": "main",
        "status": "Reject",
        "keywords": "font generation;GANet;glyph-attention;few-shot;GAN",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;5;5;4",
        "correctness": "4;3;3;3",
        "technical_novelty": "1;3;2;2",
        "empirical_novelty": "2;3;2;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 4.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": -1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "WuEiafqdy9H",
        "title": "Model-augmented Prioritized Experience Replay",
        "track": "main",
        "status": "Poster",
        "keywords": "RL;Reinforcement Learning;Replay Buffer",
        "author": "",
        "aff": "Korea Advanced Institute of Science and Technology, AITRICS; Korea Advanced Institute of Science and Technology; Samsung Advanced Institute of Technology",
        "rating": "5;6;8;8",
        "confidence": "3;5;4;3",
        "correctness": "2;3;4;3",
        "technical_novelty": "2;2;3;4",
        "empirical_novelty": "3;2;3;4",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.058025885318565944,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "WvOGCEAQhxl",
        "title": "Assessing Generalization of SGD via Disagreement",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Generalization;Deep Learning;Empirical Phenomenon;Accuracy Estimation;Stochastic Gradient Descent",
        "author": "",
        "aff": "Carnegie Mellon University; Google Research",
        "rating": "8;8;8;8",
        "confidence": "3;4;4;3",
        "correctness": "4;4;4;4",
        "technical_novelty": "3;3;4;3",
        "empirical_novelty": "3;3;4;3",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.5,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "WwKv20NrsfB",
        "title": "Apollo: An Adaptive Parameter-wised Diagonal Quasi-Newton Method for Nonconvex Stochastic Optimization",
        "track": "main",
        "status": "Reject",
        "keywords": "Optimization for Neural Networks;Optimization for Representation Learning;Stochastic Optimization;Nonconvex;Quasi-Newton;Optimization for Deep Learning",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "4;4;3;3",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8164965809277259,
        "corr_rating_correctness": 0.9428090415820632,
        "project": "anonymous link",
        "github": ""
    },
    {
        "id": "WxBFVNbDUT6",
        "title": "Benchmarking Sample Selection Strategies for Batch Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Reinforcement Learning;Experience Replay",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;4;3;4",
        "correctness": "4;3;4;3",
        "technical_novelty": "1;1;2;2",
        "empirical_novelty": "3;2;4;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 1.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "WxuE_JWxjkW",
        "title": "Expressivity of Emergent Languages is a Trade-off between Contextual Complexity and Unpredictability",
        "track": "main",
        "status": "Poster",
        "keywords": "Emergent Language;Expressivity",
        "author": "",
        "aff": "DeepMind; University of British Columbia; University of Edinburgh",
        "rating": "3;6;8;8",
        "confidence": "4;4;4;3",
        "correctness": "2;4;4;4",
        "technical_novelty": "3;3;3;2",
        "empirical_novelty": "2;0;3;4",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.49374193110101877,
        "corr_rating_correctness": 0.9169493006161777,
        "project": "",
        "github": ""
    },
    {
        "id": "X0nrKAXu7g-",
        "title": "HyperDQN: A Randomized Exploration Method for Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "exploration;reinforcement learning",
        "author": "",
        "aff": "Hong Kong University of Science and Technology; Shenzhen Research Institute of Big Data, The Chinese University of Hong Kong, Shenzhen, China",
        "rating": "3;6;6;8",
        "confidence": "4;3;3;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "3;3;2;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.14002800840280097,
        "corr_rating_correctness": 0.7276068751089989,
        "project": "",
        "github": ""
    },
    {
        "id": "X1y1ur-NCh_",
        "title": "Did I do that? Blame as a means to identify controlled effects in reinforcement learning",
        "track": "main",
        "status": "Reject",
        "keywords": "reinforcement learning;unsupervised reinforcement learning",
        "author": "Oriol Corcoll, Raul Vicente",
        "aff": "",
        "rating": "5;6;6;6",
        "confidence": "4;4;4;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "3;3;3;4",
        "empirical_novelty": "2;4;4;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "X2V7RW3Sul",
        "title": "Improving Hyperparameter Optimization by Planning Ahead",
        "track": "main",
        "status": "Reject",
        "keywords": "model-based reinforcement learning;hyperparameter optimization;model predictive control;meta-learning;transfer learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;8",
        "confidence": "4;4;2;3",
        "correctness": "3;2;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;2;4",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5525321015128181,
        "corr_rating_correctness": 0.49374193110101877,
        "project": "",
        "github": ""
    },
    {
        "id": "X3WxnuzAYyE",
        "title": "PKCAM: Previous Knowledge Channel Attention Module",
        "track": "main",
        "status": "Reject",
        "keywords": "Channel Attention;Attention;Deep Learning;Computer Vision;Neural Networks.",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;5;4;4",
        "correctness": "2;2;2;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.25,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "X4vBK5BBtQY",
        "title": "Enhancing the Transferability of Adversarial Attacks via Scale Ensemble",
        "track": "main",
        "status": "Withdraw",
        "keywords": "adversarial examples;adversarial attack;transferability;scale ensemble;image classification",
        "author": "",
        "aff": "",
        "rating": "1;3;5;5",
        "confidence": "5;3;4;4",
        "correctness": "2;2;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.42640143271122083,
        "corr_rating_correctness": 0.9045340337332909,
        "project": "",
        "github": ""
    },
    {
        "id": "X59kvde4v1Y",
        "title": "DSDF: Coordinated look-ahead strategy in stochastic multi-agent reinforcement learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "reinforcement learning;multi-agent reinforcement learning;stochastic actions;poor co-ordination",
        "author": "",
        "aff": "",
        "rating": "1;3;5;6",
        "confidence": "3;3;2;4",
        "correctness": "3;2;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 3.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.18411492357966466,
        "corr_rating_correctness": 0.22549380840084865,
        "project": "",
        "github": ""
    },
    {
        "id": "X5S3pEGPZv8",
        "title": "Revisiting Skeleton-based Action Recognition",
        "track": "main",
        "status": "Withdraw",
        "keywords": "action;skeleton;video;recognition",
        "author": "",
        "aff": "Unknown",
        "rating": "3;5;6;6",
        "confidence": "4;3;4;3",
        "correctness": "3;2;3;3",
        "technical_novelty": "1;2;3;2",
        "empirical_novelty": "1;2;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.40824829046386296,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "X6D9bAHhBQ1",
        "title": "Planning in Stochastic Environments with a Learned Model",
        "track": "main",
        "status": "Spotlight",
        "keywords": "model-based reinforcement learning;deep reinforcement learning;tree based search;MCTS",
        "author": "",
        "aff": "DeepMind, London, UK and University College London; DeepMind, London, UK",
        "rating": "5;8;8;10",
        "confidence": "4;4;4;4",
        "correctness": "3;4;4;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;4;4;4",
        "presentation": "",
        "rating_avg": 7.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.8892972917998875,
        "project": "",
        "github": ""
    },
    {
        "id": "X8cLTHexYyY",
        "title": "Learning-Augmented $k$-means Clustering",
        "track": "main",
        "status": "Spotlight",
        "keywords": "clustering;learning-augmented algorithms",
        "author": "",
        "aff": "Georgetown Day School; Carnegie Mellon University; MIT",
        "rating": "6;8;8",
        "confidence": "4;5;3",
        "correctness": "4;3;4",
        "technical_novelty": "2;4;2",
        "empirical_novelty": "2;4;2",
        "presentation": "",
        "rating_avg": 7.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.49999999999999983,
        "project": "",
        "github": ""
    },
    {
        "id": "XC-nkaS4rcS",
        "title": "Accelerated Gradient-Free Method for Heavily Constrained Nonconvex Optimization",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Constrained optimization;nonconvex;zeroth-order",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5;5",
        "confidence": "4;4;3;4;2",
        "correctness": "3;3;3;3;4",
        "technical_novelty": "2;2;2;2;3",
        "empirical_novelty": "3;3;0;2;2",
        "presentation": "",
        "rating_avg": 4.6,
        "confidence_avg": 3.4,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.2,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.37500000000000017,
        "corr_rating_correctness": 0.2500000000000001,
        "project": "",
        "github": ""
    },
    {
        "id": "XCS9lvsr5wg",
        "title": "Federated causal discovery",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Causal discovery;Data heterogeneity;Decentralized data",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "4;4;4;2",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;2;4",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7777777777777777,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "XEW8CQgArno",
        "title": "Training invariances and the low-rank phenomenon: beyond linear networks",
        "track": "main",
        "status": "Poster",
        "keywords": "deep learning;nonsmooth analysis;Clarke subdifferential;implicit regularization;low rank bias;alignment;training invariance",
        "author": "",
        "aff": "Massachusetts Institute of Technology",
        "rating": "6;8;8;8",
        "confidence": "3;4;4;3",
        "correctness": "4;4;4;4",
        "technical_novelty": "3;4;3;4",
        "empirical_novelty": "0;3;0;4",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.5,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 3.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "XGzk5OKWFFc",
        "title": "CDTrans: Cross-domain Transformer for Unsupervised Domain Adaptation",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "Alibaba Group",
        "rating": "6;8;8",
        "confidence": "3;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "2;4;3",
        "empirical_novelty": "3;4;3",
        "presentation": "",
        "rating_avg": 7.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9999999999999998,
        "corr_rating_correctness": 0.49999999999999983,
        "project": "",
        "github": "https://github.com/CDTrans/CDTrans"
    },
    {
        "id": "XHMwXYdGm6H",
        "title": "Rethinking Negative Sampling for Handling Missing Entity Annotations",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Missing Annotations;NER;Negative Sampling;Unlabeled Entity Problem",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6;6",
        "confidence": "4;4;4;4;4",
        "correctness": "2;4;3;3;3",
        "technical_novelty": "2;2;3;3;3",
        "empirical_novelty": "2;2;3;3;3",
        "presentation": "",
        "rating_avg": 5.4,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 2.6,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "XHUxf5aRB3s",
        "title": "Dealing with Non-Stationarity in MARL via Trust-Region Decomposition",
        "track": "main",
        "status": "Poster",
        "keywords": "Nonstationarity;Trust-Region Methods;Multi-Agent Reinforcement Learning",
        "author": "",
        "aff": "School of Computer Science and Technology, East China Normal University, Shanghai, China; School of Data Science, The Chinese University of Hong Kong (Shenzhen), Shenzhen Institute of Arti\ufb01cial Intelligence and Robotics for Society, Shenzhen, China",
        "rating": "6;6;6;8",
        "confidence": "3;2;3;4",
        "correctness": "3;4;3;3",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.816496580927726,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "XHxRBwjpEQ",
        "title": "Was my Model Stolen? Feature Sharing for Robust and Transferable Watermarks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5;5",
        "confidence": "4;4;3;3;4",
        "correctness": "3;3;3;3;3",
        "technical_novelty": "2;2;3;3;3",
        "empirical_novelty": "2;3;2;3;3",
        "presentation": "",
        "rating_avg": 4.6,
        "confidence_avg": 3.6,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 2.6,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.408248290463863,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://anonymous.4open.science/r/API_Protection"
    },
    {
        "id": "XIZaWGCPl0b",
        "title": "Tesseract: Gradient Flip Score to Secure Federated Learning against Model Poisoning Attacks",
        "track": "main",
        "status": "Reject",
        "keywords": "federated learning;aggregation;security;untargeted model poisoning attack",
        "author": "",
        "aff": "Paper under double-blind review",
        "rating": "5;5;6;8",
        "confidence": "4;4;4;4",
        "correctness": "3;4;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;4;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.4714045207910316,
        "project": "",
        "github": ""
    },
    {
        "id": "XJFGyJEBLuz",
        "title": "Born Again Neural Rankers",
        "track": "main",
        "status": "Reject",
        "keywords": "learning to rank;knowledge distillation;neural networks",
        "author": "",
        "aff": "",
        "rating": "3;3;8",
        "confidence": "4;4;4",
        "correctness": "3;2;4",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.8660254037844387,
        "project": "",
        "github": ""
    },
    {
        "id": "XJiajt89Omg",
        "title": "Space-Time Graph Neural Networks",
        "track": "main",
        "status": "Poster",
        "keywords": "ST-GNNs;GNNs;stability;graph-time perturbations",
        "author": "",
        "aff": "Department of Electrical and Systems Engineering, University of Pennsylvania",
        "rating": "5;5;8",
        "confidence": "3;3;3",
        "correctness": "3;4;4",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "XK4GN6UCTfH",
        "title": "MS$^2$-Transformer: An End-to-End Model for MS/MS-assisted Molecule Identification",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;5",
        "confidence": "5;3;4",
        "correctness": "3;3;4",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;3;4",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/bmebmebme/ms2transformer"
    },
    {
        "id": "XLjtkZbYUT",
        "title": "Mutual Information Minimization Based Disentangled Learning Framework For Causal Effect Estimation",
        "track": "main",
        "status": "Withdraw",
        "keywords": "causal inference;individual treatment effect;disentangled representation learning;mutual information",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;4;5",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "XLxhEjKNbXj",
        "title": "GLASS: GNN with Labeling Tricks for Subgraph Representation Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "Institute for Artificial Intelligence, Peking University; Beijing Institute for General Artificial Intelligence; Institute for Artificial Intelligence, Peking University",
        "rating": "5;6;6;6",
        "confidence": "3;4;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "3;2;2;2",
        "empirical_novelty": "3;3;2;2",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 1.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "XNYOJD0QdBD",
        "title": "Personalized PageRank meets Graph Attention Networks",
        "track": "main",
        "status": "Desk Reject",
        "keywords": "GNN;Personalized PageRank;Graph Attention Network;Graph Neural Network",
        "author": "",
        "aff": "",
        "rating": "",
        "confidence": "",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "XOh5x-vxsrV",
        "title": "Cross-Trajectory Representation Learning for Zero-Shot Generalization in RL",
        "track": "main",
        "status": "Poster",
        "keywords": "reinforcement learning;representation learning;self-supervised learning;procgen",
        "author": "",
        "aff": "Sony AIR; Universit\u00e9 de Montr\u00e9al, Quebec AI Institute, Microsoft Research; McGill University, Quebec AI Institute; Stanford University; Microsoft Research",
        "rating": "3;6;6;6",
        "confidence": "4;3;3;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "3;3;4;3",
        "empirical_novelty": "2;3;3;4",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": "https://github.com/bmazoure/ctrl_public"
    },
    {
        "id": "XSwpJ2bonX",
        "title": "Neural Circuit Architectural Priors for Embodied Control",
        "track": "main",
        "status": "Reject",
        "keywords": "neuroscience-inspired AI;robotics;motor control",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;4;4;3",
        "correctness": "2;3;2;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;1;3",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.75,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "XTzAhbVbKgq",
        "title": "Batched Lipschitz Bandits",
        "track": "main",
        "status": "Desk Reject",
        "keywords": "Multi-armed bandits;online learning;batched bandits;Lipschitz bandits",
        "author": "",
        "aff": "",
        "rating": "",
        "confidence": "",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "XVPqLyNxSyh",
        "title": "Salient ImageNet: How to discover spurious features in Deep Learning?",
        "track": "main",
        "status": "Poster",
        "keywords": "interpretability;failure explanation;debugging;robustness",
        "author": "",
        "aff": "University of Maryland, College Park",
        "rating": "6;8;8",
        "confidence": "3;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 7.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9999999999999998,
        "corr_rating_correctness": 0.49999999999999983,
        "project": "",
        "github": ""
    },
    {
        "id": "XWODe7ZLn8f",
        "title": "Contrastive Fine-grained Class Clustering via Generative Adversarial Networks",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Unsupervised Fine-grained Class Clustering;Disentangled Representation Learning;Generative Adversarial Networks",
        "author": "",
        "aff": "NAVER AI Lab & NAVER CLOVA; NAVER AI Lab",
        "rating": "6;6;8;8",
        "confidence": "3;4;3;3",
        "correctness": "4;3;4;4",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "3;2;3;2",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": "https://github.com/naver-ai/c3-gan"
    },
    {
        "id": "XY1DWeh58WR",
        "title": "Deep Recurrent Neural Network Layers with Layerwise Loss",
        "track": "main",
        "status": "Desk Reject",
        "keywords": "",
        "author": "",
        "aff": "Samsung Research, Seoul, South Korea; Seoul National University, Seoul, South Korea",
        "rating": "",
        "confidence": "",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "X_ch3VrNSRg",
        "title": "EE-Net: Exploitation-Exploration Neural Networks in Contextual Bandits",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Contextual Bandits;Exploration Strategy;Neural Networks",
        "author": "",
        "aff": "University of Illinois at Urbana-Champaign",
        "rating": "6;6;8;8",
        "confidence": "3;3;2;3",
        "correctness": "3;3;4;4",
        "technical_novelty": "3;2;3;4",
        "empirical_novelty": "2;2;4;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 2.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "X_hByk2-5je",
        "title": "Lossless Compression with Probabilistic Circuits",
        "track": "main",
        "status": "Spotlight",
        "keywords": "",
        "author": "",
        "aff": "CS Department, University of California, Irvine; CS Department, UCLA",
        "rating": "5;6;6;8",
        "confidence": "3;2;3;4",
        "correctness": "3;3;2;3",
        "technical_novelty": "3;3;3;2",
        "empirical_novelty": "3;3;2;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.6488856845230502,
        "corr_rating_correctness": 0.13245323570650439,
        "project": "",
        "github": ""
    },
    {
        "id": "Xa8sKVPnDJq",
        "title": "Composing Features: Compositional Model Augmentation for Steerability of Music Transformers",
        "track": "main",
        "status": "Reject",
        "keywords": "applications;music;controllable generation;compositionality;transformer;finetuning",
        "author": "",
        "aff": "",
        "rating": "3;3;3;6",
        "confidence": "4;4;3;3",
        "correctness": "3;2;2;4",
        "technical_novelty": "2;4;3;2",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.8703882797784892,
        "project": "",
        "github": ""
    },
    {
        "id": "Xb2YyVApEj6",
        "title": "MaiT: integrating spatial locality into image transformers with attention masks",
        "track": "main",
        "status": "Reject",
        "keywords": "vision transformer;image classification;deep learning;computer vision",
        "author": "",
        "aff": "",
        "rating": "1;3;5;5",
        "confidence": "5;5;5;3",
        "correctness": "2;3;4;3",
        "technical_novelty": "2;3;2;2",
        "empirical_novelty": "1;3;0;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5222329678670935,
        "corr_rating_correctness": 0.8528028654224417,
        "project": "",
        "github": ""
    },
    {
        "id": "XbatFr32NRm",
        "title": "Generalizing MLPs With Dropouts, Batch Normalization, and Skip Connections",
        "track": "main",
        "status": "Reject",
        "keywords": "MLP;batch normalization;dropout;residual connections;Bayesian inference",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "4;4;5;4",
        "correctness": "4;1;2;3",
        "technical_novelty": "2;2;1;2",
        "empirical_novelty": "1;2;1;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/anonymous"
    },
    {
        "id": "XctLdNfCmP",
        "title": "Predicting Physics in Mesh-reduced Space with Temporal Attention",
        "track": "main",
        "status": "Poster",
        "keywords": "fluid dynamics;graph neural network;attention neural network",
        "author": "",
        "aff": "University of Notre Dame; DeepMind; Tufts University",
        "rating": "6;6;6;8",
        "confidence": "4;4;5;4",
        "correctness": "3;4;3;4",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "3;3;2;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 4.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "Xd6T7cT7vwj",
        "title": "Strongly Self-Normalizing Neural Networks with Applications to Implicit Representation Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Strongly Self-Normalizing Neural Networks with Applications to Implicit Representation Learning",
        "author": "",
        "aff": "",
        "rating": "",
        "confidence": "",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "XeqjsCVLk1m",
        "title": "Tell me why!\u2014Explanations support learning relational and causal structure",
        "track": "main",
        "status": "Reject",
        "keywords": "Explanation;RL;Language;Relations;Causality",
        "author": "",
        "aff": "",
        "rating": "3;6;6;6",
        "confidence": "4;4;2;3",
        "correctness": "1;3;3;4",
        "technical_novelty": "1;1;2;2",
        "empirical_novelty": "1;3;2;2",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 1.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5222329678670935,
        "corr_rating_correctness": 0.9271726499455307,
        "project": "",
        "github": ""
    },
    {
        "id": "Xg47v73CDaj",
        "title": "Non-deep Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "non-deep networks",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5",
        "confidence": "5;4;5;5",
        "correctness": "2;3;4;3",
        "technical_novelty": "3;3;3;2",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "XgS9YPYtdj",
        "title": "Improved Generalization Risk Bounds for Meta-Learning with PAC-Bayes-kl Analysis",
        "track": "main",
        "status": "Withdraw",
        "keywords": "PAC-Bayes bounds;meta-learning;localized PAC-Bayes analysis",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "5;4;4;2",
        "correctness": "3;4;4;3",
        "technical_novelty": "3;3;4;4",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6882472016116854,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "XhF2VOMRHS",
        "title": "A Unified Contrastive Energy-based Model for Understanding the Generative Ability of Adversarial Training",
        "track": "main",
        "status": "Poster",
        "keywords": "Generative Models;Energy-based Models;Sampling;Adversarial Training",
        "author": "",
        "aff": "Pazhou Lab, Guangzhou, 510330, China; School of Mathematical Sciences, Peking University; Key Lab. of Machine Perception (MoE), School of Arti\ufb01cial Intelligence, Peking University; Institute for Arti\ufb01cial Intelligence, Peking University",
        "rating": "5;6;8;8",
        "confidence": "3;2;4;3",
        "correctness": "3;4;4;4",
        "technical_novelty": "2;3;4;4",
        "empirical_novelty": "2;3;4;3",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 3.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5443310539518174,
        "corr_rating_correctness": 0.7777777777777777,
        "project": "",
        "github": ""
    },
    {
        "id": "XhMa8XPHxpw",
        "title": "Low-Precision Stochastic Gradient Langevin Dynamics",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;3;6",
        "confidence": "4;4;4;4",
        "correctness": "3;3;2;3",
        "technical_novelty": "2;2;2;4",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "XizHAfgfd3J",
        "title": "Semantic-aware Representation Learning Via Probability Contrastive Loss",
        "track": "main",
        "status": "Withdraw",
        "keywords": "contrastive learning;semi-supervised learning;unsupervised domain adaptation;semi-supervised domain adaptation",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5;5",
        "confidence": "4;4;4;4;4",
        "correctness": "2;3;3;3;4",
        "technical_novelty": "2;3;2;2;2",
        "empirical_novelty": "2;2;2;3;3",
        "presentation": "",
        "rating_avg": 4.6,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.2,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.790569415042095,
        "project": "",
        "github": ""
    },
    {
        "id": "Xk1kE26xYS9",
        "title": "Learning Pessimism for Robust and Efficient Off-Policy Reinforcement Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Reinforcement learning;Off-policy learning;Continuous control;Machine learning",
        "author": "",
        "aff": "",
        "rating": "5;5;6;8",
        "confidence": "4;3;4;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;3;2;2",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.4714045207910316,
        "corr_rating_correctness": 0.8164965809277259,
        "project": "",
        "github": ""
    },
    {
        "id": "Xo0lbDt975",
        "title": "An Agnostic Approach to Federated Learning with Class Imbalance",
        "track": "main",
        "status": "Poster",
        "keywords": "Federated Learning;Class Imbalance",
        "author": "",
        "aff": "Department of Electrical and Systems Engineering, University of Pennsylvania, Philadelphia, PA 19104, USA",
        "rating": "6;6;6;6",
        "confidence": "3;3;4;3",
        "correctness": "3;3;2;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "Not provided",
        "github": "Not provided"
    },
    {
        "id": "XpmTU4k-5uf",
        "title": "TIME-LAPSE: Learning to say \u201cI don't know\u201d through spatio-temporal uncertainty scoring",
        "track": "main",
        "status": "Reject",
        "keywords": "out-of-distribution detection;OOD detection;spatio-temporal;latent-space;sequential;outlier;anomaly",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "3;4;4;3",
        "correctness": "2;1;3;2",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.5,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "Xr6-DAhePa",
        "title": "Understanding Self-supervised Learning via Information Bottleneck Principle",
        "track": "main",
        "status": "Withdraw",
        "keywords": "contrastive learning;unsupervised learning;variational information bottleneck",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5;6",
        "confidence": "5;3;2;4;3",
        "correctness": "2;2;2;2;3",
        "technical_novelty": "2;2;3;3;3",
        "empirical_novelty": "1;2;4;2;3",
        "presentation": "",
        "rating_avg": 4.4,
        "confidence_avg": 3.4,
        "correctness_avg": 2.2,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4576043153224293,
        "corr_rating_correctness": 0.6666666666666666,
        "project": "",
        "github": ""
    },
    {
        "id": "XuS18b_H0DW",
        "title": "Tactics on Refining Decision Boundary for Improving Certification-based Robust Training",
        "track": "main",
        "status": "Reject",
        "keywords": "adversarial robustness;certifiable training;deep learning",
        "author": "",
        "aff": "",
        "rating": "3;5;6;8",
        "confidence": "4;5;4;5",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 4.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5547001962252291,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "XuxAEYYGhV-",
        "title": "Improving Out-of-Distribution Robustness of Classifiers Through Interpolated Generative Models",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;4;4;4",
        "correctness": "4;2;2;3",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.17407765595569782,
        "project": "",
        "github": ""
    },
    {
        "id": "XwOnGWENp62",
        "title": "RitzNet: A Deep Neural Network Method for Linear Stress Problems",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Linear Elasticity;Deep Neural Network;Ritz Method;Unsupervised Learning",
        "author": "",
        "aff": "",
        "rating": "1;1;3;3",
        "confidence": "5;4;3;4",
        "correctness": "2;3;3;4",
        "technical_novelty": "1;1;2;2",
        "empirical_novelty": "0;1;2;1",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 1.5,
        "empirical_novelty_avg": 1.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7071067811865475,
        "corr_rating_correctness": 0.7071067811865475,
        "project": "",
        "github": ""
    },
    {
        "id": "Xx4MNjSmQQ9",
        "title": "Robust Generalization of Quadratic Neural Networks via Function Identification",
        "track": "main",
        "status": "Reject",
        "keywords": "neural network;function identification;robust generalization",
        "author": "",
        "aff": "",
        "rating": "5;5;6",
        "confidence": "3;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "2;3;4",
        "empirical_novelty": "1;3;0",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 1.3333333333333333,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.4999999999999999,
        "corr_rating_correctness": 0.4999999999999999,
        "project": "",
        "github": ""
    },
    {
        "id": "XyVXPuuO_P",
        "title": "Meta-Learning an Inference Algorithm for Probabilistic Programs",
        "track": "main",
        "status": "Reject",
        "keywords": "Probabilistic Programming;Approximate Posterior Inference;Meta Learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "4;5;3;2",
        "correctness": "2;2;3;3",
        "technical_novelty": "1;3;3;3",
        "empirical_novelty": "1;1;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9467292624062574,
        "corr_rating_correctness": 0.9622504486493761,
        "project": "",
        "github": ""
    },
    {
        "id": "XzTtHjgPDsT",
        "title": "Coordination Among Neural Modules Through a Shared Global Workspace",
        "track": "main",
        "status": "Oral",
        "keywords": "slot based recurrent architectures;attention;transformers;latent bottleneck.",
        "author": "",
        "aff": "Microsoft Research, New York, NY; Mila, University of Montreal, Max Planck Institute Germany; Indian Institute of Technology, Delhi; Google Deepmind; Google Research, Brain Team; Mila, University of Montreal",
        "rating": "6;6;8;10",
        "confidence": "4;3;3;3",
        "correctness": "4;2;4;4",
        "technical_novelty": "4;3;4;4",
        "empirical_novelty": "3;3;3;4",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.75,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5222329678670935,
        "corr_rating_correctness": 0.5222329678670935,
        "project": "",
        "github": ""
    },
    {
        "id": "Y-8bEgodif",
        "title": "Learning Dense NeRF Correspondence Through Generative Structural Priors",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Dense Correspondence;Generative Model;Neural Radiance Field",
        "author": "",
        "aff": "",
        "rating": "",
        "confidence": "",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Y03EQLbqBjP",
        "title": "Contrastive Learning Through Time",
        "track": "main",
        "status": "Withdraw",
        "keywords": "contrastive learning;object recognition;virtual environment;temporal coherence",
        "author": "",
        "aff": "",
        "rating": "3;5;6;8",
        "confidence": "4;4;4;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;3;3;4",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.16012815380508713,
        "project": "",
        "github": ""
    },
    {
        "id": "Y0cGpgUhSvp",
        "title": "Prioritized training on points that are learnable, worth learning, and not yet learned",
        "track": "main",
        "status": "Reject",
        "keywords": "Data selection;subset selection;deep learning;active learning",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "4;4;4;4",
        "correctness": "4;2;3;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "Y1O-K5itG09",
        "title": "Deep Ensemble as a Gaussian Process Posterior",
        "track": "main",
        "status": "Reject",
        "keywords": "Deep ensemble;Bayesian deep learning;Gaussian process;functional variational inference;uncertainty estimation",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5;8",
        "confidence": "4;3;3;4;4",
        "correctness": "3;3;3;4;4",
        "technical_novelty": "2;2;2;3;4",
        "empirical_novelty": "2;2;0;3;3",
        "presentation": "",
        "rating_avg": 5.6,
        "confidence_avg": 3.6,
        "correctness_avg": 3.4,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.408248290463863,
        "corr_rating_correctness": 0.6123724356957946,
        "project": "",
        "github": ""
    },
    {
        "id": "Y2eS8eWCsyG",
        "title": "A Broad Dataset is All You Need for One-Shot Object Detection",
        "track": "main",
        "status": "Reject",
        "keywords": "One-Shot Learning;Object Detection;Generalization;Instance Segmentation",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "5;2;4;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6622661785325219,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "Y3cm4HJ3Ncs",
        "title": "Learning-to-Count by Learning-to-Rank: Weakly Supervised Object Counting & Localization Using Only Pairwise Image Rankings",
        "track": "main",
        "status": "Reject",
        "keywords": "Object Counting;Weak Supervision;Ranking",
        "author": "",
        "aff": "",
        "rating": "3;3;6",
        "confidence": "5;4;4",
        "correctness": "2;3;3",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "3;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5,
        "corr_rating_correctness": 0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "Y4cs1Z3HnqL",
        "title": "Pessimistic Bootstrapping for Uncertainty-Driven Offline Reinforcement Learning",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Pessimistic Bootstrapping;Bootstrapped Q-functions;Uncertainty Estimation;Offline Reinforcement Learning",
        "author": "",
        "aff": "Princeton University; University of Technology Sydney; Northwestern University; University of Toronto, Vector Institute, NVIDIA; Harbin Institute of Technology",
        "rating": "6;6;8;8",
        "confidence": "4;4;4;4",
        "correctness": "3;4;4;4",
        "technical_novelty": "2;1;2;3",
        "empirical_novelty": "2;3;3;4",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "Y77aWEc17ln",
        "title": "Neural Shape Mating: Self-Supervised Object Assembly with Adversarial Shape Priors",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Geometric Shape Assembly;Shape Matching;Pose Estimation;Implicit Representations",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;4;3;3",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 1.0,
        "project": "https://neural-shape-mating.github.io",
        "github": "https://github.com/neural-shape-mating"
    },
    {
        "id": "Y8Ivdg7typR",
        "title": "Wakening Past Concepts without Past Data: Class-incremental Learning from Placebos",
        "track": "main",
        "status": "Reject",
        "keywords": "incremental learning;continual learning;class-incremental learning",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "4;4;4;4",
        "correctness": "3;1;2;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "Y8KfxdZl-rI",
        "title": "Weakly Supervised Label Learning Flows",
        "track": "main",
        "status": "Reject",
        "keywords": "Weakly Supervised Learning;Deep Generative Flows;Deep Learning;Deep Generative Models;Machine Learning",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6;8",
        "confidence": "3;4;4;3;4",
        "correctness": "2;2;3;3;4",
        "technical_novelty": "2;3;3;3;3",
        "empirical_novelty": "2;2;4;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.6,
        "correctness_avg": 2.8,
        "technical_novelty_avg": 2.8,
        "empirical_novelty_avg": 2.8,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.372677996249965,
        "corr_rating_correctness": 0.9759000729485333,
        "project": "",
        "github": ""
    },
    {
        "id": "Y9FNtYulBE0",
        "title": "CheXT: Knowledge-Guided Cross-Attention Transformer for Abnormality Classification and Localization in Chest X-rays",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;5",
        "confidence": "5;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "3;2;2",
        "empirical_novelty": "3;2;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "YDqIYJBQTQs",
        "title": "Unsupervised Object Learning via Common Fate",
        "track": "main",
        "status": "Reject",
        "keywords": "object learning;scene modeling;scene generation;causal modeling;causal representation learning;generative modeling;common fate",
        "author": "",
        "aff": "",
        "rating": "3;3;6",
        "confidence": "4;4;3",
        "correctness": "2;2;3",
        "technical_novelty": "1;3;2",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "YDud6vPh2V",
        "title": "Xi-learning: Successor Feature Transfer Learning for General Reward Functions",
        "track": "main",
        "status": "Reject",
        "keywords": "reinforcement learning;transfer learning;meta learning;successor features",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5",
        "confidence": "4;4;3;3",
        "correctness": "4;3;3;3",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://tinyurl.com/3xuzxff3"
    },
    {
        "id": "YHm6xV3JODS",
        "title": "Stop just recalling memorized relations: Extracting Unseen Relational Triples from the context",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Relational Triple Extraction;Natural Language Processing",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;5;4;4",
        "correctness": "2;1;4;4",
        "technical_novelty": "2;1;2;2",
        "empirical_novelty": "2;2;4;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.9622504486493763,
        "project": "",
        "github": ""
    },
    {
        "id": "YJ1WzgMVsMt",
        "title": "Reinforcement Learning with Sparse Rewards using Guidance from Offline Demonstration",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Reinforcement Learning;Sparse Rewards;Learning from Demonstrations",
        "author": "",
        "aff": "Department of Electrical and Computer Engineering, Texas A&M University",
        "rating": "6;6;8;8;8",
        "confidence": "4;4;3;4;4",
        "correctness": "4;3;4;4;3",
        "technical_novelty": "2;3;3;3;3",
        "empirical_novelty": "3;2;2;4;3",
        "presentation": "",
        "rating_avg": 7.2,
        "confidence_avg": 3.8,
        "correctness_avg": 3.6,
        "technical_novelty_avg": 2.8,
        "empirical_novelty_avg": 2.8,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.40824829046386296,
        "corr_rating_correctness": 0.16666666666666663,
        "project": "",
        "github": ""
    },
    {
        "id": "YJVMboHZCtW",
        "title": "Decision boundary variability and generalization in neural networks",
        "track": "main",
        "status": "Reject",
        "keywords": "explainability of deep learning",
        "author": "",
        "aff": "",
        "rating": "6;6;6;8",
        "confidence": "4;3;3;3",
        "correctness": "4;3;4;4",
        "technical_novelty": "3;3;3;4",
        "empirical_novelty": "3;3;2;4",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "YKAVWfKSKU",
        "title": "Deep Dirichlet Process Mixture Models",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Dirichlet process;Bayesian nonparametrics;flow-based generative model;clustering",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;3;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "3;2;2;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.13245323570650439,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "YLglAn-USkf",
        "title": "Are BERT Families Zero-Shot Learners? A Study on Their Potential and Limitations",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "Under double-blind review",
        "rating": "3;5;6;6",
        "confidence": "4;3;4;3",
        "correctness": "3;3;3;4",
        "technical_novelty": "1;2;2;2",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.40824829046386296,
        "corr_rating_correctness": 0.4714045207910316,
        "project": "",
        "github": ""
    },
    {
        "id": "YRDlrT00BP",
        "title": "On Transportation of Mini-batches: A Hierarchical Approach",
        "track": "main",
        "status": "Reject",
        "keywords": "Deep Generative Models;Deep Domain Adaptation;Color Transfer;Approximate Bayesian Computation;Gradient Flow;Optimal Transport",
        "author": "",
        "aff": "",
        "rating": "3;5;6",
        "confidence": "4;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9449111825230683,
        "corr_rating_correctness": 0.18898223650461363,
        "project": "",
        "github": ""
    },
    {
        "id": "YRq0ZUnzKoZ",
        "title": "A Relational Intervention Approach for Unsupervised Dynamics Generalization in Model-Based Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "Model-Based Reinforcement Learning;Unsupervised Dynamics Generalization",
        "author": "",
        "aff": "The University of Melbourne; The University of Sydney; JD Explore Academy",
        "rating": "6;6;8;8",
        "confidence": "4;4;4;3",
        "correctness": "2;3;4;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.9045340337332909,
        "project": "",
        "github": "https://github.com/CR-Gjx/RIA"
    },
    {
        "id": "YTtMaJUN_uc",
        "title": "Learning Universal User Representations via Self-Supervised Lifelong Behaviors Modeling",
        "track": "main",
        "status": "Reject",
        "keywords": "universal user representation;extremely long sequence modeling;self-supervised learning",
        "author": "",
        "aff": "",
        "rating": "5;5;5",
        "confidence": "4;4;3",
        "correctness": "3;3;2",
        "technical_novelty": "3;3;2",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "YVPBh4k78iZ",
        "title": "Scale Mixtures of Neural Network Gaussian Processes",
        "track": "main",
        "status": "Poster",
        "keywords": "Neural Network Gaussian Processes;Infinitely-wide Neural Networks;Scale Mixtures of Gaussians;Heavy-tailed Stochastic Processes",
        "author": "",
        "aff": "AITRICS, Seoul, South Korea; Kim Jaechul Graduate School of AI, KAIST, South Korea; School of Computing, KAIST, South Korea",
        "rating": "5;6;6;8",
        "confidence": "4;2;2;5",
        "correctness": "4;4;3;4",
        "technical_novelty": "1;2;3;3",
        "empirical_novelty": "1;0;0;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.4856618642571828,
        "corr_rating_correctness": 0.13245323570650439,
        "project": "",
        "github": ""
    },
    {
        "id": "YVa8X_2I1b",
        "title": "INFERNO: Inferring Object-Centric 3D Scene Representations without Supervision",
        "track": "main",
        "status": "Reject",
        "keywords": "object discovery;scene representation;object-centric representations;3D rendering",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5",
        "confidence": "4;4;4;5",
        "correctness": "3;3;3;2",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "0;3;3;0",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "YWNAX0caEjI",
        "title": "Neural Structured Prediction for Inductive Node Classification",
        "track": "main",
        "status": "Oral",
        "keywords": "",
        "author": "",
        "aff": "Mila - Qu \u00b4ebec AI Institute, Universit \u00b4e de Montr \u00b4eal; Mila - Qu \u00b4ebec AI Institute, HEC Montr \u00b4eal, Canadian Institute for Advanced Research (CIFAR)",
        "rating": "8;8;8;10",
        "confidence": "4;4;3;4",
        "correctness": "4;3;4;4",
        "technical_novelty": "3;3;2;4",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 8.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": "https://github.com/DeepGraphLearning/SPN"
    },
    {
        "id": "YX0lrvdPQc",
        "title": "A Johnson-Lindenstrauss Framework for Randomly Initialized CNNs",
        "track": "main",
        "status": "Poster",
        "keywords": "convolutional neural networks;Johnson-Lindenstrauss lemma;initialization;isometry;theory.",
        "author": "",
        "aff": "School of Electrical Engineering, Tel Aviv University, Tel Aviv 6997801, Israel; School of Computer and Communication Sciences, \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne, 1015 Lausanne, Switzerland",
        "rating": "6;8;8",
        "confidence": "2;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "0;3;3",
        "presentation": "",
        "rating_avg": 7.333333333333333,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 1.0,
        "corr_rating_correctness": -0.49999999999999983,
        "project": "",
        "github": ""
    },
    {
        "id": "YYHXJOawkPb",
        "title": "The Evolution of Out-of-Distribution Robustness Throughout Fine-Tuning",
        "track": "main",
        "status": "Reject",
        "keywords": "out-of-distribution;generalization;robustness",
        "author": "",
        "aff": "",
        "rating": "3;3;3;8",
        "confidence": "4;4;3;3",
        "correctness": "2;3;4;4",
        "technical_novelty": "1;2;2;3",
        "empirical_novelty": "1;3;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.5222329678670935,
        "project": "",
        "github": ""
    },
    {
        "id": "YYULSFvKru9",
        "title": "StARformer: Transformer with State-Action-Reward Representations",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Representation Learning;Reinforcement Learning;Transformer",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;4;4;4",
        "correctness": "2;2;3;3",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;2;3;0",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "YZHES8wIdE",
        "title": "Generative Planning for Temporally Coordinated Exploration in Reinforcement Learning",
        "track": "main",
        "status": "Spotlight",
        "keywords": "",
        "author": "",
        "aff": "Horizon Robotics, Cupertino CA 95014",
        "rating": "6;8;8;8",
        "confidence": "4;4;4;3",
        "correctness": "3;4;4;3",
        "technical_novelty": "2;4;4;3",
        "empirical_novelty": "2;3;4;2",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": "https://github.com/Haichao-Zhang/generative_planning"
    },
    {
        "id": "Ybx635VOYoM",
        "title": "ContraQA: Question Answering under Contradicting Contexts",
        "track": "main",
        "status": "Reject",
        "keywords": "Question Answering;Misinformation Detection;Robustness;Text Generation;Contradicting Contexts",
        "author": "",
        "aff": "Under double-blind review",
        "rating": "3;3;5;6",
        "confidence": "4;4;4;3",
        "correctness": "2;3;3;4",
        "technical_novelty": "1;2;2;3",
        "empirical_novelty": "1;2;3;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7777777777777777,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "Yc64t25hseP",
        "title": "GUIDED MCMC FOR SPARSE BAYESIAN MODELS TO DETECT RARE EVENTS IN IMAGES SANS LABELED DATA",
        "track": "main",
        "status": "Withdraw",
        "keywords": "MCMC;hierarchical Bayesian models;image classification;rare events",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "5;3;1;4",
        "correctness": "2;2;4;3",
        "technical_novelty": "1;1;2;2",
        "empirical_novelty": "1;1;2;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 1.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.50709255283711,
        "corr_rating_correctness": 0.9045340337332909,
        "project": "",
        "github": ""
    },
    {
        "id": "YeShU5mLfLt",
        "title": "On the Convergence of Certified Robust Training with Interval Bound Propagation",
        "track": "main",
        "status": "Poster",
        "keywords": "Certified robustness;Adversarial robustness;Convergence",
        "author": "",
        "aff": "University of California, Los Angeles",
        "rating": "5;6;8",
        "confidence": "4;3;2",
        "correctness": "3;3;4",
        "technical_novelty": "2;4;4",
        "empirical_novelty": "1;0;0",
        "presentation": "",
        "rating_avg": 6.333333333333333,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.3333333333333335,
        "empirical_novelty_avg": 0.3333333333333333,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9819805060619659,
        "corr_rating_correctness": 0.944911182523068,
        "project": "",
        "github": ""
    },
    {
        "id": "YedA6OCN6X",
        "title": "Evaluating generative networks using Gaussian mixtures of image features",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "1;3;5;8",
        "confidence": "5;4;3;4",
        "correctness": "3;2;3;4",
        "technical_novelty": "1;2;3;3",
        "empirical_novelty": "1;2;3;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5468687416197306,
        "corr_rating_correctness": 0.6835859270246631,
        "project": "",
        "github": ""
    },
    {
        "id": "YevsQ05DEN7",
        "title": "Understanding Dimensional Collapse in Contrastive Self-supervised Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "self-supervised learning;contrastive learning;implicit regularization;dimensional collapse",
        "author": "",
        "aff": "Facebook AI Research",
        "rating": "5;6;6;6;8",
        "confidence": "4;4;3;4;3",
        "correctness": "3;3;2;3;4",
        "technical_novelty": "2;3;3;3;4",
        "empirical_novelty": "3;2;2;3;4",
        "presentation": "",
        "rating_avg": 6.2,
        "confidence_avg": 3.6,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.8,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6666666666666667,
        "corr_rating_correctness": 0.6454972243679028,
        "project": "",
        "github": ""
    },
    {
        "id": "YfFWrndRGQx",
        "title": "Multi-Objective Online Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "online algorithm;online learning;multi-objective optimization",
        "author": "",
        "aff": "",
        "rating": "6;6;6;6",
        "confidence": "3;3;3;4",
        "correctness": "4;3;4;3",
        "technical_novelty": "3;3;3;4",
        "empirical_novelty": "3;0;3;4",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "YgPqNctmyd",
        "title": "Towards Building A Group-based Unsupervised Representation Disentanglement Framework",
        "track": "main",
        "status": "Poster",
        "keywords": "Disentangled representation learning;Group theory;VAE",
        "author": "",
        "aff": "Microsoft Research Asia; Xi\u2019an Jiaotong University; EIT; HKUST",
        "rating": "3;6;6;8",
        "confidence": "2;4;4;4",
        "correctness": "2;4;3;4",
        "technical_novelty": "2;3;3;4",
        "empirical_novelty": "2;3;2;4",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8892972917998875,
        "corr_rating_correctness": 0.8866206949335731,
        "project": "",
        "github": ""
    },
    {
        "id": "YgR1rRWETI",
        "title": "Connectivity Matters: Neural Network Pruning Through the Lens of Effective Sparsity",
        "track": "main",
        "status": "Reject",
        "keywords": "Neural Networks;Pruning;Sparsity",
        "author": "",
        "aff": "",
        "rating": "3;3;3;6",
        "confidence": "4;4;4;4",
        "correctness": "3;4;3;3",
        "technical_novelty": "1;2;1;3",
        "empirical_novelty": "2;2;1;3",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "YiBa9HKTyXE",
        "title": "Permutation-Based SGD: Is Random Optimal?",
        "track": "main",
        "status": "Poster",
        "keywords": "Convex Optimization;Stochastic Optimization;Large Scale Learning",
        "author": "",
        "aff": "University of Wisconsin-Madison",
        "rating": "6;6;6;10",
        "confidence": "3;4;2;4",
        "correctness": "3;4;4;4",
        "technical_novelty": "3;4;3;4",
        "empirical_novelty": "1;3;2;2",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5222329678670935,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "YigKlMJwjye",
        "title": "Generalized Demographic Parity for Group Fairness",
        "track": "main",
        "status": "Poster",
        "keywords": "Generalized demographic parity;estimation error analysis",
        "author": "",
        "aff": "Rice University; Texas A &M University",
        "rating": "5;6;6;6",
        "confidence": "4;3;4;3",
        "correctness": "4;4;3;4",
        "technical_novelty": "2;4;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": "https://github.com/zhimengj0326/GDP"
    },
    {
        "id": "YmONQIWli--",
        "title": "Gotta Go Fast When Generating Data with Score-Based Models",
        "track": "main",
        "status": "Reject",
        "keywords": "score-based;generative model;denoising diffusion;SDE;diffusion process",
        "author": "",
        "aff": "",
        "rating": "5;5;6;8",
        "confidence": "3;3;3;4",
        "correctness": "3;3;2;3",
        "technical_novelty": "2;2;2;4",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9428090415820632,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "Yn4CPz_LRKO",
        "title": "Conditional GANs with Auxiliary Discriminative Classifier",
        "track": "main",
        "status": "Reject",
        "keywords": "conditional generative adversarial networks;conditional image generation",
        "author": "",
        "aff": "",
        "rating": "5;5;6;8",
        "confidence": "5;5;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "1;2;2;4",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8164965809277259,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "Yp4sR6rmgFt",
        "title": "Transductive Universal Transport for Zero-Shot Action Recognition",
        "track": "main",
        "status": "Reject",
        "keywords": "zero-shot learning;action recognition;action localization;optimal transport",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "2;4;2;2",
        "correctness": "3;3;3;3",
        "technical_novelty": "3;2;2;3",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 2.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "YpBHDlalKDG",
        "title": "Complex Locomotion Skill Learning via Differentiable Physics",
        "track": "main",
        "status": "Reject",
        "keywords": "differentiable physics;locomotion skill learning;physical simulation",
        "author": "",
        "aff": "",
        "rating": "5;6;6;6",
        "confidence": "4;4;3;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "YpPiNigTzMT",
        "title": "Universalizing Weak Supervision",
        "track": "main",
        "status": "Poster",
        "keywords": "Weak supervision",
        "author": "",
        "aff": "Department of Computer Sciences, University of Wisconsin-Madison",
        "rating": "3;5;8;8",
        "confidence": "4;3;3;2",
        "correctness": "3;4;4;4",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "3;3;3;2",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8333333333333334,
        "corr_rating_correctness": 0.8164965809277261,
        "project": "",
        "github": ""
    },
    {
        "id": "YpSxqy_RE84",
        "title": "How Low Can We Go: Trading Memory for Error in Low-Precision Training",
        "track": "main",
        "status": "Poster",
        "keywords": "low-precision training;meta-learning;Pareto frontier;error-memory tradeoff;active learning;matrix factorization",
        "author": "",
        "aff": "Cornell University",
        "rating": "5;6;6;8",
        "confidence": "3;3;4;4",
        "correctness": "3;4;3;4",
        "technical_novelty": "2;4;3;3",
        "empirical_novelty": "2;4;3;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.6882472016116854,
        "corr_rating_correctness": 0.6882472016116854,
        "project": "",
        "github": ""
    },
    {
        "id": "YqHW0o9wXae",
        "title": "Assisted Learning for Organizations with Limited Imbalanced Data",
        "track": "main",
        "status": "Reject",
        "keywords": "Assisted learning;Deep learning;Reinforcement learning;Optimization;Heterogeneous learner;Imbalanced data",
        "author": "",
        "aff": "",
        "rating": "3;5;5",
        "confidence": "4;3;3",
        "correctness": "2;4;3",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 4.333333333333333,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9999999999999998,
        "corr_rating_correctness": 0.8660254037844385,
        "project": "",
        "github": ""
    },
    {
        "id": "Yr_1QZaRqmv",
        "title": "Decision Tree Algorithms for MDP",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "2;4;4;3",
        "correctness": "3;4;3;4",
        "technical_novelty": "2;1;2;3",
        "empirical_novelty": "0;1;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.17407765595569782,
        "corr_rating_correctness": 0.19245008972987526,
        "project": "",
        "github": ""
    },
    {
        "id": "Ysu4E5DhQIw",
        "title": "Cascaded Fast and Slow Models for Efficient Semantic Code Search",
        "track": "main",
        "status": "Withdraw",
        "keywords": "code retrieval;code search;fast and slow;transformer;mean reciprocal ranking;recall",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "4;4;2;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "1;2;3;2",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7543365091413573,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "YtdASzotUEW",
        "title": "Label Smoothed Embedding Hypothesis for Out-of-Distribution Detection",
        "track": "main",
        "status": "Reject",
        "keywords": "deep k-nn;label smoothing;out-of-distribution detection;robustness",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;3;3;4",
        "correctness": "2;3;3;4",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "3;3;2;2",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.2294157338705618,
        "corr_rating_correctness": 0.9733285267845754,
        "project": "",
        "github": ""
    },
    {
        "id": "YxQiIOLKgEf",
        "title": "Counterfactual Graph Learning for Link Prediction",
        "track": "main",
        "status": "Reject",
        "keywords": "Link Prediction;Graph Representation Learning;Graph Neural Networks.",
        "author": "",
        "aff": "",
        "rating": "5;5;6;8",
        "confidence": "4;4;5;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "3;3;3;4",
        "empirical_novelty": "3;3;3;0",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "YxWU4YZ4Cr",
        "title": "Generalization to Out-of-Distribution transformations",
        "track": "main",
        "status": "Reject",
        "keywords": "Out of distribution;generalization;convolution;polar transformation",
        "author": "",
        "aff": "",
        "rating": "3;3;3;6",
        "confidence": "3;3;4;3",
        "correctness": "1;3;2;4",
        "technical_novelty": "2;2;1;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 3.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.7745966692414834,
        "project": "",
        "github": ""
    },
    {
        "id": "Z0XiFAb_WDr",
        "title": "Communicating Natural Programs to Humans and Machines",
        "track": "main",
        "status": "Reject",
        "keywords": "program synthesis;communication;cognition",
        "author": "",
        "aff": "",
        "rating": "5;5;5",
        "confidence": "4;4;3",
        "correctness": "4;3;3",
        "technical_novelty": "1;3;2",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "Z1Qlm11uOM",
        "title": "Learning Audio-Visual Speech Representation by Masked Multimodal Cluster Prediction",
        "track": "main",
        "status": "Poster",
        "keywords": "audio-visual speech recognition;lip reading;speech recognition;self-supervised learning",
        "author": "",
        "aff": "Meta AI; Toyota Technological Institute at Chicago",
        "rating": "6;6;8;8",
        "confidence": "5;3;5;4",
        "correctness": "4;3;3;4",
        "technical_novelty": "3;3;4;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.30151134457776363,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/facebookresearch/av_hubert"
    },
    {
        "id": "Z7Lk2cQEG8a",
        "title": "The Hidden Convex Optimization Landscape of Regularized Two-Layer ReLU Networks: an Exact Characterization of Optimal Solutions",
        "track": "main",
        "status": "Oral",
        "keywords": "Neural networks;global optimization;convex optimization;convex analysis",
        "author": "",
        "aff": "Department of Electrical Engineering, Stanford University",
        "rating": "8;8;8;8",
        "confidence": "3;4;4;3",
        "correctness": "4;3;4;3",
        "technical_novelty": "4;3;3;3",
        "empirical_novelty": "0;3;3;0",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "Z7VhFVRVqeU",
        "title": "Neural Bootstrapping Attention for Neural Processes",
        "track": "main",
        "status": "Reject",
        "keywords": "Neural Process;Bootstrapping",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "3;3;3;4",
        "correctness": "4;3;3;3",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "3;3;3;2",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "Z8FzvVU6_Kj",
        "title": "SUMNAS: Supernet with Unbiased Meta-Features for Neural Architecture Search",
        "track": "main",
        "status": "Poster",
        "keywords": "Neural architecture search",
        "author": "",
        "aff": "Yonsei University; Seoul National University; Seoul National University; FriendliAI; NA VER AI Lab, NA VER Corporation; NA VER CLOV A, NA VER Corporation",
        "rating": "5;6;6;8",
        "confidence": "4;4;4;5",
        "correctness": "3;4;3;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9271726499455306,
        "corr_rating_correctness": -0.13245323570650439,
        "project": "",
        "github": ""
    },
    {
        "id": "ZAA0Ol4z2i4",
        "title": "Explaining Off-Policy Actor-Critic From A Bias-Variance Perspective",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;3;8",
        "confidence": "3;3;5;4",
        "correctness": "2;2;2;3",
        "technical_novelty": "2;2;2;4",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.75,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.17407765595569782,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "ZB8vwY8cg6Y",
        "title": "Using a Cross-Task Grid of Linear Probes to Interpret CNN Model Predictions On Retinal Images",
        "track": "main",
        "status": "Withdraw",
        "keywords": "linear probes;interpretability;medical imaging",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;4;4;4",
        "correctness": "3;2;3;3",
        "technical_novelty": "1;1;1;3",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 1.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "ZBESeIUB5k",
        "title": "Stochastic Training is Not Necessary for Generalization",
        "track": "main",
        "status": "Poster",
        "keywords": "Optimization;Generalization;Stochasticity;SGD;full-batch;implicit regularization;implicit bias",
        "author": "",
        "aff": "University of Siegen; University of Maryland",
        "rating": "5;6;6;8;10",
        "confidence": "3;3;4;4;5",
        "correctness": "2;4;3;3;4",
        "technical_novelty": "2;3;3;3;4",
        "empirical_novelty": "2;4;2;3;4",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.8,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8964214570007952,
        "corr_rating_correctness": 0.5976143046671968,
        "project": "",
        "github": ""
    },
    {
        "id": "ZC1s7bdR9bD",
        "title": "Path Integrals for the Attribution of Model Uncertainties",
        "track": "main",
        "status": "Reject",
        "keywords": "bayesian neural networks;path integrals;uncertainty attribution",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;3;3;4",
        "correctness": "3;4;3;4",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "2;3;3;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "ZCB_kzXYhvB",
        "title": "An Improved Composite Functional Gradient Learning by Wasserstein Regularization for Generative adversarial networks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "1;3;3",
        "confidence": "5;4;4",
        "correctness": "1;3;2",
        "technical_novelty": "1;2;2",
        "empirical_novelty": "1;2;2",
        "presentation": "",
        "rating_avg": 2.3333333333333335,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 1.6666666666666667,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.8660254037844387,
        "project": "",
        "github": ""
    },
    {
        "id": "ZDYhm_o8MX",
        "title": "Neural Manifold Clustering and Embedding",
        "track": "main",
        "status": "Reject",
        "keywords": "Self-supervised Learning;Clustering;Subspace Clustering;Manifold Learning;Deep Subspace Clustering",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6;6",
        "confidence": "4;3;4;4;3",
        "correctness": "3;3;2;3;3",
        "technical_novelty": "2;2;2;3;2",
        "empirical_novelty": "2;3;2;3;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6,
        "correctness_avg": 2.8,
        "technical_novelty_avg": 2.2,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.372677996249965,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "ZDaSIkWT-AP",
        "title": "Case-based reasoning for better generalization in textual reinforcement learning",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "IBM Research, EPFL; IBM Research; ETH Z\u00fcrich",
        "rating": "6;8;8;8",
        "confidence": "3;5;4;4",
        "correctness": "4;3;3;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.816496580927726,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "ZFIT_sGjPJ",
        "title": "Data-Dependent Randomized Smoothing",
        "track": "main",
        "status": "Reject",
        "keywords": "Network Certification;Randomized Smoothing",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "4;4;3;1",
        "correctness": "2;3;4;3",
        "technical_novelty": "3;3;2;3",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6666666666666665,
        "corr_rating_correctness": 0.8660254037844386,
        "project": "",
        "github": ""
    },
    {
        "id": "ZFWwI5ahxud",
        "title": "Learning to Adapt to Semantic Shift",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Adaptation;Incremental Learning;Deep Learning;Hebbian Learning;Synaptic Plasticity;Domain Adaptation;Continual Learning",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "5;4;4;4",
        "correctness": "3;2;2;3",
        "technical_novelty": "1;2;2;2",
        "empirical_novelty": "2;2;0;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "ZKy2X3dgPA",
        "title": "It Takes Two to Tango: Mixup for Deep Metric Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "Inria, Univ Rennes, CNRS, IRISA; Athena RC; National Technical University of Athens",
        "rating": "6;6;6;6;8",
        "confidence": "3;4;2;4;4",
        "correctness": "4;3;3;4;3",
        "technical_novelty": "2;2;3;3;3",
        "empirical_novelty": "3;2;3;4;3",
        "presentation": "",
        "rating_avg": 6.4,
        "confidence_avg": 3.4,
        "correctness_avg": 3.4,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.37500000000000006,
        "corr_rating_correctness": -0.408248290463863,
        "project": "",
        "github": ""
    },
    {
        "id": "ZN5fOmir9Uk",
        "title": "TexRel: a Green Family of Datasets for Emergent Communication with Relations",
        "track": "main",
        "status": "Withdraw",
        "keywords": "emergent communication;compositionality;metrics;language model;dataset;green;relations",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5;6",
        "confidence": "4;5;4;4;4",
        "correctness": "2;3;2;3;3",
        "technical_novelty": "2;2;2;2;2",
        "empirical_novelty": "2;2;3;2;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.2,
        "correctness_avg": 2.6,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.39528470752104744,
        "corr_rating_correctness": 0.6454972243679028,
        "project": "",
        "github": ""
    },
    {
        "id": "ZOcX-eybqoL",
        "title": "Generalisation in Lifelong Reinforcement Learning through Logical Composition",
        "track": "main",
        "status": "Poster",
        "keywords": "Reinforcement Learning;Lifelong learning;Multi task learning;Transfer learning;Logical composition;Deep Reinforcement Learning",
        "author": "",
        "aff": "School of Computer Science and Applied Mathematics, University of the Witwatersrand, Johannesburg, South Africa",
        "rating": "5;5;5;6;6;8",
        "confidence": "3;2;3;3;3;3",
        "correctness": "3;2;3;4;4;3",
        "technical_novelty": "3;4;2;2;3;3",
        "empirical_novelty": "3;3;2;3;2;3",
        "presentation": "",
        "rating_avg": 5.833333333333333,
        "confidence_avg": 2.8333333333333335,
        "correctness_avg": 3.1666666666666665,
        "technical_novelty_avg": 2.8333333333333335,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3492151478847891,
        "corr_rating_correctness": 0.2651439066774996,
        "project": "",
        "github": ""
    },
    {
        "id": "ZOjKx9dEmLB",
        "title": "NAS-Bench-360: Benchmarking Diverse Tasks for Neural Architecture Search",
        "track": "main",
        "status": "Reject",
        "keywords": "automated machine learning;neural architecture search",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5;6",
        "confidence": "5;5;4;4;5",
        "correctness": "4;3;3;3;4",
        "technical_novelty": "2;1;4;2;1",
        "empirical_novelty": "2;1;2;3;3",
        "presentation": "",
        "rating_avg": 4.4,
        "confidence_avg": 4.6,
        "correctness_avg": 3.4,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.2,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.408248290463863,
        "corr_rating_correctness": 0.06804138174397723,
        "project": "",
        "github": ""
    },
    {
        "id": "ZSKRQMvttc",
        "title": "Accelerated Policy Learning with Parallel Differentiable Simulation",
        "track": "main",
        "status": "Poster",
        "keywords": "Robot Control;Policy Learning;Differentiable Simulation;Reinforcement Learning",
        "author": "",
        "aff": "NVIDIA, University of Toronto; NVIDIA, Massachusetts Institute of Technology; NVIDIA; NVIDIA, University of Sydney; Massachusetts Institute of Technology",
        "rating": "6;8;8;8",
        "confidence": "4;4;4;4",
        "correctness": "4;4;4;4",
        "technical_novelty": "2;3;2;2",
        "empirical_novelty": "3;3;4;4",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 3.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://short-horizon-actor-critic.github.io/"
    },
    {
        "id": "ZTZa78mCbie",
        "title": "For Manifold Learning, Deep Neural Networks Can be Locality Sensitive Hash Functions",
        "track": "main",
        "status": "Withdraw",
        "keywords": "theory of deep learning;theory of representation learning;manifold learning;locality sensitive hash functions;interpretability",
        "author": "",
        "aff": "",
        "rating": "5;5;5",
        "confidence": "3;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "3;4;3",
        "empirical_novelty": "0;2;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.3333333333333335,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "ZTsoE8G3GG",
        "title": "Learning to Extend Molecular Scaffolds with Structural Motifs",
        "track": "main",
        "status": "Poster",
        "keywords": "molecules;graph neural networks;scaffold;generative model",
        "author": "",
        "aff": "Microsoft Research, United Kingdom; Novartis, Switzerland",
        "rating": "3;6;8;8",
        "confidence": "5;3;3;4",
        "correctness": "2;4;3;3",
        "technical_novelty": "1;2;3;3",
        "empirical_novelty": "3;3;3;4",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6998739952495694,
        "corr_rating_correctness": 0.5183210553488161,
        "project": "",
        "github": ""
    },
    {
        "id": "ZU-zFnTum1N",
        "title": "Bregman Gradient Policy Optimization",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "Department of Electrical and Computer Engineering, University of Pittsburgh, Pittsburgh, PA 15261, USA",
        "rating": "6;8;8",
        "confidence": "4;5;3",
        "correctness": "4;4;3",
        "technical_novelty": "1;3;3",
        "empirical_novelty": "1;0;3",
        "presentation": "",
        "rating_avg": 7.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 1.3333333333333333,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.49999999999999983,
        "project": "",
        "github": ""
    },
    {
        "id": "ZUXZKjfptc9",
        "title": "Bit-aware Randomized Response for Local Differential Privacy in Federated Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "local differential privacy;federated learning;bit-aware",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "4;3;3;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "2;3;0;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9428090415820632,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "ZUinrZwKnHb",
        "title": "Attend to Who You Are: Supervising Self-Attention for Keypoint Detection and Instance-Aware Association",
        "track": "main",
        "status": "Reject",
        "keywords": "human pose estimation;bottom-up;self-attention;transformer;instance segmentation",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5;5",
        "confidence": "4;4;4;4;3",
        "correctness": "2;3;4;3;3",
        "technical_novelty": "3;2;2;2;3",
        "empirical_novelty": "2;3;2;2;2",
        "presentation": "",
        "rating_avg": 3.8,
        "confidence_avg": 3.8,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 2.2,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6123724356957946,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "ZV3PZXrRDQ",
        "title": "Towards a Game-Theoretic View of Baseline Values in the Shapley Value",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "3;4;4;2",
        "correctness": "4;2;3;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;2;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.17407765595569782,
        "corr_rating_correctness": -0.5222329678670935,
        "project": "",
        "github": ""
    },
    {
        "id": "ZV7MoEj44Et",
        "title": "Measuring the Effectiveness of Self-Supervised Learning using Calibrated Learning Curves",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Self-Supervised Learning;Transfer Learning;Metric;Evaluation",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;4;3;2",
        "correctness": "2;3;4;3",
        "technical_novelty": "1;2;2;4",
        "empirical_novelty": "2;2;2;4",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8703882797784891,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "ZVqsBl2HapR",
        "title": "Error-based or target-based? A unifying framework for learning in recurrent spiking networks",
        "track": "main",
        "status": "Desk Reject",
        "keywords": "target-based;error-based;recurrent neural network;spiking neural network",
        "author": "",
        "aff": "",
        "rating": "",
        "confidence": "",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "ZWjEkv9rjo",
        "title": "Lattice Quantization",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Convolutional neural networks;quantization;post-training",
        "author": "",
        "aff": "",
        "rating": "3;5;5",
        "confidence": "4;4;4",
        "correctness": "2;2;4",
        "technical_novelty": "1;3;3",
        "empirical_novelty": "1;3;2",
        "presentation": "",
        "rating_avg": 4.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "ZWykq5n4zx",
        "title": "Boosting the Confidence of Near-Tight Generalization Bounds for Uniformly Stable Randomized Algorithms",
        "track": "main",
        "status": "Reject",
        "keywords": "Uniform stability;Randomized learning algorithms;Bagging;Generalization bounds;Stochastic gradient methods",
        "author": "",
        "aff": "",
        "rating": "6;6;6;8",
        "confidence": "5;4;2;3",
        "correctness": "3;4;4;4",
        "technical_novelty": "3;3;2;4",
        "empirical_novelty": "0;3;0;0",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 0.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.2581988897471611,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "ZaI7Rd11G4S",
        "title": "Embedding Compression with Hashing for Efficient Representation Learning in Graph",
        "track": "main",
        "status": "Reject",
        "keywords": "embedding compression;hashing;graph",
        "author": "",
        "aff": "",
        "rating": "3;3;6;6",
        "confidence": "4;4;3;3",
        "correctness": "4;3;3;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;0;4",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "ZaVVVlcdaN",
        "title": "FedChain: Chained Algorithms for Near-optimal Communication Cost in Federated Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "Federated Learning;Optimization;Distributed Optimization",
        "author": "",
        "aff": "Department of Electrical and Computer Engineering, Carnegie Mellon University, Pittsburgh, Pennsylvania, USA; Allen School of Computer Science and Engineering, University of Washington, Seattle, Washington, USA; Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, Champaign, Illinois, USA",
        "rating": "5;5;6;6",
        "confidence": "4;3;4;4",
        "correctness": "2;3;3;4",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;3;3;1",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.7071067811865475,
        "project": "",
        "github": ""
    },
    {
        "id": "Zae_OHNq-y",
        "title": "Imbalanced Adversarial Training with Reweighting",
        "track": "main",
        "status": "Reject",
        "keywords": "imbalanced data;robustness;adversarial training",
        "author": "",
        "aff": "",
        "rating": "3;3;3;8",
        "confidence": "4;4;4;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "3;2;2;4",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "Zca3NK3X8G",
        "title": "WaveCorr: Deep Reinforcement Learning with Permutation Invariant Policy Networks for Portfolio Management",
        "track": "main",
        "status": "Reject",
        "keywords": "permutation invariance;portfolio management;deep reinforcement learning;policy network",
        "author": "",
        "aff": "",
        "rating": "5;5;8;8",
        "confidence": "2;3;3;3",
        "correctness": "3;4;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;0;3;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 2.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896258,
        "corr_rating_correctness": -0.5773502691896258,
        "project": "",
        "github": ""
    },
    {
        "id": "ZeE81SFTsl",
        "title": "DAdaQuant: Doubly-adaptive quantization for communication-efficient Federated Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "federated learning;gradient compression;quantization;communication efficiency",
        "author": "",
        "aff": "Paper under double-blind review",
        "rating": "3;5;5;8",
        "confidence": "4;3;4;2",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8866206949335731,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "Zf4ZdI4OQPV",
        "title": "Attacking deep networks with surrogate-based adversarial black-box methods is easy",
        "track": "main",
        "status": "Poster",
        "keywords": "adversarial attacks;black-box attacks;network robustness;network analysis",
        "author": "",
        "aff": "www.five.ai",
        "rating": "5;5;6;6",
        "confidence": "3;4;4;2",
        "correctness": "2;3;4;4",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;3;2;2",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.30151134457776363,
        "corr_rating_correctness": 0.9045340337332909,
        "project": "",
        "github": "https://github.com/fiveai/GFCS"
    },
    {
        "id": "ZfcosR9vZ-j",
        "title": "Pyramid Mini-Batching for Optimal Transport",
        "track": "main",
        "status": "Withdraw",
        "keywords": "optimal transport;machine learning",
        "author": "",
        "aff": "",
        "rating": "1;3;3;5",
        "confidence": "5;3;3;4",
        "correctness": "2;2;2;3",
        "technical_novelty": "1;2;2;3",
        "empirical_novelty": "2;2;2;0",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4264014327112209,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "ZgV2C9NKk6Q",
        "title": "TorchGeo: deep learning with geospatial data",
        "track": "main",
        "status": "Reject",
        "keywords": "deep learning;remote sensing;geospatial data",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5;6",
        "confidence": "3;4;4;5;4",
        "correctness": "4;3;3;4;3",
        "technical_novelty": "2;2;3;2;3",
        "empirical_novelty": "2;3;4;0;3",
        "presentation": "",
        "rating_avg": 5.2,
        "confidence_avg": 4.0,
        "correctness_avg": 3.4,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.408248290463863,
        "project": "",
        "github": "redacted"
    },
    {
        "id": "ZgrmzzYjMc4",
        "title": "What can multi-cloud configuration learn from AutoML?",
        "track": "main",
        "status": "Reject",
        "keywords": "Cloud;AutoML;Multi-armed bandit;Black box optimizers",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5",
        "confidence": "4;4;5;3",
        "correctness": "2;4;4;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "3;2;3;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "Zk3TwMJNj7",
        "title": "Directional Bias Helps Stochastic Gradient Descent to Generalize in Nonparametric Model",
        "track": "main",
        "status": "Reject",
        "keywords": "directional bias;SGD;RKHS;nonparametric regression",
        "author": "",
        "aff": "",
        "rating": "3;5;5",
        "confidence": "4;5;4",
        "correctness": "4;4;3",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 4.333333333333333,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.4999999999999999,
        "corr_rating_correctness": -0.49999999999999983,
        "project": "",
        "github": ""
    },
    {
        "id": "ZkC8wKoLbQ7",
        "title": "Understanding and Preventing Capacity Loss in Reinforcement Learning",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Reinforcement learning;representation learning",
        "author": "",
        "aff": "Department of Computer Science, University of Oxford; DeepMind",
        "rating": "3;6;8;8",
        "confidence": "4;4;5;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;3;2;4",
        "empirical_novelty": "2;3;3;4",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 4.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.49374193110101877,
        "corr_rating_correctness": 0.8551861104941366,
        "project": "",
        "github": ""
    },
    {
        "id": "ZnUHvSyjstv",
        "title": "On the Capacity and Superposition of Minima in Neural Network Loss Function Landscapes",
        "track": "main",
        "status": "Reject",
        "keywords": "ensemble learning;interpretability;loss function landscape;theoretical chemistry",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;5;4;3",
        "correctness": "2;2;3;3",
        "technical_novelty": "1;3;2;3",
        "empirical_novelty": "2;1;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.816496580927726,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "ZnUwk6i_iTR",
        "title": "Symmetric Machine Theory of Mind",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5;6",
        "confidence": "4;4;4;2;4",
        "correctness": "3;4;3;2;4",
        "technical_novelty": "3;2;2;2;2",
        "empirical_novelty": "3;2;2;2;4",
        "presentation": "",
        "rating_avg": 4.4,
        "confidence_avg": 3.6,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.2,
        "empirical_novelty_avg": 2.6,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.25000000000000006,
        "corr_rating_correctness": -0.08908708063747484,
        "project": "",
        "github": ""
    },
    {
        "id": "ZncyIXXAB-0",
        "title": "IIT-GAN: Irregular and Intermittent Time-series Synthesis with Generative Adversarial Networks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "time-series synthesis;GANs;differential equations",
        "author": "",
        "aff": "Paper under double-blind review",
        "rating": "3;5;6;6",
        "confidence": "5;3;3;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "1;2;3;2",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7385489458759963,
        "corr_rating_correctness": 0.9428090415820632,
        "project": "",
        "github": ""
    },
    {
        "id": "ZocWLFKDN3a",
        "title": "Variational Disentangled Attention for Regularized Visual Dialog",
        "track": "main",
        "status": "Withdraw",
        "keywords": "attention mechanism;latent disentanglement;visual dialog;model regularization",
        "author": "",
        "aff": "",
        "rating": "3;5;6",
        "confidence": "4;4;2",
        "correctness": "3;3;3",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7559289460184546,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "Zq2G_VTV53T",
        "title": "FastSHAP: Real-Time Shapley Value Estimation",
        "track": "main",
        "status": "Poster",
        "keywords": "interpretability;shapley;amortization;explainability;game theory",
        "author": "",
        "aff": "New York University; University of Washington",
        "rating": "5;6;6;8",
        "confidence": "3;4;2;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;0;4",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://git.io/JCqFV (PyTorch), https://git.io/JCqbP (TensorFlow)"
    },
    {
        "id": "Zr5W2LSRhD",
        "title": "Constructing Orthogonal Convolutions in an Explicit Manner",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "Cognitive Computing Lab, Baidu Research, 10900 NE 8th St. Bellevue, Washington 98004, USA",
        "rating": "3;6;6;8",
        "confidence": "5;3;4;4",
        "correctness": "3;4;3;4",
        "technical_novelty": "3;3;3;4",
        "empirical_novelty": "2;3;3;4",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5940885257860046,
        "corr_rating_correctness": 0.7001400420140049,
        "project": "",
        "github": ""
    },
    {
        "id": "ZumkmSpY9G4",
        "title": "Bypassing Logits Bias in Online Class-Incremental Learning with a Generative Framework",
        "track": "main",
        "status": "Reject",
        "keywords": "continual learning;online class-incremental learning;catastrophic forgetting;deep learning",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "4;4;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "Zwy3usE9RxT",
        "title": "Training Deep Generative Models via Auxiliary Supervised Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "deep generative models;supervised learning;representation learning;mutual information;latent variable model",
        "author": "",
        "aff": "Paper under double-blind review",
        "rating": "3;3;5;5",
        "confidence": "5;5;4;3",
        "correctness": "2;3;2;2",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "2;3;0;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.25,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9045340337332909,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "ZzwfldvDLpC",
        "title": "Let Your Heart Speak in its Mother Tongue: Multilingual Captioning of Cardiac Signals",
        "track": "main",
        "status": "Reject",
        "keywords": "multilingual representation learning;cardiac signal captioning",
        "author": "",
        "aff": "",
        "rating": "3;3;6;8",
        "confidence": "4;5;4;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "3;2;3;4",
        "empirical_novelty": "3;2;3;4",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5443310539518174,
        "corr_rating_correctness": 0.5443310539518174,
        "project": "",
        "github": ""
    },
    {
        "id": "_2CLeIIYMPd",
        "title": "Discovering Latent Network Topology in Contextualized Representations with Randomized Dynamic Programming",
        "track": "main",
        "status": "Reject",
        "keywords": "latent structures;dynamic programming;approximate inference;randomization;memory efficiency;contextualized representations;network topology;paraphrase generation;bertology",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;3;4;4",
        "correctness": "3;4;2;4",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.13245323570650439,
        "corr_rating_correctness": 0.3458572319330373,
        "project": "",
        "github": ""
    },
    {
        "id": "_3bwD_KXl5K",
        "title": "WaveSense: Efficient Temporal Convolutions with Spiking Neural Networks for Keyword Spotting",
        "track": "main",
        "status": "Reject",
        "keywords": "spiking;keyword spotting;temporal processing;streaming;audio;neuromorphic;wavenet;wavesense;always-on;low-power;temporal convolution",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3;5",
        "confidence": "4;4;4;4;4",
        "correctness": "2;2;2;2;3",
        "technical_novelty": "2;3;2;3;2",
        "empirical_novelty": "2;2;1;2;3",
        "presentation": "",
        "rating_avg": 3.4,
        "confidence_avg": 4.0,
        "correctness_avg": 2.2,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "_4D8IVs7yO8",
        "title": "Dense-to-Sparse Gate for Mixture-of-Experts",
        "track": "main",
        "status": "Reject",
        "keywords": "Deep Learning;Transformer;Mixture of Experts.",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5;6",
        "confidence": "3;4;3;5;4",
        "correctness": "2;2;3;3;4",
        "technical_novelty": "2;2;2;2;4",
        "empirical_novelty": "2;2;2;2;3",
        "presentation": "",
        "rating_avg": 5.2,
        "confidence_avg": 3.8,
        "correctness_avg": 2.8,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 2.2,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.1336306209562122,
        "corr_rating_correctness": 0.8017837257372732,
        "project": "https://anonymous.4open.science/r/MoE-3D0D/README.moe.md",
        "github": ""
    },
    {
        "id": "_4GFbtOuWq-",
        "title": "Capacity of Group-invariant Linear Readouts from Equivariant Representations: How Many Objects can be Linearly Classified Under All Possible Views?",
        "track": "main",
        "status": "Poster",
        "keywords": "representation learning;perceptron capacity;perceptual manifolds;equivariance;cover's theorem;vc dimension",
        "author": "",
        "aff": "Harvard University; Massachusetts Institute of Technology",
        "rating": "6;6;6;8",
        "confidence": "3;3;3;3",
        "correctness": "4;4;3;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "0;3;2;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "_55bCXzj3D9",
        "title": "Exploring and Evaluating Personalized Models for Code Generation",
        "track": "main",
        "status": "Reject",
        "keywords": "code generation;custom models;NLP",
        "author": "",
        "aff": "",
        "rating": "1;3;3;3",
        "confidence": "5;4;5;5",
        "correctness": "2;3;3;3",
        "technical_novelty": "1;1;1;1",
        "empirical_novelty": "2;1;1;2",
        "presentation": "",
        "rating_avg": 2.5,
        "confidence_avg": 4.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 1.0,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "_5js_8uTrx1",
        "title": "Towards Evaluating the Robustness of Neural Networks Learned by Transduction",
        "track": "main",
        "status": "Poster",
        "keywords": "adversarial robustness;transductive learning;test-time defense;dynamic defense;attacking model spaces",
        "author": "",
        "aff": "University of Wisconsin-Madison; Google; XaiPient",
        "rating": "5;5;6;6",
        "confidence": "5;4;4;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "3;2;3;2",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 4.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": "https://github.com/jfc43/eval-transductive-robustness"
    },
    {
        "id": "_67HnXYixmN",
        "title": "Nested Policy Reinforcement Learning for Clinical Decision Support",
        "track": "main",
        "status": "Reject",
        "keywords": "machine learning for healthcare;reinforcement learning",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "5;4;4;2",
        "correctness": "2;3;2;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "1;2;1;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.75,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9271726499455306,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "_7YnfGdDVML",
        "title": "DCoM: A Deep Column Mapper for Semantic Data Type Detection",
        "track": "main",
        "status": "Reject",
        "keywords": "Semantic Data Type Detection;Machine Learning;Natural Language Processing;Semantic Column Tagging;Sensitive Data Detection;Column Search",
        "author": "",
        "aff": "",
        "rating": "3;3;6",
        "confidence": "5;4;4",
        "correctness": "2;2;3",
        "technical_novelty": "1;2;2",
        "empirical_novelty": "1;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 1.6666666666666667,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "_B8Jd7Nqs7R",
        "title": "Improved Generalization Bound for Deep Neural Networks Using Geometric Functional Analysis",
        "track": "main",
        "status": "Reject",
        "keywords": "Generalization bounds;Geometric functional analysis",
        "author": "",
        "aff": "",
        "rating": "1;3;3;5;6",
        "confidence": "4;4;3;4;3",
        "correctness": "1;3;2;4;4",
        "technical_novelty": "2;2;2;2;4",
        "empirical_novelty": "2;2;0;2;2",
        "presentation": "",
        "rating_avg": 3.6,
        "confidence_avg": 3.6,
        "correctness_avg": 2.8,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 1.6,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.42146361521176234,
        "corr_rating_correctness": 0.9442673704375604,
        "project": "",
        "github": ""
    },
    {
        "id": "_BNiN4IjC5",
        "title": "PriorGrad: Improving Conditional Denoising Diffusion Models with Data-Dependent Adaptive Prior",
        "track": "main",
        "status": "Poster",
        "keywords": "diffusion-based model;generative model;speech synthesis",
        "author": "",
        "aff": "Data Science & AI Lab., Seoul National University; Microsoft Research Asia; AIIS, ASRI, INMC, ISRC, NSI, and Interdisciplinary Program in Arti\ufb01cial Intelligence, Seoul National University",
        "rating": "6;6;6;6",
        "confidence": "4;4;3;4",
        "correctness": "3;3;3;1",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "3;3;2;2",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "_CfpJazzXT2",
        "title": "F8Net: Fixed-Point 8-bit Only Multiplication for Network Quantization",
        "track": "main",
        "status": "Oral",
        "keywords": "Neural Network Quantization;Fixed-Point Arithmetic",
        "author": "",
        "aff": "Snap Inc.; Snap Inc. and Northeastern University, USA; Northeastern University, USA; Rice University, USA",
        "rating": "5;5;6;10",
        "confidence": "5;4;4;5",
        "correctness": "3;3;4;4",
        "technical_novelty": "3;2;3;4",
        "empirical_novelty": "2;2;0;4",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 4.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.48507125007266594,
        "corr_rating_correctness": 0.7276068751089989,
        "project": "",
        "github": "https://github.com/snap-research/F8Net"
    },
    {
        "id": "_DqUHcsQfaE",
        "title": "Inference-Time Personalized Federated Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Federated learning;Personalized federated learning;hypernetworks",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;4;3;4",
        "correctness": "4;3;3;3",
        "technical_novelty": "1;2;2;2",
        "empirical_novelty": "2;3;3;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": -1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "_ERVcPna8IP",
        "title": "Can network pruning benefit deep learning under label noise?",
        "track": "main",
        "status": "Withdraw",
        "keywords": "network pruning;label noise;double descent;sparse loss landscape",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;3;4;4",
        "correctness": "3;2;3;3",
        "technical_novelty": "2;2;1;2",
        "empirical_novelty": "2;3;3;4",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.13245323570650439,
        "corr_rating_correctness": -0.13245323570650439,
        "project": "",
        "github": ""
    },
    {
        "id": "_F9xpOrqyX9",
        "title": "Spread Spurious Attribute: Improving Worst-group Accuracy with Spurious Attribute Estimation",
        "track": "main",
        "status": "Poster",
        "keywords": "worst-group loss minimization;spurious correlation",
        "author": "",
        "aff": "POSTECH; KAIST",
        "rating": "6;6;6;8",
        "confidence": "4;5;3;4",
        "correctness": "3;4;3;3",
        "technical_novelty": "3;3;2;2",
        "empirical_novelty": "3;3;2;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "_HFPHFbJrP-",
        "title": "Certified Adversarial Robustness Under the Bounded Support Set",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5",
        "confidence": "3;4;3",
        "correctness": "4;4;3",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "2;0;2",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 1.3333333333333333,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5,
        "corr_rating_correctness": -1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "_J-pKtWbDKc",
        "title": "Explainable Automatic Hypothesis Generation via High-order Graph Walks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Hypothesis generation;Edge embedding;Reinforcement learning;Graph walk;Link prediction",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;4;4;3",
        "correctness": "4;4;3;3",
        "technical_novelty": "1;2;2;3",
        "empirical_novelty": "0;2;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6622661785325219,
        "corr_rating_correctness": -0.6882472016116854,
        "project": "",
        "github": ""
    },
    {
        "id": "_K6rwRjW9WO",
        "title": "RieszNet and ForestRiesz: Automatic Debiased Machine Learning with Neural Nets and Random Forests",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;6;6;8",
        "confidence": "4;4;3;2",
        "correctness": "4;3;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.899228803025897,
        "corr_rating_correctness": -0.6622661785325219,
        "project": "",
        "github": ""
    },
    {
        "id": "_Ko4kT3ckWy",
        "title": "Increase and Conquer: Training Graph Neural Networks on Growing Graphs",
        "track": "main",
        "status": "Reject",
        "keywords": "Machine Learning;Graph Neural Networks",
        "author": "",
        "aff": "",
        "rating": "3;3;6",
        "confidence": "4;4;4",
        "correctness": "3;2;3",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "_L0nSXXUDDR",
        "title": "Learning with Neighbor Consistency for Noisy Labels",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;5",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "3;2;2",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "_LNdXw0BSx",
        "title": "Towards Coherent and Consistent Use of Entities in Narrative Generation",
        "track": "main",
        "status": "Reject",
        "keywords": "language modeling;narrative generation;entity memory;dynamic representations",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "5;3;4;4",
        "correctness": "4;3;3;3",
        "technical_novelty": "4;2;2;3",
        "empirical_novelty": "3;2;2;0",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "_MO2xzOZXv",
        "title": "Count-GNN: Graph Neural Networks for Subgraph Isomorphism Counting",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5;8",
        "confidence": "4;3;4;4;4",
        "correctness": "3;2;3;3;4",
        "technical_novelty": "2;2;2;2;3",
        "empirical_novelty": "3;2;2;3;3",
        "presentation": "",
        "rating_avg": 4.8,
        "confidence_avg": 3.8,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.2,
        "empirical_novelty_avg": 2.6,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.49099025303098287,
        "corr_rating_correctness": 0.8625819491779426,
        "project": "",
        "github": ""
    },
    {
        "id": "_MRiKN8-sw",
        "title": "Tabular Data Imputation: Choose KNN over Deep Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "data imputation;knn;deep learning;artificial neural networks;digital sobriety",
        "author": "",
        "aff": "",
        "rating": "3;3;6",
        "confidence": "5;4;5",
        "correctness": "2;2;3",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "_PHymLIxuI",
        "title": "CrossFormer: A Versatile Vision Transformer Hinging on Cross-scale Attention",
        "track": "main",
        "status": "Poster",
        "keywords": "vision transformers;architecture",
        "author": "",
        "aff": "Data Platform, Tencent; State Key Lab of CAD & CG, Zhejiang University; School of Software Technology, Zhejiang University; Columbia University",
        "rating": "5;6;6;8",
        "confidence": "5;4;5;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;0;3;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 4.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6882472016116854,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/cheerss/CrossFormer"
    },
    {
        "id": "_PlNmPOsUS9",
        "title": "PARL: Enhancing Diversity of Ensemble Networks to Resist Adversarial Attacks via Pairwise Adversarially Robust Loss Function",
        "track": "main",
        "status": "Reject",
        "keywords": "Adversarial Attack;Ensemble-based Defence;Model Diversity",
        "author": "",
        "aff": "",
        "rating": "3;3;6;6",
        "confidence": "4;5;5;3",
        "correctness": "3;3;4;4",
        "technical_novelty": "3;3;3;2",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 4.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3015113445777637,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "_QLmakITKg",
        "title": "Efficient Split-Mix Federated Learning for On-Demand and In-Situ Customization",
        "track": "main",
        "status": "Poster",
        "keywords": "federated learning",
        "author": "",
        "aff": "Department of Electrical and Computer Engineering, University of Texas at Austin; Department of Computer Science and Engineering, Michigan State University",
        "rating": "3;3;6;8",
        "confidence": "3;4;4;3",
        "correctness": "2;3;3;3",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.23570226039551587,
        "corr_rating_correctness": 0.5443310539518174,
        "project": "",
        "github": "https://github.com/illidanlab/SplitMix"
    },
    {
        "id": "_S7yM35SUCy",
        "title": "Generalizing Cross Entropy Loss with a Beta Proper Composite Loss: An Improved Loss Function for Open Set Recognition",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Proper Composite Loss;Open Set Recognition in deep learning;Out-of-distribution detection in deep learning",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "5;4;3;3",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5222329678670935,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "_SJ-_yyes8",
        "title": "Mastering Visual Continuous Control: Improved Data-Augmented Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "Image-based RL;Data augmentation in RL;Continuous Control",
        "author": "",
        "aff": "",
        "rating": "5;6;8;8",
        "confidence": "5;5;3;5",
        "correctness": "1;3;4;3",
        "technical_novelty": "2;2;1;1",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 4.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 1.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5555555555555555,
        "corr_rating_correctness": 0.8388704928078611,
        "project": "",
        "github": ""
    },
    {
        "id": "_V7e0PfB3jM",
        "title": "Noisy $\\ell^{0}$-Sparse Subspace Clustering on Dimensionality Reduced Data",
        "track": "main",
        "status": "Withdraw",
        "keywords": "$\\ell^{0}$-Sparse Subspace Clustering;Dimensionality Reduction",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "3;4;4;5",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.816496580927726,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "_Vn-mKDipa1",
        "title": "Hierarchically Regularized Deep Forecasting",
        "track": "main",
        "status": "Reject",
        "keywords": "hierarchical time series;deep learning",
        "author": "",
        "aff": "",
        "rating": "5;6;6",
        "confidence": "5;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "3;3;2",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 5.666666666666667,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8660254037844385,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "_Wzj0J2xs2D",
        "title": "CURVATURE-GUIDED DYNAMIC SCALE NETWORKS FOR MULTI-VIEW STEREO",
        "track": "main",
        "status": "Poster",
        "keywords": "multi-view stereo;3D reconstruction;dynamic scale",
        "author": "",
        "aff": "School of Computing, KAIST, Daejeon, 34141, Republic of Korea; Intelligent Robotics Research Division, ETRI, Daejeon 34129, Republic of Korea",
        "rating": "6;6;8;8",
        "confidence": "3;3;5;4",
        "correctness": "3;4;4;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;2;2;0",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9045340337332909,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "_X90SIKbHa",
        "title": "A Class of Short-term Recurrence Anderson Mixing Methods and Their Applications",
        "track": "main",
        "status": "Poster",
        "keywords": "Anderson mixing;sequence acceleration;fixed-point iteration;nonconvex optimization;stochastic optimization",
        "author": "",
        "aff": "Department of Computer Science and Technology, Tsinghua University; Yanqi Lake Beijing Institute of Mathematical Sciences and Applications; Yau Mathematical Sciences Center, Tsinghua University",
        "rating": "6;6;8",
        "confidence": "3;3;2",
        "correctness": "3;3;3",
        "technical_novelty": "3;3;4",
        "empirical_novelty": "0;3;3",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.3333333333333335,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9999999999999998,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "_XNtisL32jv",
        "title": "Temporal Efficient Training of Spiking Neural Network via Gradient Re-weighting",
        "track": "main",
        "status": "Poster",
        "keywords": "Spiking Neural Networks;Direct Training;Surrogate Gradient;Generalizability",
        "author": "",
        "aff": "University of Electronic Science and Technology of China, Shenzhen Institute for Advanced Study, UESTC; University of Electronic Science and Technology of China, Shenzhen Institute for Advanced Study, UESTC, Peng Cheng Laboratory; Peking University; Yale University",
        "rating": "5;5;8;8",
        "confidence": "4;5;4;4",
        "correctness": "3;1;3;3",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "2;1;1;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 4.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896258,
        "corr_rating_correctness": 0.5773502691896258,
        "project": "",
        "github": "https://github.com/Gus-Lab/temporal_efficient_training"
    },
    {
        "id": "_Xaf6zMDsHL",
        "title": "Momentum Contrastive Autoencoder: Using Contrastive Learning for Latent Space Distribution Matching in WAE",
        "track": "main",
        "status": "Reject",
        "keywords": "Wasserstein autoencoder;contrastive learning",
        "author": "",
        "aff": "",
        "rating": "5;5;6",
        "confidence": "3;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "3;2;2",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.4999999999999999,
        "corr_rating_correctness": 0.4999999999999999,
        "project": "",
        "github": ""
    },
    {
        "id": "_YkSZbA7ptn",
        "title": "Structural Optimization Makes Graph Classification Simpler and Better",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Structural Optimization;Graph Classification;Encoding Tree Kernel;Encoding Tree Learning",
        "author": "",
        "aff": "",
        "rating": "3;3;3;6",
        "confidence": "4;4;3;3",
        "correctness": "3;2;2;3",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 3.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "_ZoDJyBBp7z",
        "title": "Feature Flow Regularization: Improving Structured Sparsity in Deep Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "structured pruning",
        "author": "",
        "aff": "",
        "rating": "5;6;6",
        "confidence": "5;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "4;2;3",
        "empirical_novelty": "3;3;2",
        "presentation": "",
        "rating_avg": 5.666666666666667,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8660254037844385,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "__ObYt4753c",
        "title": "A Simple Approach to Adversarial Robustness in Few-shot Image Classification",
        "track": "main",
        "status": "Reject",
        "keywords": "Few-shot learning;Robustness;Image Classification",
        "author": "",
        "aff": "",
        "rating": "5;5;6",
        "confidence": "2;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;1;3",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.4999999999999999,
        "corr_rating_correctness": 0.9999999999999997,
        "project": "",
        "github": ""
    },
    {
        "id": "_cz2R6QnpQJ",
        "title": "Noise Reconstruction and Removal Network: A New Way to Denoise FIB-SEM Images",
        "track": "main",
        "status": "Reject",
        "keywords": "Neural Network;CNN;LSTM;Unsupervised learning;Denoising;FIB-SEM",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5;5",
        "confidence": "5;3;3;4;4",
        "correctness": "3;2;3;3;3",
        "technical_novelty": "1;2;2;2;2",
        "empirical_novelty": "1;2;2;2;2",
        "presentation": "",
        "rating_avg": 4.2,
        "confidence_avg": 3.8,
        "correctness_avg": 2.8,
        "technical_novelty_avg": 1.8,
        "empirical_novelty_avg": 1.8,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.21821789023599233,
        "corr_rating_correctness": 0.6123724356957947,
        "project": "",
        "github": ""
    },
    {
        "id": "_dDmyNX8aZV",
        "title": "RNAS: Robust Network Architecture Search beyond DARTS",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;5",
        "confidence": "4;2;4",
        "correctness": "3;3;3",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "0;2;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.3333333333333333,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "_dE5DwHlnQR",
        "title": "Informative Robust Causal Representation for Generalizable Deep Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Causal Representation;Mutual Information;Robust Representation",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;4;2;3",
        "correctness": "2;3;4;4",
        "technical_novelty": "2;3;4;3",
        "empirical_novelty": "2;3;4;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.48420012470625223,
        "corr_rating_correctness": 0.899228803025897,
        "project": "",
        "github": ""
    },
    {
        "id": "_dXmN3FV--0",
        "title": "Lottery Ticket Structured Node Pruning for Tabular Datasets",
        "track": "main",
        "status": "Reject",
        "keywords": "Lottery Ticket Hypothesis;Tabular;Pruning",
        "author": "",
        "aff": "",
        "rating": "1;3;3;5",
        "confidence": "5;3;3;4",
        "correctness": "3;2;3;4",
        "technical_novelty": "1;2;2;2",
        "empirical_novelty": "1;1;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4264014327112209,
        "corr_rating_correctness": 0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "_fLxZ6VpXTH",
        "title": "Stabilized Likelihood-based Imitation Learning via Denoising Continuous Normalizing Flow",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;5;8",
        "confidence": "5;4;4;4",
        "correctness": "2;3;4;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 4.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "_faKHAwA8O",
        "title": "Representation Consolidation from Multiple Expert Teachers",
        "track": "main",
        "status": "Reject",
        "keywords": "transfer learning;distillation;pretraining;model merging",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;4;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "3;3;2;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "_gZ8dG4vOr9",
        "title": "Pruning Compact ConvNets For Efficient Inference",
        "track": "main",
        "status": "Reject",
        "keywords": "pruning;neural networks;computations;latency;imagenet",
        "author": "",
        "aff": "",
        "rating": "1;3;3;3",
        "confidence": "4;4;4;4",
        "correctness": "1;2;3;4",
        "technical_novelty": "1;1;1;1",
        "empirical_novelty": "1;2;0;3",
        "presentation": "",
        "rating_avg": 2.5,
        "confidence_avg": 4.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 1.0,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.7745966692414834,
        "project": "",
        "github": ""
    },
    {
        "id": "_gZf4NEuf0H",
        "title": "Towards Understanding the Condensation of Neural Networks at Initial Training",
        "track": "main",
        "status": "Reject",
        "keywords": "neural networks;training;condensation dynamics;implicit regularization",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "3;2;3;3",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 2.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "_hszZbt46bT",
        "title": "Anomaly Detection for Tabular Data with Internal Contrastive Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "Anomaly detection;Tabular data",
        "author": "",
        "aff": "Blavatnik School of Computer Science, Tel Aviv University",
        "rating": "6;6;8;8",
        "confidence": "4;4;4;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "3;3;4;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "_ixHFNR-FZ",
        "title": "Adversarially Robust Models may not Transfer Better: Sufficient Conditions for Domain Transferability from the View of Regularization",
        "track": "main",
        "status": "Reject",
        "keywords": "Domain transferability;model regularization",
        "author": "",
        "aff": "Paper under double-blind review",
        "rating": "3;3;5;6",
        "confidence": "3;4;3;4",
        "correctness": "3;2;3;3",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "3;3;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.19245008972987526,
        "corr_rating_correctness": 0.5555555555555555,
        "project": "",
        "github": ""
    },
    {
        "id": "_j4hwbj6Opj",
        "title": "3D Meta-Registration: Meta-learning 3D Point Cloud Registration Functions",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;4;4;4",
        "correctness": "3;2;4;2",
        "technical_novelty": "3;3;2;2",
        "empirical_novelty": "3;2;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.5222329678670935,
        "project": "",
        "github": ""
    },
    {
        "id": "_jMtny3sMKU",
        "title": "Generalizing Few-Shot NAS with Gradient Matching",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "University of California, Los Angeles; Huawei Noah\u2019s Ark Lab; National University of Singapore; The Chinese University of Hong Kong",
        "rating": "6;6;6;6",
        "confidence": "4;4;3;3",
        "correctness": "4;3;3;4",
        "technical_novelty": "3;3;2;2",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/skhu101/GM-NAS"
    },
    {
        "id": "_kJXRDyaU0X",
        "title": "What Would the Expert $do(\\cdot)$?: Causal Imitation Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "imitation learning;causal inference;reinforcement learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "3;3;4;3",
        "correctness": "2;2;3;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.9622504486493761,
        "project": "",
        "github": ""
    },
    {
        "id": "_l_QjPGN5ye",
        "title": "The Boltzmann Policy Distribution: Accounting for Systematic Suboptimality in Human Models",
        "track": "main",
        "status": "Poster",
        "keywords": "human model;boltzmann rationality;suboptimality;HRI;human-robot collaboration;generative models;reinforcement learning;deep RL",
        "author": "",
        "aff": "University of California, Berkeley",
        "rating": "6;8;8;8",
        "confidence": "3;4;2;4",
        "correctness": "4;4;4;4",
        "technical_novelty": "3;3;3;4",
        "empirical_novelty": "3;3;2;4",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.25,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.17407765595569782,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/cassidylaidlaw/boltzmann-policy-distribution"
    },
    {
        "id": "_lmjQL6kcG",
        "title": "Improving the Transferability of Supervised Pretraining with an MLP Projector",
        "track": "main",
        "status": "Withdraw",
        "keywords": "transferability;supervised learning;MLP projector",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "5;4;4;4",
        "correctness": "3;2;3;4",
        "technical_novelty": "1;2;2;3",
        "empirical_novelty": "1;2;3;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 4.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5555555555555555,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "_qc3iqcq-ps",
        "title": "On the Evolution of Neuron Communities in a Deep Learning Architecture",
        "track": "main",
        "status": "Reject",
        "keywords": "explainable ai;deep learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;8",
        "confidence": "3;4;3;4",
        "correctness": "2;4;3;3",
        "technical_novelty": "1;1;3;3",
        "empirical_novelty": "1;2;3;2",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3665083330689157,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "_qjEae4op-",
        "title": "MoFE: Mixture of Factual Experts for Controlling Hallucinations in Abstractive Summarization",
        "track": "main",
        "status": "Withdraw",
        "keywords": "abstractive summarization;content hallucinations",
        "author": "",
        "aff": "Paper under double-blind review",
        "rating": "3;3;3;5",
        "confidence": "4;5;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "3;2;2;3",
        "empirical_novelty": "2;0;2;3",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "_uCb2ynRu7Y",
        "title": "Path Integral Sampler: A Stochastic Control Approach For Sampling",
        "track": "main",
        "status": "Poster",
        "keywords": "Sampling;Path Integral;Stochastic Differential Equation;MCMC",
        "author": "",
        "aff": "Center for Machine Learning, Georgia Institute of Technology; School of Aerospace Engineering, Georgia Institute of Technology",
        "rating": "5;6;8;8",
        "confidence": "3;5;4;3",
        "correctness": "3;3;4;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.058025885318565944,
        "corr_rating_correctness": 0.9622504486493761,
        "project": "",
        "github": ""
    },
    {
        "id": "_uOnt-62ll",
        "title": "Scaling Laws for the Few-Shot Adaptation of Pre-trained Image Classifiers",
        "track": "main",
        "status": "Withdraw",
        "keywords": "scaling;scale;law;laws;few-shot;one-shot;out-of-distribution;ood;generalization;image;vision",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "4;4;4;4",
        "correctness": "2;3;2;3",
        "technical_novelty": "1;2;2;1",
        "empirical_novelty": "1;2;3;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 1.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "_xwr8gOBeV1",
        "title": "Geometric and Physical Quantities improve E(3) Equivariant Message Passing",
        "track": "main",
        "status": "Spotlight",
        "keywords": "equivariant graph neural networks;steerable message passing;non-linear convolutions;molecular modeling;covariant information",
        "author": "",
        "aff": "University of Amsterdam, Johannes Kepler University Linz; University of Amsterdam; UvA-Bosch DeltaLab, University of Amsterdam",
        "rating": "6;6;6;6;8;10",
        "confidence": "3;3;3;4;4;5",
        "correctness": "3;3;4;4;4;4",
        "technical_novelty": "3;3;4;2;2;4",
        "empirical_novelty": "3;3;4;2;2;4",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8783100656536799,
        "corr_rating_correctness": 0.46291004988627577,
        "project": "",
        "github": ""
    },
    {
        "id": "_xxbJ7oSJXX",
        "title": "Offline Reinforcement Learning with Resource Constrained Online Deployment",
        "track": "main",
        "status": "Reject",
        "keywords": "Offline Reinforcement Learning;Reinforcement Learning;Transfer Learning;Knowledge Transfer;Resource Constraints",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "2;4;4;3",
        "correctness": "4;3;4;4",
        "technical_novelty": "1;4;2;3",
        "empirical_novelty": "3;4;3;2",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.17407765595569782,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "_ysluXvD1M",
        "title": "Equal Experience in Recommender Systems",
        "track": "main",
        "status": "Reject",
        "keywords": "Fairness;Recommender systems",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "3;4;3;4",
        "correctness": "4;3;3;4",
        "technical_novelty": "2;3;2;2",
        "empirical_novelty": "2;3;2;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.40824829046386296,
        "corr_rating_correctness": -0.40824829046386296,
        "project": "",
        "github": ""
    },
    {
        "id": "_zL5mZ95FV6",
        "title": "BLUnet: Arithmetic-free Inference with Bit-serialised Table Lookup Operation for Efficient Deep Neural Networks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Efficient Inference;Deep Neural Networks",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "4;3;5;4",
        "correctness": "2;2;2;2",
        "technical_novelty": "2;2;1;3",
        "empirical_novelty": "2;2;1;0",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "a0SRWViFYW",
        "title": "Stochastic Projective Splitting: Solving Saddle-Point Problems with Multiple Regularizers",
        "track": "main",
        "status": "Reject",
        "keywords": "convex optimization;min-max games;saddle-point problems;first-order stochastic methods;proximal methods;operator splitting",
        "author": "",
        "aff": "",
        "rating": "5;5;6",
        "confidence": "4;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "3;2;4",
        "empirical_novelty": "2;3;4",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.9999999999999997,
        "project": "",
        "github": ""
    },
    {
        "id": "a1m8Jba-N6l",
        "title": "$k$-Mixup Regularization for Deep Learning via Optimal Transport",
        "track": "main",
        "status": "Reject",
        "keywords": "Neural networks;Classification;Data augmentation;Optimal Transport",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6;6",
        "confidence": "4;4;4;2;3",
        "correctness": "4;3;2;4;3",
        "technical_novelty": "3;2;3;3;2",
        "empirical_novelty": "2;3;2;2;2",
        "presentation": "",
        "rating_avg": 4.6,
        "confidence_avg": 3.4,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 2.2,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7740702698132101,
        "corr_rating_correctness": -0.11821656093586504,
        "project": "",
        "github": ""
    },
    {
        "id": "a34GrNaYEcS",
        "title": "Distributionally Robust Models with Parametric Likelihood Ratios",
        "track": "main",
        "status": "Poster",
        "keywords": "distributionally robust optimization;fairness;deep learning;robustness;adversarial learning",
        "author": "",
        "aff": "Centre Sciences des Donn\u00e9es, \u00c9cole normale sup\u00e9rieure PSL, Paris, 75005, France; School of Computer Science, Carnegie Mellon University, Pittsburgh, PA 15213, USA; Computer Science Department, Stanford University, Stanford, CA 94305, USA",
        "rating": "6;6;8;8",
        "confidence": "3;3;3;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": "https://github.com/pmichel31415/P-DRO"
    },
    {
        "id": "a3NaSCJ20V",
        "title": "Equivariant Grasp learning In Real Time",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Robotic Grasping;Equivariance;Reinforcement Leanring",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "5;4;4;4",
        "correctness": "2;4;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9271726499455306,
        "corr_rating_correctness": 0.6488856845230502,
        "project": "",
        "github": ""
    },
    {
        "id": "a3hQPNqIFk6",
        "title": "Brittle interpretations: The Vulnerability of TCAV and Other Concept-based Explainability Tools to Adversarial Attack",
        "track": "main",
        "status": "Reject",
        "keywords": "interpretability;adversarial attack",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;4;4;4",
        "correctness": "2;3;3;2",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 4.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "a3mRgptHKZd",
        "title": "Faster No-Regret Learning Dynamics for Extensive-Form Correlated Equilibrium",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;6;6;8",
        "confidence": "4;4;3;2",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;3;3;4",
        "empirical_novelty": "0;3;2;0",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 1.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.899228803025897,
        "corr_rating_correctness": 0.9271726499455306,
        "project": "",
        "github": ""
    },
    {
        "id": "a43otnDilz2",
        "title": "KNIFE: Kernelized-Neural Differential Entropy Estimation",
        "track": "main",
        "status": "Reject",
        "keywords": "differential entropy estimation;differential entropy;mutual information;kernel estimation",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6;6",
        "confidence": "5;3;3;3;3",
        "correctness": "4;3;4;3;4",
        "technical_novelty": "2;2;3;2;3",
        "empirical_novelty": "3;2;3;3;3",
        "presentation": "",
        "rating_avg": 5.6,
        "confidence_avg": 3.4,
        "correctness_avg": 3.6,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 2.8,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6123724356957944,
        "corr_rating_correctness": 0.16666666666666666,
        "project": "",
        "github": ""
    },
    {
        "id": "a4W0tSTN9Kn",
        "title": "MULTI-LEVEL APPROACH TO ACCURATE AND SCALABLE HYPERGRAPH EMBEDDING",
        "track": "main",
        "status": "Withdraw",
        "keywords": "network embedding;hypergraph embedding;hyperedge classification;multi-level hypergraph embedding",
        "author": "",
        "aff": "",
        "rating": "1;3;3;5;5",
        "confidence": "4;3;5;4;3",
        "correctness": "3;2;4;3;3",
        "technical_novelty": "1;3;2;2;3",
        "empirical_novelty": "1;3;2;2;3",
        "presentation": "",
        "rating_avg": 3.4,
        "confidence_avg": 3.8,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.2,
        "empirical_novelty_avg": 2.2,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.2857142857142857,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "a61qArWbjw_",
        "title": "Scalable multimodal variational autoencoders with surrogate joint posterior",
        "track": "main",
        "status": "Reject",
        "keywords": "Deep generative models;multimodal learning",
        "author": "",
        "aff": "",
        "rating": "3;5;6;8",
        "confidence": "3;4;3;2",
        "correctness": "2;4;3;3",
        "technical_novelty": "2;3;3;4",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5883484054145521,
        "corr_rating_correctness": 0.39223227027636803,
        "project": "",
        "github": ""
    },
    {
        "id": "a68yJLSKY-P",
        "title": "Adaptive Differentially Private Empirical Risk Minimization",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Non-convex optimization;Gradient Perturbation;Differentially Private Learning;Adaptive Gradient Methods;Stochastic Gradient Descent;Theory",
        "author": "",
        "aff": "",
        "rating": "",
        "confidence": "",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "a7H7OucbWaU",
        "title": "Memory Replay with Data Compression for Continual Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "Continual Learning;Memory Replay;Data Compression",
        "author": "",
        "aff": "Huawei Noah\u2019s Ark Lab; School of Life Sciences, IDG/McGovern Institute for Brain Research, Tsinghua University; Gaoling School of AI, Renmin University of China; Dept. of Comp. Sci. & Tech., Institute for AI, BNRist Center, THBI Lab, Tsinghua University",
        "rating": "3;6;6;6",
        "confidence": "4;4;4;4",
        "correctness": "4;3;3;3",
        "technical_novelty": "1;4;2;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "aBAgwom5pTn",
        "title": "Dynamic and Efficient Gray-Box Hyperparameter Optimization for Deep Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "hyperparameter optimization",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6;6",
        "confidence": "5;4;3;3;3",
        "correctness": "2;1;3;3;3",
        "technical_novelty": "2;1;2;3;3",
        "empirical_novelty": "2;1;3;3;3",
        "presentation": "",
        "rating_avg": 4.6,
        "confidence_avg": 3.6,
        "correctness_avg": 2.4,
        "technical_novelty_avg": 2.2,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8846517369293829,
        "corr_rating_correctness": 0.8846517369293829,
        "project": "",
        "github": ""
    },
    {
        "id": "aBO5SvgSt1",
        "title": "Mirror Descent Policy Optimization",
        "track": "main",
        "status": "Poster",
        "keywords": "Reinforcement Learning;Policy Optimization",
        "author": "",
        "aff": "University of Alberta, Amii; Microsoft Research NYC; Google Research; Technion, Israel",
        "rating": "5;6;6;8",
        "confidence": "4;2;4;2",
        "correctness": "3;3;4;4",
        "technical_novelty": "1;2;4;3",
        "empirical_novelty": "2;3;4;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6882472016116854,
        "corr_rating_correctness": 0.6882472016116854,
        "project": "",
        "github": ""
    },
    {
        "id": "aBVxf5NaaRt",
        "title": "Unrolling PALM for Sparse Semi-Blind Source Separation",
        "track": "main",
        "status": "Poster",
        "keywords": "Algorithm Unrolling/Unfolding;Blind Source Separation;Sparse Representations;Multi-Convex Optimization;Hyper-parameter Choice",
        "author": "",
        "aff": "CEA Saclay, Gif-sur-Yvette, France; LTCI, T\u00e9l\u00e9m\u00e9com Paris, Institut Polytechnique de Paris, Palaiseau, France",
        "rating": "5;6;8;8",
        "confidence": "2;4;4;4",
        "correctness": "2;3;3;4",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.7777777777777777,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "aBXzcPPOuX",
        "title": "Bundle Networks: Fiber Bundles, Local Trivializations, and a Generative Approach to Exploring Many-to-one Maps",
        "track": "main",
        "status": "Poster",
        "keywords": "generative models;applications of topology to deep learning;many-to-one maps;invertible neural nets",
        "author": "",
        "aff": "University of Washington, Paci\ufb01c Northwest National Laboratory; Paci\ufb01c Northwest National Laboratory, University of Washington",
        "rating": "6;6;6;8",
        "confidence": "3;3;4;3",
        "correctness": "3;4;4;4",
        "technical_novelty": "3;4;2;4",
        "empirical_novelty": "3;0;3;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "aBsCjcPu_tE",
        "title": "SDEdit: Guided Image Synthesis and Editing with Stochastic Differential Equations",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "Stanford University; Carnegie Mellon University",
        "rating": "6;6;8",
        "confidence": "2;3;4",
        "correctness": "2;3;4",
        "technical_novelty": "2;3;2",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8660254037844385,
        "corr_rating_correctness": 0.8660254037844385,
        "project": "",
        "github": ""
    },
    {
        "id": "aD7uesX1GF_",
        "title": "Conditional Object-Centric Learning from Video",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "Google Research",
        "rating": "6;6;8;8",
        "confidence": "5;3;5;4",
        "correctness": "4;3;4;4",
        "technical_novelty": "3;3;4;3",
        "empirical_novelty": "3;3;4;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.30151134457776363,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "https://slot-attention-video.github.io/",
        "github": ""
    },
    {
        "id": "aJ9BXxg352",
        "title": "Intriguing Properties of Input-dependent Randomized Smoothing",
        "track": "main",
        "status": "Reject",
        "keywords": "randomized smoothing;certifiable robustness;deep learning;machine learning",
        "author": "",
        "aff": "",
        "rating": "3;5;5;8",
        "confidence": "4;2;4;4",
        "correctness": "4;3;4;4",
        "technical_novelty": "3;3;2;3",
        "empirical_novelty": "1;1;1;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.08084520834544431,
        "corr_rating_correctness": 0.08084520834544431,
        "project": "",
        "github": ""
    },
    {
        "id": "aJORhCrlYqu",
        "title": "ARMCMC: Online Bayesian Density Estimation of Model Parameters",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Bayesian;Probabilistic approaches;MCMC;Hunt Crossley;parameter identification.",
        "author": "",
        "aff": "",
        "rating": "1;3;3;5",
        "confidence": "4;5;4;3",
        "correctness": "3;2;1;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "aJ_GcB4vcT0",
        "title": "Unsupervised Learning of Neurosymbolic Encoders",
        "track": "main",
        "status": "Reject",
        "keywords": "unsupervised learning;representation learning;neurosymbolic program synthesis",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "3;3;3;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "3;3;3;2",
        "empirical_novelty": "2;3;2;0",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 1.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "aKZeBGUJXlH",
        "title": "Gradient Broadcast Adaptation: Defending against the backdoor attack in pre-trained models",
        "track": "main",
        "status": "Reject",
        "keywords": "backdoor attacks;deep learning security;pre-trained models",
        "author": "",
        "aff": "Paper under double-blind review",
        "rating": "3;5;8",
        "confidence": "4;3;4",
        "correctness": "2;3;4",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "1;2;3",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.1147078669352809,
        "corr_rating_correctness": 0.9933992677987828,
        "project": "",
        "github": ""
    },
    {
        "id": "aM7l2S2s5pk",
        "title": "Offline-Online Reinforcement Learning: Extending Batch and Online RL",
        "track": "main",
        "status": "Reject",
        "keywords": "Reinforcement Learning;Batch RL;Online RL;Offline RL",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "3;5;3;3",
        "correctness": "3;4;3;4",
        "technical_novelty": "1;1;1;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 1.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "aMaQjwz5IXI",
        "title": "Style Equalization: Unsupervised Learning of Controllable Generative Sequence Models",
        "track": "main",
        "status": "Reject",
        "keywords": "Controllable sequence models;Text to speech;Text to handwriting",
        "author": "",
        "aff": "",
        "rating": "3;6;8",
        "confidence": "4;4;4",
        "correctness": "2;3;4",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "2;3;4",
        "presentation": "",
        "rating_avg": 5.666666666666667,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9933992677987828,
        "project": "",
        "github": ""
    },
    {
        "id": "aNCZ8151BjY",
        "title": "Design and Evaluation for Robust Continual Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Continual Learning;robust experimental protocol;task oracle;task identifier",
        "author": "",
        "aff": "",
        "rating": "1;3;5;5",
        "confidence": "2;5;4;3",
        "correctness": "2;3;4;3",
        "technical_novelty": "1;2;1;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 1.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.40451991747794525,
        "corr_rating_correctness": 0.8528028654224417,
        "project": "",
        "github": ""
    },
    {
        "id": "aOX3a9q3RVV",
        "title": "Divisive Feature Normalization Improves Image Recognition Performance in AlexNet",
        "track": "main",
        "status": "Poster",
        "keywords": "divisive normalization;AlexNet;ImageNet;CIFAR-100;manifold capacity;sparsity;receptive fields;Batch Normalization;Group Normalization;Layer Normalization",
        "author": "",
        "aff": "Center for Neural Science, New York University; Flatiron Institute, Simons Foundation; Center for Theoretical Neuroscience, Columbia University; Swartz Program in Theoretical Neuroscience, Kavli Institute for Brain Science, Department of Neuroscience, College of Physicians and Surgeons, Zuckerman Mind Brain Behavior Institute, Columbia University",
        "rating": "6;6;8;8",
        "confidence": "4;4;4;5",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;3;3;4",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "aPOpXlnV1T",
        "title": "On the Pitfalls of Heteroscedastic Uncertainty Estimation with Probabilistic Neural Networks",
        "track": "main",
        "status": "Poster",
        "keywords": "Uncertainty Estimation;Probabilistic Neural Networks;Aleatoric Uncertainty;Heteroscedastic Uncertainty;Analysis",
        "author": "",
        "aff": "Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany; University of T\u00fcbingen, T\u00fcbingen, Germany",
        "rating": "6;6;6",
        "confidence": "4;5;4",
        "correctness": "4;3;3",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "3;2;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "aQE7-2-0Ud5",
        "title": "Boosting Semantic Segmentation via Feature Enhancement",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Deep learning;computer vision;semantic segmentation;feature enhancement",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "5;4;4;5",
        "correctness": "3;3;3;1",
        "technical_novelty": "1;1;2;2",
        "empirical_novelty": "0;2;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 1.5,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "aTzMi4yV_RO",
        "title": "Do Not Escape From the Manifold: Discovering the Local Coordinates on the Latent Space of GANs",
        "track": "main",
        "status": "Poster",
        "keywords": "generative adversarial network;disentanglement;semantic factorization;latent space control;image manipulation;grassmannian",
        "author": "",
        "aff": "Seoul National University",
        "rating": "6;6;8",
        "confidence": "4;5;3",
        "correctness": "4;4;3",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "3;3;0",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8660254037844385,
        "corr_rating_correctness": -0.9999999999999998,
        "project": "",
        "github": ""
    },
    {
        "id": "aUkOeKsGe2X",
        "title": "Autoencoder for Synthetic to Real Generalization: From Simple to More Complex Scenes",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Autoencoder;sim2real;mpi3d;sviro",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5",
        "confidence": "4;4;4;3",
        "correctness": "3;4;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "3;2;2;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "aUoV6qhY_e",
        "title": "Specialized Transformers: Faster, Smaller and more Accurate NLP Models",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;8;8",
        "confidence": "4;3;4;3",
        "correctness": "3;2;4;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.23570226039551587,
        "corr_rating_correctness": 0.5000000000000001,
        "project": "",
        "github": ""
    },
    {
        "id": "aWA3-vIQDv",
        "title": "Universality of Deep Neural Network Lottery Tickets: A Renormalization Group Perspective",
        "track": "main",
        "status": "Reject",
        "keywords": "lottery ticket hypothesis;winning tickets;renormalization group",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "3;3;5;3",
        "correctness": "2;2;3;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "1;3;3;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.13245323570650439,
        "corr_rating_correctness": 0.6882472016116854,
        "project": "",
        "github": ""
    },
    {
        "id": "aY5zi3TampL",
        "title": "Mimicking Randomized Controlled Trials to Learn End-to-End Patient Representations through Self-Supervised Covariate Balancing for Causal Treatment Effect Estimation",
        "track": "main",
        "status": "Withdraw",
        "keywords": "causal treatment effect estimation;representation learning;self-supervised learning;end-to-end causal effect estimation;randomized controlled trials",
        "author": "",
        "aff": "Paper under double-blind review",
        "rating": "3;3;3;3",
        "confidence": "3;3;5;3",
        "correctness": "3;2;2;2",
        "technical_novelty": "1;1;1;2",
        "empirical_novelty": "2;2;0;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 1.25,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "aYAA-XHKyk",
        "title": "Rethinking Class-Prior Estimation for Positive-Unlabeled Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "Positive-Unlabeled Learning;Class-Prior Estimation",
        "author": "",
        "aff": "RIKEN AIP; Hong Kong Baptist University; The University of Melbourne; The University of Sydney; JD Explore Academy, China",
        "rating": "5;6;6;8",
        "confidence": "4;4;3;4",
        "correctness": "4;4;2;4",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;3;2;0",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.13245323570650439,
        "corr_rating_correctness": 0.13245323570650439,
        "project": "",
        "github": ""
    },
    {
        "id": "aYSlxlHKEA",
        "title": "Fully Decentralized Model-based Policy Optimization with Networked Agents",
        "track": "main",
        "status": "Reject",
        "keywords": "Reinforcement learning;model-based;multi-agent;deep learning;networked system control.",
        "author": "",
        "aff": "",
        "rating": "5;5;5",
        "confidence": "3;4;3",
        "correctness": "3;4;4",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;2;1",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "a_ASZbWsQp_",
        "title": "RVFR: Robust Vertical Federated Learning via Feature Subspace Recovery",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Vertical Federated Learning;Adversarial Attacks;Backdoor Attacks;Feature Recovery;Robustness",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;3;3;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "a_nR4BPPJF1",
        "title": "Blessing of Class Diversity in Pre-training",
        "track": "main",
        "status": "Reject",
        "keywords": "representation learning;statistical learning theory",
        "author": "",
        "aff": "",
        "rating": "3;6;6;8",
        "confidence": "5;3;2;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "3;3;2;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4383570037596046,
        "corr_rating_correctness": 0.8892972917998875,
        "project": "",
        "github": ""
    },
    {
        "id": "ab7fanwXWu",
        "title": "Accelerating Optimization using Neural Reparametrization",
        "track": "main",
        "status": "Reject",
        "keywords": "optimization;graph neural networks;neural reparameterization;neural tangent kernel",
        "author": "",
        "aff": "",
        "rating": "1;3;5;6",
        "confidence": "3;3;3;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "1;2;2;3",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.676481425202546,
        "corr_rating_correctness": 0.676481425202546,
        "project": "",
        "github": ""
    },
    {
        "id": "ab7lBP7Fb60",
        "title": "Enforcing fairness in private federated learning via the modified method of differential multipliers",
        "track": "main",
        "status": "Reject",
        "keywords": "Private federated learning;fairness",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "4;4;3;3",
        "correctness": "2;3;2;4",
        "technical_novelty": "3;4;2;4",
        "empirical_novelty": "3;4;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9622504486493761,
        "corr_rating_correctness": 0.5222329678670935,
        "project": "",
        "github": ""
    },
    {
        "id": "aboaN31kfW",
        "title": "Causal Triple Attention Time Series Forecasting",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Time series forecasting;causal inference;multi-horizon;multi-series forecasting tasks",
        "author": "",
        "aff": "",
        "rating": "1;3;5",
        "confidence": "4;3;2",
        "correctness": "1;3;3",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "0;1;3",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 1.3333333333333333,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.8660254037844387,
        "project": "",
        "github": ""
    },
    {
        "id": "acD4xGc7u7",
        "title": "Self-Supervised Learning of Motion-Informed Latents",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Representation learning;self-supervised learning;video representation learning;pose estimation",
        "author": "",
        "aff": "",
        "rating": "1;3;5;5",
        "confidence": "5;4;5;4",
        "correctness": "2;2;2;3",
        "technical_novelty": "1;1;1;1",
        "empirical_novelty": "1;2;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.5,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 1.0,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.30151134457776363,
        "corr_rating_correctness": 0.5222329678670935,
        "project": "",
        "github": ""
    },
    {
        "id": "ad_F_z27pCx",
        "title": "A Discussion On the Validity of Manifold Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Manifold learning;Dimensionality Reduction;Computational Geometry;Simplicial Complex",
        "author": "",
        "aff": "",
        "rating": "3;5;6",
        "confidence": "4;4;3",
        "correctness": "2;2;3",
        "technical_novelty": "3;2;2",
        "empirical_novelty": "2;0;2",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 1.3333333333333333,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7559289460184545,
        "corr_rating_correctness": 0.7559289460184545,
        "project": "",
        "github": ""
    },
    {
        "id": "adjl32ogfqD",
        "title": "Learning Stochastic Shortest Path with Linear Function Approximation",
        "track": "main",
        "status": "Reject",
        "keywords": "reinforcement learning;stochastic shortest path",
        "author": "11537",
        "aff": "",
        "rating": "5;6;6",
        "confidence": "3;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "2;3;2",
        "empirical_novelty": "0;1;0",
        "presentation": "",
        "rating_avg": 5.666666666666667,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 0.3333333333333333,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "ae7BJIOxkxH",
        "title": "Stingy Teacher: Sparse Logits Suffice to Fail Knowledge Distillation",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Knowledge Distillation;avoid knowledge leaking",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "5;4;4;4",
        "correctness": "4;3;3;4",
        "technical_novelty": "3;2;2;3",
        "empirical_novelty": "3;2;2;4",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 4.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5555555555555555,
        "corr_rating_correctness": 0.19245008972987526,
        "project": "",
        "github": ""
    },
    {
        "id": "aedexcMXbKK",
        "title": "Larger Model Causes Lower Classification Accuracy Under Differential Privacy: Reason and Solution",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Differential privacy;feature selection;generalization;high dimension.",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;4;3;2",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7608859102526822,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "af1eUDdUVz",
        "title": "Evading Adversarial Example Detection Defenses with Orthogonal Projected Gradient Descent",
        "track": "main",
        "status": "Poster",
        "keywords": "Adversarial examples;adversarial attacks",
        "author": "",
        "aff": "Google; UC Berkeley",
        "rating": "6;8;8;8",
        "confidence": "3;4;4;3",
        "correctness": "3;4;3;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;3;2",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "afoV8W3-IYp",
        "title": "RelViT: Concept-guided Vision Transformer for Visual Relational Reasoning",
        "track": "main",
        "status": "Poster",
        "keywords": "visual relational reasoning;representation learning;systematic generalization",
        "author": "",
        "aff": "NVIDIA & Caltech; NVIDIA; Northeastern University; NVIDIA & ASU; NVIDIA & UT Austin; UCLA",
        "rating": "6;6;8",
        "confidence": "4;2;4",
        "correctness": "3;3;3",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "3;2;3",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "agBJ7SYcUVb",
        "title": "DFSSATTEN: Dynamic Fine-grained Structured Sparse Attention Mechanism",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;8;8",
        "confidence": "4;3;5;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.7071067811865476,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "ahi2XSHpAUZ",
        "title": "WeakM3D: Towards Weakly Supervised Monocular 3D Object Detection",
        "track": "main",
        "status": "Poster",
        "keywords": "Computer vision;monocular 3D object detection;weakly supervised",
        "author": "",
        "aff": "State Key Lab of CAD&CG, Zhejiang University; FABU Inc.; State Key Lab of CAD&CG, Zhejiang University; FABU Inc.",
        "rating": "6;6;6;6;8",
        "confidence": "4;5;4;4;4",
        "correctness": "4;3;3;3;3",
        "technical_novelty": "2;3;3;3;3",
        "empirical_novelty": "3;3;2;2;3",
        "presentation": "",
        "rating_avg": 6.4,
        "confidence_avg": 4.2,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.8,
        "empirical_novelty_avg": 2.6,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.2500000000000001,
        "corr_rating_correctness": -0.2500000000000001,
        "project": "",
        "github": "https://github.com/SPengLiang/WeakM3D"
    },
    {
        "id": "aisKPsMM3fg",
        "title": "Neural Stochastic Dual Dynamic Programming",
        "track": "main",
        "status": "Poster",
        "keywords": "data-driven algorithm design;learning to optimize;multi-stage stochastic optimization;primal-dual dynamic programming",
        "author": "",
        "aff": "Google Cloud AI; Google Research, Brain Team",
        "rating": "6;6;6;6",
        "confidence": "4;3;2;5",
        "correctness": "3;4;4;3",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "ajIC9wlTd52",
        "title": "Learning to Generalize Compositionally by Transferring Across Semantic Parsing Tasks",
        "track": "main",
        "status": "Reject",
        "keywords": "transfer learning;compositional generalization",
        "author": "",
        "aff": "",
        "rating": "5;6;6",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 5.666666666666667,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.4999999999999999,
        "project": "",
        "github": ""
    },
    {
        "id": "ajOSNLwqssu",
        "title": "Generating Antimicrobial Peptides from Latent Secondary Structure Space",
        "track": "main",
        "status": "Reject",
        "keywords": "Antimicrobial Peptides;Drug Discovery;Secondary Structure;VQ-VAE",
        "author": "",
        "aff": "",
        "rating": "1;5;6",
        "confidence": "4;4;4",
        "correctness": "2;3;3",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "1;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9819805060619656,
        "project": "",
        "github": ""
    },
    {
        "id": "ajXWF7bVR8d",
        "title": "Meta-Learning with Fewer Tasks through Task Interpolation",
        "track": "main",
        "status": "Oral",
        "keywords": "meta-learning;task interpolation;meta-regularization",
        "author": "",
        "aff": "Stanford University; Rutgers University",
        "rating": "8;8;8;8;8",
        "confidence": "3;4;3;4;3",
        "correctness": "3;4;3;3;4",
        "technical_novelty": "3;3;3;3;3",
        "empirical_novelty": "3;3;3;3;2",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.4,
        "correctness_avg": 3.4,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.8,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "alGr3g3L9Jo",
        "title": "The Details Matter: Preventing Class Collapse in Supervised Contrastive Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "contrastive learning;supervised contrastive learning;transfer learning;robustness;noisy labels;coresets",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;3;2;3",
        "correctness": "2;3;4;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7071067811865475,
        "corr_rating_correctness": 0.7071067811865475,
        "project": "",
        "github": ""
    },
    {
        "id": "alaQzRbCY9w",
        "title": "Bolstering Stochastic Gradient Descent with Model Building",
        "track": "main",
        "status": "Reject",
        "keywords": "Stochastic Line Search;Stochastic Model Building;Non-convex Stochastic Optimization;Unconstrained Optimization",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "3;4;4;5",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "1;2;0;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.816496580927726,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "anWCFENEc5H",
        "title": "Modeling Adversarial Noise for Adversarial Defense",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5",
        "confidence": "4;3;5",
        "correctness": "3;2;3",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "3;2;2",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8660254037844387,
        "corr_rating_correctness": 0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "an_ndI09oVZ",
        "title": "Deep banach space kernels",
        "track": "main",
        "status": "Reject",
        "keywords": "RKBS;RKHS;concatenated kernel learning;representation learning;deep learning;MLMKL;Deep Gaussian Processes;gaussian processes;kernel machines",
        "author": "",
        "aff": "",
        "rating": "1;3;3",
        "confidence": "5;3;4",
        "correctness": "2;4;4",
        "technical_novelty": "1;1;3",
        "empirical_novelty": "1;1;2",
        "presentation": "",
        "rating_avg": 2.3333333333333335,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 1.6666666666666667,
        "empirical_novelty_avg": 1.3333333333333333,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8660254037844387,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "anbBFlX1tJ1",
        "title": "Boosted Curriculum Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "reinforcement learning;curriculum learning;boosting;residual learning",
        "author": "",
        "aff": "Department of Electrical Engineering and Automation, Aalto University, Finland; Department of Computer Science, TU Darmstadt, Germany",
        "rating": "6;6;6;8",
        "confidence": "4;3;4;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "apop1GvnJZb",
        "title": "Why does Negative Sampling not Work Well? Analysis of Convexity in Negative Sampling",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Knowledge Graph Embedding;KGE;Negative Sampling;Convexity",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5;6;6;8",
        "confidence": "4;2;4;3;3;4;3",
        "correctness": "2;3;3;3;4;3;4",
        "technical_novelty": "3;4;2;2;3;3;4",
        "empirical_novelty": "2;4;2;2;2;3;4",
        "presentation": "",
        "rating_avg": 4.857142857142857,
        "confidence_avg": 3.2857142857142856,
        "correctness_avg": 3.142857142857143,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.7142857142857144,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.08068715304598781,
        "corr_rating_correctness": 0.7601397897755385,
        "project": "",
        "github": ""
    },
    {
        "id": "apv504XsysP",
        "title": "Ab-Initio Potential Energy Surfaces by Pairing GNNs with Neural Wave Functions",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Graph Neural Networks;Computational Physics;Self-Generative Learning;Machine Learning for Science",
        "author": "",
        "aff": "Department of Informatics & Munich Data Science Institute, Technical University of Munich, Germany",
        "rating": "8;8;8",
        "confidence": "4;4;2",
        "correctness": "3;3;4",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "3;2;0",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "aq6mqSkwApo",
        "title": "Meta-OLE: Meta-learned Orthogonal Low-Rank Embedding",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;6",
        "confidence": "4;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.7559289460184545,
        "project": "",
        "github": ""
    },
    {
        "id": "ar92oEosBIg",
        "title": "Graph Neural Network Guided Local Search for the Traveling Salesperson Problem",
        "track": "main",
        "status": "Poster",
        "keywords": "Traveling Salesman Problem;Graph Neural Network;Metaheuristic;Guided Local Search;Hybrid",
        "author": "",
        "aff": "Department of Electrical and Systems Engineering, University of Pennsylvania; Department of Computer Science and Technology, University of Cambridge",
        "rating": "3;3;6;8;8",
        "confidence": "5;4;5;3;3",
        "correctness": "2;2;3;3;4",
        "technical_novelty": "2;3;3;3;3",
        "empirical_novelty": "2;3;2;3;3",
        "presentation": "",
        "rating_avg": 5.6,
        "confidence_avg": 4.0,
        "correctness_avg": 2.8,
        "technical_novelty_avg": 2.8,
        "empirical_novelty_avg": 2.6,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6972166887783963,
        "corr_rating_correctness": 0.9047619047619047,
        "project": "",
        "github": ""
    },
    {
        "id": "auLXcGlEOZ7",
        "title": "On Margin Maximization in Linear and ReLU Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "Implicit bias;Homogeneous neural networks;Exponential loss;Logistic loss;Maximum margin;Linear networks;ReLU networks",
        "author": "",
        "aff": "",
        "rating": "5;6;6;6",
        "confidence": "2;4;4;3",
        "correctness": "4;4;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.25,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8703882797784891,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "auOPcdAcoy",
        "title": "Hybrid Memoised Wake-Sleep: Approximate Inference at the Discrete-Continuous Interface",
        "track": "main",
        "status": "Poster",
        "keywords": "wake-sleep;variational inference;neuro-symbolic generative models",
        "author": "",
        "aff": "Harvard University; Cornell University; MIT; University of Edinburgh & The Alan Turing Institute",
        "rating": "6;6;8",
        "confidence": "4;4;3",
        "correctness": "4;3;4",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9999999999999998,
        "corr_rating_correctness": 0.49999999999999983,
        "project": "",
        "github": ""
    },
    {
        "id": "avgclFZ221l",
        "title": "Asymmetry Learning for Counterfactually-invariant Classification in OOD Tasks",
        "track": "main",
        "status": "Oral",
        "keywords": "out-of-distribution classification;symmetries;counterfactual invariances;geometric deep learning",
        "author": "",
        "aff": "Department of Computer Science, Purdue University",
        "rating": "8;8;8",
        "confidence": "2;3;4",
        "correctness": "4;4;3",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "3;2;3",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "b-VKxdc5cY",
        "title": "Distribution Matching in Deep Generative Models with Kernel Transfer Operators",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "6;6;6;6",
        "confidence": "4;3;3;3",
        "correctness": "3;4;3;4",
        "technical_novelty": "3;2;2;4",
        "empirical_novelty": "3;2;2;2",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "b-ZaBVGx8Q",
        "title": "DP-REC: Private & Communication-Efficient Federated Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Federated learning;differential privacy;compression;communication efficiency",
        "author": "",
        "aff": "",
        "rating": "6;6;8;8",
        "confidence": "4;3;3;4",
        "correctness": "4;3;4;4",
        "technical_novelty": "3;4;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "b-ny3x071E5",
        "title": "Bootstrapped Meta-Learning",
        "track": "main",
        "status": "Oral",
        "keywords": "meta-learning;meta-gradients;meta-reinforcement learning",
        "author": "",
        "aff": "DeepMind",
        "rating": "8;8;10;10",
        "confidence": "3;3;5;4",
        "correctness": "4;4;4;4",
        "technical_novelty": "4;4;3;4",
        "empirical_novelty": "4;4;3;4",
        "presentation": "",
        "rating_avg": 9.0,
        "confidence_avg": 3.75,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 3.75,
        "empirical_novelty_avg": 3.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9045340337332909,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "b30Yre8MzuN",
        "title": "NeuroSED: Learning Subgraph Similarity via Graph Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "Subgraph similarity;graph neural networks",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "4;4;4;3",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;3;3;4",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "b4jq1xzirPS",
        "title": "An Attention-LSTM Hybrid Model for the Coordinated Routing of Multiple Vehicles",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Reinforcement Learning;Combinatorial Optimization;Traveling Salesman Problem with Drones;Vehicle Routing Problem",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;3;3;4",
        "correctness": "2;3;4;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;3;2;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "b8mo34uDObn",
        "title": "Ensembles and Cocktails: Robust Finetuning for Natural Language Generation",
        "track": "main",
        "status": "Reject",
        "keywords": "finetuning;pretrained language models;natural language generation;robustness;prefix-tuning",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "5;4;4;4",
        "correctness": "2;3;2;3",
        "technical_novelty": "1;3;4;3",
        "empirical_novelty": "0;3;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9271726499455306,
        "corr_rating_correctness": 0.6882472016116854,
        "project": "",
        "github": ""
    },
    {
        "id": "bB6YLDJewoK",
        "title": "Simpler Calibration for Survival Analysis",
        "track": "main",
        "status": "Reject",
        "keywords": "survival analysis;time-to-event analysis;calibration",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;5;3",
        "correctness": "3;3;4;3",
        "technical_novelty": "1;2;2;3",
        "empirical_novelty": "1;2;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "bBrmOMYVrh",
        "title": "LiST: Lite Self-training Makes Efficient Few-shot Learners",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Prompt fine-tuning;Semi-supervised Learning;Few-shot;NLP",
        "author": "",
        "aff": "",
        "rating": "3;5;5;8",
        "confidence": "5;3;4;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "1;2;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.39605901719066966,
        "corr_rating_correctness": 0.8892972917998875,
        "project": "",
        "github": ""
    },
    {
        "id": "bCrdi4iVvv",
        "title": "Learning Features with Parameter-Free Layers",
        "track": "main",
        "status": "Poster",
        "keywords": "ImageNet;efficient network architecture;network design;image classification",
        "author": "",
        "aff": "NAVER AI Lab, NAVER CLOVA; NAVER CLOVA; NAVER AI Lab",
        "rating": "6;6;6;8",
        "confidence": "4;4;4;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "3;2;3;4",
        "empirical_novelty": "2;3;2;4",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": "https://github.com/naver-ai/PfLayer"
    },
    {
        "id": "bE239PSGIGZ",
        "title": "Synthesising Audio Adversarial Examples for Automatic Speech Recognition",
        "track": "main",
        "status": "Reject",
        "keywords": "Adversarial Attack;Speech Synthesise;Automatic Speech Recognition",
        "author": "",
        "aff": "",
        "rating": "5;6;6;8",
        "confidence": "4;4;4;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "3;3;2;3",
        "empirical_novelty": "2;3;3;4",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9271726499455306,
        "project": "https://sites.google.com/view/ssa-asr/home",
        "github": ""
    },
    {
        "id": "bERaNdoegnO",
        "title": "Policy improvement by planning with Gumbel",
        "track": "main",
        "status": "Spotlight",
        "keywords": "AlphaZero;MuZero;reinforcement learning",
        "author": "",
        "aff": "DeepMind, London, UK; University College London; DeepMind, London, UK",
        "rating": "6;8;8;8",
        "confidence": "4;3;3;3",
        "correctness": "3;4;4;4",
        "technical_novelty": "3;3;4;3",
        "empirical_novelty": "4;3;4;3",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "bHqI0DvSIId",
        "title": "Neural Simulated Annealing",
        "track": "main",
        "status": "Reject",
        "keywords": "Combinatorial Optimization;Reinforcement Learning;Evolution Strategies;Simulated Annealing",
        "author": "",
        "aff": "",
        "rating": "5;5;6;8",
        "confidence": "5;4;4;4",
        "correctness": "2;3;4;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4714045207910316,
        "corr_rating_correctness": 0.7385489458759963,
        "project": "",
        "github": ""
    },
    {
        "id": "bM45i3LQBdl",
        "title": "Combining Differential Privacy and Byzantine Resilience in Distributed SGD",
        "track": "main",
        "status": "Reject",
        "keywords": "Distributed SGD;Byzantine resilience",
        "author": "",
        "aff": "",
        "rating": "3;3;6;6",
        "confidence": "3;3;3;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;1;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896258,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "bM5L3GLi6bG",
        "title": "Open Set Domain Adaptation with Zero-shot Learning on Graph",
        "track": "main",
        "status": "Reject",
        "keywords": "open set domain adaptation;zero-shot learning;knowledge graph;graph convolutional network;adversarial learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5",
        "confidence": "4;5;4",
        "correctness": "3;2;3",
        "technical_novelty": "3;2;2",
        "empirical_novelty": "2;0;4",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4999999999999999,
        "corr_rating_correctness": 0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "bOcUqfdH3S8",
        "title": "Provably Calibrated Regression Under Distribution Drift",
        "track": "main",
        "status": "Reject",
        "keywords": "calibration;online prediction;distribution shift;uncertainty quantification",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5",
        "confidence": "3;4;3;3",
        "correctness": "3;3;2;2",
        "technical_novelty": "3;3;2;3",
        "empirical_novelty": "2;3;3;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "bPadTQyLb2_",
        "title": "Efficient representations for privacy-preserving inference",
        "track": "main",
        "status": "Reject",
        "keywords": "Deep neural networks;Homomorphic encryption",
        "author": "",
        "aff": "",
        "rating": "3;5;6;8",
        "confidence": "5;2;3;3",
        "correctness": "2;3;4;4",
        "technical_novelty": "1;1;2;3",
        "empirical_novelty": "1;0;2;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5726562866782,
        "corr_rating_correctness": 0.9198662110077999,
        "project": "",
        "github": ""
    },
    {
        "id": "bRbZoK2HQw8",
        "title": "Attention-based Interpretation and Response to The Trade-Off of Adversarial Training",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Adversarial training;Trade-off",
        "author": "",
        "aff": "",
        "rating": "3;3;5",
        "confidence": "5;5;3",
        "correctness": "2;4;2",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": -0.5000000000000001,
        "project": "",
        "github": ""
    },
    {
        "id": "bTteFbU99ye",
        "title": "Evaluating Distributional Distortion in Neural Language Modeling",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "McGill University, Mila \u2013 Quebec Arti\ufb01cial Intelligence Institute, Canada CIFAR AI Chair, Mila; Microsoft Research; McGill University, Mila \u2013 Quebec Arti\ufb01cial Intelligence Institute",
        "rating": "8;8;8",
        "confidence": "3;4;5",
        "correctness": "3;3;4",
        "technical_novelty": "2;3;4",
        "empirical_novelty": "3;2;4",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "bUAdXW8wN6",
        "title": "Domain Invariant Adversarial Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "adversarial Training;Robustness;Domain-invariant representation;domain adaptation",
        "author": "",
        "aff": "",
        "rating": "3;3;5;8",
        "confidence": "4;3;4;4",
        "correctness": "3;4;4;4",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "3;2;4;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.49374193110101877,
        "corr_rating_correctness": 0.49374193110101877,
        "project": "",
        "github": ""
    },
    {
        "id": "bUKyC0UiZcr",
        "title": "Temporal abstractions-augmented temporally contrastive learning: an alternative to the Laplacian in RL",
        "track": "main",
        "status": "Reject",
        "keywords": "Representation learning;Laplacian;self-supervised;exploration",
        "author": "",
        "aff": "",
        "rating": "5;5;6",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "bUi8963hi5l",
        "title": "Calibrating Probabilistic Embeddings for Cross-Modal Retrieval",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5",
        "confidence": "5;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "1;3;3",
        "empirical_novelty": "2;4;3",
        "presentation": "",
        "rating_avg": 4.333333333333333,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9999999999999997,
        "corr_rating_correctness": 0.49999999999999983,
        "project": "",
        "github": ""
    },
    {
        "id": "bVT5w39X0a",
        "title": "Bayesian Relational Generative Model for Scalable Multi-modal Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Multi-modal Learning;Bayesian Learning;Neural Processes;Variational Inference",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "3;4;4;5",
        "correctness": "3;3;2;3",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "0;0;3;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.7071067811865475,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "bVkRc9NDHcK",
        "title": "Variable Length Variable Quality Audio Steganography",
        "track": "main",
        "status": "Reject",
        "keywords": "computer vision;stegaography;recurrent neural network;loss conditional training;information hiding",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "5;2;3;4",
        "correctness": "3;2;3;4",
        "technical_novelty": "3;2;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7745966692414834,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "bVuP3ltATMz",
        "title": "Large Language Models Can Be Strong Differentially Private Learners",
        "track": "main",
        "status": "Oral",
        "keywords": "language model;differential privacy;language generation;fine-tuning;NLP",
        "author": "",
        "aff": "Stanford University; Google Research",
        "rating": "6;8;8;8",
        "confidence": "4;4;3;5",
        "correctness": "3;3;3;3",
        "technical_novelty": "3;3;2;4",
        "empirical_novelty": "4;3;3;3",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/lxuechen/private-transformers"
    },
    {
        "id": "bVvMOtLMiw",
        "title": "DIVA: Dataset Derivative of a Learning Task",
        "track": "main",
        "status": "Poster",
        "keywords": "Leave one out cross validation;AutoML;dataset optimization",
        "author": "",
        "aff": "Amazon Web Services; Amazon Web Services and Department of Mathematics, University of California, Los Angeles",
        "rating": "5;6;8;8",
        "confidence": "5;3;4;3",
        "correctness": "4;3;4;3",
        "technical_novelty": "2;3;3;4",
        "empirical_novelty": "2;2;4;4",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5222329678670935,
        "corr_rating_correctness": -0.19245008972987526,
        "project": "",
        "github": ""
    },
    {
        "id": "bYGSzbCM_i",
        "title": "Online Adversarial Attacks",
        "track": "main",
        "status": "Poster",
        "keywords": "Online Algorithms;Adversarial Attacks",
        "author": "",
        "aff": "Mila, Universit\u00e9 de Montr\u00e9al; Mila, McGill University",
        "rating": "5;5;6;8",
        "confidence": "3;4;3;4",
        "correctness": "3;2;3;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.40824829046386296,
        "corr_rating_correctness": 0.8660254037844386,
        "project": "",
        "github": ""
    },
    {
        "id": "bYfk8y7BXS",
        "title": "Pessimistic Model Selection for Offline Deep Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "reinforcement learning theory;offline deep reinforcement learning;model selection;pessimism;tuning free",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "3;4;3;3",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;0;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "bZJbzaj_IlP",
        "title": "A NON-PARAMETRIC REGRESSION VIEWPOINT : GENERALIZATION OF OVERPARAMETRIZED DEEP RELU NETWORK UNDER NOISY OBSERVATIONS",
        "track": "main",
        "status": "Poster",
        "keywords": "Overparametrized Deep Neural Network;Neural Tangent Kernel;Minimax;Non-parametric regression",
        "author": "",
        "aff": "H.Milton Stewart School of Industrial and Systems Engineering, Georgia Institute of Technology, Atlanta, GA, USA",
        "rating": "6;6;8;8",
        "confidence": "3;4;3;3",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;0;3;0",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "ba81PoR_k1p",
        "title": "One for Many: an Instagram inspired black-box adversarial attack",
        "track": "main",
        "status": "Reject",
        "keywords": "black-box adversarial attacks;instragram-based image filters;evolutionary algorithm;multi-network attacks",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6;6",
        "confidence": "4;4;4;4;2",
        "correctness": "3;3;3;4;3",
        "technical_novelty": "2;2;3;3;2",
        "empirical_novelty": "2;2;2;3;3",
        "presentation": "",
        "rating_avg": 4.6,
        "confidence_avg": 3.6,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.51604684654214,
        "corr_rating_correctness": 0.5160468465421401,
        "project": "",
        "github": ""
    },
    {
        "id": "baUQQPwQiAg",
        "title": "Robust Unlearnable Examples: Protecting Data Privacy Against Adversarial Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "unlearnable examples;adversarial training;privacy",
        "author": "",
        "aff": "Institute for AI Industry Research, Tsinghua University, China; JD Explore Academy, JD.com Inc, China",
        "rating": "3;6;6;8",
        "confidence": "4;3;5;5",
        "correctness": "2;4;3;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;3;2;4",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.37998029782867415,
        "corr_rating_correctness": 0.8866206949335731,
        "project": "",
        "github": "https://github.com/fshp971/robust-unlearnable-examples"
    },
    {
        "id": "beUek8ku1Q",
        "title": "k-Median Clustering via Metric Embedding: Towards Better Initialization with Privacy",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;6;6;6",
        "confidence": "4;4;3;3",
        "correctness": "4;3;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "beiz51zcm-H",
        "title": "BO-DBA: Query-Efficient Decision-Based Adversarial Attacks via Bayesian Optimization",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Adversarial Attack;Bayesian Optimization",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "3;5;3;3",
        "correctness": "2;4;2;4",
        "technical_novelty": "3;2;1;2",
        "empirical_novelty": "2;2;1;0",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "bfuGjlCwAq",
        "title": "Learning Efficient Online 3D Bin Packing on Packing Configuration Trees",
        "track": "main",
        "status": "Poster",
        "keywords": "Bin Packing Problem;Online 3D-BPP;Reinforcement Learning",
        "author": "",
        "aff": "School of Computer Science, National University of Defense Technology, China; National Key Lab for Novel Software Technology, Nanjing University, China",
        "rating": "3;6;6;8",
        "confidence": "4;2;3;4",
        "correctness": "2;4;3;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "0;3;3;0",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.1266600992762247,
        "corr_rating_correctness": 0.5940885257860046,
        "project": "",
        "github": ""
    },
    {
        "id": "bgAS1ZvveZ",
        "title": "Faster Reinforcement Learning with Value Target Lower Bounding",
        "track": "main",
        "status": "Reject",
        "keywords": "reinforcement learning;bellman value target;lower bound;discounted return",
        "author": "",
        "aff": "",
        "rating": "3;6;6;6",
        "confidence": "5;5;4;4",
        "correctness": "3;2;4;4",
        "technical_novelty": "1;3;3;3",
        "empirical_novelty": "1;3;3;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 4.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.17407765595569782,
        "project": "",
        "github": ""
    },
    {
        "id": "bglU8l_Pq8Q",
        "title": "In defense of dual-encoders for neural ranking",
        "track": "main",
        "status": "Reject",
        "keywords": "cross-attention;dual encoder;neural ranking;distillation",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "5;3;2;4",
        "correctness": "4;3;4;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7302967433402214,
        "corr_rating_correctness": -0.40824829046386296,
        "project": "",
        "github": ""
    },
    {
        "id": "bi9j5yi-Vrv",
        "title": "A General Theory of Relativity in Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Reinforcement Learning;General RL Theory;Policy Transfer;Dynamics Modeling",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;2;4;4",
        "correctness": "3;3;3;2",
        "technical_novelty": "1;2;2;3",
        "empirical_novelty": "1;2;2;0",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": -1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "bidTZROu2y",
        "title": "Physics Informed Machine Learning of SPH: Machine Learning Lagrangian Turbulence",
        "track": "main",
        "status": "Reject",
        "keywords": "Physics Informed Machine Learning;Smoothed Particle Hydrodynamics;Sensitivity Analysis;Differentiable Programming;Mixed Mode Automatic Differentiation;Deep Learning;Turbulence;Lagrangian Fluid Simulation.",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5;6",
        "confidence": "4;4;3;3;3",
        "correctness": "2;3;4;3;4",
        "technical_novelty": "2;2;2;2;2",
        "empirical_novelty": "2;2;3;3;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.4,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6454972243679028,
        "corr_rating_correctness": 0.42257712736425823,
        "project": "",
        "github": ""
    },
    {
        "id": "bilHNPhT6-",
        "title": "On Multi-objective Policy Optimization as a Tool for Reinforcement Learning: Case Studies in Offline RL and Finetuning",
        "track": "main",
        "status": "Reject",
        "keywords": "offline RL;learning from experts;finetuning;multi-objective RL;deep RL;continuous control",
        "author": "",
        "aff": "Paper under double-blind review",
        "rating": "3;5;6;6",
        "confidence": "3;3;3;3",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.8164965809277259,
        "project": "",
        "github": ""
    },
    {
        "id": "biyvmQe5jM",
        "title": "How to decay your learning rate",
        "track": "main",
        "status": "Reject",
        "keywords": "learning rates;hyperparameter tuning;schedules",
        "author": "Aitor Lewkowycz",
        "aff": "",
        "rating": "3;3;6;6",
        "confidence": "4;4;4;3",
        "correctness": "2;3;4;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896258,
        "corr_rating_correctness": 0.7071067811865476,
        "project": "",
        "github": ""
    },
    {
        "id": "bjYunHo6LWR",
        "title": "Classification and Uncertainty Quantification of Corrupted Data using Semi-Supervised Autoencoders",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;3;4;3",
        "correctness": "4;2;1;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;1",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.4472135954999579,
        "project": "",
        "github": ""
    },
    {
        "id": "bjy5Zb2fo2",
        "title": "Scattering Networks on the Sphere for Scalable and Rotationally Equivariant Spherical CNNs",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "Kagenova Limited, Guildford, Surrey, United Kingdom.",
        "rating": "5;5;6;6",
        "confidence": "4;3;4;3",
        "correctness": "4;4;4;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "1;2;3;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "bl9zYxOVwa",
        "title": "Understanding the robustness-accuracy tradeoff by rethinking robust fairness",
        "track": "main",
        "status": "Reject",
        "keywords": "Adversarial training;Adversarial robustness",
        "author": "",
        "aff": "",
        "rating": "3;3;6;6",
        "confidence": "4;4;4;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "1;3;2;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896258,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "bmGLlsX_iJl",
        "title": "EMFlow: Data Imputation in Latent Space via EM and Deep Flow Models",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "4;3;5;4",
        "correctness": "2;3;4;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.28867513459481287,
        "corr_rating_correctness": 0.9847319278346618,
        "project": "",
        "github": ""
    },
    {
        "id": "boJy41J-tnQ",
        "title": "Subspace Regularizers for Few-Shot Class Incremental Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "few-shot class incremental learning;incremental learning;incremental classification;subspace regularization;manifold regularization;few-shot learning",
        "author": "",
        "aff": "Boston University; MIT CSAIL",
        "rating": "5;6;6;8",
        "confidence": "4;5;4;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "3;3;3;4",
        "empirical_novelty": "2;3;3;4",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 4.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.13245323570650439,
        "corr_rating_correctness": 0.6882472016116854,
        "project": "",
        "github": "https://github.com/feyzaakyurek/subspace-reg"
    },
    {
        "id": "bp-LJ4y_XC",
        "title": "Sequence Approximation using Feedforward Spiking Neural Network for Spatiotemporal Learning: Theory and Optimization Methods",
        "track": "main",
        "status": "Poster",
        "keywords": "spiking neural network;spatiotemporal processing;feedforward network",
        "author": "",
        "aff": "School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA 30332, USA",
        "rating": "6;6;8",
        "confidence": "4;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.49999999999999983,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "bpUHBc9HCU8",
        "title": "A General Unified Graph Neural Network Framework Against Adversarial Attacks",
        "track": "main",
        "status": "Reject",
        "keywords": "Graph Neural Networks;general unified framework;against adversarial attacks;robust model;graph reconstruction operation",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "5;4;4;5",
        "correctness": "3;4;2;2",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;3;3;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 4.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": -0.17407765595569782,
        "project": "",
        "github": ""
    },
    {
        "id": "bq7smM1OJIX",
        "title": "Determining the Ethno-nationality of Writers Using Written English Text",
        "track": "main",
        "status": "Reject",
        "keywords": "Ethno-nationality;Native Language Identification;Natural Language Processing;Machine Learning;Linear SVM;Less-controlled environments;ICE corpus",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "5;4;4;4",
        "correctness": "3;1;2;3",
        "technical_novelty": "1;1;1;1",
        "empirical_novelty": "1;1;2;1",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.25,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 1.0,
        "empirical_novelty_avg": 1.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "bsr02xd-utn",
        "title": "Pairwise Adversarial Training for Unsupervised Class-imbalanced Domain Adaptation",
        "track": "main",
        "status": "Reject",
        "keywords": "domain adaptation adversarial training imbalanced class distribution",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5",
        "confidence": "4;5;5;5",
        "correctness": "3;4;3;3",
        "technical_novelty": "3;3;3;2",
        "empirical_novelty": "2;3;0;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "bsycpMi00R1",
        "title": "Generalized Natural Gradient Flows in Hidden Convex-Concave Games and GANs",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "SUTD; Univ. of Montr\u00b4eal & Mila",
        "rating": "6;6;6;6",
        "confidence": "2;3;4;4",
        "correctness": "3;4;4;4",
        "technical_novelty": "3;2;3;2",
        "empirical_novelty": "0;3;2;2",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "buSCIu6izBY",
        "title": "Occupy & Specify: Investigations into a Maximum Credit Assignment Occupancy Objective for Data-efficient Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Reinforcement Learning;Intrinsic reward;MaxEnt;Probability matching;Motor control;Variational inference",
        "author": "",
        "aff": "",
        "rating": "1;3;3",
        "confidence": "3;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "1;2;2",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 2.3333333333333335,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 1.6666666666666667,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "bwq6O4Cwdl",
        "title": "How Does SimSiam Avoid Collapse Without Negative Samples? A Unified Understanding with Self-supervised Contrastive Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "SimSiam;Negative samples;SSL;Collapse;Covariance",
        "author": "",
        "aff": "Korea Advanced Institute of Science and Technology (KAIST), South Korea",
        "rating": "6;6;6;8;8",
        "confidence": "3;3;3;3;4",
        "correctness": "3;2;3;4;3",
        "technical_novelty": "3;2;2;4;3",
        "empirical_novelty": "2;2;2;4;3",
        "presentation": "",
        "rating_avg": 6.8,
        "confidence_avg": 3.2,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.8,
        "empirical_novelty_avg": 2.6,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.6123724356957946,
        "corr_rating_correctness": 0.6454972243679028,
        "project": "",
        "github": ""
    },
    {
        "id": "bxiDvWZm6zU",
        "title": "Influence-Based Reinforcement Learning for Intrinsically-Motivated Agents",
        "track": "main",
        "status": "Reject",
        "keywords": "Mutli-Agent Reinforcement Learning;Coordination;Intrinsic Motivation;Coordinated Exploration",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;4;4",
        "correctness": "2;3;3;2",
        "technical_novelty": "1;2;3;2",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "c-4HSDAWua5",
        "title": "SketchODE: Learning neural sketch representation in continuous time",
        "track": "main",
        "status": "Poster",
        "keywords": "Chirography;Sketch;Free-form;Neural ODE",
        "author": "",
        "aff": "SketchX, CVSSP, University of Surrey, UK; School of Informatics, University of Edinburgh, UK; SketchX, CVSSP, University of Surrey, UK; iFlyTek-Surrey Joint Research Centre on Artificial Intelligence; School of Informatics, University of Edinburgh, UK",
        "rating": "5;6;8;8",
        "confidence": "4;3;3;3",
        "correctness": "3;4;4;4",
        "technical_novelty": "2;3;4;3",
        "empirical_novelty": "2;3;4;4",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 3.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7777777777777777,
        "corr_rating_correctness": 0.7777777777777777,
        "project": "",
        "github": ""
    },
    {
        "id": "c0AD3ll9Wyv",
        "title": "Can Label-Noise Transition Matrix Help to Improve Sample Selection and Label Correction?",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6;6",
        "confidence": "5;5;4;5;4",
        "correctness": "2;3;4;4;3",
        "technical_novelty": "3;2;2;4;4",
        "empirical_novelty": "3;2;3;4;3",
        "presentation": "",
        "rating_avg": 4.6,
        "confidence_avg": 4.6,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5417363388859615,
        "corr_rating_correctness": 0.6698938453032357,
        "project": "",
        "github": ""
    },
    {
        "id": "c4iTLTkpY5",
        "title": "Personalized Heterogeneous Federated Learning with Gradient Similarity",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "Wen",
        "aff": "Paper under double-blind review",
        "rating": "3;3;3;5",
        "confidence": "4;4;4;3",
        "correctness": "3;2;3;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;3;4",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "c60vFLXEwED",
        "title": "PIVQGAN: Posture and Identity Disentangled Image-to-Image Translation via Vector Quantization",
        "track": "main",
        "status": "Reject",
        "keywords": "deep learning;generative model;image synthesis;generative adversarial network;self-supervised learning;image-to-image translation",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6;6",
        "confidence": "4;3;4;5;3",
        "correctness": "3;2;3;4;3",
        "technical_novelty": "2;3;2;3;2",
        "empirical_novelty": "2;3;3;2;2",
        "presentation": "",
        "rating_avg": 5.4,
        "confidence_avg": 3.8,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.2182178902359924,
        "corr_rating_correctness": 0.6454972243679027,
        "project": "",
        "github": ""
    },
    {
        "id": "c7S4WIlmu5",
        "title": "Contrastive Pre-training for Zero-Shot Information Retrieval",
        "track": "main",
        "status": "Reject",
        "keywords": "information retrieval;contrastive pretraining",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;5;4;3",
        "correctness": "3;2;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7071067811865475,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "c7zS_oS5gU",
        "title": "Federated Distillation of Natural Language Understanding with Confident Sinkhorns",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Sinkhorn;NLP;Wasserstein;Random probability skew;Federated Distillation",
        "author": "",
        "aff": "",
        "rating": "1;3;5;6",
        "confidence": "3;3;3;4",
        "correctness": "2;2;3;3",
        "technical_novelty": "1;2;3;3",
        "empirical_novelty": "1;2;3;2",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 3.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.676481425202546,
        "corr_rating_correctness": 0.911322376865767,
        "project": "",
        "github": ""
    },
    {
        "id": "c87d0TS4yX",
        "title": "Orchestrated Value Mapping for Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "Reinforcement Learning;Value Mapping;Reward Decomposition",
        "author": "",
        "aff": "Max Planck Institute for Intelligent Systems, T\u00a8ubingen, Germany; Microsoft Research, Montr\u00b4eal, Canada",
        "rating": "6;6;6",
        "confidence": "3;4;3",
        "correctness": "4;3;3",
        "technical_novelty": "3;3;2",
        "empirical_novelty": "3;2;2",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "c8AvdRAyVkz",
        "title": "Perturbation Deterioration: The Other Side of Catastrophic Overfitting",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "5;3;5;2",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4074074074074074,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "c8JDlJMBeyh",
        "title": "Towards Generic Interface for Human-Neural Network Knowledge Exchange",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "3;4;3;4",
        "correctness": "4;2;3;3",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "c9IvZqZ8SNI",
        "title": "Learning Structure from the Ground up---Hierarchical Representation Learning by Chunking",
        "track": "main",
        "status": "Reject",
        "keywords": "representation learning;interpretability;cognitive science",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "4;4;3;3",
        "correctness": "3;3;3;4",
        "technical_novelty": "1;2;3;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9622504486493761,
        "corr_rating_correctness": 0.7777777777777777,
        "project": "",
        "github": ""
    },
    {
        "id": "cAuJrUm8lG",
        "title": "Implicit Equivariance in Convolutional Networks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;4;3;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;2;2;4",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.13245323570650439,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "cBu4ElJfneV",
        "title": "GiraffeDet: A Heavy-Neck Paradigm for Object Detection",
        "track": "main",
        "status": "Poster",
        "keywords": "Object Detection;fpn;space-to-depth;representation",
        "author": "",
        "aff": "DAMO Academy, Alibaba Group",
        "rating": "5;8;8",
        "confidence": "5;3;5",
        "correctness": "3;2;4",
        "technical_novelty": "2;3;4",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/jyqi/GiraffeDet"
    },
    {
        "id": "cD0O_Sc-wNy",
        "title": "Learn the Time to Learn: Replay Scheduling for Continual Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Continual Learning;Replay Memory;Task Incremental Learning",
        "author": "",
        "aff": "",
        "rating": "3;5;6;8",
        "confidence": "4;4;4;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;2;2;0",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.16012815380508713,
        "project": "",
        "github": ""
    },
    {
        "id": "cGDAkQo1C0p",
        "title": "Reversible Instance Normalization for Accurate Time-Series Forecasting against Distribution Shift",
        "track": "main",
        "status": "Poster",
        "keywords": "Time-series forecasting;Normalization;Distribution shift",
        "author": "",
        "aff": "NAVER Corp.; KAIST AI; ETRI; VUNO",
        "rating": "5;6;8",
        "confidence": "4;3;4",
        "correctness": "3;4;3",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;3;0",
        "presentation": "",
        "rating_avg": 6.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.18898223650461363,
        "corr_rating_correctness": -0.18898223650461363,
        "project": "",
        "github": ""
    },
    {
        "id": "cJPkX1g9PQS",
        "title": "Rethinking Self-Supervision Objectives for Generalizable Coherence Modeling",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "4;4;2;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4714045207910316,
        "corr_rating_correctness": 0.4714045207910316,
        "project": "",
        "github": ""
    },
    {
        "id": "cKTBRHIVjy9",
        "title": "SubMix: Practical Private Prediction for Large-scale Language Models",
        "track": "main",
        "status": "Reject",
        "keywords": "private prediction;language models;user privacy;machine learning",
        "author": "",
        "aff": "",
        "rating": "3;3;6;8",
        "confidence": "4;5;2;3",
        "correctness": "2;1;3;4",
        "technical_novelty": "2;1;3;3",
        "empirical_novelty": "2;1;2;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7378647873726218,
        "corr_rating_correctness": 0.9486832980505139,
        "project": "",
        "github": ""
    },
    {
        "id": "cKoY420qRuL",
        "title": "Group-disentangled Representation Learning with Weakly-Supervised Regularization",
        "track": "main",
        "status": "Withdraw",
        "keywords": "variational autoencoder;representation learning;disentanglement",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5;5",
        "confidence": "4;4;3;4;2",
        "correctness": "2;3;3;3;1",
        "technical_novelty": "2;2;2;2;2",
        "empirical_novelty": "2;2;3;2;2",
        "presentation": "",
        "rating_avg": 4.6,
        "confidence_avg": 3.4,
        "correctness_avg": 2.4,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.2,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.37500000000000017,
        "corr_rating_correctness": 0.25,
        "project": "",
        "github": ""
    },
    {
        "id": "cLcLdwOfhoe",
        "title": "FedLite: A Scalable Approach for Federated Learning on Resource-constrained Clients",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;4;5;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "2;2;0;0",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.13245323570650439,
        "corr_rating_correctness": 0.6882472016116854,
        "project": "",
        "github": ""
    },
    {
        "id": "cMBKc-0OTY5",
        "title": "Kalman Filter Is All You Need: Optimization Works When Noise Estimation Fails",
        "track": "main",
        "status": "Reject",
        "keywords": "Kalman Filter;noise estimation;optimization;gradient descent;parameterization",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "3;2;4;4",
        "correctness": "3;1;3;3",
        "technical_novelty": "1;2;2;2",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8703882797784892,
        "corr_rating_correctness": 0.5555555555555555,
        "project": "",
        "github": ""
    },
    {
        "id": "cOtBRgsf2fO",
        "title": "Label Leakage and Protection in Two-party Split Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "Split Learning;label leakage;privacy;privacy protection",
        "author": "",
        "aff": "Carnegie Mellon University, ByteDance Inc.; Carnegie Mellon University; ByteDance Inc.",
        "rating": "6;6;8",
        "confidence": "2;3;4",
        "correctness": "3;4;3",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "4;3;3",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8660254037844385,
        "corr_rating_correctness": -0.49999999999999983,
        "project": "",
        "github": "https://github.com/OscarcarLi/label-protection"
    },
    {
        "id": "cU8rknuhxc",
        "title": "Learning more skills through optimistic exploration",
        "track": "main",
        "status": "Spotlight",
        "keywords": "intrinsic control;skill discovery;unsupervised skill learning;uncertainty estimation;optimistic exploration;variational information maximization",
        "author": "",
        "aff": "DeepMind",
        "rating": "6;8;8;8",
        "confidence": "4;5;3;5",
        "correctness": "3;4;3;4",
        "technical_novelty": "2;4;3;3",
        "empirical_novelty": "2;4;3;3",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 4.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.17407765595569782,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "cVak2hs06z",
        "title": "Correct-N-Contrast: a Contrastive Approach for Improving Robustness to Spurious Correlations",
        "track": "main",
        "status": "Reject",
        "keywords": "spurious correlations;contrastive learning;robustness;group shifts",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "4;4;4;4",
        "correctness": "2;3;4;4",
        "technical_novelty": "2;2;4;2",
        "empirical_novelty": "3;2;4;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9045340337332909,
        "project": "",
        "github": ""
    },
    {
        "id": "cWlMII1LwTZ",
        "title": "Task-aware Privacy Preservation for Multi-dimensional Data",
        "track": "main",
        "status": "Reject",
        "keywords": "Privacy;Representation Learning",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "5;3;4;3",
        "correctness": "2;3;3;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;0;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.899228803025897,
        "corr_rating_correctness": 0.9733285267845754,
        "project": "",
        "github": ""
    },
    {
        "id": "cZAi1yWpiXQ",
        "title": "Adversarial Robustness Through the Lens of Causality",
        "track": "main",
        "status": "Poster",
        "keywords": "Adversarial examples;Causality",
        "author": "",
        "aff": "",
        "rating": "6;8;8;8",
        "confidence": "4;3;4;3",
        "correctness": "3;3;4;4",
        "technical_novelty": "3;3;4;4",
        "empirical_novelty": "2;3;4;3",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.5,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "cav5FW0gy3C",
        "title": "Dataset Bias Prediction for Few-Shot Image Classification",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Machine Learning;Few-Shot Learning;Image Classification;Dataset Bias",
        "author": "",
        "aff": "",
        "rating": "1;3;5;6",
        "confidence": "5;2;3;5",
        "correctness": "2;1;3;4",
        "technical_novelty": "1;1;3;2",
        "empirical_novelty": "1;1;3;3",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 3.75,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.02505486760009429,
        "corr_rating_correctness": 0.7568892626614565,
        "project": "",
        "github": ""
    },
    {
        "id": "ccWaPGl9Hq",
        "title": "Towards Deployment-Efficient Reinforcement Learning: Lower Bound and Optimality",
        "track": "main",
        "status": "Spotlight",
        "keywords": "reinforcement learning theory;deployment efficiency;linear MDP",
        "author": "",
        "aff": "Microsoft Research Asia; Department of Computer Science, University of Illinois at Urbana-Champaign",
        "rating": "8;8;8;8",
        "confidence": "3;4;4;3",
        "correctness": "4;4;4;4",
        "technical_novelty": "4;3;3;3",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.5,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "cd2jyHoFa18",
        "title": "Learning Neural Processes on the Fly",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Neural Processes;Gaussian Processes;Uncertainty Quantification;Ensemble Methods;Meta-Learning",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;3;3;3",
        "correctness": "2;3;3;2",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "0;2;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "cdZLe5S0ur",
        "title": "AQUILA: Communication Efficient Federated Learning with Adaptive Quantization of Lazily-Aggregated Gradients",
        "track": "main",
        "status": "Reject",
        "keywords": "Federated Learning;communication efficiency;adaptive quantization",
        "author": "",
        "aff": "",
        "rating": "6;6;8",
        "confidence": "3;3;3",
        "correctness": "4;3;4",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "3;0;3",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.49999999999999983,
        "project": "",
        "github": ""
    },
    {
        "id": "cdwobSbmsjA",
        "title": "RAVE: A variational autoencoder for fast and high-quality neural audio synthesis",
        "track": "main",
        "status": "Reject",
        "keywords": "Variational Autoencoder;generative models;audio;music;deep learning;representation learning;latent space",
        "author": "",
        "aff": "",
        "rating": "3;5;8",
        "confidence": "4;3;4",
        "correctness": "2;3;3",
        "technical_novelty": "2;2;4",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.1147078669352809,
        "corr_rating_correctness": 0.8029550685469661,
        "project": "",
        "github": ""
    },
    {
        "id": "cggphp7nPuI",
        "title": "Reasoning-Modulated Representations",
        "track": "main",
        "status": "Reject",
        "keywords": "representation learning;algorithmic reasoning;graph neural networks;relational learning",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "4;4;4;3",
        "correctness": "4;3;4;4",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "3;2;3;2",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "ci7LBzDn2Q",
        "title": "Deep ReLU Networks Preserve Expected Length",
        "track": "main",
        "status": "Poster",
        "keywords": "deep learning theory;random ReLU networks;length distortion;initialization;expressivity",
        "author": "",
        "aff": "School of Computer Science, McGill University, Montr\u00b4eal, QC H3A 0G4 Canada; Dept. of Mathematics, University of Pennsylvania, Philadelphia, PA 19104 USA; Dept. of Operations Research & Financial Engineering, Princeton University, Princeton, NJ 08544 USA",
        "rating": "6;6;8;8",
        "confidence": "3;4;4;4",
        "correctness": "4;4;4;4",
        "technical_novelty": "3;2;4;3",
        "empirical_novelty": "0;3;2;0",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.75,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 1.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "ciSap6Cw5mk",
        "title": "MANDERA: Malicious Node Detection in Federated Learning via Ranking",
        "track": "main",
        "status": "Reject",
        "keywords": "Federated Learning;Data poisoning attack;Byzantine attack;Malicious node detection;Ranking",
        "author": "",
        "aff": "Affiliation of Author 1; Affiliation of Author 2",
        "rating": "3;6;8",
        "confidence": "3;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;3;2",
        "presentation": "",
        "rating_avg": 5.666666666666667,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "ciTmHV3Pt3v",
        "title": "Ripple Attention for Visual Perception with Sub-quadratic Complexity",
        "track": "main",
        "status": "Withdraw",
        "keywords": "attention mechanism;vision transformers;summed-area tables;stick-breaking transforms;dynamic programming",
        "author": "",
        "aff": "",
        "rating": "5;5;5",
        "confidence": "4;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "3;2;2",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "ckZY7DGa7FQ",
        "title": "A Fine-Tuning Approach to Belief State Modeling",
        "track": "main",
        "status": "Poster",
        "keywords": "imperfect-information;partial observability;search;decision-time planning",
        "author": "",
        "aff": "Meta AI; Oxford University; Carnegie Mellon University",
        "rating": "3;8;8;8",
        "confidence": "3;4;4;3",
        "correctness": "4;4;4;4",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "0;3;3;3",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 3.5,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "clwYez4n8e8",
        "title": "Logarithmic Unbiased Quantization: Practical 4-bit Training in Deep Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "quantization;efficient training;4 bit training",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "4;4;4;4",
        "correctness": "3;2;3;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "cmt-6KtR4c4",
        "title": "Leveraging Automated Unit Tests for Unsupervised Code Translation",
        "track": "main",
        "status": "Spotlight",
        "keywords": "unsupervised;translation;code;self-training;pseudo-labelling;unit tests;programming languages;deep learning;transformer",
        "author": "",
        "aff": "Facebook AI Research; Facebook AI Research, Paris-Dauphine University; University College London; Facebook",
        "rating": "5;6;8;8",
        "confidence": "4;3;4;4",
        "correctness": "4;1;4;3",
        "technical_novelty": "2;2;3;4",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.15713484026367722,
        "project": "",
        "github": ""
    },
    {
        "id": "coPc74qe9s",
        "title": "A Transferable General-Purpose Predictor for Neural Architecture Search",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Neural Architecture Search;Performance Estimation;Neural Predictor",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;5;3;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "3;3;3;2",
        "empirical_novelty": "3;3;2;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "coQhmtxr5SN",
        "title": "H-Entropy Search: Generalizing Bayesian Optimization with a Decision-theoretic Uncertainty Measure",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Bayesian optimization;entropy search;knowledge gradient;Bayesian optimal experimental design",
        "author": "",
        "aff": "",
        "rating": "3;3;6;6",
        "confidence": "3;4;4;4",
        "correctness": "4;3;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "0;3;3;4",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896258,
        "corr_rating_correctness": -0.5773502691896258,
        "project": "",
        "github": ""
    },
    {
        "id": "cpDhcsEDC2",
        "title": "FILIP: Fine-grained Interactive Language-Image Pre-Training",
        "track": "main",
        "status": "Poster",
        "keywords": "Visual-language pretraining;Language-Image Pretraining;Multi-modality model",
        "author": "",
        "aff": "Huawei Noah\u2019s Ark Lab, Hong Kong University of Science and Technology; Huawei Noah\u2019s Ark Lab; Sun Yat-sen University",
        "rating": "5;6;6;6",
        "confidence": "4;4;4;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;3;3;4",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "cpstx0xuvRY",
        "title": "Information-Theoretic Generalization Bounds for Iterative Semi-Supervised Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Generalization error;Information theory;Semi-supervised learning",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "5;3;3;4",
        "correctness": "3;4;3;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "1;2;2;2",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.17407765595569782,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "cqHeSMTkoBm",
        "title": "Learning Multi-Objective Curricula for Deep Reinforcement Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Curriculum Learning;Reinforcement learning;Hyper-network",
        "author": "",
        "aff": "",
        "rating": "3;5;6;8",
        "confidence": "4;3;4;2",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;0",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7526178090063818,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "crq5s3LLESc",
        "title": "On Label Shift in Domain Adaptation via Wasserstein Distance",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Label shift;optimal transport;Wasserstein distance;domain adaptation",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;3;4;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "3;3;2;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6882472016116854,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "cuGIoqAJf6p",
        "title": "Newer is not always better: Rethinking transferability metrics, their peculiarities, stability and performance",
        "track": "main",
        "status": "Reject",
        "keywords": "transferability metrics;fine-tuning;transfer learning;discrepancy measures;domain adaptation",
        "author": "",
        "aff": "",
        "rating": "5;5;8",
        "confidence": "3;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "2;3;4",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 1.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "cuvga_CiVND",
        "title": "No Parameters Left Behind: Sensitivity Guided Adaptive Learning Rate for Training Large Transformer Models",
        "track": "main",
        "status": "Poster",
        "keywords": "Training Large Transformer Models;Reducing Model Redundancy;Parameter Sensitivity;Adaptive Learning Rate Method;Model Generalization;Model Pruning",
        "author": "",
        "aff": "Georgia Institute of Technology; Microsoft Azure AI; Amazon; Microsoft Research",
        "rating": "6;6;6;8",
        "confidence": "3;4;4;4",
        "correctness": "4;3;4;3",
        "technical_novelty": "3;4;2;3",
        "empirical_novelty": "2;4;3;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": "https://github.com/cliang1453/SAGE"
    },
    {
        "id": "cw-EmNq5zfD",
        "title": "Group-based Interleaved Pipeline Parallelism for Large-scale DNN Training",
        "track": "main",
        "status": "Poster",
        "keywords": "Model parallelism;Pipeline parallelism;Distributed training",
        "author": "",
        "aff": "Ant Group, China",
        "rating": "3;6;8;8",
        "confidence": "3;4;4;4",
        "correctness": "3;4;4;3",
        "technical_novelty": "2;2;2;4",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9169493006161777,
        "corr_rating_correctness": 0.3665083330689157,
        "project": "",
        "github": ""
    },
    {
        "id": "czmQDWhGwd9",
        "title": "Representations of Computer Programs in the Human Brain",
        "track": "main",
        "status": "Reject",
        "keywords": "ML for PL/SE;ML models of code;Code representations;Brain representations;Cognitive neuroscience;Multivoxel pattern analysis;Representation decoding analysis;Representation similarity analysis;fMRI analysis",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5",
        "confidence": "5;4;3;4",
        "correctness": "3;4;3;3",
        "technical_novelty": "1;2;2;3",
        "empirical_novelty": "2;3;2;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/anonmyous-author/anonymous-code"
    },
    {
        "id": "d20jtFYzyxe",
        "title": "A Rate-Distortion Approach to Domain Generalization",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "5;3;4;5",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "3;2;1;2",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.20751433915982243,
        "corr_rating_correctness": 0.9271726499455306,
        "project": "",
        "github": ""
    },
    {
        "id": "d2TT6gK9qZn",
        "title": "Non-Linear Operator Approximations for Initial Value Problems",
        "track": "main",
        "status": "Poster",
        "keywords": "exponential operators;initial value problem;pade approximation;multiwavelets;partial differential equations",
        "author": "",
        "aff": "Department of Mathematics and the Norbert Wiener Center for Harmonic Analysis and Applications, University of Maryland, College Park, MD 20742, USA; Ming Hsieh Department of Electrical and Computer Engineering, University of Southern California, Los Angeles, CA 90089, USA",
        "rating": "3;5;6;8",
        "confidence": "4;4;4;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "1;3;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.8320502943378437,
        "project": "",
        "github": ""
    },
    {
        "id": "d2XZsOT-_U_",
        "title": "Match Prediction Using Learned History Embeddings",
        "track": "main",
        "status": "Reject",
        "keywords": "skill ranking;skill rating;skill",
        "author": "",
        "aff": "",
        "rating": "3;3;6",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "3;2;4",
        "empirical_novelty": "3;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "d5IQ3k7ed__",
        "title": "Finding General Equilibria in Many-Agent Economic Simulations using Deep Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "reinforcement learning;economics;simulation;multi-agent RL;equilibrium",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;3;3;3",
        "correctness": "2;3;4;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9271726499455306,
        "corr_rating_correctness": 0.6488856845230502,
        "project": "",
        "github": ""
    },
    {
        "id": "d5SCUJ5t1k",
        "title": "Objects in Semantic Topology",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "Beijing Institute of Technology; The University of Hong Kong; University of Technology Sydney; University of Sydney; ByteDance AI Lab",
        "rating": "5;5;8;8",
        "confidence": "3;3;4;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 1.0,
        "corr_rating_correctness": 0.5773502691896258,
        "project": "",
        "github": ""
    },
    {
        "id": "d7-GwtDWNNJ",
        "title": "Learning Graph Structure from Convolutional Mixtures",
        "track": "main",
        "status": "Reject",
        "keywords": "Graph Neural Network;Graph Signal Processing;Graph Learning;Topology Inference;Algorithm Unrolling",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "2;5;4;2",
        "correctness": "2;4;3;3",
        "technical_novelty": "2;3;3;4",
        "empirical_novelty": "2;2;3;4",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5555555555555555,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "d71n4ftoCBy",
        "title": "FedPara: Low-rank Hadamard Product for Communication-Efficient Federated Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "Federated learning;Parameterization;Communication efficiency",
        "author": "",
        "aff": "Department of Electrical Engineering, POSTECH; Department of Electrical Engineering, POSTECH; Graduate School of AI, POSTECH; Yonsei University",
        "rating": "6;6;6;8",
        "confidence": "2;4;4;2",
        "correctness": "4;3;3;3",
        "technical_novelty": "3;2;2;2",
        "empirical_novelty": "3;3;2;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": "https://github.com/South-hw/FedPara_ICLR22"
    },
    {
        "id": "dAFxBu5OAXh",
        "title": "Residual Contrastive Learning: Unsupervised Representation Learning from Residuals",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Self-Supervised Representation Learning;Residual Learning;Contrastive Learning",
        "author": "",
        "aff": "",
        "rating": "3;3;6",
        "confidence": "4;3;3",
        "correctness": "2;4;3",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "1;2;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "dDARN-TCiA",
        "title": "Stochastic Reweighted Gradient Descent",
        "track": "main",
        "status": "Reject",
        "keywords": "Stochastic gradient descent;Finite-sum optimization;Variance reduction;Importance sampling",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "4;3;4;4",
        "correctness": "4;3;4;4",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "2;3;3;2",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "dDjSKKA5TP1",
        "title": "Incremental False Negative Detection for Contrastive Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "Self-supervised learning;Contrastive learning;Representation learning;Clustering-based learning",
        "author": "",
        "aff": "National Taiwan University; Yonsei University; Waymo LLC; University of California, Merced; Google Research",
        "rating": "5;6;8",
        "confidence": "4;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "2;3;2",
        "empirical_novelty": "3;2;3",
        "presentation": "",
        "rating_avg": 6.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.7559289460184545,
        "project": "",
        "github": "https://github.com/tsaishien-chen/IFND"
    },
    {
        "id": "dDo8druYppX",
        "title": "Training Data Generating Networks: Shape Reconstruction via Bi-level Optimization",
        "track": "main",
        "status": "Poster",
        "keywords": "shape reconstruction single image;meta learning;few-shot learning;differentiable optimization;bi-level optimization",
        "author": "",
        "aff": "KAUST",
        "rating": "6;8;8",
        "confidence": "3;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 7.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9999999999999998,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "dEOeQgQTyvt",
        "title": "Structured Energy Network as a dynamic loss function. Case study. A case study with multi-label Classification",
        "track": "main",
        "status": "Reject",
        "keywords": "Structured Prediction;Energy network;Energy-based models;Loss-function learning;Dynamic loss function",
        "author": "",
        "aff": "",
        "rating": "3;6;6;6",
        "confidence": "4;4;3;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "dEelotBE6e2",
        "title": "Defending Against Backdoor Attacks Using Ensembles of Weak Learners",
        "track": "main",
        "status": "Reject",
        "keywords": "data poisoning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;8",
        "confidence": "4;4;3;3",
        "correctness": "2;3;3;4",
        "technical_novelty": "2;2;3;4",
        "empirical_novelty": "2;1;3;4",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8551861104941366,
        "corr_rating_correctness": 0.8638684255813602,
        "project": "",
        "github": ""
    },
    {
        "id": "dEwfxt14bca",
        "title": "When should agents explore?",
        "track": "main",
        "status": "Spotlight",
        "keywords": "exploration;mode-switching;reinforcement learning;Atari",
        "author": "",
        "aff": "DeepMind London, UK",
        "rating": "6;6;8;8",
        "confidence": "3;3;3;4",
        "correctness": "3;2;4;4",
        "technical_novelty": "4;3;3;3",
        "empirical_novelty": "4;3;3;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.9045340337332909,
        "project": "",
        "github": ""
    },
    {
        "id": "dFbKQaRk15w",
        "title": "Equivariant Subgraph Aggregation Networks",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Graph Neural Networks;Expressive power;Equivariance;Weisfeiler-Leman",
        "author": "",
        "aff": "Purdue University; UCSD CSE; University of Tuebingen; NVIDIA Research; MIT CSAIL; Imperial College London & Twitter",
        "rating": "6;6;8;8",
        "confidence": "4;4;4;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;3;4;4",
        "empirical_novelty": "1;2;3;2",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "dHJtoaE3yRP",
        "title": "NAFS: A Simple yet Tough-to-Beat Baseline for Graph Representation Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Feature Smoothing;Graph Neural Network;Graph Representation Learning",
        "author": "",
        "aff": "",
        "rating": "5;6;6",
        "confidence": "4;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;3;2",
        "presentation": "",
        "rating_avg": 5.666666666666667,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.4999999999999999,
        "project": "",
        "github": ""
    },
    {
        "id": "dHd6pU-8_fF",
        "title": "L-SR1 Adaptive Regularization by Cubics for Deep Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Non-convex optimization;deep learning;quasi-Newton methods;adaptive cubic regularization",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;4;4;4",
        "correctness": "2;2;2;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "1;3;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.0,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "dIVrWHP9_1i",
        "title": "G-Mixup: Graph Augmentation for Graph Classification",
        "track": "main",
        "status": "Reject",
        "keywords": "graph augmentation;mixup;graph classification;graphon",
        "author": "",
        "aff": "",
        "rating": "3;3;8",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "dJk1vpEFYF0",
        "title": "Personalized Federated Learning with Clustered Generalization",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Federated Learning;Personalization;Generalization;Clustering;Convergence",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "3;5;4;5",
        "correctness": "3;3;3;3",
        "technical_novelty": "3;3;3;2",
        "empirical_novelty": "3;2;2;2",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.899228803025897,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "dKLoUvtnq0C",
        "title": "Semi-supervised learning of partial differential operators and dynamical flows",
        "track": "main",
        "status": "Reject",
        "keywords": "Hypernetworks;Partial Differential Equations;Fluid Dynamics",
        "author": "",
        "aff": "",
        "rating": "5;5;8",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "dKVsqZOGOHL",
        "title": "How and When Adversarial Robustness Transfers in Knowledge Distillation?",
        "track": "main",
        "status": "Withdraw",
        "keywords": "adversarial robustness;knowledge distillation;adversarial training;vision transformer",
        "author": "",
        "aff": "",
        "rating": "3;5;6",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "0;2;3",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "dK_t8oN8G4",
        "title": "Neurosymbolic Deep Generative Models for Sequence Data with Relational Constraints",
        "track": "main",
        "status": "Reject",
        "keywords": "synthesis;music;generative;constraints",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "3;4;4;3",
        "correctness": "2;3;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;3;4",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9045340337332909,
        "project": "",
        "github": ""
    },
    {
        "id": "dLDzuxaN0Hd",
        "title": "Unsupervised Pose-Aware Part Decomposition for 3D Articulated Objects",
        "track": "main",
        "status": "Reject",
        "keywords": "unsupervised part decomposition;shape abstraction;3D shape representations;generative models;computer vision",
        "author": "",
        "aff": "",
        "rating": "5;5;8;8",
        "confidence": "4;4;2;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "4;3;3;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896258,
        "corr_rating_correctness": 0.5773502691896258,
        "project": "",
        "github": ""
    },
    {
        "id": "dLTXoSIcrik",
        "title": "Avoiding Overfitting to the Importance Weights in Offline Policy Optimization",
        "track": "main",
        "status": "Reject",
        "keywords": "Reinforcement Learning;Batch Reinforcement Learning;Policy Optimization;Overfitting",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "4;4;3;3",
        "correctness": "4;3;4;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "3;0;2;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "dNigytemkL",
        "title": "The Role of Permutation Invariance in Linear Mode Connectivity of Neural Networks",
        "track": "main",
        "status": "Poster",
        "keywords": "Permutation;Invariance;Mode Connectivity;Energy Barrier;Loss landscape;Deep Learning",
        "author": "",
        "aff": "TU Graz / CSH Vienna; Google Research, Blueshift Team; Google Research, Brain Team",
        "rating": "6;6;8;8",
        "confidence": "4;4;4;3",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "3;3;3;4",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": "https://github.com/rahimentezari/PermutationInvariance"
    },
    {
        "id": "dPyRNUlttBv",
        "title": "Optimization and Adaptive Generalization of Three layer Neural Networks",
        "track": "main",
        "status": "Poster",
        "keywords": "deep learning theory;adaptive kernel;robust deep learning;neural tangent kernel;adaptive generalization;non-convex optimization",
        "author": "",
        "aff": "MIT",
        "rating": "6;8;8;8",
        "confidence": "3;3;1;3",
        "correctness": "4;3;4;4",
        "technical_novelty": "4;4;4;3",
        "empirical_novelty": "0;1;0;0",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 2.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.75,
        "empirical_novelty_avg": 0.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "dQ7Cy_ndl1s",
        "title": "Controlling the Complexity and Lipschitz Constant improves Polynomial Nets",
        "track": "main",
        "status": "Poster",
        "keywords": "Polynomial Nets;Rademacher Complexity;Lipschitz constant;Coupled CP decomposition",
        "author": "",
        "aff": "EPFL, Switzerland",
        "rating": "5;5;6;8",
        "confidence": "3;3;3;3",
        "correctness": "3;4;4;4",
        "technical_novelty": "3;3;3;4",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.4714045207910316,
        "project": "",
        "github": ""
    },
    {
        "id": "dS3AxHZkrZT",
        "title": "You May Need both Good-GAN and Bad-GAN for Anomaly Detection",
        "track": "main",
        "status": "Reject",
        "keywords": "Anomaly Detection;GAN;Orthogonal Regularization;Bad-GAN",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;4;3;3",
        "correctness": "3;3;4;4",
        "technical_novelty": "3;3;2;3",
        "empirical_novelty": "2;2;2;4",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6882472016116854,
        "corr_rating_correctness": 0.6882472016116854,
        "project": "",
        "github": ""
    },
    {
        "id": "dSw0QtRMJkO",
        "title": "High Probability Bounds for a Class of Nonconvex Algorithms with AdaGrad Stepsize",
        "track": "main",
        "status": "Poster",
        "keywords": "adaptive methods;nonconvex optimization;stochastic optimization;high probability bounds",
        "author": "",
        "aff": "Technion; EPFL (LIONS)",
        "rating": "6;6;8",
        "confidence": "4;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "3;2;3",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9999999999999998,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "dTqOcTUOQO",
        "title": "Knowledge Removal in Sampling-based Bayesian Inference",
        "track": "main",
        "status": "Poster",
        "keywords": "Bayesian inference;Markov chain Monte Carlo;machine unlearning",
        "author": "",
        "aff": "JD Explore Academy, China; The University of Sydney, Australia",
        "rating": "3;8;8;8",
        "confidence": "3;2;2;3",
        "correctness": "4;4;4;4",
        "technical_novelty": "3;4;3;4",
        "empirical_novelty": "2;0;3;4",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 2.5,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 3.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/fshp971/mcmc-unlearning"
    },
    {
        "id": "dUHgnS1Tu13",
        "title": "Local-Global Shifting Vision Transformers",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Visual transformers",
        "author": "",
        "aff": "",
        "rating": "3;3;6",
        "confidence": "4;4;2",
        "correctness": "3;2;3",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "1;1;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.3333333333333333,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "dUV91uaXm3",
        "title": "Revisiting Over-smoothing in BERT from the Perspective of Graph",
        "track": "main",
        "status": "Spotlight",
        "keywords": "BERT;Over-smoothing;Transformer",
        "author": "",
        "aff": "The University of Hong Kong; Hong Kong University of Science and Technology; Sun Yat-sen University; Huawei Noah\u2019s Ark Lab",
        "rating": "6;6;8;8",
        "confidence": "3;3;4;3",
        "correctness": "4;3;4;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;4;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "dXPou9HkXcZ",
        "title": "Spatiotemporal Characterization of Gait from Monocular Videos with Transformers",
        "track": "main",
        "status": "Withdraw",
        "keywords": "human pose estimation;explainable AI;kinematics;gait;rehabilitation;activity recognition",
        "author": "",
        "aff": "Shirley Ryan AbilityLab, Department of Physical Medicine and Rehabilitation, Northwestern University; Shirley Ryan AbilityLab; Department of Neuroscience, Baylor College of Medicine",
        "rating": "3;3;3;3",
        "confidence": "4;4;5;4",
        "correctness": "3;4;2;2",
        "technical_novelty": "2;1;1;2",
        "empirical_novelty": "3;3;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 1.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "dYUdt59fJ0e",
        "title": "Yformer: U-Net Inspired Transformer Architecture for Far Horizon Time Series Forecasting",
        "track": "main",
        "status": "Reject",
        "keywords": "Time Series Forecasting;U-Net;Transformers",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;3;4;3",
        "correctness": "2;3;3;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "dZPgfwaTaXv",
        "title": "Relational Surrogate Loss Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences (ICT/CAS); SenseTime Research; University of Science and Technology of China; School of Computer Science, Faculty of Engineering, The University of Sydney; Huazhong University of Science and Technology",
        "rating": "6;8;8",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "4;4;4",
        "empirical_novelty": "4;4;3",
        "presentation": "",
        "rating_avg": 7.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 4.0,
        "empirical_novelty_avg": 3.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/hunto/ReLoss"
    },
    {
        "id": "dZTJQdXh3Gw",
        "title": "ImageNet as a Representative Basis for Deriving Generally Effective CNN Architectures",
        "track": "main",
        "status": "Withdraw",
        "keywords": "ImageNet;CNN design;dataset representativeness;empirical study",
        "author": "",
        "aff": "",
        "rating": "3;3;3;6",
        "confidence": "4;3;4;5",
        "correctness": "3;3;4;4",
        "technical_novelty": "3;2;1;2",
        "empirical_novelty": "2;3;0;2",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.816496580927726,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "dZ_4XPnNl56",
        "title": "Training Deep Spiking Neural Networks with Bio-plausible Learning Rules",
        "track": "main",
        "status": "Withdraw",
        "keywords": "spiking neural network;bio-plausible;deep learning;STDP",
        "author": "",
        "aff": "Under double-blind review",
        "rating": "3;5;5;5",
        "confidence": "4;3;4;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;2;2;1",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "d_2lcDh0Y9c",
        "title": "DriPP: Driven Point Processes to Model Stimuli Induced Patterns in M/EEG Signals",
        "track": "main",
        "status": "Poster",
        "keywords": "Electrophysiology;Neuroscience;Temporal point processes;Convolutional Dictionary Learning",
        "author": "",
        "aff": "Universit\u00e9 Paris-Saclay, Inria, CEA, Palaiseau, 91120, France",
        "rating": "3;6;8;8",
        "confidence": "3;4;4;4",
        "correctness": "2;3;4;3",
        "technical_novelty": "3;3;4;3",
        "empirical_novelty": "3;3;4;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9169493006161777,
        "corr_rating_correctness": 0.8638684255813602,
        "project": "",
        "github": ""
    },
    {
        "id": "daYoG2O4TtU",
        "title": "Adaptive Speech Duration Modification using a Deep-Generative Framework",
        "track": "main",
        "status": "Reject",
        "keywords": "Prosody;Encoder-Decoder;Attention;Adaptive Duration Modification;Dynamic Time Warping",
        "author": "",
        "aff": "",
        "rating": "1;3;3;6",
        "confidence": "4;4;2;4",
        "correctness": "2;2;4;3",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "1;2;2;3",
        "presentation": "",
        "rating_avg": 3.25,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.08084520834544431,
        "corr_rating_correctness": 0.37998029782867415,
        "project": "",
        "github": ""
    },
    {
        "id": "demdsohU_e",
        "title": "Neural Capacitance: A New Perspective of Neural Network Selection via Edge Dynamics",
        "track": "main",
        "status": "Reject",
        "keywords": "neural network selection;transfer learning;dynamical system;edge dynamics;network science",
        "author": "",
        "aff": "",
        "rating": "5;5;6",
        "confidence": "3;2;2",
        "correctness": "2;4;4",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "0;2;3",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4999999999999999,
        "corr_rating_correctness": 0.4999999999999999,
        "project": "",
        "github": ""
    },
    {
        "id": "dg79moSRqIo",
        "title": "One After Another: Learning Incremental Skills for a Changing World",
        "track": "main",
        "status": "Poster",
        "keywords": "Skill discovery;Incremental reinforcement learning",
        "author": "",
        "aff": "New York University",
        "rating": "6;6;6;6",
        "confidence": "5;3;4;4",
        "correctness": "4;4;3;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;3;2",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "https://notmahi.github.io/disk",
        "github": "https://github.com/notmahi/disk"
    },
    {
        "id": "dgxFTxuJ50e",
        "title": "Learnability of convolutional neural networks for infinite dimensional input via mixed and anisotropic smoothness",
        "track": "main",
        "status": "Spotlight",
        "keywords": "",
        "author": "",
        "aff": "Graduate School of Information Science and Technology, the University of Tokyo; Graduate School of Information Science and Technology, the University of Tokyo; RIKEN Center for Advanced Intelligence Project",
        "rating": "6;8;8;8",
        "confidence": "3;5;3;3",
        "correctness": "4;4;4;4",
        "technical_novelty": "3;4;4;4",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.5,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 3.75,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "dhLChxJwgMR",
        "title": "HFSP: A Hardware-friendly Soft Pruning Framework for Vision Transformers",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Vision Transformers;Hardware-friendly;Soft Token Pruning",
        "author": "",
        "aff": "",
        "rating": "3;5;5",
        "confidence": "4;3;4",
        "correctness": "2;3;3",
        "technical_novelty": "3;2;2",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 4.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.49999999999999983,
        "corr_rating_correctness": 0.9999999999999998,
        "project": "",
        "github": ""
    },
    {
        "id": "di0r7vfKrq5",
        "title": "Boosting Search Engines with Interactive Agents",
        "track": "main",
        "status": "Reject",
        "keywords": "query refinement;reinforcement learning;self-supervised learning;question answering;search engines;large language models",
        "author": "",
        "aff": "",
        "rating": "3;3;6",
        "confidence": "4;4;3",
        "correctness": "3;2;3",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "3;2;0",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "djZBr4Z7jcz",
        "title": "On the regularization landscape for the linear recommendation models",
        "track": "main",
        "status": "Reject",
        "keywords": "recommendation system;regularization;linear model",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "3;4;3;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "djhu4DIZZHR",
        "title": "NAIL: A Challenging Benchmark for Na\\\"ive Logical Reasoning",
        "track": "main",
        "status": "Reject",
        "keywords": "Logical Reasoning;Benchmark",
        "author": "",
        "aff": "",
        "rating": "3;5;6;8",
        "confidence": "5;3;4;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "1;3;3;3",
        "empirical_novelty": "1;2;2;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.39223227027636803,
        "corr_rating_correctness": 0.8006407690254357,
        "project": "",
        "github": ""
    },
    {
        "id": "djwnKXz1B2",
        "title": "EP-GAN: Unsupervised Federated Learning with Expectation-Propagation Prior GAN",
        "track": "main",
        "status": "Reject",
        "keywords": "Bayesian Deep learning;Expectation Propagation;Unsupervised Learning;Acoustic Modeling",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "2;3;4;3",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8660254037844386,
        "corr_rating_correctness": 0.9428090415820632,
        "project": "",
        "github": ""
    },
    {
        "id": "dmq_-R2LhQk",
        "title": "The Manifold Hypothesis for Gradient-Based Explanations",
        "track": "main",
        "status": "Reject",
        "keywords": "Interpretability;Explainability",
        "author": "",
        "aff": "",
        "rating": "3;3;3;6",
        "confidence": "5;5;4;3",
        "correctness": "2;3;1;3",
        "technical_novelty": "3;2;2;3",
        "empirical_novelty": "2;3;2;4",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 4.25,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8703882797784892,
        "corr_rating_correctness": 0.5222329678670935,
        "project": "",
        "github": ""
    },
    {
        "id": "dn4B7Mes2z",
        "title": "The Low-Rank Simplicity Bias in Deep Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "4;4;4;4",
        "correctness": "3;3;2;4",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "3;3;3;2",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "doGDvfnHCEj",
        "title": "On the Expressiveness, Predictability and Interpretability of Neural Temporal Point Processes",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "Under double-blind review",
        "rating": "1;3;3;5",
        "confidence": "5;4;5;3",
        "correctness": "1;2;2;3",
        "technical_novelty": "1;2;2;3",
        "empirical_novelty": "1;2;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.25,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8528028654224418,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "dpXL6lz4mOQ",
        "title": "LEARNING GUARANTEES FOR GRAPH CONVOLUTIONAL NETWORKS ON THE STOCHASTIC BLOCK MODEL",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "Department of Mathematics, Brandeis University, Waltham, MA 02453, USA",
        "rating": "5;5;6;8",
        "confidence": "4;3;3;3",
        "correctness": "3;2;3;3",
        "technical_novelty": "4;2;4;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4714045207910316,
        "corr_rating_correctness": 0.4714045207910316,
        "project": "",
        "github": ""
    },
    {
        "id": "drRnrGMZ3ze",
        "title": "Novel Policy Seeking with Constrained Optimization",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Novel Policy Discovery;Policy Diversity in Reinforcement Learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "3;3;3;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "3;2;3;2",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "drqmFn9fE9t",
        "title": "Self-Slimming Vision Transformer",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Vision transformer;efficient transformer",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "4;4;4;5",
        "correctness": "3;1;3;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 4.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 1.0,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "ds8yZOUsea",
        "title": "Hidden Parameter Recurrent State Space Models For Changing Dynamics Scenarios",
        "track": "main",
        "status": "Poster",
        "keywords": "State Space Models;Changing Dynamics;Recurrent Neural Networks;Multi Task Learning",
        "author": "",
        "aff": "Autonomous Learning Robots, KIT, Germany; LCAS, University Of Lincoln, UK; Indian Institute Of Technology, Kanpur; Max Planck Institute for Intelligent Systems, T\u00a8ubingen, Germany; Autonomous Learning Robots, KIT, Germany",
        "rating": "5;5;6;8",
        "confidence": "4;4;3;4",
        "correctness": "2;2;3;3",
        "technical_novelty": "1;2;3;2",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.8164965809277259,
        "project": "",
        "github": ""
    },
    {
        "id": "dtYnHcmQKeM",
        "title": "Physics-Informed Neural Operator for Learning Partial Differential Equations",
        "track": "main",
        "status": "Reject",
        "keywords": "Partial Differential Equations;operator learning;physics-informed;PINN;inverse problem;Navier-Stokes Equation",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "2;2;3;3",
        "correctness": "2;4;3;3",
        "technical_novelty": "1;3;3;2",
        "empirical_novelty": "1;3;3;2",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 2.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.6882472016116854,
        "corr_rating_correctness": 0.6488856845230502,
        "project": "",
        "github": ""
    },
    {
        "id": "dtpgsBPJJW",
        "title": "Riemannian Manifold Embeddings for Straight-Through Estimator",
        "track": "main",
        "status": "Reject",
        "keywords": "Neural network quantization;Riemannian manifold;Information geometry;Mirror descent",
        "author": "",
        "aff": "",
        "rating": "3;3;6;6",
        "confidence": "3;3;4;3",
        "correctness": "2;2;3;3",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896258,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "dtt435G80Ng",
        "title": "CSQ: Centered Symmetric Quantization for Extremely Low Bit Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "deep learning;classification;low precision;uniform symmetric quantization;binary neural network hardware",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;5;4;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;0;2;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "dut7suZoRqv",
        "title": "SparRL: Graph Sparsification via Deep Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "graph sparsification;graph theory;machine learning;reinforcement learning",
        "author": "",
        "aff": "",
        "rating": "3;3;3;6",
        "confidence": "4;4;4;4",
        "correctness": "3;2;4;4",
        "technical_novelty": "3;3;2;3",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5222329678670935,
        "project": "",
        "github": ""
    },
    {
        "id": "dvl241Sbrda",
        "title": "Unit Ball Model for Embedding Hierarchical Structures in the Complex Hyperbolic Space",
        "track": "main",
        "status": "Reject",
        "keywords": "Complex hyperbolic embeddings;hierarchical data embeddings;taxonomy embeddings",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "4;4;3;4",
        "correctness": "4;4;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "dwg5rXg1WS_",
        "title": "ViTGAN: Training GANs with Vision Transformers",
        "track": "main",
        "status": "Spotlight",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "6;6;6;6;8",
        "confidence": "4;4;4;4;5",
        "correctness": "4;4;3;3;4",
        "technical_novelty": "2;2;3;3;3",
        "empirical_novelty": "3;3;3;2;4",
        "presentation": "",
        "rating_avg": 6.4,
        "confidence_avg": 4.2,
        "correctness_avg": 3.6,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 1.0,
        "corr_rating_correctness": 0.408248290463863,
        "project": "",
        "github": ""
    },
    {
        "id": "dzZQEvQ6dRK",
        "title": "Disentangling Properties of Contrastive Methods",
        "track": "main",
        "status": "Reject",
        "keywords": "self-supervised learning;representation disentanglement",
        "author": "",
        "aff": "",
        "rating": "3;5;5;8",
        "confidence": "4;4;4;2",
        "correctness": "2;3;3;4",
        "technical_novelty": "2;1;4;3",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8892972917998875,
        "corr_rating_correctness": 0.9901475429766743,
        "project": "",
        "github": ""
    },
    {
        "id": "e-IkMkna5uJ",
        "title": "Spectral Bias in Practice: the Role of Function Frequency in Generalization",
        "track": "main",
        "status": "Reject",
        "keywords": "spectral bias;generalization;function frequency;image classification",
        "author": "",
        "aff": "",
        "rating": "3;3;8;8",
        "confidence": "4;4;4;5",
        "correctness": "3;3;3;2",
        "technical_novelty": "1;2;3;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "e-JV6H8lwpl",
        "title": "Subspace State-Space Identification and Model Predictive Control of Nonlinear Dynamical Systems Using Deep Neural Network with Bottleneck",
        "track": "main",
        "status": "Reject",
        "keywords": "System identification;Model predictive control;Subspace state-space system identification",
        "author": "",
        "aff": "",
        "rating": "3;5;6",
        "confidence": "5;3;2",
        "correctness": "1;3;4",
        "technical_novelty": "1;2;3",
        "empirical_novelty": "1;2;2",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "e0TRvNWsVIH",
        "title": "Learning Representation for Bayesian Optimization with Collision-free Regularization",
        "track": "main",
        "status": "Reject",
        "keywords": "Latent space;Bayesian Optimization;Collision",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;5;3;4",
        "correctness": "2;3;4;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7071067811865475,
        "corr_rating_correctness": 0.7071067811865475,
        "project": "",
        "github": ""
    },
    {
        "id": "e0jtGTfPihs",
        "title": "Signing the Supermask: Keep, Hide, Invert",
        "track": "main",
        "status": "Poster",
        "keywords": "Neural Networks;Supermask;Lottery Ticket Hypothesis;Pruning;Weight Initialization;Interpretation;Subnetworks",
        "author": "",
        "aff": "Department of Computational Linguistics and Digital Humanities, Trier University; Department of Applied Econometrics, Karlsruhe Institute of Technology; Department of Analytics and Statistics, Karlsruhe Institute of Technology",
        "rating": "5;5;6;8",
        "confidence": "4;4;4;5",
        "correctness": "3;2;3;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9428090415820632,
        "corr_rating_correctness": 0.4714045207910316,
        "project": "Not provided",
        "github": "Not provided"
    },
    {
        "id": "e0uknAgETh",
        "title": "Adversarial Attacks on Spiking Convolutional Networks for Event-based Vision",
        "track": "main",
        "status": "Reject",
        "keywords": "spiking neural networks;neuromorphic engineering;adversarial attacks;dynamic vision sensors",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5",
        "confidence": "5;2;4;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;3;2;2",
        "empirical_novelty": "3;3;2;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "e1GzwU4W2Kh",
        "title": "ConCoDE: Hard-constrained Differentiable Co-Exploration Method for Neural Architectures and Hardware Accelerators",
        "track": "main",
        "status": "Withdraw",
        "keywords": "accelerator;codesign;hard constraint;NAS",
        "author": "",
        "aff": "",
        "rating": "3;3;3;6",
        "confidence": "4;3;4;2",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "1;2;2;2",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8703882797784892,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "e2Lle5cij9D",
        "title": "Hidden Convexity of Wasserstein GANs: Interpretable Generative Models with Closed-Form Solutions",
        "track": "main",
        "status": "Poster",
        "keywords": "Wasserstein GAN;convex-concave game;saddle points;generative models;quadratic;polynomial activation;convex duality",
        "author": "",
        "aff": "Department of Electrical Engineering, Stanford University, Stanford, CA 94305, USA",
        "rating": "5;8;8;8",
        "confidence": "4;5;3;5",
        "correctness": "4;3;4;4",
        "technical_novelty": "2;4;3;3",
        "empirical_novelty": "2;4;3;3",
        "presentation": "",
        "rating_avg": 7.25,
        "confidence_avg": 4.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.17407765595569782,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": "https://github.com/ardasahiner/ProCoGAN"
    },
    {
        "id": "e42KbIw6Wb",
        "title": "Pix2seq: A Language Modeling Framework for Object Detection",
        "track": "main",
        "status": "Poster",
        "keywords": "language modeling;object detection",
        "author": "",
        "aff": "Google Research, Brain Team",
        "rating": "6;6;8;8;8",
        "confidence": "3;3;5;5;4",
        "correctness": "3;4;4;4;4",
        "technical_novelty": "2;3;4;4;4",
        "empirical_novelty": "3;2;2;2;4",
        "presentation": "",
        "rating_avg": 7.2,
        "confidence_avg": 4.0,
        "correctness_avg": 3.8,
        "technical_novelty_avg": 3.4,
        "empirical_novelty_avg": 2.6,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9128709291752769,
        "corr_rating_correctness": 0.6123724356957947,
        "project": "",
        "github": "https://github.com/google-research/pix2seq"
    },
    {
        "id": "e5S8XfS7iW-",
        "title": "Ontology-Driven Semantic Alignment of Artificial Neurons and Visual Concepts",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;4;3;5",
        "correctness": "3;4;3;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3244428422615251,
        "corr_rating_correctness": 0.13245323570650439,
        "project": "Not provided",
        "github": "Not provided"
    },
    {
        "id": "e6L5E8ig792",
        "title": "Revisiting Linear Decision Boundaries for Few-Shot Learning with Transformer Hypernetworks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Few-Shot Learning;Meta learning;Hypernetworks;Transformers",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "5;3;4;4",
        "correctness": "3;3;3;2",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "2;3;2;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.816496580927726,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "e6MVRAlKWGD",
        "title": "Cut the CARP: Fishing for zero-shot story evaluation",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Story Generation;Story Evaluation;Dataset;Storytelling;NLP;Evaluation;Contrastive learning;Language Models;Fine Tuning;Efficiency;Interactive Machine Learning;Narrative;Creativity;Human Centered AI;Creativity;Generative Models;World Models;Reader Models",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "3;3;4;4",
        "correctness": "2;2;3;2",
        "technical_novelty": "2;1;3;3",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 1.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "e6MWIbNeW1",
        "title": "Trading Quality for Efficiency of Graph Partitioning: An Inductive Method across Graphs",
        "track": "main",
        "status": "Reject",
        "keywords": "Graph Partitioning;Community Detection;Inductive Graph Embedding",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5;6;6",
        "confidence": "3;3;3;3;3;1",
        "correctness": "3;3;4;3;4;3",
        "technical_novelty": "2;3;3;3;3;3",
        "empirical_novelty": "2;2;3;3;3;3",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.8333333333333335,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4780914437337575,
        "corr_rating_correctness": 0.4724555912615341,
        "project": "",
        "github": ""
    },
    {
        "id": "e8JI3SBZKa4",
        "title": "Online approximate factorization of a kernel matrix by a Hebbian neural network",
        "track": "main",
        "status": "Reject",
        "keywords": "online kernel methods;hebbian learning;similarity matching",
        "author": "",
        "aff": "",
        "rating": "5;6;6;8",
        "confidence": "2;3;4;5",
        "correctness": "4;4;4;3",
        "technical_novelty": "2;2;3;4",
        "empirical_novelty": "2;2;3;4",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9233805168766388,
        "corr_rating_correctness": -0.9271726499455306,
        "project": "",
        "github": ""
    },
    {
        "id": "e95i1IHcWj",
        "title": "Equivariant and Stable Positional Encoding for More Powerful Graph Neural Networks",
        "track": "main",
        "status": "Poster",
        "keywords": "Graph Neural Network;Spectral Graph Theory;System Stability",
        "author": "",
        "aff": "School of Computer Science, Wuhan University; Institute for Arti\ufb01cial Intelligence, Peking University & BIGAI; Department of Computer Science, Purdue University",
        "rating": "6;6;6;8;8",
        "confidence": "4;4;5;4;3",
        "correctness": "3;3;1;4;4",
        "technical_novelty": "3;3;3;3;3",
        "empirical_novelty": "2;3;1;2;3",
        "presentation": "",
        "rating_avg": 6.8,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.2,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6454972243679028,
        "corr_rating_correctness": 0.74535599249993,
        "project": "",
        "github": "https://github.com/Graph-COM/PEG"
    },
    {
        "id": "eAEcdRkcMHh",
        "title": "HoloFormer: Deep Compression of Pre-Trained Transforms via Unified Optimization of N:M Sparsity and Integer Quantization",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Efficient Inference;N:M Sparsification;Quantization;Transformer networks",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5;5",
        "confidence": "5;3;3;3;4",
        "correctness": "3;3;2;3;3",
        "technical_novelty": "3;2;2;2;2",
        "empirical_novelty": "3;3;2;3;2",
        "presentation": "",
        "rating_avg": 4.6,
        "confidence_avg": 3.6,
        "correctness_avg": 2.8,
        "technical_novelty_avg": 2.2,
        "empirical_novelty_avg": 2.6,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8750000000000001,
        "corr_rating_correctness": -0.25000000000000006,
        "project": "",
        "github": ""
    },
    {
        "id": "eBCmOocUejf",
        "title": "On Robust Prefix-Tuning for Text Classification",
        "track": "main",
        "status": "Poster",
        "keywords": "prefix-tuning;pretrained language models;text classification;robustness in NLP;optimal control",
        "author": "",
        "aff": "Department of Computer Science and Technology, Institute for AI Industry Research, Institute for Artificial Intelligence, Tsinghua University, Beijing, 100084, China",
        "rating": "6;6;6;6",
        "confidence": "2;4;3;3",
        "correctness": "4;2;3;3",
        "technical_novelty": "4;3;3;3",
        "empirical_novelty": "4;3;3;4",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/minicheshire/Robust-Prefix-Tuning"
    },
    {
        "id": "eBS-3YiaIL-",
        "title": "Analyzing and Improving the Optimization Landscape of Noise-Contrastive Estimation",
        "track": "main",
        "status": "Spotlight",
        "keywords": "noise contrastive estimation;contrastive learning;unsupervised learning;theory",
        "author": "",
        "aff": "Machine Learning Department, Carnegie Mellon University",
        "rating": "6;6;8;8",
        "confidence": "3;4;3;2",
        "correctness": "3;4;4;4",
        "technical_novelty": "2;3;4;4",
        "empirical_novelty": "2;3;0;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7071067811865475,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "eBZsAZB8Rfh",
        "title": "Adaptive Unbiased Teacher for Cross-Domain Object Detection",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;6",
        "confidence": "5;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "2;2;1",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4999999999999999,
        "corr_rating_correctness": -0.4999999999999999,
        "project": "",
        "github": ""
    },
    {
        "id": "eCPCn25gat",
        "title": "Pretraining for Language Conditioned Imitation with Transformers",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "4;4;4;3",
        "correctness": "2;3;3;3",
        "technical_novelty": "1;2;2;3",
        "empirical_novelty": "1;2;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7777777777777777,
        "corr_rating_correctness": 0.5555555555555555,
        "project": "",
        "github": ""
    },
    {
        "id": "eDjxhFbaWX",
        "title": "HODA: Protecting DNNs Against Model Extraction Attacks via Hardness of Samples",
        "track": "main",
        "status": "Reject",
        "keywords": "Trustworthy Machine Learning;Model Extraction Attacks;Hardness of Samples",
        "author": "",
        "aff": "Paper under double-blind review",
        "rating": "1;3;5;6",
        "confidence": "4;4;4;4",
        "correctness": "1;3;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;3;3;2",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 4.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.8268106308031117,
        "project": "",
        "github": ""
    },
    {
        "id": "eELR-4Dk4U8",
        "title": "Model-based Reinforcement Learning with a Hamiltonian Canonical ODE Network",
        "track": "main",
        "status": "Reject",
        "keywords": "Reinforcement learning;Hamiltonian canonical equation;ODE;World model;Sample efficiency",
        "author": "",
        "aff": "",
        "rating": "3;3;3",
        "confidence": "4;3;5",
        "correctness": "2;2;2",
        "technical_novelty": "1;2;1",
        "empirical_novelty": "2;2;1",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 1.3333333333333333,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "eENsxDifOGu",
        "title": "Assessing and Developing Text-Based Agents for Morally Salient Scenarios",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Transformers;RL;data bias;reward bias;machine ethics;value learning;safe exploration",
        "author": "Dan Hendrycks, Mantas Mazeika, Andy Zou, Sahil Patel, Christine Zhu, Jesus Navarro, Dawn Song, Bo Li, Jacob Steinhardt",
        "aff": "",
        "rating": "",
        "confidence": "",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "eFP90pzlIz",
        "title": "Towards Achieving Adversarial Robustness Beyond Perceptual Limits",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Adversarial Robustness;Adversarial Defense;Adversarial Training",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "4;4;4;4",
        "correctness": "3;3;2;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.2721655269759087,
        "project": "",
        "github": ""
    },
    {
        "id": "eGd34W56KIT",
        "title": "SPARK: co-exploring model SPArsity and low-RanKness for compact neural networks",
        "track": "main",
        "status": "Reject",
        "keywords": "model compression;low-rankness;sparsity;tensor",
        "author": "",
        "aff": "",
        "rating": "3;6;6;8",
        "confidence": "5;3;3;3",
        "correctness": "3;4;4;4",
        "technical_novelty": "3;3;2;4",
        "empirical_novelty": "2;3;3;4",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8892972917998875,
        "corr_rating_correctness": 0.8892972917998875,
        "project": "",
        "github": ""
    },
    {
        "id": "eH8Jie3uiI",
        "title": "Vote for Nearest Neighbors Meta-Pruning of Self-Supervised Networks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "network pruning;meta pruning;self-supervision;multi-task pruning",
        "author": "",
        "aff": "N/A",
        "rating": "3;5;5;5",
        "confidence": "3;4;4;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "3;2;2;2",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 1.0,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "eIvzaLx6nKW",
        "title": "Multi-Domain Self-Supervised Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "self-supervised learning;contrastive learning;multi-domain data;unsupervised learning",
        "author": "",
        "aff": "",
        "rating": "5;6;6",
        "confidence": "4;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "3;2;3",
        "presentation": "",
        "rating_avg": 5.666666666666667,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.4999999999999999,
        "project": "",
        "github": ""
    },
    {
        "id": "eJyt4hJzOLk",
        "title": "Discrepancy-Optimal Meta-Learning for Domain Generalization",
        "track": "main",
        "status": "Reject",
        "keywords": "Domain generalization Meta-learning Transfer learning Generalization Bound",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "5;4;3;2",
        "correctness": "2;2;3;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9233805168766388,
        "corr_rating_correctness": 0.7608859102526822,
        "project": "",
        "github": ""
    },
    {
        "id": "eMudnJsb1T5",
        "title": "Sampling with Mirrored Stein Operators",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Stein's method;Sampling;Mirror descent;Natural gradient descent;Probabilistic inference;Bayesian inference;Post-selection inference;Stein operators",
        "author": "",
        "aff": "Microsoft Research Asia; Microsoft Research New England",
        "rating": "6;8;8;10",
        "confidence": "4;3;3;3",
        "correctness": "3;4;3;4",
        "technical_novelty": "4;3;3;3",
        "empirical_novelty": "4;3;3;3",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.816496580927726,
        "corr_rating_correctness": 0.7071067811865476,
        "project": "",
        "github": ""
    },
    {
        "id": "eOdSD0B5TE",
        "title": "On the Implicit Biases of Architecture & Gradient Descent",
        "track": "main",
        "status": "Reject",
        "keywords": "generalisation;function space;PAC-Bayes;NNGP;orthants;margin",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "3;3;3;2",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;1;2;2",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 2.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "ePI0bPbrih",
        "title": "Boundary Graph Neural Networks for 3D Simulations",
        "track": "main",
        "status": "Reject",
        "keywords": "Simulation;Graph Neural Network;Boundary Conditions;Granular Flow;Physics Application",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "4;3;4;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;0;2;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "eR5TdQpRMCP",
        "title": "General Incremental Learning with Domain-aware Categorical Representations",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Incremental learning;Domain-aware;EM algorithm",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "5;4;4;4",
        "correctness": "3;3;2;1",
        "technical_novelty": "3;2;2;1",
        "empirical_novelty": "3;2;2;2",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 4.25,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": -0.8703882797784891,
        "project": "",
        "github": ""
    },
    {
        "id": "eSHBmLnD1s8",
        "title": "Task Conditioned Stochastic Subsampling",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5;8",
        "confidence": "3;5;3;3",
        "correctness": "2;1;2;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "0;4;2;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.5,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.08084520834544431,
        "corr_rating_correctness": 0.5940885257860046,
        "project": "",
        "github": ""
    },
    {
        "id": "eV5d4I3eso",
        "title": "Geometric Random Walk Graph Neural Networks via Implicit Layers",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5",
        "confidence": "4;5;4;4",
        "correctness": "3;2;4;4",
        "technical_novelty": "3;2;3;2",
        "empirical_novelty": "2;0;2;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "eVzy-BWKY6Z",
        "title": "Edge Rewiring Goes Neural: Boosting Network Resilience via Policy Gradient",
        "track": "main",
        "status": "Reject",
        "keywords": "network resilience;neural combinatorial optimization;graph neural networks;reinforcement learning",
        "author": "",
        "aff": "",
        "rating": "3;3;6",
        "confidence": "5;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "2;1;3",
        "empirical_novelty": "2;1;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5000000000000001,
        "corr_rating_correctness": -0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "eW5R4Cek6y6",
        "title": "On Predicting Generalization using GANs",
        "track": "main",
        "status": "Spotlight",
        "keywords": "generalization;generative adversarial network",
        "author": "",
        "aff": "Princeton University, Computer Science Department",
        "rating": "5;8;8;8",
        "confidence": "4;4;4;3",
        "correctness": "3;4;4;4",
        "technical_novelty": "3;3;3;4",
        "empirical_novelty": "3;3;4;4",
        "presentation": "",
        "rating_avg": 7.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "eWNpRVcfzi",
        "title": "MURO: Deployment Constrained Reinforcement Learning with Model-based Uncertainty Regularized Batch Optimization",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Deployment Constrained Reinforcement Learning;Deep Reinforcement Learning;Model-based Reinforcement Learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "5;4;4;3",
        "correctness": "2;3;3;4",
        "technical_novelty": "1;2;3;2",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.816496580927726,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "eYciPrLuUhG",
        "title": "Efficient Neural Causal Discovery without Acyclicity Constraints",
        "track": "main",
        "status": "Poster",
        "keywords": "Causal discovery;structure learning",
        "author": "",
        "aff": "University of Amsterdam, QUV A lab; Qualcomm AI Research\u2217",
        "rating": "5;6;6;6;8",
        "confidence": "3;3;4;4;3",
        "correctness": "3;3;3;3;3",
        "technical_novelty": "2;3;3;3;3",
        "empirical_novelty": "2;3;2;4;3",
        "presentation": "",
        "rating_avg": 6.2,
        "confidence_avg": 3.4,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.8,
        "empirical_novelty_avg": 2.8,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.16666666666666663,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "eYyvftCgtD",
        "title": "GroupBERT: Enhanced Transformer Architecture with Efficient Grouped Structures",
        "track": "main",
        "status": "Reject",
        "keywords": "Transformer;BERT;self-supervision;compute efficiency;sparsity;convolution;natural language processing",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "5;4;4;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;1;2;2",
        "empirical_novelty": "2;1;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7071067811865475,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "eZ-xMLuKPc",
        "title": "Surgical Prediction with Interpretable Latent Representation",
        "track": "main",
        "status": "Reject",
        "keywords": "machine learning;healthcare applications;latent encoding;surgical predictions",
        "author": "",
        "aff": "",
        "rating": "3;5;6",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "2;3;2",
        "empirical_novelty": "1;0;3",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 1.3333333333333333,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.18898223650461363,
        "project": "",
        "github": ""
    },
    {
        "id": "e_D6AmszH4P",
        "title": "ViViT: Curvature access through the generalized Gauss-Newton's low-rank structure",
        "track": "main",
        "status": "Reject",
        "keywords": "generalized Gauss-Newton;curvature;second-order methods;Hessian spectrum in deep learning;automatic differentiation",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "4;2;4;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;2;1;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "e_FK_rDajEv",
        "title": "Learning Neural Causal Models with Active Interventions",
        "track": "main",
        "status": "Reject",
        "keywords": "neural causal discovery;causal structure learning;active learning;experimental design",
        "author": "",
        "aff": "",
        "rating": "3;5;5",
        "confidence": "2;4;4",
        "correctness": "2;3;3",
        "technical_novelty": "2;3;2",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 4.333333333333333,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 1.0,
        "corr_rating_correctness": 0.9999999999999998,
        "project": "",
        "github": ""
    },
    {
        "id": "ebZ0gGRJwQx",
        "title": "On the Convergence of Shallow Neural Network Training with Randomly Masked Neurons",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "3;4;3;4",
        "correctness": "3;2;3;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "1;3;0;0",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 1.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "ebl1ssKFHBb",
        "title": "Differentiable Discrete Device-to-System Codesign for Optical Neural Networks via Gumbel-Softmax",
        "track": "main",
        "status": "Withdraw",
        "keywords": "hardware-software codesign;optical neural network;regularization",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "2;4;4;4",
        "correctness": "4;3;3;3",
        "technical_novelty": "3;2;2;3",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "ecH2FKaARUp",
        "title": "An Information Fusion Approach to Learning with Instance-Dependent Label Noise",
        "track": "main",
        "status": "Poster",
        "keywords": "Instance-dependent label noise;posterior transition matrix;statiscally consistent classifier",
        "author": "",
        "aff": "Samsung Electronics; Texas A&M University; Rice University; Samsung Research America",
        "rating": "5;5;5;8",
        "confidence": "4;2;4;5",
        "correctness": "2;3;3;4",
        "technical_novelty": "3;3;4;3",
        "empirical_novelty": "2;3;4;2",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.662266178532522,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "edN_G_4njyi",
        "title": "On the Impact of Client Sampling on Federated Learning Convergence",
        "track": "main",
        "status": "Reject",
        "keywords": "Federated learning;client sampling;bias;convergence rate;distributed optimization;data heterogeneity",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5;6",
        "confidence": "3;4;4;3;5",
        "correctness": "4;4;4;3;4",
        "technical_novelty": "2;2;3;3;3",
        "empirical_novelty": "2;2;2;3;2",
        "presentation": "",
        "rating_avg": 4.4,
        "confidence_avg": 3.8,
        "correctness_avg": 3.8,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 2.2,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5345224838248488,
        "corr_rating_correctness": -0.24999999999999994,
        "project": "",
        "github": ""
    },
    {
        "id": "edONMAnhLu-",
        "title": "Surrogate Gap Minimization Improves Sharpness-Aware Training",
        "track": "main",
        "status": "Poster",
        "keywords": "generalization;sharpness-aware minimization;surrogate gap;deep learning",
        "author": "",
        "aff": "Yale University; Google Research",
        "rating": "6;6;6;8",
        "confidence": "4;4;3;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://sites.google.com/view/gsam-iclr22/home"
    },
    {
        "id": "edqz84cQ79T",
        "title": "Shaping latent representations using Self-Organizing Maps with Relevance Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Deep Clustering;Learning Prototypes;Topological Representations",
        "author": "",
        "aff": "",
        "rating": "1;3;3",
        "confidence": "4;5;3",
        "correctness": "2;2;3",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "0;2;2",
        "presentation": "",
        "rating_avg": 2.3333333333333335,
        "confidence_avg": 4.0,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 1.3333333333333333,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "ef0nInZHKIC",
        "title": "Symbolic Learning to Optimize: Towards Interpretability and Scalability",
        "track": "main",
        "status": "Poster",
        "keywords": "Symbolic Regression;Learning To Optimize;Interpretability",
        "author": "",
        "aff": "Texas A&M University; The University of Texas at Austin",
        "rating": "5;6;6;6;6",
        "confidence": "4;3;4;4;4",
        "correctness": "2;3;3;2;3",
        "technical_novelty": "2;3;3;3;3",
        "empirical_novelty": "1;3;2;2;3",
        "presentation": "",
        "rating_avg": 5.8,
        "confidence_avg": 3.8,
        "correctness_avg": 2.6,
        "technical_novelty_avg": 2.8,
        "empirical_novelty_avg": 2.2,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.2500000000000001,
        "corr_rating_correctness": 0.6123724356957948,
        "project": "",
        "github": "https://github.com/VITA-Group/Symbolic-Learning-To-Optimize"
    },
    {
        "id": "egkbgeGcGtj",
        "title": "Multi-dataset Pretraining: A Unified Model for Semantic Segmentation",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Multi-dataset;semantic segmentation;contrastive learning",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "5;4;4;4",
        "correctness": "2;3;2;4",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9271726499455306,
        "corr_rating_correctness": 0.7608859102526822,
        "project": "",
        "github": ""
    },
    {
        "id": "ei3SY1_zYsE",
        "title": "Fortuitous Forgetting in Connectionist Networks",
        "track": "main",
        "status": "Poster",
        "keywords": "Neural Networks;Generalization;Iterative Training;Compositionality;Iterated Learning",
        "author": "",
        "aff": "Mila, Universit\u00e9 de Montr\u00e9al; Mila, Universit\u00e9 de Montr\u00e9al, CIFAR Fellow; Mila, CIFAR Fellow, Google Research, Brain Team",
        "rating": "6;6;6;10",
        "confidence": "3;4;4;4",
        "correctness": "3;2;3;4",
        "technical_novelty": "3;3;2;3",
        "empirical_novelty": "3;2;2;4",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "eiwpbi3iwr",
        "title": "Neuronal Learning Analysis using Cycle-Consistent Adversarial Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "neuronal learning;unsupervised learning;calcium imaging;generative adversarial networks;cycle-consistent adversarial networks;explainable AI",
        "author": "",
        "aff": "",
        "rating": "5;5;6",
        "confidence": "3;3;5",
        "correctness": "3;4;3",
        "technical_novelty": "2;3;1",
        "empirical_novelty": "3;2;3",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 1.0,
        "corr_rating_correctness": -0.4999999999999999,
        "project": "",
        "github": ""
    },
    {
        "id": "ejFdNNTSq1",
        "title": "Analyzing the Implicit Position Encoding Ability of Transformer Decoder",
        "track": "main",
        "status": "Withdraw",
        "keywords": "NLP;Transformer;BERT;Position Encodings",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;4;4;3",
        "correctness": "2;2;3;2",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.75,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "ek9a0qIafW",
        "title": "Differentiable Prompt Makes Pre-trained Language Models Better Few-shot Learners",
        "track": "main",
        "status": "Poster",
        "keywords": "prompt-tuning;pre-trained language model;few-shot learning",
        "author": "",
        "aff": "Alibaba Group; College of Computer Science and Technology, Zhejiang University; School of Software Technology, Zhejiang University; Alibaba-Zhejiang University Joint Research Institute of Frontier Technologies; College of Computer Science and Technology, Zhejiang University; Alibaba-Zhejiang University Joint Research Institute of Frontier Technologies; College of Computer Science and Technology, Zhejiang University; Alibaba-Zhejiang University Joint Research Institute of Frontier Technologies; Hangzhou Innovation Center, Zhejiang University; School of Software Technology, Zhejiang University; Alibaba-Zhejiang University Joint Research Institute of Frontier Technologies",
        "rating": "6;6;8;8",
        "confidence": "4;4;3;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "3;3;3;4",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": "https://github.com/zjunlp/DART"
    },
    {
        "id": "eo1barn2Xmd",
        "title": "SLIM-QN: A Stochastic, Light, Momentumized Quasi-Newton Optimizer for Deep Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "Second-Order Methods;Stochastic Optimization;Deep Neural Networks",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5;6",
        "confidence": "4;4;4;3;3",
        "correctness": "3;2;3;4;4",
        "technical_novelty": "2;2;2;2;3",
        "empirical_novelty": "2;3;3;2;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.2,
        "empirical_novelty_avg": 2.6,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9682458365518543,
        "corr_rating_correctness": 0.8451542547285165,
        "project": "",
        "github": ""
    },
    {
        "id": "eoShjXqWkr",
        "title": "STransGAN: An Empirical Study on Transformer in GANs",
        "track": "main",
        "status": "Withdraw",
        "keywords": "GAN;Transformer;generative models",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "3;5;4;5",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.899228803025897,
        "corr_rating_correctness": 0.9271726499455306,
        "project": "",
        "github": ""
    },
    {
        "id": "eqNpg2HMNi1",
        "title": "Physical System Design Using Hamiltonian Monte Carlo over Learned Manifolds",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Physical Design;Mechanical Design;Generative Modeling;Hamiltonian Monte Carlo",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "5;3;3;3",
        "correctness": "3;2;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "eqRTPB134q0",
        "title": "Invariance in Policy Optimisation and Partial Identifiability in Reward Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;8;8",
        "confidence": "4;1;4;4",
        "correctness": "4;2;4;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896258,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "eqaxDZg4MHw",
        "title": "Understanding the Generalization Gap in Visual Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Visual Reinforcement Learning;Transfer in Reinforcement Learning;Generalization in Reinforcement Learning",
        "author": "",
        "aff": "",
        "rating": "3;3;3;6",
        "confidence": "4;4;5;3",
        "correctness": "2;2;3;2",
        "technical_novelty": "1;1;2;2",
        "empirical_novelty": "1;2;3;2",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 4.0,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 1.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.816496580927726,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "euAlnAcpQtv",
        "title": "Federated Contrastive Learning for Privacy-Preserving Unpaired Image-to-Image Translation",
        "track": "main",
        "status": "Withdraw",
        "keywords": "image-to-image translation;contrastive learning;federated learning",
        "author": "",
        "aff": "",
        "rating": "3;3;6",
        "confidence": "5;4;4",
        "correctness": "2;3;3",
        "technical_novelty": "1;2;3",
        "empirical_novelty": "1;2;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5,
        "corr_rating_correctness": 0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "eubJ4rgnN3",
        "title": "OUT-OF-DISTRIBUTION CLASSIFICATION WITH ADAPTIVE LEARNING OF LOW-LEVEL CONTEXTUAL FEATURES",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Out-of-Distribution;Adaptive Learning;Contextual Features",
        "author": "",
        "aff": "",
        "rating": "1;1;3;3",
        "confidence": "4;4;4;3",
        "correctness": "3;1;4;2",
        "technical_novelty": "1;1;2;2",
        "empirical_novelty": "1;2;2;3",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 1.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.4472135954999579,
        "project": "",
        "github": ""
    },
    {
        "id": "eypsJ0rvAqo",
        "title": "1-bit LAMB: Communication Efficient Large-Scale Large-Batch Training with LAMB's Convergence Speed",
        "track": "main",
        "status": "Reject",
        "keywords": "optimization;communication compression;natural language processing;language model pre-training",
        "author": "",
        "aff": "",
        "rating": "5;5;6",
        "confidence": "4;3;3",
        "correctness": "4;3;4",
        "technical_novelty": "2;3;2",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4999999999999999,
        "corr_rating_correctness": 0.4999999999999999,
        "project": "",
        "github": ""
    },
    {
        "id": "ezbMFmQY7L",
        "title": "C5T5: Controllable Generation of Organic Molecules with Transformers",
        "track": "main",
        "status": "Reject",
        "keywords": "molecular modeling;sequence modeling;conditional sequence modeling;drug discovery",
        "author": "",
        "aff": "",
        "rating": "3;5;5",
        "confidence": "4;4;3",
        "correctness": "2;3;4",
        "technical_novelty": "3;3;2",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 4.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.49999999999999983,
        "corr_rating_correctness": 0.8660254037844385,
        "project": "",
        "github": ""
    },
    {
        "id": "f-KGT01Qze0",
        "title": "Robustmix: Improving Robustness by Regularizing the Frequency Bias of Deep Nets",
        "track": "main",
        "status": "Reject",
        "keywords": "robustness;imagenet-c;mixup",
        "author": "",
        "aff": "",
        "rating": "3;5;5",
        "confidence": "5;3;4",
        "correctness": "4;2;3",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "3;2;2",
        "presentation": "",
        "rating_avg": 4.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8660254037844385,
        "corr_rating_correctness": -0.8660254037844385,
        "project": "",
        "github": ""
    },
    {
        "id": "f-LuEgBQUg",
        "title": "Language-Driven Image Style Transfer",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Artistic Style Transfer;Language-based Image Editing",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;5;5;4",
        "correctness": "4;2;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "https://ai-sub.github.io/ldist/",
        "github": ""
    },
    {
        "id": "f2K6ofowQoq",
        "title": "Efficient Second-Order Optimization for Deep Learning with Kernel Machines",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Second-order optimization;Deep learning;Kernel machines",
        "author": "",
        "aff": "",
        "rating": "3;3;3;6",
        "confidence": "4;4;2;2",
        "correctness": "1;2;2;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "0;2;2;3",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 3.0,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "f2OYVDyfIB",
        "title": "Scale Efficiently: Insights from Pretraining and Finetuning Transformers",
        "track": "main",
        "status": "Poster",
        "keywords": "transformers;attention;deep learning",
        "author": "",
        "aff": "Google Research & DeepMind; Google Research",
        "rating": "5;6;6;8",
        "confidence": "4;4;3;4",
        "correctness": "3;4;3;4",
        "technical_novelty": "2;3;2;1",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.13245323570650439,
        "corr_rating_correctness": 0.6882472016116854,
        "project": "",
        "github": ""
    },
    {
        "id": "f2lrIbGx3x7",
        "title": "Bayesian Framework for Gradient Leakage",
        "track": "main",
        "status": "Poster",
        "keywords": "federated learning;privacy;gradient leakage",
        "author": "",
        "aff": "Department of Computer Science, ETH Zurich",
        "rating": "6;6;6;8",
        "confidence": "4;2;5;5",
        "correctness": "3;4;3;4",
        "technical_novelty": "3;3;2;3",
        "empirical_novelty": "1;2;2;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.4714045207910316,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "f2zGmcA0bs7",
        "title": "Routing with Self-Attention for Multimodal Capsule Networks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "multimodal;capsule networks;self-supervision;computer vision;self-attention;routing",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "3;4;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "0;3;0;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 1.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "f3QTgKQW0TD",
        "title": "Manifold Distance Judge, an Adversarial Samples Defense Strategy Based on Service Orchestration",
        "track": "main",
        "status": "Reject",
        "keywords": "service orchestration;manifold distance detection;adversarial example;neural network.",
        "author": "",
        "aff": "",
        "rating": "1;1;3;5",
        "confidence": "5;4;4;4",
        "correctness": "2;2;2;3",
        "technical_novelty": "1;1;2;2",
        "empirical_novelty": "2;1;0;2",
        "presentation": "",
        "rating_avg": 2.5,
        "confidence_avg": 4.25,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 1.5,
        "empirical_novelty_avg": 1.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5222329678670935,
        "corr_rating_correctness": 0.8703882797784891,
        "project": "",
        "github": ""
    },
    {
        "id": "f3qFAV_MH-C",
        "title": "Transfer and Marginalize: Explaining Away Label Noise with Privileged Information",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;6;6;6",
        "confidence": "3;4;3;3",
        "correctness": "2;3;3;3",
        "technical_novelty": "3;3;3;2",
        "empirical_novelty": "2;3;2;2",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "f4c4JtbHJ7B",
        "title": "Pixab-CAM: Attend Pixel, not Channel",
        "track": "main",
        "status": "Reject",
        "keywords": "Explainable AI;Interpretable ML;Visual explanation of CNN;Class activation maps;Computer Vision",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "4;4;4;4",
        "correctness": "2;2;2;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 4.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.7777777777777777,
        "project": "",
        "github": ""
    },
    {
        "id": "f5ggjj9Rfq",
        "title": "Faking Interpolation Until You Make It",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Deep Learning;Optimisation;Step-size selection",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "5;3;3;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "3;2;3;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8703882797784891,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "f6CQliwyra",
        "title": "A Free Lunch from the Noise: Provable and Practical Exploration for Representation Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "representation learning;reinforcement learning",
        "author": "",
        "aff": "",
        "rating": "3;5;5;8",
        "confidence": "4;3;3;3",
        "correctness": "3;4;3;4",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7276068751089989,
        "corr_rating_correctness": 0.7001400420140049,
        "project": "",
        "github": ""
    },
    {
        "id": "f6R69En9_tH",
        "title": "Cross Project Software Vulnerability Detection via Domain Adaptation and Max-Margin Principle",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Cybersecurity;Cross Project Software Vulnerability Detection;Domain Adaptation;Max-Margin Principle.",
        "author": "",
        "aff": "",
        "rating": "3;5;5;8",
        "confidence": "4;3;4;3",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7001400420140049,
        "corr_rating_correctness": 0.8892972917998875,
        "project": "",
        "github": ""
    },
    {
        "id": "f7cWROZYSU",
        "title": "Detecting Worst-case Corruptions via Loss Landscape Curvature in Deep Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;8;8",
        "confidence": "3;5;4;4",
        "correctness": "4;2;4;4",
        "technical_novelty": "1;2;3;3",
        "empirical_novelty": "1;2;3;4",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "f9AIc3mEprf",
        "title": "What classifiers know what they don't know?",
        "track": "main",
        "status": "Reject",
        "keywords": "Uncertainty quantification;neural networks;benchmark",
        "author": "Mohamed Ishmael Belghazi",
        "aff": "Paper under double-blind review",
        "rating": "3;5;6",
        "confidence": "4;4;4",
        "correctness": "3;2;3",
        "technical_novelty": "2;1;2",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 1.6666666666666667,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.18898223650461363,
        "project": "",
        "github": "https://github.com/anonymous-author/UIMNET"
    },
    {
        "id": "f9D-5WNG4Nv",
        "title": "Online Coreset Selection for Rehearsal-based Continual Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "Continual Learning",
        "author": "",
        "aff": "New York University; KAIST; AITRICS",
        "rating": "5;6;6;8",
        "confidence": "4;4;4;3",
        "correctness": "2;3;4;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;0;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9271726499455306,
        "corr_rating_correctness": 0.3244428422615251,
        "project": "",
        "github": ""
    },
    {
        "id": "f9JwVXMJ1Up",
        "title": "The Needle in the haystack: Out-distribution aware Self-training in an Open-World Setting",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5;8",
        "confidence": "2;4;3;4;4",
        "correctness": "2;3;3;4;4",
        "technical_novelty": "2;2;3;2;3",
        "empirical_novelty": "2;2;3;3;3",
        "presentation": "",
        "rating_avg": 5.2,
        "confidence_avg": 3.4,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 2.6,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.71875,
        "corr_rating_correctness": 0.8017837257372732,
        "project": "",
        "github": ""
    },
    {
        "id": "f9MHpAGUyMn",
        "title": "Dynamic Token Normalization improves Vision Transformers",
        "track": "main",
        "status": "Poster",
        "keywords": "classification;Normalization;transformer",
        "author": "",
        "aff": "The University of Hong Kong; AI Technology Center of Tencent Video; ARC Lab, Tencent PCG; The Chinese University of Hong Kong",
        "rating": "5;5;6;6",
        "confidence": "4;4;4;4",
        "correctness": "3;2;4;3",
        "technical_novelty": "3;3;2;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.7071067811865475,
        "project": "",
        "github": "https://github.com/wqshao126/DTN"
    },
    {
        "id": "fCG75wd39ze",
        "title": "LORD: Lower-Dimensional Embedding of Log-Signature in Neural Rough Differential Equations",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "Yonsei University, Seoul, South Korea",
        "rating": "6;8;8;8",
        "confidence": "4;5;4;4",
        "correctness": "3;4;4;4",
        "technical_novelty": "3;3;4;3",
        "empirical_novelty": "4;4;4;2",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 4.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "fCSq8yrDkc",
        "title": "A fast and accurate splitting method for optimal transport: analysis and implementation",
        "track": "main",
        "status": "Poster",
        "keywords": "Optimal transport;Operator splitting;Douglas-Rachford;ADMM;GPUs",
        "author": "",
        "aff": "KTH Royal Institute of Technology, jlindbac@kth.se; KTH Royal Institute of Technology, mikaelj@kth.se; Ericsson AB, vien.mai@ericsson.com",
        "rating": "3;6;6;6",
        "confidence": "4;3;3;4",
        "correctness": "3;4;4;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;3;2;0",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "fE-sp8USacG",
        "title": "DropAttack: A Masked Weight Adversarial Training Method to Improve Generalization of Neural Networks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Adversarial training;random mask;regularization;generalization;neural networks",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "5;5;5;4",
        "correctness": "2;3;2;2",
        "technical_novelty": "3;2;1;2",
        "empirical_novelty": "2;2;1;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.75,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "Not provided",
        "github": "Not provided"
    },
    {
        "id": "fEcbkaHqlur",
        "title": "Beyond Target Networks: Improving Deep $Q$-learning with Functional Regularization",
        "track": "main",
        "status": "Reject",
        "keywords": "Q learning;regularization;deep Q learning",
        "author": "",
        "aff": "",
        "rating": "5;5;6;8",
        "confidence": "4;4;3;4",
        "correctness": "3;2;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;2;0;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.7385489458759963,
        "project": "",
        "github": ""
    },
    {
        "id": "fExcSKdDo_",
        "title": "Learning to Dequantise with Truncated Flows",
        "track": "main",
        "status": "Poster",
        "keywords": "variational inference;variational bayes;dequantisation;normalizing flows",
        "author": "",
        "aff": "Mila, University of Montreal; Microsoft Research, Montreal; Mila, University of Montreal, Canada CIFAR AI Chair",
        "rating": "6;6;6",
        "confidence": "4;3;4",
        "correctness": "4;3;4",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "fG9WttDhAaa",
        "title": "Rethinking Positional Encoding",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "3;4;3;4",
        "correctness": "3;2;3;2",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "fGEoHDk0C",
        "title": "A framework of deep neural networks via the solution operator of partial differential equations",
        "track": "main",
        "status": "Reject",
        "keywords": "deep neural networks;partial differential equations;solution operator",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "4;4;3;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4714045207910316,
        "corr_rating_correctness": 0.4714045207910316,
        "project": "",
        "github": ""
    },
    {
        "id": "fHPdmN3I0tY",
        "title": "Decoupled Kernel Neural Processes: Neural Network-Parameterized Stochastic Processes using Explicit Data-driven Kernel",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;6;8",
        "confidence": "5;4;2;4",
        "correctness": "3;2;1;4",
        "technical_novelty": "3;2;2;4",
        "empirical_novelty": "3;2;3;1",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.18731716231633877,
        "corr_rating_correctness": 0.5477225575051661,
        "project": "",
        "github": ""
    },
    {
        "id": "fHeK814NOMO",
        "title": "Trainable Learning Rate",
        "track": "main",
        "status": "Reject",
        "keywords": "Gradient Descent;Adaptive Step Size;Adaptive Learning Rate",
        "author": "",
        "aff": "",
        "rating": "3;5;6;8;8;10",
        "confidence": "5;5;3;4;4;5",
        "correctness": "3;4;4;3;4;4",
        "technical_novelty": "2;3;3;3;3;4",
        "empirical_novelty": "2;3;3;3;3;4",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.1304656146106883,
        "corr_rating_correctness": 0.36099743619057784,
        "project": "",
        "github": ""
    },
    {
        "id": "fILj7WpI-g",
        "title": "Perceiver IO: A General Architecture for Structured Inputs & Outputs",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Perceiver;BERT;natural language processing;optical flow;computer vision;multimodal;GLUE;ImageNet;StarCraft",
        "author": "",
        "aff": "DeepMind",
        "rating": "8;8;8;8",
        "confidence": "4;3;3;3",
        "correctness": "4;3;4;4",
        "technical_novelty": "3;3;3;4",
        "empirical_novelty": "3;4;2;4",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "fJ9iNyekd-",
        "title": "Positive and Unlabeled Federated Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Positive and Unlabeled Learning;Federated Learning",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;4;3;3",
        "correctness": "2;3;4;2",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.5222329678670935,
        "project": "",
        "github": ""
    },
    {
        "id": "fJIrkNKGBNI",
        "title": "Effective Polynomial Filter Adaptation for Graph Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "Graph Neural Networks;Graph Filters",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5",
        "confidence": "5;4;4;4",
        "correctness": "3;4;3;4",
        "technical_novelty": "3;2;4;2",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://tinyurl.com/PPGNN"
    },
    {
        "id": "fKv__asZk47",
        "title": "Learning Similarity Metrics for Volumetric Simulations with Multiscale CNNs",
        "track": "main",
        "status": "Reject",
        "keywords": "metric learning;PDEs;numerical simulation;physical modeling",
        "author": "Anonymous Authors",
        "aff": "",
        "rating": "3;8;8",
        "confidence": "3;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "2;4;3",
        "empirical_novelty": "2;4;3",
        "presentation": "",
        "rating_avg": 6.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9999999999999998,
        "corr_rating_correctness": 0.5000000000000001,
        "project": "",
        "github": ""
    },
    {
        "id": "fM8VzFD_2-",
        "title": "Discovering the neural correlate informed nosological relation among multiple neuropsychiatric disorders through dual utilisation of diagnostic information",
        "track": "main",
        "status": "Reject",
        "keywords": "computational psychiatric;variational auto-encoder;fMRI analysis",
        "author": "",
        "aff": "",
        "rating": "1;5;6;6;8",
        "confidence": "5;3;2;3;4",
        "correctness": "2;3;3;3;3",
        "technical_novelty": "1;2;3;3;3",
        "empirical_novelty": "1;2;3;3;2",
        "presentation": "",
        "rating_avg": 5.2,
        "confidence_avg": 3.4,
        "correctness_avg": 2.8,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 2.2,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5421393180573577,
        "corr_rating_correctness": 0.9070618468604282,
        "project": "",
        "github": ""
    },
    {
        "id": "fNCVBsB-N9p",
        "title": "MECATS: Mixture-of-Experts for Probabilistic Forecasts of Aggregated Time Series",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Time Series;Mixture-of-Experts;Data Aggregation;Uncertainty Estimation",
        "author": "",
        "aff": "",
        "rating": "3;3;5",
        "confidence": "4;4;2",
        "correctness": "3;3;3",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "3;2;3",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "fOsN52jn25l",
        "title": "Dual Lottery Ticket Hypothesis",
        "track": "main",
        "status": "Poster",
        "keywords": "Dual Lottery Ticket Hypothesis;Sparse Network Training",
        "author": "",
        "aff": "Meta Research, Burlingame, CA, USA; Northeastern University, Boston, MA, USA; Santa Clara University, Santa Clara, CA, USA",
        "rating": "6;6;8;8;8",
        "confidence": "4;5;4;4;4",
        "correctness": "2;2;3;3;3",
        "technical_novelty": "3;2;3;3;3",
        "empirical_novelty": "3;3;3;2;3",
        "presentation": "",
        "rating_avg": 7.2,
        "confidence_avg": 4.2,
        "correctness_avg": 2.6,
        "technical_novelty_avg": 2.8,
        "empirical_novelty_avg": 2.8,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6123724356957947,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": "https://github.com/yueb17/DLTH"
    },
    {
        "id": "fPhKeld3Okz",
        "title": "Gradient Step Denoiser for convergent Plug-and-Play",
        "track": "main",
        "status": "Poster",
        "keywords": "Plug-and-Play;Inverse Problem;Image Restoration;Denoising",
        "author": "",
        "aff": "Univ. Bordeaux, Bordeaux INP, CNRS, IMB, UMR 5251, F-33400 Talence, France",
        "rating": "6;6;6;8",
        "confidence": "4;4;5;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "3;2;2;4",
        "empirical_novelty": "3;3;2;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 4.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "fQTlgI2qZqE",
        "title": "Fast Generic Interaction Detection for Model Interpretability and Compression",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "School of Science and Engineering, The Chinese University of Hong Kong, Shenzhen; Shenzhen Research Institute of Big Data",
        "rating": "6;6;6;8",
        "confidence": "4;3;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "4;3;3;3",
        "empirical_novelty": "4;2;2;4",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/zhangtj1996/ParaACE"
    },
    {
        "id": "fR-EnKWL_Zb",
        "title": "Quadtree Attention for Vision Transformers",
        "track": "main",
        "status": "Poster",
        "keywords": "Vision Transformer;Efficient Transformer;Feature matching;Stereo;image classification;detection;3D Vision",
        "author": "",
        "aff": "Alibaba A.I. Lab; Simon Fraser University",
        "rating": "5;6;6;8",
        "confidence": "4;4;4;4",
        "correctness": "3;4;3;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "0;3;3;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.13245323570650439,
        "project": "",
        "github": "https://github.com/Tangshitao/QuadtreeAttention"
    },
    {
        "id": "fRb9LBWUo56",
        "title": "On the benefits of deep RL in accelerated MRI sampling",
        "track": "main",
        "status": "Reject",
        "keywords": "MRI reconstruction;MRI sampling;reinforcement learning;accelerated MRI;replication",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;2;2;3",
        "correctness": "3;4;3;3",
        "technical_novelty": "2;2;1;1",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 1.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.30151134457776363,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "fRnRsdc_nR7",
        "title": "Towards fast and effective single-step adversarial training",
        "track": "main",
        "status": "Reject",
        "keywords": "single-step adversarial training;catastrophic overfitting;FGSM;efficient adversarial training;fast adversarial training",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;4;2;5",
        "correctness": "3;2;3;4",
        "technical_novelty": "1;2;3;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.15789473684210528,
        "corr_rating_correctness": 0.3244428422615251,
        "project": "",
        "github": ""
    },
    {
        "id": "fSeD40P0XTI",
        "title": "ACCTS: an Adaptive Model Training Policy for Continuous Classification of Time Series",
        "track": "main",
        "status": "Reject",
        "keywords": "Continuous classification of time series;Deep learning;Model training",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "2;3;3;3",
        "correctness": "2;3;3;2",
        "technical_novelty": "3;2;3;2",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.75,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "fStt6fyzrK",
        "title": "Model-Based Robust Adaptive Semantic Segmentation",
        "track": "main",
        "status": "Reject",
        "keywords": "Semantic Segmentation;Robustness;Natural Variation",
        "author": "",
        "aff": "",
        "rating": "5;5;6",
        "confidence": "4;3;4",
        "correctness": "2;2;3",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.4999999999999999,
        "corr_rating_correctness": 0.9999999999999997,
        "project": "",
        "github": ""
    },
    {
        "id": "fTYeefgXReA",
        "title": "Equivariant Heterogeneous Graph Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "Heterogeneous Graphs;Graph Neural Networks;GNN;Equivariance",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5",
        "confidence": "4;4;2;4",
        "correctness": "3;4;4;3",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;1;3;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "fUhxuop_Q1r",
        "title": "Disentangling Generalization in Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Reinforcement learning;generalization",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;4;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;3;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "fVu3o-YUGQK",
        "title": "Efficient Self-supervised Vision Transformers for Representation Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "self-supervised learning;vision transformers;non-contrastive region-matching task",
        "author": "",
        "aff": "Microsoft Research at Redmond; Microsoft Cloud + AI",
        "rating": "6;8;8",
        "confidence": "5;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 7.333333333333333,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9999999999999997,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/microsoft/esvit"
    },
    {
        "id": "fWK3qhAtbbk",
        "title": "A Study of Aggregation of Long Time-series Input for LSTM Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "LSTM;Data Aggregation;Time Series",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "4;5;3;4",
        "correctness": "2;3;3;2",
        "technical_novelty": "2;2;1;1",
        "empirical_novelty": "1;2;2;3",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 1.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "fWVQqtshDj",
        "title": "MOBA: Multi-teacher Model Based Reinforcement Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Model-based reinforcement leanring;Multi-teacher knowledge distillation;Emsemble learning",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;3;4;3",
        "correctness": "3;2;3;3",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "fXHl76nO2AZ",
        "title": "Gradient Importance Learning for Incomplete Observations",
        "track": "main",
        "status": "Poster",
        "keywords": "Missing Data;Reinforcement Learning;Representation Learning",
        "author": "",
        "aff": "Duke University, USA; Duke University, USA; King Abdullah University of Science and Technology, Saudi Arabia",
        "rating": "6;6;6;8",
        "confidence": "4;3;2;3",
        "correctness": "4;3;4;4",
        "technical_novelty": "3;4;3;4",
        "empirical_novelty": "3;3;4;0",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": "https://github.com/gaoqitong/gradient-importance-learning"
    },
    {
        "id": "fY2-WyfrXhU",
        "title": "MemREIN: Rein the Domain Shift for Cross-Domain Few-Shot Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5;6",
        "confidence": "5;4;3;4;4",
        "correctness": "4;3;3;3;3",
        "technical_novelty": "2;2;2;2;3",
        "empirical_novelty": "2;2;2;2;3",
        "presentation": "",
        "rating_avg": 4.4,
        "confidence_avg": 4.0,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.2,
        "empirical_novelty_avg": 2.2,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5270462766947298,
        "corr_rating_correctness": -0.5833333333333335,
        "project": "",
        "github": ""
    },
    {
        "id": "fYor2QIp_3",
        "title": "An Effective GCN-based Hierarchical Multi-label classification for Protein Function Prediction",
        "track": "main",
        "status": "Reject",
        "keywords": "Bioinformatics;Protein function prediction;Machine Learning",
        "author": "",
        "aff": "",
        "rating": "1;3;3;3",
        "confidence": "5;5;5;4",
        "correctness": "2;4;2;2",
        "technical_novelty": "2;2;3;1",
        "empirical_novelty": "2;2;3;1",
        "presentation": "",
        "rating_avg": 2.5,
        "confidence_avg": 4.75,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "faMcf0MDk0f",
        "title": "BoolNet: Streamlining Binary Neural Networks Using Binary Feature Maps",
        "track": "main",
        "status": "Reject",
        "keywords": "Binary Neural Networks;Hardware-Friendly Neural Architecture Design",
        "author": "",
        "aff": "",
        "rating": "3;3;5;8",
        "confidence": "4;2;4;5",
        "correctness": "3;3;2;3",
        "technical_novelty": "2;2;3;4",
        "empirical_novelty": "2;2;0;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.7567450038061343,
        "corr_rating_correctness": -0.07053456158585983,
        "project": "",
        "github": ""
    },
    {
        "id": "famc03Gg231",
        "title": "Physical Gradients for Deep Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "deep learning;simulation;optimization;inverse problems;physics",
        "author": "",
        "aff": "",
        "rating": "3;3;6;6",
        "confidence": "2;4;4;3",
        "correctness": "2;2;2;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;4;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3015113445777637,
        "corr_rating_correctness": 0.5773502691896258,
        "project": "",
        "github": ""
    },
    {
        "id": "ffS_Y258dZs",
        "title": "Meta-Referential Games to Learn Compositional Learning Behaviours",
        "track": "main",
        "status": "Reject",
        "keywords": "language emergence;language grounding;compositionality;systematicity;few-shot learning",
        "author": "",
        "aff": "Paper under double-blind review",
        "rating": "1;3;3;3",
        "confidence": "4;3;3;2",
        "correctness": "1;3;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 2.5,
        "confidence_avg": 3.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.816496580927726,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "fgcIb5gd99r",
        "title": "Multi-scale fusion self attention mechanism",
        "track": "main",
        "status": "Reject",
        "keywords": "Attention;multi-scale;phrase information;sparsity scheme",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "3;3;4;5",
        "correctness": "3;3;3;2",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "figzpGMrdD",
        "title": "Pretrained Language Model in Continual Learning: A Comparative Study",
        "track": "main",
        "status": "Poster",
        "keywords": "Continual Learning;Pre-trained Language Model",
        "author": "",
        "aff": "Southeast University, Monash University; Monash University; MILA; Southeast University",
        "rating": "3;5;6;8",
        "confidence": "4;4;4;5",
        "correctness": "4;3;3;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;3;4",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 4.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8006407690254357,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "fkjO_FKVzw",
        "title": "Coarformer: Transformer for large graph via graph coarsening",
        "track": "main",
        "status": "Reject",
        "keywords": "Graph Neural Networks;Transformer;Graph Coarsening",
        "author": "",
        "aff": "",
        "rating": "3;5;6;8",
        "confidence": "4;3;5;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.19611613513818402,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "fpU10jwpPvw",
        "title": "Folded Hamiltonian Monte Carlo for Bayesian Generative Adversarial Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "1;3;6",
        "confidence": "4;3;3",
        "correctness": "1;2;3",
        "technical_novelty": "1;2;3",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 3.3333333333333335,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8029550685469661,
        "corr_rating_correctness": 0.9933992677987827,
        "project": "",
        "github": ""
    },
    {
        "id": "fuYtttFI-By",
        "title": "Programmable 3D snapshot microscopy with Fourier convolutional networks",
        "track": "main",
        "status": "Reject",
        "keywords": "computational microscopy;computational photography;computer vision;deep learning",
        "author": "",
        "aff": "",
        "rating": "6;6;6;6",
        "confidence": "3;4;3;3",
        "correctness": "4;3;3;4",
        "technical_novelty": "3;2;3;2",
        "empirical_novelty": "3;3;2;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "fuaHYhuYIDm",
        "title": "MAGNEx: A Model Agnostic Global Neural Explainer",
        "track": "main",
        "status": "Reject",
        "keywords": "Explainability;Neural Explainer;Faithfullness;Global;Post-hoc",
        "author": "",
        "aff": "",
        "rating": "3;3;6;6",
        "confidence": "4;4;4;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896258,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "fvLLcIYmXb",
        "title": "AS-MLP: An Axial Shifted MLP Architecture for Vision",
        "track": "main",
        "status": "Poster",
        "keywords": "Architecture Design;MLP;Classification;Detection;Segmentation",
        "author": "",
        "aff": "ShanghaiTech University & Shanghai Engineering Research Center of Intelligent Vision and Imaging & Shanghai Engineering Research Center of Energy Efficient and Custom AI IC; Youtu Lab, Tencent; ShanghaiTech University",
        "rating": "5;5;6",
        "confidence": "4;5;4",
        "correctness": "3;3;3",
        "technical_novelty": "3;1;3",
        "empirical_novelty": "4;2;3",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4999999999999999,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/svip-lab/AS-MLP"
    },
    {
        "id": "fvybrRLv4m",
        "title": "Dictionary Learning Under Generative Coefficient Priors with Applications to Compression",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Dictionary learning;generative priors;sparsity;alternating minimization;linear transformation;transfer learning;compression;algorithms",
        "author": "Hannah Lawrence",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "4;4;4;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;1;2",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5555555555555555,
        "project": "",
        "github": ""
    },
    {
        "id": "fwJWhOxuzV9",
        "title": "Semi-supervised Offline Reinforcement Learning with Pre-trained Decision Transformers",
        "track": "main",
        "status": "Reject",
        "keywords": "Multi-task RL;Decision Transformer;self-supervised RL;Pretraining",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "3;4;4;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;0",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "fwsdscicqUm",
        "title": "Improving Fairness via Federated Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "4;4;4;4",
        "correctness": "3;3;2;4",
        "technical_novelty": "2;2;1;4",
        "empirical_novelty": "2;2;0;4",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.2721655269759087,
        "project": "",
        "github": ""
    },
    {
        "id": "fwzUgo0FM9v",
        "title": "Robbing the Fed: Directly Obtaining Private Data in Federated Learning with Modified Models",
        "track": "main",
        "status": "Poster",
        "keywords": "Privacy;Federated Learning;Gradient Inversion",
        "author": "",
        "aff": "Center for Data Science, New York University; Department of Computer Science, University of Maryland; Department of Mathematics, University of Maryland",
        "rating": "5;6;6;8",
        "confidence": "2;4;2;4",
        "correctness": "3;4;3;4",
        "technical_novelty": "2;2;3;4",
        "empirical_novelty": "2;2;3;4",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.6882472016116854,
        "corr_rating_correctness": 0.6882472016116854,
        "project": "",
        "github": ""
    },
    {
        "id": "fyLvrx9M9YP",
        "title": "Towards Unsupervised Content Disentanglement in Sentence Representations via Syntactic Roles",
        "track": "main",
        "status": "Reject",
        "keywords": "NLP;disentanglement;unsupervised learning;controllable generation.",
        "author": "",
        "aff": "",
        "rating": "5;5;6;8",
        "confidence": "3;3;3;3",
        "correctness": "2;3;3;4",
        "technical_novelty": "3;2;3;2",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.8660254037844386,
        "project": "",
        "github": ""
    },
    {
        "id": "fy_XRVHqly",
        "title": "Structure-Aware Transformer Policy for Inhomogeneous Multi-Task Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "Multitask Reinforcement Learning;Modular Reinforcement Learning;Transfer Learning;Transformer;Structural Embedding",
        "author": "",
        "aff": "Kim Jaechul Graduate School of AI, KAIST, Daejeon, Republic of Korea; School of Computing, KAIST, Daejeon, Republic of Korea",
        "rating": "5;6;6;6",
        "confidence": "3;2;4;4",
        "correctness": "3;4;3;3",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.17407765595569782,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "g-xTi8MYSM",
        "title": "Improving Learning from Demonstrations by Learning from Experience",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Behavior Cloning;Learning from demonstration",
        "author": "",
        "aff": "",
        "rating": "1;1;3;3",
        "confidence": "4;5;4;3",
        "correctness": "1;4;4;2",
        "technical_novelty": "2;2;1;2",
        "empirical_novelty": "1;2;1;2",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7071067811865475,
        "corr_rating_correctness": 0.19245008972987523,
        "project": "",
        "github": ""
    },
    {
        "id": "g1D7SfQKbg",
        "title": "Learning with Noisy Labels by Efficient Transition Matrix Estimation to Combat Label Miscorrection",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Noisy Labels;Label Correction;Meta-Learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;8",
        "confidence": "5;4;4;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8638684255813602,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "g1SzIRLQXMM",
        "title": "Wiring Up Vision: Minimizing Supervised Synaptic Updates Needed to Produce a Primate Ventral Stream",
        "track": "main",
        "status": "Spotlight",
        "keywords": "computational neuroscience;primate visual ventral stream;convolutional neural networks;biologically plausible learning",
        "author": "",
        "aff": "Department of Brain and Cognitive Sciences, MIT; Center for Brains, Minds and Machines, MIT; McGovern Institute for Brain Research, MIT; Department of Brain and Cognitive Sciences, MIT; Center for Brains, Minds and Machines, MIT; McGovern Institute for Brain Research, MIT; University of Augsburg; Ludwig Maximilian University; Technical University of Munich",
        "rating": "8;8;8;8",
        "confidence": "3;4;4;4",
        "correctness": "3;4;3;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;4;4;3",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "g2LCQwG7Of",
        "title": "End-to-End Learning of Probabilistic Hierarchies on Graphs",
        "track": "main",
        "status": "Poster",
        "keywords": "hierarchical clustering;graphs;networks;graph mining;network mining;graph custering",
        "author": "",
        "aff": "Technical University of Munich",
        "rating": "6;6;8",
        "confidence": "4;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "3;3;4",
        "empirical_novelty": "3;3;0",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.3333333333333335,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9999999999999998,
        "corr_rating_correctness": 0.9999999999999998,
        "project": "",
        "github": ""
    },
    {
        "id": "g4nVdxU9RK",
        "title": "Rewardless Open-Ended Learning (ROEL)",
        "track": "main",
        "status": "Reject",
        "keywords": "unsupervised reinforcement learning;open-ended learning;skill discovery",
        "author": "",
        "aff": "",
        "rating": "3;3;3;6",
        "confidence": "4;4;3;2",
        "correctness": "3;3;3;3",
        "technical_novelty": "3;2;2;3",
        "empirical_novelty": "2;2;0;2",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8703882797784892,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "g5odb-gVVZY",
        "title": "Multilevel physics informed neural networks (MPINNs)",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5;8",
        "confidence": "4;4;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;3;3;4",
        "empirical_novelty": "2;3;3;1",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "g5tANwND04i",
        "title": "On the Convergence of mSGD and AdaGrad for Stochastic Optimization",
        "track": "main",
        "status": "Poster",
        "keywords": "stochastic gradient descent;adaptive gradient algorithm;asymptotic convergence",
        "author": "",
        "aff": "Division of Decision and Control Systems, KTH Royal Institute of Technology, SE-100 44 Stockholm, Sweden; LSC, NCMIS, Academy of Mathematics and Systems Science, Chinese Academy of Sciences, Beijing 100190, China; School of Mathematical Sciences, University of Chinese Academy of Sciences, Beijing 100049, China; Department of Electrical Engineering, University of Notre Dame, IN, USA",
        "rating": "6;6;6",
        "confidence": "3;4;2",
        "correctness": "4;2;4",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "3;0;0",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 1.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "g5ynW-jMq4M",
        "title": "Properties from mechanisms: an equivariance perspective on identifiable representation learning",
        "track": "main",
        "status": "Spotlight",
        "keywords": "representation learning;equivariance;independent component analysis;ICA;autoencoders",
        "author": "",
        "aff": "Mila - Quebec AI Institute, Universit \u00b4e de Montr \u00b4eal, Quebec, Canada",
        "rating": "6;6;8",
        "confidence": "3;2;4",
        "correctness": "4;4;3",
        "technical_novelty": "3;4;3",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 3.3333333333333335,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8660254037844385,
        "corr_rating_correctness": -0.9999999999999998,
        "project": "",
        "github": ""
    },
    {
        "id": "g6UqpVislvH",
        "title": "Generalized Fourier Features for Coordinate-Based Learning of Functions on Manifolds",
        "track": "main",
        "status": "Reject",
        "keywords": "positional encoding;fourier features;coordinate-based mlp",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6;10",
        "confidence": "4;4;4;4;4",
        "correctness": "3;4;2;3;4",
        "technical_novelty": "3;2;2;3;4",
        "empirical_novelty": "2;2;2;2;4",
        "presentation": "",
        "rating_avg": 5.4,
        "confidence_avg": 4.0,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.8,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.2696654394346322,
        "project": "",
        "github": ""
    },
    {
        "id": "g8NJR6fCCl8",
        "title": "NODE-GAM: Neural Generalized Additive Model for Interpretable Deep Learning",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Generalized Additive Model;Deep Learning Architecture;Interpretability",
        "author": "",
        "aff": "University of Toronto, Vector Institute, Hospital of Sickkids; Microsoft Research",
        "rating": "5;8;8",
        "confidence": "2;3;4",
        "correctness": "2;4;4",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "2;0;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8660254037844387,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "g9B7h9gycMg",
        "title": "LONG-TAILED RECOGNITION BY LEARNING FROM LATENT CATEGORIES",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Long-Tailed Recognition;Latent Category",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "5;4;4;3",
        "correctness": "2;4;3;3",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9733285267845754,
        "corr_rating_correctness": 0.6488856845230502,
        "project": "",
        "github": ""
    },
    {
        "id": "g9hjVsv3lOC",
        "title": "Deep Neural Networks on EEG signals to predict Attention Score using Gramian Angular Difference Field",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Auditory attention;Gramian Angular Difference Field;Electroencephalography",
        "author": "",
        "aff": "",
        "rating": "1;1;3;3",
        "confidence": "5;5;5;4",
        "correctness": "2;1;2;2",
        "technical_novelty": "1;1;1;2",
        "empirical_novelty": "1;1;1;2",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.75,
        "correctness_avg": 1.75,
        "technical_novelty_avg": 1.25,
        "empirical_novelty_avg": 1.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "gCmCiclZV6Q",
        "title": "Inferring Offensiveness In Images From Natural Language Supervision",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;3",
        "confidence": "4;3;3",
        "correctness": "2;3;3",
        "technical_novelty": "1;2;2",
        "empirical_novelty": "2;3;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 1.6666666666666667,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "gD0KBsQcGKg",
        "title": "Distribution-Driven Disjoint Prediction Intervals for Deep Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Uncertainty;Prediction Interval;Regression Uncertainty",
        "author": "",
        "aff": "",
        "rating": "3;5;5",
        "confidence": "3;4;2",
        "correctness": "2;4;3",
        "technical_novelty": "3;2;2",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 4.333333333333333,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.8660254037844385,
        "project": "",
        "github": ""
    },
    {
        "id": "gEZrGCozdqR",
        "title": "Finetuned Language Models are Zero-Shot Learners",
        "track": "main",
        "status": "Oral",
        "keywords": "natural language processing;zero-shot learning;language models",
        "author": "",
        "aff": "Google Research",
        "rating": "8;8;8;8",
        "confidence": "5;3;4;4",
        "correctness": "3;4;4;3",
        "technical_novelty": "1;2;3;4",
        "empirical_novelty": "4;4;3;4",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 3.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "gEynpztqZug",
        "title": "Mako: Semi-supervised continual learning with minimal labeled data via data programming",
        "track": "main",
        "status": "Reject",
        "keywords": "lifelong machine learning;data programming;semi-supervised learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;5;3",
        "correctness": "3;2;4;3",
        "technical_novelty": "1;2;3;2",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.7071067811865475,
        "project": "",
        "github": ""
    },
    {
        "id": "gFDFKC4gHL4",
        "title": "How Did the Model Change? Efficiently Assessing Machine Learning API Shifts",
        "track": "main",
        "status": "Poster",
        "keywords": "ML API performance shifts;ML as a service;ML monitoring;ML performance evaluation",
        "author": "",
        "aff": "Stanford University",
        "rating": "6;6;6;8",
        "confidence": "4;3;4;4",
        "correctness": "3;4;4;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "4;4;3;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "gI7KCy4UDN9",
        "title": "Post-Training Quantization Is All You Need to Perform Cross-Platform Learned Image Compression",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;6;6;6;6",
        "confidence": "4;5;4;3;3",
        "correctness": "2;4;4;2;3",
        "technical_novelty": "2;2;2;2;2",
        "empirical_novelty": "3;3;3;3;2",
        "presentation": "",
        "rating_avg": 5.4,
        "confidence_avg": 3.8,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.8,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.1336306209562122,
        "corr_rating_correctness": 0.5590169943749475,
        "project": "",
        "github": ""
    },
    {
        "id": "gI7feJ9yXPz",
        "title": "High Probability Generalization Bounds with Fast Rates for Minimax Problems",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "Gaoling School of Arti\ufb01cial Intelligence, Renmin University of China, Beijing, China",
        "rating": "6;6;8;8",
        "confidence": "3;4;5;3",
        "correctness": "3;4;3;3",
        "technical_novelty": "3;4;3;4",
        "empirical_novelty": "3;4;0;0",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.30151134457776363,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "gICys3ITSmj",
        "title": "The Close Relationship Between Contrastive Learning and Meta-Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "meta-learning;contrastive learning;self-supervised learning",
        "author": "",
        "aff": "Johns Hopkins University; University of Maryland",
        "rating": "5;5;6;6",
        "confidence": "4;3;4;3",
        "correctness": "1;3;4;3",
        "technical_novelty": "3;2;3;2",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.6882472016116854,
        "project": "",
        "github": "https://github.com/RenkunNi/MetaContrastive"
    },
    {
        "id": "gJLEXy3ySpu",
        "title": "Almost Tight L0-norm Certified Robustness of Top-k Predictions against Adversarial Perturbations",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "Duke University; Illinois Institute of Technology",
        "rating": "5;6;6;6",
        "confidence": "3;3;4;2",
        "correctness": "3;3;4;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;3;2",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "gJcEM8sxHK",
        "title": "Mapping Language Models to Grounded Conceptual Spaces",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "Department of Computer Science, Brown University",
        "rating": "5;6;8;8",
        "confidence": "5;4;4;4",
        "correctness": "3;2;4;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "4;3;3;3",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 4.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7777777777777777,
        "corr_rating_correctness": 0.5443310539518174,
        "project": "",
        "github": ""
    },
    {
        "id": "gKLAAfiytI",
        "title": "Equivariant Self-Supervised Learning: Encouraging Equivariance in Representations",
        "track": "main",
        "status": "Poster",
        "keywords": "self-supervised learning;contrastive learning;photonics science",
        "author": "",
        "aff": "Facebook AI Research; MIT Physics; MIT EECS; MIT CSAIL & BCS; MIT-IBM Watson AI Lab; MIT CSAIL",
        "rating": "6;6;6;8",
        "confidence": "4;2;4;3",
        "correctness": "3;4;3;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.17407765595569782,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": "https://github.com/rdangovs/essl"
    },
    {
        "id": "gKWxifgJVP",
        "title": "Fact-driven Logical Reasoning",
        "track": "main",
        "status": "Reject",
        "keywords": "logical reasoning;machine reading comprehension;language understanding",
        "author": "",
        "aff": "",
        "rating": "6;6;6;6",
        "confidence": "3;4;4;3",
        "correctness": "3;4;3;3",
        "technical_novelty": "3;3;4;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "gKprVaCyQmA",
        "title": "There are free lunches",
        "track": "main",
        "status": "Reject",
        "keywords": "No-Free-Lunch Theorems",
        "author": "",
        "aff": "",
        "rating": "1;3;3;5",
        "confidence": "3;3;2;2",
        "correctness": "1;2;2;3",
        "technical_novelty": "4;2;2;3",
        "empirical_novelty": "1;0;0;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.5,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 0.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7071067811865476,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "gLqnSGXVJ6l",
        "title": "Neural Combinatorial Optimization with Reinforcement Learning : Solving theVehicle Routing Problem with Time Windows",
        "track": "main",
        "status": "Reject",
        "keywords": "rienforcement learning;neural combinatorial optimization;vehicle routing problem with time windows;attention model",
        "author": "",
        "aff": "",
        "rating": "1;3;3;3",
        "confidence": "4;5;4;4",
        "correctness": "3;1;3;3",
        "technical_novelty": "1;1;2;2",
        "empirical_novelty": "1;2;2;2",
        "presentation": "",
        "rating_avg": 2.5,
        "confidence_avg": 4.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 1.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "gLtMe3vpfZa",
        "title": "Accelerating Stochastic Simulation with Interactive Neural Processes",
        "track": "main",
        "status": "Reject",
        "keywords": "neural processes;bayesian active learning;stochastic process;deep sequence model;epidemic modeling",
        "author": "",
        "aff": "",
        "rating": "5;6;6;6",
        "confidence": "4;4;3;3",
        "correctness": "2;3;2;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "gMJhuI6RGmv",
        "title": "Neural Face Identification in a 2D Wireframe Projection of a Manifold Object",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Face Identification;Wireframe;Line Drawing;3D Reconstruction",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6;6",
        "confidence": "4;3;5;3;5",
        "correctness": "2;4;4;4;4",
        "technical_novelty": "2;3;3;3;4",
        "empirical_novelty": "2;3;2;3;4",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.8,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9128709291752768,
        "project": "",
        "github": ""
    },
    {
        "id": "gNp54NxHUPJ",
        "title": "Fast Regression for Structured Inputs",
        "track": "main",
        "status": "Poster",
        "keywords": "regression;sublinear time algorithm;structured input",
        "author": "",
        "aff": "New York University; Carnegie Mellon University; University of Massachusetts Amherst",
        "rating": "6;8;10",
        "confidence": "3;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "2;3;4",
        "empirical_novelty": "0;2;3",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8660254037844385,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "gPvB4pdu_Z",
        "title": "Compositional Training for End-to-End Deep AUC Maximization",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Compositional Training;Imbalanced Losses;AUC optimization;Deep Learning",
        "author": "",
        "aff": "Computer Science & Engineering, University of Notre Dame; Department of Computer Science, University of Iowa",
        "rating": "6;8;8",
        "confidence": "3;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 7.333333333333333,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "www.libauc.org",
        "github": "https://github.com/Optimization-AI/LibAUC"
    },
    {
        "id": "gRCCdgpVZf",
        "title": "Provable Adaptation across Multiway Domains via Representation Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "Representation learning;tensor;statistical learning theory",
        "author": "",
        "aff": "University of Washington; NEC Laboratories America, Inc.; Carnegie Mellon University",
        "rating": "3;6;6;8",
        "confidence": "5;4;3;2",
        "correctness": "4;4;4;3",
        "technical_novelty": "2;3;2;4",
        "empirical_novelty": "2;3;2;2",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9393364366277244,
        "corr_rating_correctness": -0.7276068751089989,
        "project": "",
        "github": ""
    },
    {
        "id": "gSdSJoenupI",
        "title": "PolyLoss: A Polynomial Expansion Perspective of Classification Loss Functions",
        "track": "main",
        "status": "Poster",
        "keywords": "classification;computer vision;loss",
        "author": "",
        "aff": "Google LLC; Waymo LLC",
        "rating": "6;6;6;8",
        "confidence": "4;2;3;5",
        "correctness": "3;3;4;4",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.7745966692414834,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "gTdmGt48ht1",
        "title": "On the Double Descent of Random Features Models Trained with SGD",
        "track": "main",
        "status": "Desk Reject",
        "keywords": "random features;over-parameterized model;double descent;SGD",
        "author": "",
        "aff": "",
        "rating": "",
        "confidence": "",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "gULyf2IVll0",
        "title": "Empirical Study of the Decision Region and Robustness in Deep Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "Decision Region;Adversarial Robustness;Deep Neural Networks",
        "author": "",
        "aff": "",
        "rating": "5;6;6",
        "confidence": "4;4;2",
        "correctness": "3;3;3",
        "technical_novelty": "3;2;2",
        "empirical_novelty": "3;2;2",
        "presentation": "",
        "rating_avg": 5.666666666666667,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4999999999999999,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "gVRhIEajG1k",
        "title": "Rethinking Adversarial Transferability from a Data Distribution Perspective",
        "track": "main",
        "status": "Poster",
        "keywords": "Adversarial Attack;Adversarial Transferability;Black-box Attack",
        "author": "",
        "aff": "Huawei Noah\u2019s Ark Lab; Zhejiang University",
        "rating": "5;8;8",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "3;2;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "gWGexz8hFH",
        "title": "Distributed Skellam Mechanism: a Novel Approach to Federated Learning with Differential Privacy",
        "track": "main",
        "status": "Reject",
        "keywords": "Differential Privacy;Federated Learning;Skellam Distribution;Renyi Divergence",
        "author": "",
        "aff": "",
        "rating": "3;5;6;8",
        "confidence": "4;4;4;4",
        "correctness": "2;4;3;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;3;0",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.7526178090063818,
        "project": "",
        "github": ""
    },
    {
        "id": "gX9Ub6AwAd",
        "title": "ANOMALY DETECTION WITH FRAME-GROUP ATTENTION IN SURVEILLANCE VIDEOS",
        "track": "main",
        "status": "Reject",
        "keywords": "Anomaly detection;attention mechanism;frame-group;spatial-temporal feature",
        "author": "",
        "aff": "",
        "rating": "1;1;3;3",
        "confidence": "5;4;4;3",
        "correctness": "3;2;3;2",
        "technical_novelty": "1;1;1;2",
        "empirical_novelty": "1;2;1;2",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 1.25,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7071067811865475,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "gaYko_Y2_l",
        "title": "Weakly Supervised Graph Clustering",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6;6",
        "confidence": "3;3;4;2;2",
        "correctness": "3;3;2;4;3",
        "technical_novelty": "3;2;2;3;3",
        "empirical_novelty": "3;2;2;3;3",
        "presentation": "",
        "rating_avg": 5.4,
        "confidence_avg": 2.8,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 2.6,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8728715609439693,
        "corr_rating_correctness": 0.6454972243679027,
        "project": "",
        "github": ""
    },
    {
        "id": "gbe1zHyA73",
        "title": "Constrained Physical-Statistics Models for Dynamical System Identification and Prediction",
        "track": "main",
        "status": "Poster",
        "keywords": "Deep Learning;Hybrid Models;Differential Equations",
        "author": "",
        "aff": "Sorbonne Universit\u00e9, CNRS, LOCEAN-IPSL, F-75005 Paris, France; Sorbonne Universit\u00e9, CNRS, ISIR, F-75005 Paris, France; Criteo AI Labs, Paris, France; Sorbonne Universit\u00e9, CNRS, ISIR, F-75005 Paris, France",
        "rating": "3;6;6;8",
        "confidence": "3;4;3;4",
        "correctness": "4;4;3;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.7001400420140049,
        "corr_rating_correctness": -0.08084520834544431,
        "project": "",
        "github": ""
    },
    {
        "id": "gc8zLQWf2k",
        "title": "Towards the Memorization Effect of Neural Networks in Adversarial Training",
        "track": "main",
        "status": "Reject",
        "keywords": "Adversarial training;Robustness;Overfitting;Neural networks",
        "author": "",
        "aff": "",
        "rating": "5;5;6;8",
        "confidence": "4;4;3;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9428090415820632,
        "project": "",
        "github": ""
    },
    {
        "id": "gccdzDu5Ur",
        "title": "Combining Diverse Feature Priors",
        "track": "main",
        "status": "Reject",
        "keywords": "robustness;spurious correlations;feature priors",
        "author": "",
        "aff": "",
        "rating": "3;3;6;8",
        "confidence": "2;4;4;4",
        "correctness": "2;3;3;4",
        "technical_novelty": "1;1;2;3",
        "empirical_novelty": "2;1;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5443310539518174,
        "corr_rating_correctness": 0.8333333333333334,
        "project": "",
        "github": ""
    },
    {
        "id": "gciJWCp3z1s",
        "title": "On the Convergence of Projected Alternating Maximization for Equitable and Optimal Transport",
        "track": "main",
        "status": "Reject",
        "keywords": "Equitable and Optimal Transport;Fairness;Saddle Point Problem;Projected Alternating Maximization;Block Coordinate Descent;Acceleration;Rounding",
        "author": "",
        "aff": "",
        "rating": "5;6;6;8",
        "confidence": "4;3;4;4",
        "correctness": "4;3;4;4",
        "technical_novelty": "2;3;2;4",
        "empirical_novelty": "2;1;1;4",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.13245323570650439,
        "corr_rating_correctness": 0.13245323570650439,
        "project": "",
        "github": ""
    },
    {
        "id": "gdWQMQVJST",
        "title": "Neural Tangent Kernel Empowered Federated Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Federated Learning;Neural Tangent Kernel",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5",
        "confidence": "3;4;3;4",
        "correctness": "3;2;3;3",
        "technical_novelty": "2;3;2;2",
        "empirical_novelty": "2;1;2;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "gdegUuC_fxR",
        "title": "Hessian-Free High-Resolution Nesterov Acceleration for Sampling",
        "track": "main",
        "status": "Reject",
        "keywords": "Markov Chain Monte Carlo;Nesterov Accelerated Gradient;accelerated sampling",
        "author": "",
        "aff": "",
        "rating": "1;3;3;5;6;6",
        "confidence": "1;4;4;4;3;4",
        "correctness": "2;4;2;3;4;3",
        "technical_novelty": "1;3;3;3;3;2",
        "empirical_novelty": "1;2;2;3;3;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5780059766913392,
        "corr_rating_correctness": 0.5590169943749475,
        "project": "",
        "github": ""
    },
    {
        "id": "gehXu3kDU1P",
        "title": "Learning Algebraic Representation for Systematic Generalization in Abstract Reasoning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;6;8",
        "confidence": "3;3;3;3",
        "correctness": "2;4;4;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.4181210050035454,
        "project": "",
        "github": ""
    },
    {
        "id": "gex-2G2bLdh",
        "title": "Hinge Policy Optimization: Rethinking Policy Improvement and Reinterpreting PPO",
        "track": "main",
        "status": "Reject",
        "keywords": "Reinforcement learning;policy optimization;hinge loss;policy improvement;PPO-clip",
        "author": "",
        "aff": "",
        "rating": "3;5;6;8",
        "confidence": "5;4;4;2",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9544271444636667,
        "corr_rating_correctness": 0.8006407690254357,
        "project": "",
        "github": ""
    },
    {
        "id": "gf9buGzMCa",
        "title": "Expressiveness of Neural Networks Having Width Equal or Below the Input Dimension",
        "track": "main",
        "status": "Reject",
        "keywords": "Neural network approximation;expressiveness of width bounded neural networks;maximum principle",
        "author": "",
        "aff": "",
        "rating": "5;6;6;6",
        "confidence": "4;3;3;4",
        "correctness": "4;3;4;3",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "3;0;3;0",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "gfUPGPMxB7E",
        "title": "Data Sharing without Rewards in Multi-Task Offline Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "offline reinforcement learning;multi-task reinforcement learning",
        "author": "",
        "aff": "",
        "rating": "5;5;5",
        "confidence": "4;3;3",
        "correctness": "4;3;4",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "gfwON7rAm4",
        "title": "Global Convergence of Multi-Agent Policy Gradient in Markov Potential Games",
        "track": "main",
        "status": "Poster",
        "keywords": "Multi-agent Reinforcement Learning;Markov Potential Games;Policy Gradient",
        "author": "",
        "aff": "Singapore University of Technology and Design; University of California, Irvine",
        "rating": "5;6;8;8",
        "confidence": "3;3;3;4",
        "correctness": "4;4;4;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;2;0;2",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 3.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5555555555555555,
        "corr_rating_correctness": -0.5555555555555555,
        "project": "",
        "github": ""
    },
    {
        "id": "gggnCQBT_iE",
        "title": "Connecting Data to Mechanisms with Meta Structual Causal Model",
        "track": "main",
        "status": "Reject",
        "keywords": "meta-SCM;cyclic causal models;sufficient activated mechanisms",
        "author": "",
        "aff": "",
        "rating": "3;3;8",
        "confidence": "3;4;4",
        "correctness": "4;2;4",
        "technical_novelty": "2;2;4",
        "empirical_novelty": "0;1;4",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5000000000000001,
        "corr_rating_correctness": 0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "ghTlLwlBS-",
        "title": "Feudal Reinforcement Learning by Reading Manuals",
        "track": "main",
        "status": "Reject",
        "keywords": "feudal reinforcement learning;textual instruction following;reading to act;text games;multi-hop reasoning",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "5;2;4;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "4;3;3;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4736842105263159,
        "corr_rating_correctness": 0.13245323570650439,
        "project": "",
        "github": ""
    },
    {
        "id": "gi4956J8g5",
        "title": "Second-Order Unsupervised Feature Selection via Knowledge Contrastive Distillation",
        "track": "main",
        "status": "Reject",
        "keywords": "Machine Learning;Unsupervised Feature Selection;Knowledge Distillation",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6;8",
        "confidence": "5;4;4;4;4",
        "correctness": "3;3;3;3;3",
        "technical_novelty": "2;3;3;2;3",
        "empirical_novelty": "2;3;3;3;3",
        "presentation": "",
        "rating_avg": 5.6,
        "confidence_avg": 4.2,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 2.8,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8000946913656628,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "giBFoa-uS12",
        "title": "Iterated Reasoning with Mutual Information in Cooperative and Byzantine Decentralized Teaming",
        "track": "main",
        "status": "Poster",
        "keywords": "Multi-agent Reinforcement Learning;Cooperation and Coordination;Policy Gradient Optimization;Mutual Information;Iterated Reasoning",
        "author": "",
        "aff": "Georgia Institute of Technology, Atlanta, GA 30332, USA",
        "rating": "3;6;8",
        "confidence": "4;3;3",
        "correctness": "3;3;4",
        "technical_novelty": "3;2;4",
        "empirical_novelty": "2;2;4",
        "presentation": "",
        "rating_avg": 5.666666666666667,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9176629354822472,
        "corr_rating_correctness": 0.8029550685469661,
        "project": "",
        "github": ""
    },
    {
        "id": "gijKplIZ2Y-",
        "title": "Mistill: Distilling Distributed Network Protocols from Examples",
        "track": "main",
        "status": "Reject",
        "keywords": "communication networks;distributed protocols",
        "author": "",
        "aff": "",
        "rating": "5;5;6;8",
        "confidence": "3;4;4;2",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;0;0",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 1.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7385489458759963,
        "corr_rating_correctness": 0.8164965809277259,
        "project": "",
        "github": ""
    },
    {
        "id": "givsRXsOt9r",
        "title": "Spherical Message Passing for 3D Molecular Graphs",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "Department of Computer Science & Engineering, Texas A&M University, College Station, TX 77843, USA",
        "rating": "5;8;8",
        "confidence": "5;3;5",
        "correctness": "3;4;3",
        "technical_novelty": "3;3;4",
        "empirical_novelty": "2;3;4",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.3333333333333335,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5,
        "corr_rating_correctness": 0.5,
        "project": "",
        "github": "https://github.com/divelab/DIG"
    },
    {
        "id": "gjNcH0hj0LM",
        "title": "Coherence-based Label Propagation over Time Series for Accelerated Active Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "active learning;time series;pseudo labeling",
        "author": "",
        "aff": "NAVER AI Lab; University of Vermont; KAIST; UIUC; Institute for Basic Science",
        "rating": "6;6;6;10",
        "confidence": "3;3;2;4",
        "correctness": "3;4;3;4",
        "technical_novelty": "2;3;3;4",
        "empirical_novelty": "4;4;3;4",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.816496580927726,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "gmxgG6_BL_N",
        "title": "Variational Component Decoder for Source Extraction from Nonlinear Mixture",
        "track": "main",
        "status": "Reject",
        "keywords": "Source Extraction;Variational Inference;Disentanglement",
        "author": "",
        "aff": "",
        "rating": "3;5;8;8",
        "confidence": "4;4;4;2",
        "correctness": "3;3;4;4",
        "technical_novelty": "3;3;4;2",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5443310539518174,
        "corr_rating_correctness": 0.9428090415820635,
        "project": "",
        "github": ""
    },
    {
        "id": "gpp7cf0xdfN",
        "title": "Reverse Engineering of Imperceptible Adversarial Image Perturbations",
        "track": "main",
        "status": "Poster",
        "keywords": "Reverse Engineering of Deceptions;adversarial examples;denoising;neural networks;interpretability",
        "author": "",
        "aff": "",
        "rating": "6;6;8",
        "confidence": "4;2;4",
        "correctness": "4;3;3",
        "technical_novelty": "2;2;4",
        "empirical_novelty": "3;2;4",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5,
        "corr_rating_correctness": -0.49999999999999983,
        "project": "",
        "github": ""
    },
    {
        "id": "gtvM-nBZEbc",
        "title": "Learning Visual-Linguistic Adequacy, Fidelity, and Fluency for Novel Object Captioning",
        "track": "main",
        "status": "Reject",
        "keywords": "Semi-supervised Image Captioning;Novel Object Captioning",
        "author": "",
        "aff": "",
        "rating": "5;6;6;6",
        "confidence": "4;3;4;5",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;0;4",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "gxRcqTbJpVW",
        "title": "Structured Pruning Meets Orthogonality",
        "track": "main",
        "status": "Reject",
        "keywords": "network pruning;structured pruning;dynamical isometry;model compression",
        "author": "",
        "aff": "",
        "rating": "3;3;6;6",
        "confidence": "5;4;5;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 4.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896258,
        "project": "",
        "github": ""
    },
    {
        "id": "gxk4-rVATDA",
        "title": "Bit-wise Training of Neural Network Weights",
        "track": "main",
        "status": "Reject",
        "keywords": "quantization;pruning;bit-wise training;resnet;lenet",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "4;5;4;3",
        "correctness": "1;2;3;3",
        "technical_novelty": "2;1;2;3",
        "empirical_novelty": "1;2;3;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 4.0,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.816496580927726,
        "corr_rating_correctness": 0.8703882797784892,
        "project": "",
        "github": ""
    },
    {
        "id": "gzeruP-0J29",
        "title": "Revisiting and Advancing Fast Adversarial Training Through the lens of Bi-Level Optimization",
        "track": "main",
        "status": "Reject",
        "keywords": "fast adversarial training;bi-level optimization;adversarial robustness;adversarial defense",
        "author": "",
        "aff": "Paper under double-blind review",
        "rating": "3;5;5;6",
        "confidence": "4;5;4;4",
        "correctness": "2;2;3;3",
        "technical_novelty": "3;3;2;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.13245323570650439,
        "corr_rating_correctness": 0.6882472016116854,
        "project": "",
        "github": ""
    },
    {
        "id": "h-z_zqT2yJU",
        "title": "Reducing the Teacher-Student Gap via Adaptive Temperatures",
        "track": "main",
        "status": "Reject",
        "keywords": "Soft Labels;Knowledge distillation",
        "author": "",
        "aff": "",
        "rating": "5;6;6;6",
        "confidence": "4;4;4;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "h0OYV0We3oh",
        "title": "Illiterate DALL-E Learns to Compose",
        "track": "main",
        "status": "Poster",
        "keywords": "Zero-Shot Image Generation;Compositional Representation;Object-Centric Representation;Out-of-Distribution Generalization;Image Transformers",
        "author": "",
        "aff": "KAIST; Rutgers University",
        "rating": "6;6;6",
        "confidence": "5;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "2;3;2",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "https://sites.google.com/view/slate-autoencoder",
        "github": "https://github.com/singhgautam/slate"
    },
    {
        "id": "h4EOymDV3vV",
        "title": "Diffusion-Based Representation Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "5;5;4;3",
        "correctness": "3;4;2;4",
        "technical_novelty": "3;4;2;3",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7608859102526822,
        "corr_rating_correctness": 0.3458572319330373,
        "project": "",
        "github": ""
    },
    {
        "id": "hB2HIO39r8G",
        "title": "Refining Multimodal Representations using a modality-centric self-supervised module",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Multimodal modeling;self-supervision;metric learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;5;3;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7071067811865475,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "hC474P6AqN-",
        "title": "Unifying Categorical Models by Explicit Disentanglement of the Labels' Generative Factors",
        "track": "main",
        "status": "Reject",
        "keywords": "Disentanglement;explainability;latent representation",
        "author": "",
        "aff": "",
        "rating": "3;3;3;6",
        "confidence": "2;4;4;3",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.17407765595569782,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "hDQ-dYA8vB4",
        "title": "Towards Human-Understandable Visual Explanations: Human Imperceptible Cues Can Better Be Removed",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;3;6",
        "confidence": "4;4;4;3",
        "correctness": "2;2;2;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 3.75,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "hEiwVblq4P",
        "title": "Proper Straight-Through Estimator: Breaking symmetry promotes convergence to true minimum",
        "track": "main",
        "status": "Reject",
        "keywords": "quantization;binary network;low bit network;Straight through estimator;STE",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;5;3;3",
        "correctness": "3;4;2;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "1;0;0;0",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 0.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9045340337332909,
        "corr_rating_correctness": -0.7071067811865475,
        "project": "",
        "github": ""
    },
    {
        "id": "hGXij5rfiHw",
        "title": "Discovering Invariant Rationales for Graph Neural Networks",
        "track": "main",
        "status": "Poster",
        "keywords": "Interpretability;Graph Neural Networks;Causal Discovery;Invariant Learning",
        "author": "",
        "aff": "University of Science and Technology of China; National University of Singapore",
        "rating": "6;8;8",
        "confidence": "4;3;4",
        "correctness": "3;3;4",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;3;4",
        "presentation": "",
        "rating_avg": 7.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.49999999999999983,
        "corr_rating_correctness": 0.49999999999999983,
        "project": "",
        "github": "https://github.com/Wuyxin/DIR-GNN"
    },
    {
        "id": "hHmtmT58pSL",
        "title": "Don\u2019t throw away that linear head: Few-shot protein fitness prediction with generative models",
        "track": "main",
        "status": "Withdraw",
        "keywords": "language modeling;proteins;fitness prediction",
        "author": "",
        "aff": "Under double-blind review",
        "rating": "3;3;5;6",
        "confidence": "4;5;5;3",
        "correctness": "4;2;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "1;2;3;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 4.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5222329678670935,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "hJk11f5yfy",
        "title": "Encoding Hierarchical Information in Neural Networks Helps in Subpopulation Shift",
        "track": "main",
        "status": "Reject",
        "keywords": "Subpopulation shift;Hierarchical;Hierarchical Networks;Conditional Training;Domain Adaptation",
        "author": "",
        "aff": "",
        "rating": "3;5;5",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;3;2",
        "presentation": "",
        "rating_avg": 4.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "hLZHO-wzuqM",
        "title": "Benchmarking Algorithms from Machine Learning for Low-Budget Black-Box Optimization",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "3;4;3;4",
        "correctness": "3;3;2;4",
        "technical_novelty": "2;1;1;1",
        "empirical_novelty": "2;2;2;4",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 1.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "hNgDQPe8Uj",
        "title": "Learning Graph Augmentations to Learn Graph Representations",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 4.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "hOaYDFpQk3g",
        "title": "Taking ROCKET on an efficiency mission: A distributed solution for fast and accurate multivariate time series classification",
        "track": "main",
        "status": "Reject",
        "keywords": "distribution;time series;classification;multivariate;wavelet;scattering;feature selection;scaling",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5;5;6;6",
        "confidence": "4;3;4;4;3;4;4",
        "correctness": "2;2;2;2;3;3;3",
        "technical_novelty": "2;2;2;3;2;4;2",
        "empirical_novelty": "2;2;2;3;2;3;2",
        "presentation": "",
        "rating_avg": 4.428571428571429,
        "confidence_avg": 3.7142857142857144,
        "correctness_avg": 2.4285714285714284,
        "technical_novelty_avg": 2.4285714285714284,
        "empirical_novelty_avg": 2.2857142857142856,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.20952908873087348,
        "corr_rating_correctness": 0.8288497269823396,
        "project": "",
        "github": ""
    },
    {
        "id": "hP-SILoczR",
        "title": "NAS-Bench-Zero: A Large Scale Dataset for Understanding Zero-Shot Neural Architecture Search",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5;5",
        "confidence": "4;5;4;3;4",
        "correctness": "2;3;2;3;3",
        "technical_novelty": "2;2;2;3;2",
        "empirical_novelty": "2;3;2;0;2",
        "presentation": "",
        "rating_avg": 3.8,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6,
        "technical_novelty_avg": 2.2,
        "empirical_novelty_avg": 1.8,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6454972243679028,
        "corr_rating_correctness": 0.6666666666666667,
        "project": "",
        "github": ""
    },
    {
        "id": "hRVZd5g-z7",
        "title": "A Joint Subspace View to Convolutional Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "6;6;6;6;6",
        "confidence": "5;3;4;3;5",
        "correctness": "4;3;3;4;3",
        "technical_novelty": "2;3;2;2;2",
        "empirical_novelty": "2;3;3;3;2",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.4,
        "technical_novelty_avg": 2.2,
        "empirical_novelty_avg": 2.6,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "hR_SMu8cxCV",
        "title": "Scaling Laws for Neural Machine Translation",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Scaling Laws;Neural Machine Translation;NMT;Model Scaling",
        "author": "",
        "aff": "Google AI",
        "rating": "8;8;8;10",
        "confidence": "4;4;4;5",
        "correctness": "4;4;4;4",
        "technical_novelty": "2;3;3;4",
        "empirical_novelty": "4;3;3;4",
        "presentation": "",
        "rating_avg": 8.5,
        "confidence_avg": 4.25,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 1.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "hSktDu-h94",
        "title": "Automatic Loss Function Search for Predict-Then-Optimize Problems with Strong Ranking Property",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "London School of Economics and Political Science, United Kingdom; The Ohio State University, United States; Microsoft Research, China",
        "rating": "6;6;8",
        "confidence": "4;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "4;3;3",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.49999999999999983,
        "project": "",
        "github": ""
    },
    {
        "id": "hUr6K4D9f7P",
        "title": "Adversarial Weight Perturbation Improves Generalization in Graph Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "Graph neural networks;Adversarial weight perturbation",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "4;3;4;2",
        "correctness": "3;4;3;2",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4923659639173309,
        "corr_rating_correctness": -0.28867513459481287,
        "project": "",
        "github": ""
    },
    {
        "id": "hW2kwAcXq5w",
        "title": "Discriminator-Weighted Offline Imitation Learning from Suboptimal Demonstrations",
        "track": "main",
        "status": "Reject",
        "keywords": "imitation learning;offline imitation learning",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "3;3;3;4",
        "correctness": "2;3;2;3",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.6622661785325219,
        "corr_rating_correctness": 0.6882472016116854,
        "project": "",
        "github": ""
    },
    {
        "id": "h_kn4vXQp1x",
        "title": "Privacy Protected Multi-Domain Collaborative Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "4;4;4;4",
        "correctness": "4;3;4;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "hbGV3vzMPzG",
        "title": "On the Impact of Hard Adversarial Instances on Overfitting in Adversarial Training",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;6",
        "confidence": "4;5;4",
        "correctness": "3;3;3",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "2;1;3",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.18898223650461357,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "hcMvApxGSzZ",
        "title": "Fixed Neural Network Steganography: Train the images, not the network",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "Department of Computer Science, Cornell University, Ithaca, NY 14850, USA",
        "rating": "5;8;8;8",
        "confidence": "5;4;3;3",
        "correctness": "3;3;4;3",
        "technical_novelty": "3;3;3;2",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 7.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8703882797784892,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": "https://github.com/varshakishore/FNNS"
    },
    {
        "id": "hcQHRHKfN_",
        "title": "Continuously Discovering Novel Strategies via Reward-Switching Policy Optimization",
        "track": "main",
        "status": "Poster",
        "keywords": "diverse behavior;deep reinforcement learning;multi-agent reinforcement learning",
        "author": "",
        "aff": "CS Department, University of Toronto; IIIS, Tsinghua University; Shanghai Qi Zhi Institute",
        "rating": "5;8;8;8",
        "confidence": "3;3;4;3",
        "correctness": "2;4;4;4",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 7.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "hcoswsDHNAW",
        "title": "Fast AdvProp",
        "track": "main",
        "status": "Poster",
        "keywords": "Adversarial examples;efficient training;generalization",
        "author": "",
        "aff": "Nanyang Technological University; UC Santa Cruz; Johns Hopkins University",
        "rating": "5;5;8;8",
        "confidence": "4;4;4;5",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;2;3;4",
        "empirical_novelty": "2;2;3;4",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 4.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896258,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": "https://github.com/meijieru/fast_advprop"
    },
    {
        "id": "hdSn_X7Hfvz",
        "title": "Deep Probability Estimation",
        "track": "main",
        "status": "Reject",
        "keywords": "Probability estimation;calibration;uncertainty;weather forecasting;medical prognosis;car crash;benchmark datasets;deep learning;high dimensional data",
        "author": "",
        "aff": "",
        "rating": "1;5;5;6",
        "confidence": "4;4;4;3",
        "correctness": "1;3;4;3",
        "technical_novelty": "1;3;2;3",
        "empirical_novelty": "1;3;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5261522196019801,
        "corr_rating_correctness": 0.8661541520797733,
        "project": "",
        "github": ""
    },
    {
        "id": "hfU7Ka5cfrC",
        "title": "Scalable One-Pass Optimisation of High-Dimensional Weight-Update Hyperparameters by Implicit Differentiation",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Hyperparameter Optimisation",
        "author": "",
        "aff": "University of Cambridge; University of Cambridge, Alan Turing Institute",
        "rating": "6;8;8;8",
        "confidence": "3;3;4;4",
        "correctness": "3;4;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "3;3;2;3",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "hfjbX1UKNx",
        "title": "MCL-GAN: Generative Adversarial Networks with Multiple Specialized Discriminators",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5",
        "confidence": "4;4;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "3;3;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "hgKtwSb4S2",
        "title": "A generalization of the randomized singular value decomposition",
        "track": "main",
        "status": "Poster",
        "keywords": "Low rank approximation;Randomized SVD;Hilbert--Schmidt operators;Gaussian processes",
        "author": "",
        "aff": "Department of Mathematics, Cornell University, Ithaca, NY 14853, USA; Mathematical Institute, University of Oxford, Oxford, OX2 6GG, UK",
        "rating": "5;8;8",
        "confidence": "3;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "3;4;2",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5,
        "corr_rating_correctness": 0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "hjd-kcpDpf2",
        "title": "Maximizing Ensemble Diversity in Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "Ensemble Based Reinforcement Learning;Ensemble Diversity",
        "author": "",
        "aff": "Department of Computer Science, University of Central Florida; Intel Labs",
        "rating": "3;6;6;6",
        "confidence": "4;4;3;3",
        "correctness": "3;2;2;3",
        "technical_novelty": "2;2;1;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "hjlXybdILM3",
        "title": "When less is more: Simplifying inputs aids neural network understanding",
        "track": "main",
        "status": "Reject",
        "keywords": "interpretability;compression;network training",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "4;4;3;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "hk3Cxc2laT-",
        "title": "Clustered Task-Aware Meta-Learning by Learning from Learning Paths",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;6;6;6",
        "confidence": "4;4;4;2",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "hkXZKTAH5g-",
        "title": "Image Dataset Compression Based on Matrix Product States",
        "track": "main",
        "status": "Withdraw",
        "keywords": "dataset compression;matrix product state",
        "author": "",
        "aff": "",
        "rating": "1;3;5;5",
        "confidence": "4;4;3;4",
        "correctness": "1;1;4;2",
        "technical_novelty": "1;1;3;2",
        "empirical_novelty": "1;1;3;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.75,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5222329678670935,
        "corr_rating_correctness": 0.7385489458759963,
        "project": "",
        "github": ""
    },
    {
        "id": "hl9ePdHO4_s",
        "title": "Do We Need Anisotropic Graph Neural Networks?",
        "track": "main",
        "status": "Poster",
        "keywords": "graph neural networks;efficiency;latency reduction;memory reduction;architecture design;benchmarking;hardware-aware",
        "author": "",
        "aff": "Invenia Labs, Cambridge, UK; Samsung AI Center, Cambridge, UK; Department of Computer Science and Technology, University of Cambridge",
        "rating": "3;6;6;8",
        "confidence": "4;3;3;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;2;3;4",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8892972917998875,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/shyam196/egc"
    },
    {
        "id": "hm2tNDdgaFK",
        "title": "Learning 3D Representations of Molecular Chirality with Invariance to Bond Rotations",
        "track": "main",
        "status": "Poster",
        "keywords": "geometric deep learning;equivariance;molecules",
        "author": "",
        "aff": "Department of Chemical Engineering, Massachusetts Institute of Technology, Cambridge, MA 02139, USA; Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, Cambridge, MA 02139, USA",
        "rating": "5;6;8;8",
        "confidence": "4;3;4;5",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;3;4;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5443310539518174,
        "corr_rating_correctness": 0.9622504486493761,
        "project": "",
        "github": ""
    },
    {
        "id": "hniLRD_XCA",
        "title": "DeSKO: Stability-Assured Robust Control with a Deep Stochastic Koopman Operator",
        "track": "main",
        "status": "Poster",
        "keywords": "Koopman Operator;Robust Control;Robotics;Model Predictive Control;Soft Robotics",
        "author": "",
        "aff": "Department of Control Science and Engineering, Harbin Institute of Technology; Soft Robotics Lab, ETH Zurich",
        "rating": "6;6;6;8",
        "confidence": "5;3;2;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "3;3;2;2",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.2581988897471611,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "hopfHdHZGYe",
        "title": "TaCE: Time-aware Convolutional Embedding Learning for Temporal Knowledge Graph Completion",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Representation learning;temporal knowledge graph completion;knowledge graph embedding;convolutional neural networks",
        "author": "",
        "aff": "",
        "rating": "3;6;6;6",
        "confidence": "3;4;4;4",
        "correctness": "3;4;3;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 1.0,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "hpBTIv2uy_E",
        "title": "You are AllSet: A Multiset Function Framework for Hypergraph Neural Networks",
        "track": "main",
        "status": "Poster",
        "keywords": "Hypergraph neural networks;multiset functions;deep sets;set transformer",
        "author": "",
        "aff": "Department of Electrical and Computer Engineering, University of Illinois, Urbana-Champaign",
        "rating": "6;6;8;8",
        "confidence": "5;3;3;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.30151134457776363,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": "https://github.com/jianhao2016/AllSet"
    },
    {
        "id": "hq7vLjZTJPk",
        "title": "A Communication-Efficient Distributed Gradient Clipping Algorithm for Training Deep Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "Distributed Training;Federated Learning;Gradient Clipping;Communication-Efficient;Optimization",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;4;3;4",
        "correctness": "1;4;3;4",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.13245323570650439,
        "corr_rating_correctness": 0.9365858115816939,
        "project": "",
        "github": ""
    },
    {
        "id": "hqkN6lE1fFQ",
        "title": "Kernel Deformed Exponential Families for Sparse Continuous Attention",
        "track": "main",
        "status": "Reject",
        "keywords": "kernel methods;attention mechanism;theory;exponential families;deformed exponential families",
        "author": "",
        "aff": "",
        "rating": "3;5;6",
        "confidence": "2;3;2",
        "correctness": "4;3;4",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.18898223650461363,
        "corr_rating_correctness": -0.18898223650461363,
        "project": "",
        "github": ""
    },
    {
        "id": "hqkhcFHOeKD",
        "title": "Learning Towards The Largest Margins",
        "track": "main",
        "status": "Poster",
        "keywords": "loss function design;margin-based loss;classification",
        "author": "",
        "aff": "King Abdullah University of Science and Technology, Gaoling School of Arti\ufb01cial Intelligence, Renmin University of China; Harbin Institute of Technology, Peng Cheng Laboratory; Harbin Institute of Technology; Tsinghua University",
        "rating": "6;6;8;8",
        "confidence": "4;4;4;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "ht61oVsaya",
        "title": "DESTA: A Framework for Safe Reinforcement Learning with Markov Games of Intervention",
        "track": "main",
        "status": "Reject",
        "keywords": "Safe reinforcement learning;safety;Markov games;stochastic games",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "2;3;2;2",
        "correctness": "2;2;2;3",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "2;2;3;0",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 2.25,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "htWIlvDcY8",
        "title": "FALCON: Fast Visual Concept Learning by Integrating Images, Linguistic descriptions, and Conceptual Relations",
        "track": "main",
        "status": "Poster",
        "keywords": "Neuro-Symbolic Reasoning;Concept Learning;Meta-Learning",
        "author": "",
        "aff": "MIT CSAIL; MIT-IBM Watson AI Lab; MIT BCS, CBMM, CSAIL; UIUC",
        "rating": "5;6;8;8",
        "confidence": "3;3;4;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;2;4;3",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9622504486493761,
        "corr_rating_correctness": 0.9622504486493761,
        "project": "",
        "github": ""
    },
    {
        "id": "huXTh4GF2YD",
        "title": "Distance-Based Background Class Regularization for Open-Set Recognition",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;6;8",
        "confidence": "4;3;5;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "0;2;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.28867513459481287,
        "corr_rating_correctness": 0.9428090415820632,
        "project": "",
        "github": ""
    },
    {
        "id": "hw5Kug2Go3-",
        "title": "Prototypical Variational Autoencoders",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Variational Autoencoders;Latent Space Regularization",
        "author": "",
        "aff": "",
        "rating": "3;3;3",
        "confidence": "4;4;4",
        "correctness": "4;3;2",
        "technical_novelty": "3;3;2",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "hxitw01k_Ql",
        "title": "How memory architecture affects learning in a simple POMDP: the two-hypothesis testing problem",
        "track": "main",
        "status": "Reject",
        "keywords": "POMDP;memory architecture;optimization;reinforcement learning",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "3;3;3;2",
        "correctness": "4;2;2;4",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 2.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "hxznlKsIIKk",
        "title": "Leveraging Attribute Conditioning for Abstractive Multi Document Summarization",
        "track": "main",
        "status": "Withdraw",
        "keywords": "multi document summarization",
        "author": "",
        "aff": "",
        "rating": "1;1;3;3;3",
        "confidence": "5;4;4;3;4",
        "correctness": "2;2;2;3;3",
        "technical_novelty": "2;1;2;4;2",
        "empirical_novelty": "2;2;2;3;2",
        "presentation": "",
        "rating_avg": 2.2,
        "confidence_avg": 4.0,
        "correctness_avg": 2.4,
        "technical_novelty_avg": 2.2,
        "empirical_novelty_avg": 2.2,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6454972243679028,
        "corr_rating_correctness": 0.6666666666666667,
        "project": "",
        "github": ""
    },
    {
        "id": "hyuacPZQFb0",
        "title": "A Systematic Evaluation of Domain Adaptation Algorithms On Time Series Data",
        "track": "main",
        "status": "Reject",
        "keywords": "domain adaptation;time series data;benchmarking",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5;5",
        "confidence": "3;5;3;4;4",
        "correctness": "3;4;3;2;3",
        "technical_novelty": "1;2;3;1;3",
        "empirical_novelty": "2;2;3;2;3",
        "presentation": "",
        "rating_avg": 4.6,
        "confidence_avg": 3.8,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5345224838248488,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "hzmQ4wOnSb",
        "title": "GNN is a Counter? Revisiting GNN for Question Answering",
        "track": "main",
        "status": "Poster",
        "keywords": "GNN;Question Answering;QA;Reasoning;ML",
        "author": "",
        "aff": "Microsoft Research Asia; Georgia Institute of Technology; BioMap",
        "rating": "5;6;8;8",
        "confidence": "3;5;3;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;4;3;3",
        "empirical_novelty": "2;4;3;4",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.058025885318565944,
        "corr_rating_correctness": 0.5555555555555555,
        "project": "",
        "github": ""
    },
    {
        "id": "i--G7mhB19P",
        "title": "Depth Without the Magic: Inductive Bias of Natural Gradient Descent",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5;6",
        "confidence": "3;3;2;3;3",
        "correctness": "3;4;3;3;4",
        "technical_novelty": "3;2;3;2;3",
        "empirical_novelty": "0;1;2;2;3",
        "presentation": "",
        "rating_avg": 5.2,
        "confidence_avg": 2.8,
        "correctness_avg": 3.4,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 1.6,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.25000000000000006,
        "corr_rating_correctness": 0.6123724356957947,
        "project": "",
        "github": ""
    },
    {
        "id": "i1ogYhs0ByT",
        "title": "Transformer with a Mixture of Gaussian Keys",
        "track": "main",
        "status": "Reject",
        "keywords": "transformer;gaussian mixture model;attention heads;attention keys",
        "author": "",
        "aff": "",
        "rating": "5;6;6;8;8",
        "confidence": "5;4;3;4;4",
        "correctness": "3;3;3;3;3",
        "technical_novelty": "2;3;3;3;3",
        "empirical_novelty": "1;3;2;3;2",
        "presentation": "",
        "rating_avg": 6.6,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.8,
        "empirical_novelty_avg": 2.2,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.2635231383473649,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "i2baoZMYZ3",
        "title": "Continuous Control with Action Quantization from Demonstrations",
        "track": "main",
        "status": "Reject",
        "keywords": "Deep Reinforcement Learning;Action Discretization;Learning from Demonstrations",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "5;4;4;5",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;3;4",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 4.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "i3RI65sR7N",
        "title": "Hierarchical Variational Memory for Few-shot Learning Across Domains",
        "track": "main",
        "status": "Poster",
        "keywords": "Meta-learning;Variational hierarchical memory;Variational hierarchical prototype;Cross-domain few-shot learning",
        "author": "",
        "aff": "National Center for Artificial Intelligence, Saudi Data and Artificial Intelligence Authority; AIM Lab, University of Amsterdam and Inception Institute of Artificial Intelligence; AIM Lab, University of Amsterdam",
        "rating": "5;6;8",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;3;0",
        "presentation": "",
        "rating_avg": 6.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "i3abvoMoeCZ",
        "title": "Exploring Covariate and Concept Shift for Detection and Confidence Calibration of Out-of-Distribution Data",
        "track": "main",
        "status": "Reject",
        "keywords": "out-of-distribution detection;calibration;distribution shift",
        "author": "",
        "aff": "Paper under double-blind review",
        "rating": "3;5;5;6",
        "confidence": "4;4;5;2",
        "correctness": "2;3;3;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4736842105263159,
        "corr_rating_correctness": 0.9733285267845754,
        "project": "",
        "github": ""
    },
    {
        "id": "i4qKmHdq6y8",
        "title": "Learning to Abstain in the Presence of Uninformative Data",
        "track": "main",
        "status": "Reject",
        "keywords": "Selective learning;Uninformative data;PAC Learning;Sample Complexity",
        "author": "",
        "aff": "",
        "rating": "3;6;6;6",
        "confidence": "4;2;2;3",
        "correctness": "4;4;4;4",
        "technical_novelty": "3;3;4;3",
        "empirical_novelty": "2;2;3;0",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 2.75,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8703882797784892,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "i7-BqPD1e5",
        "title": "Adversarial Attack across Datasets",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6;6",
        "confidence": "4;4;4;5;4",
        "correctness": "3;3;3;3;4",
        "technical_novelty": "3;2;3;3;3",
        "empirical_novelty": "3;3;2;3;2",
        "presentation": "",
        "rating_avg": 5.4,
        "confidence_avg": 4.2,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.8,
        "empirical_novelty_avg": 2.6,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.6123724356957945,
        "corr_rating_correctness": 0.6123724356957945,
        "project": "",
        "github": ""
    },
    {
        "id": "i7FNvHnPvPc",
        "title": "Boosting the Transferability of Adversarial Attacks with Reverse Adversarial Perturbation",
        "track": "main",
        "status": "Reject",
        "keywords": "Adversarial Examples;Black-Box Attacks;Adversarial Transferability",
        "author": "",
        "aff": "Under double-blind review",
        "rating": "5;6;6;6",
        "confidence": "4;3;4;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;2;4;3",
        "empirical_novelty": "2;4;4;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "i7O3VGpb7qZ",
        "title": "Code Editing from Few Exemplars by Adaptive Multi-Extent Composition",
        "track": "main",
        "status": "Reject",
        "keywords": "code editing;few-shot learning;compositional generalization",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "2;4;3;4",
        "correctness": "3;4;3;4",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "3;2;2;2",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5222329678670935,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "i7h4M45tU8",
        "title": "Neural Temporal Logic Programming",
        "track": "main",
        "status": "Reject",
        "keywords": "logic programming;time series;neuro-symbolic;video;healthcare",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "3;3;3;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "1;2;3;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "i8d2kdxii1L",
        "title": "$p$-Laplacian Based Graph Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "Graph neural networks;$p$-Laplacian;semi-supervised learning;node prediction",
        "author": "",
        "aff": "",
        "rating": "3;5;8",
        "confidence": "4;4;3",
        "correctness": "2;3;4",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9176629354822472,
        "corr_rating_correctness": 0.9933992677987828,
        "project": "",
        "github": ""
    },
    {
        "id": "iARgLYsH2P",
        "title": "Disentangled Mask Attention in Transformer",
        "track": "main",
        "status": "Withdraw",
        "keywords": "sequential learning;mask attention;latent disentanglement;transformer",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "3;2;4;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5222329678670935,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "iC4UHbQ01Mp",
        "title": "Poisoning and Backdooring Contrastive Learning",
        "track": "main",
        "status": "Oral",
        "keywords": "Contrastive Learning;Poisoning attack;Backdoor attack;CLIP",
        "author": "",
        "aff": "Google",
        "rating": "8;8;8;8",
        "confidence": "3;4;4;3",
        "correctness": "4;4;4;3",
        "technical_novelty": "3;4;3;2",
        "empirical_novelty": "3;4;3;4",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "iEvAf8i6JjO",
        "title": "TRGP: Trust Region Gradient Projection for Continual Learning",
        "track": "main",
        "status": "Spotlight",
        "keywords": "trust region;gradient projection;scaled weight projection;continual learning;forward knowledge transfer;task correlation",
        "author": "",
        "aff": "School of ECEE, Arizona State University; Department of ECE, University of California, Davis",
        "rating": "3;6;8;8",
        "confidence": "4;4;3;4",
        "correctness": "2;3;3;4",
        "technical_novelty": "2;3;4;4",
        "empirical_novelty": "2;2;3;4",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.49374193110101877,
        "corr_rating_correctness": 0.8638684255813602,
        "project": "",
        "github": ""
    },
    {
        "id": "iEx3PiooLy",
        "title": "VAT-Mart: Learning Visual Action Trajectory Proposals for Manipulating 3D ARTiculated Objects",
        "track": "main",
        "status": "Poster",
        "keywords": "Visual Representation Learning for Robotics;Robotic Affordance and Trajectories;3D Shape Understanding",
        "author": "",
        "aff": "CFCS, CS Dept., PKU; CFCS, CS Dept., PKU and AIIT, PKU; Tencent AI Lab; Stanford University",
        "rating": "6;6;6",
        "confidence": "3;3;4",
        "correctness": "3;3;4",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "3;3;2",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "https://hyperplane-lab.github.io/vat-mart",
        "github": ""
    },
    {
        "id": "iFf26yMjRdN",
        "title": "Federated Learning with Partial Model Personalization",
        "track": "main",
        "status": "Reject",
        "keywords": "personalization;federated learning;partial personalization;adapter modules;nonconvex minimization",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;4;4",
        "correctness": "4;4;4;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "iGffRQ9jQpQ",
        "title": "Enhancing semi-supervised learning via self-interested coalitional learning",
        "track": "main",
        "status": "Reject",
        "keywords": "self-interested coalitional learning;semi-supervised learning;soft labeling;loss reweighting",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;3;3;3",
        "correctness": "2;4;3;4",
        "technical_novelty": "2;4;3;3",
        "empirical_novelty": "2;4;3;2",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9271726499455306,
        "corr_rating_correctness": 0.899228803025897,
        "project": "",
        "github": ""
    },
    {
        "id": "iJ_nnX5Qvyt",
        "title": "Combinatorial Reinforcement Learning Based Scheduling for DNN Execution on Edge",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Reinforcement Learning;Combinatorial Optimization;Edge Computing",
        "author": "",
        "aff": "",
        "rating": "3;3;3",
        "confidence": "5;4;3",
        "correctness": "2;2;2",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "iLHOIDsPv1P",
        "title": "PAC-Bayes Information Bottleneck",
        "track": "main",
        "status": "Spotlight",
        "keywords": "information bottleneck;representation learning;generalization",
        "author": "",
        "aff": "UIUC; Tencent; Tsinghua University",
        "rating": "6;6;8;10",
        "confidence": "3;3;2;3",
        "correctness": "3;3;4;4",
        "technical_novelty": "4;2;4;4",
        "empirical_novelty": "3;2;3;4",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 2.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.5,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.17407765595569782,
        "corr_rating_correctness": 0.9045340337332909,
        "project": "",
        "github": ""
    },
    {
        "id": "iMH1e5k7n3L",
        "title": "Spike-inspired rank coding for fast and accurate recurrent neural networks",
        "track": "main",
        "status": "Spotlight",
        "keywords": "",
        "author": "",
        "aff": "University College London, UK; Huawei Technologies \u2013 Zurich, Switzerland; ACS Lab, Huawei Technologies, Shenzhen, China",
        "rating": "8;8;8",
        "confidence": "4;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "3;3;0",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "iMSjopcOn0p",
        "title": "MT3: Multi-Task Multitrack Music Transcription",
        "track": "main",
        "status": "Spotlight",
        "keywords": "music transcription;transformer;multi-task learning;low resource learning;music understanding;music information retrieval",
        "author": "",
        "aff": "Interactive Audio Lab, Northwestern University; Google Research, Brain Team",
        "rating": "8;8;8;8",
        "confidence": "4;5;3;4",
        "correctness": "4;4;3;3",
        "technical_novelty": "4;2;3;3",
        "empirical_novelty": "4;4;3;4",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "https://storage.googleapis.com/mt3/index.html",
        "github": ""
    },
    {
        "id": "iMqTLyfwnOO",
        "title": "Augmented Sliced Wasserstein Distances",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "University of Surrey; University of Edinburgh, Huawei Noah\u2019s Ark Lab",
        "rating": "6;6;6;6",
        "confidence": "3;3;4;3",
        "correctness": "4;4;4;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "0;3;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.25,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "iPHLcmtietq",
        "title": "Phase Collapse in Neural Networks",
        "track": "main",
        "status": "Poster",
        "keywords": "phase collapse;neural collapse;concentration;classification;imagenet;deep networks;complex networks;sparsity in deep networks",
        "author": "",
        "aff": "Coll\u00e8ge de France, Paris, France; Flatiron Institute, New York, USA; DI, ENS, CNRS, PSL University, Paris, France",
        "rating": "6;6;8;8",
        "confidence": "2;4;4;3",
        "correctness": "4;3;3;3",
        "technical_novelty": "3;3;4;2",
        "empirical_novelty": "3;3;4;2",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.30151134457776363,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "iRCUlgmdfHJ",
        "title": "DISCOVERING AND EXPLAINING THE REPRESENTATION BOTTLENECK OF DNNS",
        "track": "main",
        "status": "Oral",
        "keywords": "representation bottleneck;representation ability;interaction;explanation",
        "author": "",
        "aff": "Shanghai Jiao Tong University; Shanghai Jiao Tong University, John Hopcroft Center and the MOE Key Lab of Artifical Intelligence, AI Institute",
        "rating": "8;8;8;10",
        "confidence": "4;3;4;4",
        "correctness": "3;4;3;3",
        "technical_novelty": "3;4;3;4",
        "empirical_novelty": "3;4;3;3",
        "presentation": "",
        "rating_avg": 8.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.5,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": "https://github.com/Nebularaid2000/bottleneck"
    },
    {
        "id": "iUt2KYdXBDD",
        "title": "Value Refinement Network (VRN)",
        "track": "main",
        "status": "Withdraw",
        "keywords": "reinforcement learning;learning to plan;navigation",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;4;3;4",
        "correctness": "3;3;2;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "1;2;3;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "iUuzzTMUw9K",
        "title": "StyleNeRF: A Style-based 3D Aware Generator for High-resolution Image Synthesis",
        "track": "main",
        "status": "Poster",
        "keywords": "Neural Radiance Field;StyleGAN;high resolution image generation",
        "author": "",
        "aff": "Meta AI; Max Planck Institute for Informatics; The University of Hong Kong",
        "rating": "6;6;8;10",
        "confidence": "5;4;5;3",
        "correctness": "4;2;4;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 4.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6363636363636364,
        "corr_rating_correctness": 0.5222329678670935,
        "project": "",
        "github": "https://github.com/facebookresearch/StyleNeRF"
    },
    {
        "id": "iaqgio-pOv",
        "title": "Analogies and Feature Attributions for Model Agnostic Explanation of Similarity Learners",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "1;5;6;6;6",
        "confidence": "5;4;3;3;3",
        "correctness": "2;3;3;3;3",
        "technical_novelty": "2;2;3;2;2",
        "empirical_novelty": "1;2;3;2;3",
        "presentation": "",
        "rating_avg": 4.8,
        "confidence_avg": 3.6,
        "correctness_avg": 2.8,
        "technical_novelty_avg": 2.2,
        "empirical_novelty_avg": 2.2,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9540646527893837,
        "corr_rating_correctness": 0.9798501839458537,
        "project": "",
        "github": ""
    },
    {
        "id": "iaxWbVx-CG_",
        "title": "Hierarchical Cross Contrastive Learning of Visual Representations",
        "track": "main",
        "status": "Reject",
        "keywords": "Self-supervised Learning;Unsupervised Learning;Computer Vision",
        "author": "",
        "aff": "",
        "rating": "5;6;6;6",
        "confidence": "4;5;3;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "ib8vMnQPQ2",
        "title": "PIM-QAT: Neural Network Quantization For Processing-In-Memory (PIM) Systems",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Processing In-Memory System;Neuromorphic System;Deep Learning;Training Dynamics;Neural Network Quantization",
        "author": "",
        "aff": "",
        "rating": "3;5;5",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 4.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "ibNr25jJrf",
        "title": "Direct Evolutionary Optimization of Variational Autoencoders With Binary Latents",
        "track": "main",
        "status": "Reject",
        "keywords": "variational optimization;variational autoencoders;denoising;inpainting;evolutionary algorithms",
        "author": "",
        "aff": "",
        "rating": "5;5;6;8;8",
        "confidence": "4;4;2;4;3",
        "correctness": "3;4;3;4;4",
        "technical_novelty": "2;3;3;4;3",
        "empirical_novelty": "2;3;2;4;3",
        "presentation": "",
        "rating_avg": 6.4,
        "confidence_avg": 3.4,
        "correctness_avg": 3.6,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.8,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.1474419561548971,
        "corr_rating_correctness": 0.5417363388859615,
        "project": "",
        "github": ""
    },
    {
        "id": "ibqTBNfJmi",
        "title": "Frequency-aware SGD for Efficient Embedding Learning with Provable Benefits",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "Meta; ISyE, Georgia Tech",
        "rating": "6;6;6;8",
        "confidence": "3;3;2;3",
        "correctness": "3;3;4;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 2.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "ibrUkC-pbis",
        "title": "Neural Models for Output-Space Invariance in Combinatorial Problems",
        "track": "main",
        "status": "Poster",
        "keywords": "neural reasoning;output space invariance",
        "author": "",
        "aff": "Department of Computer Science, Indian Institute of Technology Delhi, INDIA",
        "rating": "5;6;8",
        "confidence": "3;3;3",
        "correctness": "2;4;3",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 6.333333333333333,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.3273268353539886,
        "project": "",
        "github": ""
    },
    {
        "id": "ieNJYujcGDO",
        "title": "Towards Understanding the Data Dependency of Mixup-style Training",
        "track": "main",
        "status": "Spotlight",
        "keywords": "mixup;deep learning;semi-supervised learning;empirical risk minimization;generalization;margin;counterexample",
        "author": "",
        "aff": "University of Illinois at Urbana-Champaign; Duke University",
        "rating": "3;6;8",
        "confidence": "3;4;2",
        "correctness": "3;3;3",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 5.666666666666667,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3973597071195132,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "iedYJm92o0a",
        "title": "Show Your Work: Scratchpads for Intermediate Computation with Language Models",
        "track": "main",
        "status": "Reject",
        "keywords": "program synthesis;transformers;language models;pre-training;program induction",
        "author": "",
        "aff": "",
        "rating": "3;3;8;8",
        "confidence": "5;4;4;4",
        "correctness": "1;2;3;4",
        "technical_novelty": "2;2;4;3",
        "empirical_novelty": "3;2;4;0",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 4.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.8944271909999159,
        "project": "",
        "github": ""
    },
    {
        "id": "iim-R8xu0TG",
        "title": "FitVid: High-Capacity Pixel-Level Video Prediction",
        "track": "main",
        "status": "Reject",
        "keywords": "video prediction;self supervised learning;unsupervised learning;robotics",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "4;4;3;2",
        "correctness": "4;3;3;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "3;3;2;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8703882797784891,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "ijygjHyhcFp",
        "title": "Anarchic Federated Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;4;4;3",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6622661785325219,
        "corr_rating_correctness": 0.6882472016116854,
        "project": "",
        "github": ""
    },
    {
        "id": "in1ynkrXyMH",
        "title": "Introspective Learning : A Two-Stage approach for Inference in Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "Reasoning;Knowledge Representation;Robustness;Recognition",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "4;4;3;3",
        "correctness": "2;2;3;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "0;3;2;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8164965809277259,
        "corr_rating_correctness": 0.8164965809277259,
        "project": "",
        "github": ""
    },
    {
        "id": "inA3szzFE5",
        "title": "Spatial Frequency Sensitivity Regularization for Robustness",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "5;4;3;3",
        "correctness": "2;3;4;4",
        "technical_novelty": "2;2;3;4",
        "empirical_novelty": "1;2;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9847319278346618,
        "corr_rating_correctness": 0.9847319278346618,
        "project": "",
        "github": ""
    },
    {
        "id": "inSTvgLk2YP",
        "title": "MeshInversion: 3D textured mesh reconstruction with generative prior",
        "track": "main",
        "status": "Reject",
        "keywords": "Single-view 3D object reconstruction;GAN inversion",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;3;4;4",
        "correctness": "2;2;2;4",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.75,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.13245323570650439,
        "corr_rating_correctness": 0.6622661785325219,
        "project": "",
        "github": ""
    },
    {
        "id": "irARV_2VFs4",
        "title": "Focus on the Common Good: Group Distributional Robustness Follows",
        "track": "main",
        "status": "Poster",
        "keywords": "sub-population shift;robust optimization;domain generalization",
        "author": "",
        "aff": "Indian Institute of Technology, Bombay; Google Research, India",
        "rating": "3;6;6;8",
        "confidence": "4;3;4;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;3;4;4",
        "empirical_novelty": "3;3;4;4",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.08084520834544431,
        "corr_rating_correctness": 0.08084520834544431,
        "project": "",
        "github": "URL provided in the paper"
    },
    {
        "id": "iulEMLYh1uR",
        "title": "The Efficiency Misnomer",
        "track": "main",
        "status": "Poster",
        "keywords": "Efficiency in Machine Learning;FLOPs;Number of Parameters;Throughput",
        "author": "",
        "aff": "Google Research",
        "rating": "5;5;6;8",
        "confidence": "4;4;4;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.8164965809277259,
        "project": "",
        "github": ""
    },
    {
        "id": "ivQruZvXxtz",
        "title": "Sequential Reptile: Inter-Task Gradient Alignment for Multilingual Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "multilingual language model;gradient alignment",
        "author": "",
        "aff": "KAIST1, AITRICS2, South Korea",
        "rating": "5;5;5;6",
        "confidence": "5;4;4;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "0;2;3;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.816496580927726,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "iw-ms2znSS2",
        "title": "The Remarkable Effectiveness of Combining Policy and Value Networks in A*-based Deep RL for AI Planning",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "1;3;5;6",
        "confidence": "5;4;4;4",
        "correctness": "2;2;2;2",
        "technical_novelty": "2;2;3;4",
        "empirical_novelty": "1;2;2;3",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 4.25,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8268106308031117,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "iy2b91gvZpf",
        "title": "LDDMM-Face: Large Deformation Diffeomorphic Metric Learning for Cross-annotation Face Alignment",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Cross-annotation Face Alignment;Large Deformation Diffeomorphic Metric Mapping;Sparsely-supervised Learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;8",
        "confidence": "5;5;5;4",
        "correctness": "3;2;3;4",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "1;2;2;4",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9169493006161777,
        "corr_rating_correctness": 0.8638684255813602,
        "project": "",
        "github": ""
    },
    {
        "id": "izj68lUcBpt",
        "title": "TAda! Temporally-Adaptive Convolutions for Video Understanding",
        "track": "main",
        "status": "Poster",
        "keywords": "Video understanding;Action classification;Dynamic networks",
        "author": "",
        "aff": "Advanced Robotics Centre, National University of Singapore; S-Lab, Nanyang Technological University; DAMO Academy, Alibaba Group",
        "rating": "5;6;6;8",
        "confidence": "4;4;4;3",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9271726499455306,
        "corr_rating_correctness": 0.6882472016116854,
        "project": "https://tadaconv-iclr2022.github.io/",
        "github": ""
    },
    {
        "id": "izvwgBic9q",
        "title": "Unsupervised Learning of Full-Waveform Inversion: Connecting CNN and Partial Differential Equation in a Loop",
        "track": "main",
        "status": "Poster",
        "keywords": "Unsupervised Learning;Full-Waveform Inversion;Partial Differential Equation;Physics-Informed Machine Learning",
        "author": "",
        "aff": "",
        "rating": "3;5;8",
        "confidence": "5;4;4",
        "correctness": "2;3;3",
        "technical_novelty": "2;2;4",
        "empirical_novelty": "2;2;4",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8029550685469661,
        "corr_rating_correctness": 0.8029550685469661,
        "project": "",
        "github": ""
    },
    {
        "id": "j-63FSNcO5a",
        "title": "Learning Disentangled Representation by Exploiting Pretrained Generative Models: A Contrastive Learning View",
        "track": "main",
        "status": "Poster",
        "keywords": "Latent space discovery;Disentangled representation learning;Generative models;Contrastive learning",
        "author": "",
        "aff": "Microsoft Research Asia; Xi'an Jiaotong University; EIT; HKUST",
        "rating": "6;6;8;8",
        "confidence": "4;4;5;4",
        "correctness": "3;4;4;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;3;4",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": "https://github.com/xrenaa/DisCo"
    },
    {
        "id": "j30wC0JM39Q",
        "title": "Why do embedding spaces look as they do?",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;2;3;4",
        "correctness": "2;4;3;3",
        "technical_novelty": "3;3;3;2",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5222329678670935,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "j3krplz_4w6",
        "title": "Fooling Explanations in Text Classifiers",
        "track": "main",
        "status": "Poster",
        "keywords": "robustness;explainability;text classification;natural language processing",
        "author": "",
        "aff": "\u00b4Ecole Polytechnique F \u00b4ed\u00b4erale de Lausanne (EPFL), Lausanne, Switzerland; IBM Research Zurich, R\u00a8uschlikon, Switzerland",
        "rating": "5;5;6",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "j8J97VgdmsT",
        "title": "FLAME-in-NeRF: Neural control of Radiance Fields for Free View Face Animation",
        "track": "main",
        "status": "Reject",
        "keywords": "Neural Rendering;Facial Reanimation;3D Scene Priors",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;4;5",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;0;3;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "j97zf-nLhC",
        "title": "Zero-Shot Coordination via Semantic Relationships Between Actions and Observations",
        "track": "main",
        "status": "Reject",
        "keywords": "multi-agent communication;multi-agent reinforcement learning;attention mechanism;zero-shot coordination",
        "author": "",
        "aff": "",
        "rating": "6;6;6;6",
        "confidence": "2;4;3;3",
        "correctness": "3;4;3;3",
        "technical_novelty": "3;3;3;2",
        "empirical_novelty": "2;3;4;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "jDK19MUBT4_",
        "title": "TailMix: Overcoming the Label Sparsity for Extreme Multi-label Classification",
        "track": "main",
        "status": "Withdraw",
        "keywords": "NLP;classification;extreme multi-label learning;data augmentation",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;0;3;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "jE_ipyh20rb",
        "title": "FedProf: Selective Federated Learning with Representation Profiling",
        "track": "main",
        "status": "Reject",
        "keywords": "federated learning;neural network;representation learning;distributed computing",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "3;4;4;3",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;3;2;2",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.2294157338705618,
        "corr_rating_correctness": 0.13245323570650439,
        "project": "",
        "github": ""
    },
    {
        "id": "jFfRcKVut98",
        "title": "Learning Equivariances and Partial Equivariances From Data",
        "track": "main",
        "status": "Reject",
        "keywords": "group equivariance;learning equivariances from data;partial equivariance;group convolutional networks.",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "5;3;4;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;3;3;4",
        "empirical_novelty": "2;2;2;4",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "jFlWZEv6dv",
        "title": "AlignMix: Improving representations by interpolating aligned features",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;6",
        "confidence": "4;5;4",
        "correctness": "3;4;3",
        "technical_novelty": "3;3;2",
        "empirical_novelty": "3;2;2",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4999999999999999,
        "corr_rating_correctness": -0.4999999999999999,
        "project": "",
        "github": ""
    },
    {
        "id": "jGmNTfiXwGb",
        "title": "Learning Predictive, Online Approximations of Explanatory, Offline Algorithms",
        "track": "main",
        "status": "Reject",
        "keywords": "multi-task learning;machine learning;online algorithms;offline algorithms",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6;6",
        "confidence": "4;4;2;2;3",
        "correctness": "1;1;3;4;2",
        "technical_novelty": "3;3;4;3;3",
        "empirical_novelty": "0;2;4;3;3",
        "presentation": "",
        "rating_avg": 4.6,
        "confidence_avg": 3.0,
        "correctness_avg": 2.2,
        "technical_novelty_avg": 3.2,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8242255917447339,
        "corr_rating_correctness": 0.8091547798786779,
        "project": "",
        "github": "[GitHub repository redacted for review]"
    },
    {
        "id": "jJJWwrMrEsx",
        "title": "Truth Table Deep Convolutional Neural Network, A New SAT-Encodable Architecture - Application To Complete Robustness",
        "track": "main",
        "status": "Reject",
        "keywords": "AI Safety;SAT-encodable Neural Network;Formal Verification;Complete Verification Robustness;Interpretability;Logic Rules;XAI",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;3;4",
        "correctness": "3;2;2;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "jJOjjiZHy3h",
        "title": "Defending Against Image Corruptions Through Adversarial Augmentations",
        "track": "main",
        "status": "Poster",
        "keywords": "robustness;adversarial training;image corruptions",
        "author": "",
        "aff": "Meta; DeepMind",
        "rating": "6;6;6;8",
        "confidence": "4;3;5;3",
        "correctness": "3;4;4;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;0;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5222329678670935,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "jJWK09skiNl",
        "title": "Zero-shot detection of daily objects in YCB video dataset",
        "track": "main",
        "status": "Reject",
        "keywords": "zero-shot learning;object detection;multi-label learning;attribute vector",
        "author": "",
        "aff": "",
        "rating": "1;1;1;3;3",
        "confidence": "5;5;4;4;4",
        "correctness": "2;1;3;2;3",
        "technical_novelty": "1;1;1;1;1",
        "empirical_novelty": "1;1;1;1;2",
        "presentation": "",
        "rating_avg": 1.8,
        "confidence_avg": 4.4,
        "correctness_avg": 2.2,
        "technical_novelty_avg": 1.0,
        "empirical_novelty_avg": 1.2,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6666666666666665,
        "corr_rating_correctness": 0.32732683535398854,
        "project": "",
        "github": ""
    },
    {
        "id": "jJis-v9Pzhj",
        "title": "Positive-Unlabeled Learning with Uncertainty-aware Pseudo-label Selection",
        "track": "main",
        "status": "Reject",
        "keywords": "positive-unlabeled learning;semi-supervised learning;pseudo-labeling;deep ensembles;uncertainty quantification",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "5;4;4;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;1;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "jKzjSZYsrGP",
        "title": "SCformer: Segment Correlation Transformer for Long Sequence Time Series Forecasting",
        "track": "main",
        "status": "Reject",
        "keywords": "Transformer;time series forecasting;sparse attention",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;5;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "jLClifZ6YER",
        "title": "Fast fixed-backbone protein sequence and rotamer design",
        "track": "main",
        "status": "Withdraw",
        "keywords": "protein design;imitation learning;attention;graph networks",
        "author": "",
        "aff": "",
        "rating": "",
        "confidence": "",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "jM62SQw28f",
        "title": "DeepFIB: Self-Imputation for Time Series Anomaly Detection",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Time series anomaly detection;self-supervised learning;time series imputation",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5;5",
        "confidence": "4;5;4;4;5",
        "correctness": "3;2;2;2;3",
        "technical_novelty": "2;2;2;3;3",
        "empirical_novelty": "2;2;0;2;3",
        "presentation": "",
        "rating_avg": 3.8,
        "confidence_avg": 4.4,
        "correctness_avg": 2.4,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 1.8,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.16666666666666669,
        "corr_rating_correctness": 0.16666666666666663,
        "project": "",
        "github": ""
    },
    {
        "id": "jNB6vfl_680",
        "title": "Global Magnitude Pruning With Minimum Threshold Is All We Need",
        "track": "main",
        "status": "Reject",
        "keywords": "Pruning;Model Compression;One-shot;Global Magnitude Pruning",
        "author": "",
        "aff": "",
        "rating": "3;5;6",
        "confidence": "5;5;2",
        "correctness": "3;3;3",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "2;0;2",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 1.3333333333333333,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7559289460184545,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/GPMT-Authors/Global-Pruning-With-Minimum-Threshold"
    },
    {
        "id": "jNsynsmDkl",
        "title": "Contrastively Enforcing Distinctiveness for Multi-Label Classification",
        "track": "main",
        "status": "Reject",
        "keywords": "Multi-label Classification;Contrastive learning",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "4;4;4;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;3;0;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "jPwC2MMI85Y",
        "title": "A molecular hypergraph convolutional network with functional group information",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Molecule;Functional group;graph;hypergraph;chemistry",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "4;3;2;5",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.2581988897471611,
        "corr_rating_correctness": 0.9622504486493761,
        "project": "",
        "github": ""
    },
    {
        "id": "jT1EwXu-4hj",
        "title": "From Intervention to Domain Transportation: A Novel Perspective to Optimize Recommendation",
        "track": "main",
        "status": "Poster",
        "keywords": "Information retrieval;Learning theory;Causal inference;Missing data;Overlapping;Reweighting;Optimal transport",
        "author": "",
        "aff": "Division of Biostatistics, University of California, Berkeley, Berkeley, CA 94720, USA; Instacart, San Francisco, CA 94107, USA; Walmart Labs, Sunnyvale, CA 94086, USA",
        "rating": "5;6;6;6",
        "confidence": "4;3;3;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "jT5vnpqlrSN",
        "title": "GIR Framework: Learning Graph Positional Embeddings with Anchor Indication and Path Encoding",
        "track": "main",
        "status": "Reject",
        "keywords": "Graph neural networks;Anchor based GNN;Node representation learning",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "3;4;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "3;3;2;2",
        "empirical_novelty": "2;3;2;2",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "jT9EDW9_PWF",
        "title": "GCN-SL: Graph Convolutional Network with Structure Learning for Disassortative Graphs",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Graph neural networks;disassortative graphs;representation learning;structure learning.",
        "author": "",
        "aff": "",
        "rating": "3;3;3",
        "confidence": "5;4;5",
        "correctness": "3;3;2",
        "technical_novelty": "2;2;1",
        "empirical_novelty": "2;3;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 1.6666666666666667,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "jWaLuyg6OEw",
        "title": "First-Order Optimization Inspired from Finite-Time Convergent Flows",
        "track": "main",
        "status": "Reject",
        "keywords": "Dynamical systems;continuous-time optimization flows;first-order optimization;DNN applications",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "3;4;4;4",
        "correctness": "4;3;3;3",
        "technical_novelty": "2;3;2;2",
        "empirical_novelty": "0;2;2;2",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "jWxuLQE31IL",
        "title": "Efficient Winning Tickets Drawing over Fine-Grained Structured Sparsity",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Pruning;Lottery Ticket Hypothesis",
        "author": "",
        "aff": "",
        "rating": "3;3;5",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "2;1;2",
        "empirical_novelty": "2;1;3",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 1.6666666666666667,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "jXKKDEi5vJt",
        "title": "Byzantine-Robust Learning on Heterogeneous Datasets via Bucketing",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Federated learning;Distributed learning;Byzantine robust optimization;Heterogeneity (Non-IID)",
        "author": "",
        "aff": "EPFL",
        "rating": "6;8;8;10",
        "confidence": "4;4;3;5",
        "correctness": "3;3;4;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "jZQOWas0Lo3",
        "title": "Cycle monotonicity of adversarial attacks for optimal domain adaptation",
        "track": "main",
        "status": "Reject",
        "keywords": "Optimal Transport;Domain Adaptation;Adversarial Attacks",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;4;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;3;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "jaLDP8Hp_gc",
        "title": "Visual Correspondence Hallucination",
        "track": "main",
        "status": "Poster",
        "keywords": "visual correspondence hallucination;camera pose estimation",
        "author": "",
        "aff": "LIGM, \u00c9cole des Ponts, Univ Gustave Eiffel, CNRS, Marne-la-Vall\u00e9e, France; IMS, University of Bordeaux, Bordeaux INP, CNRS, Bordeaux, France",
        "rating": "5;8;8",
        "confidence": "4;3;4",
        "correctness": "3;3;4",
        "technical_novelty": "2;3;4",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5,
        "corr_rating_correctness": 0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "jbrgwbv8nD",
        "title": "Constraining Linear-chain CRFs to Regular Languages",
        "track": "main",
        "status": "Poster",
        "keywords": "constrained training;probabilistic graphical models;CRF;semantic role labeling;sequence labeling",
        "author": "",
        "aff": "University of Stuttgart",
        "rating": "5;6;6;8",
        "confidence": "4;4;4;4",
        "correctness": "2;3;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.7608859102526822,
        "project": "",
        "github": ""
    },
    {
        "id": "jeLW-Fh9bV",
        "title": "Skill-based Meta-Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "meta-RL;meta-reinforcement learning;skill-based meta-reinforcement learning;meta-learning;skill-based RL",
        "author": "",
        "aff": "Korea Advanced Institute of Science and Technology, AITRICS; Korea Advanced Institute of Science and Technology; University of Southern California; Korea Advanced Institute of Science and Technology, Naver AI Lab",
        "rating": "6;6;6;8",
        "confidence": "4;4;4;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "https://namsan96.github.io/SiMPL",
        "github": ""
    },
    {
        "id": "jf3q5f-uedA",
        "title": "Autonomous Shaping of Latent-Spaces from Reduced PDEs for Physical Neural Networks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "latent space representations;reduced PDE solvers;partial differential equations;differentiable physics",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "3;4;3;3",
        "correctness": "2;3;3;3",
        "technical_novelty": "4;3;3;3",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9428090415820632,
        "project": "",
        "github": ""
    },
    {
        "id": "jgAl403zfau",
        "title": "HALP: Hardware-Aware Latency Pruning",
        "track": "main",
        "status": "Reject",
        "keywords": "Efficient deep learning;deep neural network pruning;latency reduction;hardware-aware pruning",
        "author": "",
        "aff": "",
        "rating": "5;6;6;6",
        "confidence": "3;5;5;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;3;4;3",
        "empirical_novelty": "2;3;4;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 4.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8703882797784891,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "jkpT8c7jal4",
        "title": "On Deep Neural Network Calibration by Regularization and its Impact on Refinement",
        "track": "main",
        "status": "Withdraw",
        "keywords": "calibration;refinement",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "3;4;4;3",
        "correctness": "2;2;1;3",
        "technical_novelty": "3;2;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.5,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "jm0Ppu7xvok",
        "title": "An Optimally Weighted Echo State Neural Network for Highly Chaotic Time Series Modelling",
        "track": "main",
        "status": "Withdraw",
        "keywords": "time series;neural networks;young stellar objects",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "5;4;3;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;1",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "jm1RxJFQdDN",
        "title": "Perturbation Diversity Certificates Robust Generalisation",
        "track": "main",
        "status": "Withdraw",
        "keywords": "adversarial example;robust generalisation;adversarial training",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "5;4;3;3",
        "correctness": "2;2;3;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.75,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8703882797784892,
        "corr_rating_correctness": 0.9622504486493761,
        "project": "",
        "github": ""
    },
    {
        "id": "js62_xuLDDv",
        "title": "Is Fairness Only Metric Deep? Evaluating and Addressing Subgroup Gaps in Deep Metric Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "deep metric learning;fairness;representation learning",
        "author": "",
        "aff": "University of Toronto & Vector Institute; MIT; University of T\u00fcbingen",
        "rating": "6;6;6;8",
        "confidence": "4;4;3;3",
        "correctness": "3;3;3;4",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "jxTRL-VOoQo",
        "title": "Evaluating Deep Graph Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "Deep;Graph Neural Networks",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "4;5;5;4",
        "correctness": "2;2;2;3",
        "technical_novelty": "2;1;2;3",
        "empirical_novelty": "2;1;3;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 4.5,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.19245008972987526,
        "corr_rating_correctness": 0.7777777777777777,
        "project": "",
        "github": ""
    },
    {
        "id": "jxdyknFeCqO",
        "title": "Full-Precision Free Binary Graph Neural Networks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Graph Neural Networks;Binary Neural Networks;Mixture of Experts",
        "author": "",
        "aff": "",
        "rating": "3;3;3",
        "confidence": "5;2;4",
        "correctness": "2;3;3",
        "technical_novelty": "3;2;2",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "k-ES3OH7eqp",
        "title": "De novo design of protein target specific scaffold-based Inhibitors via Reinforcement Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Protein target specific molecular design;reinforcement learning;Graph Neural Networks;Lead molecule optimization;Drug Discovery;and Protein-ligand interaction.",
        "author": "",
        "aff": "Paper under double-blind review",
        "rating": "1;3;3;3",
        "confidence": "4;4;4;4",
        "correctness": "2;2;1;3",
        "technical_novelty": "1;2;2;2",
        "empirical_novelty": "0;2;2;3",
        "presentation": "",
        "rating_avg": 2.5,
        "confidence_avg": 4.0,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "k-sNDIPY-1T",
        "title": "Modelling neuronal behaviour with time series regression: Recurrent Neural Networks on synthetic C. elegans data",
        "track": "main",
        "status": "Reject",
        "keywords": "Data-driven models;RNNs;LSTMs;GRUs;C. Elegans;Time series regression;black-box",
        "author": "",
        "aff": "Paper under double-blind review",
        "rating": "3;6;8",
        "confidence": "5;5;4",
        "correctness": "3;4;4",
        "technical_novelty": "1;3;2",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 5.666666666666667,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8029550685469661,
        "corr_rating_correctness": 0.9176629354822472,
        "project": "",
        "github": ""
    },
    {
        "id": "k0pi7xDoDTC",
        "title": "IID-GAN: an IID Sampling Perspective for Regularizing Mode Collapse",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;4;3;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "1;2;2;2",
        "empirical_novelty": "1;2;1;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "k32ZY1CmE0",
        "title": "How to train RNNs on chaotic data?",
        "track": "main",
        "status": "Reject",
        "keywords": "dynamical systems;back-propagation through time;chaos;recurrent neural networks;LSTM;Lyapunov spectrum;time series",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "4;4;3;4",
        "correctness": "2;3;4;4",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.9045340337332909,
        "project": "",
        "github": ""
    },
    {
        "id": "k4jzOHrZ7F5",
        "title": "Interpreting Black-boxes Using Primitive Parameterized Functions",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Interpretability;Symbolic Metamodeling;Symbolic Regression",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "4;3;4;5",
        "correctness": "2;2;3;3",
        "technical_novelty": "2;2;2;4",
        "empirical_novelty": "2;2;0;2",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 4.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.816496580927726,
        "corr_rating_correctness": 0.9622504486493761,
        "project": "",
        "github": ""
    },
    {
        "id": "k6F-4Bw7LpV",
        "title": "Distributional Generalization: Structure Beyond Test Error",
        "track": "main",
        "status": "Reject",
        "keywords": "generalization;empirical phenomena;overparameterization",
        "author": "",
        "aff": "",
        "rating": "3;5;6",
        "confidence": "3;3;3",
        "correctness": "3;3;4",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;2;4",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.7559289460184545,
        "project": "",
        "github": ""
    },
    {
        "id": "k7-s5HSSPE5",
        "title": "Cross-Lingual Transfer with Class-Weighted Language-Invariant Representations",
        "track": "main",
        "status": "Poster",
        "keywords": "cross-lingual transfer;unsupervised cross-lingual learning;multilingual neural language model;domain adaptation",
        "author": "",
        "aff": "Department of Computer Science, University of Illinois Urbana-Champaign, Urbana, IL 61801, USA",
        "rating": "6;6;6;6",
        "confidence": "3;4;3;5",
        "correctness": "3;4;2;3",
        "technical_novelty": "4;3;2;2",
        "empirical_novelty": "4;3;2;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/rxian/domain-alignment"
    },
    {
        "id": "k7efTb0un9z",
        "title": "Learning to Schedule Learning rate with Graph Neural Networks",
        "track": "main",
        "status": "Poster",
        "keywords": "learning rate scheduling;graph neural networks",
        "author": "",
        "aff": "Department of Computer Science, UCLA; UCLA",
        "rating": "6;6;6;6;8",
        "confidence": "3;4;3;4;4",
        "correctness": "3;3;3;3;4",
        "technical_novelty": "3;2;3;2;3",
        "empirical_novelty": "3;3;2;2;3",
        "presentation": "",
        "rating_avg": 6.4,
        "confidence_avg": 3.6,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 2.6,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.408248290463863,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": "https://github.com/xyh97/GNS"
    },
    {
        "id": "k9bx1EfHI_-",
        "title": "Self-Supervised Graph Neural Networks for Improved Electroencephalographic Seizure Analysis",
        "track": "main",
        "status": "Poster",
        "keywords": "Graph neural network;Self-supervision;Interpretability;Visualization;Neuroscience;Electroencephalography;Seizure;Epilepsy;Time Series",
        "author": "",
        "aff": "Stanford University, CA, USA",
        "rating": "6;8;8",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 7.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "kAa9eDS0RdO",
        "title": "Attention-based Interpretability with Concept Transformers",
        "track": "main",
        "status": "Poster",
        "keywords": "attention;transformer;concepts;interpretability",
        "author": "",
        "aff": "IBM Research, Zurich, Switzerland",
        "rating": "5;5;6;8",
        "confidence": "5;4;4;4",
        "correctness": "2;4;3;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "1;2;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4714045207910316,
        "corr_rating_correctness": 0.4923659639173309,
        "project": "",
        "github": "https://github.com/ibm/concept_transformer"
    },
    {
        "id": "kDF4Owotj5j",
        "title": "Thinking Deeper With Recurrent Networks: Logical Extrapolation Without Overthinking",
        "track": "main",
        "status": "Reject",
        "keywords": "Deep learning;recurrent networks;thinking;extrapolation;generalization",
        "author": "",
        "aff": "",
        "rating": "5;5;6;8",
        "confidence": "4;4;4;5",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;1;3;4",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9428090415820632,
        "corr_rating_correctness": 0.9428090415820632,
        "project": "",
        "github": ""
    },
    {
        "id": "kEvhVb452CC",
        "title": "Transformed CNNs: recasting pre-trained convolutional layers with self-attention",
        "track": "main",
        "status": "Reject",
        "keywords": "convolutional networks;transformers;hybrid;fine-tuning",
        "author": "",
        "aff": "",
        "rating": "5;6;6;6",
        "confidence": "2;4;3;4",
        "correctness": "3;4;3;1",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8703882797784891,
        "corr_rating_correctness": -0.13245323570650439,
        "project": "",
        "github": ""
    },
    {
        "id": "kF9DZQQrU0w",
        "title": "Information Bottleneck: Exact Analysis of (Quantized) Neural Networks",
        "track": "main",
        "status": "Poster",
        "keywords": "information bottleneck;quantization;neural network",
        "author": "",
        "aff": "Department of Computer Science, University of Copenhagen",
        "rating": "6;6;8",
        "confidence": "4;5;3",
        "correctness": "3;3;4",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "3;2;4",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8660254037844385,
        "corr_rating_correctness": 0.9999999999999998,
        "project": "",
        "github": ""
    },
    {
        "id": "kG0AtPi6JI1",
        "title": "Visual Representation Learning over Latent Domains",
        "track": "main",
        "status": "Poster",
        "keywords": "transfer learning;latent domains;computer vision",
        "author": "",
        "aff": "University of Edinburgh",
        "rating": "3;6;6;6",
        "confidence": "2;2;3;3",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "3;3;3;2",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 2.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "kHNKTO2sYH",
        "title": "Repairing Systematic Outliers by Learning Clean Subspaces in VAEs",
        "track": "main",
        "status": "Reject",
        "keywords": "variational autoencoder;deep generative models;outlier detection;data repair",
        "author": "",
        "aff": "",
        "rating": "6;6;6",
        "confidence": "2;4;3",
        "correctness": "4;2;4",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "kHkWgqOysk_",
        "title": "On Pseudo-Labeling for Class-Mismatch Semi-Supervised Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;6;6;6",
        "confidence": "5;3;4;4",
        "correctness": "3;4;3;4",
        "technical_novelty": "2;4;3;4",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.816496580927726,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "kK3DlGuusi",
        "title": "Quantized sparse PCA for neural network weight compression",
        "track": "main",
        "status": "Reject",
        "keywords": "Model Compression;neural network quantization;sparse principal component analysis;vector quantization",
        "author": "",
        "aff": "",
        "rating": "1;5;8",
        "confidence": "5;3;3",
        "correctness": "2;3;4",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "1;2;3",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9041944301794652,
        "corr_rating_correctness": 0.996615895540124,
        "project": "",
        "github": ""
    },
    {
        "id": "kNKFOXleuC",
        "title": "Anytime Dense Prediction with Confidence Adaptivity",
        "track": "main",
        "status": "Poster",
        "keywords": "Efficient Inference;Anytime Inference;Semantic Segmentation;Dense Prediction;Computer Vision",
        "author": "",
        "aff": "University of California, Berkeley; Adobe Research",
        "rating": "6;6;6;8",
        "confidence": "3;4;4;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/liuzhuang13/anytime"
    },
    {
        "id": "kO-wQWwqnO",
        "title": "L2BGAN: An image enhancement model for image quality improvement and image analysis tasks without paired supervision",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;5;3;3",
        "correctness": "3;2;3;3",
        "technical_novelty": "1;1;2;2",
        "empirical_novelty": "1;1;2;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 1.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9045340337332909,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "kOtkgUGAVTX",
        "title": "CIC: Contrastive Intrinsic Control for Unsupervised Skill Discovery",
        "track": "main",
        "status": "Reject",
        "keywords": "unsupervised learning;reinforcement learning;exploration",
        "author": "",
        "aff": "",
        "rating": "3;6;8;8",
        "confidence": "3;4;4;3",
        "correctness": "2;4;3;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "3;3;4;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3665083330689157,
        "corr_rating_correctness": 0.5183210553488161,
        "project": "",
        "github": ""
    },
    {
        "id": "kOu3-S3wJ7",
        "title": "Filling the G_ap_s: Multivariate Time Series Imputation by Graph Neural Networks",
        "track": "main",
        "status": "Poster",
        "keywords": "graph neural networks;missing data;time series analysis;time series imputation",
        "author": "",
        "aff": "1The Swiss AI Lab IDSIA, Universit `a della Svizzera italiana2Politecnico di Milano; The Swiss AI Lab IDSIA, Universit `a della Svizzera italiana",
        "rating": "6;6;8;8",
        "confidence": "2;3;4;3",
        "correctness": "4;3;3;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.7071067811865475,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "kQ2SOflIOVC",
        "title": "Towards Better Understanding and Better Generalization of Low-shot Classification in Histology Images with Contrastive Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "Few shot learning;Histology Image;Knowledge Transferring",
        "author": "",
        "aff": "Tencent AI Lab, UC Los Angeles; Tencent AI Lab, Xiamen University; Tencent AI Lab, Tsinghua University; Tencent AI Lab",
        "rating": "5;6;6;8;8",
        "confidence": "3;3;4;4;4",
        "correctness": "4;3;3;3;4",
        "technical_novelty": "3;3;3;2;3",
        "empirical_novelty": "2;3;3;3;4",
        "presentation": "",
        "rating_avg": 6.6,
        "confidence_avg": 3.6,
        "correctness_avg": 3.4,
        "technical_novelty_avg": 2.8,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.748455199183749,
        "corr_rating_correctness": -0.06804138174397723,
        "project": "",
        "github": "https://github.com/TencentAILabHealthcare/Few-shot-WSI"
    },
    {
        "id": "kQMXLDF_z20",
        "title": "Tackling Oversmoothing of GNNs with Contrastive Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "graph mining;oversmoothing;contrastive learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "4;5;4;4",
        "correctness": "3;2;3;3",
        "technical_novelty": "2;1;2;3",
        "empirical_novelty": "2;1;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5555555555555555,
        "corr_rating_correctness": 0.5555555555555555,
        "project": "",
        "github": ""
    },
    {
        "id": "kQns9y_JH6",
        "title": "Improved Fine-tuning by Leveraging Pre-training Data: Theory and Practice",
        "track": "main",
        "status": "Withdraw",
        "keywords": "pre-training;fine-tuning;generalization theory",
        "author": "",
        "aff": "",
        "rating": "3;5;6",
        "confidence": "4;4;3",
        "correctness": "2;3;3",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "3;3;4",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 3.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7559289460184545,
        "corr_rating_correctness": 0.9449111825230683,
        "project": "",
        "github": ""
    },
    {
        "id": "kR1hC6j48Tp",
        "title": "GATSBI: Generative Adversarial Training for Simulation-Based Inference",
        "track": "main",
        "status": "Poster",
        "keywords": "Machine Learning;simulation-based inference;generative adversarial networks;approximate bayesian computation;data-driven modelling;GANs;SBI;likelihood-free inference;implicit models",
        "author": "",
        "aff": "Helmholtz Centre Hereon; University of T\u00fcbingen; TU Munich",
        "rating": "5;6;6;8",
        "confidence": "4;3;5;4",
        "correctness": "3;4;4;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.2294157338705618,
        "project": "",
        "github": ""
    },
    {
        "id": "kSqyNY_QrD9",
        "title": "Learning to Solve Multi-Robot Task Allocation with a Covariant-Attention based Neural Architecture",
        "track": "main",
        "status": "Reject",
        "keywords": "MRTA;Reinforcement learning;graph learning",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6;8",
        "confidence": "4;2;3;3;3",
        "correctness": "2;3;3;3;3",
        "technical_novelty": "2;2;3;2;3",
        "empirical_novelty": "3;3;3;3;0",
        "presentation": "",
        "rating_avg": 5.6,
        "confidence_avg": 3.0,
        "correctness_avg": 2.8,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3892494720807615,
        "corr_rating_correctness": 0.8000946913656628,
        "project": "",
        "github": ""
    },
    {
        "id": "kSwqMH0zn1F",
        "title": "PipeGCN: Efficient Full-Graph Training of Graph Convolutional Networks with Pipelined Feature Communication",
        "track": "main",
        "status": "Poster",
        "keywords": "Graph Neural Networks;Graph Convolutional Networks;Distributed Training;Asynchronous Training;Full-Graph Training;Large-Graph Training;Stale Features",
        "author": "",
        "aff": "Rice University; UIUC",
        "rating": "6;6;6;6",
        "confidence": "4;4;3;3",
        "correctness": "3;3;4;3",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/RICE-EIC/PipeGCN"
    },
    {
        "id": "kTcRljax0x9",
        "title": "Assessing Deep Reinforcement Learning Policies via Natural Corruptions at the Edge of Imperceptibility",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "1;3;5;5;6",
        "confidence": "5;4;4;4;4",
        "correctness": "4;4;3;4;3",
        "technical_novelty": "1;2;3;2;3",
        "empirical_novelty": "2;2;3;2;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.2,
        "correctness_avg": 3.6,
        "technical_novelty_avg": 2.2,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8385254915624213,
        "corr_rating_correctness": -0.6846531968814576,
        "project": "",
        "github": ""
    },
    {
        "id": "kUGYDTJUcuc",
        "title": "Unifying Top-down and Bottom-up for Recurrent Visual Attention",
        "track": "main",
        "status": "Reject",
        "keywords": "visual attention model;reinforcement learning",
        "author": "",
        "aff": "",
        "rating": "3;3;6",
        "confidence": "4;4;2",
        "correctness": "3;3;4",
        "technical_novelty": "2;2;4",
        "empirical_novelty": "2;2;4",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "kUtux8k0G6y",
        "title": "Avoiding Robust Misclassifications for Improved Robustness without Accuracy Loss",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "Paper under double-blind review",
        "rating": "3;5;5;8",
        "confidence": "4;3;3;3",
        "correctness": "3;4;3;4",
        "technical_novelty": "1;2;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7276068751089989,
        "corr_rating_correctness": 0.7001400420140049,
        "project": "",
        "github": ""
    },
    {
        "id": "kW05eAYtOma",
        "title": "Rethinking Pareto Approaches in Constrained Reinforcement Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Constrained Reinforcement Learning;Pareto optimization;Constrained Markov Decision Process",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5",
        "confidence": "4;3;3;3",
        "correctness": "2;3;3;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "kWuBTQmkO8_",
        "title": "MixRL: Data Mixing Augmentation for Regression using Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "data augmentation;regression;mixup;reinforcement learning",
        "author": "",
        "aff": "",
        "rating": "3;5;5",
        "confidence": "4;3;4",
        "correctness": "2;3;3",
        "technical_novelty": "2;3;2",
        "empirical_novelty": "2;3;2",
        "presentation": "",
        "rating_avg": 4.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.49999999999999983,
        "corr_rating_correctness": 0.9999999999999998,
        "project": "",
        "github": ""
    },
    {
        "id": "kZ0UYdhqkNY",
        "title": "Variational methods for simulation-based inference",
        "track": "main",
        "status": "Spotlight",
        "keywords": "likelihood-free inference;simulation-based inference;variational inference;neural density estimation",
        "author": "",
        "aff": "University of T\u00fcbingen",
        "rating": "6;6;8;8",
        "confidence": "4;3;4;3",
        "correctness": "4;4;4;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "k_Zy6glYaqc",
        "title": "Quantum Alphatron",
        "track": "main",
        "status": "Desk Reject",
        "keywords": "",
        "author": "",
        "aff": "Paper under double-blind review",
        "rating": "",
        "confidence": "",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "kamUXjlAZuw",
        "title": "On Learning with Fairness Trade-Offs",
        "track": "main",
        "status": "Reject",
        "keywords": "fairness;statistical learning;PAC;social welfare",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;4;4;2",
        "correctness": "3;4;2;4",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.5222329678670935,
        "project": "",
        "github": ""
    },
    {
        "id": "kavTY__jxp",
        "title": "Spatial Graph Attention and Curiosity-driven Policy for Antiviral Drug Discovery",
        "track": "main",
        "status": "Poster",
        "keywords": "reinforcement learning;graph neural network;molecule generation;drug discovery;curiosity-driven policy",
        "author": "",
        "aff": "Argonne National Laboratory & University of Chicago; Pacifiic Northwest National Laboratory & National Virtual Biotechnology Laboratory, US Department of Energy; University of Tennessee, Knoxville & Oak Ridge National Laboratory & National Virtual Biotechnology Laboratory, US Department of Energy; Argonne National Laboratory & National Virtual Biotechnology Laboratory, US Department of Energy; University of California, Berkeley & National Virtual Biotechnology Laboratory, US Department of Energy; Lawrence Berkeley National Laboratory & National Virtual Biotechnology Laboratory, US Department of Energy; University of Chicago; Oak Ridge National Laboratory & National Virtual Biotechnology Laboratory, US Department of Energy",
        "rating": "6;6;8",
        "confidence": "3;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;0;3",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.49999999999999983,
        "corr_rating_correctness": -0.49999999999999983,
        "project": "",
        "github": ""
    },
    {
        "id": "kcadk-DShNO",
        "title": "Why be adversarial? Let's cooperate!: Cooperative Dataset Alignment via JSD Upper Bound",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;6;6",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "4;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 3.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "kcrIligNnl",
        "title": "Direct Molecular Conformation Generation",
        "track": "main",
        "status": "Reject",
        "keywords": "Molecular Conformation Generation",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "3;5;3;5",
        "correctness": "3;2;4;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;0;2;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.40824829046386296,
        "corr_rating_correctness": 0.28867513459481287,
        "project": "",
        "github": "https://github.com/DirectMolecularConfGen/DMCG"
    },
    {
        "id": "kcwyXtt7yDJ",
        "title": "Graph-Relational Domain Adaptation",
        "track": "main",
        "status": "Poster",
        "keywords": "Graphs;Network Topology;Transfer Learning;Domain Adaptation;Adversarial Learning",
        "author": "",
        "aff": "AWS AI Labs; Massachusetts Institute of Technology; Rutgers University",
        "rating": "5;6;6",
        "confidence": "5;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "3;3;2",
        "empirical_novelty": "2;3;0",
        "presentation": "",
        "rating_avg": 5.666666666666667,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8660254037844385,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/Wang-ML-Lab/GRDA"
    },
    {
        "id": "keQjAwuC7j-",
        "title": "Two Birds, One Stone: Achieving both Differential Privacy and Certified Robustness for Pre-trained Classifiers via Input Perturbation",
        "track": "main",
        "status": "Reject",
        "keywords": "Differential Privacy;Certified Robustness;Pre-trained Classifiers;Input Perturbation",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "4;4;3;4",
        "correctness": "2;3;4;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.8703882797784892,
        "project": "",
        "github": ""
    },
    {
        "id": "keeCvPPd3vL",
        "title": "Improved Image Generation via Sparsity",
        "track": "main",
        "status": "Reject",
        "keywords": "Sparse Modeling;Image Generation",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "3;4;3;3",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5555555555555555,
        "corr_rating_correctness": 0.5555555555555555,
        "project": "",
        "github": ""
    },
    {
        "id": "kezNJydWvE",
        "title": "Clean Images are Hard to Reblur: Exploiting the Ill-Posed Inverse Task for Dynamic Scene Deblurring",
        "track": "main",
        "status": "Poster",
        "keywords": "Deblur;Reblur;Loss;Test-time adaptation;Self-supervised",
        "author": "",
        "aff": "ASRI, Department of ECE, Seoul National University, Seoul, Korea; NVIDIA; ASRI, Department of ECE, Seoul National University, Seoul, Korea",
        "rating": "5;6;8",
        "confidence": "4;4;4",
        "correctness": "2;3;4",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "0;3;3",
        "presentation": "",
        "rating_avg": 6.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9819805060619659,
        "project": "",
        "github": ""
    },
    {
        "id": "kfug4WKP_Jq",
        "title": "SS-MAIL: Self-Supervised Multi-Agent Imitation Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Imitation Learning;Generative Models;Multi-Agent;Time-Series Prediction",
        "author": "",
        "aff": "",
        "rating": "3;3;3",
        "confidence": "3;4;2",
        "correctness": "2;2;2",
        "technical_novelty": "3;2;2",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "kiNEOCSEzt",
        "title": "Estimating and Penalizing Induced Preference Shifts in Recommender Systems",
        "track": "main",
        "status": "Reject",
        "keywords": "recommender systems;preference shift;preference estimation;preference tampering",
        "author": "",
        "aff": "",
        "rating": "5;6;6;6",
        "confidence": "4;3;3;4",
        "correctness": "2;4;3;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;3;0",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "kiwu8tcVf38",
        "title": "Momentum as Variance-Reduced Stochastic Gradient",
        "track": "main",
        "status": "Withdraw",
        "keywords": "momentum;variance reduction",
        "author": "",
        "aff": "",
        "rating": "1;3;3;3;3",
        "confidence": "3;4;5;3;4",
        "correctness": "1;3;3;3;4",
        "technical_novelty": "2;2;1;2;3",
        "empirical_novelty": "1;2;1;1;1",
        "presentation": "",
        "rating_avg": 2.6,
        "confidence_avg": 3.8,
        "correctness_avg": 2.8,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.2,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5345224838248487,
        "corr_rating_correctness": 0.9185586535436916,
        "project": "",
        "github": ""
    },
    {
        "id": "kj0_45Y4r9i",
        "title": "Discriminative Similarity for Data Clustering",
        "track": "main",
        "status": "Poster",
        "keywords": "Discriminative Similarity;Rademacher Complexity;Generalization Bound;Data Clustering",
        "author": "",
        "aff": "School of Computing and Augmented Intelligence, Arizona State University, Tempe, AZ 85281, USA; Cognitive Computing Lab, Baidu Research, Bellevue, WA 98004, USA",
        "rating": "5;6;6;8",
        "confidence": "3;3;4;5",
        "correctness": "2;3;4;4",
        "technical_novelty": "2;3;3;4",
        "empirical_novelty": "2;3;3;4",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.899228803025897,
        "corr_rating_correctness": 0.7608859102526822,
        "project": "",
        "github": ""
    },
    {
        "id": "kj8TBnJ0SXh",
        "title": "FaceDet3D: Facial Expressions with 3D Geometric Detail Hallucination",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "3;3;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "2;0;1;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "kkgh_x_DBSM",
        "title": "Protecting Proprietary Data: Poisoning for Secure Dataset Release",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Secure Dataset Release;Data Poisoning;Availability Attack",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "3;4;4;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5555555555555555,
        "corr_rating_correctness": 0.5555555555555555,
        "project": "",
        "github": ""
    },
    {
        "id": "kl8flCo98nm",
        "title": "LEARNING DISTRIBUTIONS GENERATED BY SINGLE-LAYER RELU NETWORKS IN THE PRESENCE OF ARBITRARY OUTLIERS",
        "track": "main",
        "status": "Reject",
        "keywords": "Learning distribution;ReLU;Truncated Gaussian;Unsupervised learning",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "3;3;4;3",
        "correctness": "3;4;4;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "0;1;0;0",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 0.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "kocM6lVTIfJ",
        "title": "Feature Shapley: A general framework to discovering useful feature interactions",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Feature Learning;Shapley Value;Click-through Rate;Asset Pricing",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "5;3;4;3",
        "correctness": "4;3;3;2",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4061811972299616,
        "corr_rating_correctness": -0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "krI-ahhgN2",
        "title": "Self-Contrastive Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "contrastive learning;representation learning;image classification;mutual information",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "4;4;4;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "3;2;4;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "krQLTdel74N",
        "title": "Robust Graph Data Learning with Latent Graph Convolutional Representation",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;5;4;3",
        "correctness": "3;3;3;2",
        "technical_novelty": "2;1;3;2",
        "empirical_novelty": "2;1;0;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7071067811865475,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "kroqZZb-6s",
        "title": "Cluster-based Feature Importance Learning for Electronic Health Record Time-series",
        "track": "main",
        "status": "Reject",
        "keywords": "Clustering;Electronic Health Records",
        "author": "",
        "aff": "Paper under double-blind review",
        "rating": "5;5;6;8",
        "confidence": "3;5;3;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;1;3;3",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "ks_uMcTPyW4",
        "title": "Reinforcement Learning with Efficient Active Feature Acquisition",
        "track": "main",
        "status": "Reject",
        "keywords": "Representation Learning;Reinforcement Learning;Active Learning",
        "author": "",
        "aff": "",
        "rating": "5;6;6",
        "confidence": "3;3;4",
        "correctness": "2;3;3",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 5.666666666666667,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.4999999999999999,
        "corr_rating_correctness": 0.9999999999999997,
        "project": "",
        "github": ""
    },
    {
        "id": "ktHKpsbsxx",
        "title": "WeaveNet: A Differentiable Solver for Non-linear Assignment Problems",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Non-linear assignment;Deep Learning;Stable Matching;3D Point Cloud Matching",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "3;4;3;4",
        "correctness": "2;3;4;3",
        "technical_novelty": "1;3;2;3",
        "empirical_novelty": "1;3;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.40824829046386296,
        "corr_rating_correctness": 0.8660254037844386,
        "project": "",
        "github": ""
    },
    {
        "id": "kxARp2zoqAk",
        "title": "Information-Aware Time Series Meta-Contrastive Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Information-Aware Time Series Meta-Contrastive Learning",
        "author": "",
        "aff": "",
        "rating": "3;5;6;10",
        "confidence": "4;4;5;3",
        "correctness": "2;2;3;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "1;3;4;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5547001962252291,
        "corr_rating_correctness": 0.9460998335825322,
        "project": "",
        "github": ""
    },
    {
        "id": "kz6rsFehYjd",
        "title": "Towards General Robustness to Bad Training Data",
        "track": "main",
        "status": "Reject",
        "keywords": "General Robustness;Data Valuation;Data Utility Learning",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "3;3;3;4",
        "correctness": "3;2;3;3",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "l3SDgUh7qZO",
        "title": "SphereFace2: Binary Classification is All You Need for Deep Face Recognition",
        "track": "main",
        "status": "Spotlight",
        "keywords": "",
        "author": "",
        "aff": "University of Cambridge; Carnegie Mellon University",
        "rating": "8;8;8",
        "confidence": "3;4;5",
        "correctness": "3;4;3",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "4;3;3",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/OpenSphere"
    },
    {
        "id": "l431c_2eGO2",
        "title": "Mix-MaxEnt: Creating High Entropy Barriers To Improve Accuracy and Uncertainty Estimates of Deterministic Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "regularizer;maximum entropy;uncertainty estimation;data-shift robustness;calibration;out-of-distribution detection",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6;6",
        "confidence": "5;3;4;4;3",
        "correctness": "3;4;2;3;3",
        "technical_novelty": "3;2;2;2;3",
        "empirical_novelty": "3;3;2;2;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.8,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 2.6,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7319250547113999,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "l4IHywGq6a",
        "title": "Data-Efficient Graph Grammar Learning for Molecular Generation",
        "track": "main",
        "status": "Oral",
        "keywords": "molecular generation;graph grammar;data efficient generative model",
        "author": "",
        "aff": "MIT CSAIL; MIT-IBM Watson AI Lab",
        "rating": "8;8;8;8",
        "confidence": "4;3;4;3",
        "correctness": "4;4;4;3",
        "technical_novelty": "4;3;3;4",
        "empirical_novelty": "3;3;4;3",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.5,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/gmh14/data_efficient_grammar"
    },
    {
        "id": "l5HdwFu2Ttp",
        "title": "Tabula: Efficiently Computing Nonlinear Activation Functions for Private Neural Network Inference",
        "track": "main",
        "status": "Withdraw",
        "keywords": "private neural network inference;privacy;security;performance",
        "author": "",
        "aff": "",
        "rating": "1;3;6",
        "confidence": "5;2;2",
        "correctness": "1;3;3",
        "technical_novelty": "1;2;3",
        "empirical_novelty": "1;3;0",
        "presentation": "",
        "rating_avg": 3.3333333333333335,
        "confidence_avg": 3.0,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.3333333333333333,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8029550685469661,
        "corr_rating_correctness": 0.802955068546966,
        "project": "",
        "github": ""
    },
    {
        "id": "l5aSHXi8jG5",
        "title": "Demystifying Limited Adversarial Transferability in Automatic Speech Recognition Systems",
        "track": "main",
        "status": "Poster",
        "keywords": "optimization attacks;transferability;adversarial machine learning",
        "author": "",
        "aff": "University of Florida",
        "rating": "5;5;5;8",
        "confidence": "4;3;4;3",
        "correctness": "3;3;2;3",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "l8It-0lE5e7",
        "title": "Implicit Bias of Adversarial Training for Deep Neural Networks",
        "track": "main",
        "status": "Poster",
        "keywords": "adversarial training;adversarial examples",
        "author": "",
        "aff": "The University of Edinburgh, UK; DataCanvas Lab, DataCanvas, Beijing, China",
        "rating": "5;5;8;8",
        "confidence": "3;4;3;3",
        "correctness": "3;2;4;4",
        "technical_novelty": "3;4;3;4",
        "empirical_novelty": "0;4;4;0",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896258,
        "corr_rating_correctness": 0.9045340337332909,
        "project": "",
        "github": ""
    },
    {
        "id": "l9tb1bKyfMn",
        "title": "LMSA: Low-relation Mutil-head Self-Attention Mechanism in Visual Transformer",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "1;3;3",
        "confidence": "5;5;5",
        "correctness": "3;2;2",
        "technical_novelty": "1;1;1",
        "empirical_novelty": "1;1;1",
        "presentation": "",
        "rating_avg": 2.3333333333333335,
        "confidence_avg": 5.0,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 1.0,
        "empirical_novelty_avg": 1.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "lD8qAOTu5FJ",
        "title": "Addressing the Stability-Plasticity Dilemma via Knowledge-Aware Continual Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Continual learning;Class incremental learning;Stability-plasticity dilemma;Sparse neural networks;Knowledge-Awareness",
        "author": "",
        "aff": "",
        "rating": "3;3;6;6",
        "confidence": "4;5;5;3",
        "correctness": "3;2;4;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 4.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3015113445777637,
        "corr_rating_correctness": 0.7071067811865476,
        "project": "",
        "github": ""
    },
    {
        "id": "lDvJM5XUyrx",
        "title": "Towards Understanding Catastrophic Overfitting in Fast Adversarial Training",
        "track": "main",
        "status": "Desk Reject",
        "keywords": "Robustness;Fast Adversarial Training;Catastrophic Overfitting",
        "author": "",
        "aff": "Under double-blind review",
        "rating": "",
        "confidence": "",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "lEB5Dnz_MmH",
        "title": "A Collaborative Attention Adaptive Network for Financial Market Forecasting",
        "track": "main",
        "status": "Reject",
        "keywords": "Financial market forecasting;Deep fusion;Collaborative attention",
        "author": "",
        "aff": "",
        "rating": "3;5;5",
        "confidence": "5;4;3",
        "correctness": "2;3;3",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 4.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8660254037844385,
        "corr_rating_correctness": 0.9999999999999998,
        "project": "",
        "github": ""
    },
    {
        "id": "lEXrEcrbmV",
        "title": "Data-Efficient Contrastive Learning by Differentiable Hard Sample and Hard Positive Pair Generation",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Contrastive learning;Data-efficient learning;Hard sample generation",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;4;4;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.13245323570650439,
        "project": "",
        "github": ""
    },
    {
        "id": "lEoFUoMH2Uu",
        "title": "Foreground-attention in neural decoding: Guiding Loop-Enc-Dec to reconstruct visual stimulus images from fMRI",
        "track": "main",
        "status": "Reject",
        "keywords": "neural decoding;visual stimulus image reconstruction;visual attention;encoder-decoder;fMRI",
        "author": "",
        "aff": "",
        "rating": "3;3;5",
        "confidence": "5;3;5",
        "correctness": "3;3;2",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;1;3",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5,
        "corr_rating_correctness": -1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "lGRG9TxQ3x",
        "title": "Feature Grinding: Efficient Backdoor Sanitation in Deep Neural Networks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Backdoor Sanitation;Deep Neural Network Security;Feature Grinding",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;4;3;4",
        "correctness": "2;2;2;2",
        "technical_novelty": "3;2;2;2",
        "empirical_novelty": "2;1;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.75,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "lKcq2fe-HB",
        "title": "Metrics Matter: A Closer Look on Self-Paced Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Curriculum Learning;Reinforcement Learning;Self-Paced Learning",
        "author": "",
        "aff": "",
        "rating": "5;6;6",
        "confidence": "3;4;2",
        "correctness": "3;3;4",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 5.666666666666667,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.4999999999999999,
        "project": "",
        "github": ""
    },
    {
        "id": "lKrchawH4sB",
        "title": "Heterologous Normalization",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5",
        "confidence": "4;4;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "3;3;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "lL3lnMbR4WU",
        "title": "Open-vocabulary Object Detection via Vision and Language Knowledge Distillation",
        "track": "main",
        "status": "Poster",
        "keywords": "Open-vocabulary recognition;Object detection;Knowledge distillation",
        "author": "",
        "aff": "Nvidia; Google Research",
        "rating": "6;8;8",
        "confidence": "5;5;4",
        "correctness": "3;4;3",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "3;4;4",
        "presentation": "",
        "rating_avg": 7.333333333333333,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 3.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4999999999999999,
        "corr_rating_correctness": 0.49999999999999983,
        "project": "",
        "github": "https://github.com/tensorflow/tpu/tree/master/models/official/detection/projects/vild"
    },
    {
        "id": "lNreaMZf9X",
        "title": "Learning Dynamics Models for Model Predictive Agents",
        "track": "main",
        "status": "Reject",
        "keywords": "Model Learning;Model Based Reinforcement Learning;Control",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "3;4;4;3",
        "correctness": "3;2;4;3",
        "technical_novelty": "2;3;1;2",
        "empirical_novelty": "1;3;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.40824829046386296,
        "corr_rating_correctness": 0.28867513459481287,
        "project": "https://sites.google.com/view/learning-better-models",
        "github": ""
    },
    {
        "id": "lP11WtZwquE",
        "title": "Language Model Pre-training on True Negatives",
        "track": "main",
        "status": "Reject",
        "keywords": "Pre-trained Language Models;Masked Language Modeling;False Negatives;Natural Language Understanding",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5;5",
        "confidence": "4;4;4;3;4",
        "correctness": "2;2;3;3;3",
        "technical_novelty": "2;2;2;2;2",
        "empirical_novelty": "2;2;2;3;2",
        "presentation": "",
        "rating_avg": 4.2,
        "confidence_avg": 3.8,
        "correctness_avg": 2.6,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.2,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.408248290463863,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "lQI_mZjvBxj",
        "title": "Towards Model Agnostic Federated Learning Using Knowledge Distillation",
        "track": "main",
        "status": "Poster",
        "keywords": "Federated Learning;Knowledge Distillation;Model Agnostic Communication;Kernel Regression",
        "author": "",
        "aff": "EPFL; EPFL, UC Berkeley",
        "rating": "3;6;6;8",
        "confidence": "4;3;3;4",
        "correctness": "3;4;3;4",
        "technical_novelty": "2;4;3;3",
        "empirical_novelty": "2;4;2;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.14002800840280097,
        "corr_rating_correctness": 0.7001400420140049,
        "project": "",
        "github": ""
    },
    {
        "id": "lTiW8Jet8t",
        "title": "Efficient Ensembles of Graph Neural Networks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "4;4;4;3",
        "correctness": "2;2;3;3",
        "technical_novelty": "1;2;2;3",
        "empirical_novelty": "2;2;2;4",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.75,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7777777777777777,
        "corr_rating_correctness": 0.9622504486493761,
        "project": "",
        "github": ""
    },
    {
        "id": "lTqGXfn9Tv",
        "title": "Phenomenology of Double Descent in Finite-Width Neural Networks",
        "track": "main",
        "status": "Poster",
        "keywords": "double descent;generalization;neural networks;hessian;flatness",
        "author": "",
        "aff": "Department of Mathematics and Computer Science, University of Basel; MPI for Intelligent Systems, T\u00fcbingen, Germany; ETH Z\u00fcrich, Switzerland; ETH Z\u00fcrich, Switzerland; MPI for Intelligent Systems, T\u00fcbingen, Germany",
        "rating": "3;8;8;8;8",
        "confidence": "3;4;4;4;4",
        "correctness": "2;3;3;3;4",
        "technical_novelty": "1;3;4;4;3",
        "empirical_novelty": "2;3;2;3;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.8,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.6,
        "presentation_avg": 0,
        "corr_rating_confidence": 1.0,
        "corr_rating_correctness": 0.7905694150420948,
        "project": "",
        "github": "Available on GitHub (link not provided in text)"
    },
    {
        "id": "lUyvp-6V9G",
        "title": "Multi-Vector Embedding on Networks with Taxonomies",
        "track": "main",
        "status": "Withdraw",
        "keywords": "network embedding;heterogeneous network embedding;hyperbolic space",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;5;3",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "lVRfcp9ZEB_",
        "title": "IsoScore: Measuring the Uniformity of Vector Space Utilization",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Contextualized Word Embeddings;Isotropy;Natural Language Processing",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "3;4;4;4",
        "correctness": "2;2;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;3;3;2",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.75,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9271726499455306,
        "corr_rating_correctness": 0.6882472016116854,
        "project": "",
        "github": ""
    },
    {
        "id": "lVtq6C5_3QL",
        "title": "Generating Transferable Adversarial Patch by Simultaneously Optimizing its Position and Perturbations",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;6;8",
        "confidence": "5;4;3;4",
        "correctness": "2;2;4;3",
        "technical_novelty": "1;2;2;4",
        "empirical_novelty": "2;0;2;4",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5000000000000001,
        "corr_rating_correctness": 0.7106690545187014,
        "project": "",
        "github": ""
    },
    {
        "id": "lY0-7bj0Vfz",
        "title": "Prototype memory and attention mechanisms for few shot image generation",
        "track": "main",
        "status": "Poster",
        "keywords": "neuroscience;deep learning",
        "author": "",
        "aff": "Carnegie Mellon University",
        "rating": "5;5;8",
        "confidence": "4;3;3",
        "correctness": "3;3;4",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "3;2;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "l_amHf1oaK",
        "title": "Complete Verification via Multi-Neuron Relaxation Guided Branch-and-Bound",
        "track": "main",
        "status": "Poster",
        "keywords": "Certified Robustness;Branch-and-Bound;Convex Relaxation",
        "author": "",
        "aff": "Department of Computer Science, ETH Zurich, Switzerland",
        "rating": "6;6;6;6;6",
        "confidence": "5;4;4;3;4",
        "correctness": "4;2;4;4;2",
        "technical_novelty": "2;3;2;3;3",
        "empirical_novelty": "0;3;2;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 2.2,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "lbauk6wK2-y",
        "title": "Object Pursuit: Building a Space of Objects via Discriminative Weight Generation",
        "track": "main",
        "status": "Poster",
        "keywords": "object-centric;continual learning;representation learning;hypernetwork",
        "author": "",
        "aff": "Stanford University; Tsinghua University, Stanford University; Tsinghua University",
        "rating": "5;5;6;6",
        "confidence": "3;3;2;3",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 2.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": "https://github.com/pptrick/Object-Pursuit"
    },
    {
        "id": "ldkunzUzRWj",
        "title": "A Simple and Debiased Sampling Method for Personalized Ranking",
        "track": "main",
        "status": "Reject",
        "keywords": "personalized ranking;class-imbalance;negative sampling;deep learning",
        "author": "",
        "aff": "",
        "rating": "3;3;6;8",
        "confidence": "5;4;3;4",
        "correctness": "2;4;3;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;1;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5000000000000001,
        "corr_rating_correctness": 0.42640143271122094,
        "project": "",
        "github": ""
    },
    {
        "id": "lf0W6tcWmh-",
        "title": "Towards understanding how momentum improves generalization in deep learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Deep learning theory;non-convex optimization",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5;6",
        "confidence": "4;4;4;4;2",
        "correctness": "3;2;2;4;4",
        "technical_novelty": "2;3;3;2;4",
        "empirical_novelty": "2;3;2;2;4",
        "presentation": "",
        "rating_avg": 4.8,
        "confidence_avg": 3.6,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.8,
        "empirical_novelty_avg": 2.6,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6123724356957946,
        "corr_rating_correctness": 0.22821773229381923,
        "project": "",
        "github": ""
    },
    {
        "id": "lgGKToqwtwG",
        "title": "Infusing Future Information into Monotonic Attention Through Language Models",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Simultaneous Translation;Monotonic Attention;Speech Translation",
        "author": "",
        "aff": "",
        "rating": "3;3;6",
        "confidence": "3;5;4",
        "correctness": "2;2;4",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "lgOylcEZQgr",
        "title": "Online Unsupervised Learning of Visual Representations and Categories",
        "track": "main",
        "status": "Reject",
        "keywords": "Unsupervised learning;self-supervised learning;few-shot learning;visual representation learning;visual category learning",
        "author": "",
        "aff": "",
        "rating": "3;6;6;6",
        "confidence": "3;3;3;4",
        "correctness": "4;2;3;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;2;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": -0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "liIJKb1gudP",
        "title": "Center Loss Regularization for Continual Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Continual Learning;Supervised Learning;Classification;Lifelong Learning;Catastrophic Forgetting;Domain Adaptation;Continual Domain Adaptation",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5;6",
        "confidence": "5;5;4;4;4",
        "correctness": "2;3;3;3;3",
        "technical_novelty": "4;2;2;2;3",
        "empirical_novelty": "3;2;2;2;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.4,
        "correctness_avg": 2.8,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6454972243679027,
        "corr_rating_correctness": 0.39528470752104744,
        "project": "",
        "github": ""
    },
    {
        "id": "liV-Re74fK",
        "title": "Density Estimation for Conservative Q-Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Offline Reinforcement Learning;Batch Reinforcement Learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "5;4;2;3",
        "correctness": "2;3;4;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8944271909999159,
        "corr_rating_correctness": 0.7071067811865475,
        "project": "",
        "github": ""
    },
    {
        "id": "lifRwnIuAv0",
        "title": "PGD-2 can be better than FGSM + GradAlign",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "ljCoTzUsdS",
        "title": "Distinguishing rule- and exemplar-based generalization in learning systems",
        "track": "main",
        "status": "Reject",
        "keywords": "inductive bias;combinatorial generalization;cognitive psychology;robustness to spurious correlation",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "4;3;1;4",
        "correctness": "2;2;3;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;4",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.15713484026367722,
        "corr_rating_correctness": 0.9622504486493761,
        "project": "",
        "github": ""
    },
    {
        "id": "ljnUrvex8d",
        "title": "Representation Topology Divergence: A Method for Comparing Neural Network Representations.",
        "track": "main",
        "status": "Withdraw",
        "keywords": "representation learning;understanding deep learning;topological data analysis",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;5;3;2",
        "correctness": "2;2;3;4",
        "technical_novelty": "3;1;3;2",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8944271909999159,
        "corr_rating_correctness": 0.9045340337332909,
        "project": "",
        "github": ""
    },
    {
        "id": "ljxWpdBl4V",
        "title": "Closed-form Sample Probing for Learning Generative Models in Zero-shot Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "zero-shot learning;generative zero-shot learning;generative models",
        "author": "",
        "aff": "Middle East Technical University, Department of Computer Engineering, Ankara, Turkey",
        "rating": "5;5;6;6;6",
        "confidence": "2;5;4;3;4",
        "correctness": "3;4;3;3;3",
        "technical_novelty": "2;2;3;3;2",
        "empirical_novelty": "2;2;2;2;2",
        "presentation": "",
        "rating_avg": 5.6,
        "confidence_avg": 3.6,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.08006407690254361,
        "corr_rating_correctness": -0.6123724356957946,
        "project": "",
        "github": ""
    },
    {
        "id": "lkQ7meEa-qv",
        "title": "Learning Neural Acoustic Fields",
        "track": "main",
        "status": "Reject",
        "keywords": "Audio-Visual Learning;Acoustic",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "4;4;4;4",
        "correctness": "3;4;2;3",
        "technical_novelty": "2;2;2;4",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.5443310539518174,
        "project": "https://sites.google.com/view/nafs-iclr-2022/",
        "github": ""
    },
    {
        "id": "lnEaqbTJIRz",
        "title": "The Inductive Bias of In-Context Learning: Rethinking Pretraining Example Design",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Language Modeling;Pretraining;Self-attention;Transformers;Expressivity;Separation Rank;Sentence Embeddings",
        "author": "",
        "aff": "The Hebrew University of Jerusalem",
        "rating": "8;8;8;8;8",
        "confidence": "3;2;3;3;3",
        "correctness": "3;4;3;3;3",
        "technical_novelty": "3;4;2;3;4",
        "empirical_novelty": "3;4;2;2;2",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 2.8,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 3.2,
        "empirical_novelty_avg": 2.6,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "lpkGn3k2YdD",
        "title": "Learning Long-Term Reward Redistribution via Randomized Return Decomposition",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Reinforcement Learning;Long-Term Credit Assignment;Reward Redistribution;Return Decomposition",
        "author": "",
        "aff": "University of Illinois at Urbana-Champaign; University of Illinois at Urbana-Champaign and HeliXon Limited; Shanghai Jiao Tong University; BIMSA and AIR, Tsinghua University",
        "rating": "5;8;8;8",
        "confidence": "4;3;4;2",
        "correctness": "3;2;4;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 7.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5222329678670935,
        "corr_rating_correctness": 0.17407765595569782,
        "project": "",
        "github": ""
    },
    {
        "id": "lpwzJuyFs2",
        "title": "Learning Stochastic Representations of Physical Systems",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "1;3;3;3",
        "confidence": "5;4;3;4",
        "correctness": "3;4;4;3",
        "technical_novelty": "1;2;2;2",
        "empirical_novelty": "1;2;2;2",
        "presentation": "",
        "rating_avg": 2.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.816496580927726,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "lrocYB-0ST2",
        "title": "Approximation and Learning with Deep Convolutional Models: a Kernel Perspective",
        "track": "main",
        "status": "Poster",
        "keywords": "kernel methods;deep learning theory;convolution;approximation;generalization",
        "author": "",
        "aff": "Center for Data Science, New York University",
        "rating": "6;8;8;8",
        "confidence": "4;3;3;4",
        "correctness": "3;4;4;4",
        "technical_novelty": "4;3;3;4",
        "empirical_novelty": "4;3;3;4",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.5,
        "empirical_novelty_avg": 3.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "lsQCDXjOl3k",
        "title": "Unconditional Diffusion Guidance",
        "track": "main",
        "status": "Reject",
        "keywords": "diffusion;score;guidance;generative",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "3;3;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "4;2;2;2",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "lsljy2bG3n",
        "title": "$m$-mix: Generating hard negatives via multiple samples mixing for contrastive learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Graph learning;self supervised learning",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;4;3;3",
        "correctness": "2;3;4;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "3;2;3;2",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6882472016116854,
        "corr_rating_correctness": 0.6488856845230502,
        "project": "",
        "github": ""
    },
    {
        "id": "ltM1RMZntpu",
        "title": "Weighted Training for Cross-Task Learning",
        "track": "main",
        "status": "Oral",
        "keywords": "Cross-task learning;Natural language processing;Representation learning",
        "author": "",
        "aff": "The Technion; University of Pennsylvania",
        "rating": "6;8;8;8",
        "confidence": "3;3;3;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "3;4;4;4",
        "empirical_novelty": "3;3;3;4",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.75,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "http://cogcomp.org/page/publication_view/963"
    },
    {
        "id": "luO6l9cP6b6",
        "title": "Identifying the Limits of Cross-Domain Knowledge Transfer for Pretrained Models",
        "track": "main",
        "status": "Reject",
        "keywords": "transfer learning;pretrained language model",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;3;5;4",
        "correctness": "2;3;3;4",
        "technical_novelty": "3;2;1;2",
        "empirical_novelty": "3;2;1;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9733285267845754,
        "project": "",
        "github": ""
    },
    {
        "id": "lu_DAxnWsh",
        "title": "Guiding Transformers to Process in Steps",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "5;3;4;4",
        "correctness": "3;2;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;1",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "lusH5Q9Vt5_",
        "title": "Generalized Sampling Method for Few Shot Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Few-shot learning;distribution estimation;sampling method",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "5;5;3;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9045340337332909,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "lvM693mon8q",
        "title": "Compressed-VFL: Communication-Efficient Learning with Vertically Partitioned Data",
        "track": "main",
        "status": "Reject",
        "keywords": "Federated Learning;Optimization;Split Learning;Cross-Silo Learning;Compression;Quantization;Sparsification",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "5;3;3;3",
        "correctness": "2;3;2;4",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "0;2;2;2",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.8703882797784891,
        "project": "",
        "github": ""
    },
    {
        "id": "lyLVzukXi08",
        "title": "Neural Variational Dropout Processes",
        "track": "main",
        "status": "Poster",
        "keywords": "Meta Learning;Few-shot Learning;Bayesian Neural Networks;Variatinoal Dropout",
        "author": "",
        "aff": "Everdoubling LLC., Seoul, South Korea; Seoul National University",
        "rating": "6;6;8",
        "confidence": "3;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "2;3;2",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9999999999999998,
        "corr_rating_correctness": -0.49999999999999983,
        "project": "",
        "github": ""
    },
    {
        "id": "lycl1GD7fVP",
        "title": "Neural tangent kernel eigenvalues accurately predict generalization",
        "track": "main",
        "status": "Reject",
        "keywords": "deep learning;generalization;neural tangent kernel;kernel regression;inductive bias",
        "author": "",
        "aff": "",
        "rating": "3;5;6;8",
        "confidence": "5;3;2;5",
        "correctness": "2;3;3;3",
        "technical_novelty": "1;2;3;4",
        "empirical_novelty": "2;3;3;1",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.053376051268362375,
        "corr_rating_correctness": 0.8006407690254357,
        "project": "",
        "github": ""
    },
    {
        "id": "lyzRAErG6Kv",
        "title": "Self-Supervised Structured Representations for Deep Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Reinforcement Learning;Representation Learning;Optical Flow Estimation;Structured representation;Self-supervised Learning",
        "author": "",
        "aff": "",
        "rating": "5;5;6;8",
        "confidence": "2;4;3;2",
        "correctness": "4;3;4;4",
        "technical_novelty": "2;3;2;4",
        "empirical_novelty": "2;3;3;2",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 2.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4923659639173309,
        "corr_rating_correctness": 0.4714045207910316,
        "project": "https://sites.google.com/view/iclr2022-s3r",
        "github": ""
    },
    {
        "id": "lzg1FIdbPht",
        "title": "Denoised Internal Models: a Brain-Inspired Autoencoder against Adversarial Attacks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "adversarial attacks;robustness of neural network;autoencoder;visual cortex;engram cell",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "3;4;5;4",
        "correctness": "2;2;3;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.8703882797784891,
        "project": "",
        "github": ""
    },
    {
        "id": "lzupY5zjaU9",
        "title": "Distribution Compression in Near-Linear Time",
        "track": "main",
        "status": "Poster",
        "keywords": "Distribution compression;linear time;thinning;i.i.d. sampling;Markov chain Monte Carlo;maximum mean discrepancy;reproducing kernel Hilbert space",
        "author": "",
        "aff": "Department of EECS, UC Berkeley; Microsoft Research New England; Department of Computer Science, Harvard University and Department of EECS, MIT",
        "rating": "6;8;8",
        "confidence": "3;3;3",
        "correctness": "4;3;4",
        "technical_novelty": "2;3;2",
        "empirical_novelty": "2;4;4",
        "presentation": "",
        "rating_avg": 7.333333333333333,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 3.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.49999999999999983,
        "project": "",
        "github": ""
    },
    {
        "id": "m22XrToDacC",
        "title": "Distributionally Robust Recourse Action",
        "track": "main",
        "status": "Reject",
        "keywords": "Algorithmic recourse;Robust optimization",
        "author": "",
        "aff": "",
        "rating": "3;5;5",
        "confidence": "5;3;3",
        "correctness": "3;3;4",
        "technical_novelty": "3;3;2",
        "empirical_novelty": "1;2;2",
        "presentation": "",
        "rating_avg": 4.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.49999999999999983,
        "project": "",
        "github": ""
    },
    {
        "id": "m2MiIwuI0m",
        "title": "An Analysis of Attentive Walk-Aggregating Graph Neural Networks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "graph neural network;graph representation learning;attention weighting;walk aggregation;representation power;learning guarantees;interpretability",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5",
        "confidence": "4;4;4;4",
        "correctness": "3;4;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "m4BAEB_Imy",
        "title": "iPrune: A Magnitude Based Unstructured Pruning Method for Efficient Binary Networks in Hardware",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "5;5;4;3",
        "correctness": "2;4;2;2",
        "technical_novelty": "1;1;2;2",
        "empirical_novelty": "0;1;0;1",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 1.5,
        "empirical_novelty_avg": 0.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "m5EBN92vjN",
        "title": "AASEG: ATTENTION AWARE NETWORK FOR REAL TIME SEMANTIC SEGMENTATION",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "1;1;1;3",
        "confidence": "5;4;5;4",
        "correctness": "2;2;2;3",
        "technical_novelty": "1;1;1;2",
        "empirical_novelty": "2;1;1;2",
        "presentation": "",
        "rating_avg": 1.5,
        "confidence_avg": 4.5,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 1.25,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "m716e-0clj",
        "title": "Communicate Then Adapt: An Effective Decentralized Adaptive Method for Deep Training",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5;8",
        "confidence": "5;4;4;3",
        "correctness": "3;2;2;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9901475429766743,
        "corr_rating_correctness": 0.5488604301969737,
        "project": "",
        "github": ""
    },
    {
        "id": "m7S4NvprHVl",
        "title": "Demystifying Hyperparameter Optimization in Federated Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Federated Learning;Data Heterogeneity;Hyperparameter Optimization",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "4;5;3;4",
        "correctness": "2;3;4;3",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5443310539518174,
        "corr_rating_correctness": 0.5443310539518174,
        "project": "",
        "github": ""
    },
    {
        "id": "m7zsaLt1Sab",
        "title": "Finding One Missing Puzzle of Contextual Word Embedding: Representing Contexts as Manifold",
        "track": "main",
        "status": "Reject",
        "keywords": "Contextual Word Embedding;Category Theory;Manifold",
        "author": "",
        "aff": "Under double-blind review",
        "rating": "1;3;3;3;3",
        "confidence": "3;2;4;3;2",
        "correctness": "3;2;2;2;3",
        "technical_novelty": "1;2;2;2;2",
        "empirical_novelty": "1;2;2;2;2",
        "presentation": "",
        "rating_avg": 2.6,
        "confidence_avg": 2.8,
        "correctness_avg": 2.4,
        "technical_novelty_avg": 1.8,
        "empirical_novelty_avg": 1.8,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.13363062095621214,
        "corr_rating_correctness": -0.6123724356957944,
        "project": "",
        "github": ""
    },
    {
        "id": "m8bypnj7Yl5",
        "title": "Neural Solvers for Fast and Accurate Numerical Optimal Control",
        "track": "main",
        "status": "Poster",
        "keywords": "Deep Learning;Numerical Methods;Optimal Control",
        "author": "",
        "aff": "KAIST, DiffEqML; KAIST; Stanford University, DiffEqML; The University of Tokyo, DiffEqML",
        "rating": "5;6;8",
        "confidence": "4;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "2;3;2",
        "empirical_novelty": "2;2;4",
        "presentation": "",
        "rating_avg": 6.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.944911182523068,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "m8uJvVgwRci",
        "title": "Creating Training Sets via Weak Indirect Supervision",
        "track": "main",
        "status": "Poster",
        "keywords": "weak supervision;data programming;training label synthesis",
        "author": "",
        "aff": "Microsoft Research Asia; University of Science and Technology of China; Carnegie Mellon University; University of Washington",
        "rating": "6;8;8;8",
        "confidence": "4;4;2;4",
        "correctness": "3;4;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "mF122BuAnnW",
        "title": "Localized Randomized Smoothing for Collective Robustness Certification",
        "track": "main",
        "status": "Reject",
        "keywords": "Adversarial robustness;Robustness certification;Robust machine learning;Randomized smoothing;Verification",
        "author": "",
        "aff": "",
        "rating": "3;3;5;8",
        "confidence": "5;3;4;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9169493006161777,
        "project": "",
        "github": ""
    },
    {
        "id": "mF5tmqUfdsw",
        "title": "Zeroth-Order Actor-Critic",
        "track": "main",
        "status": "Reject",
        "keywords": "reinforcement learning;zeroth-order optimization;actor-critic",
        "author": "",
        "aff": "",
        "rating": "6;6;6",
        "confidence": "3;4;3",
        "correctness": "3;3;1",
        "technical_novelty": "3;3;2",
        "empirical_novelty": "3;3;2",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "mFpP0THYeaX",
        "title": "Gradual Domain Adaptation in the Wild: When Intermediate Distributions are Absent",
        "track": "main",
        "status": "Reject",
        "keywords": "gradual domain adaptation;self-training;gradual distribution shift;curriculum learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5;6",
        "confidence": "5;4;3;2;4",
        "correctness": "3;2;4;3;4",
        "technical_novelty": "1;3;2;3;2",
        "empirical_novelty": "1;2;2;3;4",
        "presentation": "",
        "rating_avg": 4.4,
        "confidence_avg": 3.6,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.2,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5229763603684907,
        "corr_rating_correctness": 0.801783725737273,
        "project": "",
        "github": ""
    },
    {
        "id": "mHu2vIds_-b",
        "title": "Boosting Randomized Smoothing with Variance Reduced Classifiers",
        "track": "main",
        "status": "Spotlight",
        "keywords": "adversarial robustness;certified robustness;randomized smoothing",
        "author": "",
        "aff": "Department of Computer Science, ETH Zurich, Switzerland",
        "rating": "6;8;8",
        "confidence": "4;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "3;3;2",
        "empirical_novelty": "3;2;0",
        "presentation": "",
        "rating_avg": 7.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.49999999999999983,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/eth-sri/smoothing-ensembles"
    },
    {
        "id": "mJXARDIxVl6",
        "title": "Optimistic Policy Optimization is Provably Efficient in Non-stationary MDPs",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;3;4",
        "correctness": "3;4;4;3",
        "technical_novelty": "2;3;2;2",
        "empirical_novelty": "1;0;0;0",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 0.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "mKDtUtxIGJ",
        "title": "Deep Point Cloud Reconstruction",
        "track": "main",
        "status": "Poster",
        "keywords": "Computer Vision;3D Geometry;Deep Learning based Point Cloud Understanding;Point Cloud Denoising;Point Cloud Upsampling",
        "author": "",
        "aff": "POSTECH; KAIST",
        "rating": "5;6;6;8",
        "confidence": "4;4;3;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.13245323570650439,
        "corr_rating_correctness": 0.9271726499455306,
        "project": "",
        "github": ""
    },
    {
        "id": "mKsMcL8FfsV",
        "title": "Learning Rich Nearest Neighbor Representations from Self-supervised Ensembles",
        "track": "main",
        "status": "Reject",
        "keywords": "k-NN;ensemble;self-supervised learning",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;4;3;4",
        "correctness": "3;3;2;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "0;4;2;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "mL07kYPn3E",
        "title": "Few-shot Learning with Big Prototypes",
        "track": "main",
        "status": "Reject",
        "keywords": "Prototype;Few-shot Learning;Meta-learning",
        "author": "",
        "aff": "",
        "rating": "5;6;6;6",
        "confidence": "4;4;3;2",
        "correctness": "2;3;3;4",
        "technical_novelty": "1;2;3;3",
        "empirical_novelty": "1;2;3;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5222329678670935,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "mMiKHj7Pobj",
        "title": "Revealing the Incentive to Cause Distributional Shift",
        "track": "main",
        "status": "Reject",
        "keywords": "alignment;incentives;unit testing;distributional shift;content recommendation;myopic reinforcement learning",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;3;2;3",
        "correctness": "4;4;4;3",
        "technical_novelty": "3;2;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "mNLLDtkAy4X",
        "title": "Escaping Stochastic Traps with Aleatoric Mapping Agents",
        "track": "main",
        "status": "Reject",
        "keywords": "Curiosity;Neuroscience;Acetylcholine;Uncertainty;Reinforcement learning;Intrinsic Rewards",
        "author": "",
        "aff": "",
        "rating": "3;5;6",
        "confidence": "4;4;5",
        "correctness": "2;4;2",
        "technical_novelty": "1;2;4",
        "empirical_novelty": "1;2;4",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.7559289460184544,
        "corr_rating_correctness": 0.1889822365046137,
        "project": "",
        "github": ""
    },
    {
        "id": "mOXHnLqR7AC",
        "title": "Causal Scene BERT: Improving object detection by searching for challenging groups",
        "track": "main",
        "status": "Withdraw",
        "keywords": "object detection;computer vision;masked language modeling;autonomous vehicles;causality",
        "author": "",
        "aff": "",
        "rating": "",
        "confidence": "",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "mPlm356yMIP",
        "title": "Digging Into Output Representation for Monocular 3D Object Detection",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Computer vision;monocular 3D object detection;output representation",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5;8",
        "confidence": "4;3;4;4;3",
        "correctness": "3;4;3;3;3",
        "technical_novelty": "1;2;3;3;4",
        "empirical_novelty": "2;2;3;2;3",
        "presentation": "",
        "rating_avg": 5.2,
        "confidence_avg": 3.6,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6634034720037775,
        "corr_rating_correctness": -0.0625,
        "project": "",
        "github": ""
    },
    {
        "id": "mQDpmgFKu1P",
        "title": "Language Modeling using LMUs: 10x Better Data Efficiency or Improved Scaling Compared to Transformers",
        "track": "main",
        "status": "Reject",
        "keywords": "Recurrent Neural Network;Legendre Memory Unit;Natural Language Processing",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;4;4;3",
        "correctness": "2;2;3;2",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "1;2;1;3",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.75,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "mQxt8l7JL04",
        "title": "Regularized Autoencoders for Isometric Representation Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "Autoencoders;Manifold Learning;Regularization;Geometry;Distortion",
        "author": "",
        "aff": "Department of Mechanical Engineering, Seoul National University and Saige Research; Department of Mechanical Engineering, Seoul National University",
        "rating": "5;5;5;6;8",
        "confidence": "3;4;3;4;3",
        "correctness": "4;3;3;3;3",
        "technical_novelty": "3;2;3;3;3",
        "empirical_novelty": "2;2;2;2;3",
        "presentation": "",
        "rating_avg": 5.8,
        "confidence_avg": 3.4,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.8,
        "empirical_novelty_avg": 2.2,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.21004201260420152,
        "corr_rating_correctness": -0.3429971702850177,
        "project": "",
        "github": "https://github.com/Gabe-YHLee/IRV-AE-public"
    },
    {
        "id": "mRF387I4Wl",
        "title": "FlowX: Towards Explainable Graph Neural Networks via Message Flows",
        "track": "main",
        "status": "Reject",
        "keywords": "Deep learning;Graph Neural Networks;Explainability",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "5;4;5;5",
        "correctness": "2;3;3;4",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "1;2;0;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.8660254037844386,
        "project": "",
        "github": ""
    },
    {
        "id": "mRc_t2b3l1-",
        "title": "Rethinking the limiting dynamics of SGD: modified loss, phase space oscillations, and anomalous diffusion",
        "track": "main",
        "status": "Reject",
        "keywords": "learning dynamics;loss landscape;stochastic differential equation;modified equation analysis;hessian;geometry;physics;fokker-plank;modified loss;probability currents;diffusion",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "5;5;4;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;4;2;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7385489458759963,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "mTcO4-QCOB",
        "title": "Analyzing the Effects of Classifier Lipschitzness on Explainers",
        "track": "main",
        "status": "Reject",
        "keywords": "Explainers;Explanation;Robustness;Astuteness;Lipschitz;Blackbox;Classifiers",
        "author": "",
        "aff": "",
        "rating": "3;5;5",
        "confidence": "5;4;3",
        "correctness": "2;3;4",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 4.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8660254037844385,
        "corr_rating_correctness": 0.8660254037844385,
        "project": "",
        "github": ""
    },
    {
        "id": "mYaOK2og0tf",
        "title": "A Practical PAC-Bayes Generalisation Bound for Deep Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "generalisation;hessian;pac-bayesian",
        "author": "",
        "aff": "",
        "rating": "1;1;3",
        "confidence": "4;3;3",
        "correctness": "1;2;2",
        "technical_novelty": "1;2;2",
        "empirical_novelty": "1;2;2",
        "presentation": "",
        "rating_avg": 1.6666666666666667,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 1.6666666666666667,
        "technical_novelty_avg": 1.6666666666666667,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4999999999999999,
        "corr_rating_correctness": 0.4999999999999999,
        "project": "",
        "github": ""
    },
    {
        "id": "mZsZy481_F",
        "title": "FROB: Few-shot ROBust Model for Classification with Out-of-Distribution Detection",
        "track": "main",
        "status": "Reject",
        "keywords": "Classification and Out-of-Distribution Detection;Confidence Prediction;Few-Shot Out-of-Distribution Detection;Outlier Exposure;Robustness",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "5;3;4;2",
        "correctness": "3;2;2;3",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "2;1;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7745966692414834,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "mdUYT5QV0O",
        "title": "Training Structured Neural Networks Through Manifold Identification and Variance Reduction",
        "track": "main",
        "status": "Poster",
        "keywords": "Structured neural networks;variance reduction;manifold identification;proximal methods",
        "author": "",
        "aff": "Academia Sinica",
        "rating": "6;8;8",
        "confidence": "4;4;3",
        "correctness": "3;1;4",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 7.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.49999999999999983,
        "corr_rating_correctness": -0.18898223650461365,
        "project": "",
        "github": "https://www.github.com/zihsyuan1214/rmda"
    },
    {
        "id": "metRpM4Zrcb",
        "title": "Continual Learning with Filter Atom Swapping",
        "track": "main",
        "status": "Spotlight",
        "keywords": "continual learning",
        "author": "",
        "aff": "Department of ECE, Purdue University",
        "rating": "6;8;8;8",
        "confidence": "3;4;3;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;3;4;4",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "mfwdY3U_9ea",
        "title": "Igeood: An Information Geometry Approach to Out-of-Distribution Detection",
        "track": "main",
        "status": "Poster",
        "keywords": "out-of-distribution detection;anomaly detection;deep learning",
        "author": "",
        "aff": "International Laboratory on Learning Systems (ILLS), McGill ETS MILA CNRS Universit\u00e9 Paris-Saclay CentraleSup\u00e9lec, H3C 1K3 Quebec, Canada; Laboratoire des signaux et syst\u00e8mes (L2S), Universit\u00e9 Paris-Saclay CNRS CentraleSup\u00e9lec, 91190, Gif-sur-Yvette, France",
        "rating": "5;6;6;8",
        "confidence": "3;3;4;4",
        "correctness": "2;3;3;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;2;3;4",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.6882472016116854,
        "corr_rating_correctness": 0.9733285267845754,
        "project": "",
        "github": ""
    },
    {
        "id": "mhYUBYNoGz",
        "title": "Machine Learning For Elliptic PDEs: Fast Rate Generalization Bound, Neural Scaling Law and Minimax Optimality",
        "track": "main",
        "status": "Poster",
        "keywords": "Numerical PDE;non-parametric statistics;computational physics",
        "author": "",
        "aff": "Department of Computing and Mathematical Sciences, Caltech, Pasadena, CA 91125, USA; Institute for Computational & Mathematical Engineering, Stanford University, Stanford, CA 94305, USA; Mathematics Department, Duke University, Durham, NC 27708-0320; Department of Mathematics, Stanford University, Stanford, CA 94305, USA; Department of Management Science & Engineering, Stanford University, Stanford, CA 94305, USA",
        "rating": "6;6;8;8",
        "confidence": "3;3;3;4",
        "correctness": "3;4;4;3",
        "technical_novelty": "3;3;4;3",
        "empirical_novelty": "3;1;2;2",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "mhv2gWm3sf",
        "title": "$f$-Divergence Thermodynamic Variational Objective: a Deformed Geometry Perspective",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;4;4;3",
        "correctness": "2;3;3;3",
        "technical_novelty": "3;3;2;4",
        "empirical_novelty": "2;1;3;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "miA4AkGK00R",
        "title": "EF21 with Bells & Whistles: Practical Algorithmic Extensions of Modern Error Feedback",
        "track": "main",
        "status": "Reject",
        "keywords": "EF21;error feedback;bidirectional compression;regularization;variance reduction;heavy ball momentum;stochastic approximation",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "4;3;4;4",
        "correctness": "3;4;3;3",
        "technical_novelty": "3;2;2;2",
        "empirical_novelty": "1;2;2;2",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "mk0HzdqY7i1",
        "title": "What\u2019s Wrong with Deep Learning in Tree Search for Combinatorial Optimization",
        "track": "main",
        "status": "Poster",
        "keywords": "deep learning;combinatorial optimization;maximum independent set",
        "author": "",
        "aff": "The Academic College of Tel Aviv-Yaffo, Israel; Hasso Plattner Institute, University of Potsdam; Department of Mathematics, University of Potsdam",
        "rating": "6;8;8;8",
        "confidence": "4;4;5;3",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;1;1;3",
        "empirical_novelty": "3;4;3;3",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "mk8AzPcd3x",
        "title": "BCDR: Betweenness Centrality-based Distance Resampling for Graph Shortest Distance Embedding",
        "track": "main",
        "status": "Reject",
        "keywords": "graph representation learning;graph shortest path distance;shortest distance query;graph embedding;random walk",
        "author": "",
        "aff": "",
        "rating": "3;3;6;6",
        "confidence": "4;4;4;2",
        "correctness": "3;3;1;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896258,
        "corr_rating_correctness": -0.2294157338705618,
        "project": "",
        "github": ""
    },
    {
        "id": "mmUA7_O9mjY",
        "title": "Contact Points Discovery for Soft-Body Manipulations with Differentiable Physics",
        "track": "main",
        "status": "Spotlight",
        "keywords": "differentiable physics;soft body manipulation",
        "author": "",
        "aff": "University of Rochester; MIT BCS, CBMM, CSAIL; MIT; UC San Diego; MIT-IBM Watson AI Lab",
        "rating": "6;8;8",
        "confidence": "4;3;3",
        "correctness": "3;3;4",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 7.333333333333333,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9999999999999998,
        "corr_rating_correctness": 0.49999999999999983,
        "project": "http://cpdeform.csail.mit.edu",
        "github": ""
    },
    {
        "id": "mniwiEAuzL",
        "title": "Sample-efficient actor-critic algorithms with an etiquette for zero-sum Markov games",
        "track": "main",
        "status": "Reject",
        "keywords": "zero sum Markov-games;policy gradient;actor-critic;temporal difference",
        "author": "",
        "aff": "",
        "rating": "5;6;6;6",
        "confidence": "4;4;3;2",
        "correctness": "4;4;3;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;0;0;0",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 0.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5222329678670935,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "moHCzz6D5H3",
        "title": "Peek-a-Boo: What (More) is Disguised in a Randomly Weighted Neural Network, and How to Find It Efficiently",
        "track": "main",
        "status": "Poster",
        "keywords": "Sparse Neural Network;Lottery Ticket Hypothesis;Efficient Machine Leanring",
        "author": "",
        "aff": "University of Texas at Austin; University of Texas at Austin, Carnegie Mellon University",
        "rating": "5;6;8;8",
        "confidence": "3;4;4;4",
        "correctness": "3;4;4;4",
        "technical_novelty": "3;2;4;3",
        "empirical_novelty": "2;2;4;4",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.7777777777777777,
        "corr_rating_correctness": 0.7777777777777777,
        "project": "",
        "github": "https://github.com/VITA-Group/Peek-a-Boo"
    },
    {
        "id": "morSrUyWG26",
        "title": "AutoOED: Automated Optimal Experimental Design Platform with Data- and Time-Efficient Multi-Objective Optimization",
        "track": "main",
        "status": "Reject",
        "keywords": "optimal experiment design;bayesian optimization;multi-objective optimization;software platform",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "5;5;4;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "1;2;3;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 4.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8703882797784891,
        "corr_rating_correctness": 0.0,
        "project": "https://sites.google.com/view/autooed",
        "github": ""
    },
    {
        "id": "mqIeP6qPvta",
        "title": "FoveaTer: Foveated Transformer for Image Classification",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;6;8",
        "confidence": "4;4;4;4",
        "correctness": "3;2;4;3",
        "technical_novelty": "2;3;4;4",
        "empirical_novelty": "0;2;3;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.19611613513818402,
        "project": "",
        "github": ""
    },
    {
        "id": "ms7xJWbf8Ku",
        "title": "Efficient Packing: Towards 2x NLP Speed-Up without Loss of Accuracy for BERT",
        "track": "main",
        "status": "Reject",
        "keywords": "deep learning;BERT;IPU;GPU;hardware-acceleration;padding;Wikipedia;NLP",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6;6",
        "confidence": "4;4;4;3;3",
        "correctness": "3;3;3;4;3",
        "technical_novelty": "2;3;2;3;3",
        "empirical_novelty": "1;4;2;2;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 2.2,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.74535599249993,
        "corr_rating_correctness": 0.4564354645876385,
        "project": "",
        "github": ""
    },
    {
        "id": "msRBojTz-Nh",
        "title": "Learned Simulators for Turbulence",
        "track": "main",
        "status": "Poster",
        "keywords": "learned simulation;turbulence",
        "author": "",
        "aff": "Google Research, Cambridge, MA; DeepMind, London, UK; Princeton University, Princeton, NJ; Center for Computational Astrophysics, Flatiron Institute, New York, NY",
        "rating": "6;6;8;8",
        "confidence": "3;3;4;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "0;3;3;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "mvq4blDaCkN",
        "title": "Efficient Semi-Supervised Adversarial Training without Guessing Labels",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "1;3;5",
        "confidence": "5;4;3",
        "correctness": "1;3;4",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "1;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.9819805060619659,
        "project": "",
        "github": ""
    },
    {
        "id": "mwdfai8NBrJ",
        "title": "Policy Smoothing for Provably Robust Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "Reinforcement Learning;Provable Adversarial Robustness;Randomized Smoothing",
        "author": "",
        "aff": "Department of Computer Science, University of Maryland - College Park, USA",
        "rating": "5;6;6;6;8",
        "confidence": "2;2;5;3;4",
        "correctness": "3;4;3;4;4",
        "technical_novelty": "2;3;3;3;3",
        "empirical_novelty": "2;3;3;3;3",
        "presentation": "",
        "rating_avg": 6.2,
        "confidence_avg": 3.2,
        "correctness_avg": 3.6,
        "technical_novelty_avg": 2.8,
        "empirical_novelty_avg": 2.8,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.4900980294098034,
        "corr_rating_correctness": 0.5833333333333334,
        "project": "",
        "github": ""
    },
    {
        "id": "mz7Bkl2Pz6",
        "title": "Global Convergence and Stability of Stochastic Gradient Descent",
        "track": "main",
        "status": "Reject",
        "keywords": "Stochastic Gradient Descent;Nonconvexity;Noise Model;Global Convergence;Stability",
        "author": "",
        "aff": "",
        "rating": "6;6;6",
        "confidence": "4;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "3;0;0",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 1.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "n0OeTdNRG0Q",
        "title": "Efficient Sharpness-aware Minimization for Improved Training of Neural Networks",
        "track": "main",
        "status": "Poster",
        "keywords": "Efficient learning;gengeralization;training algorithm",
        "author": "",
        "aff": "Centre for Frontier AI Research (CFAR), A*STAR, Singapore; Institute of High Performance Computing (IHPC), A*STAR, Singapore; Department of Mathematics, National University of Singapore; Department of Electrical and Computer Engineering, National University of Singapore",
        "rating": "6;8;8;8",
        "confidence": "4;4;4;4",
        "correctness": "4;4;3;4",
        "technical_novelty": "3;4;3;4",
        "empirical_novelty": "3;4;3;4",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.5,
        "empirical_novelty_avg": 3.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": "https://github.com/dydjw9/Efficient_SAM"
    },
    {
        "id": "n1BMcctC12",
        "title": "Randomized Primal-Dual Coordinate Method for Large-scale Linearly Constrained Nonsmooth Nonconvex Optimization",
        "track": "main",
        "status": "Reject",
        "keywords": "primal-dual methods;constrained nonconvex nonsmooth optimization;coordinate descent methods;global convergence;iteration complexity",
        "author": "",
        "aff": "",
        "rating": "3;6;6;6",
        "confidence": "4;3;3;2",
        "correctness": "3;4;4;3",
        "technical_novelty": "2;3;2;2",
        "empirical_novelty": "1;3;0;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.816496580927726,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "n2EEbUzETI",
        "title": "Contextual Text Detection",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Scene Text Detection;Contextual Text Detection",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "4;5;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 4.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "http://xxxxxxx",
        "github": ""
    },
    {
        "id": "n54Drs00M1",
        "title": "Learning affective meanings that derives the social behavior using Bidirectional Encoder Representations from Transformers",
        "track": "main",
        "status": "Reject",
        "keywords": "Affect Control Theory;Bidirectional Encoder Representations from Transformers;affective lexicon;formal theory",
        "author": "",
        "aff": "",
        "rating": "1;3;3;5",
        "confidence": "4;2;4;3",
        "correctness": "2;3;2;3",
        "technical_novelty": "1;2;2;2",
        "empirical_novelty": "1;2;2;3",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4264014327112209,
        "corr_rating_correctness": 0.7071067811865476,
        "project": "",
        "github": ""
    },
    {
        "id": "n6Bc3YElODq",
        "title": "Model-Based Opponent Modeling",
        "track": "main",
        "status": "Reject",
        "keywords": "multi-agent reinforcement learning;opponent modeling",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "3;4;4;4",
        "correctness": "2;2;3;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.75,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 1.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "n7bD7_GSsce",
        "title": "Knowledge is reward: Learning optimal exploration by predictive reward cashing",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Optimal exploration;Bayes-adaptive;Belief-augmented;Information;Reinforcement Learning",
        "author": "",
        "aff": "",
        "rating": "5;5;5;8",
        "confidence": "4;4;2;2",
        "correctness": "3;4;3;3",
        "technical_novelty": "3;3;3;4",
        "empirical_novelty": "3;2;2;2",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "nBU_u6DLvoK",
        "title": "UniFormer: Unified Transformer for Efficient Spatial-Temporal Representation Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "Spatial-Temporal Representation Learning;3D Convolution;Transformer",
        "author": "",
        "aff": "",
        "rating": "6;8;8;8",
        "confidence": "3;4;3;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "3;2;4;3",
        "empirical_novelty": "3;4;4;3",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "nCw4talHmo5",
        "title": "ParaDiS: Parallelly Distributable Slimmable Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "convolutional neural networks;efficient inference;distributed inference;parallel distribution;slimmable neural networks;flexible neural networks",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;4;4;2",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "1;2;3;2",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6622661785325219,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "nD9Pf-PjTbT",
        "title": "Convergence of Generalized Belief Propagation Algorithm on Graphs with Motifs",
        "track": "main",
        "status": "Reject",
        "keywords": "Belief Propagation;Bethe energy function",
        "author": "",
        "aff": "",
        "rating": "1;1;3;3",
        "confidence": "5;4;3;4",
        "correctness": "1;1;3;3",
        "technical_novelty": "2;1;2;2",
        "empirical_novelty": "1;1;0;0",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 0.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7071067811865475,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "nDY6Y5x9vkA",
        "title": "A Two-Stage Data-Free Adversarial Patch Generation Framework",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Deep Learning;Computer Vision;Adversarial Attack",
        "author": "",
        "aff": "",
        "rating": "3;5;6",
        "confidence": "5;3;4",
        "correctness": "2;3;4",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6546536707079772,
        "corr_rating_correctness": 0.9819805060619659,
        "project": "",
        "github": ""
    },
    {
        "id": "nEfdkfAyRT8",
        "title": "Escaping Saddle Points in Nonconvex Minimax Optimization via Cubic-Regularized Gradient Descent-Ascent",
        "track": "main",
        "status": "Reject",
        "keywords": "Minimax optimization;Gradient descent-ascent;saddle point;cubic regularization;Lojasiewicz gradient geometry",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6;8",
        "confidence": "5;4;4;5;3",
        "correctness": "4;4;4;4;4",
        "technical_novelty": "2;2;4;4;3",
        "empirical_novelty": "0;1;0;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.2,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 1.4,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5634361698190111,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "nG4DkcHDw_",
        "title": "Does Adversarial Robustness Really Imply Backdoor Vulnerability?",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Adversarial training;backdoor attack",
        "author": "",
        "aff": "",
        "rating": "3;3;3;8",
        "confidence": "4;4;5;3",
        "correctness": "3;3;2;4",
        "technical_novelty": "1;2;2;3",
        "empirical_novelty": "2;3;3;4",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.816496580927726,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "nHpzE7DqAnG",
        "title": "Does your graph need a confidence boost? Convergent boosted smoothing on graphs with tabular node features",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Graph Neural Network;Boosting;Node classification;Tabular Data",
        "author": "",
        "aff": "Amazon; Shanghai Jiao Tong University; University of Maryland",
        "rating": "6;6;8;8",
        "confidence": "4;2;3;3",
        "correctness": "4;3;4;3",
        "technical_novelty": "2;3;3;4",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "nK7eZEURiJ4",
        "title": "Towards Understanding Distributional Reinforcement Learning: Regularization, Optimization, Acceleration and Sinkhorn Algorithm",
        "track": "main",
        "status": "Reject",
        "keywords": "distributional reinforcement learning",
        "author": "",
        "aff": "",
        "rating": "1;3;3;5",
        "confidence": "4;5;3;4",
        "correctness": "1;4;2;4",
        "technical_novelty": "1;2;2;2",
        "empirical_novelty": "1;2;0;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 1.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.8164965809277259,
        "project": "",
        "github": ""
    },
    {
        "id": "nKWjE4QF1hB",
        "title": "AlphaZero-based Proof Cost Network to Aid Game Solving",
        "track": "main",
        "status": "Poster",
        "keywords": "Monte-Carlo Tree Search;Solving Games;AlphaZero;Deep Reinforcement Learning",
        "author": "",
        "aff": "Department of Computer Science, National Yang Ming Chiao Tung University, Hsinchu, Taiwan; Research Center for Information Technology Innovation, Academia Sinica, Taiwan; Department of Computer Science, National Yang Ming Chiao Tung University, Hsinchu, Taiwan; Department of Computing Science, University of Alberta, Edmonton, Canada",
        "rating": "5;5;8;8",
        "confidence": "3;3;4;3",
        "correctness": "4;4;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896258,
        "corr_rating_correctness": -1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "nKZvpGRdJlG",
        "title": "Mind Your Solver! On Adversarial Attack and Defense for Combinatorial Optimization",
        "track": "main",
        "status": "Reject",
        "keywords": "Adversarial Attack;Combinatorial Optimization;Reinforcement Learning",
        "author": "",
        "aff": "Under double-blind review",
        "rating": "1;3;3;3",
        "confidence": "5;3;4;3",
        "correctness": "1;1;2;2",
        "technical_novelty": "3;2;1;3",
        "empirical_novelty": "1;3;2;2",
        "presentation": "",
        "rating_avg": 2.5,
        "confidence_avg": 3.75,
        "correctness_avg": 1.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8703882797784891,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "nL2lDlsrZU",
        "title": "SAINT: Improved Neural Networks for Tabular Data via Row Attention and Contrastive Pre-Training",
        "track": "main",
        "status": "Reject",
        "keywords": "Transformer;Tabular;Attention;Contrastive Pre-Training",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "5;4;4;4",
        "correctness": "2;2;3;3",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 4.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5555555555555555,
        "corr_rating_correctness": 0.9622504486493761,
        "project": "",
        "github": ""
    },
    {
        "id": "nLb60uXd6Np",
        "title": "Geometric Algebra Attention Networks for Small Point Clouds",
        "track": "main",
        "status": "Reject",
        "keywords": "deep learning;geometric algebra;equivariance;geometric deep learning;rotation equivariance;permutation equivariance;chemistry;physics;biology;attention;point cloud",
        "author": "",
        "aff": "",
        "rating": "3;6;6;6",
        "confidence": "4;2;3;3",
        "correctness": "2;4;4;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;4;2",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.816496580927726,
        "corr_rating_correctness": 0.8703882797784892,
        "project": "",
        "github": ""
    },
    {
        "id": "nMo44IjBHX5",
        "title": "Continual Learning Using Pseudo-Replay via Latent Space Sampling",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Continual learning;lifelong learning",
        "author": "",
        "aff": "",
        "rating": "5;5;6",
        "confidence": "3;4;3",
        "correctness": "4;3;4",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "3;2;3",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4999999999999999,
        "corr_rating_correctness": 0.4999999999999999,
        "project": "",
        "github": ""
    },
    {
        "id": "nNpDhjI2T_s",
        "title": "Learning to Coordinate in Multi-Agent Systems: A Coordinated Actor-Critic Algorithm and Finite-Time Guarantees",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Reinforcement Learning;Multi-Agent System;Optimization",
        "author": "",
        "aff": "",
        "rating": "5;5;6",
        "confidence": "4;4;2",
        "correctness": "3;4;4",
        "technical_novelty": "3;3;2",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.4999999999999999,
        "project": "",
        "github": ""
    },
    {
        "id": "nNqA3yrZdDJ",
        "title": "Sample Complexity of Offline Reinforcement Learning with Deep ReLU Networks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "offline reinforcement learning;deep ReLU networks;function approximation",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "3;3;3;3",
        "correctness": "4;3;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "1;1;0;0",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 0.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "nO5caZwFwYu",
        "title": "Efficient Active Search for Combinatorial Optimization Problems",
        "track": "main",
        "status": "Poster",
        "keywords": "heuristic search;combinatorial optimization;learning to optimize;reinforcement learning;traveling salesperson problem;vehicle routing problem;job shop scheduling problem",
        "author": "",
        "aff": "Samsung SDS, Korea; Bielefeld University, Germany",
        "rating": "6;6;8;8",
        "confidence": "3;3;4;4",
        "correctness": "4;4;4;4",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "3;3;2;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.5,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 1.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "nRCS3BfynGQ",
        "title": "Symmetry-driven graph neural networks",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "4;4;4;4",
        "correctness": "2;3;4;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "0;2;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9847319278346618,
        "project": "",
        "github": ""
    },
    {
        "id": "nRj0NcmSuxb",
        "title": "FairCal: Fairness Calibration for Face Verification",
        "track": "main",
        "status": "Poster",
        "keywords": "face verification;bias;fairness;clustering;calibration",
        "author": "",
        "aff": "McGill University; Universit\u00e9 de Montr\u00e9al, Mila; McGill University, Mila",
        "rating": "3;6;6",
        "confidence": "3;5;3",
        "correctness": "3;3;3",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "2;0;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 1.3333333333333333,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5000000000000001,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "nT0GS37Clr",
        "title": "FSL: Federated Supermask Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Collaborative learning;robustness;poisoning attacks;communication efficiency",
        "author": "",
        "aff": "",
        "rating": "3;6;6;6",
        "confidence": "4;4;4;5",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;0;2;2",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "nUoI0DKg_Ti",
        "title": "Learning Sampling Policy for Faster Derivative Free Optimization",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Derivative free optimization;reinforcement learning",
        "author": "",
        "aff": "",
        "rating": "3;3;3;6",
        "confidence": "4;4;4;3",
        "correctness": "2;3;2;4",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.8703882797784892,
        "project": "",
        "github": ""
    },
    {
        "id": "nWFFfnnz-mF",
        "title": "Effects of Conservatism on Offline Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Conservatism;Offline Reinforcement Learning;Optimization.",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5;5",
        "confidence": "3;3;3;2;4",
        "correctness": "2;2;2;3;3",
        "technical_novelty": "2;2;3;3;2",
        "empirical_novelty": "2;2;2;2;3",
        "presentation": "",
        "rating_avg": 4.2,
        "confidence_avg": 3.0,
        "correctness_avg": 2.4,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 2.2,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.6666666666666667,
        "project": "",
        "github": ""
    },
    {
        "id": "nWlk4jwupZ",
        "title": "ScheduleNet: Learn to solve multi-agent scheduling problems with reinforcement learning",
        "track": "main",
        "status": "Reject",
        "keywords": "scheduling problems;combinatorial optimization;reinforcement learning;graph;graph neural network",
        "author": "",
        "aff": "",
        "rating": "6;6;6;6",
        "confidence": "3;3;4;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "2;3;4;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "nWprF5r2spe",
        "title": "ON THE GENERALIZATION OF WASSERSTEIN ROBUST FEDERATED LEARNING",
        "track": "main",
        "status": "Reject",
        "keywords": "Federated Learning;Robust Optimization;Adversarial Training",
        "author": "",
        "aff": "",
        "rating": "3;5;6",
        "confidence": "4;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "1;3;3",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7559289460184545,
        "corr_rating_correctness": 0.7559289460184545,
        "project": "",
        "github": ""
    },
    {
        "id": "nZOUYEN6Wvy",
        "title": "Granger causal inference on DAGs identifies genomic loci regulating transcription",
        "track": "main",
        "status": "Poster",
        "keywords": "Granger causality;causal inference;graph neural networks;gene regulation;single-cell genomics;chromatin accessibility;directed acyclic graphs;single-cell multimodal",
        "author": "",
        "aff": "Computer Science and Artificial Intelligence Laboratory, MIT, Cambridge, MA 02139, USA; Department of Mathematics, MIT, Cambridge, MA 02139, USA; Computer Science and Artificial Intelligence Laboratory, MIT, Cambridge, MA 02139, USA",
        "rating": "8;8;8;8",
        "confidence": "4;3;3;4",
        "correctness": "4;3;4;4",
        "technical_novelty": "3;2;2;3",
        "empirical_novelty": "3;3;2;0",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/alexw16/gridnet"
    },
    {
        "id": "nZXmDrV5OA2",
        "title": "Assumption-Free Survival Analysis Under Local Smoothness Prior",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Survival analysis;time-to-event modeling;Neural ODE;regularization",
        "author": "",
        "aff": "",
        "rating": "1;3;3;5",
        "confidence": "5;3;5;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;3;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4264014327112209,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "nZeVKeeFYf9",
        "title": "LoRA: Low-Rank Adaptation of Large Language Models",
        "track": "main",
        "status": "Poster",
        "keywords": "Transfer learning;Adaptation;Transformer;Fine-tuning;Low-rank;RoBERTa;DeBERTa;GPT-2;GPT-3",
        "author": "",
        "aff": "Carnegie Mellon University; Microsoft Corporation",
        "rating": "6;6;8;8",
        "confidence": "5;4;5;4",
        "correctness": "3;2;4;4",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 4.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9045340337332909,
        "project": "",
        "github": "https://github.com/microsoft/LoRA"
    },
    {
        "id": "nZon4NT0WSw",
        "title": "TsmoBN: Interventional Generalization for Unseen Clients in Federated Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Federated Learning;Unseen Client Generalization;Structural Causal Model",
        "author": "",
        "aff": "",
        "rating": "3;3;5",
        "confidence": "4;4;4",
        "correctness": "2;2;2",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 4.0,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "naoQDOYsHnS",
        "title": "Learning Pseudometric-based Action Representations for Offline Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "offline reinforcement learning\uff0crepresentation learning\uff0c metric learning",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "4;3;2;3",
        "correctness": "3;3;4;4",
        "technical_novelty": "1;2;3;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7071067811865475,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "nbC8iTTXIrk",
        "title": "Optimization inspired Multi-Branch Equilibrium Models",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "Pazhou Lab, Guangzhou, 510330, China; Key Lab. of Machine Perception (MoE), School of Artificial Intelligence, Peking University; Institute for Artificial Intelligence, Peking University",
        "rating": "5;6;6;6",
        "confidence": "3;1;2;3",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 2.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5222329678670935,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "nc0ETaieux",
        "title": "Minimax Optimality (Probably) Doesn't Imply Distribution Learning for GANs",
        "track": "main",
        "status": "Poster",
        "keywords": "theory of GANs;distribution learning;pseudorandom generators;cryptography",
        "author": "",
        "aff": "CMU; UCLA; Microsoft Research; UC Berkeley",
        "rating": "3;6;6;6;6",
        "confidence": "3;3;4;3;4",
        "correctness": "3;3;3;3;4",
        "technical_novelty": "3;4;3;3;4",
        "empirical_novelty": "1;3;3;0;1",
        "presentation": "",
        "rating_avg": 5.4,
        "confidence_avg": 3.4,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 3.4,
        "empirical_novelty_avg": 1.6,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.4082482904638631,
        "corr_rating_correctness": 0.25,
        "project": "",
        "github": ""
    },
    {
        "id": "neqU3HWDgE",
        "title": "Unsupervised Disentanglement with Tensor Product Representations on the Torus",
        "track": "main",
        "status": "Poster",
        "keywords": "Variational Auto-Encoder;Disentanglement Learning",
        "author": "",
        "aff": "School of Physics and Astronomy, Tel-Aviv University, Israel; School of Computer Science, Tel-Aviv University, Israel; Univrses, Sweden",
        "rating": "3;6;8;8",
        "confidence": "5;3;3;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;4;4;3",
        "empirical_novelty": "2;3;4;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6998739952495694,
        "corr_rating_correctness": 0.8551861104941366,
        "project": "",
        "github": "https://github.com/rotmanmi/Unsupervised-Disentanglement-Torus"
    },
    {
        "id": "nf3A0WZsXS5",
        "title": "Surreal-GAN:Semi-Supervised Representation Learning via GAN for uncovering heterogeneous disease-related imaging patterns",
        "track": "main",
        "status": "Poster",
        "keywords": "Representation Learning;Disease-related imaging patterns;Alzheimer's disease;MRI;GAN",
        "author": "",
        "aff": "Center for Biomedical Image Computing and Analytics, University of Pennsylvania and Graduate Group in Applied Mathematics and Computational Science, University of Pennsylvania; Center for Biomedical Image Computing and Analytics, University of Pennsylvania",
        "rating": "5;6;8;8",
        "confidence": "4;4;3;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "1;3;3;4",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5555555555555555,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "ngjR4Gw9oAp",
        "title": "Soft Actor-Critic with Inhibitory Networks for Faster Retraining",
        "track": "main",
        "status": "Reject",
        "keywords": "soft actor-critic;SAC;maximum entropy RL;inhibitory response;cognitive control",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "3;3;4;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "nhN-fqxmNGx",
        "title": "A Comparison of Hamming Errors of Representative Variable Selection Methods",
        "track": "main",
        "status": "Poster",
        "keywords": "Lasso;Hamming error;phase diagram;rare and weak signals;elastic net;SCAD;thresholded Lasso;forward selection;forward backward selection",
        "author": "",
        "aff": "Department of Statistics, Harvard University, Cambridge, MA 02138, USA",
        "rating": "3;6;6;8",
        "confidence": "5;3;3;4",
        "correctness": "3;4;3;4",
        "technical_novelty": "2;3;3;4",
        "empirical_novelty": "1;3;3;4",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5488604301969737,
        "corr_rating_correctness": 0.7001400420140049,
        "project": "",
        "github": ""
    },
    {
        "id": "nhnJ3oo6AB",
        "title": "Learning Vision-Guided Quadrupedal Locomotion End-to-End with Cross-Modal Transformers",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Reinforcement Learning;Robotics;Locomotion Control;Multi-Modal Transformer",
        "author": "",
        "aff": "UC San Diego; UC Berkeley; Tsinghua University",
        "rating": "6;8;8;8",
        "confidence": "4;5;4;4",
        "correctness": "2;4;4;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.8703882797784891,
        "project": "https://rchalyang.github.io/LocoTransformer/",
        "github": ""
    },
    {
        "id": "niZImJIrqVt",
        "title": "Mean-Variance Efficient Reinforcement Learning by Expected Quadratic Utility Maximization",
        "track": "main",
        "status": "Reject",
        "keywords": "Reinforcement learning;Mean-variance tradeoff",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6;8",
        "confidence": "4;3;3;4;4",
        "correctness": "3;3;4;3;4",
        "technical_novelty": "2;2;3;3;3",
        "empirical_novelty": "2;3;2;0;3",
        "presentation": "",
        "rating_avg": 5.8,
        "confidence_avg": 3.6,
        "correctness_avg": 3.4,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.560112033611204,
        "corr_rating_correctness": 0.4900980294098034,
        "project": "",
        "github": ""
    },
    {
        "id": "nioAdKCEdXB",
        "title": "Likelihood Training of Schr\u00f6dinger Bridge using Forward-Backward SDEs Theory",
        "track": "main",
        "status": "Poster",
        "keywords": "Schr\u00f6dinger Bridge;score-based generative model;optimal transport;forward-backward stochastic differential equations;stochastic optimal control",
        "author": "",
        "aff": "Georgia Institute of Technology, USA",
        "rating": "5;6;8;8",
        "confidence": "3;5;4;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "4;3;4;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.058025885318565944,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/ghliu/SB-FBSDE"
    },
    {
        "id": "nj6G6ZPMuX",
        "title": "Reconstruction for disentanglement, Contrast for invariance",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Representation learning;Disentanglement learning;Invariant learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;5;4;4",
        "correctness": "3;2;3;4",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.7071067811865475,
        "project": "",
        "github": ""
    },
    {
        "id": "nkaba3ND7B5",
        "title": "Autonomous Reinforcement Learning: Formalism and Benchmarking",
        "track": "main",
        "status": "Poster",
        "keywords": "reinforcement learning;autonomous;reset-free reinforcement learning;continual reinforcement learning",
        "author": "",
        "aff": "Stanford University; University of California, Berkeley; MIT; Google Brain",
        "rating": "3;5;8;8",
        "confidence": "4;4;4;4",
        "correctness": "2;4;4;4",
        "technical_novelty": "1;2;3;2",
        "empirical_novelty": "2;1;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.8164965809277261,
        "project": "",
        "github": "https://github.com/architsharma97/earl_benchmark"
    },
    {
        "id": "nnU3IUMJmN",
        "title": "Capturing Structural Locality in Non-parametric Language Models",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "Carnegie Mellon University; School of Computer Science, Carnegie Mellon University",
        "rating": "6;6;6;8",
        "confidence": "3;2;4;3",
        "correctness": "4;4;4;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "0;1;2;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "noaG7SrPVK0",
        "title": "Counterfactual Plans under Distributional Ambiguity",
        "track": "main",
        "status": "Poster",
        "keywords": "Counterfactual explanations;Robust optimization",
        "author": "",
        "aff": "VinAI Research, Vietnam",
        "rating": "5;6;8",
        "confidence": "3;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "3;3;4",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 6.333333333333333,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 3.3333333333333335,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.944911182523068,
        "corr_rating_correctness": 0.7559289460184545,
        "project": "",
        "github": ""
    },
    {
        "id": "np5BgCFSsbm",
        "title": "Neocortical cell type classification from electrophysiology recordings using deep neural networks",
        "track": "main",
        "status": "Desk Reject",
        "keywords": "neuron type classification;convolutional neural network;electrophysiology",
        "author": "",
        "aff": "Department of Molecular and Cell Biology, University of California, Berkeley, Berkeley, CA 94720, USA; Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, Berkeley, CA 94720, USA; Department of Electrical Engineering and Computer Sciences, Helen Wills Neuroscience Institute, University of California, Berkeley, Berkeley, CA 94720, USA",
        "rating": "",
        "confidence": "",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "nrGGfMbY_qK",
        "title": "Online Continual Learning on Class Incremental Blurry Task Configuration with Anytime Inference",
        "track": "main",
        "status": "Poster",
        "keywords": "online;continual learning;task-free continual learning;any-time inference",
        "author": "",
        "aff": "NAVER AI Lab.; Yonsei University; Upstage AI Research; GIST, South Korea",
        "rating": "3;6;8;8",
        "confidence": "4;3;3;4",
        "correctness": "2;4;3;3",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3665083330689157,
        "corr_rating_correctness": 0.5183210553488161,
        "project": "",
        "github": "https://github.com/naver-ai/i-Blurry"
    },
    {
        "id": "nsjkNB2oKsQ",
        "title": "Off-Policy Reinforcement Learning with Delayed Rewards",
        "track": "main",
        "status": "Reject",
        "keywords": "Delayed Rewards;Off-Policy Reinforcement Learning",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;4;4;4",
        "correctness": "2;2;3;3",
        "technical_novelty": "2;3;2;2",
        "empirical_novelty": "2;0;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "nuWpS9FNSKn",
        "title": "One Objective for All Models --- Self-supervised Learning for Topic Models",
        "track": "main",
        "status": "Reject",
        "keywords": "self-supervised learning;topic models",
        "author": "",
        "aff": "",
        "rating": "5;6;6;6",
        "confidence": "4;3;3;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "nwKXyFvaUm",
        "title": "Diverse Client Selection for Federated Learning via Submodular Maximization",
        "track": "main",
        "status": "Poster",
        "keywords": "federated learning;submodularity;diversity",
        "author": "",
        "aff": "University of Washington; CMU; Intel Labs",
        "rating": "3;6;6;8",
        "confidence": "4;2;3;3",
        "correctness": "2;4;4;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;4;3;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5940885257860046,
        "corr_rating_correctness": 0.5488604301969737,
        "project": "",
        "github": ""
    },
    {
        "id": "nxcABL7jbQh",
        "title": "Zero Pixel Directional Boundary by Vector Transform",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "Computer Vision Lab, ETH Zurich, Switzerland and VISICS, ESAT/PSI, KU Leuven, Belgium; Computer Vision Lab, ETH Zurich, Switzerland",
        "rating": "6;6;8",
        "confidence": "3;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "3;3;4",
        "empirical_novelty": "3;2;4",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.3333333333333335,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.49999999999999983,
        "corr_rating_correctness": 0.9999999999999998,
        "project": "",
        "github": ""
    },
    {
        "id": "nzqZufLU1v",
        "title": "Lidar Range Image Compression with Deep Delta Encoding",
        "track": "main",
        "status": "Withdraw",
        "keywords": "lidar;point cloud;range image;compression;delta encoding",
        "author": "",
        "aff": "",
        "rating": "3;3;5",
        "confidence": "3;5;2",
        "correctness": "2;3;2",
        "technical_novelty": "2;1;2",
        "empirical_novelty": "1;1;2",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 1.6666666666666667,
        "empirical_novelty_avg": 1.3333333333333333,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7559289460184545,
        "corr_rating_correctness": -0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "nzvbBD_3J-g",
        "title": "On Incorporating Inductive Biases into VAEs",
        "track": "main",
        "status": "Poster",
        "keywords": "VAEs;Variational autoencoders;Variational auto-encoders;Representation learning;Inductive biases",
        "author": "",
        "aff": "University of Edinburgh; Department of Statistics, University of Oxford",
        "rating": "6;6;6;8",
        "confidence": "5;4;4;4",
        "correctness": "4;2;4;3",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": -0.17407765595569782,
        "project": "",
        "github": ""
    },
    {
        "id": "o-1v9hdSult",
        "title": "Bridging the Gap: Providing Post-Hoc Symbolic Explanations for Sequential Decision-Making Problems with Inscrutable Representations",
        "track": "main",
        "status": "Poster",
        "keywords": "Explanations;XAI;Post-hoc explanations",
        "author": "",
        "aff": "School of Computing & AI, Arizona State University",
        "rating": "5;6;8;10",
        "confidence": "4;2;4;4",
        "correctness": "2;4;3;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "0;3;3;4",
        "presentation": "",
        "rating_avg": 7.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3758230140014144,
        "corr_rating_correctness": 0.5888015039841447,
        "project": "",
        "github": ""
    },
    {
        "id": "o0ehFykKVtr",
        "title": "Know Thyself: Transferable Visual Control Policies Through Robot-Awareness",
        "track": "main",
        "status": "Poster",
        "keywords": "visual foresight;dynamics models;visuomotor control;video prediction;planning;transfer",
        "author": "",
        "aff": "GRASP Lab, University of Pennsylvania",
        "rating": "5;6;6;8",
        "confidence": "3;3;4;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;4;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.6882472016116854,
        "corr_rating_correctness": -0.13245323570650439,
        "project": "https://www.seas.upenn.edu/~hued/rac",
        "github": ""
    },
    {
        "id": "o1FEqIONNAa",
        "title": "Rank4Class: Examining Multiclass Classification through the Lens of Learning to Rank",
        "track": "main",
        "status": "Withdraw",
        "keywords": "multiclass classification;learning to rank;neural ranking models",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;3;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "o2Pgj6cCPXt",
        "title": "A Biology-Informed Similarity Metric for Simulated Patches of Human Cell Membrane",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Applications;Cancer Biology;Autonomous Multiscale;Metric Learning;Similarity Metrics",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "5;4;3;3",
        "correctness": "2;3;3;4",
        "technical_novelty": "2;4;2;3",
        "empirical_novelty": "2;2;2;0",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.899228803025897,
        "corr_rating_correctness": 0.9733285267845754,
        "project": "",
        "github": ""
    },
    {
        "id": "o2UwRc8fbXI",
        "title": "Adaptive Graph Capsule Convolutional Networks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;3;6",
        "confidence": "4;4;4;4",
        "correctness": "3;2;2;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;0;0;3",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 4.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "o6dG7nVYDS",
        "title": "Finding lost DG: Explaining domain generalization via model complexity",
        "track": "main",
        "status": "Reject",
        "keywords": "domain generalisation;rademacher complexity",
        "author": "",
        "aff": "",
        "rating": "3;5;5;8",
        "confidence": "4;4;4;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;2;4",
        "empirical_novelty": "1;2;3;4",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.7276068751089989,
        "project": "",
        "github": ""
    },
    {
        "id": "o86_622j0sb",
        "title": "Imperceptible Black-box Attack via Refining in Salient Region",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5",
        "confidence": "4;4;4;4",
        "correctness": "3;3;4;2",
        "technical_novelty": "3;2;2;2",
        "empirical_novelty": "2;3;3;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "o8gZlfQNZDJ",
        "title": "An Integrated System Architecture for Generative Audio Modeling",
        "track": "main",
        "status": "Withdraw",
        "keywords": "audio textures;sound synthesis;generative adversarial network;recurrent neural network;self organizing map",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "4;4;3;4",
        "correctness": "2;3;4;3",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;2;0;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4714045207910316,
        "corr_rating_correctness": 0.8660254037844386,
        "project": "",
        "github": ""
    },
    {
        "id": "o8iGesI9HN-",
        "title": "Optimized Separable Convolution: Yet Another Efficient Convolution Operator",
        "track": "main",
        "status": "Reject",
        "keywords": "Separable Convolution;Volumetric Receptive Field;Optimized",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5",
        "confidence": "4;5;4;3",
        "correctness": "2;3;4;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "o9DnX55PEAo",
        "title": "Cross-Architecture Distillation Using Bidirectional CMOW Embeddings",
        "track": "main",
        "status": "Reject",
        "keywords": "natural language processing;word embedding;knowledge distillation;model compression;efficient methods;transfer learning",
        "author": "",
        "aff": "",
        "rating": "3;5;6",
        "confidence": "5;3;4",
        "correctness": "2;3;4",
        "technical_novelty": "1;3;3",
        "empirical_novelty": "0;3;2",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6546536707079772,
        "corr_rating_correctness": 0.9819805060619659,
        "project": "",
        "github": ""
    },
    {
        "id": "oAy7yPmdNz",
        "title": "CoordX: Accelerating Implicit Neural Representation with a Split MLP Architecture",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "Department of Computer Science, University of Toronto; Vector Institute, Canada; Department of Computer Science, University of Toronto",
        "rating": "6;6;8;8",
        "confidence": "4;3;4;4",
        "correctness": "3;4;4;4",
        "technical_novelty": "3;2;3;4",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "oC12z8lkbrU",
        "title": "Generate, Annotate, and Learn: Generative Models Advance Self-Training and Knowledge Distillation",
        "track": "main",
        "status": "Reject",
        "keywords": "deep generative models;semi-supervised learning;knowledge distillation;large language models",
        "author": "",
        "aff": "",
        "rating": "5;5;6;8",
        "confidence": "4;4;4;3",
        "correctness": "3;4;4;4",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "3;3;4;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9428090415820632,
        "corr_rating_correctness": 0.4714045207910316,
        "project": "",
        "github": ""
    },
    {
        "id": "oDFvtxzPOx",
        "title": "Self-Supervision Enhanced Feature Selection with Correlated Gates",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Feature Selection;Feature Importance;Self-Supervised Learning",
        "author": "",
        "aff": "Chung-Ang University, Korea; UCLA, USA; University of Cambridge, UK, UCLA, USA, Alan Turing Institute, UK",
        "rating": "8;8;10",
        "confidence": "3;2;4",
        "correctness": "4;4;4",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 8.666666666666666,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8660254037844385,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "oEV21dutJ0L",
        "title": "Joint Self-Supervised Learning for Vision-based Reinforcement Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "reinforcement learning;self-supervised learning;data efficiency;generalization",
        "author": "",
        "aff": "",
        "rating": "1;3;5;5;6",
        "confidence": "4;4;4;4;4",
        "correctness": "2;2;3;3;3",
        "technical_novelty": "1;2;2;2;2",
        "empirical_novelty": "2;2;3;2;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6,
        "technical_novelty_avg": 1.8,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9128709291752769,
        "project": "",
        "github": ""
    },
    {
        "id": "oEyUP37aoU7",
        "title": "Secure Domain Adaptation with Multiple Sources",
        "track": "main",
        "status": "Withdraw",
        "keywords": "unsupervised domain adaptation;multi-source domain adaptation;data privacy;source-free adaptation",
        "author": "",
        "aff": "",
        "rating": "1;3;3;3",
        "confidence": "4;5;5;5",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;2;1",
        "empirical_novelty": "2;2;3;1",
        "presentation": "",
        "rating_avg": 2.5,
        "confidence_avg": 4.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 1.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "oJGDYQFKL3i",
        "title": "OBJECT DYNAMICS DISTILLATION FOR SCENE DECOMPOSITION AND REPRESENTATION",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "School of Artificial Intelligence, University of Chinese Academy of Sciences; Institute of Automation, Chinese Academy of Sciences; Centre for Artificial Intelligence and Robotics, Hong Kong Institute of Science & Innovation, Chinese Academy of Sciences",
        "rating": "5;6;6;6;8",
        "confidence": "3;3;3;2;3",
        "correctness": "2;3;4;3;4",
        "technical_novelty": "3;3;3;2;3",
        "empirical_novelty": "2;2;3;3;3",
        "presentation": "",
        "rating_avg": 6.2,
        "confidence_avg": 2.8,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.8,
        "empirical_novelty_avg": 2.6,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.10206207261596575,
        "corr_rating_correctness": 0.7637626158259733,
        "project": "",
        "github": "https://github.com/tqace/ODDN"
    },
    {
        "id": "oLYTo-pL0Be",
        "title": "Towards Scheduling Federated Deep Learning using Meta-Gradients for Inter-Hospital Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "federated learning;hospital",
        "author": "",
        "aff": "",
        "rating": "3;5;5",
        "confidence": "4;4;4",
        "correctness": "2;3;2",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "2;0;2",
        "presentation": "",
        "rating_avg": 4.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 1.3333333333333333,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.49999999999999983,
        "project": "",
        "github": ""
    },
    {
        "id": "oMI9PjOb9Jl",
        "title": "DAB-DETR: Dynamic Anchor Boxes are Better Queries for DETR",
        "track": "main",
        "status": "Poster",
        "keywords": "Object detection;Transformer",
        "author": "",
        "aff": "International Digital Economy Academy (IDEA); Dept. of Comp. Sci. and Tech., BNRist Center, State Key Lab for Intell. Tech. & Sys., Institute for AI, Tsinghua-Bosch Joint Center for ML, Tsinghua University.",
        "rating": "5;6;8",
        "confidence": "5;4;4",
        "correctness": "3;2;3",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 6.333333333333333,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7559289460184544,
        "corr_rating_correctness": 0.18898223650461363,
        "project": "",
        "github": "https://github.com/IDEA-opensource/DAB-DETR"
    },
    {
        "id": "oOuPVoT1kA5",
        "title": "FEVERLESS: Fast and Secure Vertical Federated Learning based on XGBoost for Decentralized Labels",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;6;8",
        "confidence": "3;4;2;3",
        "correctness": "3;2;3;4",
        "technical_novelty": "2;1;2;3",
        "empirical_novelty": "2;0;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5000000000000001,
        "corr_rating_correctness": 0.8333333333333334,
        "project": "",
        "github": "https://github.com/feverless111/vfl"
    },
    {
        "id": "oPON8TpOQVz",
        "title": "Chameleon Sampling: Diverse and Pure Example Selection for Online Continual Learning with Noisy Labels",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Continual Learning;Robust Learning;Noisy Labels;Label Noise",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5",
        "confidence": "3;4;4;2",
        "correctness": "3;2;2;3",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;3;2;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "oSP1hwZB24",
        "title": "Dynamic Parameterized Network for CTR Prediction",
        "track": "main",
        "status": "Reject",
        "keywords": "Recommendation System;Feature modeling;User Behavior modeling;Dynamic Network",
        "author": "",
        "aff": "",
        "rating": "3;5;6",
        "confidence": "5;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "1;2;3",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.944911182523068,
        "corr_rating_correctness": 0.7559289460184545,
        "project": "",
        "github": ""
    },
    {
        "id": "oTQNAU_g_AZ",
        "title": "DAIR: Disentangled Attention Intrinsic Regularization for Safe and Efficient Bimanual Manipulation",
        "track": "main",
        "status": "Reject",
        "keywords": "Reinforcement Learning;Safe Robotics;Bimanual Manipulation;Attention Mechanism",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "5;3;4;3",
        "correctness": "2;3;3;3",
        "technical_novelty": "3;3;3;2",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.899228803025897,
        "corr_rating_correctness": 0.9271726499455306,
        "project": "https://bimanual-attention.github.io/",
        "github": ""
    },
    {
        "id": "oU3aTsmeRQV",
        "title": "Self-ensemble Adversarial Training for Improved Robustness",
        "track": "main",
        "status": "Poster",
        "keywords": "Adversarial Example;Adversarial Training",
        "author": "",
        "aff": "Key Lab. of Machine Perception (MoE), School of Artificial Intelligence, Peking University; Institute for Artificial Intelligence, Peking University",
        "rating": "5;6;6;8",
        "confidence": "4;4;3;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "4;2;3;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.13245323570650439,
        "corr_rating_correctness": 0.9271726499455306,
        "project": "",
        "github": "https://github.com/whj363636/Self-Ensemble-Adversarial-Training"
    },
    {
        "id": "oVE1z8NlNe",
        "title": "Divergence-aware Federated Self-Supervised Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "Federated Learning;Self-supervised Learning;Unsupervised representation learning",
        "author": "",
        "aff": "NTU, Singapore; S-Lab, NTU, Singapore; SenseTime Research",
        "rating": "3;5;6;8",
        "confidence": "5;2;3;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.2480694691784169,
        "corr_rating_correctness": 0.8006407690254357,
        "project": "",
        "github": ""
    },
    {
        "id": "oVfIKuhqfC",
        "title": "Non-Denoising Forward-Time Diffusions",
        "track": "main",
        "status": "Reject",
        "keywords": "deep learning;diffusion;SDE;generative modelling;DDPM",
        "author": "",
        "aff": "",
        "rating": "3;5;5;8",
        "confidence": "3;2;4;2",
        "correctness": "4;3;3;4",
        "technical_novelty": "3;2;3;4",
        "empirical_novelty": "1;2;2;1",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 2.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.46442036401282394,
        "corr_rating_correctness": 0.14002800840280097,
        "project": "",
        "github": ""
    },
    {
        "id": "oWZsQ8o5EA",
        "title": "On the Generalization of Models Trained with SGD: Information-Theoretic Bounds and Implications",
        "track": "main",
        "status": "Poster",
        "keywords": "deep learning;generalization;information theory;learning bound;regularization",
        "author": "",
        "aff": "University of Ottawa",
        "rating": "5;6;8;10",
        "confidence": "3;3;4;3",
        "correctness": "4;3;3;4",
        "technical_novelty": "3;3;3;4",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 7.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.22549380840084865,
        "corr_rating_correctness": 0.13018891098082386,
        "project": "",
        "github": ""
    },
    {
        "id": "oZe7Zdia1H5",
        "title": "Lottery Tickets can have Structural Sparsity",
        "track": "main",
        "status": "Reject",
        "keywords": "Lottery Ticket Hypothesis;Structural Winning Tickets",
        "author": "",
        "aff": "",
        "rating": "5;6;8;8",
        "confidence": "5;4;4;4",
        "correctness": "1;4;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;4;4",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7777777777777777,
        "corr_rating_correctness": 0.7777777777777778,
        "project": "",
        "github": ""
    },
    {
        "id": "o_HsiMPYh_x",
        "title": "Leveraging unlabeled data to predict out-of-distribution performance",
        "track": "main",
        "status": "Poster",
        "keywords": "Distribution Shift;OOD error prediction;Deep Learning",
        "author": "",
        "aff": "Carnegie Mellon University; Google Research, Blueshift team; Google Research, Brain team",
        "rating": "5;6;8;8;8",
        "confidence": "4;3;4;3;4",
        "correctness": "3;4;4;4;4",
        "technical_novelty": "2;3;3;3;3",
        "empirical_novelty": "3;3;3;3;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.6,
        "correctness_avg": 3.8,
        "technical_novelty_avg": 2.8,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.7905694150420949,
        "project": "",
        "github": ""
    },
    {
        "id": "oaKw-GmBZZ",
        "title": "Learning Time-dependent PDE Solver using Message Passing Graph Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "graph neural networks;partial differential equations;time-dependent PDE;message passing graph neural networks",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;4;5;3",
        "correctness": "3;3;3;4",
        "technical_novelty": "1;2;2;3",
        "empirical_novelty": "0;2;1;0",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 0.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3244428422615251,
        "corr_rating_correctness": 0.6622661785325219,
        "project": "",
        "github": ""
    },
    {
        "id": "oapKSVM2bcj",
        "title": "Einops: Clear and Reliable Tensor Manipulations with Einstein-like Notation",
        "track": "main",
        "status": "Oral",
        "keywords": "tensor manipulations;tensor transformation;einops;einstein notation;einsum",
        "author": "",
        "aff": "Herophilus, Inc.",
        "rating": "3;3;6;8",
        "confidence": "4;5;4;4",
        "correctness": "2;2;4;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5443310539518174,
        "corr_rating_correctness": 0.9428090415820635,
        "project": "",
        "github": ""
    },
    {
        "id": "obi9EkyVeED",
        "title": "FedDrop: Trajectory-weighted Dropout for Efficient Federated Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "federated learning;efficient training;dropout;stochastic model;channel selection",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;3;4;3",
        "correctness": "2;4;4;3",
        "technical_novelty": "2;3;2;4",
        "empirical_novelty": "2;2;2;4",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.8703882797784891,
        "project": "",
        "github": ""
    },
    {
        "id": "oe8U8WETg4t",
        "title": "Linear Backpropagation Leads to Faster Convergence",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Convergence analysis;Backpropagation analysis",
        "author": "",
        "aff": "",
        "rating": "3;3;6",
        "confidence": "5;3;4",
        "correctness": "2;4;3",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "of3y9kPkAWA",
        "title": "Reinforcement Learning with Predictive Consistent Representations",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Reinforcement Learning;Data Efficiency;Representation Learning",
        "author": "",
        "aff": "",
        "rating": "1;3;5;5;5",
        "confidence": "4;3;4;4;4",
        "correctness": "2;3;3;3;3",
        "technical_novelty": "2;2;3;2;3",
        "empirical_novelty": "1;2;2;2;3",
        "presentation": "",
        "rating_avg": 3.8,
        "confidence_avg": 3.8,
        "correctness_avg": 2.8,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.25,
        "corr_rating_correctness": 0.8750000000000001,
        "project": "",
        "github": ""
    },
    {
        "id": "ofLwshMBL_H",
        "title": "Continual Learning Using Task Conditional Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "catastrophic forgetting;continual learning",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;4;4;4",
        "correctness": "3;2;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "oh4TirnfSem",
        "title": "PF-GNN: Differentiable particle filtering based approximation of universal graph representations",
        "track": "main",
        "status": "Poster",
        "keywords": "Graph Neural Networks;Graph representation learning;Expressive GNN",
        "author": "",
        "aff": "School of Computing, National University of Singapore; School of Computing, National University of Singapore & PayPal Innovation Lab",
        "rating": "6;6;8;8",
        "confidence": "2;5;5;3",
        "correctness": "3;3;3;4",
        "technical_novelty": "3;4;2;3",
        "empirical_novelty": "3;3;2;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.19245008972987523,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "ohKxcPdAscw",
        "title": "Improved Generalization-Robustness Trade-off via Uncertainty Targeted Attacks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "uncertainty estimation;adversarial-training",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "3;4;4;4",
        "correctness": "3;3;3;2",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;1;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": -1.0,
        "project": "",
        "github": "https://anonymous.4open.science/r/Uncertainty-Targeted-Attacks-5BD3"
    },
    {
        "id": "ohYt48SDnEQ",
        "title": "Stochastic Variance Reduced Ensemble Adversarial Attack",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Ensemble-based attack;adversarial example;stochastic variance reduced model;transferability",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;4;4;4",
        "correctness": "4;3;3;3",
        "technical_novelty": "1;2;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "oiZJwC_fyS",
        "title": "Neural Network Approximation based on Hausdorff distance of Tropical Zonotopes",
        "track": "main",
        "status": "Poster",
        "keywords": "Tropical Geometry;Zonotopes;Hausdorff Approximation;Neural Network Compression",
        "author": "",
        "aff": "University of Texas at Austin; National Technical University of Athens; ETH Zurich",
        "rating": "5;5;5;6",
        "confidence": "2;1;3;2",
        "correctness": "3;3;3;3",
        "technical_novelty": "3;3;4;3",
        "empirical_novelty": "3;3;2;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 2.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "oiy9BAuqnDg",
        "title": "Information Condensing Active Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "active learning",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;3;2;3",
        "correctness": "2;1;1;3",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.0,
        "correctness_avg": 1.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6488856845230502,
        "corr_rating_correctness": 0.20751433915982243,
        "project": "",
        "github": ""
    },
    {
        "id": "oj2yn1Q4Ett",
        "title": "Decentralized Learning for Overparameterized Problems: A Multi-Agent Kernel Approximation Approach",
        "track": "main",
        "status": "Poster",
        "keywords": "distributed optimization;over-parameterized optimization;kernel learning",
        "author": "",
        "aff": "The Ohio State University; Michigan State University; University of Minnesota; CUHK",
        "rating": "5;6;6",
        "confidence": "5;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "2;3;2",
        "empirical_novelty": "2;2;0",
        "presentation": "",
        "rating_avg": 5.666666666666667,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 1.3333333333333333,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9999999999999998,
        "corr_rating_correctness": 0.4999999999999999,
        "project": "",
        "github": ""
    },
    {
        "id": "okmZ6-zU6Lz",
        "title": "Quantifying the Controllability of Coarsely Characterized Networked Dynamical Systems",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;6;6",
        "confidence": "2;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "1;3;0",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 1.3333333333333333,
        "presentation_avg": 0,
        "corr_rating_confidence": 1.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "olQbo52II9",
        "title": "Learning to Solve Combinatorial Problems via Efficient Exploration",
        "track": "main",
        "status": "Reject",
        "keywords": "reinforcement learning;combinatorial optimisation;graph neural network;maximum cut",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;3;3;3",
        "correctness": "2;3;2;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9271726499455306,
        "corr_rating_correctness": 0.7608859102526822,
        "project": "",
        "github": ""
    },
    {
        "id": "on54StZqGQ_",
        "title": "Degradation Attacks on Certifiably Robust Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "adversarial examples;certified defenses;degradation attacks",
        "author": "",
        "aff": "",
        "rating": "5;6;6;6",
        "confidence": "5;3;5;3",
        "correctness": "2;2;3;4",
        "technical_novelty": "2;2;4;3",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.5222329678670935,
        "project": "",
        "github": ""
    },
    {
        "id": "onqK4xDBYji",
        "title": "BERMo: What can BERT learn from ELMo?",
        "track": "main",
        "status": "Withdraw",
        "keywords": "BERT;Pruning;Faster Convergence;Stable Pruning",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "4;4;4;3",
        "correctness": "3;3;2;3",
        "technical_novelty": "1;2;1;2",
        "empirical_novelty": "2;2;1;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 1.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "onwTC5W0XJ",
        "title": "Causally Focused Convolutional Networks Through Minimal Human Guidance",
        "track": "main",
        "status": "Reject",
        "keywords": "Causal Features;Convolutional Networks;Interpretability;Minimal Guidance;Computer Vision;Deep Learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5",
        "confidence": "3;4;4",
        "correctness": "3;2;3",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5,
        "corr_rating_correctness": 0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "oopnT6Vqho",
        "title": "Provable Regret Bounds for Deep Online Learning and Control",
        "track": "main",
        "status": "Withdraw",
        "keywords": "online learning;deep neural networks;online control;nonstochastic control",
        "author": "",
        "aff": "",
        "rating": "3;3;6;8",
        "confidence": "3;3;3;2",
        "correctness": "4;3;4;3",
        "technical_novelty": "1;2;3;3",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8164965809277261,
        "corr_rating_correctness": -0.23570226039551587,
        "project": "",
        "github": ""
    },
    {
        "id": "otOZeCahAhL",
        "title": "Towards Robust Domain Generalization in 2D Neural Audio Processing",
        "track": "main",
        "status": "Withdraw",
        "keywords": "2D audio processing;Domain generalization;Explicit normalization;Frequency-wise normalization;Domain-invariant feature",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;5;4;3",
        "correctness": "2;1;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;1;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.0,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.816496580927726,
        "corr_rating_correctness": 0.5222329678670935,
        "project": "",
        "github": ""
    },
    {
        "id": "ovRQmeVFbrC",
        "title": "PARS: PSEUDO-LABEL AWARE ROBUST SAMPLE SELECTION FOR LEARNING WITH NOISY LABELS",
        "track": "main",
        "status": "Reject",
        "keywords": "learning with label noise",
        "author": "",
        "aff": "",
        "rating": "5;6;6",
        "confidence": "3;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 5.666666666666667,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9999999999999997,
        "corr_rating_correctness": 0.4999999999999999,
        "project": "",
        "github": ""
    },
    {
        "id": "oxC2IBx8OuZ",
        "title": "Towards Federated Learning on Time-Evolving Heterogeneous Data",
        "track": "main",
        "status": "Reject",
        "keywords": "Federated Learning;Continual Learning;Convergence Analysis",
        "author": "",
        "aff": "",
        "rating": "3;3;8;8",
        "confidence": "4;3;3;3",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;4;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "oxwsctgY5da",
        "title": "A Branch and Bound Framework for Stronger Adversarial Attacks of ReLU Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "adversarial attack;branch and bound;adversarial robustness;deep neural network",
        "author": "",
        "aff": "",
        "rating": "6;6;8;8",
        "confidence": "2;3;3;2",
        "correctness": "4;4;3;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;3;2",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 2.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "oxxUMeFwEHd",
        "title": "Topological Graph Neural Networks",
        "track": "main",
        "status": "Poster",
        "keywords": "topology;persistent homology;gnn;graph neural networks;graph classification;node classification;filtrations;topological data analysis;tda",
        "author": "",
        "aff": "Department of Biosystems Science and Engineering, ETH Zurich, 4058 Basel, Switzerland; SIB Swiss Institute of Bioinformatics, Switzerland; Department of Biosystems Science and Engineering, ETH Zurich, 4058 Basel, Switzerland; SIB Swiss Institute of Bioinformatics, Switzerland; Institute of AI for Health, Helmholtz Munich, 85764 Neuherberg, Germany; Technical University of Munich, 80333 Munich, Germany; ESAT-STADIUS, KU Leuven, 3001 Leuven, Belgium",
        "rating": "6;6;6;6",
        "confidence": "3;3;3;3",
        "correctness": "4;3;3;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "oykI6Kmq3Xi",
        "title": "Fast Convergence of Optimistic Gradient Ascent in Network Zero-Sum Extensive Form Games",
        "track": "main",
        "status": "Desk Reject",
        "keywords": "extensive form games;network extensive form games;online learning;optimistic gradient descent ascent",
        "author": "",
        "aff": "Paper under double-blind review",
        "rating": "",
        "confidence": "",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "p-BhZSz59o4",
        "title": "BEiT: BERT Pre-Training of Image Transformers",
        "track": "main",
        "status": "Oral",
        "keywords": "self-supervised learning;pre-training;vision Transformer",
        "author": "",
        "aff": "Microsoft Research; Harbin Institute of Technology",
        "rating": "8;8;8;8",
        "confidence": "5;4;4;4",
        "correctness": "3;4;4;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;3;4",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/microsoft/unilm"
    },
    {
        "id": "p0rCmDEN_-",
        "title": "Visual hyperacuity with moving sensor and recurrent neural computations",
        "track": "main",
        "status": "Poster",
        "keywords": "visual system;convolutional neural networks;recurrent neural networks;active vision;active sensing;ocular drift",
        "author": "",
        "aff": "Dept. of Brain Sciences, Weizmann Institute, Rehovot, Israel",
        "rating": "3;3;5;10",
        "confidence": "3;5;4;4",
        "correctness": "2;2;3;4",
        "technical_novelty": "3;2;2;4",
        "empirical_novelty": "2;2;2;4",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9746972340815895,
        "project": "",
        "github": ""
    },
    {
        "id": "p36db089HBP",
        "title": "SONG: Self-Organizing Neural Graphs",
        "track": "main",
        "status": "Withdraw",
        "keywords": "decision graphs;self-organizing models;neural networks;Markov processes;decision trees;interpretability",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;3;4;3",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6882472016116854,
        "corr_rating_correctness": 0.6882472016116854,
        "project": "",
        "github": ""
    },
    {
        "id": "p3DKPQ7uaAi",
        "title": "Temporal Alignment Prediction for Supervised Representation Learning and Few-Shot Sequence Classification",
        "track": "main",
        "status": "Poster",
        "keywords": "Temporal Alignment;Supervised Representation Learning;Few-shot Action Recognition;Alignment Prediction;Sequence Classification",
        "author": "",
        "aff": "Beijing Key Laboratory of Big Data Management and Analysis Methods, Gaoling School of Arti\ufb01cial Intelligence, Renmin University of China, Beijing 100872, China",
        "rating": "6;6;8",
        "confidence": "3;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9999999999999998,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "p46vOpFJkr_",
        "title": "ExCon: Explanation-driven Supervised Contrastive Learning for Image Classification",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Representation Learning;Explainable Deep Learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;5;4;4",
        "correctness": "4;3;3;3",
        "technical_novelty": "3;2;2;2",
        "empirical_novelty": "2;3;3;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "p4H9QlbJvx",
        "title": "Rethinking Again the Value of Network Pruning -- A Dynamical Isometry Perspective",
        "track": "main",
        "status": "Reject",
        "keywords": "neural network pruning;dynamical isometry;model compression;filter pruning",
        "author": "",
        "aff": "",
        "rating": "3;5;5;8",
        "confidence": "4;4;3;5",
        "correctness": "2;2;3;3",
        "technical_novelty": "1;2;3;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 4.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5940885257860046,
        "corr_rating_correctness": 0.7001400420140049,
        "project": "",
        "github": ""
    },
    {
        "id": "p7LSrQ3AADp",
        "title": "Beyond Faithfulness: A Framework to Characterize and Compare Saliency Methods",
        "track": "main",
        "status": "Reject",
        "keywords": "saliency methods;interpretability;faithfulness;explainability;attribution;feature importance",
        "author": "",
        "aff": "",
        "rating": "3;5;8",
        "confidence": "4;5;5",
        "correctness": "3;3;4",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;3;0",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8029550685469661,
        "corr_rating_correctness": 0.9176629354822472,
        "project": "",
        "github": ""
    },
    {
        "id": "p98WJxUC3Ca",
        "title": "Discrepancy-Based Active Learning for Domain Adaptation",
        "track": "main",
        "status": "Poster",
        "keywords": "active learning;domain adaptation;discrepancy;kmedoids;single batch;covariate shift",
        "author": "",
        "aff": "Centre Borelli, Universit \u00b4e Paris-Saclay, CNRS, ENS Paris-Saclay; ENSIIE, Centre Borelli, Universit \u00b4e Paris-Saclay, CNRS, ENS Paris-Saclay; Michelin, Centre Borelli, Universit \u00b4e Paris-Saclay, CNRS, ENS Paris-Saclay",
        "rating": "6;6;6;6",
        "confidence": "4;3;4;3",
        "correctness": "4;4;3;3",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "3;3;2;2",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "pC00NfsvnSK",
        "title": "Improving zero-shot generalization in offline reinforcement learning using generalized similarity functions",
        "track": "main",
        "status": "Reject",
        "keywords": "reinforcement learning;representation learning;self-supervised learning;offline RL;generalized value function;generalization",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "2;3;4;4",
        "correctness": "3;2;3;4",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9045340337332909,
        "corr_rating_correctness": 0.7071067811865475,
        "project": "",
        "github": ""
    },
    {
        "id": "pETy-HVvGtt",
        "title": "Disentanglement Analysis with Partial Information Decomposition",
        "track": "main",
        "status": "Poster",
        "keywords": "disentangled representations;variational autoencoders;deep generative models",
        "author": "",
        "aff": "The University of Tokyo",
        "rating": "5;6;6;8",
        "confidence": "5;4;3;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;2;3;4",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3244428422615251,
        "corr_rating_correctness": 0.6882472016116854,
        "project": "",
        "github": ""
    },
    {
        "id": "pFyXqxChZc",
        "title": "IntSGD: Adaptive Floatless Compression of Stochastic Gradients",
        "track": "main",
        "status": "Spotlight",
        "keywords": "optimization;distributed optimization;compression;theory;parallel training;switchML",
        "author": "",
        "aff": "KAUST\u2217; CNRS, \u00c9cole Normale Sup\u00e9rieure, Inria; KAUST",
        "rating": "6;8;8",
        "confidence": "3;3;2",
        "correctness": "3;4;3",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 7.333333333333333,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.49999999999999983,
        "corr_rating_correctness": 0.49999999999999983,
        "project": "",
        "github": ""
    },
    {
        "id": "pIjvdJ_QUYv",
        "title": "Practical and Private Heterogeneous Federated Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;6;6",
        "confidence": "4;3;2",
        "correctness": "2;3;2",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "2;3;2",
        "presentation": "",
        "rating_avg": 5.666666666666667,
        "confidence_avg": 3.0,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8660254037844385,
        "corr_rating_correctness": 0.4999999999999999,
        "project": "",
        "github": ""
    },
    {
        "id": "pJAwaNEexRV",
        "title": "Gradient Assisted Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Multi-Organization Learning;Distributed Machine Learning;Machine Learning Applications",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "4;2;4;3",
        "correctness": "4;3;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;3;3;0",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.17407765595569782,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "pLNLdHrZmcX",
        "title": "SANE: Specialization-Aware Neural Network Ensemble",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "3;3;4;5",
        "correctness": "3;4;4;2",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;3;2;1",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9045340337332909,
        "corr_rating_correctness": -0.30151134457776363,
        "project": "",
        "github": ""
    },
    {
        "id": "pMQwKL1yctf",
        "title": "Language modeling via stochastic processes",
        "track": "main",
        "status": "Oral",
        "keywords": "contrastive learning;language modelling;stochastic processes",
        "author": "",
        "aff": "Stanford University",
        "rating": "8;8;8;8",
        "confidence": "4;4;4;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "3;3;4;3",
        "empirical_novelty": "3;3;4;3",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/rosewang2008/language_modeling_via_stochastic_processes"
    },
    {
        "id": "pN1JOdrSY9",
        "title": "Contrastive Clustering to Mine Pseudo Parallel Data for Unsupervised Translation",
        "track": "main",
        "status": "Poster",
        "keywords": "machine translation;unsupervised machine translation;pseudo-parallel data;contrastive clustering;pretraining",
        "author": "",
        "aff": "Nanyang Technological University; Meta AI; Johns Hopkins University",
        "rating": "5;6;8;8",
        "confidence": "4;4;4;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "4;3;4;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5555555555555555,
        "project": "",
        "github": ""
    },
    {
        "id": "pP9ag2g5f0",
        "title": "Exploring Complicated Search Spaces with Interleaving-Free Sampling",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Complicated search spaces;Interleaving-free sampling;Interleaved connections;Degradation",
        "author": "",
        "aff": "",
        "rating": "3;5;5;8",
        "confidence": "4;3;4;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.08084520834544431,
        "corr_rating_correctness": 0.7276068751089989,
        "project": "",
        "github": ""
    },
    {
        "id": "pQ02Y-onvZA",
        "title": "$\\sbf{\\delta^2}$-exploration for Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Reinforcement learning;exploration;Q-learning;DQN",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;3;4",
        "correctness": "2;3;3;2",
        "technical_novelty": "2;1;3;2",
        "empirical_novelty": "1;2;2;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "pSbqyZRKzbw",
        "title": "WHICH SAMPLES SHOULD BE LEARNED FIRST\uff1aEASY OR HARD\uff1f",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Sample weighting;Priority mode;Unified weighting scheme;Focal loss;Self-paced learning",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "5;3;3;3",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9271726499455306,
        "corr_rating_correctness": 0.6882472016116854,
        "project": "",
        "github": ""
    },
    {
        "id": "pSy3DZV3PGJ",
        "title": "Safe Multi-Task Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "multi-task learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5;5",
        "confidence": "5;5;5;4;3",
        "correctness": "2;2;4;3;3",
        "technical_novelty": "2;2;2;2;2",
        "empirical_novelty": "2;1;2;1;2",
        "presentation": "",
        "rating_avg": 4.2,
        "confidence_avg": 4.4,
        "correctness_avg": 2.8,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.6,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6123724356957946,
        "corr_rating_correctness": 0.8728715609439696,
        "project": "",
        "github": ""
    },
    {
        "id": "pTJKCACq6tM",
        "title": "Robust Training in High Dimensions via Block Coordinate Geometric Median Descent",
        "track": "main",
        "status": "Withdraw",
        "keywords": "robust;optimization;efficient;geometric median;median;breakdown point",
        "author": "",
        "aff": "",
        "rating": "",
        "confidence": "",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "Code Link",
        "github": ""
    },
    {
        "id": "pVU7Gp7Nq4k",
        "title": "Representation mitosis in wide neural networks",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "4;2;4;2",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;3;1;2",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "pWBNOgdeURp",
        "title": "An Operator Theoretic View On Pruning Deep Neural Networks",
        "track": "main",
        "status": "Poster",
        "keywords": "deep neural network pruning;Koopman operator theory",
        "author": "",
        "aff": "AIMdyn Inc.; Johns Hopkins University; AIMdyn Inc., UC Santa Barbara",
        "rating": "6;6;6;6",
        "confidence": "4;3;3;2",
        "correctness": "3;4;4;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "pXNXwaLu5MN",
        "title": "Domain-Invariant Representation Learning with Global and Local Consistency",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Domain adaptation;Wasserstein distance;Contrastive loss;Information theory",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;3;4;4",
        "correctness": "2;2;2;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.75,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "pabrsHBfKU",
        "title": "Adapt to Adaptation: Learning to Personalize for Cross-Silo Federated Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Federated learning;Personalization;Optimization",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "3;4;4;3",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.19245008972987526,
        "corr_rating_correctness": 0.7777777777777777,
        "project": "",
        "github": ""
    },
    {
        "id": "pbduKpYzn9j",
        "title": "A Comprehensive Overhaul of Distilling Unconditional GANs",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6;6",
        "confidence": "4;5;4;3;4",
        "correctness": "2;3;2;4;3",
        "technical_novelty": "2;2;2;3;3",
        "empirical_novelty": "2;2;2;2;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.8,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 2.2,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.2886751345948129,
        "corr_rating_correctness": 0.7319250547113999,
        "project": "",
        "github": ""
    },
    {
        "id": "per0G3dnkYh",
        "title": "Marginal Tail-Adaptive Normalizing Flows",
        "track": "main",
        "status": "Reject",
        "keywords": "Normalizing Flows;Heavy-Tailed Data;Generative Models",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "4;4;4;3",
        "correctness": "4;4;4;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;1;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "pfNyExj7z2",
        "title": "Vector-quantized Image Modeling with Improved VQGAN",
        "track": "main",
        "status": "Poster",
        "keywords": "VQGAN;Vision Transformers;Vector-quantized Image Modeling",
        "author": "",
        "aff": "Google Research",
        "rating": "6;6;6;6",
        "confidence": "4;5;4;4",
        "correctness": "3;4;3;4",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "3;3;3;4",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "pgKE5Q-CF2",
        "title": "Neuron-Enhanced Autoencoder based Collaborative filtering: Theory and Practice",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "1;3;5;5",
        "confidence": "5;3;4;4",
        "correctness": "1;3;4;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "1;2;2;3",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.42640143271122083,
        "corr_rating_correctness": 0.899228803025897,
        "project": "",
        "github": ""
    },
    {
        "id": "pgir5f7ekAL",
        "title": "Generative Principal Component Analysis",
        "track": "main",
        "status": "Poster",
        "keywords": "Principal component analysis;generative models;sparse principal component analysis;projected power methods;optimal statistical rates",
        "author": "",
        "aff": "PCG, Tencent; National University of Singapore; Chinese Academy of Sciences",
        "rating": "5;6;8",
        "confidence": "4;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "2;4;3",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 6.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.18898223650461363,
        "project": "",
        "github": ""
    },
    {
        "id": "pgkwZxLW8b",
        "title": "Efficient Image Representation Learning with Federated Sampled Softmax",
        "track": "main",
        "status": "Reject",
        "keywords": "Federated learning;sampled softmax",
        "author": "",
        "aff": "",
        "rating": "3;3;3;8",
        "confidence": "4;4;3;4",
        "correctness": "4;3;3;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;4",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "pjqqxepwoMy",
        "title": "Variational oracle guiding for reinforcement learning",
        "track": "main",
        "status": "Poster",
        "keywords": "variational Bayes;oracle guiding;reinforcement learning;decision making;probabilistic modeling;game;Mahjong",
        "author": "",
        "aff": "Microsoft Research Asia; Institute of Arti\ufb01cial Intelligence, Hefei Comprehensive National Science Center; University of Alberta; Okinawa Institute of Science and Technology",
        "rating": "3;6;6;8",
        "confidence": "4;4;3;4",
        "correctness": "2;3;2;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.75,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.08084520834544431,
        "corr_rating_correctness": 0.7001400420140049,
        "project": "",
        "github": "https://github.com/Agony5757/mahjong"
    },
    {
        "id": "pk7XtG0ln6Z",
        "title": "Response-based Distillation for Incremental Object Detection",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Incremental Object Detection;Incremental Learning;Knowledge Distillation",
        "author": "",
        "aff": "",
        "rating": "3;3;3",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;2;0",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.3333333333333333,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "pkh8bwJbUbL",
        "title": "Fair Representation Learning through Implicit Path Alignment",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Fairness",
        "author": "",
        "aff": "",
        "rating": "3;6;6;6",
        "confidence": "3;3;4;4",
        "correctness": "2;3;4;3",
        "technical_novelty": "2;2;3;4",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "pntT0DUWqw",
        "title": "DisTop: Discovering a Topological representation to learn diverse and rewarding skills",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Hierarchical reinforcement learning;Representation learning;Developmental learning;Reinforcement learning",
        "author": "",
        "aff": "",
        "rating": "1;3;3;6",
        "confidence": "5;4;4;4",
        "correctness": "2;2;2;4",
        "technical_novelty": "1;3;3;2",
        "empirical_novelty": "1;2;0;3",
        "presentation": "",
        "rating_avg": 3.25,
        "confidence_avg": 4.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7276068751089989,
        "corr_rating_correctness": 0.8892972917998875,
        "project": "",
        "github": ""
    },
    {
        "id": "pqD4hEOH2NW",
        "title": "Fingerprinting Multi-exit Deep Neural Network Models via Inference Time",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Adversarial Machine Learning;DNN Watermarking;DNN Fingerprinting;Intellectual Property Protection;Multi-exit Models;Robustness",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;5;4;4",
        "correctness": "3;2;2;4",
        "technical_novelty": "2;1;3;2",
        "empirical_novelty": "3;2;0;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.8703882797784891,
        "project": "",
        "github": ""
    },
    {
        "id": "prGV5dvPYy",
        "title": "Gradient flows on the feature-Gaussian manifold",
        "track": "main",
        "status": "Withdraw",
        "keywords": "gradient flow;feature-Gaussian manifold;MMD;hierarchical optimal transport",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "3;3;3;3",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;1;3;1",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9271726499455306,
        "project": "",
        "github": ""
    },
    {
        "id": "psNSQsmd4JI",
        "title": "Containerized Distributed Value-Based Multi-Agent Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Multi-agent reinforcement learning;Distributed reinforcement learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "3;3;3;4",
        "correctness": "3;2;3;2",
        "technical_novelty": "3;2;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "psQ6wcNXjS1",
        "title": "EBM Life Cycle: MCMC Strategies for Synthesis, Defense, and Density Modeling",
        "track": "main",
        "status": "Reject",
        "keywords": "energy-based model;MCMC sampling;Langevin sampling;generative modeling;unsupervised learning;image synthesis;adversarial defense;density estimation",
        "author": "",
        "aff": "",
        "rating": "3;3;5;8",
        "confidence": "4;4;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;1;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "psh0oeMSBiF",
        "title": "COPA: Certifying Robust Policies for Offline Reinforcement Learning against Poisoning Attacks",
        "track": "main",
        "status": "Poster",
        "keywords": "certified robustness;poisoning attacks;reinforcement learning",
        "author": "",
        "aff": "University of Illinois at Urbana-Champaign; Carnegie Mellon University; Lawrence Livermore National Laboratory; Amazon AWS AI",
        "rating": "5;5;6;6",
        "confidence": "2;4;4;2",
        "correctness": "4;3;3;3",
        "technical_novelty": "3;2;3;4",
        "empirical_novelty": "4;2;3;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "https://copa-leaderboard.github.io",
        "github": "https://github.com/copa-leaderboard"
    },
    {
        "id": "ptZfV8tJbpe",
        "title": "Modeling label correlations implicitly through latent label encodings for multi-label text classification",
        "track": "main",
        "status": "Reject",
        "keywords": "multi-label text classification;multi-label classification;label correlation;label embedding",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5;6",
        "confidence": "4;4;4;4;4",
        "correctness": "3;3;2;2;3",
        "technical_novelty": "2;2;1;1;3",
        "empirical_novelty": "1;2;2;2;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6,
        "technical_novelty_avg": 1.8,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "ptxGmKMLH_",
        "title": "A Closer Look at Prototype Classifier for Few-shot Image Classification",
        "track": "main",
        "status": "Reject",
        "keywords": "few-shot;meta-learning;prototypical network;fine-tuning;prototypical clasifier",
        "author": "",
        "aff": "",
        "rating": "5;6;6",
        "confidence": "4;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 5.666666666666667,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.4999999999999999,
        "project": "",
        "github": ""
    },
    {
        "id": "pu-8VNGljir",
        "title": "Learning to Affiliate: Mutual Centralized Learning for Few-shot Classification",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "3;3;3;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "pz1euXohm4H",
        "title": "Target-Side Input Augmentation for Sequence to Sequence Generation",
        "track": "main",
        "status": "Poster",
        "keywords": "Sequence Gerneration;Data Augmentation",
        "author": "",
        "aff": "Microsoft Research Asia; Gaoling School of Arti\ufb01cial Intelligence, Remin University of China",
        "rating": "5;6;6;8",
        "confidence": "4;4;4;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.6622661785325219,
        "project": "",
        "github": "https://github.com/TARGET-SIDE-DATA-AUG/TSDASG"
    },
    {
        "id": "pzgENfIRBil",
        "title": "Self-consistent Gradient-like Eigen Decomposition in Solving Schr\u00f6dinger Equations",
        "track": "main",
        "status": "Reject",
        "keywords": "Schr\u00f6dinger Equation;Hartree-Fock;Self-consistent;Eigen-decomposition;online learning;stochastic k-PCA;Oja's Algorithm;EigenGame",
        "author": "",
        "aff": "",
        "rating": "5;5;5;8",
        "confidence": "2;3;3;4",
        "correctness": "3;2;3;4",
        "technical_novelty": "2;2;3;4",
        "empirical_novelty": "2;2;3;4",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.816496580927726,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "q1QmAqT_4Zh",
        "title": "Koopman Q-learning: Offline Reinforcement Learning via Symmetries of Dynamics",
        "track": "main",
        "status": "Reject",
        "keywords": "offline reinforcement learning;representation learning;Koopman theory;symmetries of representations;data augmentation",
        "author": "",
        "aff": "",
        "rating": "5;6;6;6",
        "confidence": "3;4;3;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "q23I9kJE3gA",
        "title": "Conditional set generation using Seq2seq models",
        "track": "main",
        "status": "Reject",
        "keywords": "natural language processing;nlp;language generation",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "3;4;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "q2DCMRTvdZ-",
        "title": "Picking up the pieces: separately evaluating supernet training and architecture selection",
        "track": "main",
        "status": "Reject",
        "keywords": "neural architecture search;automl;deep learning theory",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3;5",
        "confidence": "4;5;5;4;4",
        "correctness": "3;4;3;3;4",
        "technical_novelty": "2;2;2;1;3",
        "empirical_novelty": "2;2;3;2;3",
        "presentation": "",
        "rating_avg": 3.4,
        "confidence_avg": 4.4,
        "correctness_avg": 3.4,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.40824829046386296,
        "corr_rating_correctness": 0.6123724356957946,
        "project": "",
        "github": ""
    },
    {
        "id": "q2ZaVU6bEsT",
        "title": "CONTEXT AUGMENTATION AND FEATURE REFINEMENT NETWORK FOR TINY OBJECT DETECTION",
        "track": "main",
        "status": "Reject",
        "keywords": "Tiny Object Detection;context augmentation;feature refinement;Data Enhancement",
        "author": "",
        "aff": "",
        "rating": "3;3;3",
        "confidence": "4;4;5",
        "correctness": "3;2;1",
        "technical_novelty": "3;1;1",
        "empirical_novelty": "2;2;1",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 1.6666666666666667,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "q4HaTeMO--y",
        "title": "Declarative nets that are equilibrium models",
        "track": "main",
        "status": "Poster",
        "keywords": "deep equilibrium models;deep declarative networks;implicit layers;kernel methods;generalised linear models",
        "author": "",
        "aff": "Data61, CSIRO, Canberra, Australia; Space & Astronomy, CSIRO, Epping, Australia; Machine Learning & Artificial Intelligence Future Science Platform",
        "rating": "6;6;6;8",
        "confidence": "2;4;3;3",
        "correctness": "4;3;4;3",
        "technical_novelty": "3;2;3;4",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "q4pQkTlImdk",
        "title": "Not All Attention Is All You Need",
        "track": "main",
        "status": "Withdraw",
        "keywords": "dropout;meta-learning;pre-trained language model;self-attention",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "3;3;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.6882472016116854,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "q4tZR1Y-UIs",
        "title": "It Takes Four to Tango: Multiagent Self Play for Automatic Curriculum Generation",
        "track": "main",
        "status": "Poster",
        "keywords": "curriculum generation;unsupervised reinforcement learning;goal conditioned reinforcement learning;multi agent",
        "author": "",
        "aff": "UCLA; UC Berkeley",
        "rating": "5;6;6;8",
        "confidence": "3;4;3;4",
        "correctness": "3;4;4;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.6882472016116854,
        "corr_rating_correctness": -0.2294157338705618,
        "project": "",
        "github": "https://github.com/yuqingd/cusp"
    },
    {
        "id": "q58E59ZPLp",
        "title": "Conceptron: a probabilistic deep one-class classification method",
        "track": "main",
        "status": "Withdraw",
        "keywords": "unsupervised learning;one-class learning;anomaly detection;nystrom method;kernel methods",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3;5",
        "confidence": "5;4;4;4;4",
        "correctness": "4;2;2;2;3",
        "technical_novelty": "2;2;2;2;2",
        "empirical_novelty": "1;1;2;1;2",
        "presentation": "",
        "rating_avg": 3.4,
        "confidence_avg": 4.2,
        "correctness_avg": 2.6,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.4,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.25,
        "corr_rating_correctness": 0.25000000000000006,
        "project": "",
        "github": ""
    },
    {
        "id": "q5ru7alcpfM",
        "title": "Unsupervised Domain Adaptation By Optimal Transportation Of Clusters Between Domains",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "1;3;3",
        "confidence": "5;3;3",
        "correctness": "4;2;3",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "1;2;2",
        "presentation": "",
        "rating_avg": 2.3333333333333335,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": -0.8660254037844387,
        "project": "",
        "github": ""
    },
    {
        "id": "q79uMSC6ZBT",
        "title": "Learning to Complete Code with Sketches",
        "track": "main",
        "status": "Poster",
        "keywords": "sketch;generative model;ml4code",
        "author": "",
        "aff": "School of Computer Science and Engineering, Sun Yat-sen University, China; Microsoft, Redmond, WA, USA; Microsoft Research, Cambridge, UK; Microsoft Research, Beijing, China",
        "rating": "5;6;8;8",
        "confidence": "4;4;5;4",
        "correctness": "3;4;4;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 4.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5555555555555555,
        "corr_rating_correctness": 0.7777777777777777,
        "project": "",
        "github": ""
    },
    {
        "id": "q7n2RngwOM",
        "title": "$\\beta$-Intact-VAE: Identifying and Estimating Causal Effects under Limited Overlap",
        "track": "main",
        "status": "Poster",
        "keywords": "VAE;variational autoencoder;balanced representation Learning;treatment effects;causal inference;identifiability;identification;CATE;ATE;weak overlap;limited overlap;Prognostic Model;Prognostic score",
        "author": "",
        "aff": "Department of Statistical Science, The Graduate University for Advanced Studies & The Institute of Statistical Mathematics, Tachikawa, Tokyo",
        "rating": "6;6;6;8",
        "confidence": "3;3;3;3",
        "correctness": "4;4;3;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;2;2",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "q9zIvzRaU94",
        "title": "Causal discovery from conditionally stationary time-series",
        "track": "main",
        "status": "Reject",
        "keywords": "causal discovery;temporal inference;graph neural network;time series;non-stationary;probabilistic modelling",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;3;4;3",
        "correctness": "2;3;3;2",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "qCBmozgVr9r",
        "title": "Few-Shot Attribute Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Few-shot learning;transfer learning;attribute learning",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "5;4;4;3",
        "correctness": "2;3;4;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9733285267845754,
        "corr_rating_correctness": 0.6488856845230502,
        "project": "",
        "github": ""
    },
    {
        "id": "qDx6DXD3Fzt",
        "title": "Provably Robust Detection of Out-of-distribution Data (almost) for free",
        "track": "main",
        "status": "Reject",
        "keywords": "out-of-distribution detection;adversarial noise;provable robustness;guarantees",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6;8",
        "confidence": "4;4;4;4;5",
        "correctness": "2;3;4;2;3",
        "technical_novelty": "2;2;3;2;3",
        "empirical_novelty": "2;2;4;2;3",
        "presentation": "",
        "rating_avg": 5.6,
        "confidence_avg": 4.2,
        "correctness_avg": 2.8,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 2.6,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.7385489458759964,
        "corr_rating_correctness": 0.4276686017238498,
        "project": "",
        "github": ""
    },
    {
        "id": "qEGBB9YB31",
        "title": "Where do Models go Wrong? Parameter-Space Saliency Maps for Explainability",
        "track": "main",
        "status": "Reject",
        "keywords": "explainability;interpretability;saliency maps;parameter saliency",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "5;4;4;2",
        "correctness": "4;2;3;4",
        "technical_novelty": "3;3;3;4",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6882472016116854,
        "corr_rating_correctness": 0.30151134457776363,
        "project": "",
        "github": ""
    },
    {
        "id": "qESp3gXBm2g",
        "title": "TRAKR \u2013 A reservoir-based tool for fast and accurate classification of neural time-series patterns",
        "track": "main",
        "status": "Reject",
        "keywords": "neuroscience;recurrent neural networks;reservoir networks;time series classification;neural data;electrophysiological recordings",
        "author": "",
        "aff": "",
        "rating": "3;6;6",
        "confidence": "4;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "2;3;2",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "qHsuiKXkUb",
        "title": "High Precision Score-based Diffusion Models",
        "track": "main",
        "status": "Reject",
        "keywords": "Diffusion Model;Score-based Model",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5;5",
        "confidence": "4;3;4;3;3",
        "correctness": "2;3;3;3;2",
        "technical_novelty": "2;3;2;2;3",
        "empirical_novelty": "2;4;4;2;3",
        "presentation": "",
        "rating_avg": 4.6,
        "confidence_avg": 3.4,
        "correctness_avg": 2.6,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6123724356957948,
        "corr_rating_correctness": 0.6123724356957948,
        "project": "",
        "github": ""
    },
    {
        "id": "qI4542Y2s1D",
        "title": "FILM: Following Instructions in Language with Modular Methods",
        "track": "main",
        "status": "Poster",
        "keywords": "Instruction Following;Visual Language Navigation;Embodied Instruction Following;VLN;ALFRED",
        "author": "",
        "aff": "Facebook AI Research; Carnegie Mellon University",
        "rating": "6;6;6;6",
        "confidence": "5;4;4;3",
        "correctness": "3;3;3;2",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "4;2;3;2",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "https://soyeonm.github.io/FILM%20webpage/",
        "github": "https://github.com/soyeonm/FILM"
    },
    {
        "id": "qLm6hqXBIj_",
        "title": "Learning Representations that Support Robust Transfer of Predictors",
        "track": "main",
        "status": "Withdraw",
        "keywords": "out-of-distribution generalization;representation learning",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "5;3;4;5",
        "correctness": "3;3;2;3",
        "technical_novelty": "2;3;2;2",
        "empirical_novelty": "1;3;3;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5222329678670935,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "qLqeb9AjD2o",
        "title": "Confidence-aware Training of Smoothed Classifiers for Certified Robustness",
        "track": "main",
        "status": "Reject",
        "keywords": "randomized smoothing;adversarial robustness;certified defense;adversarial defense;robust training;confidence calibration",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;5;4;3",
        "correctness": "4;3;3;3",
        "technical_novelty": "3;1;3;2",
        "empirical_novelty": "2;1;3;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7071067811865475,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "qNcedShvOs4",
        "title": "EinSteinVI: General and Integrated Stein Variational Inference",
        "track": "main",
        "status": "Reject",
        "keywords": "Stein variational inference;variational inference;probabilistic programming;Pyro;deep probabilistic programming;deep learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;3;3",
        "correctness": "4;3;4;3",
        "technical_novelty": "2;2;1;2",
        "empirical_novelty": "2;2;1;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "qO-PN1zjmi_",
        "title": "Novelty detection using ensembles with regularized disagreement",
        "track": "main",
        "status": "Reject",
        "keywords": "out-of-distribution detection;novelty detection;ensembles;ensemble diversity;outlier detection;regularization",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6;6",
        "confidence": "4;4;4;4;3",
        "correctness": "3;3;4;3;3",
        "technical_novelty": "2;2;2;3;3",
        "empirical_novelty": "2;2;3;3;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.8,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4564354645876385,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://bit.ly/3a7aQyN"
    },
    {
        "id": "qOcf6HgSmRH",
        "title": "DeeperGCN: All You Need to Train Deeper GCNs",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Graph Neural Networks;Graph Representation Learning",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;4;4;4",
        "correctness": "1;2;3;3",
        "technical_novelty": "2;3;2;2",
        "empirical_novelty": "2;0;3;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.0,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.899228803025897,
        "project": "",
        "github": ""
    },
    {
        "id": "qPQRIj_Y_EW",
        "title": "Learning to Solve an Order Fulfillment Problem in Milliseconds with Edge-Feature-Embedded Graph Attention",
        "track": "main",
        "status": "Reject",
        "keywords": "Combinatorial Optimization;Machine Learning;Modern Supply Chain Management",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "3;4;4;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "3;3;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.19245008972987526,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "qPzR-M6HY8x",
        "title": "Approximating Instance-Dependent Noise via Instance-Confidence Embedding",
        "track": "main",
        "status": "Reject",
        "keywords": "instance-dependent noise;label noise;classification;robustness;weakly supervised learning",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;4;4;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;4;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9271726499455306,
        "project": "",
        "github": ""
    },
    {
        "id": "qQuzhbU3Gto",
        "title": "An Interpretable Graph Generative Model with Heterophily",
        "track": "main",
        "status": "Reject",
        "keywords": "graph;network;generative;heterophily;community detection;link prediction;interpretability",
        "author": "",
        "aff": "",
        "rating": "3;3;5",
        "confidence": "4;5;4",
        "correctness": "3;2;3",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4999999999999999,
        "corr_rating_correctness": 0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "qR4qv6_113C",
        "title": "Exploring the Optimality of Tight-Frame Scattering Networks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Scattering Transforms;Wavelets;Few-sample learning",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;4;2;2",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;1;2",
        "empirical_novelty": "2;3;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "qRDQi3ocgR3",
        "title": "Which Shortcut Cues Will DNNs Choose? A Study from the Parameter-Space Perspective",
        "track": "main",
        "status": "Poster",
        "keywords": "shortcut learning;shortcut bias;loss geometry;simplicity bias;flat minima;generalization;wisconsin card sorting test",
        "author": "",
        "aff": "NAVER AI Lab, NAVER Corp, Seoul, 13638, Republic of Korea",
        "rating": "5;6;8",
        "confidence": "4;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 6.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.7559289460184545,
        "project": "",
        "github": ""
    },
    {
        "id": "qSTEPv2uLR8",
        "title": "Physics Informed Convex Artificial Neural Networks (PICANNs) for Optimal Transport based Density Estimation",
        "track": "main",
        "status": "Reject",
        "keywords": "Optimal Mass Transport;Density Estimation;Physics Informed Neural Networks;Input Convex Neural Networks;Monge Ampere Equation",
        "author": "",
        "aff": "",
        "rating": "5;5;6;8",
        "confidence": "4;3;5;3",
        "correctness": "3;4;3;3",
        "technical_novelty": "2;4;2;4",
        "empirical_novelty": "2;1;2;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.24618298195866545,
        "corr_rating_correctness": -0.4714045207910316,
        "project": "",
        "github": ""
    },
    {
        "id": "qSV5CuSaK_a",
        "title": "Few-Shot Backdoor Attacks on Visual Object Tracking",
        "track": "main",
        "status": "Poster",
        "keywords": "Backdoor Attack;Visual Object Tracking;AI Security;Deep Learning",
        "author": "",
        "aff": "Research Center of Arti\ufb01cial Intelligence, Peng Cheng Laboratory, China; School of Computer Science, Fudan University, China; Tsinghua Shenzhen International Graduate School, Tsinghua University, China",
        "rating": "6;6;6",
        "confidence": "4;2;3",
        "correctness": "3;3;3",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "qTBC7E4c454",
        "title": "Recursive Construction of Stable Assemblies of Recurrent Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "stability;deep learning;RNN;combinations;modularity;sparsity;negative feedback;sequence learning;contraction analysis",
        "author": "",
        "aff": "",
        "rating": "5;6;6;8",
        "confidence": "4;2;2;3",
        "correctness": "4;2;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 2.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.20751433915982243,
        "corr_rating_correctness": 0.13245323570650439,
        "project": "",
        "github": ""
    },
    {
        "id": "qTHBE7E9iej",
        "title": "Learning transferable motor skills with hierarchical latent mixture policies",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Robotics;Reinforcement Learning;Hierarchical;Latent Variable Models;Skills;Transfer",
        "author": "",
        "aff": "DeepMind, London, UK",
        "rating": "8;8;8;8",
        "confidence": "4;4;4;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "3;2;2;3",
        "empirical_novelty": "3;3;3;2",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "qTTccuW4dja",
        "title": "AriEL: volume coding for sentence generation comparisons",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;3;6",
        "confidence": "4;3;3;2",
        "correctness": "3;2;2;3",
        "technical_novelty": "3;1;2;3",
        "empirical_novelty": "1;0;2;3",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 3.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.816496580927726,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "qWhajfmKEUt",
        "title": "Delving into Feature Space: Improving Adversarial Robustness by Feature Spectral Regularization",
        "track": "main",
        "status": "Reject",
        "keywords": "adversarial example;adversarial robustness;spectral signature",
        "author": "",
        "aff": "",
        "rating": "3;5;6",
        "confidence": "4;4;3",
        "correctness": "2;3;3",
        "technical_novelty": "1;2;3",
        "empirical_novelty": "2;3;0",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7559289460184545,
        "corr_rating_correctness": 0.9449111825230683,
        "project": "",
        "github": ""
    },
    {
        "id": "qXBs0jmQkqx",
        "title": "FIFO: Learning Fog-invariant Features for Foggy Scene Segmentation",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Foggy scene understanding;Fog-invariant feature learning;Semantic segmentation",
        "author": "",
        "aff": "",
        "rating": "3;5;8",
        "confidence": "5;4;4",
        "correctness": "2;3;4",
        "technical_novelty": "2;2;4",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8029550685469661,
        "corr_rating_correctness": 0.9933992677987828,
        "project": "",
        "github": ""
    },
    {
        "id": "qXa0nhTRZGV",
        "title": "Understanding Sharpness-Aware Minimization",
        "track": "main",
        "status": "Reject",
        "keywords": "Sharpness-aware minimization;implicit bias;noisy labels;adversarial training",
        "author": "",
        "aff": "",
        "rating": "3;3;3;6",
        "confidence": "3;4;3;4",
        "correctness": "4;3;4;3",
        "technical_novelty": "2;1;3;3",
        "empirical_novelty": "2;2;0;3",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "qY79G8jGsep",
        "title": "DISSECT: Disentangled Simultaneous Explanations via Concept Traversals",
        "track": "main",
        "status": "Poster",
        "keywords": "Explainability;Interpretability;Counterfactual generation;Generative Adversarial Network;Variational Autoencoder",
        "author": "",
        "aff": "MIT; Google Research / MIT; Google Research",
        "rating": "6;6;6;6",
        "confidence": "4;3;4;3",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "qZNw8Ao_BIC",
        "title": "Understanding and Improving Robustness of Vision Transformers through Patch-based Negative Augmentation",
        "track": "main",
        "status": "Reject",
        "keywords": "Vision Transformer;robustness under distributional shift;data augmentation",
        "author": "",
        "aff": "",
        "rating": "3;5;6;8",
        "confidence": "4;4;5;4",
        "correctness": "1;4;3;4",
        "technical_novelty": "2;3;4;4",
        "empirical_novelty": "2;4;0;4",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 4.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.16012815380508713,
        "corr_rating_correctness": 0.792593923901217,
        "project": "",
        "github": ""
    },
    {
        "id": "qaQ8kUBYhEK",
        "title": "Spectral Multiplicity Entails Sample-wise Multiple Descent",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "Authors",
        "aff": "",
        "rating": "3;6;6;8",
        "confidence": "4;2;2;4",
        "correctness": "4;4;4;4",
        "technical_novelty": "1;2;3;3",
        "empirical_novelty": "0;0;3;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.14002800840280097,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "qaxhBG1UUaS",
        "title": "GPT-Critic: Offline Reinforcement Learning for End-to-End Task-Oriented Dialogue Systems",
        "track": "main",
        "status": "Poster",
        "keywords": "task-oriented dialogue;pre-trained language model;offline reinforcement learning",
        "author": "",
        "aff": "Graduate School of AI, KAIST, Daejeon, Republic of Korea; School of Computing, KAIST, Daejeon, Republic of Korea",
        "rating": "6;6;6;6",
        "confidence": "4;5;3;3",
        "correctness": "3;4;3;3",
        "technical_novelty": "3;1;2;3",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "qfGcsAGhFbc",
        "title": "Rethinking Client Reweighting for Selfish Federated Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Federated Learning;Sample Reweighting;Variance Reduction;Medical Image",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "3;4;3;3",
        "correctness": "2;2;3;4",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.9045340337332909,
        "project": "",
        "github": ""
    },
    {
        "id": "qfLJBJf_DnH",
        "title": "Brain insights improve RNNs' accuracy and robustness for hierarchical control of continually learned autonomous motor motifs",
        "track": "main",
        "status": "Reject",
        "keywords": "neuroscience;dynamical systems;thalamocortical architecture;motor preparation;continual learning;hierarchical continuous motor control;out-of-distribution generalization;robustness",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "3;4;3;2",
        "correctness": "2;3;3;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;4",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.816496580927726,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "qfaNCudAnji",
        "title": "Deep Q-Network with Proximal Iteration",
        "track": "main",
        "status": "Reject",
        "keywords": "reinforcement learning;deep learning",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;5;4;4",
        "correctness": "3;4;3;4",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "0;3;2;0",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 4.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "qgVYxyz2p7W",
        "title": "S2C2 - An orthogonal method for Semi-Supervised Learning on ambiguous labels",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Semi-Supervised;Data-Centric;Clustering;Classification",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;5;4;3",
        "correctness": "4;2;2;3",
        "technical_novelty": "1;2;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.816496580927726,
        "corr_rating_correctness": 0.17407765595569782,
        "project": "",
        "github": ""
    },
    {
        "id": "qhAeZjs7dCL",
        "title": "Generative Models as a Data Source for Multiview Representation Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "Generative models;GANs;Contrastive Learning;Representation Learning",
        "author": "",
        "aff": "Massachusetts Institute of Technology",
        "rating": "6;8;8;8",
        "confidence": "4;3;4;4",
        "correctness": "3;4;4;4",
        "technical_novelty": "3;3;2;2",
        "empirical_novelty": "3;4;3;4",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 3.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 1.0,
        "project": "https://ali-design.github.io/GenRep/",
        "github": ""
    },
    {
        "id": "qhC8mr2LEKq",
        "title": "CrossBeam: Learning to Search in Bottom-Up Program Synthesis",
        "track": "main",
        "status": "Poster",
        "keywords": "Program Synthesis;Bottom-Up Search",
        "author": "",
        "aff": "Cornell University; Google Research",
        "rating": "6;8;8;8",
        "confidence": "3;5;4;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "3;3;4;3",
        "empirical_novelty": "3;3;3;0",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.816496580927726,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": "https://github.com/google-research/crossbeam"
    },
    {
        "id": "qhkFX-HLuHV",
        "title": "Can an Image Classifier Suffice For Action Recognition?",
        "track": "main",
        "status": "Poster",
        "keywords": "action recognition;image classifier;super image;vision transformer",
        "author": "",
        "aff": "MIT-IBM Watson AI Lab",
        "rating": "6;8;8;8",
        "confidence": "5;3;3;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;4;3;3",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8703882797784891,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": "https://github.com/IBM/sifar-pytorch"
    },
    {
        "id": "qhqxE0z3r3y",
        "title": "A Decidability-Based Loss Function",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Metric Learning;Deep Learning",
        "author": "",
        "aff": "",
        "rating": "1;1;3;3",
        "confidence": "4;4;4;4",
        "correctness": "2;2;3;3",
        "technical_novelty": "1;1;2;2",
        "empirical_novelty": "1;1;2;2",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 1.5,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": "github link"
    },
    {
        "id": "qiBTPIoQ0lz",
        "title": "Improving OOD Generalization with Causal Invariant Transformations",
        "track": "main",
        "status": "Withdraw",
        "keywords": "domain generalization;minimax problem;structural model",
        "author": "",
        "aff": "",
        "rating": "1;3;5;8",
        "confidence": "5;5;3;3",
        "correctness": "3;2;3;4",
        "technical_novelty": "1;2;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8700628401410974,
        "corr_rating_correctness": 0.6835859270246631,
        "project": "",
        "github": ""
    },
    {
        "id": "qiMXBIf4NfB",
        "title": "How unlabeled data improve generalization in self-training? A one-hidden-layer theoretical analysis",
        "track": "main",
        "status": "Poster",
        "keywords": "Self-training;Semi-supervised learning;Convergence analysis;Generalization analysis",
        "author": "",
        "aff": "",
        "rating": "6;6;6;8",
        "confidence": "3;3;3;3",
        "correctness": "2;3;3;4",
        "technical_novelty": "3;3;2;4",
        "empirical_novelty": "3;3;1;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "qiSE7datah",
        "title": "Training Deep Neural Networks with Joint Quantization and Pruning of Features and Weights",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Deep Learning;Quantization;Pruning;Feature Sparsity;Model Compression;Unstructured Feature Pruning",
        "author": "Xinyu Zhang",
        "aff": "",
        "rating": "",
        "confidence": "",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "qiukmqxQF6",
        "title": "LatTe Flows: Latent Temporal Flows for Multivariate Sequence Analysis",
        "track": "main",
        "status": "Reject",
        "keywords": "time-series analysis;multivariate time series forecasting;latent space;autoregressive models",
        "author": "",
        "aff": "",
        "rating": "1;3;5",
        "confidence": "5;3;4",
        "correctness": "2;3;3",
        "technical_novelty": "1;1;2",
        "empirical_novelty": "1;2;3",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 1.3333333333333333,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5,
        "corr_rating_correctness": 0.8660254037844385,
        "project": "",
        "github": ""
    },
    {
        "id": "qj1IZ-6TInc",
        "title": "Real-Time Neural Voice Camouflage",
        "track": "main",
        "status": "Oral",
        "keywords": "automatic speech recognition;predictive models;privacy",
        "author": "",
        "aff": "Department of Computer Science, Columbia University, New York, NY, 10025",
        "rating": "8;8;8",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "voicecamo.cs.columbia.edu",
        "github": ""
    },
    {
        "id": "qjN4h_wwUO",
        "title": "GradMax: Growing Neural Networks using Gradient Information",
        "track": "main",
        "status": "Poster",
        "keywords": "efficient training;efficient;computer vision;architecture search",
        "author": "",
        "aff": "Google Research, Brain Team",
        "rating": "5;6;6;6",
        "confidence": "3;4;3;3",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;4;3;3",
        "empirical_novelty": "2;4;3;2",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": "https://github.com/google-research/growneuron"
    },
    {
        "id": "qkTEaJ9orc1",
        "title": "MOG: Molecular Out-of-distribution Generation with Energy-based Models",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Drug Discovery;Molecule Generation;Energy-based Models",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "4;3;4;4",
        "correctness": "4;3;2;3",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "qkpR1lriAKA",
        "title": "Vicinal Counting Networks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;3;4",
        "correctness": "3;3;2;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;0",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "{{project link not provided}}",
        "github": "{{github link not provided}}"
    },
    {
        "id": "qmf56RZbzFJ",
        "title": "State-Only Imitation Learning by Trajectory Distribution Matching",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Imitation Learning;Normalising Flows;Learning from Observations;Density Models",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "5;5;4;4",
        "correctness": "1;1;2;3",
        "technical_novelty": "1;2;2;2",
        "empirical_novelty": "2;2;1;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.5,
        "correctness_avg": 1.75,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "qnQN4yr6FJz",
        "title": "Variational Inference for Discriminative Learning with Generative Modeling of Feature Incompletion",
        "track": "main",
        "status": "Oral",
        "keywords": "Black-box variational inference;missing values;evidence upper bound",
        "author": "",
        "aff": "IBM Research \u2013 Tokyo",
        "rating": "5;6;6;8",
        "confidence": "3;4;3;4",
        "correctness": "4;4;4;4",
        "technical_novelty": "3;3;3;4",
        "empirical_novelty": "1;3;3;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.5,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.6882472016116854,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "qnm-2v-baW",
        "title": "Poly-CAM: High resolution class activation map for convolutional neural networks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "XAI;explainability;saliency map;CAM;deep learning;CNN;convolutional neural network",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5",
        "confidence": "3;4;4;5",
        "correctness": "4;3;4;3",
        "technical_novelty": "3;2;2;2",
        "empirical_novelty": "3;2;2;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "qoEa_G3pKop",
        "title": "ACCELERATING VARIATIONAL QUANTUM ALGORITHMS WITH MULTIPLE QUANTUM PROCESSORS",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Quantum machine learning;quantum neural network",
        "author": "",
        "aff": "",
        "rating": "3;3;3;6",
        "confidence": "3;4;3;5",
        "correctness": "2;3;2;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8703882797784892,
        "corr_rating_correctness": 0.8703882797784892,
        "project": "https://anonymous.4open.science/r/QUDIO-1076/",
        "github": ""
    },
    {
        "id": "qpcG27kYK6z",
        "title": "Concentric Spherical GNN for 3D Representation Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "spherical cnn;CNN;point cloud;graph convolution;rotation;equivariance;3D;molecular;volumetric",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "4;5;3;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "1;2;2;0",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5222329678670935,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "qqdXHUGec9h",
        "title": "Exploiting Class Activation Value for Partial-Label Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "Partial-label Learning;Class Activation Map",
        "author": "",
        "aff": "",
        "rating": "3;6;8",
        "confidence": "4;5;4",
        "correctness": "2;3;4",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 5.666666666666667,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.11470786693528084,
        "corr_rating_correctness": 0.9933992677987828,
        "project": "",
        "github": ""
    },
    {
        "id": "qrdbsZEZPZ",
        "title": "Certified Robustness for Free in Differentially Private Federated Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Certified Robustness;Differential Privacy;Federated Learning",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;3;4;2",
        "correctness": "3;4;3;4",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "0;2;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7608859102526822,
        "corr_rating_correctness": 0.6882472016116854,
        "project": "",
        "github": ""
    },
    {
        "id": "qsZoGvFiJn1",
        "title": "Hindsight is 20/20: Leveraging Past Traversals to Aid 3D Perception",
        "track": "main",
        "status": "Poster",
        "keywords": "3D object detection;perception with historical context",
        "author": "",
        "aff": "Cornell University, Ithaca, NY; The Ohio State University, Columbus, OH",
        "rating": "6;8;8;8",
        "confidence": "4;4;3;4",
        "correctness": "3;4;4;4",
        "technical_novelty": "3;4;4;4",
        "empirical_novelty": "3;4;4;4",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.75,
        "empirical_novelty_avg": 3.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": "https://github.com/YurongYou/Hindsight"
    },
    {
        "id": "qvUJV2-t_c",
        "title": "Using a one dimensional parabolic model of the full-batch loss to estimate learning rates during training",
        "track": "main",
        "status": "Reject",
        "keywords": "Empirics based Optimization;Optimization;Line Search;SGD;Deep Learning",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;4;2;4",
        "correctness": "3;2;2;4",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.8703882797784891,
        "project": "",
        "github": ""
    },
    {
        "id": "qw674L9PfQE",
        "title": "CLOOB: Modern Hopfield Networks with InfoLOOB Outperform CLIP",
        "track": "main",
        "status": "Reject",
        "keywords": "Deep learning;Associative memory;Hopfield networks;Contrastive learning;Multimodal learning",
        "author": "",
        "aff": "",
        "rating": "5;5;6;8",
        "confidence": "4;4;4;3",
        "correctness": "3;4;3;3",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9428090415820632,
        "corr_rating_correctness": -0.4714045207910316,
        "project": "",
        "github": ""
    },
    {
        "id": "qwBK94cP1y",
        "title": "Optimal Transport for Causal Discovery",
        "track": "main",
        "status": "Spotlight",
        "keywords": "causal discovery;optimal transport;functional causal model",
        "author": "",
        "aff": "KTH Royal Institute of Technology, Silo AI; Microsoft Research; KTH Royal Institute of Technology; Carnegie Mellon University, Mohamed bin Zayed University of Arti\ufb01cial Intelligence",
        "rating": "6;6;8",
        "confidence": "4;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "3;4;4",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 3.6666666666666665,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.49999999999999983,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "qwULHx9zld",
        "title": "Random matrices in service of ML footprint: ternary random features with no performance loss",
        "track": "main",
        "status": "Poster",
        "keywords": "Computationally efficient methods;kernel methods;random features;random matrix theory",
        "author": "",
        "aff": "University Grenoble Alpes, Inria, CNRS, Grenoble INP, LIG, 38000 Grenoble, France; Huazhong University of Science & Technology, China; Huawei Noah\u2019s Ark Lab (London)",
        "rating": "6;6;8;8",
        "confidence": "2;3;3;2",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;4;3;4",
        "empirical_novelty": "2;3;4;4",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 2.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "qy4uO5c_OB",
        "title": "Efficient Bi-level Optimization for Non-smooth Optimization",
        "track": "main",
        "status": "Withdraw",
        "keywords": "bilevel optimization;nonsmooth",
        "author": "",
        "aff": "",
        "rating": "3;5;6",
        "confidence": "4;4;4",
        "correctness": "2;4;4",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.944911182523068,
        "project": "",
        "github": ""
    },
    {
        "id": "qyTBxTztIpQ",
        "title": "CrowdPlay: Crowdsourcing Human Demonstrations for Offline Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "School of Engineering and Applied Sciences, Harvard University",
        "rating": "5;6;8",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "3;4;4",
        "empirical_novelty": "3;3;2",
        "presentation": "",
        "rating_avg": 6.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.6666666666666665,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "https://mgerstgrasser.github.io/crowdplay/",
        "github": "https://github.com/mgerstgrasser/crowdplay"
    },
    {
        "id": "qynB_fAt5TQ",
        "title": "Centroid Approximation for Bootstrap",
        "track": "main",
        "status": "Reject",
        "keywords": "bootstrap;centroid approximation;uncertainty",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;4;4;3",
        "correctness": "2;3;3;3",
        "technical_novelty": "3;3;3;1",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "qynwf18DgXM",
        "title": "Manifold Micro-Surgery with Linearly Nearly Euclidean Metrics",
        "track": "main",
        "status": "Reject",
        "keywords": "Geometry;Ricci flow;Neural network;Metric learning;Information geometry",
        "author": "",
        "aff": "",
        "rating": "3;3;5",
        "confidence": "3;2;3",
        "correctness": "2;3;3",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "1;0;0",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 0.3333333333333333,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5,
        "corr_rating_correctness": 0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "qyzTEWWM0Pp",
        "title": "Multiresolution Equivariant Graph Variational Autoencoder",
        "track": "main",
        "status": "Reject",
        "keywords": "group equivariant model;graph neural network;hierarchical generative model;variational autoencoder;graph generation;link prediction;unsupervised representation learning",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5;5;6",
        "confidence": "4;4;4;4;3;3",
        "correctness": "2;3;2;4;4;3",
        "technical_novelty": "3;2;2;3;3;3",
        "empirical_novelty": "2;2;0;3;1;3",
        "presentation": "",
        "rating_avg": 4.833333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 1.8333333333333333,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5252257314388904,
        "corr_rating_correctness": 0.4548588261473422,
        "project": "",
        "github": ""
    },
    {
        "id": "qzT7ONeJKaK",
        "title": "Confident Data-free Model Stealing for Black-box Adversarial Attacks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "machine learning;black-box attacks;data-free model stealing",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "4;4;2;5",
        "correctness": "2;2;3;3",
        "technical_novelty": "3;3;2;2",
        "empirical_novelty": "3;2;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "r4PibJdCyn",
        "title": "TotalRecall: A Bidirectional Candidates Generation Framework for Large Scale Recommender \\& Advertising Systems",
        "track": "main",
        "status": "Reject",
        "keywords": "Recommender System;Advertising System;Collaborative filtering;Matrix Factorization;Contrastive Learning;Candidates Generation;Embeddings",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "4;4;4;4",
        "correctness": "3;2;3;2",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "r5hq-Ooh_Ba",
        "title": "MutexMatch: Semi-supervised Learning with Mutex-based Consistency Regularization",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Semi-supervised learning;Barely supervised Learning;Mutex-based consistency regularization",
        "author": "",
        "aff": "",
        "rating": "5;5;5",
        "confidence": "4;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "4;2;3",
        "empirical_novelty": "3;3;0",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "r5qumLiYwf9",
        "title": "MaGNET: Uniform Sampling from Deep Generative Network Manifolds Without Retraining",
        "track": "main",
        "status": "Poster",
        "keywords": "Deep Generative Networks;Uniform Sampling;Fairness;Data Augmentation",
        "author": "",
        "aff": "Rice University",
        "rating": "5;6;8",
        "confidence": "4;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "4;2;4",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 6.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.3333333333333335,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.944911182523068,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://bit.ly/magnet-sampling"
    },
    {
        "id": "r88Isj2alz",
        "title": "NODEAttack: Adversarial Attack on the Energy Consumption of Neural ODEs",
        "track": "main",
        "status": "Reject",
        "keywords": "Adversarial Machine Learning;Energy Consumption",
        "author": "",
        "aff": "",
        "rating": "3;3;6;6",
        "confidence": "4;4;4;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896258,
        "project": "",
        "github": ""
    },
    {
        "id": "r8S93OsHWEf",
        "title": "Improving Adversarial Defense with Self-supervised Test-time Fine-tuning",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "4;4;4;3",
        "correctness": "3;3;4;4",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7777777777777777,
        "corr_rating_correctness": 0.9622504486493761,
        "project": "",
        "github": ""
    },
    {
        "id": "r9cpyzP-DQ",
        "title": "Learning Efficient and Robust Ordinary Differential Equations via Diffeomorphisms",
        "track": "main",
        "status": "Reject",
        "keywords": "Differentiable ODE integrator;Neural ODEs;diffeomorphisms;differential geometry",
        "author": "",
        "aff": "",
        "rating": "3;3;6;6",
        "confidence": "4;4;5;3",
        "correctness": "2;3;4;4",
        "technical_novelty": "2;2;4;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9045340337332909,
        "project": "",
        "github": ""
    },
    {
        "id": "rF5UoZFrsF4",
        "title": "VUT: Versatile UI Transformer for Multimodal Multi-Task User Interface Modeling",
        "track": "main",
        "status": "Reject",
        "keywords": "User Interface Modeling;Multimodal input;Multi-task learning;Transformer;Layout Detection;Language Grounding;Image Captioning;Screen Summarization;Tappability Prediction.",
        "author": "",
        "aff": "",
        "rating": "5;5;5",
        "confidence": "4;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "rFJWoYoxrDB",
        "title": "On Redundancy and Diversity in Cell-based Neural Architecture Search",
        "track": "main",
        "status": "Poster",
        "keywords": "NAS;machine learning architectures;AutoML",
        "author": "",
        "aff": "Huawei Noah\u2019s Ark Lab, London; Machine Learning Research Group, University of Oxford; Huawei Noah\u2019s Ark Lab, Hong Kong",
        "rating": "5;6;6;6;8",
        "confidence": "4;4;4;4;4",
        "correctness": "3;3;4;4;3",
        "technical_novelty": "2;2;3;2;3",
        "empirical_novelty": "2;3;3;3;3",
        "presentation": "",
        "rating_avg": 6.2,
        "confidence_avg": 4.0,
        "correctness_avg": 3.4,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 2.8,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.16666666666666663,
        "project": "",
        "github": "https://github.com/xingchenwan/cell-based-NAS-analysis"
    },
    {
        "id": "rFUwBW8qgIZ",
        "title": "CrossMatch: Improving Semi-Supervised Object Detection via Multi-Scale Consistency",
        "track": "main",
        "status": "Withdraw",
        "keywords": "semi-supervised learning;object detection;multi-scale learning",
        "author": "",
        "aff": "",
        "rating": "5;5;6",
        "confidence": "5;5;4",
        "correctness": "3;3;3",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9999999999999998,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "rFbR4Fv-D6-",
        "title": "Automated Self-Supervised Learning for Graphs",
        "track": "main",
        "status": "Poster",
        "keywords": "Self-supervised learning;Graph neural networks;AutoML",
        "author": "",
        "aff": "New Jersey Institute of Technology; Snap Inc.; Michigan State University; City University of Hong Kong",
        "rating": "5;6;6;8",
        "confidence": "4;3;4;4",
        "correctness": "3;4;3;4",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.13245323570650439,
        "corr_rating_correctness": 0.6882472016116854,
        "project": "",
        "github": ""
    },
    {
        "id": "rGg-Qcyplgq",
        "title": "Distributional Perturbation for Efficient Exploration in Distributional Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "distributional reinforcement learning;perturbation;exploration",
        "author": "",
        "aff": "",
        "rating": "5;6;6",
        "confidence": "4;3;3",
        "correctness": "4;3;3",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 5.666666666666667,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9999999999999997,
        "corr_rating_correctness": -0.9999999999999997,
        "project": "",
        "github": ""
    },
    {
        "id": "rHMaBYbkkRJ",
        "title": "CLEVA-Compass: A Continual Learning Evaluation Assessment Compass to Promote Research Transparency and Comparability",
        "track": "main",
        "status": "Poster",
        "keywords": "continual learning;lifelong learning;machine learning evaluation",
        "author": "",
        "aff": "AI and Machine Learning Group, Dept. of Computer Science, TU Darmstadt, Germany; Centre for Cognitive Science, TU Darmstadt, Germany; Hessian Center for AI (hessian.AI), Darmstadt, Germany; AI and Machine Learning Group, Dept. of Computer Science, TU Darmstadt, Germany",
        "rating": "5;8;8;8",
        "confidence": "3;4;4;5",
        "correctness": "2;4;3;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;3;0",
        "presentation": "",
        "rating_avg": 7.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.816496580927726,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "rI0LYgGeYaw",
        "title": "Understanding approximate and unrolled dictionary learning for pattern recovery",
        "track": "main",
        "status": "Poster",
        "keywords": "Dictionary learning;bi-level optimization;unrolling;pattern learning",
        "author": "",
        "aff": "Universit\u00e9 Paris-Saclay, Inria, CEA, L2S, Universit\u00e9 Paris-Saclay\u2013CNRS\u2013CentraleSupelec; L2S, Universit\u00e9 Paris-Saclay\u2013CNRS\u2013CentraleSupelec, Gif-sur-Yvette, 91190, France; Universit\u00e9 Paris-Saclay, Inria, CEA, Palaiseau, 91120, France",
        "rating": "3;6;6;8",
        "confidence": "4;5;4;3",
        "correctness": "2;3;3;4",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "1;2;2;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.39605901719066966,
        "corr_rating_correctness": 0.9901475429766743,
        "project": "",
        "github": ""
    },
    {
        "id": "rJvY_5OzoI",
        "title": "Multi-Critic Actor Learning: Teaching RL Policies to Act with Style",
        "track": "main",
        "status": "Poster",
        "keywords": "Reinforcement Learning;Multi-Style Learning;Multi-Task Learning;Actor-Critic",
        "author": "",
        "aff": "Boston University & Electronic Arts; Electronic Arts; Boston University & MIT-IBM Watson AI Lab",
        "rating": "6;6;6;8;8",
        "confidence": "4;4;5;4;4",
        "correctness": "3;3;3;3;3",
        "technical_novelty": "3;3;2;3;2",
        "empirical_novelty": "2;3;2;3;3",
        "presentation": "",
        "rating_avg": 6.8,
        "confidence_avg": 4.2,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 2.6,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.408248290463863,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "rLARdZ3FxCM",
        "title": "Projective Manifold Gradient Layer for Deep Rotation Regression",
        "track": "main",
        "status": "Withdraw",
        "keywords": "regression;rotation;manifold",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "4;5;4;3",
        "correctness": "2;2;4;3",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.816496580927726,
        "corr_rating_correctness": 0.7543365091413573,
        "project": "",
        "github": ""
    },
    {
        "id": "rMbLORc8oS",
        "title": "SemiRetro: Semi-template framework boosts deep retrosynthesis prediction",
        "track": "main",
        "status": "Reject",
        "keywords": "Retrosynthesis prediction;molecular graph learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "5;4;3;5",
        "correctness": "3;2;4;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.058025885318565944,
        "corr_rating_correctness": 0.8703882797784892,
        "project": "",
        "github": ""
    },
    {
        "id": "rN9tjzY9UD",
        "title": "Adaptive Learning of Tensor Network Structures",
        "track": "main",
        "status": "Reject",
        "keywords": "Tensor Networks;Tensor Network Topology;Structure Learning;Tensor Completion;Tensor Decomposition",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;5;3;4",
        "correctness": "3;2;2;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;1;2;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7071067811865475,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "rOGm97YR22N",
        "title": "Mixed-Memory RNNs for Learning Long-term Dependencies in Irregularly Sampled Time Series",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5;8;8",
        "confidence": "4;4;3;3;4",
        "correctness": "2;3;2;4;3",
        "technical_novelty": "2;2;3;4;3",
        "empirical_novelty": "3;3;3;4;3",
        "presentation": "",
        "rating_avg": 5.8,
        "confidence_avg": 3.6,
        "correctness_avg": 2.8,
        "technical_novelty_avg": 2.8,
        "empirical_novelty_avg": 3.2,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.29475317237328164,
        "corr_rating_correctness": 0.7994108773089582,
        "project": "",
        "github": ""
    },
    {
        "id": "rRg0ghtqRw2",
        "title": "That Escalated Quickly: Compounding Complexity by Editing Levels at the Frontier of Agent Capabilities",
        "track": "main",
        "status": "Reject",
        "keywords": "Reinforcement Learning;Unsupervised Environment Design",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "3;4;3;4",
        "correctness": "4;2;4;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "3;2;3;0",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": -0.17407765595569782,
        "project": "",
        "github": ""
    },
    {
        "id": "rS9-7AuPKWK",
        "title": "Towards Understanding Generalization via Decomposing Excess Risk Dynamics",
        "track": "main",
        "status": "Poster",
        "keywords": "generalization;excess risk;stability;dynamics",
        "author": "",
        "aff": "Department of Industrial and Operational Engineering, University of Michigan, Ann Arbor; Institute for Interdisciplinary Information Sciences, Tsinghua University and Shanghai Qi Zhi Institute; Institute for Interdisciplinary Information Sciences, Tsinghua University",
        "rating": "5;5;5;5",
        "confidence": "4;3;2;3",
        "correctness": "3;4;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;0;3;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "rS9t6WH34p",
        "title": "Decomposing 3D Scenes into Objects via Unsupervised Volume Segmentation",
        "track": "main",
        "status": "Reject",
        "keywords": "Representation Learning;Unsupervised Object Discovery;Neural Radiance Fields",
        "author": "",
        "aff": "",
        "rating": "5;6;6;8",
        "confidence": "3;3;3;2",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;2;3;4",
        "empirical_novelty": "2;3;3;4",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 2.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9271726499455306,
        "corr_rating_correctness": -0.13245323570650439,
        "project": "",
        "github": ""
    },
    {
        "id": "rSI-tyrv-ni",
        "title": "Does Entity Abstraction Help Generative Transformers Reason?",
        "track": "main",
        "status": "Reject",
        "keywords": "Transformers;reasoning;compositional generalization;entity type;abstraction",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "4;4;4;3",
        "correctness": "3;2;4;3",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;1;2;2",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7777777777777777,
        "corr_rating_correctness": 0.5443310539518174,
        "project": "",
        "github": ""
    },
    {
        "id": "rTAclwH46Tb",
        "title": "Eigencurve: Optimal Learning Rate Schedule for SGD on Quadratic Objectives with Skewed Hessian Spectrums",
        "track": "main",
        "status": "Poster",
        "keywords": "optimization;learning rate schedule;optimal convergence rate",
        "author": "",
        "aff": "The Hong Kong University of Science and Technology; Xi\u2019an Jiaotong University",
        "rating": "6;6;6;8",
        "confidence": "4;3;4;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "3;2;4;3",
        "empirical_novelty": "3;2;1;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "rUPMwMfrVvb",
        "title": "Improving Discriminative Visual Representation Learning via Automatic Mixup",
        "track": "main",
        "status": "Withdraw",
        "keywords": "representation learning;classification;mixup",
        "author": "",
        "aff": "",
        "rating": "5;5;6",
        "confidence": "4;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.4999999999999999,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "rUwm9wCjURV",
        "title": "In a Nutshell, the Human Asked for This: Latent Goals for Following Temporal Specifications",
        "track": "main",
        "status": "Poster",
        "keywords": "Deep Reinforcement Learning;Out-Of-Distribution Generalisation;Temporal Logic",
        "author": "",
        "aff": "Department of Computing, Imperial College London, London, United Kingdom; IBISC, Universit\u00e9 d\u2019Evry, Evry, France",
        "rating": "3;6;8;8",
        "confidence": "4;4;3;4",
        "correctness": "2;3;4;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "1;3;3;4",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.49374193110101877,
        "corr_rating_correctness": 0.9945577827230725,
        "project": "",
        "github": ""
    },
    {
        "id": "rWXfFogxRJN",
        "title": "AdaAug: Learning Class- and Instance-adaptive Data Augmentation Policies",
        "track": "main",
        "status": "Poster",
        "keywords": "Data Augmentation;Automated Data Augmentation",
        "author": "",
        "aff": "Department of Computer Science and Engineering, The Hong Kong University of Science and Technology",
        "rating": "6;6;6;8",
        "confidence": "4;4;4;5",
        "correctness": "3;4;4;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 4.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 1.0,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": "https://github.com/jamestszhim/adaptive_augment"
    },
    {
        "id": "rX3rZYP8zZF",
        "title": "CareGraph: A Graph-based Recommender System for Diabetes Self-Care",
        "track": "main",
        "status": "Reject",
        "keywords": "knowledge graph;knowledge graph embedding;recommendation system",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;4;4;5",
        "correctness": "3;2;2;2",
        "technical_novelty": "2;1;2;2",
        "empirical_novelty": "3;1;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.25,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 1.0,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "rYzcqIR5Uq-",
        "title": "Burst Image Restoration and Enhancement",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Burst super-resolution;multi-frame processing;feature alignment;burst image enhancement",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "4;4;3;4",
        "correctness": "3;1;3;3",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.75,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "rbFPSQHlllm",
        "title": "AutoMO-Mixer: An automated multi-objective multi-layer perspecton Mixer model for medical image based diagnosis",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "1;1;3;3",
        "confidence": "5;4;4;4",
        "correctness": "1;2;2;3",
        "technical_novelty": "1;1;2;2",
        "empirical_novelty": "1;1;2;2",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.25,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 1.5,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.7071067811865475,
        "project": "",
        "github": ""
    },
    {
        "id": "rbPg0zkHGi",
        "title": "Deep Active Learning with Noise Stability",
        "track": "main",
        "status": "Reject",
        "keywords": "deep learning;active learning;noise stability",
        "author": "",
        "aff": "",
        "rating": "3;5;6",
        "confidence": "5;3;4",
        "correctness": "1;3;3",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;0;3",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 4.0,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6546536707079772,
        "corr_rating_correctness": 0.944911182523068,
        "project": "",
        "github": ""
    },
    {
        "id": "rbv-uYT1zR",
        "title": "Coherence-Based Document Clustering",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Topic Modeling;LDA;Transformers;Coherence;Document Clustering",
        "author": "",
        "aff": "",
        "rating": "1;1;3",
        "confidence": "5;4;4",
        "correctness": "1;3;2",
        "technical_novelty": "1;2;2",
        "empirical_novelty": "1;1;1",
        "presentation": "",
        "rating_avg": 1.6666666666666667,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 1.6666666666666667,
        "empirical_novelty_avg": 1.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4999999999999999,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "rczz7TUKIIB",
        "title": "Loss meta-learning for forecasting",
        "track": "main",
        "status": "Reject",
        "keywords": "meta-learning;loss function;forecasting;learning to learn",
        "author": "",
        "aff": "",
        "rating": "1;3;3;6",
        "confidence": "4;4;5;3",
        "correctness": "2;2;1;3",
        "technical_novelty": "1;2;2;3",
        "empirical_novelty": "1;1;1;3",
        "presentation": "",
        "rating_avg": 3.25,
        "confidence_avg": 4.0,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5940885257860046,
        "corr_rating_correctness": 0.5940885257860046,
        "project": "",
        "github": ""
    },
    {
        "id": "rdBuE6EigGl",
        "title": "The Importance of the Current Input in Sequence Modeling",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5",
        "confidence": "3;5;5",
        "correctness": "4;3;3",
        "technical_novelty": "2;1;3",
        "empirical_novelty": "2;0;2",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.3333333333333333,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5,
        "corr_rating_correctness": -0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "reFFte7mA0F",
        "title": "Conditional Expectation based Value Decomposition for Scalable On-Demand Ride Pooling",
        "track": "main",
        "status": "Reject",
        "keywords": "Ride-Pool Matching Problem(RMP);Value Decomposition;Approximate Dynamic Programming(ADP);Reinforcement Learning",
        "author": "",
        "aff": "",
        "rating": "5;5;8",
        "confidence": "4;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "3;2;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "rhDaUTtfsqs",
        "title": "Curriculum Learning: A Regularization Method for Efficient and Stable Billion-Scale GPT Model Pre-Training",
        "track": "main",
        "status": "Reject",
        "keywords": "curriculum learning;natural language processing;language model pre-training",
        "author": "",
        "aff": "",
        "rating": "5;5;5;8",
        "confidence": "3;5;4;3",
        "correctness": "4;4;2;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5222329678670935,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "rhOiUS8KQM9",
        "title": "Enabling Arbitrary Translation Objectives with Adaptive Tree Search",
        "track": "main",
        "status": "Poster",
        "keywords": "Machine Translation;Decoding;MCTS;Beam Search",
        "author": "",
        "aff": "Amazon.com; Talka, Inc.; DeepMind, Ltd.",
        "rating": "5;6;6;8",
        "confidence": "3;4;4;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;2;3;4",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.6622661785325219,
        "corr_rating_correctness": 0.9271726499455306,
        "project": "",
        "github": ""
    },
    {
        "id": "rl8jF3GENq",
        "title": "Wavelet-Packet Powered Deepfake Image Detection",
        "track": "main",
        "status": "Reject",
        "keywords": "signal processing;wavelets;wavelet packets;deepfake detection",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5;5",
        "confidence": "4;5;3;5;4",
        "correctness": "3;4;3;4;3",
        "technical_novelty": "2;1;2;3;3",
        "empirical_novelty": "2;2;2;2;2",
        "presentation": "",
        "rating_avg": 4.2,
        "confidence_avg": 4.2,
        "correctness_avg": 3.4,
        "technical_novelty_avg": 2.2,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3273268353539886,
        "corr_rating_correctness": -0.16666666666666663,
        "project": "",
        "github": ""
    },
    {
        "id": "rlYiXFdSy70",
        "title": "Graph-Enhanced Exploration for Goal-oriented Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "Deep Reinforcement Learning;Goal-oriented Reinforcement Learning;Graph Structure;Exploration",
        "author": "",
        "aff": "",
        "rating": "6;6;6;6",
        "confidence": "4;4;2;3",
        "correctness": "3;3;4;3",
        "technical_novelty": "3;3;2;4",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "rmMOupN1Sqp",
        "title": "Don't Take It Literally: An Edit-Invariant Sequence Loss for Text Generation",
        "track": "main",
        "status": "Withdraw",
        "keywords": "text generation;edit invariance;natural language processing;text stytle transfer;learning with noise",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;4;3;4",
        "correctness": "2;3;3;4",
        "technical_novelty": "3;3;3;4",
        "empirical_novelty": "3;4;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.13245323570650439,
        "corr_rating_correctness": 0.9733285267845754,
        "project": "",
        "github": ""
    },
    {
        "id": "roaUjIvWD8j",
        "title": "Fingerprints of Super Resolution Networks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "super resolution;model attribution;model parsing;GAN;image forensics",
        "author": "",
        "aff": "",
        "rating": "3;3;3;6",
        "confidence": "4;4;5;3",
        "correctness": "2;3;4;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.816496580927726,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "roaZrQMGsd6",
        "title": "CARD: Certifiably Robust Machine Learning Pipeline via Domain Knowledge Integration",
        "track": "main",
        "status": "Withdraw",
        "keywords": "certified robustness;knowledge rule integration",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "4;4;3;4",
        "correctness": "3;2;3;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "roxWnqcguNq",
        "title": "Constituency Tree Representation for Argument Unit Recognition",
        "track": "main",
        "status": "Reject",
        "keywords": "transformer;attention;bert;graph attention network;constituency parsing;deep learning",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;5;4;4",
        "correctness": "2;3;2;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "rpxJc9j04U",
        "title": "Proof Artifact Co-Training for Theorem Proving with Language Models",
        "track": "main",
        "status": "Poster",
        "keywords": "self-supervised learning;mathematics;reasoning;theorem proving;language modeling",
        "author": "",
        "aff": "Carnegie Mellon University\u2021; Google Research, Stanford University\u2020; University of Pittsburgh; OpenAI; IBM Research\u2217",
        "rating": "5;5;8;8",
        "confidence": "3;4;5;4",
        "correctness": "4;2;4;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "3;2;3;4",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.7071067811865476,
        "corr_rating_correctness": 0.5773502691896258,
        "project": "",
        "github": ""
    },
    {
        "id": "rq1-7_lwisw",
        "title": "Beyond Object Recognition: A New Benchmark towards Object Concept Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Object Concept Learning;Attributes;Affordance;Causal Inference",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "4;3;3;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;4;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.40824829046386296,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "rqcLsG8Kme9",
        "title": "rQdia: Regularizing Q-Value Distributions With Image Augmentation",
        "track": "main",
        "status": "Reject",
        "keywords": "deep reinforcement learning;regularization;q-value distributions;invariance;image augmentation;continuous control;Atari",
        "author": "",
        "aff": "",
        "rating": "3;3;6;6",
        "confidence": "4;5;3;5",
        "correctness": "2;3;4;4",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3015113445777637,
        "corr_rating_correctness": 0.9045340337332909,
        "project": "",
        "github": ""
    },
    {
        "id": "rqolQhuq6Hs",
        "title": "Logarithmic landscape and power-law escape rate of SGD",
        "track": "main",
        "status": "Reject",
        "keywords": "stochastic gradient descent;noise structure;escape rate;flat minima;statistical physics",
        "author": "",
        "aff": "",
        "rating": "3;6;6",
        "confidence": "3;3;2",
        "correctness": "4;3;3",
        "technical_novelty": "2;3;4",
        "empirical_novelty": "0;2;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5,
        "corr_rating_correctness": -1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "rrWeE9ZDw_",
        "title": "Autonomous Learning of Object-Centric Abstractions for High-Level Planning",
        "track": "main",
        "status": "Poster",
        "keywords": "reinforcement learning;planning;multitask;transfer;objects",
        "author": "",
        "aff": "University of the Witwatersrand, Johannesburg, South Africa; Brown University, Providence RI 02912, USA",
        "rating": "5;6;8",
        "confidence": "4;3;3",
        "correctness": "3;3;4",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 6.333333333333333,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7559289460184545,
        "corr_rating_correctness": 0.944911182523068,
        "project": "",
        "github": ""
    },
    {
        "id": "rvost-n5X4G",
        "title": "SPP-RL: State Planning Policy Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "reinforcement learning;off-policy;constrained optimization;robotics;state planning;state-state;mujoco;safety-gym;antpush",
        "author": "",
        "aff": "",
        "rating": "3;5;8",
        "confidence": "4;3;4",
        "correctness": "4;2;3",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.1147078669352809,
        "corr_rating_correctness": -0.3973597071195132,
        "project": "",
        "github": ""
    },
    {
        "id": "rw1mZl_ss3L",
        "title": "Concurrent Adversarial Learning for Large-Batch Training",
        "track": "main",
        "status": "Poster",
        "keywords": "Distributed Machine Learnig;Large-Batch Training;Adversarial Learning",
        "author": "",
        "aff": "Department of Computer Science and Engineering, Hong Kong University of Science and Technology; Department of Computer Science, National University of Singapore; Department of Computer Science, University of California, Los Angeles",
        "rating": "5;6;8",
        "confidence": "4;5;3",
        "correctness": "4;3;3",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "3;3;4",
        "presentation": "",
        "rating_avg": 6.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 3.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6546536707079772,
        "corr_rating_correctness": -0.7559289460184545,
        "project": "",
        "github": ""
    },
    {
        "id": "rwE8SshAlxw",
        "title": "Unsupervised Discovery of Object Radiance Fields",
        "track": "main",
        "status": "Poster",
        "keywords": "object discovery;scene decomposition;3D scene representations;object-centric learning",
        "author": "",
        "aff": "Stanford University",
        "rating": "5;8;8",
        "confidence": "3;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;4;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5,
        "corr_rating_correctness": 0.5,
        "project": "https://kovenyu.com/uORF/",
        "github": ""
    },
    {
        "id": "rwEv1SklKFt",
        "title": "Poisoned classifiers are not only backdoored, they are fundamentally broken",
        "track": "main",
        "status": "Reject",
        "keywords": "Backdoor attacks;Randomized Smoothing;Trigger construction",
        "author": "",
        "aff": "Under double-blind review",
        "rating": "3;3;5;5;5",
        "confidence": "4;4;4;4;4",
        "correctness": "3;4;3;4;3",
        "technical_novelty": "2;1;3;4;3",
        "empirical_novelty": "3;2;2;3;3",
        "presentation": "",
        "rating_avg": 4.2,
        "confidence_avg": 4.0,
        "correctness_avg": 3.4,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 2.6,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.16666666666666663,
        "project": "",
        "github": ""
    },
    {
        "id": "rwR3N1ApI3V",
        "title": "Is deeper better? It depends on locality of relevant features",
        "track": "main",
        "status": "Withdraw",
        "keywords": "deep learning;generalization;overparameterization;neural tangent kernel",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;3;3",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;2;2;1",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "rwSWaS_tGgG",
        "title": "Uncertainty Regularized Policy Learning for Offline Reinforcement Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "off-policy RL;offline Learning",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "4;4;4;4",
        "correctness": "4;2;4;3",
        "technical_novelty": "2;1;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "rxF4IN3R2ml",
        "title": "MQTransformer: Multi-Horizon Forecasts with Context Dependent and Feedback-Aware Attention",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;6",
        "confidence": "4;3;4",
        "correctness": "4;4;3",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.4999999999999999,
        "corr_rating_correctness": -0.9999999999999997,
        "project": "",
        "github": ""
    },
    {
        "id": "rzvOQrnclO0",
        "title": "Gradient Information Matters in Policy Optimization by Back-propagating through Model",
        "track": "main",
        "status": "Poster",
        "keywords": "Model-based RL;Policy Optimization",
        "author": "",
        "aff": "Microsoft Research Asia; Academy of Mathematics and Systems Science, Chinese Academy of Sciences; Beijing Jiaotong University; Institute of Computing Technology, Chinese Academy of Sciences",
        "rating": "6;6;8;8",
        "confidence": "4;4;4;3",
        "correctness": "3;3;4;3",
        "technical_novelty": "3;2;3;4",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": "https://github.com/CCreal/ddppo"
    },
    {
        "id": "s-b95PMK4E6",
        "title": "Hierarchical Modular Framework for Long Horizon Instruction Following",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;6;8;8;8",
        "confidence": "4;4;4;4;4",
        "correctness": "3;4;4;3;3",
        "technical_novelty": "2;3;3;2;2",
        "empirical_novelty": "2;4;3;4;3",
        "presentation": "",
        "rating_avg": 6.6,
        "confidence_avg": 4.0,
        "correctness_avg": 3.4,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 3.2,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.16666666666666663,
        "project": "",
        "github": ""
    },
    {
        "id": "s03AQxehtd_",
        "title": "ProtoRes: Proto-Residual Network for Pose Authoring via Learned Inverse Kinematics",
        "track": "main",
        "status": "Oral",
        "keywords": "inverse kinematics;deep learning;pose modeling",
        "author": "",
        "aff": "Unity Labs",
        "rating": "6;8;8",
        "confidence": "3;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "3;3;2",
        "presentation": "",
        "rating_avg": 7.333333333333333,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.49999999999999983,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "s2UpjzX82FS",
        "title": "Privacy-preserving Task-Agnostic Vision Transformer for Image Processing",
        "track": "main",
        "status": "Reject",
        "keywords": "Federated learning;Split learning;Transformer;Image processing",
        "author": "",
        "aff": "",
        "rating": "5;6;6;8",
        "confidence": "2;3;3;3",
        "correctness": "4;3;4;3",
        "technical_novelty": "3;2;2;3",
        "empirical_novelty": "2;2;2;4",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 2.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.6622661785325219,
        "corr_rating_correctness": -0.6882472016116854,
        "project": "",
        "github": ""
    },
    {
        "id": "s3K0arSRl4d",
        "title": "TransDreamer: Reinforcement Learning with Transformer World Models",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Model-Based Reinforcement Learning;Transformer World Models",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6;6",
        "confidence": "4;4;4;5;4",
        "correctness": "3;2;3;3;3",
        "technical_novelty": "2;3;2;4;3",
        "empirical_novelty": "2;2;3;2;3",
        "presentation": "",
        "rating_avg": 4.6,
        "confidence_avg": 4.2,
        "correctness_avg": 2.8,
        "technical_novelty_avg": 2.8,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5160468465421401,
        "corr_rating_correctness": 0.5897678246195884,
        "project": "",
        "github": ""
    },
    {
        "id": "s3V9I71JvkD",
        "title": "Offline Meta-Reinforcement Learning with Online Self-Supervision",
        "track": "main",
        "status": "Reject",
        "keywords": "reinforcement learning;meta learning;meta reinforcement learning;offline reinforcement learning",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "4;4;4;3",
        "correctness": "3;4;4;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "3;3;4;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4714045207910316,
        "corr_rating_correctness": 0.40824829046386296,
        "project": "",
        "github": ""
    },
    {
        "id": "s51gCxF70pq",
        "title": "Learning Temporally-Consistent Representations for Data-Efficient Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Reinforcement learning;representation learning;continuous control",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5;6",
        "confidence": "4;4;4;4;3",
        "correctness": "3;2;3;3;3",
        "technical_novelty": "2;2;2;3;2",
        "empirical_novelty": "2;2;3;3;3",
        "presentation": "",
        "rating_avg": 4.4,
        "confidence_avg": 3.8,
        "correctness_avg": 2.8,
        "technical_novelty_avg": 2.2,
        "empirical_novelty_avg": 2.6,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6666666666666666,
        "corr_rating_correctness": 0.5833333333333335,
        "project": "",
        "github": ""
    },
    {
        "id": "s5lIqsrOu3Z",
        "title": "Closed-Loop Data Transcription to an LDR via Minimaxing Rate Reduction",
        "track": "main",
        "status": "Reject",
        "keywords": "Linear discriminative representation;Generative model",
        "author": "",
        "aff": "",
        "rating": "3;5;6",
        "confidence": "3;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "3;2;0",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.18898223650461363,
        "corr_rating_correctness": 0.7559289460184545,
        "project": "",
        "github": ""
    },
    {
        "id": "s5yOwPJicj",
        "title": "Carousel Memory: Rethinking the Design of Episodic Memory for Continual Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Continual Learning;Episodic Memory;Memory Replay;System for AI",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "5;4;4;4",
        "correctness": "3;4;3;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;0;2;4",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "s6cyuoLbZLU",
        "title": "Comparing representations of biological data learned with different AI paradigms, augmenting and cropping strategies",
        "track": "main",
        "status": "Withdraw",
        "keywords": "representation learning;self-supervised learning;multi-crops;augmentations;application",
        "author": "",
        "aff": "",
        "rating": "1;3;3;8",
        "confidence": "5;4;5;5",
        "correctness": "1;3;3;4",
        "technical_novelty": "1;1;2;3",
        "empirical_novelty": "2;2;3;4",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 4.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.16744367165578428,
        "corr_rating_correctness": 0.8649597882660589,
        "project": "",
        "github": ""
    },
    {
        "id": "s6roE3ZocH1",
        "title": "Genetic Algorithm for Constrained Molecular Inverse Design",
        "track": "main",
        "status": "Reject",
        "keywords": "Genetic Algorithm;Constrained Optimization;Molecular Inverse Design;Molecular Generation",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "4;4;5;4",
        "correctness": "3;2;2;3",
        "technical_novelty": "2;2;1;2",
        "empirical_novelty": "2;2;0;1",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 1.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "sA4qIu3zv6v",
        "title": "Towards General Function Approximation in Zero-Sum Markov Games",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "Department of Statistics and Data Science, Yale University; School of Mathematical Sciences, Peking University; Department of Electrical and Computer Engineering, Princeton University; Departments of Industrial Engineering & Management Sciences, Northwestern University",
        "rating": "3;6;6;6",
        "confidence": "3;2;3;3",
        "correctness": "3;4;4;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 2.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "sBHGzpXndG",
        "title": "Collaborative Three-Stream Transformers for Video Captioning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Video captioning;transformer;cross-modality",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5",
        "confidence": "4;4;4;4",
        "correctness": "3;4;4;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "3;2;0;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "sBHVNmCt3t",
        "title": "On The Vulnerability of Recurrent Neural Networks to Membership Inference Attacks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Privacy;Recurrent Neural Networks;Membership Inference Attack;Reinforcement Learning",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "3;4;4;3",
        "correctness": "3;4;2;2",
        "technical_novelty": "1;2;1;2",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 1.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": -0.5222329678670935,
        "project": "",
        "github": ""
    },
    {
        "id": "sBT5nxwt18Q",
        "title": "Advancing Nearest Neighbor Explanation-by-Example with Critical Classification Regions",
        "track": "main",
        "status": "Reject",
        "keywords": "Explainable AI;Post-hoc Nearest Neighbor Explanation-by-Example;User Study;Case-based Reasoning;Convolutional Neural Network",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "3;4;3;4",
        "correctness": "2;2;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;1;3;4",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.19245008972987526,
        "corr_rating_correctness": 0.9622504486493761,
        "project": "https://after anon review",
        "github": ""
    },
    {
        "id": "sCrKKSWtFl5",
        "title": "Neural Photometric Stereo for Shape and Material Estimation",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;6",
        "confidence": "5;5;5",
        "correctness": "2;1;4",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 5.0,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "sEIl_stzQyB",
        "title": "Greedy-based Value Representation for Efficient Coordination in Multi-agent Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "multi-agent cooperation;reinforcement learning algorithm",
        "author": "",
        "aff": "",
        "rating": "3;3;3;6",
        "confidence": "4;3;3;2",
        "correctness": "2;2;2;4",
        "technical_novelty": "3;2;4;3",
        "empirical_novelty": "2;2;4;3",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 3.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.816496580927726,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "sHUFhv03qX_",
        "title": "Q-Learning Scheduler for Multi-Task Learning through the use of Histogram of Task Uncertainty",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Q-learning;Multi-Task Learning;MTL Scheduling;Histogram of Task Uncertainty",
        "author": "",
        "aff": "",
        "rating": "3;3;5;8",
        "confidence": "3;4;3;4",
        "correctness": "3;1;4;4",
        "technical_novelty": "2;1;1;3",
        "empirical_novelty": "2;2;2;4",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3665083330689157,
        "corr_rating_correctness": 0.6982565352753429,
        "project": "",
        "github": ""
    },
    {
        "id": "sJJXksSg7yi",
        "title": "Rotation-Equivariant Keypoint Detection",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Equivariant representation;Keypoint detector;Image matching",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "5;5;5;3",
        "correctness": "3;2;2;4",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.30151134457776363
    },
    {
        "id": "sKiAuHhc3w",
        "title": "Fine-grained Software Vulnerability Detection via Information Theory and Contrastive Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Cybersecurity;Fine-grained vulnerability detection;Mutual information;Contrastive learning.",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5;6",
        "confidence": "4;4;4;3;3",
        "correctness": "2;2;2;3;3",
        "technical_novelty": "2;2;2;2;3",
        "empirical_novelty": "2;2;1;3;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6,
        "correctness_avg": 2.4,
        "technical_novelty_avg": 2.2,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9682458365518543,
        "corr_rating_correctness": 0.9682458365518543,
        "project": "",
        "github": ""
    },
    {
        "id": "sMNvG2UMd_l",
        "title": "Mean-Shifted Contrastive Loss for Anomaly Detection",
        "track": "main",
        "status": "Withdraw",
        "keywords": "anomaly detection",
        "author": "",
        "aff": "",
        "rating": "3;3;5;8",
        "confidence": "4;5;4;5",
        "correctness": "3;2;3;4",
        "technical_novelty": "2;2;2;4",
        "empirical_novelty": "2;2;1;4",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3665083330689157,
        "corr_rating_correctness": 0.8638684255813602,
        "project": "",
        "github": ""
    },
    {
        "id": "sMqybmUh_u8",
        "title": "Provable Hierarchy-Based Meta-Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "RL theory;regret bounds;hierarchical RL;meta-RL",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "3;3;2;4",
        "correctness": "3;4;4;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.40824829046386296,
        "project": "",
        "github": ""
    },
    {
        "id": "sNuFKTMktcY",
        "title": "Active Hierarchical Exploration with Stable Subgoal Representation Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "Hierarchical Reinforcement Learning;Exploration;Representation Learning",
        "author": "",
        "aff": "Nanjing University; Tsinghua University",
        "rating": "6;6;8;8",
        "confidence": "3;4;4;4",
        "correctness": "4;3;4;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;4;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "sOK-zS6WHB",
        "title": "Responsible Disclosure of Generative Models Using Scalable Fingerprinting",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Generative models;fingerprinting;responsible disclosure;deep fake detection and attribution",
        "author": "",
        "aff": "CISPA Helmholtz Center for Information Security; Salesforce Research, University of Maryland, Max Planck Institute for Informatics; University of Maryland",
        "rating": "6;6;8;8;8",
        "confidence": "4;4;4;3;4",
        "correctness": "2;2;4;4;3",
        "technical_novelty": "2;3;4;3;4",
        "empirical_novelty": "2;3;3;3;3",
        "presentation": "",
        "rating_avg": 7.2,
        "confidence_avg": 3.8,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.2,
        "empirical_novelty_avg": 2.8,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.408248290463863,
        "corr_rating_correctness": 0.9128709291752769,
        "project": "",
        "github": "https://github.com/..."
    },
    {
        "id": "sPIFuucA3F",
        "title": "Offline Neural Contextual Bandits: Pessimism, Optimization and Generalization",
        "track": "main",
        "status": "Poster",
        "keywords": "offline policy learning;offline contextual bandits;neural network function approximation",
        "author": "",
        "aff": "Department of Engineering Science, University of Oxford; Applied AI Institute, Deakin University",
        "rating": "6;6;6;6",
        "confidence": "3;3;4;3",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "sPfB2PI87BZ",
        "title": "Mapping conditional distributions for domain adaptation under generalized target shift",
        "track": "main",
        "status": "Poster",
        "keywords": "Unsupervised domain adaptation;generalized target shift",
        "author": "",
        "aff": "CNRS-ISIR, Sorbonne University; Criteo AI Lab; Universit \u00b4e de Rouen, LITIS; Criteo AI Lab; CNRS-ISIR, Sorbonne University",
        "rating": "5;6;8",
        "confidence": "2;3;4",
        "correctness": "4;3;4",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "2;3;2",
        "presentation": "",
        "rating_avg": 6.333333333333333,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9819805060619659,
        "corr_rating_correctness": 0.18898223650461363,
        "project": "",
        "github": ""
    },
    {
        "id": "sRZ3GhmegS",
        "title": "CoBERL: Contrastive BERT for Reinforcement Learning",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Reinforcement Learning;Contrastive Learning;Representation Learning;Transformer;Deep Reinforcement Learning",
        "author": "",
        "aff": "DeepMind London",
        "rating": "6;8;8",
        "confidence": "3;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 7.333333333333333,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.49999999999999983,
        "corr_rating_correctness": 0.49999999999999983,
        "project": "",
        "github": ""
    },
    {
        "id": "sS0dHmaH1I",
        "title": "Fast Adaptive Anomaly Detection",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;6;8;8",
        "confidence": "4;2;3;4;3",
        "correctness": "2;3;3;4;4",
        "technical_novelty": "2;2;3;3;3",
        "empirical_novelty": "2;2;3;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.2,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 2.6,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9860132971832695,
        "project": "",
        "github": ""
    },
    {
        "id": "sTECq7ZjtKX",
        "title": "OSSuM: A Gradient-Free Approach For Pruning Neural Networks At Initialization",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Pruning;Supermasking;Gradient-free training;Sparse networks",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "4;5;3;2",
        "correctness": "3;2;2;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "0;1;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "sTNHCrIKDQc",
        "title": "Graphon based Clustering and Testing of Networks: Algorithms and Theory",
        "track": "main",
        "status": "Poster",
        "keywords": "Clustering;Networks;Graphs;Two-sample testing;Graphon",
        "author": "",
        "aff": "Technical University of Munich; Technical University of Munich, Munich Data Science Institute; University of T\u00fcbingen",
        "rating": "6;8;8",
        "confidence": "4;3;3",
        "correctness": "4;3;3",
        "technical_novelty": "3;4;3",
        "empirical_novelty": "0;3;2",
        "presentation": "",
        "rating_avg": 7.333333333333333,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.3333333333333335,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9999999999999998,
        "corr_rating_correctness": -0.9999999999999998,
        "project": "",
        "github": ""
    },
    {
        "id": "sTkY-RVYBz",
        "title": "Counterbalancing Teacher: Regularizing Batch Normalized Models for Robustness",
        "track": "main",
        "status": "Reject",
        "keywords": "Robust representation learning;domain generalization",
        "author": "",
        "aff": "",
        "rating": "3;5;6;8",
        "confidence": "4;4;2;4",
        "correctness": "2;3;3;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.16012815380508713,
        "corr_rating_correctness": 0.9805806756909202,
        "project": "",
        "github": ""
    },
    {
        "id": "sWbXSWzHPa",
        "title": "Invariant Learning with Partial Group Labels",
        "track": "main",
        "status": "Reject",
        "keywords": "Distributional Robust Optimization;Invariant Representation Learning;Semi-supervised learning;Dataset bias",
        "author": "",
        "aff": "",
        "rating": "3;3;6;6",
        "confidence": "4;5;3;3",
        "correctness": "2;4;4;4",
        "technical_novelty": "2;4;2;3",
        "empirical_novelty": "1;3;2;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9045340337332909,
        "corr_rating_correctness": 0.5773502691896258,
        "project": "",
        "github": ""
    },
    {
        "id": "sWqjiqlUDso",
        "title": "Path-specific Causal Fair Prediction via Auxiliary Graph Structure Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;3",
        "confidence": "5;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "sX3XaHwotOg",
        "title": "Pretraining Text Encoders with Adversarial Mixture of Training Signal Generators",
        "track": "main",
        "status": "Poster",
        "keywords": "Language Model Pretraining",
        "author": "",
        "aff": "University of Illinois at Urbana-Champaign; Microsoft",
        "rating": "3;6;6;8;8;8",
        "confidence": "5;3;4;4;5;4",
        "correctness": "3;3;4;3;4;3",
        "technical_novelty": "1;2;3;3;3;4",
        "empirical_novelty": "2;3;3;3;3;4",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 4.166666666666667,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.20180183819889375,
        "corr_rating_correctness": 0.19611613513818404,
        "project": "",
        "github": ""
    },
    {
        "id": "sXNVFBc-0aP",
        "title": "Public Data-Assisted Mirror Descent for Private Model Training",
        "track": "main",
        "status": "Reject",
        "keywords": "Differential Privacy;Public Data;Mirror Descent",
        "author": "",
        "aff": "",
        "rating": "5;6;8",
        "confidence": "5;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "3;3;4",
        "empirical_novelty": "3;4;4",
        "presentation": "",
        "rating_avg": 6.333333333333333,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 3.3333333333333335,
        "empirical_novelty_avg": 3.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7559289460184544,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "sZttLyMsfzb",
        "title": "Optimization Variance: Exploring Generalization Properties of DNNs",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Double Descent;Generalization;Deep Neural Networks",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "3;5;5;3",
        "correctness": "4;4;4;2",
        "technical_novelty": "2;1;1;2",
        "empirical_novelty": "2;2;2;1",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 1.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "saNgDizIODl",
        "title": "NUQ: Nonparametric Uncertainty Quantification for Deterministic Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "Out-of-distribution detection;uncertainty quantification;epistemic uncertainty;aleatoric uncertainty;non-parametric models;Nadaraya-Watson estimator;Misclassification detection",
        "author": "",
        "aff": "",
        "rating": "5;5;5",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "scSheedMzl",
        "title": "Locally Invariant Explanations: Towards Causal Explanations through Local Invariant Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "explainable AI",
        "author": "",
        "aff": "",
        "rating": "5;5;5;8",
        "confidence": "4;4;2;4",
        "correctness": "3;4;3;3",
        "technical_novelty": "2;2;4;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "shbAgEsk3qM",
        "title": "Understanding and Leveraging Overparameterization in Recursive Value Estimation",
        "track": "main",
        "status": "Poster",
        "keywords": "Temporal Difference Learning;Residual Minimization;Value Estimation;Overparameterization",
        "author": "",
        "aff": "Google, Department of Computing Science, University of Alberta; Google",
        "rating": "3;5;6;8",
        "confidence": "4;3;2;4",
        "correctness": "2;3;3;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;2;1",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.08362420100070908,
        "corr_rating_correctness": 0.9805806756909202,
        "project": "",
        "github": ""
    },
    {
        "id": "shdfw9sQnAP",
        "title": "Cronus: Robust and Heterogeneous Collaborative Learning with Black-Box Knowledge Transfer",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Federated Learning;Poisoning attacks and defenses",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "5;4;4;5",
        "correctness": "2;3;3;3",
        "technical_novelty": "3;2;2;1",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "shpkpVXzo3h",
        "title": "8-bit Optimizers via Block-wise Quantization",
        "track": "main",
        "status": "Spotlight",
        "keywords": "language models;pretraining;finetuning;GPU memory",
        "author": "",
        "aff": "",
        "rating": "6;8;8",
        "confidence": "5;5;5",
        "correctness": "3;3;3",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "4;3;3",
        "presentation": "",
        "rating_avg": 7.333333333333333,
        "confidence_avg": 5.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "siCt4xZn5Ve",
        "title": "What Happens after SGD Reaches Zero Loss? --A Mathematical Framework",
        "track": "main",
        "status": "Spotlight",
        "keywords": "SGD;implicit bias;generalization;deep learning;implicit regularization;manifold",
        "author": "",
        "aff": "Department of Statistics and Data Science, Yale University; Department of Computer Science, Princeton University",
        "rating": "8;8;8;10",
        "confidence": "3;3;4;5",
        "correctness": "4;4;4;4",
        "technical_novelty": "3;3;4;4",
        "empirical_novelty": "2;3;0;0",
        "presentation": "",
        "rating_avg": 8.5,
        "confidence_avg": 3.75,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 3.5,
        "empirical_novelty_avg": 1.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8703882797784891,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "size4UxXVCY",
        "title": "Graph Tree Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "Graph neural networks;Tree based convolutional neural network;Domain general learning",
        "author": "",
        "aff": "",
        "rating": "1;1;1",
        "confidence": "3;3;4",
        "correctness": "2;2;2",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "0;2;0",
        "presentation": "",
        "rating_avg": 1.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 0.6666666666666666,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "sk63PSiUyci",
        "title": "AI-SARAH: Adaptive and Implicit Stochastic Recursive Gradient Methods",
        "track": "main",
        "status": "Reject",
        "keywords": "practical variant of SARAH;adaptive step-size;tune-free algorithm;implicit approach;convex optimization in machine learning",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "5;4;4;4",
        "correctness": "4;3;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;0;3;2",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "snJ1WYQOR5",
        "title": "Neural Plenoptic Sampling: Capture Light-field from Imaginary Eyes",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;4;4;5",
        "correctness": "2;2;3;3",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "1;2;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 1.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "srtIXtySfT4",
        "title": "Neural Parameter Allocation Search",
        "track": "main",
        "status": "Poster",
        "keywords": "efficient training methods;cross-layer parameter sharing",
        "author": "",
        "aff": "Boston University; ETH Z\u00fcrich; MIT-IBM Watson AI Lab",
        "rating": "5;6;6;8",
        "confidence": "3;3;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;3;3;4",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.6882472016116854,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "swRxhFpK5ds",
        "title": "One Timestep Is All You Need: Training Spiking Neural Networks with Ultra Low Latency",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Spiking Neural Networks;One timestep Inference;Iterative Initialization and Retraining;Ultra-high energy efficiency",
        "author": "",
        "aff": "",
        "rating": "3;3;6",
        "confidence": "4;5;5",
        "correctness": "2;2;3",
        "technical_novelty": "2;1;3",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "swbAS4OpXW",
        "title": "One-Shot Generative Domain Adaptation",
        "track": "main",
        "status": "Reject",
        "keywords": "generative domain adaptation",
        "author": "",
        "aff": "",
        "rating": "3;5;8",
        "confidence": "5;5;5",
        "correctness": "1;3;4",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "2;2;4",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 5.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9538209664765321,
        "project": "",
        "github": ""
    },
    {
        "id": "swiyAeGzFhQ",
        "title": "Learning to Guide and to be Guided in the Architect-Builder Problem",
        "track": "main",
        "status": "Poster",
        "keywords": "Social Learning;Interactive Learning;Teacher-Student Learning;Computational Experimental Semiotics;Socially Supervised Learning",
        "author": "",
        "aff": "Qu\u00b4ebec AI institute (Mila), Polythechnique Montr\u00b4eal, ServiceNow - Element AI; Inria - Flowers team, Universit\u00b4e de Bordeaux; Inria - Flowers team, Universit\u00b4e de Bordeaux, ENSTA ParisTech; Inria - Flowers team, Univ. Bordeaux, Microsoft Research Montreal; Qu\u00b4ebec AI institute (Mila), McGill University",
        "rating": "3;5;6;8",
        "confidence": "4;3;4;4",
        "correctness": "2;4;3;4",
        "technical_novelty": "2;2;3;4",
        "empirical_novelty": "2;2;3;4",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.16012815380508713,
        "corr_rating_correctness": 0.7526178090063818,
        "project": "",
        "github": ""
    },
    {
        "id": "swrMQttr6wN",
        "title": "Learning to Map for Active Semantic Goal Navigation",
        "track": "main",
        "status": "Poster",
        "keywords": "visual navigation;semantic map;uncertainty estimation",
        "author": "",
        "aff": "Amazon; University of Pennsylvania",
        "rating": "5;6;8",
        "confidence": "4;4;4",
        "correctness": "2;4;3",
        "technical_novelty": "4;3;4",
        "empirical_novelty": "4;2;4",
        "presentation": "",
        "rating_avg": 6.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.6666666666666665,
        "empirical_novelty_avg": 3.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.3273268353539886,
        "project": "",
        "github": ""
    },
    {
        "id": "sxpUavxXE0v",
        "title": "Decoupled Contrastive Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Contrastive Learning;Unsupervised Learning;Self-Supervised Learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5;5",
        "confidence": "4;4;4;4;3",
        "correctness": "2;2;3;4;3",
        "technical_novelty": "3;2;3;2;3",
        "empirical_novelty": "3;2;3;2;3",
        "presentation": "",
        "rating_avg": 4.2,
        "confidence_avg": 3.8,
        "correctness_avg": 2.8,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 2.6,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.408248290463863,
        "corr_rating_correctness": 0.8728715609439696,
        "project": "",
        "github": ""
    },
    {
        "id": "syzTg1vyBtL",
        "title": "Congested bandits: Optimal routing via short-term resets",
        "track": "main",
        "status": "Reject",
        "keywords": "Multi-armed bandits;linear contextual bandits;policy regret;congestion aware routing",
        "author": "",
        "aff": "",
        "rating": "3;3;3;8",
        "confidence": "3;4;4;3",
        "correctness": "3;4;3;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;1;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "t14vYukzfvF",
        "title": "Unsupervised Visual Program Induction with Function Modularization",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "1;3;5;6",
        "confidence": "4;5;4;3",
        "correctness": "1;2;3;3",
        "technical_novelty": "1;2;3;2",
        "empirical_novelty": "1;2;3;2",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 4.0,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.552344770738994,
        "corr_rating_correctness": 0.9813358399735743,
        "project": "",
        "github": ""
    },
    {
        "id": "t1QXzSGwr9",
        "title": "Image Compression and Classification Using Qubits and Quantum Deep Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "quantum machine learning;flexible representation of quantum images;quantum neural network",
        "author": "",
        "aff": "",
        "rating": "1;3;3;5",
        "confidence": "5;5;4;2",
        "correctness": "3;4;4;2",
        "technical_novelty": "1;2;2;2",
        "empirical_novelty": "1;2;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8660254037844385,
        "corr_rating_correctness": -0.4264014327112209,
        "project": "",
        "github": ""
    },
    {
        "id": "t2LJBsPxQM",
        "title": "Scaling-up Diverse Orthogonal Convolutional Networks by a Paraunitary Framework",
        "track": "main",
        "status": "Reject",
        "keywords": "orthogonal convolutions;adversarial robustness;spectral analysis;paraunitary systems",
        "author": "",
        "aff": "",
        "rating": "3;6;6;8",
        "confidence": "5;4;4;4",
        "correctness": "2;4;3;4",
        "technical_novelty": "2;3;3;4",
        "empirical_novelty": "2;2;3;4",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8892972917998875,
        "corr_rating_correctness": 0.8866206949335731,
        "project": "",
        "github": ""
    },
    {
        "id": "t2Mzgc9JEjZ",
        "title": "Certified Patch Robustness via Smoothed Vision Transformers",
        "track": "main",
        "status": "Withdraw",
        "keywords": "adversarial robustness;patch defense;vision transformers;deep learning;computer vision;certified defense;adversarial example",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "4;3;3;4",
        "correctness": "4;3;3;4",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;4",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "t3BFUDHwEJU",
        "title": "Delayed Geometric Discounts: An alternative criterion for Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "4;4;3;3",
        "correctness": "3;2;3;3",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "3;1;3;2",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9622504486493761,
        "corr_rating_correctness": 0.5555555555555555,
        "project": "",
        "github": ""
    },
    {
        "id": "t3E10H8UNz",
        "title": "Transferring Hierarchical Structure with Dual Meta Imitation Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "imitation learning;meta learning;hierarchical structure;robot learning",
        "author": "",
        "aff": "",
        "rating": "6;6;6;8",
        "confidence": "3;4;2;4",
        "correctness": "3;4;4;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5222329678670935,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "t5EmXZ3ZLR",
        "title": "SOSP: Efficiently Capturing Global Correlations by Second-Order Structured Pruning",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Structured Pruning;Saliency-based Pruning;Network Compression;Hessian Approximation;Neural Architecture Search;Deep Learning;Computer Vision",
        "author": "",
        "aff": "Bosch Center for Arti\ufb01cial Intelligence (BCAI), Robert Bosch GmbH, 71272 Renningen, Germany; Institute for Stochastics and Applications, University of Stuttgart, 70569 Stuttgart, Germany",
        "rating": "6;8;8;8",
        "confidence": "3;2;4;3",
        "correctness": "3;4;3;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "t5s-hd1bqLk",
        "title": "Conditioning Sequence-to-sequence Networks with Learned Activations",
        "track": "main",
        "status": "Poster",
        "keywords": "Conditional Neural Networks;Sound Enhancement;Personalized ASR",
        "author": "",
        "aff": "Samsung AI Centre, Cambridge, UK; Samsung AI Centre, Cambridge, UK and University of Cambridge, UK",
        "rating": "6;6;6",
        "confidence": "4;3;3",
        "correctness": "4;3;3",
        "technical_novelty": "3;3;4",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.3333333333333335,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "t7y6MKiyiWx",
        "title": "Classical and Quantum Algorithms for Orthogonal Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "orthogonal neural networks;orthogonality;quantum computing;quantum machine learning;quantum deep learning;complexity;quantum computer",
        "author": "",
        "aff": "",
        "rating": "1;5;6;6",
        "confidence": "5;2;2;4",
        "correctness": "3;2;4;4",
        "technical_novelty": "1;2;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7001400420140049,
        "corr_rating_correctness": 0.3656362120635653,
        "project": "",
        "github": ""
    },
    {
        "id": "t8O-4LKFVx",
        "title": "Learning Optimal Conformal Classifiers",
        "track": "main",
        "status": "Spotlight",
        "keywords": "conformal prediction;conformal classification;uncertainty estimation",
        "author": "",
        "aff": "DeepMind; Max Planck Institute for Informatics, Saarland Informatics Campus; DeepMind",
        "rating": "5;8;8;8",
        "confidence": "3;3;3;4",
        "correctness": "3;2;3;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;3;0",
        "presentation": "",
        "rating_avg": 7.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "t98k9ePQQpn",
        "title": "Optimal Transport for Long-Tailed Recognition with Learnable Cost Matrix",
        "track": "main",
        "status": "Poster",
        "keywords": "Long-tailed recognition;imbalanced classification;optimal transport",
        "author": "",
        "aff": "Cognitive Computing Lab, Baidu Research, No.10 Xibeiwang East Road, Beijing 100193, China; 10900 NE 8th St. Bellevue, Washington 98004, USA",
        "rating": "6;6;6",
        "confidence": "3;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "3;2;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "tBIQEvApZK5",
        "title": "Feature Kernel Distillation",
        "track": "main",
        "status": "Poster",
        "keywords": "Knowledge distillation;Neural Network (NN) Feature learning;ensembling NNs;Deep learning fundamentals;Image classification",
        "author": "",
        "aff": "Samsung Research UK; Department of Statistics, University of Oxford; Samsung Research UK",
        "rating": "6;6;6;8",
        "confidence": "4;3;4;3",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "tBoSm4hUWV",
        "title": "WaveMix: Multi-Resolution Token Mixing for Images",
        "track": "main",
        "status": "Withdraw",
        "keywords": "image classification;computer vision;wavelet transform;resource efficient",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "4;5;5;5",
        "correctness": "2;2;2;1",
        "technical_novelty": "3;2;2;3",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.75,
        "correctness_avg": 1.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "tBtoZYKd9n",
        "title": "Evaluation Metrics for Graph Generative Models: Problems, Pitfalls, and Practical Solutions",
        "track": "main",
        "status": "Spotlight",
        "keywords": "graph generative models;model evaluation",
        "author": "",
        "aff": "Department of Biosystems Science and Engineering, ETH Z\u00fcrich, Switzerland; SIB Swiss Institute of Bioinformatics, Switzerland; Department of Biosystems Science and Engineering, ETH Z\u00fcrich, Switzerland; SIB Swiss Institute of Bioinformatics, Switzerland; Institute of AI for Health, Helmholtz Munich, Germany; Technical University of Munich, Germany",
        "rating": "5;8;8;8",
        "confidence": "3;4;4;5",
        "correctness": "3;3;3;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 7.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.816496580927726,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "tCx6AefvuPf",
        "title": "Node-Level Differentially Private Graph Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "differential privacy;graph neural networks;node-level privacy",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "3;3;4;3",
        "correctness": "3;4;1;4",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "1;2;2;2",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": -0.15713484026367722,
        "project": "",
        "github": ""
    },
    {
        "id": "tD7eCtaSkR",
        "title": "Improved deterministic l2 robustness on CIFAR-10 and CIFAR-100",
        "track": "main",
        "status": "Spotlight",
        "keywords": "provable robustness;adversarial examples",
        "author": "",
        "aff": "University of Maryland, College Park",
        "rating": "6;6;8;8",
        "confidence": "5;4;2;4",
        "correctness": "4;4;4;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;4;2;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6882472016116854,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": "https://github.com/singlasahil14/SOC"
    },
    {
        "id": "tDirSp3pczB",
        "title": "Sharp Learning Bounds for Contrastive Unsupervised Representation Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "6;6;6;8;8",
        "confidence": "5;4;4;4;3",
        "correctness": "2;3;3;4;4",
        "technical_novelty": "2;1;3;3;3",
        "empirical_novelty": "2;0;1;3;3",
        "presentation": "",
        "rating_avg": 6.8,
        "confidence_avg": 4.0,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 1.8,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6454972243679028,
        "corr_rating_correctness": 0.8728715609439696,
        "project": "",
        "github": ""
    },
    {
        "id": "tDw7Mmat8co",
        "title": "Towards Safe Reinforcement Learning via Constraining Conditional Value-at-Risk",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5",
        "confidence": "3;4;3;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;3;2;4",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "tFQyjbOz34",
        "title": "Detecting Modularity in Deep Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "Modularity;clustering;interpretability;feature visualization;lesions",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "4;4;3;2",
        "correctness": "3;2;3;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8703882797784891,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "tFgdrQbbaa",
        "title": "Learning curves for continual learning in neural networks: Self-knowledge transfer and forgetting",
        "track": "main",
        "status": "Poster",
        "keywords": "continual learning;neural tangent kernel;statistical mechanics",
        "author": "",
        "aff": "National Institute of Advanced Industrial Science and Technology (AIST), Japan",
        "rating": "5;6;6;8",
        "confidence": "3;3;4;2",
        "correctness": "2;4;4;4",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "2;0;3;0",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 1.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6488856845230502,
        "corr_rating_correctness": 0.6622661785325219,
        "project": "",
        "github": ""
    },
    {
        "id": "tG8QrhMwEqS",
        "title": "Adaptive Activation-based Structured Pruning",
        "track": "main",
        "status": "Reject",
        "keywords": "model compression;structured pruning",
        "author": "",
        "aff": "",
        "rating": "3;5;5",
        "confidence": "5;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 4.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "tHx6q2dM86s",
        "title": "HYPOCRITE: Homoglyph Adversarial Examples for Natural Language Web Services in the Physical World",
        "track": "main",
        "status": "Reject",
        "keywords": "Adversarial Examples;Homograph;Natural Language;Web Services;Physical World",
        "author": "",
        "aff": "Paper under double-blind review",
        "rating": "3;3;3",
        "confidence": "5;3;4",
        "correctness": "4;3;2",
        "technical_novelty": "1;1;2",
        "empirical_novelty": "1;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 1.3333333333333333,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "tJCwZBHm-jW",
        "title": "Image2Point: 3D Point-Cloud Understanding with 2D Image Pretrained Models",
        "track": "main",
        "status": "Reject",
        "keywords": "Computer vision;Point-cloud;Cross-modality.",
        "author": "",
        "aff": "",
        "rating": "6;6;6;6;6",
        "confidence": "5;3;4;5;3",
        "correctness": "4;3;4;3;3",
        "technical_novelty": "4;1;2;3;2",
        "empirical_novelty": "4;3;2;4;2",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.4,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "tJhIY38d2TS",
        "title": "Local Reweighting for Adversarial Training",
        "track": "main",
        "status": "Reject",
        "keywords": "adversarial training",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;5;4",
        "correctness": "3;1;2;3",
        "technical_novelty": "2;1;3;3",
        "empirical_novelty": "0;2;3;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.25,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.30151134457776363,
        "project": "",
        "github": ""
    },
    {
        "id": "tJtOObu7Hxk",
        "title": "FINDING AND FIXING SPURIOUS PATTERNS WITH EXPLANATIONS",
        "track": "main",
        "status": "Withdraw",
        "keywords": "explainability;interpretability;debugging;spurious patterns;spurious correlations;image classification",
        "author": "Gregory Plumb",
        "aff": "",
        "rating": "1;3;3;5",
        "confidence": "4;4;3;3",
        "correctness": "1;3;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7071067811865476,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": "https://github.com/user/repo"
    },
    {
        "id": "tP7AnumqyjB",
        "title": "Deep Semi-Supervised 3D Shape Reconstruction by Solving a Poisson Equation with Spectral Methods",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Poisson equation;3D reconstruction;Physics informed machine learning;Semi-supervised learning",
        "author": "",
        "aff": "",
        "rating": "1;3;3;3;5",
        "confidence": "4;4;4;5;4",
        "correctness": "3;2;2;2;2",
        "technical_novelty": "2;2;2;3;3",
        "empirical_novelty": "2;2;3;0;3",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.2,
        "correctness_avg": 2.2,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.7905694150420949,
        "project": "",
        "github": ""
    },
    {
        "id": "tQ2yZj4sCnk",
        "title": "Divergence-Regularized Multi-Agent Actor-Critic",
        "track": "main",
        "status": "Reject",
        "keywords": "multi-agent reinforcement learning",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "4;3;3;2",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;4;2",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7071067811865475,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "tRfoq5xfU4f",
        "title": "Source-Free Few-Shot Domain Adaptation",
        "track": "main",
        "status": "Withdraw",
        "keywords": "domain adaptation;few-shot learning;model finetuning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5;5;5",
        "confidence": "5;5;4;4;4;5",
        "correctness": "4;2;3;3;3;3",
        "technical_novelty": "2;2;3;3;2;2",
        "empirical_novelty": "2;2;3;3;3;2",
        "presentation": "",
        "rating_avg": 4.333333333333333,
        "confidence_avg": 4.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7071067811865476,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "tT9t_ZctZRL",
        "title": "Towards Deepening Graph Neural Networks: A GNTK-based Optimization Perspective",
        "track": "main",
        "status": "Poster",
        "keywords": "Trainablity;Graph Neural Tangent Kernel;Critical DropEdge",
        "author": "",
        "aff": "Aalborg University; Northeastern University; University of Technology Sydney; The University of Sydney",
        "rating": "5;6;6;6;8",
        "confidence": "3;3;2;4;2",
        "correctness": "3;3;3;3;4",
        "technical_novelty": "3;3;2;3;3",
        "empirical_novelty": "2;2;2;3;3",
        "presentation": "",
        "rating_avg": 6.2,
        "confidence_avg": 2.8,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.8,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4909902530309828,
        "corr_rating_correctness": 0.9185586535436918,
        "project": "",
        "github": ""
    },
    {
        "id": "tUMr0Iox8XW",
        "title": "Efficient Computation of Deep Nonlinear Infinite-Width Neural Networks that Learn Features",
        "track": "main",
        "status": "Poster",
        "keywords": "infinite-width neural network;feature learning;maximal update parametrization;NTK",
        "author": "Greg Yang, Michael Santacroce, Edward J. Hu",
        "aff": "Microsoft",
        "rating": "6;6;6;8",
        "confidence": "3;3;4;3",
        "correctness": "3;3;2;4",
        "technical_novelty": "3;3;4;4",
        "empirical_novelty": "3;2;3;4",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.5,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": "github.com/santacml/pilim"
    },
    {
        "id": "tUa4REjGjTf",
        "title": "On the Certified Robustness for Ensemble Models and Beyond",
        "track": "main",
        "status": "Poster",
        "keywords": "robustness;ensemble;certified robustness",
        "author": "",
        "aff": "University of Illinois Urbana-Champaign; Peking University; Lawrence Livermore National Laboratory",
        "rating": "6;6;6;8;8",
        "confidence": "3;4;4;3;4",
        "correctness": "4;3;3;4;4",
        "technical_novelty": "3;3;3;4;3",
        "empirical_novelty": "2;4;4;4;3",
        "presentation": "",
        "rating_avg": 6.8,
        "confidence_avg": 3.6,
        "correctness_avg": 3.6,
        "technical_novelty_avg": 3.2,
        "empirical_novelty_avg": 3.4,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.16666666666666663,
        "corr_rating_correctness": 0.6666666666666667,
        "project": "",
        "github": ""
    },
    {
        "id": "tV3N0DWMxCg",
        "title": "Natural Posterior Network: Deep Bayesian Predictive Uncertainty for Exponential Family Distributions",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Uncertainty;Exponential Family;Bayesian Update;Conjugate Prior",
        "author": "",
        "aff": "Department of Informatics & Munich Data Science Institute, Technical University of Munich, Germany",
        "rating": "6;6;8;8;8",
        "confidence": "4;4;3;3;3",
        "correctness": "3;3;4;3;3",
        "technical_novelty": "2;3;4;3;3",
        "empirical_novelty": "2;3;4;2;3",
        "presentation": "",
        "rating_avg": 7.2,
        "confidence_avg": 3.4,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.8,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.40824829046386296,
        "project": "",
        "github": ""
    },
    {
        "id": "tYRrOdSnVUy",
        "title": "Non-Transferable Learning: A New Approach for Model Ownership Verification and Applicability Authorization",
        "track": "main",
        "status": "Oral",
        "keywords": "Domain Adaptation;Transfer Learning;Societal Considerations of Representation Learning;Model Watermark",
        "author": "",
        "aff": "Northwestern University",
        "rating": "8;8;8",
        "confidence": "5;2;4",
        "correctness": "4;4;4",
        "technical_novelty": "4;3;4",
        "empirical_novelty": "4;0;4",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 3.6666666666666665,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "tgcAoUVHRIB",
        "title": "Neural Methods for Logical Reasoning over Knowledge Graphs",
        "track": "main",
        "status": "Poster",
        "keywords": "Knowledge Graphs;Knowledge Graph Reasoning;Graph Mining;Data Mining;Machine Learning;Artificial Intelligence;Deep Learning",
        "author": "",
        "aff": "EPFL; ETH Zurich",
        "rating": "5;5;6;8",
        "confidence": "3;3;4;3",
        "correctness": "4;3;2;3",
        "technical_novelty": "3;2;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.28867513459481287,
        "project": "",
        "github": "https://github.com/amayuelas/NNKGReasoning"
    },
    {
        "id": "tge0BZv1Ay",
        "title": "PDQN - A Deep Reinforcement Learning Method for Planning with Long Delays: Optimization of Manufacturing Dispatching",
        "track": "main",
        "status": "Reject",
        "keywords": "This paper proposes the PDQN;a novel method based on integrating Deep Reinforcement Learning and abstract planning for developing dynamic scheduling for policies in  systems with very delayed rewards;e.g. manufacturing.",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;4;4",
        "correctness": "2;3;4;3",
        "technical_novelty": "1;2;2;2",
        "empirical_novelty": "1;2;3;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.7071067811865475,
        "project": "",
        "github": ""
    },
    {
        "id": "tiKNfYpH8le",
        "title": "Pareto Navigation Gradient Descent: a First Order Algorithm for Optimization in Pareto Set",
        "track": "main",
        "status": "Reject",
        "keywords": "Pareto set;Multitask learning",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "5;3;2;3",
        "correctness": "2;4;4;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "1;0;3;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9271726499455306,
        "corr_rating_correctness": 0.8703882797784891,
        "project": "",
        "github": ""
    },
    {
        "id": "tiQ5Zh2S3zV",
        "title": "A multi-domain splitting framework for time-varying graph structure",
        "track": "main",
        "status": "Reject",
        "keywords": "graph signal processing;time-varying structure;anomaly detection;multi-domain analysis;graph learning",
        "author": "",
        "aff": "",
        "rating": "1;1;3;3;5",
        "confidence": "5;5;4;2;2",
        "correctness": "1;1;2;2;3",
        "technical_novelty": "1;1;1;2;2",
        "empirical_novelty": "0;0;1;1;2",
        "presentation": "",
        "rating_avg": 2.6,
        "confidence_avg": 3.6,
        "correctness_avg": 1.8,
        "technical_novelty_avg": 1.4,
        "empirical_novelty_avg": 0.8,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8669214468630108,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "tiWbMTFS57A",
        "title": "A partial theory of Wide Neural Networks using WC functions and its practical implications",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;3;6",
        "confidence": "3;3;3;2",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;0;2;4",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 2.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "tk1eA4lvVRC",
        "title": "Robust Meta-learning with Sampling Noise and Label Noise via Eigen-Reptile",
        "track": "main",
        "status": "Withdraw",
        "keywords": "meta-learning;few-shot;noisy label",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "4;3;2;3",
        "correctness": "4;2;2;3",
        "technical_novelty": "3;3;2;3",
        "empirical_novelty": "2;2;4;0",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.17407765595569782,
        "project": "",
        "github": ""
    },
    {
        "id": "tlkHrUlNTiL",
        "title": "Disentangling deep neural networks with rectified linear units using duality",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;6;6;6",
        "confidence": "4;3;2;3",
        "correctness": "4;4;3;3",
        "technical_novelty": "3;3;3;2",
        "empirical_novelty": "3;3;3;0",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.816496580927726,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "tlkMbWBEAFb",
        "title": "Fully Steerable 3D Spherical Neurons",
        "track": "main",
        "status": "Reject",
        "keywords": "geometric deep learning;steerable network;conformal embedding;spherical neuron;3D shape classification",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5;8",
        "confidence": "2;3;2;2;4",
        "correctness": "3;2;3;3;3",
        "technical_novelty": "3;3;3;3;3",
        "empirical_novelty": "2;2;2;2;3",
        "presentation": "",
        "rating_avg": 5.6,
        "confidence_avg": 2.6,
        "correctness_avg": 2.8,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.2,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.875,
        "corr_rating_correctness": 0.25000000000000006,
        "project": "",
        "github": ""
    },
    {
        "id": "tm9-r3-O2lt",
        "title": "CONTROLLING THE MEMORABILITY OF REAL AND UNREAL FACE IMAGES",
        "track": "main",
        "status": "Reject",
        "keywords": "Memorability;Face Memorability;Face Memorability Modification;StyleGAN;Latent Vector;Image2Style",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "4;4;3;4",
        "correctness": "3;2;3;3",
        "technical_novelty": "1;2;2;2",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.5555555555555555,
        "project": "",
        "github": ""
    },
    {
        "id": "tsg-Lf1MYp",
        "title": "Natural Attribute-based Shift Detection",
        "track": "main",
        "status": "Reject",
        "keywords": "attribute shift;out-of-distribution detection;distribution shift",
        "author": "",
        "aff": "",
        "rating": "5;6;8",
        "confidence": "4;4;3",
        "correctness": "3;4;4",
        "technical_novelty": "4;3;3",
        "empirical_novelty": "3;4;3",
        "presentation": "",
        "rating_avg": 6.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 3.3333333333333335,
        "empirical_novelty_avg": 3.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.944911182523068,
        "corr_rating_correctness": 0.7559289460184545,
        "project": "",
        "github": ""
    },
    {
        "id": "tvKdi-Nodsx",
        "title": "Relative Instance Credibility Inference for Learning with Noisy Labels",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;5",
        "confidence": "4;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "2;3;2",
        "empirical_novelty": "3;2;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "tvwNdOKhuF5",
        "title": "Superior Performance with Diversified Strategic Control in FPS Games Using General Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Reinforcement Learning;Hindsight Experience Replay;FPS Games",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "4;5;3;3",
        "correctness": "3;3;2;3",
        "technical_novelty": "2;1;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "twgEkDwFTP",
        "title": "Understanding Overfitting in Reweighting Algorithms for Worst-group Performance",
        "track": "main",
        "status": "Reject",
        "keywords": "Reweighting algorithms;Worst-group performance;Implicit bias;Fairness",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "3;4;4;3",
        "correctness": "3;4;2;3",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "2;1;2;2",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.19245008972987526,
        "corr_rating_correctness": -0.5443310539518174,
        "project": "",
        "github": ""
    },
    {
        "id": "twv2QlJhXzo",
        "title": "Imitation Learning from Observations under Transition Model Disparity",
        "track": "main",
        "status": "Poster",
        "keywords": "Imitation Learning;Deep Reinforcement Learning",
        "author": "",
        "aff": "",
        "rating": "5;6;6",
        "confidence": "3;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 5.666666666666667,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9999999999999997,
        "corr_rating_correctness": -0.9999999999999997,
        "project": "",
        "github": ""
    },
    {
        "id": "tx4qfdJSFvG",
        "title": "On the Unreasonable Effectiveness of Feature Propagation in Learning on Graphs with Missing Node Features",
        "track": "main",
        "status": "Reject",
        "keywords": "graph neural networks;missing features;graphs;feature propagation",
        "author": "",
        "aff": "",
        "rating": "5;5;5;8",
        "confidence": "4;4;4;3",
        "correctness": "4;4;3;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "tyTH9kOxcvh",
        "title": "Modeling Label Space Interactions in Multi-label Classification using Box Embeddings",
        "track": "main",
        "status": "Poster",
        "keywords": "Multi-label classification;Box Embeddings;Representation Learning;Embeddings",
        "author": "",
        "aff": "Manning College of Information & Computer Sciences, University of Massachusetts Amherst",
        "rating": "5;5;6;8",
        "confidence": "3;4;4;3",
        "correctness": "3;4;4;4",
        "technical_novelty": "3;1;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.40824829046386296,
        "corr_rating_correctness": 0.4714045207910316,
        "project": "",
        "github": "https://github.com/iesl/box-mlc-iclr-2022"
    },
    {
        "id": "tyrJsbKAe6",
        "title": "Pessimistic Model-based Offline Reinforcement Learning under Partial Coverage",
        "track": "main",
        "status": "Poster",
        "keywords": "Reinforcement learning Theory;Offline reinforcement learning;PAC Bounds",
        "author": "",
        "aff": "Department of Computer Science, Cornell University, Ithaca, NY 14850, USA",
        "rating": "5;6;6;8",
        "confidence": "5;3;4;4",
        "correctness": "3;4;4;4",
        "technical_novelty": "2;2;3;4",
        "empirical_novelty": "0;0;3;0",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 0.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3244428422615251,
        "corr_rating_correctness": 0.6622661785325219,
        "project": "",
        "github": ""
    },
    {
        "id": "tzO3RXxzuM",
        "title": "Stability based Generalization Bounds for Exponential Family Langevin Dynamics",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;5;8",
        "confidence": "2;3;3;4",
        "correctness": "4;3;4;4",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.816496580927726,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "tzefRCscZXZ",
        "title": "Adversarial Visual Robustness by Causal Intervention",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Adversarial Robustness;Causality;Instrumental Variable",
        "author": "",
        "aff": "",
        "rating": "3;6;6",
        "confidence": "5;5;5",
        "correctness": "1;2;3",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;4;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 5.0,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.8660254037844387,
        "project": "",
        "github": ""
    },
    {
        "id": "u2GZOiUTbt",
        "title": "Task Affinity with Maximum Bipartite Matching in Few-Shot Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "Task Affinity;Transfer Learning;Few-Shot Learning",
        "author": "",
        "aff": "Department of Electrical and Computer Engineering, Duke University",
        "rating": "3;6;8",
        "confidence": "3;4;3",
        "correctness": "2;3;3",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "3;2;4",
        "presentation": "",
        "rating_avg": 5.666666666666667,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.1147078669352809,
        "corr_rating_correctness": 0.9176629354822472,
        "project": "",
        "github": ""
    },
    {
        "id": "u2JeVfXIQa",
        "title": "Adaptive Cross-Layer Attention for Image Restoration",
        "track": "main",
        "status": "Reject",
        "keywords": "image restoration;neural architecture search;non-local attention",
        "author": "",
        "aff": "",
        "rating": "5;5;6;8",
        "confidence": "5;2;4;4",
        "correctness": "3;4;3;3",
        "technical_novelty": "3;2;2;3",
        "empirical_novelty": "3;2;3;2",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.18731716231633877,
        "corr_rating_correctness": -0.4714045207910316,
        "project": "",
        "github": ""
    },
    {
        "id": "u3IYqzOdQdl",
        "title": "MixtureEnsembles: Leveraging Parameter Sharing for Efficient Ensembles",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Enesembles;Robust Learning;Efficient Computing",
        "author": "",
        "aff": "",
        "rating": "3;3;3;6",
        "confidence": "4;3;4;4",
        "correctness": "3;2;3;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;0;3",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "u4C_qLuEpZ",
        "title": "Exploring General Intelligence of Program Analysis for Multiple Tasks",
        "track": "main",
        "status": "Reject",
        "keywords": "GNN;program analysis",
        "author": "",
        "aff": "",
        "rating": "1;3;3;3",
        "confidence": "4;4;4;5",
        "correctness": "1;2;3;2",
        "technical_novelty": "1;2;1;2",
        "empirical_novelty": "1;0;2;3",
        "presentation": "",
        "rating_avg": 2.5,
        "confidence_avg": 4.25,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 1.5,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "u6TRGdzhfip",
        "title": "Reliable Adversarial Distillation with Unreliable Teachers",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "6;6;6;8",
        "confidence": "4;4;3;4",
        "correctness": "4;3;3;4",
        "technical_novelty": "4;3;3;4",
        "empirical_novelty": "4;3;3;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.5,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "u6s8dSporO8",
        "title": "Group equivariant neural posterior estimation",
        "track": "main",
        "status": "Poster",
        "keywords": "simulation-based inference;likelihood-free inference;machine learning for science;equivariances;group transformations",
        "author": "",
        "aff": "Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany; Max Planck Institute for Intelligent Systems & Machine Learning in Science, University of T\u00fcbingen, T\u00fcbingen, Germany; Machine Learning in Science, University of T\u00fcbingen, T\u00fcbingen, Germany; Max Planck Institute for Gravitational Physics, Potsdam, Germany",
        "rating": "5;5;6;8",
        "confidence": "3;2;2;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "4;3;3;4",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 2.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.7385489458759963,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "u6sUACr7feW",
        "title": "DPP-TTS: Diversifying prosodic features of speech via determinantal point processes",
        "track": "main",
        "status": "Reject",
        "keywords": "Text to speech synthesis;determinantal point processes;prosody modeling",
        "author": "",
        "aff": "",
        "rating": "3;5;5",
        "confidence": "4;4;3",
        "correctness": "3;2;3",
        "technical_novelty": "3;2;4",
        "empirical_novelty": "2;3;2",
        "presentation": "",
        "rating_avg": 4.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.49999999999999983,
        "corr_rating_correctness": -0.49999999999999983,
        "project": "",
        "github": ""
    },
    {
        "id": "u6ybkty-bL",
        "title": "When Complexity Is Good: Do We Need Recurrent Deep Learning For Time Series Outlier Detection?",
        "track": "main",
        "status": "Reject",
        "keywords": "Outlier Detection;Time Series;Deep Learning;Recurrent Neural Networks",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "4;5;5;4",
        "correctness": "2;2;2;3",
        "technical_novelty": "1;1;2;2",
        "empirical_novelty": "1;2;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.5,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 1.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "u7PVCewFya",
        "title": "Losing Less: A Loss for Differentially Private Deep Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Differentially Private Deep Learning;DP-SGD",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "4;5;2;3",
        "correctness": "3;2;4;3",
        "technical_novelty": "3;2;2;2",
        "empirical_novelty": "3;3;2;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8944271909999159,
        "corr_rating_correctness": 0.7071067811865475,
        "project": "",
        "github": ""
    },
    {
        "id": "u7UxOTefG2",
        "title": "Uncertainty-based out-of-distribution detection requires suitable function space priors",
        "track": "main",
        "status": "Reject",
        "keywords": "Bayesian Statistics;Out-of-distribution Detection;Machine Learning;Neural Networks;Epistemic Uncertainty;Gaussian Process",
        "author": "",
        "aff": "",
        "rating": "5;5;6",
        "confidence": "3;2;4",
        "correctness": "3;4;3",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "1;2;2",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8660254037844385,
        "corr_rating_correctness": -0.4999999999999999,
        "project": "",
        "github": ""
    },
    {
        "id": "uB12zutkXJR",
        "title": "GRAPHIX: A Pre-trained Graph Edit Model for Automated Program Repair",
        "track": "main",
        "status": "Reject",
        "keywords": "Program Repair;Graph Neural Networks;Pre-training",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "5;5;3;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 4.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.17407765595569782,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "uEBrNNEfceE",
        "title": "Safe Linear-Quadratic Dual Control with Almost Sure Performance Guarantee",
        "track": "main",
        "status": "Reject",
        "keywords": "reinforcement learning",
        "author": "",
        "aff": "",
        "rating": "5;5;6;8",
        "confidence": "4;3;5;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;0;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.28867513459481287,
        "corr_rating_correctness": 0.9428090415820632,
        "project": "",
        "github": ""
    },
    {
        "id": "uF_Wl0xSA7O",
        "title": "Independent Component Alignment for Multi-task Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "multi-task learning;optimization",
        "author": "",
        "aff": "",
        "rating": "5;6;8",
        "confidence": "5;3;3",
        "correctness": "2;4;3",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "2;3;2",
        "presentation": "",
        "rating_avg": 6.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7559289460184546,
        "corr_rating_correctness": 0.3273268353539886,
        "project": "",
        "github": ""
    },
    {
        "id": "uHq5rHHektz",
        "title": "Contextual Fusion For Adversarial Robustness",
        "track": "main",
        "status": "Reject",
        "keywords": "Image processing;Neuroscience;Multi-modal representations",
        "author": "",
        "aff": "",
        "rating": "1;3;3;3",
        "confidence": "5;4;4;4",
        "correctness": "2;3;2;2",
        "technical_novelty": "1;1;1;1",
        "empirical_novelty": "1;2;1;1",
        "presentation": "",
        "rating_avg": 2.5,
        "confidence_avg": 4.25,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 1.0,
        "empirical_novelty_avg": 1.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "uHv20yi8saL",
        "title": "Monotonic Improvement Guarantees under Non-stationarity for Decentralized PPO",
        "track": "main",
        "status": "Reject",
        "keywords": "Multi-Agent Reinforcement Learning",
        "author": "",
        "aff": "",
        "rating": "3;6;6;8",
        "confidence": "4;2;3;3",
        "correctness": "1;4;3;3",
        "technical_novelty": "1;3;3;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5940885257860046,
        "corr_rating_correctness": 0.7388664511337208,
        "project": "",
        "github": ""
    },
    {
        "id": "uPv9Y3gmAI5",
        "title": "Language model compression with weighted low-rank factorization",
        "track": "main",
        "status": "Poster",
        "keywords": "model compression;low-rank approximation;transformer;language model",
        "author": "",
        "aff": "Northeastern University; Samsung Research America",
        "rating": "6;6;6",
        "confidence": "4;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "3;2;2",
        "empirical_novelty": "3;0;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "uR77O7SL55h",
        "title": "Scalable Sinkhorn Backpropagation",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Optimal Transport;Implicit Differentiation",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;4;3",
        "correctness": "4;3;4;3",
        "technical_novelty": "1;2;2;3",
        "empirical_novelty": "0;1;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "uS4AQe9Tv_R",
        "title": "Improving Gender Fairness of Pre-Trained Language Models without Catastrophic Forgetting",
        "track": "main",
        "status": "Withdraw",
        "keywords": "gender fairness;pre-trained language model;BERT",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6;6",
        "confidence": "4;4;4;4;5",
        "correctness": "2;3;3;3;3",
        "technical_novelty": "1;2;2;3;3",
        "empirical_novelty": "1;2;2;2;3",
        "presentation": "",
        "rating_avg": 4.6,
        "confidence_avg": 4.2,
        "correctness_avg": 2.8,
        "technical_novelty_avg": 2.2,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5160468465421401,
        "corr_rating_correctness": 0.5897678246195884,
        "project": "",
        "github": ""
    },
    {
        "id": "uSE03demja",
        "title": "RISP: Rendering-Invariant State Predictor with Differentiable Simulation and Rendering for Cross-Domain Parameter Estimation",
        "track": "main",
        "status": "Oral",
        "keywords": "differentiable rendering;differentiable simulation;system identification",
        "author": "",
        "aff": "MIT CSAIL; MIT BCS, CBMM, CSAIL; MIT-IBM Watson AI Lab",
        "rating": "8;8;8",
        "confidence": "4;3;4",
        "correctness": "4;4;3",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "4;3;3",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "http://risp.csail.mit.edu",
        "github": ""
    },
    {
        "id": "uUN0Huq-n_V",
        "title": "Polyphonic Music Composition: An Adversarial Inverse Reinforcement Learning Approach",
        "track": "main",
        "status": "Reject",
        "keywords": "music;reinforcement learning;airl;deep learning",
        "author": "",
        "aff": "",
        "rating": "3;5;6",
        "confidence": "5;4;4",
        "correctness": "2;3;4",
        "technical_novelty": "1;3;3",
        "empirical_novelty": "2;4;3",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.944911182523068,
        "corr_rating_correctness": 0.9819805060619659,
        "project": "",
        "github": ""
    },
    {
        "id": "uVTp9Z-IUOC",
        "title": "Test-Time Adaptation to Distribution Shifts by Confidence Maximization and Input Transformation",
        "track": "main",
        "status": "Reject",
        "keywords": "natural corruptions;corruption robustness;distribution shift;test time adaptation;domain shift",
        "author": "",
        "aff": "",
        "rating": "5;6;6;6",
        "confidence": "4;5;4;5",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "3;2;4;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 4.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "uVXEKeqJbNa",
        "title": "Stiffness-aware neural network for learning Hamiltonian systems",
        "track": "main",
        "status": "Poster",
        "keywords": "Hamiltonain systems;Neural network;Stiff dynamical systems;Data-driven method",
        "author": "",
        "aff": "Sun Yat-sen University; Purdue University; Argonne National Laboratory",
        "rating": "6;6;6;8",
        "confidence": "4;3;3;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "uXpTNpkXFLB",
        "title": "Towards Predictable Feature Attribution: Revisiting and Improving Guided BackPropagation",
        "track": "main",
        "status": "Withdraw",
        "keywords": "explanation;interpretation;BP-based attributions;predictability",
        "author": "",
        "aff": "",
        "rating": "3;3;6",
        "confidence": "4;4;2",
        "correctness": "1;2;3",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "2;1;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.8660254037844387,
        "project": "",
        "github": ""
    },
    {
        "id": "uY6fuowMIT",
        "title": "Approximate Bijective Correspondence for isolating factors of variation",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "1;5;5;6",
        "confidence": "4;4;2;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "1;2;2;2",
        "empirical_novelty": "1;2;0;2",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 1.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.22549380840084865,
        "corr_rating_correctness": 0.9771398364036774,
        "project": "",
        "github": ""
    },
    {
        "id": "uYLFoz1vlAC",
        "title": "Efficiently Modeling Long Sequences with Structured State Spaces",
        "track": "main",
        "status": "Oral",
        "keywords": "sequence models;state space;RNN;CNN;Long Range Arena",
        "author": "",
        "aff": "Department of Computer Science, Stanford University",
        "rating": "8;8;8",
        "confidence": "4;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "4;4;3",
        "empirical_novelty": "4;4;3",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 3.6666666666666665,
        "empirical_novelty_avg": 3.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/HazyResearch/state-spaces"
    },
    {
        "id": "uc8UsmcInvB",
        "title": "Statistically Meaningful Approximation: a Theoretical Analysis for Approximating Turing Machines with Transformers",
        "track": "main",
        "status": "Reject",
        "keywords": "approximation theory;generalization bounds;sample complexity bounds;learning theory",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;2;4;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "3;2;2;3",
        "empirical_novelty": "0;0;3;0",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 0.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.13245323570650439,
        "corr_rating_correctness": 0.6622661785325219,
        "project": "",
        "github": ""
    },
    {
        "id": "ucASPPD9GKN",
        "title": "Is Homophily a Necessity for Graph Neural Networks?",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "New Jersey Institute of Technology; Snap Inc.; Michigan State University",
        "rating": "6;6;6;6",
        "confidence": "4;4;4;4",
        "correctness": "3;3;2;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "ue4CArRAsct",
        "title": "Structure by Architecture: Disentangled Representations without Regularization",
        "track": "main",
        "status": "Reject",
        "keywords": "Autoencoder;Structure;Disentanglement;Generative;Hybridization",
        "author": "",
        "aff": "",
        "rating": "5;6;6;8",
        "confidence": "3;4;3;2",
        "correctness": "2;3;3;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6488856845230502,
        "corr_rating_correctness": 0.6622661785325219,
        "project": "",
        "github": ""
    },
    {
        "id": "uecYQBshVYV",
        "title": "Revisiting transposed convolutions for interpreting raw waveform sound event recognition CNNs by sonification",
        "track": "main",
        "status": "Withdraw",
        "keywords": "convolutional neural networks;interpretability;sound event recognition;raw waveform;contrastive learning;self-supervised learning;sound classification;audioset",
        "author": "",
        "aff": "",
        "rating": "1;3;5;5",
        "confidence": "4;3;3;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "1;2;2;2",
        "empirical_novelty": "2;2;1;0",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 1.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.30151134457776363,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "ufGMqIM0a4b",
        "title": "InfinityGAN: Towards Infinite-Pixel Image Synthesis",
        "track": "main",
        "status": "Poster",
        "keywords": "generative modeling;image synthesis;generative adversarial networks;infinite-pixel synthesis;GANs",
        "author": "",
        "aff": "Snap Inc.; Carnegie Mellon University; UC Merced, Yonsei University, Google Research; UC Merced",
        "rating": "6;8;8;8",
        "confidence": "4;4;3;4",
        "correctness": "3;4;4;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 1.0,
        "project": "https://hubert0527.github.io/infinityGAN/",
        "github": ""
    },
    {
        "id": "ugxdsne_TlO",
        "title": "GCF: Generalized Causal Forest for Heterogeneous Treatment Effect Estimation Using Nonparametric Methods",
        "track": "main",
        "status": "Reject",
        "keywords": "Heterogeneous Treatment Effect;Causal Inference;Double/Debiased Machine Learning;Continuous Treatment",
        "author": "",
        "aff": "",
        "rating": "1;5;5",
        "confidence": "4;3;2",
        "correctness": "1;3;3",
        "technical_novelty": "1;2;2",
        "empirical_novelty": "0;2;3",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 3.0,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 1.6666666666666667,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8660254037844385,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "uknMhonhXo",
        "title": "Selective Cross-Domain Consistency Regularization for Time Series Domain Generalization",
        "track": "main",
        "status": "Withdraw",
        "keywords": "time series classification;domain generalization;robustness",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;3;3;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "uoBAKAFkVKx",
        "title": "Hypothesis Driven Coordinate Ascent for Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Reinforcement Learning;Black-Box Optimization;Hypothesis Testing;Coordinate Ascent;Block Coordinate Ascent;Random Search;MDP",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "3;4;3;4",
        "correctness": "2;3;3;4",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "uorVGbWV5sw",
        "title": "Strength of Minibatch Noise in SGD",
        "track": "main",
        "status": "Spotlight",
        "keywords": "stochastic gradient descent;minibatch noise;discrete-time SGD;noise and fluctuation;exact solvable models",
        "author": "",
        "aff": "The University of Tokyo",
        "rating": "6;8;8;8",
        "confidence": "3;3;3;3",
        "correctness": "3;3;4;4",
        "technical_novelty": "3;3;4;3",
        "empirical_novelty": "1;3;0;2",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "uouGog2bW-F",
        "title": "Numerical Solution of Fredholm Integral Equations of the Second Kind using Neural Network Models",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Neural network;Second kind Fredholm integral equation;Collocation NN",
        "author": "",
        "aff": "",
        "rating": "1;1;1;1;3",
        "confidence": "5;4;5;4;2",
        "correctness": "4;3;1;2;3",
        "technical_novelty": "1;2;1;1;1",
        "empirical_novelty": "1;1;0;1;2",
        "presentation": "",
        "rating_avg": 1.4,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6,
        "technical_novelty_avg": 1.2,
        "empirical_novelty_avg": 1.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.912870929175277,
        "corr_rating_correctness": 0.19611613513818404,
        "project": "",
        "github": ""
    },
    {
        "id": "upnDJ7itech",
        "title": "Knowledge Infused Decoding",
        "track": "main",
        "status": "Poster",
        "keywords": "natural language;decoding;reinforcement learning;knowledge integration;generation",
        "author": "",
        "aff": "Northwestern University; Dartmouth College; Microsoft",
        "rating": "5;6;6;8",
        "confidence": "2;4;3;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.7608859102526822,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/microsoft/KID"
    },
    {
        "id": "uqBOne3LUKy",
        "title": "Is Importance Weighting Incompatible with Interpolating Classifiers?",
        "track": "main",
        "status": "Poster",
        "keywords": "overparameterization;distribution shifts;importance weighting;implicit bias;generalization analysis;interpolation",
        "author": "",
        "aff": "Department of Computer Science, Stanford University",
        "rating": "5;6;6;8",
        "confidence": "4;4;4;3",
        "correctness": "4;4;4;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9271726499455306,
        "corr_rating_correctness": -0.9271726499455306,
        "project": "",
        "github": ""
    },
    {
        "id": "uut_j3UrRCg",
        "title": "Provable hierarchical lifelong learning with a sketch-based modular architecture",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "3;2;3;2",
        "correctness": "3;2;4;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.7071067811865475,
        "project": "",
        "github": ""
    },
    {
        "id": "uwnOHjgUrTa",
        "title": "DNN Quantization with Attention",
        "track": "main",
        "status": "Reject",
        "keywords": "Deep learning;Computer vision;Quantization",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "4;2;4;4",
        "correctness": "3;2;3;3",
        "technical_novelty": "2;2;1;2",
        "empirical_novelty": "2;2;1;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "uxgg9o7bI_3",
        "title": "A New Perspective on \"How Graph Neural Networks Go Beyond Weisfeiler-Lehman?\"",
        "track": "main",
        "status": "Oral",
        "keywords": "Graph Neural Networks;Graph Isomorphism;Weisfeiler Lehman",
        "author": "",
        "aff": "School of Computing, Australian National University, Canberra, Australia",
        "rating": "8;8;8;8",
        "confidence": "3;4;4;3",
        "correctness": "4;4;4;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "0;3;3;3",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.5,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "uxxFrDwrE7Y",
        "title": "Learning Fast, Learning Slow: A General Continual Learning Method based on Complementary Learning System",
        "track": "main",
        "status": "Poster",
        "keywords": "Continual Learning;Catastrophic Forgetting;Complementary Learning Systems Theory;Experience Replay",
        "author": "",
        "aff": "Advanced Research Lab, NavInfo Europe, Eindhoven, Netherlands; ",
        "rating": "5;6;6;8",
        "confidence": "2;4;5;3",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;3;4;2",
        "empirical_novelty": "2;3;4;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.10259783520851541,
        "corr_rating_correctness": 0.6882472016116854,
        "project": "",
        "github": "https://github.com/NeurAI-Lab/CLS-ER"
    },
    {
        "id": "uy602F8cTrh",
        "title": "CausalDyna: Improving Generalization of Dyna-style Reinforcement Learning via Counterfactual-Based Data Augmentation",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "5;4;4;4",
        "correctness": "2;2;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "1;2;3;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "uydP1ykieNv",
        "title": "Ensemble-in-One: Learning Ensemble within Random Gated Networks for Enhanced Adversarial Robustness",
        "track": "main",
        "status": "Reject",
        "keywords": "Adversarial robustness;ensemble learning;random gated network;parameter sharing",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "3;4;3;4",
        "correctness": "3;3;3;2",
        "technical_novelty": "3;2;2;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": -1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "uymKrQiVuPg",
        "title": "Learning From Unpaired Data: A Variational Bayes Approach",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Unpaired degradation modeling;Variational auto-encoder;Real-world image restoration",
        "author": "",
        "aff": "",
        "rating": "3;5;5",
        "confidence": "4;3;2",
        "correctness": "1;2;4",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 4.333333333333333,
        "confidence_avg": 3.0,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8660254037844385,
        "corr_rating_correctness": 0.7559289460184545,
        "project": "",
        "github": ""
    },
    {
        "id": "v-27phh2c8O",
        "title": "AARL: Automated Auxiliary Loss for Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Reinforcement learning;Representation learning;Auxiliary Loss",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "3;4;4;4",
        "correctness": "2;2;3;3",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;1;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.75,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5555555555555555,
        "corr_rating_correctness": 0.9622504486493761,
        "project": "",
        "github": ""
    },
    {
        "id": "v-f7ifhKYps",
        "title": "Maximum Entropy Population Based Training for Zero-Shot Human-AI Coordination",
        "track": "main",
        "status": "Reject",
        "keywords": "Human-AI Coordination;Reinforcement Learning;Zero-Shot Human-AI Coordination;Deep Reinforcement Learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6;6",
        "confidence": "5;3;4;3;3",
        "correctness": "3;3;2;4;3",
        "technical_novelty": "2;3;2;3;3",
        "empirical_novelty": "2;3;3;2;2",
        "presentation": "",
        "rating_avg": 4.6,
        "confidence_avg": 3.6,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.51604684654214,
        "corr_rating_correctness": 0.23312620206007845,
        "project": "",
        "github": ""
    },
    {
        "id": "v-v1cpNNK_v",
        "title": "NASI: Label- and Data-agnostic Neural Architecture Search at Initialization",
        "track": "main",
        "status": "Poster",
        "keywords": "Neural Architecture Search;Initialization;Label- and Data-agnostic;Transferability;Neural Tangent Kernel",
        "author": "",
        "aff": "Department of Computer Science, National University of Singapore",
        "rating": "6;6;6;8",
        "confidence": "5;4;3;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "3;3;4;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "v3LXWP63qOZ",
        "title": "Learning Minimal Representations with Model Invariance",
        "track": "main",
        "status": "Reject",
        "keywords": "Representation Learning;Minimal Representations;Reinforcement Learning;Self-supervised Learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "4;4;4;4",
        "correctness": "1;1;3;3",
        "technical_novelty": "1;2;3;2",
        "empirical_novelty": "1;2;3;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 4.0,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9622504486493761,
        "project": "",
        "github": ""
    },
    {
        "id": "v3aeIsY_vVX",
        "title": "Chunked Autoregressive GAN for Conditional Waveform Synthesis",
        "track": "main",
        "status": "Poster",
        "keywords": "audio generation;speech synthesis;deep learning;generative models;autoregression;generative adversarial networks",
        "author": "",
        "aff": "Northwestern University; Mila, Quebec Artificial Intelligence Institute, Universite de Montreal; Descript, Inc.",
        "rating": "6;8;8",
        "confidence": "4;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "2;4;3",
        "empirical_novelty": "3;4;4",
        "presentation": "",
        "rating_avg": 7.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9999999999999998,
        "project": "",
        "github": ""
    },
    {
        "id": "v6s3HVjPerv",
        "title": "Do Users Benefit From Interpretable Vision? A User Study, Baseline, And Dataset",
        "track": "main",
        "status": "Poster",
        "keywords": "Interpretable ML;User Study;Human Subject Evaluation;Invertible Neural Networks;Convolutional Networks",
        "author": "",
        "aff": "TU Berlin; Freie Universit\u00a8at Berlin",
        "rating": "5;5;6;8",
        "confidence": "5;5;3;3",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "3;3;4;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8164965809277259,
        "corr_rating_correctness": 0.8164965809277259,
        "project": "",
        "github": ""
    },
    {
        "id": "v8OlxjGn23S",
        "title": "Low-Budget Active Learning via Wasserstein Distance: An Integer Programming Approach",
        "track": "main",
        "status": "Poster",
        "keywords": "active learning;integer optimization",
        "author": "",
        "aff": "NVIDIA; University of Toronto, Vector Institute",
        "rating": "6;6;6;8",
        "confidence": "4;3;3;3",
        "correctness": "4;3;3;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "v9iBLdSkFiP",
        "title": "TADA: Taxonomy Adaptive Domain Adaptation",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "5;5;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;1;3;2",
        "empirical_novelty": "0;1;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 4.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9622504486493761,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "vA7doMdgi75",
        "title": "Implicit Bias of Projected Subgradient Method Gives Provable Robust Recovery of Subspaces of Unknown Codimension",
        "track": "main",
        "status": "Spotlight",
        "keywords": "representation learning;robust subspace recovery;dual principals component pursuit;outliers;model selection",
        "author": "",
        "aff": "Mathematical Institute for Data Science, Johns Hopkins University, Baltimore, MD, USA",
        "rating": "5;6;8;8",
        "confidence": "4;4;2;3",
        "correctness": "4;4;4;3",
        "technical_novelty": "2;2;3;4",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 3.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8703882797784892,
        "corr_rating_correctness": -0.5555555555555555,
        "project": "",
        "github": ""
    },
    {
        "id": "vBn2OXZuQCF",
        "title": "How does Contrastive Pre-training Connect Disparate Domains?",
        "track": "main",
        "status": "Reject",
        "keywords": "pre-training;contrastive learning;robustness;out-of-distribution;domain shift",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "3;4;4;3",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "2;3;3;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "vDa28vlSBCP",
        "title": "Interactively Generating Explanations for Transformer Language Models",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "3;4;3;4",
        "correctness": "3;3;3;2",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;3;2;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "vDwBW49HmO",
        "title": "Gradient Matching for Domain Generalization",
        "track": "main",
        "status": "Poster",
        "keywords": "Domain generalization;multi-source domain adaptation",
        "author": "",
        "aff": "Facebook AI Research; Meta Reality Labs; University of Oxford; The University of Edinburgh & The Alan Turing Institute",
        "rating": "6;6;6;6;8",
        "confidence": "4;5;3;3;4",
        "correctness": "3;4;3;2;4",
        "technical_novelty": "3;3;3;2;3",
        "empirical_novelty": "3;2;3;2;3",
        "presentation": "",
        "rating_avg": 6.4,
        "confidence_avg": 3.8,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.8,
        "empirical_novelty_avg": 2.6,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.13363062095621223,
        "corr_rating_correctness": 0.5345224838248488,
        "project": "",
        "github": "https://github.com/YugeTen/fish"
    },
    {
        "id": "vEIVxSN8Xhx",
        "title": "Log-Polar Space Convolution",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;4;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "vEZyTBRPP6o",
        "title": "Actor-critic is implicitly biased towards high entropy optimal policies",
        "track": "main",
        "status": "Poster",
        "keywords": "implicit bias;reinforcement learning;actor-critic;policy gradient;mixing time;convergence rate;mirror ascent.",
        "author": "",
        "aff": "University of Illinois, Urbana-Champaign",
        "rating": "6;8;8",
        "confidence": "3;4;2",
        "correctness": "3;4;4",
        "technical_novelty": "3;4;4",
        "empirical_novelty": "0;4;0",
        "presentation": "",
        "rating_avg": 7.333333333333333,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 3.6666666666666665,
        "empirical_novelty_avg": 1.3333333333333333,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9999999999999998,
        "project": "",
        "github": ""
    },
    {
        "id": "vF0Qil7nPEd",
        "title": "Sequence-to-sequence modeling for action identification at high temporal resolution",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Deep learning;Action recognition;Benchmark dataset;Fine-grained action recognition;Stroke rehabilitation;Seq2seq models;sequence prediction",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "5;2;4;4",
        "correctness": "3;3;2;3",
        "technical_novelty": "1;2;2;2",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4736842105263159,
        "corr_rating_correctness": -0.13245323570650439,
        "project": "",
        "github": ""
    },
    {
        "id": "vHVcB-ak3Si",
        "title": "Dive Deeper Into Integral Pose Regression",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "National University of Singapore, Singapore",
        "rating": "6;6;8",
        "confidence": "5;4;4",
        "correctness": "2;4;3",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "2;3;0",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4999999999999999,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "vIC-xLFuM6",
        "title": "Overcoming The Spectral Bias of Neural Value Approximation",
        "track": "main",
        "status": "Poster",
        "keywords": "spectral bias;neural value approximation;Q learning;reinforcement learning;neural tangent kernels;kernel regression",
        "author": "",
        "aff": "NSF AI Institute for Artificial Intelligence and Fundamental Interactions (IAIFI), Computer Science and Artificial Intelligence Laboratory (CSAIL), Improbable AI Lab, Massachusetts Institute Technology",
        "rating": "3;6;6",
        "confidence": "4;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "2;4;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": "https://geyang.github.io/ffn"
    },
    {
        "id": "vJZ7dPIjip3",
        "title": "Generalization of Neural Combinatorial Solvers Through the Lens of Adversarial Robustness",
        "track": "main",
        "status": "Poster",
        "keywords": "Generalization;Neural Combinatorial Optimization;Adversarial Robustness",
        "author": "",
        "aff": "CISPA Helmholtz Center for Information Security; Department of Informatics & Munich Data Science Institute, Technical University of Munich",
        "rating": "6;8;8",
        "confidence": "3;4;2",
        "correctness": "3;4;4",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "3;2;4",
        "presentation": "",
        "rating_avg": 7.333333333333333,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9999999999999998,
        "project": "",
        "github": ""
    },
    {
        "id": "vJb4I2ANmy",
        "title": "Noisy Feature Mixup",
        "track": "main",
        "status": "Poster",
        "keywords": "Data augmentation;implicit regularization;mixup;noise injection;model robustness",
        "author": "",
        "aff": "Nordita, KTH and Stockholm University; ICSI and UC Berkeley; University of Pittsburgh and ICSI; University of Pittsburgh; University of Toronto",
        "rating": "6;6;8;8",
        "confidence": "4;3;4;3",
        "correctness": "4;3;4;3",
        "technical_novelty": "3;3;3;2",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "vKMVrqvXbXu",
        "title": "Effects of Data Geometry in Early Deep Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Deep learning;geometry;manifolds;deep learning theory",
        "author": "",
        "aff": "",
        "rating": "5;5;6;8",
        "confidence": "4;4;2;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "3;2;3;4",
        "empirical_novelty": "2;2;0;0",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 1.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.8164965809277259,
        "project": "",
        "github": ""
    },
    {
        "id": "vKefw-zKOft",
        "title": "Towards Efficient On-Chip Training of Quantum Neural Networks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Quantum Computing;Machine Learning;Neural Networks;Robustness;Quantum Machine Learning;Quantum Neural Networks;On-Chip;Training",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5;5",
        "confidence": "5;5;4;2;5",
        "correctness": "2;4;3;3;2",
        "technical_novelty": "2;2;3;3;1",
        "empirical_novelty": "2;2;2;2;3",
        "presentation": "",
        "rating_avg": 4.2,
        "confidence_avg": 4.2,
        "correctness_avg": 2.8,
        "technical_novelty_avg": 2.2,
        "empirical_novelty_avg": 2.2,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.560112033611204,
        "corr_rating_correctness": -0.21821789023599233,
        "project": "",
        "github": "https://github.com/anonymous-author/qnn-training (as mentioned in the text, the actual link may vary)"
    },
    {
        "id": "vLz0e9S-iF3",
        "title": "Quasi-potential theory for escape problem: Quantitative sharpness effect on SGD's escape from local minima",
        "track": "main",
        "status": "Reject",
        "keywords": "deep learning;learning dynamics;SGD;flat minima",
        "author": "",
        "aff": "",
        "rating": "3;3;5",
        "confidence": "5;4;3",
        "correctness": "1;3;4",
        "technical_novelty": "1;3;3",
        "empirical_novelty": "0;2;0",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 0.6666666666666666,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8660254037844387,
        "corr_rating_correctness": 0.7559289460184545,
        "project": "",
        "github": ""
    },
    {
        "id": "vMWl7Ta1ymW",
        "title": "Regularizing Image Classification Neural Networks with Partial Differential Equations",
        "track": "main",
        "status": "Withdraw",
        "keywords": "partial differential equations;image classification;differential equations",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5;5",
        "confidence": "2;4;4;4;3",
        "correctness": "2;3;3;2;3",
        "technical_novelty": "2;2;3;3;3",
        "empirical_novelty": "2;2;2;3;3",
        "presentation": "",
        "rating_avg": 3.8,
        "confidence_avg": 3.4,
        "correctness_avg": 2.6,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.10206207261596574,
        "corr_rating_correctness": -0.16666666666666663,
        "project": "",
        "github": ""
    },
    {
        "id": "vMYCSy4VwvD",
        "title": "Multi-Domain Active Learning: A Comparative Study",
        "track": "main",
        "status": "Withdraw",
        "keywords": "active learning;multi-domain Learning",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;4;4;4",
        "correctness": "4;4;3;3",
        "technical_novelty": "2;2;1;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "vNDHZZa-Q92",
        "title": "Neural Extensions: Training Neural Networks with Set Functions",
        "track": "main",
        "status": "Desk Reject",
        "keywords": "continuous extensions;algorithmic reasoning;set functions;machine learning;combinatorial optimization;image classification",
        "author": "",
        "aff": "",
        "rating": "",
        "confidence": "",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "vPK-G5HbnWg",
        "title": "PACE: A Parallelizable Computation Encoder for Directed Acyclic Graphs",
        "track": "main",
        "status": "Reject",
        "keywords": "DAG encoder;graph neural network;Transformer",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "5;3;4;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "vQ58AMOw4Il",
        "title": "Hermitry Ratio: Evaluating the validity of perturbation methods for explainable deep learning",
        "track": "main",
        "status": "Reject",
        "keywords": "deep learning;explainability;heatmaps;out-of-distribution detection",
        "author": "",
        "aff": "Under double-blind review",
        "rating": "3;3;3;5",
        "confidence": "4;3;4;5",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.816496580927726,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "vQmIksuciu2",
        "title": "EXPLAINABLE AI-BASED DYNAMIC FILTER PRUNING OF CONVOLUTIONAL NEURAL NETWORKS",
        "track": "main",
        "status": "Reject",
        "keywords": "XAI;Pruning;CNN;Explainable-AI",
        "author": "",
        "aff": "",
        "rating": "1;3;3;5",
        "confidence": "4;3;5;4",
        "correctness": "2;3;2;3",
        "technical_novelty": "1;2;1;2",
        "empirical_novelty": "1;2;1;3",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 1.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.7071067811865476,
        "project": "",
        "github": ""
    },
    {
        "id": "vRhkfX8G_H9",
        "title": "SpSC: A Fast and Provable Algorithm for Sampling-Based GNN Training",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;5;3;3",
        "correctness": "3;2;4;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5222329678670935,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "vSix3HPYKSU",
        "title": "Message Passing Neural PDE Solvers",
        "track": "main",
        "status": "Spotlight",
        "keywords": "neural PDE solvers;message passing;autoregressive models;zero-stability",
        "author": "",
        "aff": "University of Amsterdam, Johannes Kepler University Linz; Qualcomm AI Research; University of Amsterdam",
        "rating": "6;6;8;8",
        "confidence": "4;3;4;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "3;2;4;3",
        "empirical_novelty": "3;2;4;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "vUH85MOXO7h",
        "title": "A Neural Tangent Kernel Perspective of Infinite Tree Ensembles",
        "track": "main",
        "status": "Poster",
        "keywords": "Neural Tangent Kernel;Tree Ensemble;Soft Tree",
        "author": "",
        "aff": "National Institute of Informatics, The Graduate University for Advanced Studies, SOKENDAI",
        "rating": "3;8;8",
        "confidence": "2;3;3",
        "correctness": "3;4;4",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;3;4",
        "presentation": "",
        "rating_avg": 6.333333333333333,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9999999999999998,
        "corr_rating_correctness": 0.9999999999999998,
        "project": "",
        "github": ""
    },
    {
        "id": "vUvEyDA30k",
        "title": "Staircase Sign Method for Boosting Adversarial Attacks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "black-box;transferable perturbation;simple but effective;non-targeted&targeted attacks.",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "5;3;4;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "1;0;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6488856845230502,
        "corr_rating_correctness": 0.13245323570650439,
        "project": "Not provided",
        "github": "Not provided"
    },
    {
        "id": "vXGcHthY6v",
        "title": "Invariance Through Inference",
        "track": "main",
        "status": "Reject",
        "keywords": "invariance;representation learning;out-of-distribution;domain adaptation;generalization",
        "author": "",
        "aff": "",
        "rating": "5;6;6;6",
        "confidence": "4;4;3;2",
        "correctness": "2;4;3;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;3;0",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5222329678670935,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "v_gc2xDfXxR",
        "title": "PASS: Patch-Aware Self-Supervision for Vision Transformer",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Self-supervised learning;Vision Transformer;patch-level representations",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5;5",
        "confidence": "4;5;5;4;4",
        "correctness": "4;3;3;3;2",
        "technical_novelty": "2;2;3;3;3",
        "empirical_novelty": "1;2;2;2;3",
        "presentation": "",
        "rating_avg": 4.6,
        "confidence_avg": 4.4,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.4082482904638631,
        "corr_rating_correctness": -0.790569415042095,
        "project": "",
        "github": ""
    },
    {
        "id": "vaRCHVj0uGI",
        "title": "Solving Inverse Problems in Medical Imaging with Score-Based Generative Models",
        "track": "main",
        "status": "Poster",
        "keywords": "score-based generative modeling;inverse problems;sparse-view CT;undersampled MRI;metal artifact removal;diffusion",
        "author": "",
        "aff": "Stanford University",
        "rating": "6;6;8",
        "confidence": "3;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "3;3;2",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9999999999999998,
        "corr_rating_correctness": -0.49999999999999983,
        "project": "",
        "github": ""
    },
    {
        "id": "vcUmUvQCloe",
        "title": "Joint Shapley values: a measure of joint feature importance",
        "track": "main",
        "status": "Poster",
        "keywords": "explainable AI;Shapley value;interaction index;cooperative game theory",
        "author": "",
        "aff": "Economics, Mathematics & Statistics, Birkbeck College University of London, UK; Raptor Financial Technologies, Tokyo, Japan; Economics, University of Birmingham, UK",
        "rating": "5;8;8",
        "confidence": "3;2;3",
        "correctness": "3;3;4",
        "technical_novelty": "3;3;4",
        "empirical_novelty": "2;3;4",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.3333333333333335,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5,
        "corr_rating_correctness": 0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "vdKncX1WclT",
        "title": "Red Alarm for Pre-trained Models: Universal Vulnerability to Neuron-Level Backdoor Attacks",
        "track": "main",
        "status": "Reject",
        "keywords": "Pre-trained models;Backdoor attacks",
        "author": "",
        "aff": "Paper under double-blind review",
        "rating": "3;3;5;6",
        "confidence": "4;4;4;4",
        "correctness": "2;2;3;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "1;2;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 4.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9622504486493761,
        "project": "",
        "github": ""
    },
    {
        "id": "vdP_emhLjAt",
        "title": "Predicting Unreliable Predictions by Shattering a Neural Network",
        "track": "main",
        "status": "Withdraw",
        "keywords": "generalization;expressivity",
        "author": "",
        "aff": "",
        "rating": "1;3;3;6",
        "confidence": "4;2;3;3",
        "correctness": "1;2;3;3",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;3;2;2",
        "presentation": "",
        "rating_avg": 3.25,
        "confidence_avg": 3.0,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.39605901719066966,
        "corr_rating_correctness": 0.8021806287494232,
        "project": "",
        "github": ""
    },
    {
        "id": "vdbidlOkeF0",
        "title": "Scaling Densities For Improved Density Ratio Estimation",
        "track": "main",
        "status": "Reject",
        "keywords": "density ratio estimation;scaled bregman divergence;mutual information estimation;representation learning",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "4;4;3;4",
        "correctness": "2;3;4;3",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4714045207910316,
        "corr_rating_correctness": 0.8660254037844386,
        "project": "",
        "github": ""
    },
    {
        "id": "vds4SNooOe",
        "title": "Superclass-Conditional Gaussian Mixture Model For Learning Fine-Grained Embeddings",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Deep learning;represenation learning;generative model",
        "author": "",
        "aff": "Renascience, Inc.; NEC Laboratories America; NEC Corporation",
        "rating": "6;8;8",
        "confidence": "2;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "3;3;4",
        "presentation": "",
        "rating_avg": 7.333333333333333,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 1.0,
        "corr_rating_correctness": -0.49999999999999983,
        "project": "",
        "github": ""
    },
    {
        "id": "vfsRB5MImo9",
        "title": "Towards Continual Knowledge Learning of Language Models",
        "track": "main",
        "status": "Poster",
        "keywords": "continual learning;knowledge acquisition;catastrophic forgetting;large language models;pretraining;natural language processing",
        "author": "",
        "aff": "KAIST AI; LG AI Research",
        "rating": "3;6;6;8",
        "confidence": "5;4;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;3;3;4",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 4.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8892972917998875,
        "corr_rating_correctness": 0.0,
        "project": "https://this.https.url",
        "github": ""
    },
    {
        "id": "vgqS1vkkCbE",
        "title": "Value Function Spaces: Skill-Centric State Abstractions for Long-Horizon Reasoning",
        "track": "main",
        "status": "Poster",
        "keywords": "hierarchical reinforcement learning;planning;representation learning;robotics",
        "author": "Dhruv Shah",
        "aff": "Berkeley AI Research, UC Berkeley; Google Research, Robotics @ Google",
        "rating": "6;6;6;6",
        "confidence": "3;3;4;4",
        "correctness": "3;4;3;3",
        "technical_novelty": "3;2;3;2",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "vh-0sUt8HlG",
        "title": "MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer",
        "track": "main",
        "status": "Poster",
        "keywords": "Vision transformer;Mobile;Edge Devices;Transformer;CNN;Efficient Network;Detection;Segmentation;ImageNet",
        "author": "",
        "aff": "Apple",
        "rating": "5;6;8",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;3;0",
        "presentation": "",
        "rating_avg": 6.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/apple/ml-cvnets"
    },
    {
        "id": "vi9nRayoeaS",
        "title": "ASAP DML: Deep Metric Learning with Alternating Sets of Alternating Proxies",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Deep Metric Learning;Alternating Projections;Generalization",
        "author": "",
        "aff": "",
        "rating": "3;5;6",
        "confidence": "4;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "2;4;2",
        "empirical_novelty": "1;4;2",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7559289460184545,
        "corr_rating_correctness": 0.18898223650461363,
        "project": "",
        "github": ""
    },
    {
        "id": "viWF5cyz6i",
        "title": "An Efficient and Reliable Tolerance-Based Algorithm for Principal Component Analysis",
        "track": "main",
        "status": "Reject",
        "keywords": "principal component analysis;dimensionality reduction;data compression",
        "author": "",
        "aff": "",
        "rating": "3;5;5",
        "confidence": "3;3;3",
        "correctness": "3;4;2",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "1;2;3",
        "presentation": "",
        "rating_avg": 4.333333333333333,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "vjaGQ4cftD",
        "title": "Referring Self-supervised Learning on 3D Point Cloud",
        "track": "main",
        "status": "Withdraw",
        "keywords": "3D point cloud;self-supervised learning",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5;5",
        "confidence": "3;3;3;4;4",
        "correctness": "2;3;2;2;3",
        "technical_novelty": "2;2;3;2;3",
        "empirical_novelty": "1;2;2;3;0",
        "presentation": "",
        "rating_avg": 4.6,
        "confidence_avg": 3.4,
        "correctness_avg": 2.4,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 1.6,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.408248290463863,
        "corr_rating_correctness": 0.408248290463863,
        "project": "",
        "github": ""
    },
    {
        "id": "vkZtFD0zga8",
        "title": "Uncertainty-Aware Deep Video Compression with Ensembles",
        "track": "main",
        "status": "Reject",
        "keywords": "Video compression;uncertainty;ensemble learning",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "3;4;3;3",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "vkaMaq95_rX",
        "title": "EXACT: Scalable Graph Neural Networks Training via Extreme Activation Compression",
        "track": "main",
        "status": "Poster",
        "keywords": "graph neural networks;scalable GNN training;quantization;random projection",
        "author": "",
        "aff": "Rice University; Samsung Research America",
        "rating": "3;6;8",
        "confidence": "5;3;3",
        "correctness": "3;3;4",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 5.666666666666667,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9176629354822472,
        "corr_rating_correctness": 0.8029550685469661,
        "project": "",
        "github": "https://github.com/warai-0toko/Exact"
    },
    {
        "id": "vnENCLwVBET",
        "title": "OUMG: Objective and Universal Metric for Text Generation with Guiding Ability",
        "track": "main",
        "status": "Reject",
        "keywords": "evaluation metric;text generation;objective",
        "author": "",
        "aff": "",
        "rating": "1;1;3;3;3",
        "confidence": "4;4;5;4;3",
        "correctness": "1;1;1;2;2",
        "technical_novelty": "1;1;1;2;2",
        "empirical_novelty": "1;1;1;2;2",
        "presentation": "",
        "rating_avg": 2.2,
        "confidence_avg": 4.0,
        "correctness_avg": 1.4,
        "technical_novelty_avg": 1.4,
        "empirical_novelty_avg": 1.4,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.6666666666666667,
        "project": "",
        "github": ""
    },
    {
        "id": "vnF5gDNvcKX",
        "title": "Variance Reduced Domain Randomization for Policy Gradient",
        "track": "main",
        "status": "Reject",
        "keywords": "Reinforcement learning;generalization;variance reduction",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5",
        "confidence": "4;5;4;2",
        "correctness": "3;4;4;3",
        "technical_novelty": "2;2;2;4",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "vnOHGQY4FP1",
        "title": "Rethinking Temperature in Graph Contrastive Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "self-supervised learning;graph contrastive learning;uniformity",
        "author": "",
        "aff": "",
        "rating": "3;5;6;8",
        "confidence": "5;4;4;4",
        "correctness": "2;3;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;3;2",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8006407690254357,
        "corr_rating_correctness": 0.9198662110077999,
        "project": "",
        "github": ""
    },
    {
        "id": "voEpzgY8gsT",
        "title": "Additive Poisson Process: Learning Intensity of Higher-Order Interaction in Poisson Processes",
        "track": "main",
        "status": "Reject",
        "keywords": "Poisson Process;Log-Linear Model;Energy-Based Model;Generalized Additive Models;Information Geometry",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;3;3",
        "correctness": "2;3;4;2",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.30151134457776363,
        "project": "",
        "github": ""
    },
    {
        "id": "vpiOnyOBTzQ",
        "title": "Disentangled generative models for robust dynamical system prediction",
        "track": "main",
        "status": "Reject",
        "keywords": "disentanglement;dynamical systems;prediction;generative models;robustness;out-of-distribution;distribution shift;causal inference",
        "author": "",
        "aff": "",
        "rating": "1;3;3;5;6",
        "confidence": "4;3;4;3;4",
        "correctness": "3;3;2;3;3",
        "technical_novelty": "2;2;2;3;2",
        "empirical_novelty": "2;2;2;2;2",
        "presentation": "",
        "rating_avg": 3.6,
        "confidence_avg": 3.6,
        "correctness_avg": 2.8,
        "technical_novelty_avg": 2.2,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.1873171623163388,
        "corr_rating_correctness": 0.17206180040292135,
        "project": "https://bit.ly/dis-dyn-systems",
        "github": "https://anonymous.4open.science/r/dis-dyn-systems/"
    },
    {
        "id": "vqGi8Kp0wM",
        "title": "Mind the Gap: Domain Gap Control for Single Shot Domain Adaptation for Generative Adversarial Networks",
        "track": "main",
        "status": "Poster",
        "keywords": "GAN;StyleGAN;Clip;Domain Adaptation;Style Transfer;Single Shot",
        "author": "",
        "aff": "Miami University; KAUST",
        "rating": "6;6;8",
        "confidence": "4;4;3",
        "correctness": "2;3;4",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;3;4",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9999999999999998,
        "corr_rating_correctness": 0.8660254037844385,
        "project": "",
        "github": "https://zpdesu.github.io/MindTheGap"
    },
    {
        "id": "vr39r4Rjt3z",
        "title": "Designing Less Forgetful Networks for Continual Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Continual Learning",
        "author": "",
        "aff": "",
        "rating": "5;5;6;8;8",
        "confidence": "4;5;4;3;3",
        "correctness": "3;3;2;3;4",
        "technical_novelty": "2;3;3;3;4",
        "empirical_novelty": "3;3;2;3;4",
        "presentation": "",
        "rating_avg": 6.4,
        "confidence_avg": 3.8,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9063269671749656,
        "corr_rating_correctness": 0.4662524041201569,
        "project": "",
        "github": ""
    },
    {
        "id": "vr4Wo33bd1",
        "title": "Semi-supervised Long-tailed Recognition using Alternate Sampling",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "1;5;5;5;5",
        "confidence": "5;3;5;5;4",
        "correctness": "3;3;2;3;4",
        "technical_novelty": "2;3;2;2;3",
        "empirical_novelty": "1;3;2;2;2",
        "presentation": "",
        "rating_avg": 4.2,
        "confidence_avg": 4.4,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.37499999999999994,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "vrW3tvDfOJQ",
        "title": "Sample Efficient Deep Reinforcement Learning via Uncertainty Estimation",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Deep reinforcement learning;uncertainty estimation;inverse-variance;heteroscedastic",
        "author": "",
        "aff": "Robotics and Embodied AI Lab, Mila - Quebec Institute of Artificial Intelligence, Universit \u00b4e de Montr \u00b4eal, Quebec, Canada, \u2217Canada CIFAR AI Chair; Robotics and Embodied AI Lab, Mila - Quebec Institute of Artificial Intelligence, Universit \u00b4e de Montr \u00b4eal, Quebec, Canada",
        "rating": "8;8;8;10",
        "confidence": "4;4;4;5",
        "correctness": "3;3;4;4",
        "technical_novelty": "4;3;3;3",
        "empirical_novelty": "3;4;2;4",
        "presentation": "",
        "rating_avg": 8.5,
        "confidence_avg": 4.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 1.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "vruwp11pWnO",
        "title": "Improving and Assessing Anomaly Detectors for Large-Scale Settings",
        "track": "main",
        "status": "Reject",
        "keywords": "anomaly;ood;distribution shift;out-of-distribution",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5;6",
        "confidence": "5;3;4;4;4",
        "correctness": "2;3;4;3;3",
        "technical_novelty": "1;2;3;2;3",
        "empirical_novelty": "2;4;3;3;3",
        "presentation": "",
        "rating_avg": 4.8,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.2,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6454972243679028,
        "corr_rating_correctness": 0.6454972243679028,
        "project": "",
        "github": ""
    },
    {
        "id": "vsEi1UMa7TC",
        "title": "Exploiting Knowledge Distillation for Few-Shot Image Generation",
        "track": "main",
        "status": "Withdraw",
        "keywords": "few-show image generation;knowledge distillation",
        "author": "",
        "aff": "",
        "rating": "3;3;5",
        "confidence": "4;5;4",
        "correctness": "3;3;3",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4999999999999999,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "vtDzHJOsmfJ",
        "title": "Non-convex Optimization for Learning a Fair Predictor under Equalized Loss Fairness Constraint",
        "track": "main",
        "status": "Reject",
        "keywords": "Non-convex Optimization;Fairness;Supervised Learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "5;3;4;3",
        "correctness": "3;4;4;4",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "1;2;4;2",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4061811972299616,
        "corr_rating_correctness": 0.5555555555555555,
        "project": "",
        "github": ""
    },
    {
        "id": "vtLbsGUyYx",
        "title": "AutoCoG: A Unified Data-Modal Co-Search Framework for Graph Neural Networks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "GCN;NAS",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;5;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "3;3;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "vuw072gfi3W",
        "title": "A Permutation-Invariant Representation of Neural Networks with Neuron Embeddings",
        "track": "main",
        "status": "Withdraw",
        "keywords": "neural networks;neural network representation;neuroevolution;transfer learning",
        "author": "",
        "aff": "",
        "rating": "1;3;5;6",
        "confidence": "5;4;3;3",
        "correctness": "2;3;3;3",
        "technical_novelty": "1;2;2;4",
        "empirical_novelty": "1;1;2;0",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9813358399735743,
        "corr_rating_correctness": 0.8268106308031117,
        "project": "",
        "github": ""
    },
    {
        "id": "vwLLQ-HwqhZ",
        "title": "Continual Normalization: Rethinking Batch Normalization for Online Continual Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "Continual Learning;Batch Normalization",
        "author": "",
        "aff": "Salesforce Research Asia; Singapore Management University, Salesforce Research Asia; Singapore Management University",
        "rating": "5;6;6;8",
        "confidence": "4;4;4;4",
        "correctness": "3;4;3;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;3;3;4",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.13245323570650439,
        "project": "",
        "github": "https://github.com/phquang/Continual-Normalization"
    },
    {
        "id": "vwj6aUeocyf",
        "title": "Long Expressive Memory for Sequence Modeling",
        "track": "main",
        "status": "Spotlight",
        "keywords": "sequence modeling;long-term dependencies;multiscale ordinary differential equations;dynamical systems",
        "author": "",
        "aff": "ETH Z\u00fcrich; University of Pittsburgh; ICSI and UC Berkeley",
        "rating": "6;6;8;8",
        "confidence": "3;3;4;4",
        "correctness": "4;4;3;4",
        "technical_novelty": "3;3;4;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 1.0,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "vxlAHR9AyZ6",
        "title": "$\\alpha$-Weighted Federated Adversarial Training",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;5;8",
        "confidence": "4;3;5;3",
        "correctness": "3;2;3;4",
        "technical_novelty": "2;3;2;4",
        "empirical_novelty": "2;4;2;4",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5222329678670935,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "vyn49BUAkoD",
        "title": "Bayesian Active Learning with Fully Bayesian Gaussian Processes",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "3;4;4;4",
        "correctness": "2;3;3;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9271726499455306,
        "corr_rating_correctness": 0.9733285267845754,
        "project": "",
        "github": ""
    },
    {
        "id": "w-CPUXXrAj",
        "title": "On the Limitations of Multimodal VAEs",
        "track": "main",
        "status": "Poster",
        "keywords": "multimodal learning;variational autoencoder;variational information bottleneck;information theory",
        "author": "",
        "aff": "Department of Computer Science, ETH Zurich",
        "rating": "6;6;8;8",
        "confidence": "3;3;5;3",
        "correctness": "3;4;3;3",
        "technical_novelty": "4;2;3;3",
        "empirical_novelty": "3;2;4;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "w01vBAcewNX",
        "title": "On Covariate Shift of Latent Confounders in Imitation and Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "imitation learning;reinforcement learning;expert data;hidden confounding;causal inference;covariate shift",
        "author": "",
        "aff": "Nvidia Research, Technion; Technion; Nvidia Research",
        "rating": "5;6;6;6",
        "confidence": "4;4;4;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "w1UbdvWH_R3",
        "title": "Neural Collapse Under MSE Loss: Proximity to and Dynamics on the Central Path",
        "track": "main",
        "status": "Oral",
        "keywords": "neural collapse;deep learning theory;deep learning;inductive bias;equiangular tight frame;ETF;nearest class center;mean squared error loss;MSE loss;invariance;renormalization;gradient flow;dynamics;adversarial robustness",
        "author": "",
        "aff": "Stanford University; Cornell University; University of Toronto",
        "rating": "6;6;8;8",
        "confidence": "3;4;4;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "3;3;4;3",
        "empirical_novelty": "3;3;4;0",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "https://colab.research.google.com/drive/... (mentioned in the text as 'here')",
        "github": "https://github.com/... (not provided in the text)"
    },
    {
        "id": "w4cXZDDib1H",
        "title": "ViDT: An Efficient and Effective Fully Transformer-based Object Detector",
        "track": "main",
        "status": "Poster",
        "keywords": "object detection;vision transformer;detection transformer",
        "author": "",
        "aff": "University of California at Merced; NAVER AI Lab; Google Research",
        "rating": "5;6;8",
        "confidence": "4;4;5",
        "correctness": "4;3;4",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;2;4",
        "presentation": "",
        "rating_avg": 6.333333333333333,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.944911182523068,
        "corr_rating_correctness": 0.18898223650461363,
        "project": "",
        "github": "https://github.com/naver-ai/vidt"
    },
    {
        "id": "w60btE_8T2m",
        "title": "Spanning Tree-based Graph Generation for Molecules",
        "track": "main",
        "status": "Spotlight",
        "keywords": "molecule generation;tree generation;graph generation;deep generative model;de novo drug design",
        "author": "",
        "aff": "POSTECH; Georgia Institute of Technology; Biomap; MBZUAI",
        "rating": "6;6;8;8",
        "confidence": "5;4;4;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;0;2;4",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "w7Nb5dSMM-",
        "title": "Evolutionary perspective on model fine-tuning",
        "track": "main",
        "status": "Reject",
        "keywords": "Evolutionary algorithms;stochastic gradient descent;fine-tuning",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "5;4;4;4",
        "correctness": "2;2;3;2",
        "technical_novelty": "3;2;2;3",
        "empirical_novelty": "1;0;2;3",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.25,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "w8HXzn2FyKm",
        "title": "Finite-Time Error Bounds for Distributed Linear Stochastic Approximation",
        "track": "main",
        "status": "Reject",
        "keywords": "Stochastic Approximation;Distributed Stochastic Approximation;Finite-time Analysis",
        "author": "",
        "aff": "Affiliation of the Author (Please provide actual affiliation(s) if available); Affiliation of the Second Author (Please provide actual affiliation(s) if available)",
        "rating": "5;5;5;5;5",
        "confidence": "5;4;3;4;3",
        "correctness": "3;3;3;3;4",
        "technical_novelty": "4;2;3;3;3",
        "empirical_novelty": "4;2;1;0;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.8,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "wClmeg9u7G",
        "title": "Distributed Methods with Compressed Communication for Solving Variational Inequalities, with Theoretical Guarantees",
        "track": "main",
        "status": "Reject",
        "keywords": "convex optimization;saddle point problem;minmax problem;distributed optimization;quantization;compression",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;5;2;3",
        "correctness": "2;2;3;2",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8944271909999159,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "wENMvIsxNN",
        "title": "D-CODE: Discovering Closed-form ODEs from Observed Trajectories",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Symbolic Regression;Ordinary Differential Equation",
        "author": "",
        "aff": "University of Cambridge; University of Cambridge, UCLA, The Alan Turing Institute",
        "rating": "6;6;8;8",
        "confidence": "4;4;3;3",
        "correctness": "3;4;4;4",
        "technical_novelty": "3;2;4;3",
        "empirical_novelty": "4;2;3;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "wGLGG4918oc",
        "title": "CubeTR: Learning to Solve the Rubik's Cube using Transformers",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Machine Learning;Transformers;Reinforcement Learning;Rubik's Cube",
        "author": "",
        "aff": "",
        "rating": "1;1;1;1",
        "confidence": "4;5;5;3",
        "correctness": "1;1;3;1",
        "technical_novelty": "2;1;1;3",
        "empirical_novelty": "1;1;1;2",
        "presentation": "",
        "rating_avg": 1.0,
        "confidence_avg": 4.25,
        "correctness_avg": 1.5,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 1.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "wIK1fWFXvU9",
        "title": "Understanding the Interaction of Adversarial Training with Noisy Labels",
        "track": "main",
        "status": "Reject",
        "keywords": "noisy labels;adversarial training",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "5;4;3;3",
        "correctness": "3;2;3;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.899228803025897,
        "corr_rating_correctness": -0.13245323570650439,
        "project": "",
        "github": ""
    },
    {
        "id": "wIzUeM3TAU",
        "title": "Expressiveness and Approximation Properties of Graph Neural Networks",
        "track": "main",
        "status": "Oral",
        "keywords": "Graph Neural Networks;Colour Refinement;Weisfeiler-Leman;Separation Power;Universality",
        "author": "",
        "aff": "School of Engineering, Pontificia Universidad Cat\u00f3lica de Chile, Chile & IMFD, Chile; Department of Computer Science, University of Antwerp, Belgium",
        "rating": "8;8;8;10",
        "confidence": "4;4;2;4",
        "correctness": "4;4;4;4",
        "technical_novelty": "3;3;3;4",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 8.5,
        "confidence_avg": 3.5,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "wMXYbJB-gX",
        "title": "Towards Understanding Label Smoothing",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "4;3;3;4",
        "correctness": "3;4;3;3",
        "technical_novelty": "3;3;2;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "wMpS-Z_AI_E",
        "title": "A Theoretical Analysis on Feature Learning in Neural Networks: Emergence from Inputs and Advantage over Fixed Features",
        "track": "main",
        "status": "Poster",
        "keywords": "neural networks;feature learning;provable advantage;theoretical analysis",
        "author": "",
        "aff": "University of Wisconsin-Madison",
        "rating": "5;6;6;6;8",
        "confidence": "4;3;3;2;3",
        "correctness": "4;3;4;3;3",
        "technical_novelty": "2;3;3;3;3",
        "empirical_novelty": "3;2;2;2;2",
        "presentation": "",
        "rating_avg": 6.2,
        "confidence_avg": 3.0,
        "correctness_avg": 3.4,
        "technical_novelty_avg": 2.8,
        "empirical_novelty_avg": 2.2,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3227486121839514,
        "corr_rating_correctness": -0.5833333333333334,
        "project": "",
        "github": ""
    },
    {
        "id": "wNsNT56zDkG",
        "title": "Adversarial Rademacher Complexity of Deep Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "Adversarial Robustness;Generalization;Rademacher complexity",
        "author": "",
        "aff": "",
        "rating": "6;8;8;8",
        "confidence": "3;4;3;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "wQ7RCayXUSl",
        "title": "Why so pessimistic? Estimating uncertainties for offline RL through ensembles, and why their independence matters.",
        "track": "main",
        "status": "Reject",
        "keywords": "offline reinforcement learning;batch reinforcement learning;ensembles;uncertainty estimation.",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5;5",
        "confidence": "2;4;4;2;5",
        "correctness": "2;2;3;3;2",
        "technical_novelty": "2;1;2;2;2",
        "empirical_novelty": "2;2;2;3;3",
        "presentation": "",
        "rating_avg": 4.2,
        "confidence_avg": 3.4,
        "correctness_avg": 2.4,
        "technical_novelty_avg": 1.8,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.2721655269759087,
        "corr_rating_correctness": 0.6666666666666667,
        "project": "",
        "github": ""
    },
    {
        "id": "wQDdEFPy6vi",
        "title": "Local Learning Matters: Rethinking Data Heterogeneity in Federated Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Federated Learning",
        "author": "",
        "aff": "",
        "rating": "3;5;5",
        "confidence": "3;3;4",
        "correctness": "3;4;3",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 4.333333333333333,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.49999999999999983,
        "corr_rating_correctness": 0.49999999999999983,
        "project": "",
        "github": ""
    },
    {
        "id": "wQStfB93RZZ",
        "title": "Asynchronous Multi-Agent Actor-Critic with Macro-Actions",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "3;3;4;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "3;3;2;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "wQfgfb8VKTn",
        "title": "Context-Aware Sparse Deep Coordination Graphs",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Multi-agent reinforcement learning;Sparse coordination graphs;Deep coordination graphs",
        "author": "",
        "aff": "Institute for Interdisciplinary Information Sciences (IIIS), Tsinghua University; National Key Laboratory of Novel Software Technology, Nanjing University",
        "rating": "6;6;8;8",
        "confidence": "3;3;4;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "3;3;4;4",
        "empirical_novelty": "3;3;4;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.5,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 1.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": "https://github.com/TonghanWang/CASEC-MACO-benchmark"
    },
    {
        "id": "wRODLDHaAiW",
        "title": "iLQR-VAE : control-based learning of input-driven dynamics with applications to neural data",
        "track": "main",
        "status": "Oral",
        "keywords": "neuroscience;latent variable models;RNN;VAE;motor control;control theory;dynamical systems",
        "author": "",
        "aff": "Gatsby Computational Neuroscience Unit, University College London, London, UK; Department of Engineering, University of Cambridge, Cambridge, UK",
        "rating": "8;8;8",
        "confidence": "3;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "3;4;4",
        "empirical_novelty": "2;4;3",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 3.6666666666666665,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "wTTjnvGphYj",
        "title": "Graph Neural Networks with Learnable Structural and Positional Representations",
        "track": "main",
        "status": "Poster",
        "keywords": "graph neural networks;graph representation learning;transformers;positional encoding",
        "author": "",
        "aff": "National University of Singapore; Mila, University of Montr\u00e9al; Loyola Marymount University; Nanyang Technological University, Singapore",
        "rating": "5;5;6;8;8",
        "confidence": "4;4;3;4;4",
        "correctness": "3;3;3;4;3",
        "technical_novelty": "2;2;3;3;3",
        "empirical_novelty": "2;2;3;3;3",
        "presentation": "",
        "rating_avg": 6.4,
        "confidence_avg": 3.8,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 2.6,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.14744195615489716,
        "corr_rating_correctness": 0.5897678246195885,
        "project": "",
        "github": "https://github.com/vijaydwivedi75/gnn-lspe"
    },
    {
        "id": "wVFkD13GpeX",
        "title": "ReGVD: Revisiting Graph Neural Networks for Vulnerability Detection",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Vulnerability Detection;Cyber Security;Graph Neural Networks;Programming Language",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "4;4;3;5",
        "correctness": "3;3;3;2",
        "technical_novelty": "1;2;1;3",
        "empirical_novelty": "1;2;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "wX4Z5X5vpm",
        "title": "Plan Your Target and Learn Your Skills: State-Only Imitation Learning via Decoupled Policy Optimization",
        "track": "main",
        "status": "Withdraw",
        "keywords": "reinforcement learning;imitation learning",
        "author": "",
        "aff": "",
        "rating": "5;5;5",
        "confidence": "4;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "4;3;3",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.3333333333333335,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "wYqLTy4wkor",
        "title": "Grounding Aleatoric Uncertainty in Unsupervised Environment Design",
        "track": "main",
        "status": "Reject",
        "keywords": "reinforcement learning;curriculum learning;generalization;environment design;procedural content generation",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5",
        "confidence": "4;3;3;2",
        "correctness": "4;2;3;3",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "w_drCosT76",
        "title": "Differentiable Scaffolding Tree for Molecule Optimization",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "University of Illinois at Urbana-Champaign; Georgia Institute of Technology; Amplitude; Massachusetts Institute of Technology",
        "rating": "5;6;8;10",
        "confidence": "5;5;4;4",
        "correctness": "3;4;4;4",
        "technical_novelty": "4;4;3;4",
        "empirical_novelty": "2;2;3;4",
        "presentation": "",
        "rating_avg": 7.25,
        "confidence_avg": 4.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.911322376865767,
        "corr_rating_correctness": 0.676481425202546,
        "project": "",
        "github": "https://github.com/futianfan/DST"
    },
    {
        "id": "wbPObLm6ueA",
        "title": "Fairness Guarantees under Demographic Shift",
        "track": "main",
        "status": "Poster",
        "keywords": "Fairness and Bias in Artificial Intelligence;Machine Learning",
        "author": "",
        "aff": "Department of Computer Science, University of Texas at Austin; College of Information and Computer Sciences, University of Massachusetts",
        "rating": "5;6;6;8",
        "confidence": "4;3;4;5",
        "correctness": "3;4;3;4",
        "technical_novelty": "4;3;3;3",
        "empirical_novelty": "4;3;3;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.6488856845230502,
        "corr_rating_correctness": 0.6882472016116854,
        "project": "",
        "github": ""
    },
    {
        "id": "wfRZkDvxOqj",
        "title": "Multi-Task Neural Processes",
        "track": "main",
        "status": "Reject",
        "keywords": "Multi-task learning;Neural processes;Variational Inference",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "4;4;4;3",
        "correctness": "2;3;4;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "1;2;4;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.7071067811865475,
        "project": "",
        "github": "https://anonymous.4open.science/r/Multi-Task-Neural-Processes/"
    },
    {
        "id": "wfZGut6e09",
        "title": "Pareto Policy Adaptation",
        "track": "main",
        "status": "Poster",
        "keywords": "multi-objective reinforcement learning;policy gradient;pareto optimality;policy adaptation",
        "author": "",
        "aff": "University of Southern California, Los Angeles, USA",
        "rating": "5;6;8",
        "confidence": "4;3;2",
        "correctness": "3;3;4",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "3;2;3",
        "presentation": "",
        "rating_avg": 6.333333333333333,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9819805060619659,
        "corr_rating_correctness": 0.944911182523068,
        "project": "",
        "github": ""
    },
    {
        "id": "wgR0BQfG5vi",
        "title": "Adaptive Label Smoothing with Self-Knowledge",
        "track": "main",
        "status": "Reject",
        "keywords": "Regularization;Model Calibration;Adaptive Label Smoothing;Self-Knowledge Distillation;Overconfidence;Natural Language Generation",
        "author": "",
        "aff": "",
        "rating": "6;6;6;6",
        "confidence": "3;4;4;4",
        "correctness": "4;3;4;4",
        "technical_novelty": "3;3;4;2",
        "empirical_novelty": "3;3;4;2",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "wk5-XVtitD",
        "title": "Language Model Pre-training Improves Generalization in Policy Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Large Language model;Imitation learning;Interactive tasks;policy learning",
        "author": "",
        "aff": "",
        "rating": "3;3;3;6",
        "confidence": "5;4;4;5",
        "correctness": "3;2;2;4",
        "technical_novelty": "1;2;2;2",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 4.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.8703882797784892,
        "project": "",
        "github": ""
    },
    {
        "id": "wkMG8cdvh7-",
        "title": "Understanding and Improving Graph Injection Attack by Promoting Unnoticeability",
        "track": "main",
        "status": "Poster",
        "keywords": "Graph Neural Networks;Adversarial Attacks;Node Classification",
        "author": "",
        "aff": "Hong Kong Baptist University; The University of Sydney; The Chinese University of Hong Kong",
        "rating": "6;6;6;8",
        "confidence": "5;3;3;4",
        "correctness": "4;3;3;4",
        "technical_novelty": "2;3;3;4",
        "empirical_novelty": "2;3;4;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.17407765595569782,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "wmQCFqV9r8L",
        "title": "SpaceMAP: Visualizing Any Data in 2-dimension by Space Expansion",
        "track": "main",
        "status": "Reject",
        "keywords": "dimensionality reduction;data embedding;manifold learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5;5",
        "confidence": "4;4;4;4;3",
        "correctness": "2;3;3;4;2",
        "technical_novelty": "3;3;3;3;3",
        "empirical_novelty": "2;3;4;2;2",
        "presentation": "",
        "rating_avg": 4.2,
        "confidence_avg": 3.8,
        "correctness_avg": 2.8,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.6,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.408248290463863,
        "corr_rating_correctness": 0.3273268353539886,
        "project": "",
        "github": ""
    },
    {
        "id": "wogsFPHwftY",
        "title": "Learning Super-Features for Image Retrieval",
        "track": "main",
        "status": "Poster",
        "keywords": "image retrieval;landmark retrieval;mid-level features",
        "author": "",
        "aff": "NAVER LABS Europe, Grenoble, France",
        "rating": "6;8;8;8",
        "confidence": "4;4;4;5",
        "correctness": "3;4;4;4",
        "technical_novelty": "2;4;3;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 4.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": "https://github.com/naver/FIRe"
    },
    {
        "id": "wqD6TfbYkrn",
        "title": "A Conditional Point Diffusion-Refinement Paradigm for 3D Point Cloud Completion",
        "track": "main",
        "status": "Poster",
        "keywords": "Point Cloud Completion;Denoising Diffusion Pobabilistic Model;Conditional Generation",
        "author": "",
        "aff": "CUHK-SenseTime Joint Lab, The Chinese University of Hong Kong and Shanghai AI Laboratory; S-Lab, Nanyang Technological University; University of California, San Diego; CUHK-SenseTime Joint Lab, The Chinese University of Hong Kong",
        "rating": "6;8;8",
        "confidence": "5;4;5",
        "correctness": "3;4;4",
        "technical_novelty": "3;4;4",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 7.333333333333333,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 3.6666666666666665,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4999999999999999,
        "corr_rating_correctness": 0.9999999999999998,
        "project": "",
        "github": "https://github.com/ZhaoyangLyu/Point_Diffusion_Refinement"
    },
    {
        "id": "wronZ3Mx_d",
        "title": "Transfer Learning for Bayesian HPO with End-to-End Meta-Features",
        "track": "main",
        "status": "Reject",
        "keywords": "meta-learning;hyperparameter optimization;meta-features;deep kernel learning;Bayesian optimization;transfer learning",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6;8",
        "confidence": "3;3;3;3;3",
        "correctness": "3;3;4;3;4",
        "technical_novelty": "3;3;2;3;3",
        "empirical_novelty": "3;2;2;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.4,
        "technical_novelty_avg": 2.8,
        "empirical_novelty_avg": 2.6,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.74535599249993,
        "project": "",
        "github": ""
    },
    {
        "id": "wsJodhkuqs",
        "title": "Coordinated Attacks Against Federated Learning: A Multi-Agent Reinforcement Learning Approach",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Federated learning;adversarial attackers;multi-agent reinforcement learning;model-based reinforcement learning",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "3;3;3;3",
        "correctness": "4;3;4;3",
        "technical_novelty": "1;3;3;3",
        "empirical_novelty": "2;3;3;4",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.40824829046386296,
        "project": "",
        "github": ""
    },
    {
        "id": "wsuQ2h6KZXQ",
        "title": "Image-to-Image MLP-mixer for Image Reconstruction",
        "track": "main",
        "status": "Withdraw",
        "keywords": "MLP-mixer;image reconstruction;denoising;compressive sensing",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;3;4",
        "correctness": "2;2;4;3",
        "technical_novelty": "1;2;2;2",
        "empirical_novelty": "2;2;2;1",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.9045340337332909,
        "project": "",
        "github": ""
    },
    {
        "id": "wu5yYUutDGW",
        "title": "Boundary-aware Pre-training for Video Scene Segmentation",
        "track": "main",
        "status": "Reject",
        "keywords": "Temporal Segmentation;Video Scene segmentation;Self-supervised Learning",
        "author": "",
        "aff": "",
        "rating": "5;6;6",
        "confidence": "5;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 5.666666666666667,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9999999999999998,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "wv6g8fWLX2q",
        "title": "TAMP-S2GCNets: Coupling Time-Aware Multipersistence Knowledge Representation with Spatio-Supra Graph Convolutional Networks for Time-Series Forecasting",
        "track": "main",
        "status": "Spotlight",
        "keywords": "topological data analysis;multipersistence;graph convolutional networks;supragraph diffusion;multivariate time series forecasting",
        "author": "",
        "aff": "Department of Electrical and Computer Engineering, Princeton University; Lawrence Berkeley National Laboratory; Department of Mathematical Sciences, University of Texas at Dallas; Jet Propulsion Laboratory, Caltech; Department of Mathematical Sciences, University of Texas at Dallas; National Science Foundation; Department of Mathematical Sciences, University of Texas at Dallas",
        "rating": "8;8;8",
        "confidence": "3;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "3;4;4",
        "empirical_novelty": "4;4;4",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 3.6666666666666665,
        "empirical_novelty_avg": 4.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "ww6-vH7LgV",
        "title": "FastEnsemble: Benchmarking and Accelerating Ensemble-based Uncertainty Estimation for Image-to-Image Translation",
        "track": "main",
        "status": "Withdraw",
        "keywords": "uncertainty estimation;confidence calibration;biomedical imaging",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "2;4;3;5",
        "correctness": "3;4;3;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.6024640760767093,
        "corr_rating_correctness": -0.5555555555555555,
        "project": "",
        "github": ""
    },
    {
        "id": "wwDg3bbYBIq",
        "title": "Learning to Remember Patterns: Pattern Matching Memory Networks for Traffic Forecasting",
        "track": "main",
        "status": "Poster",
        "keywords": "Traffic Forecasting;Deep Learning",
        "author": "",
        "aff": "Ulsan National Institute of Science and Technology",
        "rating": "5;6;8;8",
        "confidence": "4;4;5;2",
        "correctness": "3;2;4;4",
        "technical_novelty": "3;2;4;3",
        "empirical_novelty": "2;2;4;3",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.22075539284417395,
        "corr_rating_correctness": 0.7543365091413573,
        "project": "",
        "github": ""
    },
    {
        "id": "wwIBobGFj2V",
        "title": "RoQNN: Noise-Aware Training for Robust Quantum Neural Networks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Quantum Computing;Machine Learning;Neural Networks;Robustness;Quantum Machine Learning;Quantum Neural Networks",
        "author": "",
        "aff": "",
        "rating": "3;3;5;8",
        "confidence": "5;4;5;3",
        "correctness": "4;2;3;4",
        "technical_novelty": "2;2;2;4",
        "empirical_novelty": "2;2;2;4",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6998739952495694,
        "corr_rating_correctness": 0.47886115464444223,
        "project": "",
        "github": "https://github.com/anonymous-author/roqnn (assuming this is the correct link provided in the text)"
    },
    {
        "id": "wwVb95CkrFm",
        "title": "Neuro-Symbolic Ontology-Mediated Query Answering",
        "track": "main",
        "status": "Withdraw",
        "keywords": "knowledge graph embeddings;ontologies;logical query answering;reasoning",
        "author": "",
        "aff": "",
        "rating": "3;5;6",
        "confidence": "5;4;4",
        "correctness": "2;2;4",
        "technical_novelty": "1;3;3",
        "empirical_novelty": "1;2;4",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.944911182523068,
        "corr_rating_correctness": 0.7559289460184546,
        "project": "",
        "github": ""
    },
    {
        "id": "wxVpa5z4DU1",
        "title": "Accuracy-Privacy Trade-off in Deep Ensemble: A Membership Inference Perspective",
        "track": "main",
        "status": "Reject",
        "keywords": "Ensemble Learning;Deep Ensemble;Membership Inference",
        "author": "",
        "aff": "Under double-blind review",
        "rating": "5;5;6;6",
        "confidence": "4;4;4;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;2;1;2",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "wzJnpBhRILm",
        "title": "Extreme normalization: approximating full-data batch normalization with single examples",
        "track": "main",
        "status": "Reject",
        "keywords": "batch normalization;optimization",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "4;3;4;2",
        "correctness": "2;3;4;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5222329678670935,
        "corr_rating_correctness": 0.5443310539518174,
        "project": "",
        "github": ""
    },
    {
        "id": "x-YLAN2wJI",
        "title": "ESCo: Towards Provably Effective and Scalable Contrastive Representation Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Contrastive Learning;Unsupervised Representation Learning",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;4;3;2",
        "correctness": "3;3;3;4",
        "technical_novelty": "3;1;1;2",
        "empirical_novelty": "2;1;1;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8703882797784891,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "x3F9PuOUKZc",
        "title": "Subpixel object segmentation using wavelets and multiresolution analysis",
        "track": "main",
        "status": "Reject",
        "keywords": "Segmentation;wavelets;contour prediction;multiresolution analysis",
        "author": "",
        "aff": "",
        "rating": "3;6;6;6",
        "confidence": "4;4;5;3",
        "correctness": "2;2;3;4",
        "technical_novelty": "2;3;3;4",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5222329678670935,
        "project": "",
        "github": ""
    },
    {
        "id": "x4NvCoi2Wnb",
        "title": "MIKE - Multi-task Implicit Knowledge Embeddings by Autoencoding through a Shared Input Space",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Representation Learning;Joint Embedding;Multi-task Learning;Knowledge Transfer;Distillation;Transfer Learning",
        "author": "",
        "aff": "",
        "rating": "1;3;3;5",
        "confidence": "3;4;4;4",
        "correctness": "2;2;2;2",
        "technical_novelty": "2;3;2;2",
        "empirical_novelty": "2;3;1;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.816496580927726,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "x4tkHYGpTdq",
        "title": "DSEE: Dually Sparsity-embedded Efficient Tuning of Pre-trained Language Models",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5;5",
        "confidence": "5;3;4;4;4",
        "correctness": "2;3;3;2;3",
        "technical_novelty": "1;2;2;3;2",
        "empirical_novelty": "1;2;3;2;3",
        "presentation": "",
        "rating_avg": 4.2,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.2,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.16666666666666663,
        "project": "",
        "github": ""
    },
    {
        "id": "x8l2miKNqPb",
        "title": "Generate Triggers in Neural Relation Extraction",
        "track": "main",
        "status": "Desk Reject",
        "keywords": "relation triggers\uff0cevolutive mask\uff0c pointer network",
        "author": "",
        "aff": "",
        "rating": "",
        "confidence": "",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "xCVJMsPv3RT",
        "title": "Dropout Q-Functions for Doubly Efficient Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "Reinforcement learning",
        "author": "",
        "aff": "National Institute of Advanced Industrial Science and Technology; The University of Tokyo; NEC Corporation",
        "rating": "6;6;6",
        "confidence": "4;3;4",
        "correctness": "3;3;4",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "xD3RiCCfsY",
        "title": "On Learning to Solve Cardinality Constrained Combinatorial Optimization in One-Shot: A Re-parameterization Approach via Gumbel-Sinkhorn-TopK",
        "track": "main",
        "status": "Reject",
        "keywords": "Combinatorial Problems;Gumbel Re-parameterization;Optimal Transport;Machine Learning",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "4;4;3;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "3;3;3;2",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "xDIvIqQ3DXD",
        "title": "On the approximation properties of recurrent encoder-decoder architectures",
        "track": "main",
        "status": "Spotlight",
        "keywords": "encoder-decoder;recurrent neural networks;approximation;temporal product",
        "author": "",
        "aff": "School of Mathematical Sciences, Peking University; Department of Mathematics, National University of Singapore",
        "rating": "6;8;8",
        "confidence": "2;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "2;4;3",
        "empirical_novelty": "2;0;3",
        "presentation": "",
        "rating_avg": 7.333333333333333,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9999999999999998,
        "corr_rating_correctness": 0.49999999999999983,
        "project": "",
        "github": ""
    },
    {
        "id": "xENf4QUL4LW",
        "title": "Sample Selection with Uncertainty of Losses for Learning with Noisy Labels",
        "track": "main",
        "status": "Poster",
        "keywords": "Learning with noisy labels;Sample selection;Uncertainty",
        "author": "",
        "aff": "RIKEN AIP and The University of Tokyo; RIKEN AIP; Hong Kong Baptist University; The University of Melbourne; University of Science and Technology of China; TML Lab, The University of Sydney",
        "rating": "5;6;6;8;8",
        "confidence": "5;4;4;3;2",
        "correctness": "3;3;3;4;4",
        "technical_novelty": "3;4;3;3;4",
        "empirical_novelty": "3;3;3;3;4",
        "presentation": "",
        "rating_avg": 6.6,
        "confidence_avg": 3.6,
        "correctness_avg": 3.4,
        "technical_novelty_avg": 3.4,
        "empirical_novelty_avg": 3.2,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9478946531678893,
        "corr_rating_correctness": 0.9525793444156803,
        "project": "",
        "github": ""
    },
    {
        "id": "xEaJvbVKeT",
        "title": "Open-Set Representation Learning through Combinatorial Embedding",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Open-Set;Combinatorial Learning;Retrieval;Novel Class Discovery",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;5;5;3",
        "correctness": "3;4;3;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.17407765595569782,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "xFOyMwWPkz",
        "title": "Quantitative Performance Assessment of CNN Units via Topological Entropy Calculation",
        "track": "main",
        "status": "Poster",
        "keywords": "interpretation of neural network units;computational topology;convolutional neural networks;entropy",
        "author": "",
        "aff": "Department of Electronic Engineering, Tsinghua University",
        "rating": "5;6;6;8",
        "confidence": "3;4;4;4",
        "correctness": "4;3;3;3",
        "technical_novelty": "3;3;2;3",
        "empirical_novelty": "2;3;2;0",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.6622661785325219,
        "corr_rating_correctness": -0.6622661785325219,
        "project": "",
        "github": ""
    },
    {
        "id": "xGZcxaYbJBF",
        "title": "A Multi-Task Learning Algorithm for Non-personalized Recommendations",
        "track": "main",
        "status": "Desk Reject",
        "keywords": "Recommendation and Ranking;Non-personalized Recommendations;Multitask Learning;collaborative filtering;Two-tower DNN",
        "author": "Power Edit 6.0",
        "aff": "Paper under double-blind review",
        "rating": "",
        "confidence": "",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "xIAxm1b4pWc",
        "title": "Improving Sentiment Classification Using 0-Shot Generated Labels for Custom Transformer Embeddings",
        "track": "main",
        "status": "Reject",
        "keywords": "Sentiment Classification;Transformer;Natural Language Processing",
        "author": "",
        "aff": "",
        "rating": "3;3;3",
        "confidence": "5;3;4",
        "correctness": "3;3;1",
        "technical_novelty": "1;1;1",
        "empirical_novelty": "2;2;0",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 1.0,
        "empirical_novelty_avg": 1.3333333333333333,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "xKZ4K0lTj_",
        "title": "Hierarchical Few-Shot Imitation with Skill Transition Models",
        "track": "main",
        "status": "Poster",
        "keywords": "behavioral priors;skill extraction;imitation learning;few-shot learning",
        "author": "",
        "aff": "",
        "rating": "6;6;6;8",
        "confidence": "3;4;5;5",
        "correctness": "3;4;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "3;3;2;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5222329678670935,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "xLfAgCroImw",
        "title": "Energy-Based Learning for Cooperative Games, with Applications to Valuation Problems in Machine Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "Valuation problems;Shapley value;Model interpretation;Data valuation;Enegy-based learning;Attribution-based feature interpretation;Model valuation for ensembles;Feature attributions",
        "author": "",
        "aff": "ETH Z\u00fcrich; Tencent AI Lab",
        "rating": "6;6;8;8",
        "confidence": "4;3;3;4",
        "correctness": "4;4;4;4",
        "technical_novelty": "2;4;4;4",
        "empirical_novelty": "2;2;3;4",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.5,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 3.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "https://valuationgame.github.io",
        "github": ""
    },
    {
        "id": "xMJWUKJnFSw",
        "title": "NodePiece: Compositional and Parameter-Efficient Representations of Large Knowledge Graphs",
        "track": "main",
        "status": "Poster",
        "keywords": "knowledge graphs;graph representation learning;tokenization;link prediction;node classification",
        "author": "",
        "aff": "Mila, McGill University, Montreal, Canada",
        "rating": "5;6;8;8",
        "confidence": "4;4;4;3",
        "correctness": "4;4;3;4",
        "technical_novelty": "2;3;3;4",
        "empirical_novelty": "0;3;3;4",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5555555555555555,
        "corr_rating_correctness": -0.5555555555555555,
        "project": "",
        "github": "https://github.com/migalkin/NodePiece"
    },
    {
        "id": "xNO7OEIcJc6",
        "title": "Language-biased image classification: evaluation based on semantic representations",
        "track": "main",
        "status": "Poster",
        "keywords": "interpretation of learned representations;language and visual processing;language-biased image classification;cognitive science",
        "author": "",
        "aff": "INRIA, France; Microsoft Research Montreal; INRIA, France; ENS Rennes, France; INRIA, France; Universit\u00e9 de Bordeaux, France; INRIA, France",
        "rating": "3;6;6;8",
        "confidence": "4;3;3;4",
        "correctness": "1;3;3;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;2;4",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.14002800840280097,
        "corr_rating_correctness": 0.8892972917998875,
        "project": "",
        "github": ""
    },
    {
        "id": "xNOVfCCvDpM",
        "title": "Post hoc Explanations may be Ineffective for Detecting Unknown Spurious Correlation",
        "track": "main",
        "status": "Poster",
        "keywords": "explanations;feature attributions;spurious correlation;interpretability;training point ranking",
        "author": "",
        "aff": "MIT CSAIL; Stanford; Google Research",
        "rating": "6;6;6",
        "confidence": "3;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/adebayoj/posthocspurious"
    },
    {
        "id": "xO4xryFQltO",
        "title": "A new perspective on probabilistic image modeling",
        "track": "main",
        "status": "Desk Reject",
        "keywords": "deep mixture models;sum-product networks;probabilistic circuits;image modeling",
        "author": "",
        "aff": "Fulda University of Applied Sciences, Fulda, Germany",
        "rating": "",
        "confidence": "",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "Not provided in the text",
        "github": "https://github.com/... (not provided in the text)"
    },
    {
        "id": "xOHuV8s7Yl",
        "title": "Two Instances of Interpretable Neural Network for Universal Approximations",
        "track": "main",
        "status": "Reject",
        "keywords": "Explainable Artificial Intelligence;Neural Network;Universal Approximation;Universal Approximator",
        "author": "",
        "aff": "",
        "rating": "1;3;3;3",
        "confidence": "5;4;3;4",
        "correctness": "2;2;3;2",
        "technical_novelty": "1;2;1;2",
        "empirical_novelty": "1;2;0;2",
        "presentation": "",
        "rating_avg": 2.5,
        "confidence_avg": 4.0,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 1.5,
        "empirical_novelty_avg": 1.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.816496580927726,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "xOeWOPFXrTh",
        "title": "Learning Higher-Order Dynamics in Video-Based Cardiac Measurement",
        "track": "main",
        "status": "Reject",
        "keywords": "Computer Vision;Dynamic Systems;Deep Learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5;6",
        "confidence": "3;5;2;4;4",
        "correctness": "3;4;3;3;3",
        "technical_novelty": "2;2;2;1;3",
        "empirical_novelty": "2;2;2;3;3",
        "presentation": "",
        "rating_avg": 4.4,
        "confidence_avg": 3.6,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.19611613513818404,
        "corr_rating_correctness": -0.5833333333333335,
        "project": "",
        "github": ""
    },
    {
        "id": "xP3cPq2hQC",
        "title": "Cross-Domain Imitation Learning via Optimal Transport",
        "track": "main",
        "status": "Poster",
        "keywords": "optimal transportation;imitation learning;cross-domain imitation learning;gromov-Wasserstein",
        "author": "",
        "aff": "Facebook AI; Berkeley AI Research; University College London",
        "rating": "6;6;6;8",
        "confidence": "3;4;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "4;3;3;4",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.5,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.0,
        "project": "https://arnaudfickinger.github.io/gwil/",
        "github": ""
    },
    {
        "id": "xQUe1pOKPam",
        "title": "Pre-training Molecular Graph Representation with 3D Geometry",
        "track": "main",
        "status": "Poster",
        "keywords": "Pre-training;SSL;Molecule;3D Geometry;2D representation",
        "author": "",
        "aff": "University of Cambridge, MPI for Intelligent Systems, T\u00fcbingen; Mila, Universit\u00e9 de Montr\u00e9al; Mila, Universit\u00e9 de Montr\u00e9al, HEC Montr\u00e9al, CIFAR AI Chair; National Research Council Canada; University of Cambridge",
        "rating": "5;5;6;6",
        "confidence": "4;4;4;3",
        "correctness": "3;3;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;3;3;2",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": "Available"
    },
    {
        "id": "xREjEGUoY4c",
        "title": "Robot Intent Recognition Method Based on State Grid Business Office",
        "track": "main",
        "status": "Desk Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "",
        "confidence": "",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "xRK8xgFuiu",
        "title": "Causal Discovery via Cholesky Factorization",
        "track": "main",
        "status": "Reject",
        "keywords": "DAG Structure Learning;Causal Discovery",
        "author": "",
        "aff": "",
        "rating": "3;3;3;6;6",
        "confidence": "4;5;5;3;2",
        "correctness": "1;3;4;3;4",
        "technical_novelty": "3;2;3;3;2",
        "empirical_novelty": "0;0;3;3;2",
        "presentation": "",
        "rating_avg": 4.2,
        "confidence_avg": 3.8,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 1.6,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9101820546182062,
        "corr_rating_correctness": 0.37267799624996495,
        "project": "",
        "github": ""
    },
    {
        "id": "xS8AMYiEav3",
        "title": "Sound and Complete Neural Network Repair with Minimality and Locality Guarantees",
        "track": "main",
        "status": "Poster",
        "keywords": "Neural Network Repair",
        "author": "",
        "aff": "Division of System Engineering, Boston University; Department of Electrical and Computer Engineering, Boston University",
        "rating": "5;6;8;8",
        "confidence": "4;3;4;5",
        "correctness": "2;4;4;3",
        "technical_novelty": "2;4;3;4",
        "empirical_novelty": "2;3;2;4",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5443310539518174,
        "corr_rating_correctness": 0.5222329678670935,
        "project": "",
        "github": ""
    },
    {
        "id": "xUdEO_yE-GV",
        "title": "Localized Persistent Homologies for more Effective Deep Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Delineation;Persistent Homology;Topology;Aerial Images;Microscopy scans",
        "author": "",
        "aff": "",
        "rating": "3;5;6;8",
        "confidence": "5;4;4;4",
        "correctness": "3;4;3;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 4.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8006407690254357,
        "corr_rating_correctness": 0.5547001962252291,
        "project": "",
        "github": ""
    },
    {
        "id": "xVGrCe5fCXY",
        "title": "Denoising Diffusion Gamma Models",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "3;3;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 1.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "xVlPHwnNKv",
        "title": "Fast Deterministic Stackelberg Actor-Critic",
        "track": "main",
        "status": "Reject",
        "keywords": "Deep Reinforcement Learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;8",
        "confidence": "4;4;3;2",
        "correctness": "3;2;3;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "3;2;2;4",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9945577827230725,
        "corr_rating_correctness": 0.8638684255813602,
        "project": "",
        "github": ""
    },
    {
        "id": "xWRX16GCugt",
        "title": "Sequoia: A Software Framework to Unify Continual Learning Research",
        "track": "main",
        "status": "Reject",
        "keywords": "Continual Learning;Reinforcement Learning;Software Engineering;Deep learning",
        "author": "",
        "aff": "",
        "rating": "1;3;5;5",
        "confidence": "4;5;4;4",
        "correctness": "4;3;3;3",
        "technical_novelty": "1;2;1;1",
        "empirical_novelty": "1;1;2;3",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 1.25,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.17407765595569782,
        "corr_rating_correctness": -0.8703882797784891,
        "project": "",
        "github": "this GitHub URL"
    },
    {
        "id": "xZ6H7wydGl",
        "title": "Robust and Scalable SDE Learning: A Functional Perspective",
        "track": "main",
        "status": "Poster",
        "keywords": "SDE Learning;Parallelization;Importance Sampling",
        "author": "",
        "aff": "InstaDeep Ltd., South Africa; Oxford University, United Kingdom; Oxford University, InstaDeep Ltd., United Kingdom; Discovery Insure, South Africa",
        "rating": "5;5;6",
        "confidence": "2;3;2",
        "correctness": "2;3;3",
        "technical_novelty": "3;3;3",
        "empirical_novelty": "2;1;2",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4999999999999999,
        "corr_rating_correctness": 0.4999999999999999,
        "project": "",
        "github": ""
    },
    {
        "id": "x_PopzVOmYj",
        "title": "Tr-NAS: Memory-Efficient Neural Architecture Search with Transferred Blocks",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Neural Architecture Search;Memory-Efficient NAS",
        "author": "",
        "aff": "",
        "rating": "3;3;5",
        "confidence": "4;5;5",
        "correctness": "3;2;3",
        "technical_novelty": "2;1;2",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 1.6666666666666667,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.4999999999999999,
        "corr_rating_correctness": 0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "xa6otUDdP2W",
        "title": "Effective Model Sparsification by Scheduled Grow-and-Prune Methods",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "Princeton University; Northeastern University; Dalian University of Technology; DAMO Academy, Alibaba Group",
        "rating": "6;6;6;8",
        "confidence": "4;3;4;5",
        "correctness": "4;3;4;4",
        "technical_novelty": "3;3;2;3",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.816496580927726,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": "https://github.com/boone891214/GaP"
    },
    {
        "id": "xaTensJtCP5",
        "title": "Semi-Empirical Objective Functions for Neural MCMC Proposal Optimization",
        "track": "main",
        "status": "Reject",
        "keywords": "Markov Chain Monte Carlo;Neural MCMC;Generative Models;Deep Generative Models;Normalizing Flows",
        "author": "",
        "aff": "",
        "rating": "3;5;5;8",
        "confidence": "4;3;4;3",
        "correctness": "3;4;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7001400420140049,
        "corr_rating_correctness": 0.7276068751089989,
        "project": "",
        "github": ""
    },
    {
        "id": "xbu1tzbjvd",
        "title": "Analyzing Populations of Neural Networks via Dynamical Model Embedding",
        "track": "main",
        "status": "Reject",
        "keywords": "dynamics;RNNs;model averaging;model clustering;CNNs;semi-supervised learning",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "4;4;4;4",
        "correctness": "3;3;2;3",
        "technical_novelty": "3;2;4;2",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "xbx7Hxjbd79",
        "title": "COLA: Consistent Learning with Opponent-Learning Awareness",
        "track": "main",
        "status": "Reject",
        "keywords": "Differentiable games;multi-agent reinforcement learning;general-sum games;lola",
        "author": "",
        "aff": "",
        "rating": "3;3;6;8",
        "confidence": "2;3;3;3",
        "correctness": "1;2;3;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.75,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5443310539518174,
        "corr_rating_correctness": 0.9486832980505139,
        "project": "",
        "github": ""
    },
    {
        "id": "xdNcdoHdBER",
        "title": "Sneakoscope: Revisiting Unsupervised Out-of-Distribution Detection",
        "track": "main",
        "status": "Withdraw",
        "keywords": "OOD Detection;Unsupervised Approaches;Model Confidence Calibration;Hidden Representation Analysis",
        "author": "",
        "aff": "",
        "rating": "1;3;3;3",
        "confidence": "4;5;5;4",
        "correctness": "3;2;4;2",
        "technical_novelty": "1;1;1;1",
        "empirical_novelty": "1;2;2;2",
        "presentation": "",
        "rating_avg": 2.5,
        "confidence_avg": 4.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 1.0,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": -0.17407765595569782,
        "project": "",
        "github": ""
    },
    {
        "id": "xf0B7-7MRo6",
        "title": "AIR-Net: Adaptive and Implicit Regularization Neural Network for matrix completion",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5",
        "confidence": "4;4;3;3",
        "correctness": "3;4;3;4",
        "technical_novelty": "3;3;2;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 4.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "xiXOrugVHs",
        "title": "Long Document Summarization with Top-Down and Bottom-Up Representation Inference",
        "track": "main",
        "status": "Reject",
        "keywords": "top-down inference;bottom-up inference;long document summarization",
        "author": "",
        "aff": "",
        "rating": "5;5;6",
        "confidence": "3;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "3;2;3",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4999999999999999,
        "corr_rating_correctness": 0.9999999999999997,
        "project": "",
        "github": ""
    },
    {
        "id": "xkjqJYqRJy",
        "title": "Bayesian Neural Network Priors Revisited",
        "track": "main",
        "status": "Poster",
        "keywords": "Bayesian deep learning;Bayesian neural networks;Priors",
        "author": "",
        "aff": "Google AI Berlin, Germany; University of Bristol, United Kingdom; Imperial College London, United Kingdom; University of Cambridge, United Kingdom; ETH Z\u00fcrich, Switzerland",
        "rating": "3;5;6;8",
        "confidence": "4;4;5;4",
        "correctness": "1;3;2;4",
        "technical_novelty": "2;3;2;1",
        "empirical_novelty": "2;3;4;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 4.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.16012815380508713,
        "corr_rating_correctness": 0.8682431421244592,
        "project": "",
        "github": ""
    },
    {
        "id": "xm6YD62D1Ub",
        "title": "VICReg: Variance-Invariance-Covariance Regularization for Self-Supervised Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "self-supervised learning;representation learning;computer vision",
        "author": "",
        "aff": "Facebook AI Research; Inria, \u00c9cole normale sup\u00e9rieure, CNRS, PSL Research University; Courant Institute, New York University; Center for Data Science, New York University",
        "rating": "3;6;6;6",
        "confidence": "4;4;4;3",
        "correctness": "3;4;3;3",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "2;3;3;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "xmrtP-ADzk",
        "title": "Self-Supervised Learning for Binary Networks by Joint Classifier Training",
        "track": "main",
        "status": "Withdraw",
        "keywords": "binary networks;unsupervised representation learning",
        "author": "",
        "aff": "",
        "rating": "",
        "confidence": "",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "xnYACQquaGV",
        "title": "Neural Contextual Bandits with Deep Representation and Shallow Exploration",
        "track": "main",
        "status": "Poster",
        "keywords": "neural network;deep representation learning",
        "author": "",
        "aff": "University of California, Los Angeles; California Institute of Technology; DeepMind; Adobe Research",
        "rating": "3;6;8;8",
        "confidence": "4;4;4;3",
        "correctness": "4;4;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;2;3;2",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.75,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.49374193110101877,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "xo_5lb5ond",
        "title": "LEAN: graph-based pruning for convolutional neural networks by extracting longest chains",
        "track": "main",
        "status": "Reject",
        "keywords": "Pruning;Sparsity;Compression;Graph pruning",
        "author": "",
        "aff": "",
        "rating": "3;5;5;5;5",
        "confidence": "4;3;4;3;3",
        "correctness": "3;3;3;3;3",
        "technical_novelty": "2;3;2;3;3",
        "empirical_novelty": "2;2;2;3;3",
        "presentation": "",
        "rating_avg": 4.6,
        "confidence_avg": 3.4,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6,
        "empirical_novelty_avg": 2.4,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6123724356957948,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "xp2D-1PtLc5",
        "title": "ClsVC: Learning Speech Representations with two different classification tasks.",
        "track": "main",
        "status": "Reject",
        "keywords": "voice conversion;gradient reversal;adversarial learning;speech synthesis",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;4;4;3",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "xqt9fZmCTsP",
        "title": "Mining Multi-Label Samples from Single Positive Labels",
        "track": "main",
        "status": "Withdraw",
        "keywords": "GANs;MCMC;sampling;conditional generation;single positive label;multi-label",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "3;3;4;3",
        "correctness": "4;3;4;3",
        "technical_novelty": "4;2;3;3",
        "empirical_novelty": "2;2;0;2",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "xs-tJn58XKv",
        "title": "Learning Stable Classifiers by Transferring Unstable Features",
        "track": "main",
        "status": "Reject",
        "keywords": "transfer learning;spurious correlation;invariant learning",
        "author": "",
        "aff": "",
        "rating": "3;3;6;6;6",
        "confidence": "4;4;5;4;4",
        "correctness": "4;4;4;3;3",
        "technical_novelty": "2;2;2;2;2",
        "empirical_novelty": "2;2;3;3;3",
        "presentation": "",
        "rating_avg": 4.8,
        "confidence_avg": 4.2,
        "correctness_avg": 3.6,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.6,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.4082482904638631,
        "corr_rating_correctness": -0.6666666666666666,
        "project": "",
        "github": ""
    },
    {
        "id": "xspalMXAB0M",
        "title": "A Boosting Approach to Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6;6",
        "confidence": "4;3;3;3;4",
        "correctness": "3;3;3;4;4",
        "technical_novelty": "2;3;3;3;4",
        "empirical_novelty": "1;1;3;0;0",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.4,
        "correctness_avg": 3.4,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 1.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.372677996249965,
        "corr_rating_correctness": 0.74535599249993,
        "project": "",
        "github": ""
    },
    {
        "id": "xtZXWpXVbiK",
        "title": "Flow-based Recurrent Belief State Learning for POMDPs",
        "track": "main",
        "status": "Reject",
        "keywords": "Partially Observable Markov Decision Process;POMDP;Model-based Reinforcement Learning;Visual Control Task",
        "author": "",
        "aff": "",
        "rating": "6;6;8;8",
        "confidence": "4;4;2;4",
        "correctness": "4;3;3;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "xw04RdwI2kS",
        "title": "Inverse Contextual Bandits: Learning How Behavior Evolves over Time",
        "track": "main",
        "status": "Reject",
        "keywords": "inverse contextual bandits;understanding decision-making",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "4;4;2;3",
        "correctness": "4;3;4;3",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9045340337332909,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "xwAw8QZkpWZ",
        "title": "SAFER: Data-Efficient and Safe Reinforcement Learning Through Skill Acquisition",
        "track": "main",
        "status": "Reject",
        "keywords": "safety;reinforcement learning;behavioral priors;skill primitives",
        "author": "",
        "aff": "",
        "rating": "3;5;6;8",
        "confidence": "4;4;3;4",
        "correctness": "2;4;3;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "3;3;2;4",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.16012815380508713,
        "corr_rating_correctness": 0.39223227027636803,
        "project": "",
        "github": ""
    },
    {
        "id": "xxU6qGx-2ew",
        "title": "Gaussian Differential Privacy Transformation: from identification to application",
        "track": "main",
        "status": "Reject",
        "keywords": "differential privacy;gaussian differential privacy;privacy profile",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "5;3;4;3",
        "correctness": "4;4;3;4",
        "technical_novelty": "1;2;2;4",
        "empirical_novelty": "0;2;0;0",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 0.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.899228803025897,
        "corr_rating_correctness": -0.13245323570650439,
        "project": "",
        "github": ""
    },
    {
        "id": "xxyTjJFzy3C",
        "title": "Contrastive Learning of 3D Shape Descriptor with Dynamic Adversarial Views",
        "track": "main",
        "status": "Reject",
        "keywords": "Dynamic multi-views",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "4;4;3;4",
        "correctness": "2;3;3;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4714045207910316,
        "corr_rating_correctness": 0.8660254037844386,
        "project": "",
        "github": ""
    },
    {
        "id": "xy_2w3J3kH",
        "title": "Communication-Efficient Actor-Critic Methods for Homogeneous Markov Games",
        "track": "main",
        "status": "Poster",
        "keywords": "multi-agent reinforcement learning;multi-agent communication",
        "author": "",
        "aff": "Artificial Intelligence Institute, University of South Carolina",
        "rating": "6;6;6;6",
        "confidence": "3;4;5;3",
        "correctness": "2;3;3;4",
        "technical_novelty": "3;3;2;3",
        "empirical_novelty": "3;2;3;2",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "xzeGP-PtPMI",
        "title": "Sequential Communication in Multi-Agent Reinforcement Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "multi-agent communication;multi-agent reinforcement learning",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "4;4;3;4",
        "correctness": "2;2;2;2",
        "technical_novelty": "1;3;3;2",
        "empirical_novelty": "2;0;2;0",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "y-yL78_sZcr",
        "title": "Gradient Imbalance and solution in Online Continual learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Online continual learning;Lifelong learning;Gradient imbalance",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5",
        "confidence": "3;4;4;4",
        "correctness": "3;1;2;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;2;3;0",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "y0VvIg25yk",
        "title": "On the Learning and Learnability of Quasimetrics",
        "track": "main",
        "status": "Poster",
        "keywords": "embedding learning;quasimetric learning;deep learning",
        "author": "",
        "aff": "MIT CSAIL",
        "rating": "5;6;8;8",
        "confidence": "3;3;2;3",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;3;3;2",
        "empirical_novelty": "3;3;3;2",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 2.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5555555555555555,
        "corr_rating_correctness": 0.5555555555555555,
        "project": "ssnl.github.io/quasimetric",
        "github": "github.com/SsnL/poisson_quasimetric_embedding"
    },
    {
        "id": "y1PXylgrXZ",
        "title": "Certified Robustness for Deep Equilibrium Models via Interval Bound Propagation",
        "track": "main",
        "status": "Poster",
        "keywords": "deep equilibrium models;certified robustness;interval bound propagation",
        "author": "",
        "aff": "Stanford University; CMU and Bosch Center for AI",
        "rating": "3;5;6;8",
        "confidence": "5;3;3;3",
        "correctness": "2;4;3;3",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8006407690254357,
        "corr_rating_correctness": 0.39223227027636803,
        "project": "",
        "github": "https://github.com/cwein3/ibp-mondeq-code"
    },
    {
        "id": "y1faDxZ_-0a",
        "title": "SSFL: Tackling Label Deficiency in Federated Learning via Personalized Self-Supervision",
        "track": "main",
        "status": "Reject",
        "keywords": "federated learning",
        "author": "",
        "aff": "",
        "rating": "1;3;3;5",
        "confidence": "5;3;4;3",
        "correctness": "1;3;3;3",
        "technical_novelty": "1;3;2;2",
        "empirical_novelty": "0;2;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8528028654224418,
        "corr_rating_correctness": 0.816496580927726,
        "project": "",
        "github": ""
    },
    {
        "id": "y3niPR1CJf6",
        "title": "Wasserstein Weisfeiler-Lehman Subtree Distance for Graph-Structured Data",
        "track": "main",
        "status": "Withdraw",
        "keywords": "graph distance;graph machine learning;optimal tarnsport",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "4;4;4;4",
        "correctness": "2;3;2;3",
        "technical_novelty": "2;3;2;2",
        "empirical_novelty": "2;1;2;1",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "y7tKDxxTo8T",
        "title": "Zero-Shot Recommender Systems",
        "track": "main",
        "status": "Reject",
        "keywords": "Zero Shot Learning;Recommender Systems;Neural Networks;Bayesian",
        "author": "",
        "aff": "",
        "rating": "3;5;6",
        "confidence": "4;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "1;2;3",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9449111825230683,
        "project": "",
        "github": ""
    },
    {
        "id": "y8zhHLm7FsP",
        "title": "Ensemble Kalman Filter (EnKF) for Reinforcement Learning (RL)",
        "track": "main",
        "status": "Reject",
        "keywords": "decision and control;control theory;reinforcement learning",
        "author": "",
        "aff": "",
        "rating": "3;3;3",
        "confidence": "5;4;5",
        "correctness": "4;3;3",
        "technical_novelty": "1;2;2",
        "empirical_novelty": "1;1;0",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 1.6666666666666667,
        "empirical_novelty_avg": 0.6666666666666666,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "yBYVUDj7yF",
        "title": "The Power of Contrast for Feature Learning: A Theoretical Analysis",
        "track": "main",
        "status": "Reject",
        "keywords": "contrastive learning;self-supervised learning;transfer learning",
        "author": "",
        "aff": "",
        "rating": "5;6;6",
        "confidence": "4;4;3",
        "correctness": "3;4;2",
        "technical_novelty": "3;4;3",
        "empirical_novelty": "3;2;2",
        "presentation": "",
        "rating_avg": 5.666666666666667,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.3333333333333335,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4999999999999999,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "yCS5dckx_vj",
        "title": "Towards Demystifying Representation Learning with Non-contrastive Self-supervision",
        "track": "main",
        "status": "Reject",
        "keywords": "self-supervised learning;representation learning;non-contrastive methods;DirectPred;theoretical analysis",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "4;3;3;3",
        "correctness": "4;4;4;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.25,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9428090415820632,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "yGNzJk_tYr4",
        "title": "Causally Estimating the Sensitivity of Neural NLP Models to Spurious Features",
        "track": "main",
        "status": "Withdraw",
        "keywords": "spurious feature;causality;robustness;data augmentation",
        "author": "",
        "aff": "",
        "rating": "1;3;3;6",
        "confidence": "4;4;4;5",
        "correctness": "3;2;3;4",
        "technical_novelty": "1;2;2;2",
        "empirical_novelty": "1;2;2;3",
        "presentation": "",
        "rating_avg": 3.25,
        "confidence_avg": 4.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8892972917998875,
        "corr_rating_correctness": 0.5940885257860046,
        "project": "",
        "github": ""
    },
    {
        "id": "yJF-89OH94U",
        "title": "DICE: A Simple Sparsification Method for Out-of-distribution Detection",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;6",
        "confidence": "4;3;4",
        "correctness": "3;4;3",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.18898223650461363,
        "corr_rating_correctness": 0.18898223650461363,
        "project": "",
        "github": ""
    },
    {
        "id": "yKIAXjkJc2F",
        "title": "Imbedding Deep Neural Networks",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Neural ODEs;Optimal Control;Deep Neural Networks;Invariant Imbedding",
        "author": "",
        "aff": "University of Exeter; Etcembly Ltd.",
        "rating": "6;8;8;8",
        "confidence": "4;5;3;3",
        "correctness": "3;4;4;3",
        "technical_novelty": "3;4;3;3",
        "empirical_novelty": "3;0;3;3",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 3.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.17407765595569782,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": "github.com/andrw3000/inimnet"
    },
    {
        "id": "yK_jcv_aLX",
        "title": "Action-Sufficient State Representation Learning for Control with Structural Constraints",
        "track": "main",
        "status": "Reject",
        "keywords": "Representation learning in RL;Minimal sufficient state representations;Graphical model;World model",
        "author": "",
        "aff": "",
        "rating": "5;5;5;8",
        "confidence": "3;2;5;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "3;3;2;4",
        "empirical_novelty": "3;2;2;4",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.2581988897471611,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "yOBqNg-CqB0",
        "title": "Re-evaluating Word Mover's Distance",
        "track": "main",
        "status": "Reject",
        "keywords": "optimal transport;word mover's distance",
        "author": "",
        "aff": "",
        "rating": "3;3;8;8",
        "confidence": "4;4;4;4",
        "correctness": "4;2;3;3",
        "technical_novelty": "1;1;4;3",
        "empirical_novelty": "3;1;3;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "yQ7Nm-56FWU",
        "title": "Adversarial Training with Rectified Rejection",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Adversarial Training;Rectified Rejection;Coupling Strategy",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "5;4;4;2",
        "correctness": "2;2;3;3",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "3;0;3;2",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.75,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8388704928078611,
        "corr_rating_correctness": 0.9622504486493761,
        "project": "",
        "github": ""
    },
    {
        "id": "yRYtnKAZqxU",
        "title": "Interrogating Paradigms in Self-supervised Graph Representation Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Graph Neural Networks;Contrastive Learning;Self-supervised Learning",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5",
        "confidence": "4;4;4;4",
        "correctness": "2;1;2;4",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "ySQH0oDyp7",
        "title": "QDrop: Randomly Dropping Quantization for Extremely Low-bit Post-Training Quantization",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "SenseTime Research; State Key Lab of Software Development Environment, Beihang University",
        "rating": "6;8;8;8",
        "confidence": "3;4;5;4",
        "correctness": "3;2;4;4",
        "technical_novelty": "2;3;4;3",
        "empirical_novelty": "2;3;4;3",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.816496580927726,
        "corr_rating_correctness": 0.17407765595569782,
        "project": "https://github.com/ModelTC/MQBench",
        "github": "https://github.com/wimh966/QDrop"
    },
    {
        "id": "yV4_fWe4nM",
        "title": "Deep Fair Discriminative Clustering",
        "track": "main",
        "status": "Reject",
        "keywords": "Clustering;Deep learning;Fairness",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "3;4;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;3;2;2",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.9271726499455306,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "yWpo7kKaDM",
        "title": "Multimodal Dialogue State Tracking",
        "track": "main",
        "status": "Withdraw",
        "keywords": "dialogue state tracking;multimodal;video-grounded dialogue;video-dialogue transformer network;synthetic benchmark",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "3;4;3;3",
        "correctness": "4;3;2;3",
        "technical_novelty": "2;3;4;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.13245323570650439,
        "corr_rating_correctness": -0.6488856845230502,
        "project": "",
        "github": ""
    },
    {
        "id": "yXBb-0cPSKO",
        "title": "Regularized-OFU: an efficient algorithm for general contextual bandit with optimization oracles",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "yiczho",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;4;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;1;2;3",
        "empirical_novelty": "3;2;3;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "y_op4lLLaWL",
        "title": "Variational autoencoders in the presence of low-dimensional data: landscape and implicit bias",
        "track": "main",
        "status": "Poster",
        "keywords": "variational autoencoders;encoder;optima;stability;low-dimensional manifold",
        "author": "",
        "aff": "Robotics Institute, Carnegie Mellon University; Department of Computer Science, Stanford University; Machine Learning Department, Carnegie Mellon University",
        "rating": "5;5;6;8",
        "confidence": "4;3;3;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;4;3",
        "empirical_novelty": "3;2;2;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.40824829046386296,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "y_tIL5vki1l",
        "title": "LatentKeypointGAN: Controlling GANs via Latent Keypoints",
        "track": "main",
        "status": "Reject",
        "keywords": "Part Disentanglement;Unsupervised Learning",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "4;4;4;4",
        "correctness": "4;3;2;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "1;2;2;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.7071067811865475,
        "project": "",
        "github": ""
    },
    {
        "id": "ybsh6zEzIKA",
        "title": "Intrusion-Free Graph Mixup",
        "track": "main",
        "status": "Reject",
        "keywords": "graph augmentation;Mixup;graph classification;graph neural networks",
        "author": "",
        "aff": "",
        "rating": "3;5;5;8",
        "confidence": "5;4;4;4",
        "correctness": "2;3;2;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7276068751089989,
        "corr_rating_correctness": 0.8866206949335731,
        "project": "",
        "github": ""
    },
    {
        "id": "ydopy-e6Dg",
        "title": "Image BERT Pre-training with Online Tokenizer",
        "track": "main",
        "status": "Poster",
        "keywords": "online tokenizer;masked image modeling;vision transformer",
        "author": "",
        "aff": "UC Santa Cruz; Shanghai Jiao Tong University; Johns Hopkins University; ByteDance",
        "rating": "6;6;8",
        "confidence": "4;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 6.666666666666667,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.9999999999999998,
        "project": "",
        "github": "https://github.com/bytedance/ibot"
    },
    {
        "id": "yeP_zx9vqNm",
        "title": "Finding Biological Plausibility for Adversarially Robust Features via Metameric Tasks",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Peripheral Computation;Adversarial Robustness;Perceptual Invariance;Metamerism;Texture;Psychophysics",
        "author": "",
        "aff": "Center for Brains, Minds and Machines, Massachusetts Institute of Technology",
        "rating": "8;8;8;8",
        "confidence": "4;4;3;4",
        "correctness": "3;3;3;2",
        "technical_novelty": "3;3;3;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/anneharrington/Adversarially-Robust-Periphery"
    },
    {
        "id": "yfe1VMYAXa4",
        "title": "OntoProtein: Protein Pretraining With Gene Ontology Embedding",
        "track": "main",
        "status": "Poster",
        "keywords": "pre-trained language model;knowledge graph;protein representation",
        "author": "",
        "aff": "College of Computer Science and Technology, Zhejiang University; School of Software Technology, Zhejiang University; Hangzhou Innovation Center, Zhejiang University; Alibaba-Zhejiang University Joint Research Institute of Frontier Technologies",
        "rating": "6;6;6",
        "confidence": "3;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "4;2;3",
        "empirical_novelty": "3;2;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/zjunlp/OntoProtein"
    },
    {
        "id": "ygGMP1zkiD1",
        "title": "Debiasing Pretrained Text Encoders by Paying Attention to Paying Attention",
        "track": "main",
        "status": "Reject",
        "keywords": "Fairness;Pretrained Text Encoders;Self-Attention;Knowledge Distillation;Social Biases;Debiasing",
        "author": "",
        "aff": "",
        "rating": "3;6;6",
        "confidence": "3;4;4",
        "correctness": "2;3;3",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 1.0,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "yhCp5RcZD7",
        "title": "Geometry-Consistent Neural Shape Representation with Implicit Displacement Fields",
        "track": "main",
        "status": "Poster",
        "keywords": "implicit functions;shape reconstruction;shape representation;object reconstruction",
        "author": "",
        "aff": "ETH Zurich",
        "rating": "5;6;6;10",
        "confidence": "4;3;4;4",
        "correctness": "4;4;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "3;3;3;4",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 3.75,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.22549380840084865,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": "https://github.com/yifita/idf"
    },
    {
        "id": "yhjfOvBvvmz",
        "title": "Weakly-Supervised Learning of Disentangled and Interpretable Skills for Hierarchical Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Reinforcement learning;Variational autoencoder;Disentangled representation learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "3;4;3;4",
        "correctness": "3;2;3;3",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "yjMQuLLcGWK",
        "title": "FP-DETR: Detection Transformer Advanced by Fully Pre-training",
        "track": "main",
        "status": "Poster",
        "keywords": "Object Detection;Detection Transformer;Pre-training;Visual Prompt",
        "author": "",
        "aff": "University of Science and Technology of China; JD Explore Academy, China; The University of Sydney; Institute of Arti\ufb01cial Intelligence, Hefei Comprehensive National Science Center",
        "rating": "5;6;6;6",
        "confidence": "4;4;4;5",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "3;3;3;2",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": "https://github.com/encounter1997/FP-DETR"
    },
    {
        "id": "yjsA8Uin-Y",
        "title": "A Good Representation Detects Noisy Labels",
        "track": "main",
        "status": "Reject",
        "keywords": "noisy labels;sample selection;training-free;representation;noise dection",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "3;4;4;4",
        "correctness": "3;2;3;3",
        "technical_novelty": "3;2;3;2",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "yjxVspo7gXt",
        "title": "Scaling Fair Learning to Hundreds of Intersectional Groups",
        "track": "main",
        "status": "Reject",
        "keywords": "machine fairness;intersectional fairness;bias mitigation;fair learning;knowledge distillation",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "3;4;3;3",
        "correctness": "3;2;4;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;3;4",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": 0.7071067811865475,
        "project": "",
        "github": ""
    },
    {
        "id": "youe3QQepVB",
        "title": "Generative Modeling for Multitask Visual Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;6",
        "confidence": "4;3;4",
        "correctness": "3;3;4",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.4999999999999999,
        "corr_rating_correctness": 0.9999999999999997,
        "project": "",
        "github": ""
    },
    {
        "id": "yphXO883gqN",
        "title": "The Deep Generative Decoder: using MAP estimates of representations",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;3;6",
        "confidence": "5;4;4;4",
        "correctness": "3;4;3;1",
        "technical_novelty": "1;1;1;3",
        "empirical_novelty": "1;2;2;3",
        "presentation": "",
        "rating_avg": 3.75,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 1.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": -0.9271726499455307,
        "project": "",
        "github": ""
    },
    {
        "id": "yql6px0bcT",
        "title": "Decentralized Cross-Entropy Method for Model-Based Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Reinforcement Learning;Cross-Entropy Method;Planning;Model-Based RL",
        "author": "",
        "aff": "",
        "rating": "3;6;6",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "1;2;3",
        "empirical_novelty": "1;3;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "yrD7B9N_54F",
        "title": "Few-shot graph link prediction with domain adaptation",
        "track": "main",
        "status": "Reject",
        "keywords": "link prediction;few-shot learning;domain adaptation",
        "author": "",
        "aff": "",
        "rating": "3;5;5;8",
        "confidence": "5;4;3;5",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;2;2;4",
        "empirical_novelty": "2;2;2;4",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.1266600992762247,
        "corr_rating_correctness": 0.8892972917998875,
        "project": "",
        "github": ""
    },
    {
        "id": "yrbF6ekqQ9w",
        "title": "Robust fine-tuning of zero-shot models",
        "track": "main",
        "status": "Withdraw",
        "keywords": "robustness;zero-shot;fine-tuning;CLIP;distribution shift",
        "author": "",
        "aff": "",
        "rating": "3;5;6",
        "confidence": "5;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "1;3;4",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9819805060619659,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "ys-bh0Eer_",
        "title": "Block Contextual MDPs for Continual Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Reinforcement Learning;MDP;Block Contextual MDP;Continual Learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;4;4",
        "correctness": "3;3;1;3",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "3;2;1;3",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "yulAchHedcT",
        "title": "Faster Neural Net Inference via Forests of Sparse Oblique Decision Trees",
        "track": "main",
        "status": "Withdraw",
        "keywords": "neural network compression;tree-based compression;decision trees;decision forests",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "3;4;3;5",
        "correctness": "3;4;4;4",
        "technical_novelty": "2;2;3;2",
        "empirical_novelty": "3;3;3;2",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.7608859102526822,
        "corr_rating_correctness": 0.9271726499455306,
        "project": "",
        "github": ""
    },
    {
        "id": "yuv0mwPOlz3",
        "title": "Active Learning over Multiple Domains in Natural Language Tasks",
        "track": "main",
        "status": "Reject",
        "keywords": "natural language processing;active learning;domain shift detection",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "2;2;3;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "1;2;3;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 2.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.7608859102526822,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "ywEx0OiJflS",
        "title": "Multi-Class Classification from Single-Class Data with Confidences",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Weakly supervised learning;unbiased risk estimator;empirical risk minimization",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;5;5;2",
        "correctness": "2;4;4;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "1;1;1;4",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3746343246326776,
        "corr_rating_correctness": 0.9271726499455306,
        "project": "",
        "github": ""
    },
    {
        "id": "yx_uIzoHJv",
        "title": "Effect of Pressure for Compositionality on Language Emergence",
        "track": "main",
        "status": "Reject",
        "keywords": "Language Emergence;Neural Language Emergence;Compositionality",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "2;4;4;4",
        "correctness": "3;2;4;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;0;2;2",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "yzDTTtlIlMr",
        "title": "Momentum Doesn't Change The Implicit Bias",
        "track": "main",
        "status": "Reject",
        "keywords": "Momentum-based Optimizers;Convergence Analysis;Implicit Bias",
        "author": "",
        "aff": "",
        "rating": "5;5;6;8",
        "confidence": "4;4;3;4",
        "correctness": "4;4;4;4",
        "technical_novelty": "3;2;3;4",
        "empirical_novelty": "1;0;0;0",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.75,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 0.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "yztpblfGkZ-",
        "title": "Graph Convolutional Networks via Adaptive Filter Banks",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5;6",
        "confidence": "5;4;3;3;4",
        "correctness": "3;1;3;2;4",
        "technical_novelty": "2;1;2;2;3",
        "empirical_novelty": "3;2;3;3;2",
        "presentation": "",
        "rating_avg": 4.4,
        "confidence_avg": 3.8,
        "correctness_avg": 2.6,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.6,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5790660241435861,
        "corr_rating_correctness": 0.6210344279375827,
        "project": "",
        "github": ""
    },
    {
        "id": "z-5BjnU3-OQ",
        "title": "HyperCGAN: Text-to-Image Synthesis with HyperNet-Modulated Conditional Generative Adversarial Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "gan;generative modelling;text-to-image;text2image;hypernetworks",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "4;4;4;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "3;2;2;3",
        "empirical_novelty": "3;2;2;2",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "z1-I6rOKv1S",
        "title": "Autoregressive Quantile Flows for Predictive Uncertainty Estimation",
        "track": "main",
        "status": "Spotlight",
        "keywords": "",
        "author": "",
        "aff": "Department of Computer Science, Cornell Tech and Cornell University",
        "rating": "6;8;8",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "2;4;4",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 7.333333333333333,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.3333333333333335,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "z2B0JJeNdvT",
        "title": "Distributed Zeroth-Order Optimization: Convergence Rates That Match Centralized Counterpart",
        "track": "main",
        "status": "Reject",
        "keywords": "Zeroth-order optimization;distributed optimization",
        "author": "",
        "aff": "",
        "rating": "3;5;6",
        "confidence": "4;4;5",
        "correctness": "3;3;3",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.7559289460184544,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "z2zmSDKONK",
        "title": "Exploring the Robustness of Distributional Reinforcement Learning against Noisy State Observations",
        "track": "main",
        "status": "Reject",
        "keywords": "distributional reinforcement learning;robustness",
        "author": "",
        "aff": "",
        "rating": "3;5;6",
        "confidence": "5;2;4",
        "correctness": "2;4;3",
        "technical_novelty": "2;4;3",
        "empirical_novelty": "1;2;3",
        "presentation": "",
        "rating_avg": 4.666666666666667,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.49999999999999994,
        "corr_rating_correctness": 0.6546536707079772,
        "project": "",
        "github": ""
    },
    {
        "id": "z3Tf4kdOE5D",
        "title": "FedDiscrete: A Secure Federated Learning Algorithm Against Weight Poisoning",
        "track": "main",
        "status": "Reject",
        "keywords": "federated learning;weight poisoning defense",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;5;3;4",
        "correctness": "2;3;3;2",
        "technical_novelty": "1;2;3;2",
        "empirical_novelty": "1;2;3;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7071067811865475,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "z7DAilcTx7",
        "title": "A Distributional Robustness Perspective on Adversarial Training with the $\\infty$-Wasserstein Distance",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "5;5;5",
        "confidence": "4;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "1;3;2",
        "empirical_novelty": "1;1;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.3333333333333333,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "z7p2V6KROOV",
        "title": "Extending the WILDS Benchmark for Unsupervised Adaptation",
        "track": "main",
        "status": "Oral",
        "keywords": "distribution shifts;adaptation;unlabeled data",
        "author": "",
        "aff": "University of Tokyo; Caltech; University of California, Berkeley; INRAE; Boston University; Stanford University; University of Saskatchewan",
        "rating": "6;8;8;8",
        "confidence": "4;3;4;4",
        "correctness": "4;4;3;4",
        "technical_novelty": "2;2;3;1",
        "empirical_novelty": "3;3;3;4",
        "presentation": "",
        "rating_avg": 7.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": "https://wilds.stanford.edu"
    },
    {
        "id": "z8Bz7m6T-xJ",
        "title": "Overcoming Label Ambiguity with Multi-label Iterated Learning",
        "track": "main",
        "status": "Withdraw",
        "keywords": "supervised learning;multi-label learning;label ambiguity;label noise",
        "author": "",
        "aff": "",
        "rating": "5;5;5;5",
        "confidence": "4;4;4;5",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "z8j0bPU4DIw",
        "title": "Evolution Strategies as an Alternate Learning method for Hierarchical Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Hierarchical reinforcement learning;evolution strategies;reinforcement learning",
        "author": "",
        "aff": "",
        "rating": "3;3;5;5",
        "confidence": "4;4;4;4",
        "correctness": "3;2;3;3",
        "technical_novelty": "1;2;3;2",
        "empirical_novelty": "2;2;2;0",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "z8xVlqWwRrK",
        "title": "EVaDE : Event-Based Variational Thompson Sampling for Model-Based Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "Model-based Reinforcement Learning;Thompson sampling;Exploration",
        "author": "",
        "aff": "",
        "rating": "5;5;6;8",
        "confidence": "3;3;3;3",
        "correctness": "4;3;3;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;0;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.40824829046386296,
        "project": "",
        "github": ""
    },
    {
        "id": "zAyZFRptzvh",
        "title": "Auditing AI models for Verified Deployment under Semantic Specifications",
        "track": "main",
        "status": "Reject",
        "keywords": "auditing deep learning;verification;interpretability",
        "author": "",
        "aff": "Paper under double-blind review",
        "rating": "5;6;6;8",
        "confidence": "2;5;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;3;3;4",
        "empirical_novelty": "2;4;3;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.4736842105263159,
        "corr_rating_correctness": 0.0,
        "project": "https://sites.google.com/view/audit-ai",
        "github": ""
    },
    {
        "id": "zBOI9LFpESK",
        "title": "Learning Generalizable Representations for Reinforcement Learning via Adaptive Meta-learner of Behavioral Similarities",
        "track": "main",
        "status": "Poster",
        "keywords": "deep reinforcement learning;deep learning;representation learning",
        "author": "",
        "aff": "Nanyang Technological University, Singapore",
        "rating": "5;6;6;6",
        "confidence": "3;3;5;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "3;3;2;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5222329678670935,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "zBVjxKB6g84",
        "title": "Understanding Clipping for Federated Learning: Convergence and Client-Level Differential Privacy",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;3;8",
        "confidence": "4;4;4;3",
        "correctness": "4;3;2;4",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "3;1;2;4",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.5222329678670935,
        "project": "",
        "github": ""
    },
    {
        "id": "zBhwgP7kt4",
        "title": "Dynamic Least-Squares Regression",
        "track": "main",
        "status": "Reject",
        "keywords": "Least squares regression;dynamic algorithm",
        "author": "",
        "aff": "",
        "rating": "6;6;6;8",
        "confidence": "4;4;3;4",
        "correctness": "4;3;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "0;2;3;1",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "zFlFjoyOW-z",
        "title": "Interest-based Item Representation Framework for Recommendation with Multi-Interests Capsule Network",
        "track": "main",
        "status": "Reject",
        "keywords": "Feature Representation;Recommendation System;Dynamic Routing of Capsule",
        "author": "",
        "aff": "",
        "rating": "1;3;3;3",
        "confidence": "4;5;4;3",
        "correctness": "2;1;3;3",
        "technical_novelty": "2;2;1;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 2.5,
        "confidence_avg": 4.0,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.17407765595569782,
        "project": "",
        "github": ""
    },
    {
        "id": "zFyCvjXof60",
        "title": "Hypergraph Convolutional Networks via Equivalency between Hypergraphs and Undirected Graphs",
        "track": "main",
        "status": "Reject",
        "keywords": "hypergraph learning;equivalency of hypergraph;graph neural networks",
        "author": "",
        "aff": "",
        "rating": "5;5;6;8",
        "confidence": "5;3;3;3",
        "correctness": "4;3;4;4",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;3;4",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4714045207910316,
        "corr_rating_correctness": 0.4714045207910316,
        "project": "",
        "github": ""
    },
    {
        "id": "zHZ1mvMUMW8",
        "title": "Succinct Compression: Near-Optimal and Lossless Compression of Deep Neural Networks during Inference Runtime",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "4;3;4;3",
        "correctness": "3;2;3;2",
        "technical_novelty": "2;3;2;2",
        "empirical_novelty": "2;3;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "zIUyj55nXR",
        "title": "Frame Averaging for Invariant and Equivariant Network Design",
        "track": "main",
        "status": "Oral",
        "keywords": "Invariant and equivariant neural network;expressive power",
        "author": "",
        "aff": "Facebook AI Research; Weizmann Institute of Science",
        "rating": "8;8;8;8",
        "confidence": "2;5;4;4",
        "correctness": "3;4;4;2",
        "technical_novelty": "4;4;4;4",
        "empirical_novelty": "3;4;4;3",
        "presentation": "",
        "rating_avg": 8.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 4.0,
        "empirical_novelty_avg": 3.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "zKbMQ2NY1y",
        "title": "Aug-ILA: More Transferable Intermediate Level Attacks with Augmented References",
        "track": "main",
        "status": "Reject",
        "keywords": "adversarial examples;adversarial transferability;intermediate feature;image augmentation",
        "author": "",
        "aff": "",
        "rating": "3;5;6;6",
        "confidence": "4;3;3;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "3;2;3;2",
        "empirical_novelty": "2;3;3;2",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.40824829046386296,
        "corr_rating_correctness": 0.9428090415820632,
        "project": "",
        "github": ""
    },
    {
        "id": "zLb9oSWy933",
        "title": "Fast Finite Width Neural Tangent Kernel",
        "track": "main",
        "status": "Reject",
        "keywords": "Neural Tangent Kernel;NTK;Finite Width;Fast;Algorithm;JAX;Jacobian;Software",
        "author": "Roman Novak",
        "aff": "",
        "rating": "3;6;6;6",
        "confidence": "5;4;3;4",
        "correctness": "4;3;3;3",
        "technical_novelty": "1;3;2;1",
        "empirical_novelty": "2;4;4;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 1.75,
        "empirical_novelty_avg": 3.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.816496580927726,
        "corr_rating_correctness": -1.0,
        "project": "",
        "github": "https://github.com/iclr2022anon/fast_finite_width_ntk"
    },
    {
        "id": "zNHzqZ9wrRB",
        "title": "Equivariant Transformers for Neural Network based Molecular Potentials",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Molecular Modeling;Quantum Chemistry;Attention;Transformers",
        "author": "",
        "aff": "Computational Science Laboratory, Pompeu Fabra University, PRBB, C/ Doctor Aiguader 88, 08003 Barcelona, Spain and Institute of Cognitive Science, Osnabr\u00fcck University, Neuer Graben 29 / Schloss, 49074 Osnabr\u00fcck, Germany; Computational Science Laboratory, Pompeu Fabra University, C/ Doctor Aiguader 88, 08003 Barcelona, Spain and ICREA, Passeig Lluis Companys 23, 08010 Barcelona, Spain and Acellera Labs, C/ Doctor Trueta 183, 08005 Barcelona, Spain",
        "rating": "6;6;8;8",
        "confidence": "5;3;4;4",
        "correctness": "3;4;4;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;0;3;3",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "zNR43c03lRy",
        "title": "Learning to Annotate Part Segmentation with Gradient Matching",
        "track": "main",
        "status": "Poster",
        "keywords": "semi-supervised learning;part segmentation;semantic segmentation;generative models;gradient matching",
        "author": "",
        "aff": "Department of Automation, Tsinghua University, BNRist; School of Informatics, University of Edinburgh",
        "rating": "6;6;6;8",
        "confidence": "3;4;4;3",
        "correctness": "4;3;3;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "0;2;3;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5773502691896257,
        "corr_rating_correctness": -0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "zNlkpFBT9aD",
        "title": "Automatic Portrait Video Matting via Context Motion Network",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6;6",
        "confidence": "4;4;5;4;2",
        "correctness": "3;2;4;3;3",
        "technical_novelty": "2;2;2;3;2",
        "empirical_novelty": "2;2;3;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.8,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.2,
        "empirical_novelty_avg": 2.6,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.372677996249965,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "zPLQSnfd14w",
        "title": "Two Regimes of Generalization for Non-Linear Metric Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "metric learning;guarantees;sparsity",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "3;4;3;3",
        "correctness": "3;2;4;4",
        "technical_novelty": "3;1;3;3",
        "empirical_novelty": "0;2;2;2",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 1.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5555555555555555,
        "corr_rating_correctness": 0.8703882797784892,
        "project": "",
        "github": ""
    },
    {
        "id": "zRJu6mU2BaE",
        "title": "ConFeSS: A Framework for Single Source Cross-Domain Few-Shot Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "Qualcomm AI Research",
        "rating": "5;6;6;6",
        "confidence": "4;4;5;4",
        "correctness": "3;4;4;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 4.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.3333333333333333,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "zRb7IWkTZAU",
        "title": "Zero-Shot Reward Specification via Grounded Natural Language",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "4;4;4;2",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7777777777777777,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "zU2v47WF0Ku",
        "title": "Implicit Bias of Linear Equivariant Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "Implicit bias;equivariance;deep learning;linear networks;convolution;CNN",
        "author": "andyd",
        "aff": "",
        "rating": "5;6;6;6",
        "confidence": "4;3;2;2",
        "correctness": "4;3;4;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "1;2;2;2",
        "presentation": "",
        "rating_avg": 5.75,
        "confidence_avg": 2.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 1.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.8703882797784891,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "zXM0b4hi5_B",
        "title": "On the relation between statistical learning and perceptual distances",
        "track": "main",
        "status": "Spotlight",
        "keywords": "",
        "author": "",
        "aff": "Image Processing Lab, Universitat de Valencia; Engineering Mathematics, University of Bristol; Google Research",
        "rating": "6;6;6;8",
        "confidence": "5;4;5;2",
        "correctness": "4;3;2;4",
        "technical_novelty": "1;3;2;4",
        "empirical_novelty": "2;3;2;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.9428090415820632,
        "corr_rating_correctness": 0.5222329678670935,
        "project": "",
        "github": ""
    },
    {
        "id": "zXne1klXIQ",
        "title": "Improving Out-of-Distribution Robustness via Selective Augmentation",
        "track": "main",
        "status": "Reject",
        "keywords": "out-of-distribution robustness;distribution shifts;selective data augmentation",
        "author": "",
        "aff": "",
        "rating": "5;5;6",
        "confidence": "3;4;4",
        "correctness": "2;3;4",
        "technical_novelty": "3;2;2",
        "empirical_novelty": "3;3;3",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.4999999999999999,
        "corr_rating_correctness": 0.8660254037844385,
        "project": "",
        "github": ""
    },
    {
        "id": "z_gX7gZe2cV",
        "title": "Membership Inference Attack in Face of Data Transformations",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Membership inference attack;Data transformation;Data privacy",
        "author": "",
        "aff": "",
        "rating": "3;3;3;3",
        "confidence": "3;4;4;5",
        "correctness": "2;1;3;3",
        "technical_novelty": "2;2;2;2",
        "empirical_novelty": "2;2;2;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "zaALYtvbRlH",
        "title": "SpanDrop: Simple and Effective Counterfactual Learning for Long Sequences",
        "track": "main",
        "status": "Reject",
        "keywords": "sequential data;sample efficiency;data augmentation",
        "author": "",
        "aff": "",
        "rating": "3;3;3;8",
        "confidence": "3;4;4;5",
        "correctness": "3;4;3;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;1;2;3",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.816496580927726,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "zbZL1s-pBF",
        "title": "Training-Free Robust Multimodal Learning via Sample-Wise Jacobian Regularization",
        "track": "main",
        "status": "Reject",
        "keywords": "Jacobian Regularization;Robust Multimodal Learning",
        "author": "",
        "aff": "",
        "rating": "5;5;6",
        "confidence": "4;3;3",
        "correctness": "4;3;3",
        "technical_novelty": "3;2;3",
        "empirical_novelty": "3;2;3",
        "presentation": "",
        "rating_avg": 5.333333333333333,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.4999999999999999,
        "corr_rating_correctness": -0.4999999999999999,
        "project": "",
        "github": ""
    },
    {
        "id": "zc0YnpS90ug",
        "title": "On Exploring Node-feature and Graph-structure Diversities for Node Drop Graph Pooling",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Graph Neural Networks;Graph Pooling;Graph Classification",
        "author": "",
        "aff": "",
        "rating": "3;3;3;5",
        "confidence": "4;5;4;4",
        "correctness": "2;3;2;3",
        "technical_novelty": "2;3;2;2",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 3.5,
        "confidence_avg": 4.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": "http://github.com/xxx/xxx"
    },
    {
        "id": "zdpZyJ7xu4",
        "title": "FOCUS: Familiar Objects in Common And Uncommon Settings",
        "track": "main",
        "status": "Withdraw",
        "keywords": "focus;dataset;focus dataset;generalization;distributional robustness;robustness",
        "author": "",
        "aff": "",
        "rating": "3;3;3",
        "confidence": "4;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "2;2;1",
        "empirical_novelty": "2;2;3",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 1.6666666666666667,
        "empirical_novelty_avg": 2.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "zeGpMIt6Pfq",
        "title": "BioLCNet: Reward-modulated Locally Connected Spiking Neural Networks",
        "track": "main",
        "status": "Reject",
        "keywords": "Spiking Neural Networks;Locally Connected Networks;Spike-timing-dependent plasticity;Reinforcement Learning",
        "author": "",
        "aff": "",
        "rating": "3;3;6",
        "confidence": "4;4;3",
        "correctness": "2;3;3",
        "technical_novelty": "2;2;3",
        "empirical_novelty": "2;2;2",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.3333333333333335,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -1.0,
        "corr_rating_correctness": 0.5,
        "project": "",
        "github": ""
    },
    {
        "id": "zfKQn4zN6sB",
        "title": "$\\ell_\\infty$-Robustness and Beyond: Unleashing Efficient Adversarial Training",
        "track": "main",
        "status": "Withdraw",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;3;5;6",
        "confidence": "5;5;5;5",
        "correctness": "3;3;3;4",
        "technical_novelty": "2;2;2;3",
        "empirical_novelty": "2;0;2;4",
        "presentation": "",
        "rating_avg": 4.25,
        "confidence_avg": 5.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.7777777777777777,
        "project": "",
        "github": ""
    },
    {
        "id": "zf_Ll3HZWgy",
        "title": "How Much Can CLIP Benefit Vision-and-Language Tasks?",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "University of California, Los Angeles; University of California, Berkeley; University of North Carolina at Chapel Hill",
        "rating": "5;6;6;8",
        "confidence": "5;4;4;4",
        "correctness": "4;3;3;4",
        "technical_novelty": "1;3;2;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 6.25,
        "confidence_avg": 4.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6622661785325219,
        "corr_rating_correctness": 0.2294157338705618,
        "project": "",
        "github": ""
    },
    {
        "id": "zfmB5vgfaCt",
        "title": "TransSlowDown: Efficiency Attacks on Neural Machine Translation Systems",
        "track": "main",
        "status": "Reject",
        "keywords": "",
        "author": "",
        "aff": "",
        "rating": "3;5;5;6",
        "confidence": "4;4;5;4",
        "correctness": "3;3;2;3",
        "technical_novelty": "3;2;3;4",
        "empirical_novelty": "3;2;3;3",
        "presentation": "",
        "rating_avg": 4.75,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 3.0,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.13245323570650439,
        "corr_rating_correctness": -0.13245323570650439,
        "project": "",
        "github": ""
    },
    {
        "id": "zhynF6JnC4q",
        "title": "Adaptive Q-learning for Interaction-Limited Reinforcement Learning",
        "track": "main",
        "status": "Reject",
        "keywords": "reinforcement learning;offline reinforcement learning;online-to-offline;limited interactions",
        "author": "",
        "aff": "",
        "rating": "3;6;6;6",
        "confidence": "4;4;3;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "2;3;2;2",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 2.25,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": ""
    },
    {
        "id": "ziRLU3Y2PN_",
        "title": "Generalized rectifier wavelet covariance models for texture synthesis",
        "track": "main",
        "status": "Poster",
        "keywords": "texture synthesis;generative models;wavelets",
        "author": "",
        "aff": "ENS, PSL University, Paris, France; Coll`ege de France, Paris, France; Flatiron Institute, New York, USA; Universit\u00b4e de Toulouse, INP, IRIT, Toulouse, France",
        "rating": "3;8;8;8",
        "confidence": "4;5;3;5",
        "correctness": "3;4;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "3;3;3;3",
        "presentation": "",
        "rating_avg": 6.75,
        "confidence_avg": 4.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.17407765595569782,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "znpOLJUYGcA",
        "title": "Automatic Integration for Neural Temporal Point Process",
        "track": "main",
        "status": "Withdraw",
        "keywords": "point process",
        "author": "",
        "aff": "",
        "rating": "",
        "confidence": "",
        "correctness": "",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 0,
        "correctness_avg": 0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "zokEN0xOb0Q",
        "title": "Differential Privacy with Manifold Data Dependency",
        "track": "main",
        "status": "Withdraw",
        "keywords": "Differential privacy;data correlation",
        "author": "",
        "aff": "",
        "rating": "3;6;6",
        "confidence": "5;2;4",
        "correctness": "2;4;4",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "2;3;3",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 2.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.7559289460184545,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": ""
    },
    {
        "id": "zou-Ry64vqx",
        "title": "FedMorph: Communication Efficient Federated Learning via Morphing Neural Network",
        "track": "main",
        "status": "Reject",
        "keywords": "Federated Learning;Communication efficient",
        "author": "",
        "aff": "",
        "rating": "3;3;3",
        "confidence": "4;3;3",
        "correctness": "3;2;3",
        "technical_novelty": "2;2;2",
        "empirical_novelty": "2;0;2",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.3333333333333333,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "zq1iJkNk3uN",
        "title": "Supervision Exists Everywhere: A Data Efficient Contrastive Language-Image Pre-training Paradigm",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "University of Sydney; The University of Texas at Austin; SenseTime Research",
        "rating": "6;6;6;8",
        "confidence": "5;3;4;3",
        "correctness": "4;3;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "3;3;2;3",
        "presentation": "",
        "rating_avg": 6.5,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.75,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.5222329678670935,
        "corr_rating_correctness": 0.3333333333333333,
        "project": "",
        "github": "https://github.com/Sense-GVT/DeCLIP"
    },
    {
        "id": "zrW-LVXj2k1",
        "title": "On the benefits of maximum likelihood estimation for Regression and Forecasting",
        "track": "main",
        "status": "Poster",
        "keywords": "Forecasting;Time-Series;Regression;MLE",
        "author": "",
        "aff": "Google Research",
        "rating": "5;5;8",
        "confidence": "2;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "2;3;3",
        "empirical_novelty": "3;4;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 3.3333333333333335,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.5,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "zrdUVVAvcP2",
        "title": "GrASP: Gradient-Based Affordance Selection for Planning",
        "track": "main",
        "status": "Reject",
        "keywords": "reinforcement learning;affordances",
        "author": "",
        "aff": "",
        "rating": "5;5;6;8",
        "confidence": "4;2;3;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "2;2;3;3",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.5,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "zuDmDfeoB_1",
        "title": "How Does the Task Landscape Affect MAML Performance?",
        "track": "main",
        "status": "Reject",
        "keywords": "Meta-learning;MAML;multi-task linear regression;two-layer neural networks",
        "author": "",
        "aff": "",
        "rating": "5;5;5;6",
        "confidence": "3;3;4;3",
        "correctness": "3;4;3;4",
        "technical_novelty": "2;3;2;3",
        "empirical_novelty": "2;3;2;2",
        "presentation": "",
        "rating_avg": 5.25,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.3333333333333333,
        "corr_rating_correctness": 0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "zuqcmNVK4c2",
        "title": "Self-Joint Supervised Learning",
        "track": "main",
        "status": "Poster",
        "keywords": "",
        "author": "",
        "aff": "Center for Research in Computer Vision, Department of Computer Science, University of Central Florida; Department of Statistics and Data Science, University of Central Florida",
        "rating": "5;8;8",
        "confidence": "3;4;5",
        "correctness": "3;4;4",
        "technical_novelty": "2;2;4",
        "empirical_novelty": "3;4;4",
        "presentation": "",
        "rating_avg": 7.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 2.6666666666666665,
        "empirical_novelty_avg": 3.6666666666666665,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8660254037844387,
        "corr_rating_correctness": 1.0,
        "project": "",
        "github": "github.com/ndkn/Self-joint-Learning"
    },
    {
        "id": "zxEfpcmTDnF",
        "title": "Learning and controlling the source-filter representation of speech with a variational autoencoder",
        "track": "main",
        "status": "Reject",
        "keywords": "Deep generative models;variational autoencoder (VAE);speech processing;source-filter model of speech production;representation learning",
        "author": "",
        "aff": "",
        "rating": "5;5;6;6",
        "confidence": "4;4;4;4",
        "correctness": "4;4;4;3",
        "technical_novelty": "2;2;3;3",
        "empirical_novelty": "2;2;2;3",
        "presentation": "",
        "rating_avg": 5.5,
        "confidence_avg": 4.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.5,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": -0.5773502691896257,
        "project": "",
        "github": ""
    },
    {
        "id": "zxm7rzEPaj",
        "title": "Treatment effect estimation with confounder balanced instrumental variable regression",
        "track": "main",
        "status": "Withdraw",
        "keywords": "treatment effect;unmeasured confounders;instrumental variable;confounder balance;representaion learning",
        "author": "",
        "aff": "",
        "rating": "6;6;6;6",
        "confidence": "3;4;3;3",
        "correctness": "4;3;4;4",
        "technical_novelty": "2;3;3;3",
        "empirical_novelty": "3;3;3;0",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 2.25,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.0,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "zyrhwrd9EYs",
        "title": "To Impute or Not To Impute? Missing Data in Treatment Effect Estimation",
        "track": "main",
        "status": "Reject",
        "keywords": "Causality",
        "author": "",
        "aff": "",
        "rating": "3;3;5",
        "confidence": "4;3;5",
        "correctness": "1;3;2",
        "technical_novelty": "1;2;3",
        "empirical_novelty": "1;2;2",
        "presentation": "",
        "rating_avg": 3.6666666666666665,
        "confidence_avg": 4.0,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.6666666666666667,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.8660254037844387,
        "corr_rating_correctness": 0.0,
        "project": "",
        "github": ""
    },
    {
        "id": "zz9hXVhf40",
        "title": "Revisiting Design Choices in Offline Model Based Reinforcement Learning",
        "track": "main",
        "status": "Spotlight",
        "keywords": "Model-Based Reinforcement Learning;Offline Reinforcement Learning;Uncertainty Quantification",
        "author": "",
        "aff": "Department of Engineering, University of Oxford",
        "rating": "6;6;6;8;8",
        "confidence": "4;4;4;4;3",
        "correctness": "4;2;3;4;4",
        "technical_novelty": "2;2;3;3;2",
        "empirical_novelty": "3;3;3;3;3",
        "presentation": "",
        "rating_avg": 6.8,
        "confidence_avg": 3.8,
        "correctness_avg": 3.4,
        "technical_novelty_avg": 2.4,
        "empirical_novelty_avg": 3.0,
        "presentation_avg": 0,
        "corr_rating_confidence": -0.6123724356957946,
        "corr_rating_correctness": 0.6123724356957946,
        "project": "",
        "github": ""
    },
    {
        "id": "zz_qjE6N1OF",
        "title": "P4O: Efficient Deep Reinforcement Learning with Predictive Processing Proximal Policy Optimization",
        "track": "main",
        "status": "Withdraw",
        "keywords": "reinforcement learning;predictive processing",
        "author": "",
        "aff": "",
        "rating": "1;3;3;3;3",
        "confidence": "4;5;4;4;4",
        "correctness": "3;2;4;2;3",
        "technical_novelty": "1;2;3;2;2",
        "empirical_novelty": "1;2;3;1;2",
        "presentation": "",
        "rating_avg": 2.6,
        "confidence_avg": 4.2,
        "correctness_avg": 2.8,
        "technical_novelty_avg": 2.0,
        "empirical_novelty_avg": 1.8,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.24999999999999994,
        "corr_rating_correctness": -0.13363062095621214,
        "project": "",
        "github": ""
    },
    {
        "id": "zzk231Ms1Ih",
        "title": "A Theory of Tournament Representations",
        "track": "main",
        "status": "Poster",
        "keywords": "tournament;skew-symmetric;pairwise ranking",
        "author": "",
        "aff": "Cohesity Inc; Indian Institute of Technology; Indian Institute of Technology, RBCDSAI, IIT",
        "rating": "5;5;6;8",
        "confidence": "4;3;3;4",
        "correctness": "3;4;3;4",
        "technical_novelty": "3;2;3;3",
        "empirical_novelty": "2;0;0;1",
        "presentation": "",
        "rating_avg": 6.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 2.75,
        "empirical_novelty_avg": 0.75,
        "presentation_avg": 0,
        "corr_rating_confidence": 0.40824829046386296,
        "corr_rating_correctness": 0.40824829046386296,
        "project": "",
        "github": ""
    }
]