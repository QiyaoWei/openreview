[
    {
        "id": "01wSNY5T60",
        "title": "Are Compressed Language Models Less Subgroup Robust?",
        "track": "main",
        "status": "Short Main",
        "keywords": "Language Model Compression;Subgroup Robustness",
        "author": "",
        "aff": "expert.ai, Siena, Italy; Predictive Analytics Lab, University of Sussex, UK; Predictive Analytics Lab, University of Sussex, UK; BCAM Severo Ochoa Strategic Lab on Trustworthy Machine Learning, Spain; Monash University, Indonesia",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "05vb8rwGct",
        "title": "Towards Informative Few-Shot Prompt with Maximum Information Gain for In-Context Learning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large Language Model;In-context Learning;Information Gain",
        "author": "",
        "aff": "School of Computing, National University of Singapore",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "06oozRd4jU",
        "title": "Graph vs. Sequence: An Empirical Study on Knowledge Forms for Knowledge-Grounded Dialogue",
        "track": "main",
        "status": "Long Main",
        "keywords": "Knowledge-Grounded Dialogue;Empirical Study",
        "author": "",
        "aff": "School of Computer Science and Technology, Beijing Institute of Technology; Beijing Institute of Technology Southeast Academy of Information Technology; Beijing Engineering Research Center of High Volume Language Information Processing and Cloud Computing Applications",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "0C5C70C3n8",
        "title": "Mitigating Intrinsic Named Entity-Related Hallucinations of Abstractive Text Summarization",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Abstractive text summarization;named entity-related hallucinations;adaptive margin ranking loss",
        "author": "",
        "aff": "Visualisation Institute, University of Technology Sydney, Australia; Australian Artificial Intelligence Institute (AAII), University of Technology Sydney, Australia",
        "rating": "",
        "confidence": "3;3;4;4",
        "correctness": "3;3;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "0DkaimvWs0",
        "title": "Contrastive Pre-training for Personalized Expert Finding",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Expert Finding;Recommender Systems;Community Question Answering;Pre-training",
        "author": "",
        "aff": "",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "0DyJbE93XO",
        "title": "A Thorough Examination on Zero-shot Dense Retrieval",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Zero-shot dense retrieval; Information retrieval",
        "author": "",
        "aff": "Gaoling School of Artificial Intelligence, Renmin University of China; Baidu Inc.",
        "rating": "",
        "confidence": "1;2;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "0EQ4z8n5rp",
        "title": "Global Voices, Local Biases: Socio-Cultural Prejudices across Languages",
        "track": "main",
        "status": "Long Main",
        "keywords": "bias;multilinguality;language models",
        "author": "",
        "aff": "Department of Computer Science, George Mason University",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/iamshnoo/weathub"
    },
    {
        "id": "0GO8Dtl8lJ",
        "title": "Unleashing the Multilingual Encoder Potential: Boosting Zero-Shot Performance via Probability Calibration",
        "track": "main",
        "status": "Short Findings",
        "keywords": "prompt learning;multilingual encoders;calibration",
        "author": "",
        "aff": "Center for Information and Language Processing (CIS), LMU Munich, Germany; Munich Center for Machine Learning (MCML), Germany; Center for Information and Language Processing (CIS), LMU Munich, Germany",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ercong21/calibration"
    },
    {
        "id": "0JepdeBcDk",
        "title": "An Attribution Method for Siamese Encoders",
        "track": "main",
        "status": "Short Main",
        "keywords": "feature attribution;interpretability;explainability;siamese encoder;sentence transformer;integrated gradients;integrated Jacobians",
        "author": "",
        "aff": "Institute for Natural Language Processing, University of Stuttgart, Germany",
        "rating": "",
        "confidence": "3;2;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/lucasmllr/xsbert"
    },
    {
        "id": "0KYSlQdMu6",
        "title": "TacoPrompt: A Collaborative Multi-Task Prompt Learning Method for Self-Supervised Taxonomy Completion",
        "track": "main",
        "status": "Long Main",
        "keywords": "Taxonomy completion;prompt learning;self-supervised learning;multi-task learning",
        "author": "",
        "aff": "College of Computer Science, Nankai University, Tianjin, China",
        "rating": "",
        "confidence": "3;4;5;3",
        "correctness": "3;3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/cyclexu/TacoPrompt"
    },
    {
        "id": "0LXEvcD3dB",
        "title": "SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal Conversational Abilities",
        "track": "main",
        "status": "Long Findings",
        "keywords": "large language model;speech;multi-modal",
        "author": "",
        "aff": "School of Computer Science, Fudan University; Shanghai Key Laboratory of Intelligent Information Processing, Fudan University",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://0nutation.github.io/SpeechGPT.github.io/",
        "github": "https://github.com/0nutation/SpeechGPT"
    },
    {
        "id": "0M2m9GUTLN",
        "title": "Fair Text Classification with Wasserstein Independence",
        "track": "main",
        "status": "Long Main",
        "keywords": "Text Classification;Fairness;Wasserstein",
        "author": "",
        "aff": "T\u00e9l\u00e9com Paris, Institut Polytechnique de Paris, Paris, France; Laboratoire Hubert Curien, UMR CNRS 5516, Saint-Etienne, France",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/LetenoThibaud/wasserstein_fair_classification"
    },
    {
        "id": "0ODPaEbHxG",
        "title": "Measuring Pointwise $\\mathcal{V}$-Usable Information In-Context-ly",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Hardness;Pointwise V-Usable Information;In-Context Learning",
        "author": "",
        "aff": "Computational Health Informatics Program, Boston Children\u2019s Hospital, Harvard Medical School; Department of Radiation Oncology, Brigham and Women\u2019s Hospital/Dana-Farber Cancer Institute; Ubiquitous Knowledge Processing Lab (UKP Lab), Technical University of Darmstadt; Artificial Intelligence in Medicine (AIM) Program, Mass General Brigham, Harvard Medical School",
        "rating": "",
        "confidence": "2;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "www.ukp.tu-darmstadt.de",
        "github": "https://github.com/UKPLab/in-context-pvi"
    },
    {
        "id": "0OtGfwj8eB",
        "title": "Reinforcement Replaces Supervision: Query focused Summarization using Deep Reinforcement Learning",
        "track": "main",
        "status": "Long Main",
        "keywords": "reinforcement learning for long text;query focused summarization;passage embedding;long form question answering",
        "author": "",
        "aff": "TCS Research, India; Computer Science and Engineering, IIT Bombay, India",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "0Rdp7a3y2H",
        "title": "Adversarial Text Generation by Search and Learning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Adversarial robustness;Adversarial training;Unsupervised Text Generation",
        "author": "",
        "aff": "Chinese Academy of Sciences, Institute of Information Engineering, Beijing, China; Alibaba Group, Alibaba Artificial Intelligence Governance Laboratory, Beijing, China; University of Bristol, Department of Electrical and Electronic Engineering, Bristol, UK",
        "rating": "",
        "confidence": "2;4;2",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "0SF6Kr1lrx",
        "title": "Leap-of-Thought: Accelerating Transformers via Dynamic Token Routing",
        "track": "main",
        "status": "Long Main",
        "keywords": "transformer;language models;token routing;token pruning;input length reduction",
        "author": "",
        "aff": "BK21 FOUR R&E Center for Artificial Intelligence, Korea University, Seoul, South Korea; Department of Artificial Intelligence, Korea University, Seoul, South Korea; Department of Computer Science and Engineering, Korea University, Seoul, South Korea",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/yeachan-kr/lottransformer"
    },
    {
        "id": "0SIyWZEOmJ",
        "title": "The Linearity of the Effect of Surprisal on Reading Times across Languages",
        "track": "main",
        "status": "Short Findings",
        "keywords": "psycholinguistics;surprisal theory;linearity;reading time;cross-linguistic",
        "author": "",
        "aff": "Stanford University; University of Washington; University of California, Irvine",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "0ULLuIRdcu",
        "title": "ClimateBERT-NetZero: Detecting and Assessing Net Zero and Reduction Targets",
        "track": "main",
        "status": "Short Main",
        "keywords": "ClimateBERT;BERT;climate change;net zero",
        "author": "",
        "aff": "University of Oxford; University of Zurich; Swiss Finance Institute (SFI); FAU Erlangen-N\u00fcrnberg; Net Zero Tracker",
        "rating": "",
        "confidence": "4;5;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://huggingface.co/climatebert/netzero-reduction"
    },
    {
        "id": "0VQImEvjPJ",
        "title": "NormDial: A Comparable Bilingual Synthetic Dialog Dataset for Modeling Social Norm Adherence and Violation",
        "track": "main",
        "status": "Short Main",
        "keywords": "social norms;resources and evaluation;large language models",
        "author": "",
        "aff": "Department of Computer Science, Columbia University; Data Science Institute, Columbia University",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "0W2aSP6y3x",
        "title": "Vision-Enhanced Semantic Entity Recognition in Document Images via Visually-Asymmetric Consistency Learning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Visually rich documents;Information extraction;Consistency Learning;Multimodality",
        "author": "",
        "aff": "School of Computer Engineering and Science, Shanghai University, China; Department of Computer Science and Engineering, Shanghai Jiao Tong University, China; Graduate School of Informatics, Kyoto University, Japan",
        "rating": "",
        "confidence": "3;3;3;4",
        "correctness": "4;2;3;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "0aiFUPYan3",
        "title": "VER: Unifying Verbalizing Entities and Relations",
        "track": "main",
        "status": "Long Findings",
        "keywords": "definition modeling;relation modeling;entity relationships",
        "author": "",
        "aff": "Department of Computer Science, University of Illinois at Urbana-Champaign",
        "rating": "",
        "confidence": "5;4;2",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/jeffhj/VER"
    },
    {
        "id": "0b2chPXfVG",
        "title": "Orca: A Few-shot Benchmark for Chinese Conversational Machine Reading Comprehension",
        "track": "main",
        "status": "Long Findings",
        "keywords": "dataset;conversational machine reading comprehension",
        "author": "",
        "aff": "CCNL, IDEA, Shenzhen, China; Xiaobing.AI; Institute of Information Engineering, Chinese Academy of Sciences; Hong Kong University of Science and Technology (Guangzhou), Hong Kong University of Science and Technology",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/nuochenpku/Orca"
    },
    {
        "id": "0bderX6zwr",
        "title": "FFAEval: Evaluating Dialogue System via Free-For-All Ranking",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Human Evaluation;Dialogue System Evaluation",
        "author": "",
        "aff": "Department of Computer Science and Technology, Tsinghua University, Beijing, China; School of Information, Renmin University of China, Beijing, China; Engineering Research Center of Database and Business Intelligence, MOE, China; Zhipu.AI",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "3;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/RUCKBReasoning/FFAEval"
    },
    {
        "id": "0duz9dhwRc",
        "title": "Stance Detection on Social Media with Background Knowledge",
        "track": "main",
        "status": "Long Main",
        "keywords": "Stance Detection;Knowledge Augmentation;Background Knowledge",
        "author": "",
        "aff": "Shenzhen Technology University, Shenzhen, China; Harbin Insitute of Technology, Shenzhen, China; SIAT, Chinese Academy of Sciences, Shenzhen, China; The Chinese University of Hong Kong, Hong Kong, China",
        "rating": "",
        "confidence": "5;4;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "0eWQVWvPgu",
        "title": "Unveiling the Power of Argument Arrangement in Online Persuasive Discussions",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Argument Mining;Persuasive Dialogues;Persuasion Strategies;ChangeMyView",
        "author": "",
        "aff": "University of Groningen; Bauhaus-Universit\u00e4t Weimar",
        "rating": "",
        "confidence": "5;2;2",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "0hTPJBnncc",
        "title": "MQuAKE: Assessing Knowledge Editing in Language Models via Multi-Hop Questions",
        "track": "main",
        "status": "Long Main",
        "keywords": "Knowledge Editing;Multi-hop Question Answering;Language Models",
        "author": "",
        "aff": "Stanford University; Princeton University",
        "rating": "",
        "confidence": "3;5;4;4",
        "correctness": "4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/princeton-nlp/MQuAKE"
    },
    {
        "id": "0hyn6MJmnP",
        "title": "TADI: Topic-aware Attention and Powerful Dual-encoder Interaction for Recall in News Recommendation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "news recommendation;recommendation",
        "author": "",
        "aff": "N/A",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "0iRgUfkwp3",
        "title": "Causal Intervention-based Few-Shot Named Entity Recognition",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Causal Intervention;Few-Shot Learning;Named Entity Recognition",
        "author": "",
        "aff": "University of South China",
        "rating": "",
        "confidence": "5;3;3",
        "correctness": "2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "0ii51brFyn",
        "title": "Enhanced Simultaneous Machine Translation with Word-level Policies",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Simultaneous Machine Translation;word-level policies",
        "author": "",
        "aff": "XL8 Inc.",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/xl8-ai/WordSiMT"
    },
    {
        "id": "0isMLQIUpQ",
        "title": "Is ChatGPT the ultimate Data Augmentation Algorithm?",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Data augmentation;ChatGPT;GPT-3.5;classification;T5",
        "author": "",
        "aff": "RALI, Diro, Universit\u00e9 de Montr\u00e9al",
        "rating": "",
        "confidence": "3;2;5",
        "correctness": "3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "0juZSwZLA4",
        "title": "ScdNER: Span-Based Consistency-Aware Document-Level Named Entity Recognition",
        "track": "main",
        "status": "Short Main",
        "keywords": "named entity recognition;span-based;document-level;consistency-aware",
        "author": "",
        "aff": "Iowa State University / Ames, IA 50011",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "0kseDcA5Nm",
        "title": "Give Me the Facts! A Survey on Factual Knowledge Probing in Pre-trained Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "factual knowledge probing",
        "author": "",
        "aff": "Institute for AI in Medicine (IKIM), University Hospital Essen, University of Duisburg-Essen; Institute for AI in Medicine (IKIM), University Hospital Essen, University of Mannheim, University of Marburg",
        "rating": "",
        "confidence": "1;1;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 2.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "0lE7w8RJDw",
        "title": "Learning Knowledge-Enhanced Contextual Language Representations for Domain Natural Language Understanding",
        "track": "main",
        "status": "Long Main",
        "keywords": "Closed-domain;Pre-trained Language Model;Knowledge Graph",
        "author": "",
        "aff": "East China Normal University, Shanghai, China; Tongji University, Shanghai, China; East China Normal University, Shanghai, China; Alibaba Group, Hangzhou, China; Alibaba Group, Hangzhou, China",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/alibaba/EasyNLP"
    },
    {
        "id": "0n92zm014A",
        "title": "Self-ICL: Zero-Shot In-Context Learning with Self-Generated Demonstrations",
        "track": "main",
        "status": "Long Main",
        "keywords": "in-context learning;zero-shot;bootstrapping",
        "author": "",
        "aff": "National Taiwan University, Taiwan",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ntunlplab/Self-ICL"
    },
    {
        "id": "0sDieI5GJh",
        "title": "QUADRo: Dataset and Models for QUestion-Answer Database Retrieval",
        "track": "main",
        "status": "Long Findings",
        "keywords": "question answering;semantic similarity;nlp application;question answering database;question answering resources;question ranking and retrieval",
        "author": "",
        "aff": "Amazon Alexa AI; University of Trento, Amazon Alexa AI",
        "rating": "",
        "confidence": "2;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "0tEed0ZiFX",
        "title": "Learning Semantic Role Labeling from Compatible Label Sequences",
        "track": "main",
        "status": "Long Findings",
        "keywords": "SRL",
        "author": "",
        "aff": "University of Utah; University of Colorado Boulder; Google Research",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "0u3O7Ju21x",
        "title": "Calibrated Seq2seq Models for Efficient and Generalizable Ultra-fine Entity Typing",
        "track": "main",
        "status": "Long Findings",
        "keywords": "entity typing;information extraction;probability calibration",
        "author": "",
        "aff": "Language Technologies Institute, Carnegie Mellon University\u2020; Megagon Labs\u2020, Language Technologies Institute, Carnegie Mellon University\u00a7",
        "rating": "",
        "confidence": "3;4;5",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/yanlinf/CASENT"
    },
    {
        "id": "106xRbVC4k",
        "title": "Revisiting Entropy Rate Constancy in Text",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Uniform Information Density;Entropy Rate;Large Language Models;Linguistic Theories",
        "author": "",
        "aff": "Computer Science Division, University of California, Berkeley",
        "rating": "",
        "confidence": "3;4;2",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "10iYooV68H",
        "title": "A Training-Free Debiasing Framework with Counterfactual Reasoning for Conversational Emotion Detection",
        "track": "main",
        "status": "Long Main",
        "keywords": "Conversational Emotion Detection;Counterfactual Reasoning;Debiasing",
        "author": "",
        "aff": "Harbin Institute of Technology, Shenzhen, China; Guangdong Provincial Key Laboratory of Novel Security Intelligence Technologies; SIAT, Chinese Academy of Sciences, Shenzhen, China; Harbin Institute of Technology, Shenzhen, China; Guangdong Provincial Key Laboratory of Novel Security Intelligence Technologies; Peng Cheng Laboratory, Shenzhen, China; The Chinese University of Hong Kong, Hong Kong, China",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/TuGengs/TFD"
    },
    {
        "id": "14WRhMNq7H",
        "title": "MolCA: Molecular Graph-Language Modeling with Cross-Modal Projector and Uni-Modal Adapter",
        "track": "main",
        "status": "Long Main",
        "keywords": "Molecular Language Modeling;Cross-Modal Alignment;Molecule Captioning;Molecule-Text Retrieval",
        "author": "",
        "aff": "University of Science and Technology of China; National University of Singapore; Singapore Management University",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/acharkq/MolCA"
    },
    {
        "id": "16ZOs6YPDT",
        "title": "Variance Matters: Detecting Semantic Differences without Corpus/Word Alignment",
        "track": "main",
        "status": "Long Main",
        "keywords": "Semantic difference;semantic shift;word vectors;variance;concentration parameter",
        "author": "",
        "aff": "University of Tokyo, Japan; AIST, Japan; Tokyo University of Foreign Studies, Japan; Konan University, Japan",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/nagata-github/vmf_meaning_change_detector"
    },
    {
        "id": "18skb5S2Gv",
        "title": "Nearest Neighbor Machine Translation is Meta-Optimizer on Output Projection Layer",
        "track": "main",
        "status": "Long Main",
        "keywords": "Nearest Neighbor Machine Translation;meta-optimization;domain adaptation;Neural Machine Translation",
        "author": "",
        "aff": "University of Science and Technology of China; Shanghai Jiao Tong University; Tencent AI Lab",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/RuizGao/knnmt-meta-optimizer"
    },
    {
        "id": "19sGqVUxQw",
        "title": "Inverse Scaling Can Become U-Shaped",
        "track": "main",
        "status": "Short Main",
        "keywords": "inverse scaling;scaling;language models;evaluation",
        "author": "",
        "aff": "Google; Reka AI; OpenAI",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "19uudhc1s8",
        "title": "Analyzing Film Adaptation through Narrative Alignment",
        "track": "main",
        "status": "Long Main",
        "keywords": "Text Alignment;Book Movie Alignment",
        "author": "",
        "aff": "Department of Computer Science, Stony Brook University, NY, USA",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "1BMj6opwbj",
        "title": "From Values to Opinions: Predicting Human Behaviors and Stances Using Value-Injected Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Schwartz Value Theory;Large Language Model;Human Behavior;Personality;Value Injection",
        "author": "",
        "aff": "Seoul National University, Seoul, South Korea; University of Richmond, V A, USA; Sungkyunkwan University, Suwon, South Korea",
        "rating": "",
        "confidence": "4;3;4;4",
        "correctness": "5;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/dongjunKANG/VIM"
    },
    {
        "id": "1CaBi9kEng",
        "title": "ScanDL: A Diffusion Model for Generating Synthetic Scanpaths on Texts",
        "track": "main",
        "status": "Long Main",
        "keywords": "scanpath generation;eye movements;diffusion models;computational psycholinguistics;deep neural networks;transformer;eye tracking",
        "author": "",
        "aff": "Department of Computational Linguistics, University of Zurich, Switzerland; Department of Computational Linguistics, University of Zurich, Switzerland and Department of Computer Science, University of Potsdam, Germany; Department of Computer Science, University of Potsdam, Germany",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "5;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/DiLi-Lab/ScanDL"
    },
    {
        "id": "1IRFq6qdke",
        "title": "BanglaAbuseMeme: A Dataset for Bengali Abusive Meme Classification",
        "track": "main",
        "status": "Long Main",
        "keywords": "abusive meme;low-resource language;social media",
        "author": "",
        "aff": "IIT Kharagpur, West Bengal, India",
        "rating": "",
        "confidence": "5;4;5",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/hate-alert/BanglaAbuseMeme"
    },
    {
        "id": "1N5Ia3KLX8",
        "title": "Closed Boundary Learning for Classification Tasks with the Universum Class",
        "track": "main",
        "status": "Long Findings",
        "keywords": "classification tasks;representation learning;the miscellaneous class",
        "author": "",
        "aff": "School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; Institute of Catastrophe Risk Management, Interdisciplinary Graduate Programme, Nanyang Technological University, Singapore",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/hzzhou01/Closed-Boundary-Learning"
    },
    {
        "id": "1PXPP9Gzgc",
        "title": "BERTwich: Extending BERT\u2019s Capabilities to Model Dialectal and Noisy Text",
        "track": "main",
        "status": "Long Findings",
        "keywords": "BERT;language modeling;dialects;noisy text;fine-tuning",
        "author": "",
        "aff": "Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA",
        "rating": "",
        "confidence": "5;3;4",
        "correctness": "2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "1RVUxlrFJZ",
        "title": "Can Retriever-Augmented Language Models Reason? The Blame Game Between the Retriever and the Language Model",
        "track": "main",
        "status": "Long Findings",
        "keywords": "retriever-augmented language models;reasoning of language models",
        "author": "",
        "aff": "McGill University / Mila, Facebook CIFAR AI Chair; Intel Labs; McGill University / Mila",
        "rating": "",
        "confidence": "4;4;3;4",
        "correctness": "4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/McGill-NLP/retriever-lm-reasoning"
    },
    {
        "id": "1Sn1dpNaP3",
        "title": "Evaluating Parameter-Efficient Finetuning Approaches for Pre-trained Models on the Financial Domain",
        "track": "main",
        "status": "Short Findings",
        "keywords": "NLP;fine-tuning;parameter efficiency;financial domain",
        "author": "",
        "aff": "Zortify S.A. | 9, Rue du Laboratoire, L-1911 Gare Luxembourg; University of Luxembourg | 6, Rue Coudenhove-Kalergi, L-1359 Luxembourg",
        "rating": "",
        "confidence": "5;4;5;4",
        "correctness": "2;2;1;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.5,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "1UCopEeGz7",
        "title": "Rationale-Enhanced Language Models are Better Continual Relation Learners",
        "track": "main",
        "status": "Short Main",
        "keywords": "continual learning;relation extraction;rationale",
        "author": "",
        "aff": "; National Key Laboratory for Multimedia Information Processing, School of Computer Science, Peking University",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/WeiminXiong/RationaleCL"
    },
    {
        "id": "1VsVZm4DLg",
        "title": "All Things Considered: Detecting Partisan Events from News Media with Cross-Article Comparison",
        "track": "main",
        "status": "Long Main",
        "keywords": "Partisan event detection;media bias",
        "author": "",
        "aff": "Computer Science and Engineering, University of Michigan, Ann Arbor, MI; Computer Science, UC Santa Barbara, Santa Barbara, CA; Computer Science and Engineering, Texas A&M University, College Station, TX; Department of Political Science, Northeastern University, Boston, MA",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/launchnlp/ATC"
    },
    {
        "id": "1WJoJPXwiG",
        "title": "FinEntity: Entity-level Sentiment Classification for Financial Texts",
        "track": "main",
        "status": "Short Main",
        "keywords": "Named Entity Recognition;Sentiment Analysis;Financial NLP",
        "author": "",
        "aff": "Hong Kong University of Science and Technology; Hong Kong Monetary Authority",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/yixuantt/FinEntity"
    },
    {
        "id": "1Xht3SKAoY",
        "title": "ExpNote: Black-box Large Language Models are better Task Solvers with Experience Notebook",
        "track": "main",
        "status": "Short Findings",
        "keywords": "large language model;self-reflection;in-context learning",
        "author": "",
        "aff": "School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; CAS Engineering Laboratory for Intelligent Industrial Vision, Institute of Automation, Chinese Academy of Sciences, Beijing, China; The Laboratory of Cognition and Decision Intelligence for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; Shanghai Artificial Intelligence Laboratory",
        "rating": "",
        "confidence": "5;4;3;4",
        "correctness": "2;3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/forangel2014/ExpNote"
    },
    {
        "id": "1cKjvlvR7Z",
        "title": "Test-Time Self-Adaptive Small Language Models for Question Answering",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Language Models;Question Answering;Test-Time Adaption",
        "author": "",
        "aff": "Graduate School of AI, Korea Advanced Institute of Science and Technology; School of Computing, Korea Advanced Institute of Science and Technology; School of Computing and Graduate School of AI, Korea Advanced Institute of Science and Technology",
        "rating": "",
        "confidence": "3;4;5",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/starsuzi/T-SAS"
    },
    {
        "id": "1faXw8rfeq",
        "title": "Anaphor Assisted Document-Level Relation Extraction",
        "track": "main",
        "status": "Long Main",
        "keywords": "relation extraction;document level;anaphor;graph",
        "author": "",
        "aff": "SKLSDE, Beihang University, Beijing, China; SKLSDE, Beihang University, Beijing, China; Zhongguancun Laboratory, Beijing, China; School of Electrical Engineering and Computer Science, University of Ottawa, Ottawa, Canada",
        "rating": "",
        "confidence": "4;1;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/BurgerBurgerBurger/AA"
    },
    {
        "id": "1gUUznQgVC",
        "title": "SAC$^3$: Reliable Hallucination Detection in Black-Box Language Models via Semantic-aware Cross-check Consistency",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Hallucination;semantic consistency;blackbox;large language models;confidence",
        "author": "",
        "aff": "Vanderbilt University, Vanderbilt University Medical Center; Vanderbilt University; Intuit AI Research",
        "rating": "",
        "confidence": "3;5;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/intuit/sac3"
    },
    {
        "id": "1iQMzgmKeD",
        "title": "Extrapolating Multilingual Understanding Models as Multilingual Generators",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multilingual Translation;Prompt Tuning;Non-autoregressive Generation",
        "author": "",
        "aff": "Department of Computer Science and Engineering, Shanghai Jiao Tong University; Key Laboratory of Shanghai Education Commission for Intelligent Interaction and Cognitive Engineering, Shanghai Jiao Tong University, Shanghai, China; Carnegie Mellon University; Shanghai Artificial Intelligence Laboratory",
        "rating": "",
        "confidence": "2;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/chengzhipanpan/XLMR4MT"
    },
    {
        "id": "1kmIDTfQ4N",
        "title": "BERT Has More to Offer: BERT Layers Combination Yields Better Sentence Embeddings",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Sentence Embedding;BERT;BERT-LC;Layers Combination",
        "author": "",
        "aff": "Department of Computer Science, The University of Texas at Dallas; Department of Electrical and Computer Engineering, The University of Texas at Dallas",
        "rating": "",
        "confidence": "5;3;3",
        "correctness": "3;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/DiamondRock/BERT-Layers-Combination"
    },
    {
        "id": "1mGD6ZLTwv",
        "title": "Assessing Privacy Risks in Language Models: A Case Study on Summarization Tasks",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Summarization;Membership Inference Attack;Privacy;Language Model",
        "author": "",
        "aff": "Microsoft Research, Redmond, WA, USA; Department of Computer Science, Rice University, TX, USA; Microsoft, Redmond, WA, USA",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "1pxxAJwBXj",
        "title": "CorefPrompt: Prompt-based Event Coreference Resolution by Measuring Event Type and Argument Compatibilities",
        "track": "main",
        "status": "Long Main",
        "keywords": "event coreference;event coreference resolution;prompt",
        "author": "",
        "aff": "School of Computer Science and Technology, Soochow University, China",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "2;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/jsksxs360/prompt-event-coref-emnlp2023"
    },
    {
        "id": "1qJgZUAc8j",
        "title": "Exploring the Numerical Reasoning Capabilities of Language Models: A Comprehensive Analysis on Tabular Data",
        "track": "main",
        "status": "Long Findings",
        "keywords": "numerical reasoning;probing language models;numeracy;tables;tabular data",
        "author": "",
        "aff": "King\u2019s College London; University of Utah; Meesho; University of Pennsylvania",
        "rating": "",
        "confidence": "3;4;3;4",
        "correctness": "3;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/mubasharaak/numerical_reasoning"
    },
    {
        "id": "1tZxE1WPKz",
        "title": "Incorporating Object-Level Visual Context for Multimodal Fine-Grained Entity Typing",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Fine-Grained Entity Typing;Multimodal Learning.",
        "author": "",
        "aff": "College of Computer Science, VCIP, TMCC, TBI Center, Nankai University, China",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "2;5;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "219K9bcUgC",
        "title": "Does Listener Gaze in Face-to-Face Interaction Follow the Entropy Rate Constancy Principle: An Empirical Study",
        "track": "main",
        "status": "Short Findings",
        "keywords": "entropy rate constancy principle;information density;dialogue;nonverbal behaviour;gaze",
        "author": "",
        "aff": "Digital Linguistics Lab, Department Linguistics, Faculty of Linguistics and Literary Studies, Bielefeld University, Bielefeld, Germany",
        "rating": "",
        "confidence": "2;4;3",
        "correctness": "2;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "266rF9DyWk",
        "title": "Automatic Transcription of Handwritten Old Occitan Language",
        "track": "main",
        "status": "Long Main",
        "keywords": "handwritten text recognition;low-resource languages;transformer;computer vision;natural language processing",
        "author": "",
        "aff": "Munich Center for Machine Learning (MCML), LMU, Munich, Germany; Bavarian Academy of Sciences, BAdW, Munich, Germany; Department of Statistics, LMU, Munich, Germany",
        "rating": "",
        "confidence": "5;5;1",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://huggingface.co/misoda"
    },
    {
        "id": "27HNeESZQF",
        "title": "PromptARA: Improving Deep Representation in Hybrid Automatic Readability Assessment with Prompt and Orthogonal Projection",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Readability assessment; Deep learning; Prompt learning; Orthogonal projection layer; Linguistic feature",
        "author": "",
        "aff": "School of Digital Industry, Jiangxi Normal University; School of Foreign Languages, JiangXi University of Science and Technology; School of Computer and Information Science, Jiangxi Normal University",
        "rating": "",
        "confidence": "4;4;3;5",
        "correctness": "3;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "2AF1OrD7Y1",
        "title": "Rethinking Word-Level Auto-Completion in Computer-Aided Translation",
        "track": "main",
        "status": "Long Main",
        "keywords": "machine translation;interactive machine translation;computer assisted translation;word level auto completion",
        "author": "",
        "aff": "Shanghai Jiao Tong University, China; Tencent AI Lab, China",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/galaxyChen/WLAC-Joint-Training"
    },
    {
        "id": "2FDty4mLqP",
        "title": "Open Information Extraction via Chunks",
        "track": "main",
        "status": "Long Main",
        "keywords": "Information Extraction;sentence chunking",
        "author": "",
        "aff": "School of Computer Science and Engineering, Nanyang Technological University, Singapore; A*STAR Centre for Frontier AI Research, Singapore; Institute for Infocomm Research, A*STAR, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "To be available upon paper acceptance"
    },
    {
        "id": "2IfYI3dkX7",
        "title": "RexUIE: A Recursive Method with Explicit Schema Instructor for Universal Information Extraction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Universal Information Extraction;Few-Shot Learning",
        "author": "",
        "aff": "College of Computer Science and Technology, Zhejiang University; Guanghua Law School, Zhejiang University; Damo Academy, Alibaba Group; College of Computer Science and Technology, Zhejiang University, Shanghai Institute for Advanced Study of Zhejiang University",
        "rating": "",
        "confidence": "5;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "2KTvN4Edvl",
        "title": "Guideline Learning for In-Context Information Extraction",
        "track": "main",
        "status": "Long Main",
        "keywords": "information extraction;in-context learning;large language models",
        "author": "",
        "aff": "University of Chinese Academy of Sciences, Beijing 100049, China; Peng Cheng Laboratory, Shenzhen 518066, China; Key Lab of Intelligent Information Processing of Chinese Academy of Sciences (CAS), Institute of Computing Technology, CAS, Beijing 100190, China",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "2MDPYm3FPl",
        "title": "Hallucination Detection for Generative Large Language Models by Bayesian Sequential Estimation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Hallucination dectection;fact checking;Bayesian sequential estimation;generative large language models",
        "author": "",
        "aff": "Alibaba Group; School of Computer Science, Fudan University, Shanghai, China; Shanghai Key Laboratory of Intelligent Information Processing",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/xhwang22/HallucinationDetection"
    },
    {
        "id": "2MXXycs2T6",
        "title": "QADYNAMICS: Training Dynamics-Driven Synthetic QA Diagnostic for Zero-Shot Commonsense Question Answering",
        "track": "main",
        "status": "Short Findings",
        "keywords": "commonsense reasoning;question-answering;training dynamics;zero shot",
        "author": "",
        "aff": "Department of Computer Science and Engineering, HKUST, Hong Kong SAR, China",
        "rating": "",
        "confidence": "3;5;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/HKUST-KnowComp/QaDynamics"
    },
    {
        "id": "2MiTZxLFA9",
        "title": "GRACE: Discriminator-Guided Chain-of-Thought Reasoning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "chain-of-thought;guided decoding;math reasoning;symbolic reasoning;multi-step reasoning;large language models",
        "author": "",
        "aff": "LG AI Research; University of Michigan; University of Illinois at Chicago",
        "rating": "",
        "confidence": "5;3;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/mukhal/grace"
    },
    {
        "id": "2O39az85g6",
        "title": "Exploring Context-Aware Evaluation Metrics for Machine Translation",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Machine Translation;Automatic Evaluation Metric;Context Awareness",
        "author": "",
        "aff": "Wangxuan Institute of Computer Technology, Peking University",
        "rating": "",
        "confidence": "4;4;3;4",
        "correctness": "3;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "2Rdfdri2oT",
        "title": "Making Large Language Models Better Data Creators",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Model;Data Creation",
        "author": "",
        "aff": "Microsoft Research; Information Sciences Institute, University of Southern California",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "2TtN6DqjWa",
        "title": "Learning Interpretable Style Embeddings via Prompting LLMs",
        "track": "main",
        "status": "Long Findings",
        "keywords": "style;stylometry;representation learning;embeddings;vectors;interpretability;prompting;llm",
        "author": "",
        "aff": "Columbia University; University of Pennsylvania",
        "rating": "",
        "confidence": "5;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "2U9hDBaOCn",
        "title": "Specialist or Generalist? Instruction Tuning for Specific NLP Tasks",
        "track": "main",
        "status": "Long Main",
        "keywords": "LLMs;Instruction Tuning;Data Efficiency",
        "author": "",
        "aff": "Tsinghua Shenzhen International Graduate School, Tsinghua University; Language Technology Lab, University of Cambridge; Tencent AI Lab",
        "rating": "",
        "confidence": "2;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/DavidFanzz/Generalist_or_Specialist"
    },
    {
        "id": "2UJvVc8gnP",
        "title": "Masked Path Modeling for Vision-and-Language Navigation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Vision-and-Language Navigation;Masked Data Modeling",
        "author": "",
        "aff": "University of California, Los Angeles; Amazon Alexa AI",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/PlusLabNLP/mpm"
    },
    {
        "id": "2WZ4Wp1OSo",
        "title": "Building Multi-domain Dialog State Trackers from Single-domain Dialogs",
        "track": "main",
        "status": "Long Main",
        "keywords": "dialog state tracking;multi-domain dialog;conversational query rewrite",
        "author": "",
        "aff": "The CoAI Group, DCST, Institute for Artificial Intelligence, State Key Lab of Intelligent Technology and Systems, Beijing National Research Center for Information Science and Technology, Tsinghua University, Beijing 100084, China",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "2X5RXTOsLU",
        "title": "Dialect Transfer for Swiss German Speech Translation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "speech to text;speech translation;swiss german;low resource",
        "author": "",
        "aff": "University of Applied Sciences and Arts Northwestern Switzerland, Windisch; Zurich University of Applied Sciences, Winterthur",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "2XDbDwNlTn",
        "title": "FACTIFY3M: A benchmark for multimodal fact verification with explainability through 5W Question-Answering",
        "track": "main",
        "status": "Long Main",
        "keywords": "Multimodality;Fact Verification;Disinformation;Explainability",
        "author": "",
        "aff": "UCLA, USA; University of South Carolina, USA; Amazon AI, USA; Stanford University, USA",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "2YEY9SPVEA",
        "title": "Task-Adaptive Tokenization: Enhancing Long-Form Text Generation Efficacy in Mental Health and Beyond",
        "track": "main",
        "status": "Long Main",
        "keywords": "task-adaptive tokenization;text generation;long-form generation;text segmentation",
        "author": "",
        "aff": "The CoAI group, Tsinghua University, Beijing; Language and Information Technologies Lab (LIT), Department of Computer Science and Engineering, University of Michigan, Ann Arbor",
        "rating": "",
        "confidence": "3;2;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "github.com/MichiganNLP/task-adaptive_tokenization"
    },
    {
        "id": "2anfut5geh",
        "title": "Challenges in Context-Aware Neural Machine Translation",
        "track": "main",
        "status": "Long Main",
        "keywords": "neural machine translation;document-level neural machine translation;context-aware neural machine translation",
        "author": "",
        "aff": "University of Washington; Information Sciences Institute, University of Southern California",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Linghao-Jin/canmt-challenges"
    },
    {
        "id": "2b7aSGxb6M",
        "title": "MSCFFN: A New FFN with Multi-Space Cross to Accelerate Transformer",
        "track": "main",
        "status": "Short Findings",
        "keywords": "New FFN structure;MSCFFN;Multi-Space Cross method;Accelerate Transformers",
        "author": "",
        "aff": "Du Xiaoman Financial, Beijing, China; Beihang University, Beijing, China; Du Xiaoman Financial, Beijing, China",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "2;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/henriTang/Transformer_Speed"
    },
    {
        "id": "2bBIY12n43",
        "title": "A State-Vector Framework for Dataset Effects",
        "track": "main",
        "status": "Long Main",
        "keywords": "data influence;probing;fine-tuning;multi-task learning;datasets",
        "author": "",
        "aff": "University of Toronto, Vector Institute for Artificial Intelligence, Dalhousie University; University of Toronto, Vector Institute for Artificial Intelligence",
        "rating": "",
        "confidence": "4;2;4",
        "correctness": "4;3;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "2c3u5YDUUy",
        "title": "MTGER: Multi-view Temporal Graph Enhanced Temporal Reasoning over Time-Involved Document",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Question Answering;Temporal Reasoning;Natural Language Processing",
        "author": "",
        "aff": "Harbin Institute of Technology, Harbin, China; Peng Cheng Laboratory, Shenzhen, China; Harbin Institute of Technology, Harbin, China",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "2hYi3mXxqf",
        "title": "T-Projection: High Quality Annotation Projection for Sequence Labeling Tasks",
        "track": "main",
        "status": "Long Findings",
        "keywords": "annotation projection;low-resource;sequence labeling;text2text language models;machine translation;automatic data generation",
        "author": "",
        "aff": "HiTZ Center - Ixa, University of the Basque Country UPV/EHU",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ikergarcia1996/T-Projection"
    },
    {
        "id": "2jibzAXJzH",
        "title": "T5Score: Discriminative Fine-tuning of Generative Evaluation Metrics",
        "track": "main",
        "status": "Long Findings",
        "keywords": "text generation;evaluation",
        "author": "",
        "aff": "New York University; Carnegie Mellon University",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://anonymous.4open.science/r/T5Score-F21D"
    },
    {
        "id": "2kSufHoYEi",
        "title": "NORMSAGE: Multi-Lingual Multi-Cultural Norm Discovery from Conversations On-the-Fly",
        "track": "main",
        "status": "Long Main",
        "keywords": "social norms;discovery;grounding",
        "author": "",
        "aff": "University of Illinois Urbana-Champaign; Stony Brook University; Columbia University",
        "rating": "",
        "confidence": "3;4;5",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/..."
    },
    {
        "id": "2lI1pVL6aj",
        "title": "CRAB: Assessing the Strength of Causal Relationships Between Real-world Events",
        "track": "main",
        "status": "Long Main",
        "keywords": "causal reasoning;benchmark;causal score;event causality",
        "author": "",
        "aff": "EPFL",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/epfl-nlp/CRAB"
    },
    {
        "id": "2mxzS2Xv2e",
        "title": "A Causal View of Entity Bias in (Large) Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "entity bias;knowledge conflicts;causal analysis;large language models",
        "author": "",
        "aff": "University of California, Los Angeles; University of California, Davis; University of Southern California",
        "rating": "",
        "confidence": "3;3;2",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/luka-group/Causal-View-of-Entity-Bias"
    },
    {
        "id": "2prcotJejU",
        "title": "Prompting with Pseudo-Code Instructions",
        "track": "main",
        "status": "Long Main",
        "keywords": "Instruction Finetuning;Pseudo-Code Instructions;Large Language Model",
        "author": "",
        "aff": "IBM Research AI",
        "rating": "",
        "confidence": "4;4;4;3",
        "correctness": "3;4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/mayank31398/pseudo-code-instructions"
    },
    {
        "id": "2qKRa94sow",
        "title": "Connecting degree and polarity: An artificial language learning study",
        "track": "main",
        "status": "Long Main",
        "keywords": "semantics;degree;polarity;artificial language learning",
        "author": "",
        "aff": "University of Groningen; Spotify, United Kingdom; Inworld.AI, Germany",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "2wFVkTDGOZ",
        "title": "Emptying the Ocean with a Spoon: Should We Edit Models?",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Model Editing;LLMs;Factual Knowledge;Continual Learning;Knowledge Representation;Opinion Paper",
        "author": "",
        "aff": "Department of Computer Science, Ben-Gurion University of the Negev, Be\u2019er Sheva, Israel",
        "rating": "",
        "confidence": "4;4;4;5",
        "correctness": "2;2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "2z4s0W375H",
        "title": "Tuna: Instruction Tuning using Feedback from Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large Lanugage Models; Instruction Tuning",
        "author": "",
        "aff": "Microsoft Research Asia; StatNLP Research Group, Singapore University of Technology and Design; Tsinghua University",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/microsoft/LMOps"
    },
    {
        "id": "2z9o8bMQNd",
        "title": "Conversation Understanding using Relational Temporal Graph Neural Networks with Auxiliary Cross-Modality Interaction",
        "track": "main",
        "status": "Long Main",
        "keywords": "Multimodal Emotion Recognition;Relational Temporal GNNs;Conversation Understanding;Pairwise Cross Modality",
        "author": "",
        "aff": "VNU University of Engineering and Technology, Hanoi, Vietnam",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "30kbnyD9hF",
        "title": "Exchange-of-Thought: Enhancing Large Language Model Capabilities through Cross-Model Communication",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Models; Model Communication; Chain-of-Thought",
        "author": "",
        "aff": "School of Computer Science, Fudan University; National University of Singapore",
        "rating": "",
        "confidence": "2;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "33aJCNQV1C",
        "title": "A linear time approximation of Wasserstein distance with word embedding selection",
        "track": "main",
        "status": "Long Main",
        "keywords": "optimal transport;group feature selection;document classification;word embedding",
        "author": "",
        "aff": "Kyoto University, Japan; Okinawa Institute of Science and Technology, Japan",
        "rating": "",
        "confidence": "3;4;2",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "377w7agYKC",
        "title": "CoRec: An Easy Approach for Coordination Recognition",
        "track": "main",
        "status": "Short Main",
        "keywords": "coordination recognition;shallow parsing",
        "author": "",
        "aff": "Department of Computer Science, Iowa State University, Ames, Iowa, USA",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/qingwang-isu/CoRec"
    },
    {
        "id": "38k1q1yyCe",
        "title": "Crossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss Weighting",
        "track": "main",
        "status": "Long Main",
        "keywords": "machine translation;idioms;multi-word expressions;retrieval-based machine translation",
        "author": "",
        "aff": "Carnegie Mellon University; Google Research",
        "rating": "",
        "confidence": "4;4;4;3",
        "correctness": "4;2;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/nightingal3/idiom-translation/"
    },
    {
        "id": "3AxESAk0Re",
        "title": "STAIR: Learning Sparse Text and Image Representation in Grounded Tokens",
        "track": "main",
        "status": "Long Main",
        "keywords": "Image text retrieval;sparse embedding;interpretability",
        "author": "",
        "aff": "Apple AI/ML",
        "rating": "",
        "confidence": "3;4;5",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "3CIQIYNGlp",
        "title": "Exploring the Impact of Model Scaling on Parameter-Efficient Tuning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Parameter-efficient fine-tuning;Pre-trained language model",
        "author": "",
        "aff": "Department of Computer Science and Technology, Tsinghua University; Gaoling School of Artificial Intelligence, Renmin University; Ping An Technology; University of Massachusetts Lowell",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/yushengsu-thu/PET_Scaling"
    },
    {
        "id": "3EcjsgPq74",
        "title": "Towards A Unified View of Sparse Feed-Forward Network in Pretraining Large Language Model",
        "track": "main",
        "status": "Long Main",
        "keywords": "Mixture-of-Experts;Efficiency;Transformer;Architecture;Pretraining;LLM",
        "author": "",
        "aff": "Meta AI; University of Washington, Seattle",
        "rating": "",
        "confidence": "2;3;3;3",
        "correctness": "3;4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "3ErwybEDgt",
        "title": "DiQAD: A Benchmark Dataset for Open-domain Dialogue Quality Assessment",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Dataset;Dialogue Evaluation Dataset;Dialogue Quality Assessment;Dialogue Quality Evaluation;Dialogue Quality Benchmark;Dialogue Evaluation",
        "author": "",
        "aff": "Baidu Inc., Beijing, China; Leiden University, Leiden, The Netherlands; Shandong University, Qingdao, China",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/yukunZhao/Dataset_Dialogue_quality_evaluation"
    },
    {
        "id": "3F1qEXWKFE",
        "title": "PIVOINE: Instruction Tuning for Open-world Entity Profiling",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large Language Model;Information Extraction;Instruction Tuning",
        "author": "",
        "aff": "University of Southern California, Los Angeles, CA; Tencent AI Lab, Bellevue, WA",
        "rating": "",
        "confidence": "4;5;3;5",
        "correctness": "3;3;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Lukeming-tsinghua/Instruction-Tuning-for-Open-world-IE"
    },
    {
        "id": "3FNrGv5MKb",
        "title": "$k$NN-LM Does Not Improve Open-ended Text Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "retrieval-augmented language model;text generation;text generation evaluation;kNN-LM",
        "author": "",
        "aff": "University of Massachusetts Amherst; Adobe Research",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "3I1A9xAI8S",
        "title": "Dr ChatGPT tell me what I want to hear: How different prompts impact health answer correctness",
        "track": "main",
        "status": "Long Main",
        "keywords": "ChatGPT;LLM;Health Misinformation;Prompt Knowledge;Consumer Health",
        "author": "",
        "aff": "CSIRO and The University of Queensland, Brisbane, Australia; The University of Queensland, Brisbane, Australia",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ielab/drChatGPT-health_prompting"
    },
    {
        "id": "3JBKnkUACW",
        "title": "Sub-network Discovery and Soft-masking for Continual Learning of Mixed Tasks",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Continual Learning;Heterogeneous Tasks;Sub-network Discovery",
        "author": "",
        "aff": "Meta; Department of Computer Science, University of Illinois at Chicago",
        "rating": "",
        "confidence": "4;4;2",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ZixuanKe/PyContinual"
    },
    {
        "id": "3JP1Jsng4G",
        "title": "mReFinED: An Efficient End-to-End Multilingual Entity Linking System",
        "track": "main",
        "status": "Short Findings",
        "keywords": "entity linking;multilingual;end-to-end",
        "author": "",
        "aff": "School of Information Science and Technology, VISTEC, Thailand; Amazon",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/amazon-science/ReFinED/tree/mrefined"
    },
    {
        "id": "3LIUMrCKrv",
        "title": "It Ain't Over: A Multi-aspect Diverse Math Word Problem Dataset",
        "track": "main",
        "status": "Long Main",
        "keywords": "Math Word Problem;Arithmetic Reasonong;Natural Language Processing;Dataset;Large Language Model",
        "author": "",
        "aff": "Sungkyunkwan University, Republic of Korea",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/JiwooKimAR/dmath"
    },
    {
        "id": "3LdaPmAnji",
        "title": "EDeR: Towards Understanding Dependency Relations Between Events",
        "track": "main",
        "status": "Long Main",
        "keywords": "dataset;event dependency relation",
        "author": "",
        "aff": "Australian National University; Tencent AI lab",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "3MEV3aIDDq",
        "title": "Can Pre-trained Vision and Language Models Answer Visual Information-Seeking Questions?",
        "track": "main",
        "status": "Long Main",
        "keywords": "visual question answering;vision and language;pre-trained multimodal model",
        "author": "",
        "aff": "Georgia Institute of Technology; Google Deepmind; Google Research",
        "rating": "",
        "confidence": "2;3;5",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://open-vision-language.github.io/infoseek/",
        "github": ""
    },
    {
        "id": "3Nq9KRcvx5",
        "title": "DiNeR: A Large Realistic Dataset for Evaluating Compositional Generalization",
        "track": "main",
        "status": "Long Main",
        "keywords": "compositional generalization;dish name recognition;large realistic dataset;language model evaluation",
        "author": "",
        "aff": "Wangxuan Institute of Computer Technology, Peking University",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "3OvLxe9n9S",
        "title": "Dialogue Act-Aided Backchannel Prediction Using Multi-Task Learning",
        "track": "main",
        "status": "Short Findings",
        "keywords": "backchannel prediction;multi-task learning;dialogue act;pre-trained audio encoder;voice activity projection",
        "author": "",
        "aff": "Department of Computer Engineering, Chungnam National University; Department of Radio and Information Communications Engineering, Chungnam National University",
        "rating": "",
        "confidence": "4;2;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "3Q6LON8y2I",
        "title": "Is ChatGPT Good at Search? Investigating Large Language Models as Re-Ranking Agents",
        "track": "main",
        "status": "Long Main",
        "keywords": "Passage Re-ranking;Information Retrieval;Large Language Models",
        "author": "",
        "aff": "Baidu Inc., Beijing, China; Leiden University, Leiden, The Netherlands; Shandong University, Qingdao, China",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "www.github.com/sunnweiwei/RankGPT"
    },
    {
        "id": "3QibSyz6Qt",
        "title": "NarrativeXL: a Large-scale Dataset for Long-Term Memory Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "NLP;long-term memory;long term memory;reading comprehension",
        "author": "",
        "aff": "Santa Fe Institute / Santa Fe, NM; University of California, Irvine / Irvine, CA",
        "rating": "",
        "confidence": "5;3;3;3",
        "correctness": "3;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "Not provided",
        "github": "Not provided"
    },
    {
        "id": "3QzTzulZwY",
        "title": "IMTLab: An Open-Source Platform for Building, Evaluating, and Diagnosing Interactive Machine Translation Systems",
        "track": "main",
        "status": "Long Main",
        "keywords": "Interactive Machine Translation; Neural Machine Translation; Lexical-constrained Translation",
        "author": "",
        "aff": "University of Science and Technology of China; Shanghai Jiao Tong University; National Key Laboratory for Novel Software Technology, Nanjing University; Tencent AI Lab",
        "rating": "",
        "confidence": "4;5;2",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "3RS2T9EPjI",
        "title": "In-Image Neural Machine Translation with Segmented Pixel Sequence-to-Sequence Model",
        "track": "main",
        "status": "Long Findings",
        "keywords": "In-Image Machine Translation;Neural Machine Translation",
        "author": "",
        "aff": "School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China; School of Computer Science and Engineering, Beihang University, Beijing, 100191, China; Xiaomi AI Lab, Beijing, China",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/YanzhiTian/E2E-IIMT"
    },
    {
        "id": "3RTpKMVg0P",
        "title": "Privacy Implications of Retrieval-Based Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Privacy;Retrieval-based language models",
        "author": "",
        "aff": "Princeton University",
        "rating": "",
        "confidence": "3;1;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Princeton-SysML/kNNLM_privacy"
    },
    {
        "id": "3Uu4rZ6hLI",
        "title": "Unveiling the Essence of Poetry: Introducing a Comprehensive Dataset and Benchmark for Poem Summarization",
        "track": "main",
        "status": "Short Main",
        "keywords": "Poem summarization;Creative language summarization;Creative language interpretation;Natural language understanding;Automatic text summarization;Language models",
        "author": "",
        "aff": "York University, Dialpad Canada Inc.; Islamic University of Technology",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Ridwan230/PoemSum"
    },
    {
        "id": "3XDDWCu8CF",
        "title": "A Simple Baseline for Knowledge-Based Visual Question Answering",
        "track": "main",
        "status": "Short Main",
        "keywords": "Knowledge-based Visual Question Answering (KB-VQA);Commonsense Reasoning;Few-shot learning",
        "author": "",
        "aff": "Athens University of Economics and Business; Queen Mary University of London",
        "rating": "",
        "confidence": "4;3;2",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/alexandrosXe/A-Simple-Baseline-For-Knowledge-Based-VQA"
    },
    {
        "id": "3aF1Rv3dHG",
        "title": "One-Model-Connects-All: A Unified Graph Pre-Training Model for Online Community Modeling",
        "track": "main",
        "status": "Long Findings",
        "keywords": "community;pre-train;graph",
        "author": "",
        "aff": "School of Data Science, Fudan University, China; Research Institute of Intelligent Complex Systems, Fudan University, China; School of Computer Science, Fudan University, China; School of Management, Fudan University, China; School of Data Science, Fudan University, China; Huawei Technologies Co.,Ltd, China",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "3;3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "3dNeNpmyiO",
        "title": "Learning to Describe for Predicting Zero-shot Drug-Drug Interactions",
        "track": "main",
        "status": "Long Main",
        "keywords": "Reinforcement Learning;Prompt Learning;Drug-Drug Interaction",
        "author": "",
        "aff": "Hong Kong University of Science and Technology (GZ), Guang Zhou, China; 4Paradigm Inc., Beijing, China; Harbin Institute of Technology, Shenzhen, China; Guangdong Provincial Key Laboratory of Novel Security Intelligence Technologies; Peng Cheng Laboratory, Shenzhen, China; Harbin Institute of Technology, Shenzhen, China",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/zhufq00/DDIs-Prediction"
    },
    {
        "id": "3e8rcsIO7H",
        "title": "Dense Retrieval as Indirect Supervision for Large-space Decision Making",
        "track": "main",
        "status": "Long Findings",
        "keywords": "large decision spaces;dense retrieval;extreme multi-label classification;ultra-fine entity typing;few-shot intent classification",
        "author": "",
        "aff": "University of California, Davis; University of Southern California",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/luka-group/DDR"
    },
    {
        "id": "3gdG9upo7e",
        "title": "Generative Table Pre-training Empowers Models for Tabular Prediction",
        "track": "main",
        "status": "Long Main",
        "keywords": "tabular prediction;generative table pre-training",
        "author": "",
        "aff": "Sea AI Lab; Skywork AI; Fudan University; Tsinghua University",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ZhangTP1996/TapTap"
    },
    {
        "id": "3k5GFJEGem",
        "title": "ParroT: Translating during Chat using Large Language Models tuned with Human Translation and Feedback",
        "track": "main",
        "status": "Long Findings",
        "keywords": "machine translation;instruction tuning;LoRA;human feedback;LLaMA;BLOOMZ;ChatGPT;GPT-4",
        "author": "",
        "aff": "Shanghai Jiao Tong University; Tsinghua Shenzhen International Graduate School; Tencent AI Lab; The Chinese University of Hong Kong",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/wxjiao/ParroT"
    },
    {
        "id": "3l9zUuFo9m",
        "title": "Cache me if you Can: an Online Cost-aware Teacher-Student framework to Reduce the Calls to Large Language Models",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Online Learning;Cost-Efficient;LLMs Applications;Caching;Teacher-Student",
        "author": "",
        "aff": "Department of Informatics, Athens University of Economics and Business, Greece; Helvia.ai; Department of Informatics, Athens University of Economics and Business, Greece; Archimedes Unit, Athena Research Center, Greece; Department of Informatics, Athens University of Economics and Business, Greece; Workable; Helvia.ai",
        "rating": "",
        "confidence": "5;3;2",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "3pvdo2yHXq",
        "title": "Speech-enriched Memory for Inference-time Adaptation of ASR Models to Word Dictionaries",
        "track": "main",
        "status": "Long Main",
        "keywords": "ASR Adaptation;Inference-time adaptation;Contextual Biasing",
        "author": "",
        "aff": "IIT Bombay2; IBM Research1, IIT Bombay2; IBM Research1",
        "rating": "",
        "confidence": "4;3;3;3",
        "correctness": "4;4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "3qF5MqUl3Y",
        "title": "R2H: Building Multimodal Navigation Helpers that Respond to Help Requests",
        "track": "main",
        "status": "Long Main",
        "keywords": "Multimodal Understanding;Embodied AI;Vision-and-language Navigation",
        "author": "",
        "aff": "University of California, Santa Cruz",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://sites.google.com/view/response2helprequests/home",
        "github": ""
    },
    {
        "id": "3qG4r6FGWD",
        "title": "Aligning Predictive Uncertainty with Clarification Questions in Grounded Dialog",
        "track": "main",
        "status": "Long Findings",
        "keywords": "predictive uncertainty;calibration;grounded dialog;clarification question;instruction following;collaborative dialog",
        "author": "",
        "aff": "Language Technology Lab, University of Amsterdam; University of Amsterdam",
        "rating": "",
        "confidence": "3;4;3;2",
        "correctness": "4;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "3u3kXSeVvR",
        "title": "Viewing Knowledge Transfer in Multilingual Machine Translation Through a Representational Lens",
        "track": "main",
        "status": "Long Findings",
        "keywords": "multilingual machine translation;cross-lingual knowledge transfer",
        "author": "",
        "aff": "Language Technology Lab, University of Amsterdam",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "3ymHqvobHJ",
        "title": "Cross-lingual Open-Retrieval Question Answering for African Languages",
        "track": "main",
        "status": "Long Findings",
        "keywords": "African Languages;Question Answering;Information Retrieval;Low-resource Languages",
        "author": "",
        "aff": "",
        "rating": "",
        "confidence": "3;4;5",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "40NCUv4I2R",
        "title": "Enhancing Text-to-SQL Capabilities of Large Language Models: A Study on Prompt Design Strategies",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Text-to-SQL;Few-shot;Zero-shot;In-context Learning;Large Language Models",
        "author": "",
        "aff": "Yale University; Allen Institute for AI; Columbia University",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "41vXNjZbIn",
        "title": "Improving Input-label Mapping with Demonstration Replay for In-context Learning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "in-context learning;causal language modeling",
        "author": "",
        "aff": "Gaoling School of Artificial Intelligence, Renmin University of China; Wangxuan Institute of Computer Technology, Peking University; National Key Laboratory of General Artificial Intelligence; Beijing Institute for General Artificial Intelligence; Meituan; Meta AI; Wangxuan Institute of Computer Technology, Peking University",
        "rating": "",
        "confidence": "4;5;4;3",
        "correctness": "4;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "4272bEn4Q0",
        "title": "Large Language Models are Complex Table Parsers",
        "track": "main",
        "status": "Long Main",
        "keywords": "Complex Table QA;GPT-3.5;Large language models",
        "author": "",
        "aff": "Children\u2019s Hospital of Fudan University, National Children\u2019s Medical Center, Shanghai, China; Academy for Engineering and Technology, Fudan University, Shanghai, China; School of Computer Science, Shanghai Key Laboratory of Intelligent Information Processing, Fudan University, Shanghai 200433, China; Academy for Engineering and Technology, Fudan University, Shanghai, China; Children\u2019s Hospital of Fudan University, National Children\u2019s Medical Center, Shanghai, China; School of Computer Science, Shanghai Key Laboratory of Intelligent Information Processing, Fudan University, Shanghai 200433, China",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "42Cc5s71zl",
        "title": "D$^2$TV: Dual Knowledge Distillation and Target-oriented Vision Modeling for Many-to-Many Multimodal Summarization",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multimodal Summarization; Cross-lingual Summarization; Many-to-many Multimodal Summarization",
        "author": "",
        "aff": "School of Computer Science and Technology, Soochow University, Suzhou, China; Beijing Key Lab of Traffic Data Analysis and Mining, Beijing Jiaotong University, Beijing, China; Pattern Recognition Center, WeChat AI, Tencent Inc, China",
        "rating": "",
        "confidence": "2;3;4;4",
        "correctness": "3;2;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/XL2248/D2TV"
    },
    {
        "id": "42LIoV0C1h",
        "title": "Qualitative Code Suggestion: A Human-Centric Approach to Qualitative Coding",
        "track": "main",
        "status": "Long Findings",
        "keywords": "qualitative coding;human-centric",
        "author": "",
        "aff": "McGill University, Mila Quebec AI Institute",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "43SOcneD8W",
        "title": "Chain-of-Thought Tuning: Masked Language Models can also Think Step By Step in Natural Language Understanding",
        "track": "main",
        "status": "Long Main",
        "keywords": "masked language models;multi-step reasoning;Chain-of-Thought;natural language understanding",
        "author": "",
        "aff": "MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University; School of Software Engineering, Sun Yat-sen University",
        "rating": "",
        "confidence": "2;3;3;4",
        "correctness": "4;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "45uZxlMLol",
        "title": "Annotation Sensitivity: Training Data Collection Methods Affect Model Performance",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Annotation sensitivity;human annotation;annotation instrument;task structure effects",
        "author": "",
        "aff": "University of Maryland, College Park; LMU Munich; RTI International",
        "rating": "",
        "confidence": "3;5;4",
        "correctness": "4;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "46WcPRhRwG",
        "title": "Evaluating and Enhancing the Robustness of Code Pre-trained Models through Structure-Aware Adversarial Samples Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Neural Code Intelligence;Pre-trained Language Models;Adversarial Attack",
        "author": "",
        "aff": "East China Normal University, Shanghai, China; Institute for Infocomm Research, A*STAR, Singapore",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/nchen909/CodeRobustness"
    },
    {
        "id": "49HfhYU9S6",
        "title": "Assessing Step-by-Step Reasoning against Lexical Negation: A Case Study on Syllogism",
        "track": "main",
        "status": "Short Main",
        "keywords": "Negation;Prompting;Reasoning;Language model;Model Analysis;Probing;Chain-of-thought",
        "author": "",
        "aff": "Tohoku University; Tohoku University, RIKEN; MBZUAI",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/muyo8692/stepbystep-reasoning-vs-negation"
    },
    {
        "id": "4AcHxGE6M4",
        "title": "CP-BCS: Binary Code Summarization Guided by Control Flow Graph and Pseudo Code",
        "track": "main",
        "status": "Long Main",
        "keywords": "binary code summarization",
        "author": "",
        "aff": "Anytime.AI; Stony Brook University; Zhejiang University",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "4AiERjB5JD",
        "title": "Prefix-Tuning Based Unsupervised Text Style Transfer",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Unsupervised text style transfer;Prefix-Tuning",
        "author": "",
        "aff": "Peking University; Guangming Laboratory",
        "rating": "",
        "confidence": "5;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "4EXbwN9Ezw",
        "title": "A Boundary Offset Prediction Network for Named Entity Recognition",
        "track": "main",
        "status": "Long Findings",
        "keywords": "named entity recognition;span-based methods;boundary connections;boundary offset prediction network;type-related boundary offsets",
        "author": "",
        "aff": "Institute of Information Engineering, CAS, China; Meituan, China",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "4FDx4KMZnu",
        "title": "Mixture of Soft Prompts for Controllable Data Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "data augmentation;parameter efficient training;few-shot learning;structured prediction",
        "author": "",
        "aff": "Cornell University; Scite AI; Columbia University",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "4Ggw1DsgRQ",
        "title": "Enhancing Computation Efficiency in Large Language Models through Weight and Activation Quantization",
        "track": "main",
        "status": "Long Main",
        "keywords": "Post-training quantization;LLM;Transformers;Numerical format",
        "author": "",
        "aff": "SAPEON Korea Inc.; Seoul National University; Hanyang University",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "4GmujJSuq0",
        "title": "What to Read in a Contract? Party-Specific Summarization of Legal Obligations, Entitlements, and Prohibitions",
        "track": "main",
        "status": "Long Main",
        "keywords": "Legal NLP;Rights and Obligation Extraction;Summarization;Importance Ranking",
        "author": "",
        "aff": "\u2020University of Maryland, College Park; \u2021Adobe Research; \u2020University of Maryland, College Park; \u2021Adobe Research",
        "rating": "",
        "confidence": "5;2;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "http://bit.ly/legal-importance",
        "github": ""
    },
    {
        "id": "4IubiozIFH",
        "title": "Exploring the Effectiveness of Multi-Lingual Commonsense Knowledge-Aware Open-Domain Dialogue Response Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "response generation;dialogue system;commonsense knowledge;multi-lingual",
        "author": "",
        "aff": "National Pilot School of Software, Yunnan University, Kunming, China; Engineering Research Center of Cyberspace, Yunnan University, Kunming, China; Auburn University, Auburn, Alabama, USA",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Y-NLP/Chatbots/tree/main/EMNLP2023_MCK-T5"
    },
    {
        "id": "4Jnjap7NSx",
        "title": "Distance-Based Propagation for Efficient Knowledge Graph Reasoning",
        "track": "main",
        "status": "Long Main",
        "keywords": "knowledge graphs;link prediction;graph neural network",
        "author": "",
        "aff": "Michigan State University; Rensselaer Polytechnic Institute; IBM T. J. Watson Research Center; Colorado School of Mines",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/HarryShomer/TAGNet"
    },
    {
        "id": "4JpybEffzH",
        "title": "Non-Autoregressive Document-Level Machine Translation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "NAT;Document-level MT;Machine Translation",
        "author": "",
        "aff": "Institute of Advanced Technology, Westlake Institute for Advanced Study; Tsinghua University; Nanyang Technological University; Zhejiang University, School of Engineering, Westlake University; School of Engineering, Westlake University",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/baoguangsheng/nat-on-doc"
    },
    {
        "id": "4KRiWsfOwn",
        "title": "Merging Experts into One: Improving Computational Efficiency of Mixture of Experts",
        "track": "main",
        "status": "Short Main",
        "keywords": "Mixture of Experts;Computational Efficiency",
        "author": "",
        "aff": "University of Maryland, College Park; University of Chinese Academy of Sciences; JD Explore Academy; The University of Sydney",
        "rating": "",
        "confidence": "5;4;3",
        "correctness": "4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Shwai-He/MEO"
    },
    {
        "id": "4M4U3uC3Iy",
        "title": "ChatCoT: Tool-Augmented Chain-of-Thought Reasoning on Chat-based Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "large language models;complex reasoning;chain-of-thought",
        "author": "",
        "aff": "School of Information, Renmin University of China; Gaoling School of Artificial Intelligence, Renmin University of China; Gaoling School of Artificial Intelligence, Renmin University of China and School of Information, Renmin University of China",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/RUCAIBOX/ChatCoT"
    },
    {
        "id": "4MjZNeTCqZ",
        "title": "UniChart: A Universal Vision-language Pretrained Model for Chart Comprehension and Reasoning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Charts;Pretraining",
        "author": "",
        "aff": "York University, Canada; Nanyang Technological University, Singapore, Salesforce AI; Nanyang Technological University, Singapore",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "4PPT1An0kY",
        "title": "Self-Ensemble of $N$-best Generation Hypotheses by Lexically Constrained Decoding",
        "track": "main",
        "status": "Short Main",
        "keywords": "Reranking;Lexically Constrained Decoding;Generation",
        "author": "",
        "aff": "Graduate School of Science and Engineering, Ehime University; Graduate School of Information Science and Technology, Osaka University",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "4WrqZlEK3K",
        "title": "LMGQS: A Large-scale Dataset for Query-focused Summarization",
        "track": "main",
        "status": "Long Findings",
        "keywords": "query-focused summarization;large-scale dataset;zero-shot summarization;large language model",
        "author": "",
        "aff": "Microsoft Azure AI",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "4aBxFtqRNa",
        "title": "GNAT: A General Narrative Alignment Tool",
        "track": "main",
        "status": "Long Main",
        "keywords": "Text Alignment",
        "author": "",
        "aff": "Department of Computer Science, Stony Brook University, NY, USA",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "4akD4Z2BBg",
        "title": "Biomedical Named Entity Recognition via Dictionary-based Synonym Generalization",
        "track": "main",
        "status": "Long Main",
        "keywords": "Biomedical named entity recognition;NER;BioNLP;Synonym Generalization",
        "author": "",
        "aff": "School of Computing Science, University of Glasgow; Language Technology Lab, University of Cambridge; Cohere",
        "rating": "",
        "confidence": "2;4;3;3",
        "correctness": "4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/fuzihaofzh/BioNER-SynGen"
    },
    {
        "id": "4dJMzjIR2k",
        "title": "Hi-ArG: Exploring the Integration of Hierarchical Argumentation Graphs in Language Pretraining",
        "track": "main",
        "status": "Long Main",
        "keywords": "computational argumentation;knowledge graph;abstract meaning representation",
        "author": "",
        "aff": "Huawei Poisson Lab; ByteDance; Fudan University",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ljcleo/Hi-ArG"
    },
    {
        "id": "4k5BcBYKAS",
        "title": "GTA: Gated Toxicity Avoidance for LM Performance Preservation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "language model;controllable text generation;toxicity avoidance;nontoxic text generation;text generation;natural language generation",
        "author": "",
        "aff": "Department of Artificial Intelligence, Ajou University, Suwon 16499, Republic of Korea; Department of Software and Computer Engineering, Ajou University, Suwon 16499, Republic of Korea",
        "rating": "",
        "confidence": "4;4;5;4",
        "correctness": "3;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "4kuLaebvKx",
        "title": "ICU: Conquering Language Barriers in Vision-and-Language Modeling by Dividing the Tasks into Image Captioning and Language Understanding",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Cross-lingual Language Understanding;Multimodality",
        "author": "",
        "aff": "Department of Computational Linguistics, University of Zurich",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/gjwubyron/ICU"
    },
    {
        "id": "4nQN6Z6OY3",
        "title": "Outlier Dimensions Encode Task Specific Knowledge",
        "track": "main",
        "status": "Short Main",
        "keywords": "outlier dimensions;LLMs;fine-tuning;interpretability",
        "author": "",
        "aff": "Brown University; University of T\u00fcbingen",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/wrudman/outlier_dimensions"
    },
    {
        "id": "4sgXjFtnqg",
        "title": "Efficient Multilingual Language Model Compression through Vocabulary Trimming",
        "track": "main",
        "status": "Long Findings",
        "keywords": "multilingual;language model;model compression;efficiency",
        "author": "",
        "aff": "Cardiff NLP, School of Computer Science and Informatics, Cardiff University, UK",
        "rating": "",
        "confidence": "2;4;5",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/asahi417/lm-vocab-trimmer"
    },
    {
        "id": "4to6zjnEQV",
        "title": "Bridging Continuous and Discrete Spaces: Interpretable Sentence Representation Learning via Compositional Operations",
        "track": "main",
        "status": "Long Main",
        "keywords": "sentence embedding;representation learning",
        "author": "",
        "aff": "Tencent AI Lab, Seattle; University of Southern California",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/jyhuang36/InterSent"
    },
    {
        "id": "4toYWE7g6U",
        "title": "ChatEdit: Towards Multi-turn Interactive Facial Image Editing via Dialogue",
        "track": "main",
        "status": "Long Main",
        "keywords": "Interactive image editing;Task-oriented dialogue",
        "author": "",
        "aff": "WATRIX.AI; NIO; University of California, Santa Barbara; Beijing University of Posts and Telecommunications",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/cuixing100876/ChatEdit"
    },
    {
        "id": "4uylA0mUkk",
        "title": "Data Factors for Better Compositional Generalization",
        "track": "main",
        "status": "Long Main",
        "keywords": "compositional generalization;data factors",
        "author": "",
        "aff": "UNC Chapel Hill",
        "rating": "",
        "confidence": "3;4;4;4",
        "correctness": "4;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/owenzx/data4comp"
    },
    {
        "id": "4wAKqlfV5t",
        "title": "Improving Multimodal Sentiment Analysis: Supervised Angular margin-based Contrastive Learning for Enhanced Fusion Representation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multimodal Sentiment Analysis;Contrastive Learning",
        "author": "",
        "aff": "National University of Singapore, Singapore; Nanyang Technological University, Singapore",
        "rating": "",
        "confidence": "4;1;3;5",
        "correctness": "4;2;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "50rXrJNqHQ",
        "title": "API-Assisted Code Generation for Question Answering on Varied Table Structures",
        "track": "main",
        "status": "Long Main",
        "keywords": "table question answering;code generation",
        "author": "",
        "aff": "Carnegie Mellon University",
        "rating": "",
        "confidence": "5;4;5",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "51BB1xOWq1",
        "title": "GenKIE: Robust Generative Multimodal Document Key Information Extraction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Key information extraction;Multimodal generative model",
        "author": "",
        "aff": "Zhejiang University; University of Michigan; National University of Defense Technology; School of Computing Science, University of Glasgow",
        "rating": "",
        "confidence": "2;5;4;3",
        "correctness": "2;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Glasgow-AI4BioMed/GenKIE"
    },
    {
        "id": "51gbtl2VxL",
        "title": "Incorporating Probing Signals into Multimodal Machine Translation via Visual Question-Answering Pairs",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multimodal machine translation;Large language models;VQA;Probing tasks",
        "author": "",
        "aff": "School of Software, Northeastern University, Shenyang, China; School of Computer Science and Engineering, Northeastern University, Shenyang, China",
        "rating": "",
        "confidence": "3;4;1;4;4",
        "correctness": "3;4;4;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.2,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/libeineu/MMT-VQA"
    },
    {
        "id": "54WhV6RTzi",
        "title": "Style-Aware Radiology Report Generation with RadGraph and Few-Shot Prompting",
        "track": "main",
        "status": "Long Findings",
        "keywords": "language model;radiology;report generation;few-shot prompting;in-context learning;radgraph",
        "author": "",
        "aff": "Harvard Medical School; John Hopkins University; Aligarh Muslim University; Jawaharlal Institute of Postgraduate Medical Education and Research; Stanford University",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "56UYArtXyA",
        "title": "FreeAL: Towards Human-Free Active Learning in the Era of Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Active learning;Large language model;Human-free zero-shot learning",
        "author": "",
        "aff": "Zhejiang University, Hangzhou, China; NetEase Fuxi AI Lab, Hangzhou, China",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Justherozen/FreeAL"
    },
    {
        "id": "57yfvVESPE",
        "title": "Tunable Soft Prompts are Messengers in Federated Learning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "federated learning",
        "author": "",
        "aff": "Alibaba Group; Sun Yat-sen University",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/alibaba/FederatedScope/tree/fedsp/federatedscope/nlp/fedsp"
    },
    {
        "id": "58jpJdPgKi",
        "title": "Representation Projection Invariance Mitigates Representation Collapse",
        "track": "main",
        "status": "Long Findings",
        "keywords": "representation learning;generalization;representation collapse",
        "author": "",
        "aff": "Amazon AI; Johns Hopkins University; University of Toronto",
        "rating": "",
        "confidence": "2;3;4;4;4",
        "correctness": "4;3;2;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.4,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/arazd/REPINA"
    },
    {
        "id": "59gI2XQPmH",
        "title": "Alignment Precedes Fusion: Open-Vocabulary Named Entity Recognition as Context-Type Semantic Matching",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Open-Vocabulary;Named Entity Recognition",
        "author": "",
        "aff": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "5Az3d5TkMJ",
        "title": "LIMIT: Language Identification, Misidentification, and Translation using Hierarchical Models in 350+ Languages",
        "track": "main",
        "status": "Long Main",
        "keywords": "language identification;resource creation;machine translation;low-resource languages",
        "author": "",
        "aff": "Department of Computer Science, George Mason University",
        "rating": "",
        "confidence": "5;5;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/magarw/limit"
    },
    {
        "id": "5BWvVIa5Uz",
        "title": "Emergent Inabilities? Inverse Scaling Over the Course of Pretraining",
        "track": "main",
        "status": "Short Findings",
        "keywords": "language models;inverse scaling;transformers;training dynamics",
        "author": "",
        "aff": "Department of Cognitive Science, University of California San Diego",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "5DUhBxRqKR",
        "title": "Drilling Down into the Discourse Structure with LLMs for Long Document Question Answering",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Long Document Question Answering;Large Language Model;Zero-shot Prompting;Evidence Retrieval",
        "author": "",
        "aff": "Adobe Research, India; University of Michigan, Ann Arbor, MI",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "5EHI2FGf1D",
        "title": "Unsupervised Binary Code Translation with Application to Code Clone Detection and Vulnerability Discovery",
        "track": "main",
        "status": "Long Findings",
        "keywords": "NLP;Neural Machine Translation;Binary Code Analysis;Vulnerability Discovery;Code Clone Detection",
        "author": "",
        "aff": "George Mason University; University of South Carolina",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "5IFMe8TuSy",
        "title": "Exploring Jiu-Jitsu Argumentation for Writing Peer Review Rebuttals",
        "track": "main",
        "status": "Long Main",
        "keywords": "Peer Reviews;Rebuttals;Attitude Roots;Jiu-Jitsu Persuasion",
        "author": "",
        "aff": "Ubiquitous Knowledge Processing Lab, Department of Computer Science and Hessian Center for AI (hessian.AI), Technical University of Darmstadt; Data Science Group, University of Hamburg",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/UKPLab/EMNLP2023_jiu_jitsu_argumentation_for_rebuttals"
    },
    {
        "id": "5K2fiOlcGG",
        "title": "Sparse Frame Grouping Network with Action Centered for Untrimmed Video Paragraph Captioning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "video paragraph captioning;transformer;grouping;action centered;contrastive learning",
        "author": "",
        "aff": "Sch. of Inf. Tech, Deakin University; Sch. of Inf. Manag. & Eng, Shanghai Key Laboratory of Financial Information Technology, Shanghai University of Finance and Economics; Sch. of Comp. Sci, Shanghai Key Laboratory of Intelligent Information Processing, Fudan University",
        "rating": "",
        "confidence": "5;3;3;4",
        "correctness": "2;3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "5NMl0TYLey",
        "title": "InfoCL: Alleviating Catastrophic Forgetting in Continual Text Classification from An Information Theoretic Perspective",
        "track": "main",
        "status": "Long Findings",
        "keywords": "continual learning;text classification",
        "author": "",
        "aff": "National Key Laboratory for Multimedia Information Processing, School of Computer Science, Peking University; Alibaba Group",
        "rating": "",
        "confidence": "2;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Yifan-Song793/InfoCL"
    },
    {
        "id": "5Ob6DsDv2V",
        "title": "A Comprehensive Evaluation of Biomedical Entity Linking Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Entity Linking;Entity Normalization;Candidate Generation;Biomedical Natural Language Processing",
        "author": "",
        "aff": "Georgia Institute of Technology; Enveda Biosciences, Georgia Institute of Technology",
        "rating": "",
        "confidence": "3;5;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/davidkartchner/biomedical-entity-linking"
    },
    {
        "id": "5PvFFNRTbp",
        "title": "A Frustratingly Easy Post-Training Quantization Scheme for LLMs",
        "track": "main",
        "status": "Long Main",
        "keywords": "Quantization;Efficient LLM;Model Compression",
        "author": "",
        "aff": "Samsung Research",
        "rating": "",
        "confidence": "3;2;4",
        "correctness": "4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/SamsungLabs/Z-Fold"
    },
    {
        "id": "5QNpjtdjD8",
        "title": "Exploring the Boundaries of GPT-4 in Radiology",
        "track": "main",
        "status": "Long Main",
        "keywords": "benchmarking GPT-4;radiology;evaluation;large language model",
        "author": "",
        "aff": "Harvard University; Microsoft Health Futures",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "5TEfD2GBUc",
        "title": "FANToM: A Benchmark for Stress-testing Machine Theory of Mind in Interactions",
        "track": "main",
        "status": "Long Main",
        "keywords": "theory of mind;benchmark;interaction;conversation;large language model;llm",
        "author": "",
        "aff": "Seoul National University; University of Washington; Carnegie Mellon University; Allen Institute for Artificial Intelligence",
        "rating": "",
        "confidence": "3;3;1;2",
        "correctness": "4;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://hyunw.kim/fantom",
        "github": ""
    },
    {
        "id": "5UW6Mivj9M",
        "title": "Let GPT be a Math Tutor: Teaching Math Word Problem Solvers with Customized Exercise Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Mathematical Reasoning;Large Languague Models;Customized Learning",
        "author": "",
        "aff": "",
        "rating": "",
        "confidence": "3;5;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "5ZHznxXCIb",
        "title": "Context-faithful Prompting for Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large language models;knowledge update;prompt",
        "author": "",
        "aff": "Microsoft Research; University of Southern California",
        "rating": "",
        "confidence": "4;3;1",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/wzhouad/context-faithful-llm"
    },
    {
        "id": "5jc17fMzqf",
        "title": "1-PAGER: One Pass Answer Generation and Evidence Retrieval",
        "track": "main",
        "status": "Long Findings",
        "keywords": "retrieval;openbook qa;generative retrieval",
        "author": "",
        "aff": "Google Deepmind; Google Research",
        "rating": "",
        "confidence": "1;4;4",
        "correctness": "2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "5kV1ZwKMeQ",
        "title": "A Confederacy of Models: a Comprehensive Evaluation of LLMs on Creative Writing",
        "track": "main",
        "status": "Long Findings",
        "keywords": "LLMs;language models;creative writing;evaluation;text generation;storytelling;creativity",
        "author": "",
        "aff": "School of Business & Creative Industries, University of the Sunshine Coast, Sunshine Coast, Australia; Universidade da Coru\u00f1a, CITIC, Department of CS and IT, 15071 A Coru\u00f1a, Spain",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "5;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "5nHLFcj7Y9",
        "title": "Text Representation Distillation via Information Bottleneck Principle",
        "track": "main",
        "status": "Long Main",
        "keywords": "knowledge distillation;text representation;text retrieval;language model",
        "author": "",
        "aff": "; Alibaba Group",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Alibaba-NLP/IBKD"
    },
    {
        "id": "5o4a4OjhQW",
        "title": "What Comes Next? Evaluating Uncertainty in Neural Text Generators Against Human Production Variability",
        "track": "main",
        "status": "Long Main",
        "keywords": "uncertainty;NLG;variability;language production;text generation",
        "author": "",
        "aff": "LMU Munich; University of Amsterdam",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/dmg-illc/nlg-uncertainty-probes"
    },
    {
        "id": "5sGLPiG1vE",
        "title": "When are Lemons Purple? The Concept Association Bias of Vision-Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "vision and language;bias",
        "author": "",
        "aff": "EPFL; Yale University",
        "rating": "",
        "confidence": "3;3;2",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "5uZQ6spv9u",
        "title": "BRAINTEASER: Lateral Thinking Puzzles for Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "commonsense reasoning;adversarial robustness;computational creativity",
        "author": "",
        "aff": "Tencent AI Lab, Bellevue, WA; Information Sciences Institute, Viterbi School of Engineering, University of Southern California; Department of Computer Science, Faculty of Science, Vrije Universiteit Amsterdam",
        "rating": "",
        "confidence": "2;3;2",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/author_or_organization/BRain_TEASER"
    },
    {
        "id": "5vOHRbLNE7",
        "title": "HierarchicalContrast: A Coarse-to-Fine Contrastive Learning Framework for Cross-Domain Zero-Shot Slot Filling",
        "track": "main",
        "status": "Long Findings",
        "keywords": "slot-filling;task-oriented dialogue;contrastive learning;cross-domain adaption;zero-shot learning",
        "author": "",
        "aff": "College of Computer Science and Technology, Zhejiang University",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "3;2;1;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ai-agi/HiCL.CTRZTCoach"
    },
    {
        "id": "5x5Vxclc1K",
        "title": "SMoP: Towards Efficient and Effective Prompt Tuning with Sparse Mixture-of-Prompts",
        "track": "main",
        "status": "Short Main",
        "keywords": "Natural Language Processing;Prompt Tuning;Parameter-Efficient Fine-tuning;Mixture-of-Experts",
        "author": "",
        "aff": "Department of Artificial Intelligence, Korea University, Seoul, Republic of Korea; BK21 FOUR R&E Center for Artificial Intelligence, Korea University, Seoul, Republic of Korea; Department of Computer Science and Engineering, Korea University, Seoul, Republic of Korea",
        "rating": "",
        "confidence": "4;4;4;3",
        "correctness": "3;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/jyjohnchoi/SMoP"
    },
    {
        "id": "63UKbaiyAe",
        "title": "Discourse Sense Flows: Modelling the Rhetorical Style of Documents across Various Domains",
        "track": "main",
        "status": "Long Findings",
        "keywords": "rhetorical style;cross-domain;discourse parsing;discourse signals;connecting phrases;sense recognition",
        "author": "",
        "aff": "Applied Computational Linguistics, Department of Linguistics, University of Potsdam, Germany",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "65teZsn7HR",
        "title": "Exploring Linguistic Properties of Monolingual BERTs with Typological Classification among Languages",
        "track": "main",
        "status": "Long Findings",
        "keywords": "interpretability;CKA;typological similarity;BERT",
        "author": "",
        "aff": "University for foreigners of Siena, Italy; University of Rome Tor Vergata, Italy; Campus Bio-Medico University of Rome, Italy; Idiap Research Institute, Switzerland",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "68A4GE4nqf",
        "title": "Evaluating Subjective Cognitive Appraisals of Emotions from Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Emotion;Cognitive Appraisal;Large Language Models",
        "author": "",
        "aff": "Department of Psychology, The University of Texas at Austin; Department of Linguistics, The University of Texas at Austin",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/honglizhan/CovidET-Appraisals-Public"
    },
    {
        "id": "6DKS4tb387",
        "title": "Gradually Excavating External Knowledge for Implicit Complex Question Answering",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Question answering;Knowledge Retrieval;Multi-step question answering;Large Language Model",
        "author": "",
        "aff": "The University of Hong Kong; Huawei Noah\u2019s Ark Lab",
        "rating": "",
        "confidence": "4;5;4;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "6DMhUhx5oy",
        "title": "Fighting Fire with Fire: The Dual Role of LLMs in Crafting and Detecting Elusive Disinformation",
        "track": "main",
        "status": "Long Main",
        "keywords": "LLM;Prompt Engineering;Disinformation Detection;Natural Language Inference;Semantic Reasoning;In-context Learning",
        "author": "",
        "aff": "The Pennsylvania State University, University Park, PA, USA; MIT Lincoln Laboratory, Lexington, MA, USA; The Pennsylvania State University, University Park, PA, USA",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/mickeymst/F3"
    },
    {
        "id": "6Jqa4YmUMf",
        "title": "Investigating the Effectiveness of Multiple Expert Models Collaboration",
        "track": "main",
        "status": "Short Findings",
        "keywords": "machine translation;multi-domain translation;multiple model collaboration",
        "author": "",
        "aff": "Tohoku University; Tohoku University, Langsmith Inc.; Tohoku University, MBZUAI; Tohoku University, RIKEN",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "6KyZrSp8y3",
        "title": "Unnatural language processing: How do language models handle machine-generated prompts?",
        "track": "main",
        "status": "Long Findings",
        "keywords": "prompting;interpretability;large language modelling;unnatural language processing",
        "author": "",
        "aff": "Universitat Pompeu Fabra (UPF) / Barcelona; UPF and ICREA / Barcelona",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "6LkytBaTy9",
        "title": "Bias Neutralization in Non-Parallel Texts: A Cyclic Approach with Auxiliary Guidance",
        "track": "main",
        "status": "Long Main",
        "keywords": "Bias Correction;Subjective Bias;Generative Adversarial Networks;Unsupervised Learning;Auxiliary Guidance",
        "author": "",
        "aff": "Texas A&M University, College Station, USA",
        "rating": "",
        "confidence": "4;2;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "6P32h3LTC1",
        "title": "A Multi-Modal Multilingual Benchmark for Document Image Classification",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Document AI;layout-aware models;visually-rich document understanding;multilingual document image classification",
        "author": "",
        "aff": "AWS AI Labs",
        "rating": "",
        "confidence": "4;5;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://huggingface.co/datasets/AmazonScience/MultilingualMultiModalClassification",
        "github": ""
    },
    {
        "id": "6RQTvSLbgi",
        "title": "IEKG: A Commonsense Knowledge Graph for Idiomatic Expressions",
        "track": "main",
        "status": "Long Main",
        "keywords": "idiomatic expression;figurative semantics;commonsense knowledge;idiomatic expression comprehension;natural language understanding",
        "author": "",
        "aff": "University of Illinois Urbana-Champaign; Princeton University; Washington University in St. Louis",
        "rating": "",
        "confidence": "3;2;2",
        "correctness": "4;3;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "6RuXWFEQzg",
        "title": "Open-world Semi-supervised Generalized Relation Discovery Aligned in a Real-world Setting",
        "track": "main",
        "status": "Long Main",
        "keywords": "Information extraction;relation extraction",
        "author": "",
        "aff": "Department of Computer Science & Engineering, University of California, San Diego",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "6UklbMESHZ",
        "title": "An Empirical Investigation of Implicit and Explicit Knowledge-Enhanced Methods for Ad Hoc Dataset Retrieval",
        "track": "main",
        "status": "Long Findings",
        "keywords": "ad hoc dataset retrieval;dataset search;dense retrieval;semantic search",
        "author": "",
        "aff": "State Key Laboratory for Novel Software Technology, Nanjing University, China",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "4;3;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "6WcsVlZE5I",
        "title": "Towards a Deep Understanding of Multilingual End-to-End Speech Translation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multilingual Speech Translation;Multilinguality",
        "author": "",
        "aff": "College of Intelligence and Computing, Tianjin University, Tianjin, China",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "3;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "6YQ1uh9IGG",
        "title": "A Survey on Out-of-Distribution Detection in NLP",
        "track": "main",
        "status": "Reject",
        "keywords": "OOD Detection",
        "author": "",
        "aff": "EMNLP submission",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "6c2s6HddQ4",
        "title": "The Locality and Symmetry of Positional Encodings",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Positional Encodings;Sentence Representations;Pre-trained Language Models",
        "author": "",
        "aff": "LTCI, T\u00e9l\u00e9com Paris, Institut Polytechnique de Paris, France; Inria, Soda, Saclay, France",
        "rating": "",
        "confidence": "2;3;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/tigerchen52/locality_symmetry"
    },
    {
        "id": "6dyvFZLRX8",
        "title": "BotPercent: Estimating Bot Populations in Twitter Communities",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Twitter bot detection;social network analysis",
        "author": "",
        "aff": "Allen Institute for AI; University of Washington; Xi\u2019an Jiaotong University; University of Notre Dame",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/TamSiuhin/BotPercent"
    },
    {
        "id": "6eBgIRnlGA",
        "title": "Mitigating Temporal Misalignment by Discarding Outdated Facts",
        "track": "main",
        "status": "Long Main",
        "keywords": "Question Answering;Temporal",
        "author": "",
        "aff": "Department of Computer Science, The University of Texas at Austin",
        "rating": "",
        "confidence": "4;2;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/mikejqzhang/mitigating_misalignment"
    },
    {
        "id": "6i98agKoZ1",
        "title": "Self-Improvement of Non-autoregressive Model via Sequence-Level Distillation",
        "track": "main",
        "status": "Long Main",
        "keywords": "non-autoregressive transformers;self-improvement;distillation",
        "author": "",
        "aff": "Cooperative Medianet Innovation Center, Shanghai Jiao Tong University; Shanghai Artificial Intelligence Laboratory; Cooperative Medianet Innovation Center, Shanghai Jiao Tong University; Fudan University",
        "rating": "",
        "confidence": "4;4;2",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "6j7JZnEzf4",
        "title": "Language Models with Rationality",
        "track": "main",
        "status": "Long Main",
        "keywords": "Interpretability;question answering;belief;entailment;belief graphs;consistency",
        "author": "",
        "aff": "Allen Institute for AI, Seattle, WA; Center for Information and Language Processing, LMU Munich, Germany; Allen Institute for AI, Seattle, WA and Center for Information and Language Processing, LMU Munich, Germany",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "6jik3wCbTr",
        "title": "Mitigating Data Imbalance and Representation Degeneration in Multilingual Machine Translation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Data Imbalance;Representation Degeneration;Multilingual Machine Translation",
        "author": "",
        "aff": "Center for Information and Language Processing, LMU Munich, Germany; Munich Center for Machine Learning, Germany",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "2;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/lavine-lmu/Bi-ACL"
    },
    {
        "id": "6lXuQBMsyM",
        "title": "DetGPT: Detect What You Need via Reasoning",
        "track": "main",
        "status": "Long Main",
        "keywords": "embodied AI;multi-modal learning;object detection",
        "author": "",
        "aff": "The University of Hong Kong; The Hong Kong University of Science and Technology; Shanghai Jiao Tong University",
        "rating": "",
        "confidence": "5;4;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/OptimalScale/DetGPT"
    },
    {
        "id": "6mPs06irie",
        "title": "GlobalBench: A Benchmark for Global Progress in Natural Language Processing",
        "track": "main",
        "status": "Long Main",
        "keywords": "Multilingual benchmark;Leaderboard",
        "author": "",
        "aff": "Harvard University; Carnegie Mellon University; MBZUAI; Shanghai Jiaotong University; The Hong Kong University of Science and Technology; George Mason University",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/neulab/globalbench"
    },
    {
        "id": "6mZIF4OxSq",
        "title": "K-HATERS: A Hate Speech Detection Corpus in Korean with Target-Specific Ratings",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Hate speech;Offensive language;Dataset construction;Fairness;Explainability",
        "author": "",
        "aff": "TUNiB; School of AI Convergence, Soongsil University; Department of Intelligent Semiconductors, Soongsil University",
        "rating": "",
        "confidence": "3;5;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ssu-humane/K-HATERS"
    },
    {
        "id": "6muz29kMQu",
        "title": "Multilingual Holistic Bias: Extending Descriptors and Patterns to Unveil Demographic Biases in Languages at Scale",
        "track": "main",
        "status": "Long Main",
        "keywords": "Multilingual holistic bias;Machine Translation;Sentence Embeddings",
        "author": "",
        "aff": "\u2020FAIR, Meta",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "6nLdWdTeos",
        "title": "Learning Dynamic Representations for Discourse Dependency Parsing",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Discourse dependency parsing;Transition systems;Dynamic sub-tree representations;Graph attention networks",
        "author": "",
        "aff": "Wangxuan Institute of Computer Technology, Peking University, China; Wangxuan Institute of Computer Technology, Peking University, China and Center for Data Science, Peking University, China",
        "rating": "",
        "confidence": "3;3;2",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/lty-lty/Discourse-Dependency-Parsing"
    },
    {
        "id": "6ne78DBkxl",
        "title": "PaRaDe: Passage Ranking using Demonstrations with LLMs",
        "track": "main",
        "status": "Short Findings",
        "keywords": "in-context learning;demonstration;query likelihood;re-ranking;question generation",
        "author": "",
        "aff": "Google; UMass Amherst CICS",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "6pPCKWzYw4",
        "title": "Code-Switching Metrics Using Intonation Units",
        "track": "main",
        "status": "Long Main",
        "keywords": "Computationally-aided linguistic analysis;Linguistic Diversity;Multilingualism and Cross-Lingual NLP;Spanish-English Code-Switching",
        "author": "",
        "aff": "University of California, Los Angeles; Pennsylvania State University; University of Montana",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://nmcode-switching.la.psu.edu",
        "github": ""
    },
    {
        "id": "6srsYdjLnV",
        "title": "Hi Guys or Hi Folks? Benchmarking Gender-Neutral Machine Translation with the GeNTE Corpus",
        "track": "main",
        "status": "Long Main",
        "keywords": "inclusivity;machine translation;gender;non-binary;evaluation;benchmark",
        "author": "",
        "aff": "Fondazione Bruno Kessler; University of Trento, Fondazione Bruno Kessler; Fondazione Bruno Kessler, University of Trento",
        "rating": "",
        "confidence": "3;4;4;3",
        "correctness": "4;3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "6tW1WEHIJe",
        "title": "Is the Answer in the Text? Challenging ChatGPT with Evidence Retrieval from Instructive Text",
        "track": "main",
        "status": "Short Findings",
        "keywords": "question answering;hallucination;evidence retrieval;dataset creation;generative language models;chatgpt",
        "author": "",
        "aff": "Hochschule der Medien Stuttgart, Germany; Bosch Center for Artificial Intelligence, Renningen, Germany; Bosch Center for Artificial Intelligence, Renningen, Germany; Ludwig Maximilian University of Munich, Germany; Bosch Center for Artificial Intelligence, Renningen, Germany; University of Augsburg, Germany; Bosch Center for Artificial Intelligence, Renningen, Germany; University of Stuttgart, Germany; University of Augsburg, Germany",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "6wj8Xczqkn",
        "title": "INarIG: Iterative Non-autoregressive Instruct Generation Model For Word-Level Auto Completion",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Word-Level Auto Completion;Computer-Aided Translation",
        "author": "",
        "aff": "Huawei Translation Service Center, Beijing, China",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "6zSuMMtUjO",
        "title": "IntenDD: A Unified Contrastive Learning Approach for Intent Detection and Discovery",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Intent Discovery;Intent Detection;Contrastive Learning;Modified Adsorption;Label Propagation",
        "author": "",
        "aff": "Uniphore Inc.; University of Utah; Stony Brook University; amrith.tech",
        "rating": "",
        "confidence": "3;5;5;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "71Lz8HW3NE",
        "title": "Addressing NER Annotation Noises with Uncertainty-Guided Tree-Structured CRFs",
        "track": "main",
        "status": "Long Main",
        "keywords": "Named Entity Recognition (NER);Partial and Incorrect Annotation;Uncertainty;constituency tree parsing",
        "author": "",
        "aff": "Tencent AI Lab; Beijing Key Lab of Traffic Data Analysis and Mining, Beijing Jiaotong University",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "73kjtIZ4pt",
        "title": "TELeR: A General Taxonomy of LLM Prompts for Benchmarking Complex Tasks",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Large Language Models;Prompt Engineering;Prompt Taxonomy;Benchmarking",
        "author": "",
        "aff": "Big Data Intelligence (BDI) Lab, Department of Computer Science & Software Engineering, Auburn University, Alabama, USA",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "77h6pSkw4N",
        "title": "DocSplit: Simple Contrastive Pretraining for Large Document Embeddings",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Natural Language Processing; Machine Learning;Text Embeddings",
        "author": "",
        "aff": "Claremont McKenna College; Claremont Graduate University",
        "rating": "",
        "confidence": "3;3;5",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "7CTp2gwqin",
        "title": "TLM: Token-Level Masking for Transformers",
        "track": "main",
        "status": "Long Main",
        "keywords": "Token-Level;Masking;Transformers;Overfitting",
        "author": "",
        "aff": "Zhejiang University; University of Sussex",
        "rating": "",
        "confidence": "3;4;5;3",
        "correctness": "3;3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Young1993/tlm"
    },
    {
        "id": "7D4TPisEBk",
        "title": "Selective Demonstrations for Cross-domain Text-to-SQL",
        "track": "main",
        "status": "Long Findings",
        "keywords": "text-to-SQL;semantic parsing;in-context learning",
        "author": "",
        "aff": "The Ohio State University",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/shuaichenchang/ODIS-Text-to-SQL"
    },
    {
        "id": "7DueCuvmgM",
        "title": "Incorporating Structured Representations into Pretrained Vision \\& Language Models Using Scene Graphs",
        "track": "main",
        "status": "Long Main",
        "keywords": "Vision and language models; Scene graphs; Visio-linguistic compositionality",
        "author": "",
        "aff": "MIT-IBM Watson AI Lab; UC Berkeley; IBM Research; Tel-Aviv University",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "7F5w5AQrv7",
        "title": "Task-Aware Self-Supervised Framework for Dialogue Discourse Parsing",
        "track": "main",
        "status": "Long Findings",
        "keywords": "dialogue discourse parsing;emotion recognition in conversations;self-supervision;Soft-window triangular mask",
        "author": "",
        "aff": "City University of Hong Kong, Hong Kong SAR; Nanyang Technological University, Singapore",
        "rating": "",
        "confidence": "5;4;2",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/senticnet/DialogDP"
    },
    {
        "id": "7FXgefa9lU",
        "title": "This Reads Like That: Deep Learning for Interpretable Natural Language Processing",
        "track": "main",
        "status": "Short Main",
        "keywords": "interpretability;natural language processing;deep learning",
        "author": "",
        "aff": "ETH Z\u00fcrich",
        "rating": "",
        "confidence": "3;3;2",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/fanconic/this_reads_like_that"
    },
    {
        "id": "7FaWK7HpKK",
        "title": "Interpreting Answers to Yes-No Questions in User-Generated Content",
        "track": "main",
        "status": "Long Findings",
        "keywords": "yes-no questions;question answering",
        "author": "",
        "aff": "JP Morgan Chase & Co.; University of Texas at Austin; Walmart Global Tech; University of Arizona; Arizona State University",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "4;4;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/shivammathur33/twitter-yn"
    },
    {
        "id": "7GxY4WVBzc",
        "title": "Arabic Mini-ClimateGPT : A Climate Change and Sustainability Tailored Arabic LLM",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Large Language Model;Climate change;Sustainability;Arabic NLP",
        "author": "",
        "aff": "Mohamed bin Zayed University of Artificial Intelligence; Mohamed bin Zayed University of Artificial Intelligence, Link\u00f6ping University",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/mbzuai-oryx/ClimateGPT"
    },
    {
        "id": "7Gy8FXaTv6",
        "title": "CRUSH4SQL: Collective Retrieval Using Schema Hallucination For Text2SQL",
        "track": "main",
        "status": "Long Main",
        "keywords": "Text-to-SQL;LLM;Retrieval augmentation;Query decomposition",
        "author": "",
        "aff": "Department of Computer Science and Engineering, Indian Institute of Technology Bombay, Mumbai, India",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/iMayK/CRUSH4SQLbenchmarks"
    },
    {
        "id": "7H45HfXsJb",
        "title": "KCTS: Knowledge-Constrained Tree Search Decoding with Token-Level Hallucination Detection",
        "track": "main",
        "status": "Long Main",
        "keywords": "Hallucination;Knowledge Grounding;Natural Language Generation;Constrained Decoding;Controllable Text Generation",
        "author": "",
        "aff": "Department of Computer Science and Engineering, HKUST, Hong Kong SAR",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/HKUST-KnowComp/Knowledge-Constrained-Decoding"
    },
    {
        "id": "7IB8gZRptd",
        "title": "SUT: Active Defects Probing for Transcompiler Models",
        "track": "main",
        "status": "Short Main",
        "keywords": "Program translation;LLM Evaluation;Unit Test;Syntax Error Analysis",
        "author": "",
        "aff": "School of Artificial Intelligence, Jilin University; Microsoft Cloud and AI; Shanghai Jiao Tong University",
        "rating": "",
        "confidence": "5;3;1",
        "correctness": "4;3;1",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "7IcVI11lkO",
        "title": "Improving Transformer-based Program Repair Model through False Behavior Diagnosis",
        "track": "main",
        "status": "Long Main",
        "keywords": "Transformer;Program Repair;False Behavior",
        "author": "",
        "aff": "Department of Artificial Intelligence Convergence, Chonnam National University; College of Computing and Informatics, Sungkyunkwan University; Department of Electrical and Computer Engineering, Sungkyunkwan University",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "7Jis2yiiEZ",
        "title": "Syllogistic Reasoning for Legal Judgment Analysis",
        "track": "main",
        "status": "Long Main",
        "keywords": "Legal Judgment Analysis;Syllogism;Syllogistic Reasoning",
        "author": "",
        "aff": "Leiden University, Leiden, The Netherlands; Shandong University, Qingdao, China; Microsoft Research Asia, Beijing, China; Centrum Wiskunde & Informatica, Amsterdam, The Netherlands",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "3;3;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "7LBhEJ1DII",
        "title": "Quantifying Character Similarity with Vision Transformers",
        "track": "main",
        "status": "Long Main",
        "keywords": "record linkage;homoglyphs;character similarity",
        "author": "",
        "aff": "Harvard University; Cambridge, MA, USA.; Harvard University; Cambridge, MA, USA. National Bureau of Economic Research; Cambridge, MA, USA.",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "7MmYaN93lb",
        "title": "Is Robustness Transferable across Languages in Multilingual Neural Machine Translation?",
        "track": "main",
        "status": "Long Findings",
        "keywords": "robustness;transfer learning;multilingual neural machine translation",
        "author": "",
        "aff": "College of Intelligence and Computing, Tianjin University, Tianjin, China",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "7O9bTjLgTQ",
        "title": "VISIT: Visualizing and Interpreting the Semantic Information Flow of Transformers",
        "track": "main",
        "status": "Long Findings",
        "keywords": "attention;interpretability;visualization",
        "author": "",
        "aff": "Technion - Israel Institute of Technology",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/shacharKZ/VISIT-Visualizing-Transformers"
    },
    {
        "id": "7QSa2w5Wai",
        "title": "Transitioning Representations between Languages for Cross-lingual Event Detection via Langevin Dynamics",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Event Detection;Information Extraction;Cross-lingual Transfer Learning;Langevin Dynamics",
        "author": "",
        "aff": "VinAI Research, Vietnam; Adobe Research, USA; Department of Computer Science, University of Oregon, Eugene, OR, USA; Department of Computer Science, University of Oregon, Eugene, OR, USA and VinAI Research, Vietnam",
        "rating": "",
        "confidence": "4;4;5;4",
        "correctness": "3;3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "7QSvLXXHQt",
        "title": "Who Wrote it and Why? Prompting Large-Language Models for Authorship Verification",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Authorship Verification;Chain-of-Thought Prompting",
        "author": "",
        "aff": "Singapore University of Technology and Design",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "7RzRbVXWPN",
        "title": "AfriSenti: A Twitter Sentiment Analysis Benchmark for African Languages",
        "track": "main",
        "status": "Long Main",
        "keywords": "Africa;Sentiment;Dataset;NLP",
        "author": "",
        "aff": "Fraunhofer FIT; University of Cambridge; Cardiff University; University of Deusto; Hassan II University of Casablanca; Universit\u00e4t Hamburg; Ahmadu Bello University, Zaria; University of Porto, Portugal; Google Research; Bayero University Kano; Digital Umuganda; Wollo University; dLab; Uppsala University; Accra Institute of Technology; University of Porto, Portugal; LIAAD - INESC TEC; National Research Council Canada; University of Porto, Portugal; Bayero University Kano; Bahir Dar University; Jimma University; University College London; LIAAD - INESC TEC; Kaduna State University",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://afrisenti-semeval.github.io",
        "github": "https://github.com/AfriSenti"
    },
    {
        "id": "7SaXczaBpG",
        "title": "RWKV: Reinventing RNNs for the Transformer Era",
        "track": "main",
        "status": "Long Findings",
        "keywords": "large language model;scaling laws;open source;pretraining",
        "author": "",
        "aff": "Wroclaw U. of Science and Technology; Moves; Peking University; U. of Science and Technology of China; RuoxinTech; EleutherAI; Ohio State U.; Crisis24; Tsinghua University; National U. of Singapore; New York U.; Storyteller.io; U. of C., Santa Cruz; Purdue U.; U. of Electronic Science and Technology of China; Criteo AI Lab; Yale U.; Databaker Technology; U. of Oslo; U. of British Columbia; Nextremer; Generative AI Commons",
        "rating": "",
        "confidence": "3;4;4;5",
        "correctness": "4;2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/BlinkDL/RWKV-LM"
    },
    {
        "id": "7TKKvwyQef",
        "title": "DialGuide: Aligning Dialogue Model Behavior with Developer Guidelines",
        "track": "main",
        "status": "Long Findings",
        "keywords": "dialogue;safety;generation",
        "author": "",
        "aff": "Amazon Alexa AI; Language Technologies Institute, Carnegie Mellon University",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "7UVOFuNk27",
        "title": "e-THERAPIST: I suggest you to cultivate a mindset of positivity and nurture uplifting thoughts",
        "track": "main",
        "status": "Long Main",
        "keywords": "Dialogue Systems;Psychotherapy;Persona;Sentiment;Politeness;Interpersonal communication Strategy;Rewards;Reinforcement Learning",
        "author": "",
        "aff": "Department of Computer Science and Engineering, Indian Institute of Technology Patna, India",
        "rating": "",
        "confidence": "5;3;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://www.iitp.ac.in/ai-nlp-ml/resources.html#e-THERAPIST",
        "github": "https://github.com/Mishrakshitij/e-THERAPIST.git"
    },
    {
        "id": "7UvOkmrB8V",
        "title": "Approximating CKY with Transformers",
        "track": "main",
        "status": "Long Findings",
        "keywords": "transformer;algorithmic reasoning;dynamic programming;constituency parsing",
        "author": "",
        "aff": "Duke University; University of Southern California",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "7YluNq3HQQ",
        "title": "BYOC: Personalized Few-Shot Classification with Co-Authored Class Descriptions",
        "track": "main",
        "status": "Long Findings",
        "keywords": "text classification;large language models;prompt engineering;few-shot classification;user study;personalization",
        "author": "",
        "aff": "Bardeen, Inc., San Francisco, CA, USA; University of California Berkeley, Berkeley, CA, USA",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "7Z1F0h7gWq",
        "title": "Learn and Consolidate: Continual Adaptation for Zero-Shot and Multilingual Neural Machine Translation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Multilingual Neural Machine Translation;Zero-shot Machine Translation;Continual Learning",
        "author": "",
        "aff": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "2;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "7cXoueVCoL",
        "title": "CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code",
        "track": "main",
        "status": "Long Main",
        "keywords": "nl2code;code generation;code;evaluation;codebert;bertscore",
        "author": "",
        "aff": "Language Technologies Institute, Carnegie Mellon University",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "2;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/neulab/code-bert-score"
    },
    {
        "id": "7fdIbXjRSp",
        "title": "Thorny Roses: Investigating the Dual Use Dilemma in Natural Language Processing",
        "track": "main",
        "status": "Long Findings",
        "keywords": "dual use;ai ethics;checklist;harms;survey",
        "author": "",
        "aff": "Mohamed Bin Zayed University of Artificial Intelligence, United Arab Emirates; Hasso Plattner Institute, Germany; University of Copenhagen, Denmark",
        "rating": "",
        "confidence": "5;3;3",
        "correctness": "2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/copenlu/dual-use"
    },
    {
        "id": "7gIhLGqyph",
        "title": "Are Structural Concepts Universal in Transformer Language Models? Towards Interpretable Cross-Lingual Generalization",
        "track": "main",
        "status": "Long Findings",
        "keywords": "cross-lingual generalization;syntax;multilinguality;language models",
        "author": "",
        "aff": "School of Computer Science, Fudan University; Institute of Modern Languages and Linguistics, Fudan University; Research Institute of Intelligent Complex Systems, Fudan University; Department of Chinese Language and Literature, Fudan University; School of Computer Science, Fudan University; Institute of Modern Languages and Linguistics, Fudan University",
        "rating": "",
        "confidence": "3;2;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "7hSVLwNbWT",
        "title": "Coverage-based Example Selection for In-Context Learning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "In-Context Learning;Demonstration Selection;Large Language Models;Prompting;Compositional Generalization;Semantic Parsing",
        "author": "",
        "aff": "Scaled Cognition; University of California Irvine",
        "rating": "",
        "confidence": "4;3;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Shivanshu-Gupta/icl-coverage"
    },
    {
        "id": "7jYZd05yjJ",
        "title": "ClusterLLM: Large Language Models as a Guide for Text Clustering",
        "track": "main",
        "status": "Long Main",
        "keywords": "text clustering;large language model;sentence relation;entropy-based sampling",
        "author": "",
        "aff": "University of California, San Diego",
        "rating": "",
        "confidence": "2;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/zhang-yu-wei/ClusterLLM"
    },
    {
        "id": "7okuG5JhaM",
        "title": "Can ChatGPT Perform Reasoning Using the IRAC Method in Analyzing Legal Scenarios Like a Lawyer?",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Legal Reasoning;IRAC method;Natural Language Processing;Generative Language Models;In-context Learning;Question Decomposition",
        "author": "",
        "aff": "Deakin University; Monash University; School of Information Technology, Monash University Malaysia",
        "rating": "",
        "confidence": "3;5;4",
        "correctness": "2;5;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "7qCuicCunf",
        "title": "Learning to love diligent trolls: Accounting for rater effects in the dialogue safety task",
        "track": "main",
        "status": "Short Findings",
        "keywords": "chatbots;trolls;safety;automated essay scoring;latent class analysis",
        "author": "",
        "aff": "McGill University / Montreal, QC, Canada",
        "rating": "",
        "confidence": "2;3;4;3;4",
        "correctness": "4;3;2;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.2,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "7rjkSqMJ5n",
        "title": "Target-Agnostic Gender-Aware Contrastive Learning for Mitigating Bias in Multilingual Machine Translation",
        "track": "main",
        "status": "Long Main",
        "keywords": "machine translation;bias mitigation;contrastive learning",
        "author": "",
        "aff": "Dept. of ECE, Seoul National University; Microsoft Research Asia; IPAI, Seoul National University",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/minwhoo/GACL"
    },
    {
        "id": "7s8KOmvdJc",
        "title": "InheritSumm: A General, Versatile and Compact Summarizer by Distilling from GPT",
        "track": "main",
        "status": "Long Findings",
        "keywords": "summarization;distillation;zero-shot;few-shot;large language model",
        "author": "",
        "aff": "Microsoft Azure AI",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "7umLwqBbvw",
        "title": "A Comprehensive Evaluation of Tool-Assisted Generation Strategies",
        "track": "main",
        "status": "Long Findings",
        "keywords": "tool-assisted;tool-augmented;tool usage;large language models;LLMs;few-shot",
        "author": "",
        "aff": "Google DeepMind; Google Research; Bar Ilan University",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "7vR0fWRwTX",
        "title": "Exploring Discourse Structure in Document-level Machine Translation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Document-level Machine Translation;Discourse Structure;RST Parsing",
        "author": "",
        "aff": "Wangxuan Institute of Computer Technology, Peking University",
        "rating": "",
        "confidence": "3;4;3;4",
        "correctness": "3;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "7wJhlDMNH7",
        "title": "Can We Edit Multimodal Large Language Models?",
        "track": "main",
        "status": "Long Main",
        "keywords": "Model Editing;Multimodal Language Models;Large Language Models",
        "author": "",
        "aff": "Zhejiang University, Zhejiang University - Ant Group Joint Laboratory of Knowledge Graph; Zhejiang University, Zhejiang University - Ant Group Joint Laboratory of Knowledge Graph, Donghai Laboratory; Zhejiang Laboratory; Platform and Content Group, Tencent",
        "rating": "",
        "confidence": "1;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/zjunlp/EasyEdit"
    },
    {
        "id": "80ZDEuEJVC",
        "title": "A Parallel Corpus for Vietnamese Central-Northern Dialect Text Transfer",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Vietnamese;Dialect;Text Style Transfer",
        "author": "",
        "aff": "VinAI Research, Vietnam; Nanyang Technological University, Singapore",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "83m634EuTW",
        "title": "Re-Examining Summarization Evaluation across Multiple Quality Criteria",
        "track": "main",
        "status": "Short Findings",
        "keywords": "summarization;evaluation;summarization evaluation;confounding variable;spurious correlation;confounding factor",
        "author": "",
        "aff": "Amazon; Bar-Ilan University; Bar-Ilan University; Amazon",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "855dPxyaex",
        "title": "Finding Authentic Counterhate Arguments: A Case Study with Public Figures",
        "track": "main",
        "status": "Long Main",
        "keywords": "Hate Speech;Counterhate;Social Media",
        "author": "",
        "aff": "College of Computer Engineering and Sciences, Prince Sattam Bin Abdulaziz University; Department of Communication and Information Engineering, Zewail City University; Department of Computer Science, University of Arizona",
        "rating": "",
        "confidence": "3;5;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "8752c2KVwd",
        "title": "Dialect-to-Standard Normalization: A Large-Scale Multilingual Evaluation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "text normalization;multilingual evaluation;multilingual datasets;linguistic variation;dialects and language varieties;Finnish;Norwegian;Slovene;Swiss German",
        "author": "",
        "aff": "Department of Informatics, University of Oslo; Department of Digital Humanities, University of Helsinki; Department of Digital Humanities, University of Helsinki; Department of Digital Humanities, University of Helsinki; Faculty of Information Technology and Communication Sciences, Tampere University",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Helsinki-NLP/dialect-to-standard"
    },
    {
        "id": "87WEkTIVSh",
        "title": "Multilingual Pixel Representations for Translation and Effective Cross-lingual Transfer",
        "track": "main",
        "status": "Long Main",
        "keywords": "machine translation;pixel representations;multilinguality;cross-lingual transfer;unseen scripts",
        "author": "",
        "aff": "Human Language Technology Center of Excellence; Johns Hopkins University; Microsoft",
        "rating": "",
        "confidence": "4;4;2",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "8851TT2R0l",
        "title": "The Benefits of Label-Description Training for Zero-Shot Text Classification",
        "track": "main",
        "status": "Long Main",
        "keywords": "zero-shot;text classification;label description",
        "author": "",
        "aff": "Educational Testing Service; Toyota Technological Institute at Chicago",
        "rating": "",
        "confidence": "5;4;5",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "8AKBcTXEd3",
        "title": "Unifying Discrete and Continuous Representations for Unsupervised Paraphrase Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "unsupervised paraphrase generation;discrete variables;VQ-VAE;entity",
        "author": "",
        "aff": "College of Computer Science, Sichuan University",
        "rating": "",
        "confidence": "4;4;1",
        "correctness": "3;5;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "8B9mL26NDT",
        "title": "On the Impact of Cross-Domain Data on German Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "large language models;cross-domain datasets;data diversity;data quality;benchmark",
        "author": "",
        "aff": "Department of Computer Science, University of Applied Sciences and Arts Dortmund, Dortmund, Germany; Department of Diagnostic and Interventional Radiology, University Hospital RWTH Aachen, Aachen, Germany; Institute for AI in Medicine (IKIM), University Hospital Essen (A\u00f6R), Essen, Germany; Institute for Medical Informatics, Biometry and Epidemiology (IMIBE), University Hospital Essen (A\u00f6R), Essen, Germany; Cancer Research Center Cologne Essen (CCCE), West German Cancer Center Essen, University Hospital Essen (A\u00f6R), Essen, Germany; Department of Health Outcomes and Biomedical Informatics, College of Medicine, University of Florida, Gainesville, FL, USA; NVIDIA, Santa Clara, CA, USA",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://huggingface.co/ikim-uk-essen"
    },
    {
        "id": "8CQ0DUuSAK",
        "title": "Clustering Pseudo Language Family in Multilingual Translation Models with Fisher Information Matrix",
        "track": "main",
        "status": "Short Main",
        "keywords": "Multilingual Translation;Low-resource",
        "author": "",
        "aff": "Institute of Computing and Intelligence, Harbin Institute of Technology, Shenzhen, China",
        "rating": "",
        "confidence": "2;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ecoli-hit/PseudoFamily"
    },
    {
        "id": "8DKrruapZ5",
        "title": "Boosting Prompt-Based Self-Training With Mapping-Free Automatic Verbalizer for Multi-Class Classification",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Prompt-based Learning;Prompt-based fine-tuning;Prompt-based self-training;Verbalizer;Label Word Mapping",
        "author": "",
        "aff": "Korea University, Seoul, Republic of Korea",
        "rating": "",
        "confidence": "4;4;2",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/yookyungkho/MAV"
    },
    {
        "id": "8ElstW3DUT",
        "title": "DADA: Dialect Adaptation via Dynamic Aggregation of Linguistic Rules",
        "track": "main",
        "status": "Long Main",
        "keywords": "Dialect Adaptation; Dialect Robustness; Linguistic Diversity; Fairness; Human-Centered NLP",
        "author": "",
        "aff": "Stanford University; Harvard University; Georgia Institute of Technology",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/SALT-NLP/DADA"
    },
    {
        "id": "8FXeFY5487",
        "title": "Enhancing Scalability of Pre-trained Language Models via Efficient Parameter Sharing",
        "track": "main",
        "status": "Long Findings",
        "keywords": "parameter-efficient;pre-trained language models;scalability",
        "author": "",
        "aff": "Department of Physics, Renmin University of China; Gaoling School of Artificial Intelligence, Renmin University of China",
        "rating": "",
        "confidence": "4;3;3;3",
        "correctness": "4;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/RUCAIBox/MPOBERT-code"
    },
    {
        "id": "8FgdMHbW27",
        "title": "Poisoning Retrieval Corpora by Injecting Adversarial Passages",
        "track": "main",
        "status": "Short Main",
        "keywords": "Dense Retrieval;Corpus Poisoning;Adversarial Attack",
        "author": "",
        "aff": "Princeton University; Tsinghua University",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/princeton-nlp/corpus-poisoning"
    },
    {
        "id": "8IrFLWRvuW",
        "title": "InfoDiffusion: Information Entropy Aware Diffusion Process for Non-Autoregressive Text Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Text generation;Diffusion model;Information entropy",
        "author": "",
        "aff": "Department of Computing, The Hong Kong Polytechnic University, China; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, China; MIIT Key Laboratory of Pattern Analysis and Machine Intelligence, Nanjing, China",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/rzhwang/InfoDiffusion"
    },
    {
        "id": "8L5SA7ENI4",
        "title": "The Sentiment Problem: A Critical Survey towards Deconstructing Sentiment Analysis",
        "track": "main",
        "status": "Long Main",
        "keywords": "Sentiment Analysis;Natural Language Processing;Critical Survey;Ethics in NLP;Ethics based Auditing.",
        "author": "",
        "aff": "Department of Computer Science & Engineering, College of Engineering, Pennsylvania State University; College of Information Sciences and Technology, Pennsylvania State University",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "8LSuy5nNmz",
        "title": "Multilingual Generation and Answering of Questions from Texts and Knowledge Graphs",
        "track": "main",
        "status": "Long Findings",
        "keywords": "question generation;question answering;multilinguality;multi-modality;knowledge bases;consistency",
        "author": "",
        "aff": "CNRS/LORIA and Universit\u00e9 de Lorraine",
        "rating": "",
        "confidence": "3;2;2",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://gitlab.inria.fr/hankelvin/multlingual_kg-text_qgqa"
    },
    {
        "id": "8NA76tz7Jj",
        "title": "Data Augmentation for Code Translation with Comparable Corpora and Multiple References",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Code translation;Machine learning for code",
        "author": "",
        "aff": "Language Technologies Institute, Carnegie Mellon University",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Veronicium/CMTrans"
    },
    {
        "id": "8NFU2kLql3",
        "title": "HANSEN: Human and AI Spoken Text Benchmark for Authorship Analysis",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Authorship analysis;Spoken text;Large Language Model;AI text detection",
        "author": "",
        "aff": "The University of Mississippi, USA; MIT Lincoln Laboratory, USA; ISTI-CNR, Pisa, Italy; The Pennsylvania State University, USA",
        "rating": "",
        "confidence": "5;3;3",
        "correctness": "2;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://huggingface.co/datasets/HANSEN-REPO/HANSEN",
        "github": "https://github.com/HANSEN-REPO/HANSEN"
    },
    {
        "id": "8PNFSDJ3md",
        "title": "Empower Nested Boolean Logic via Self-Supervised Curriculum Learning",
        "track": "main",
        "status": "Long Main",
        "keywords": "nested boolean logic;curriculum learning",
        "author": "",
        "aff": "Department of Computer Science and Engineering, Shanghai Jiao Tong University; Key Laboratory of Shanghai Education Commission for Intelligent Interaction and Cognitive Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Computer Science and Technology, Soochow University, Suzhou, China; Harbin Institute of Technology, Shenzhen, China",
        "rating": "",
        "confidence": "4;4;2",
        "correctness": "3;5;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/gingasan/boolkill"
    },
    {
        "id": "8POQ904HEc",
        "title": "HeQ: a Large and Diverse Hebrew Reading Comprehension Benchmark",
        "track": "main",
        "status": "Long Findings",
        "keywords": "hebrew;machine reading comprehension;question answering;dataset",
        "author": "",
        "aff": "Webiks, Tel Aviv, Israel; Bar-Ilan University, Ramat-Gan, Israel; Allen Institute for AI, Seattle, WA; Bar-Ilan University, Ramat-Gan, Israel",
        "rating": "",
        "confidence": "3;3;2",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "8Rif7M7Z6A",
        "title": "DepNeCTI: Dependency-based Nested Compound Type Identification for Sanskrit",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Nested compound type identification for Sanskrit;word-level lexical semantics;newly annotated dataset;benchmarking and dependency-based novel framework.",
        "author": "",
        "aff": "University of Hyderabad; IIT Kharagpur; IIT Roorkee; UC Berkeley",
        "rating": "",
        "confidence": "3;2;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/yaswanth-iitkgp/DepNeCTI"
    },
    {
        "id": "8UWPQboDq9",
        "title": "Multi-Task Learning of Query Generation and Classification for Generative Conversational Question Rewriting",
        "track": "main",
        "status": "Long Findings",
        "keywords": "multi-task learning;follow-up question identification;conversational question rewriting;text generation model",
        "author": "",
        "aff": "University of Glasgow, UK",
        "rating": "",
        "confidence": "5;2;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "8VK9XXgFHp",
        "title": "A Read-and-Select Framework for Zero-shot Entity Linking",
        "track": "main",
        "status": "Long Findings",
        "keywords": "entity linking;zero-shot learning",
        "author": "",
        "aff": "Harbin Institute of Technology (Shenzhen), Shenzhen, China",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "1;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/HITsz-TMG/Read-and-Select"
    },
    {
        "id": "8WXwPUBFEb",
        "title": "Reading Order Matters: Information Extraction from Visually-rich Documents by Token Path Prediction",
        "track": "main",
        "status": "Long Main",
        "keywords": "visually-rich document understanding;information extraction;named entity recognition",
        "author": "",
        "aff": "Institute of Modern Languages and Linguistics, Fudan University, Shanghai, China; School of Computer Science, Fudan University, Shanghai, China; Ant Info Security Lab, Ant Group Inc., Hangzhou, China",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "5;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "8Y9G7579DP",
        "title": "You Told Me That Joke Twice: A Systematic Investigation of Transferability and Robustness of Humor Detection Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "humor detection;evaluation;transferability;robustness",
        "author": "",
        "aff": "HSE University, Moscow, Russia; HSE University, Moscow, Russia; School of Engineering and Digital Sciences, Nazarbayev University, Astana, Kazakhstan",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "4;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Humor-Research/Humor-detection"
    },
    {
        "id": "8cRL5fPwUI",
        "title": "Time-Aware Language Modeling for Historical Text Dating",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Text Dating;Diachronic Text Evaluation;Time-Aware Language Model;Temporal Adaption;Hierarchical Model",
        "author": "",
        "aff": "Wuhan University, China; Guangdong University of Foreign Studies, China",
        "rating": "",
        "confidence": "3;4;4;4",
        "correctness": "2;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/coderlihong/text-dating"
    },
    {
        "id": "8e9aFrksRq",
        "title": "Semantic Decomposition of Question and SQL for Text-to-SQL Parsing",
        "track": "main",
        "status": "Long Findings",
        "keywords": "semantic parsing;text-to-sql;question decomposition;compositionality",
        "author": "",
        "aff": "Dept of Computer Science, Ben Gurion University, Beer Sheva, Israel",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "8gYRHspcxK",
        "title": "Aligning Large Language Models through Synthetic Feedback",
        "track": "main",
        "status": "Long Main",
        "keywords": "Alignment Learning;Large Language Models",
        "author": "",
        "aff": "NAVER Cloud; NAVER Cloud, NAVER AI Lab, SNU AI Center; NAVER Cloud, NAVER AI Lab, KAIST AI; NAVER Cloud, NAVER AI Lab; NAVER AI Lab, KAIST AI",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "github.com/naver-ai/almost"
    },
    {
        "id": "8iB0FJmOfV",
        "title": "q2d: Turning Questions into Dialogs to Teach Models How to Search",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large language models;dialog generation;query generation;external search API;synthetic training data;QReCC dataset;information-seeking dialogs;q2d;data generation pipeline;synthetic dialogs;human-generated dialogs;grounded responses;anaphora;outdated information;hallucinations;factually consistent responses;multi-hop QA;PaLM",
        "author": "",
        "aff": "\u2021Google Research; \u2020The Hebrew University of Jerusalem;\u2021Google Research",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "8l2m7jctGv",
        "title": "Focus on the Core: Efficient Attention via Pruned Token Compression for Document Classification",
        "track": "main",
        "status": "Long Findings",
        "keywords": "document classification;pre-trained transformer;attention;token pruning;token combining",
        "author": "",
        "aff": "Department of Artificial Intelligence, Chung-Ang University; Graduate School of Advanced Imaging Sciences, Multimedia and Film, Chung-Ang University",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "8mJujVetQv",
        "title": "Less than One-shot: Named Entity Recognition via Extremely Weak Supervision",
        "track": "main",
        "status": "Long Findings",
        "keywords": "extremely weak supervison;few-shot learning;named entity extraction",
        "author": "",
        "aff": "University of California, San Diego",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "KomeijiForce/X-NER"
    },
    {
        "id": "8oy8hUeem9",
        "title": "InstOptima: Evolutionary Multi-objective Instruction Optimization via Large Language Model-based Instruction Operators",
        "track": "main",
        "status": "Short Findings",
        "keywords": "instruction optimization;automated instruction generation;evolutionary multi-objective optimization;language model-based operators",
        "author": "",
        "aff": "Department of Computer Science, University of Exeter, EX4 4QF, Exeter, UK",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "8uSB79mZks",
        "title": "Relation-Aware Question Answering for Heterogeneous Knowledge Graphs",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Question Answering;Knowledge Graph;Heterogeneous",
        "author": "",
        "aff": "Ant Group; Wangxuan Institute of Computer Technology, Peking University, The National Key Laboratory of Cross-Media General Artificial Intelligence, Beijing Institute for General Artificial Intelligence (BIGAI), Beijing, China, Institute for Artificial Intelligence, Peking University; Wangxuan Institute of Computer Technology, Peking University",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/yanmenxue/RAH-KBQA"
    },
    {
        "id": "8xyd9i1XLb",
        "title": "MoPe: Model Perturbation based Privacy Attacks on Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "large language model;membership inference;data extraction",
        "author": "",
        "aff": "Harvard University; Harvard College",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "8zQ77tPTMR",
        "title": "Consistency is Key: On Data-Efficient Modality Transfer in Speech Translation",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Speech Translation;Cross-modal Transfer;Efficient Training",
        "author": "",
        "aff": "Seoul National University; Kakao Brain",
        "rating": "",
        "confidence": "4;2;4;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/hjlee1371/consistency-s2tt"
    },
    {
        "id": "99msyVXHEq",
        "title": "CLAIR: Evaluating Image Captions with Large Language Models",
        "track": "main",
        "status": "Short Main",
        "keywords": "Image Captioning;Evaluation;Metrics;Large Language Models",
        "author": "",
        "aff": "University of California, Berkeley",
        "rating": "",
        "confidence": "4;4;4;3",
        "correctness": "3;3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://davidmchan.github.io/clair/"
    },
    {
        "id": "9Ax0pyaLgh",
        "title": "Cross-modality Data Augmentation for End-to-End Sign Language Translation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Sign Language Translation;Cross Modality;Data Augmentation",
        "author": "",
        "aff": "Thrust of Artificial Intelligence, HKUST (Guangzhou), Guangzhou, China; Department of Computer Science and Engineering, HKUST, Hong Kong SAR, China; Guangzhou HKUST Fok Ying Tung Research Institute; Tencent AI Lab; Thrust of Artificial Intelligence, HKUST (Guangzhou), Guangzhou, China",
        "rating": "",
        "confidence": "5;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Atrewin/SignXmDA"
    },
    {
        "id": "9BuTdxSfIO",
        "title": "kNN-CM: A Non-parametric Inference-Phase Adaptation of Parametric Text Classifiers",
        "track": "main",
        "status": "Long Findings",
        "keywords": "nearest neighbors;text classification;semi-parametric models;non-parametric models;kNN-CM;kNN-LM",
        "author": "",
        "aff": "Singapore University of Technology and Design, Singapore; Beijing University of Posts and Telecommunications",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Bhardwaj-Rishabh/kNN-CM"
    },
    {
        "id": "9EYS2EEqFq",
        "title": "CAR: Conceptualization-Augmented Reasoner for Zero-Shot Commonsense Question Answering",
        "track": "main",
        "status": "Long Findings",
        "keywords": "commonsense reasoning;conceptualization;zero shot;question answering",
        "author": "",
        "aff": "NLP Lab, School of Computer and Communication Sciences, EPFL, Switzerland; Department of Computer Science and Engineering, HKUST, Hong Kong SAR, China",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/HKUST-KnowComp/CAR"
    },
    {
        "id": "9EYaUfyRYk",
        "title": "Beyond Testers\u2019 Biases: Guiding Model Testing with Knowledge Bases using LLMs",
        "track": "main",
        "status": "Long Findings",
        "keywords": "model testing;knowledge base;large language models;human-centered NLP",
        "author": "",
        "aff": "Carnegie Mellon Software Engineering Institute; Carnegie Mellon University",
        "rating": "",
        "confidence": "5;5;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/malusamayo/Weaver"
    },
    {
        "id": "9F6h0oIYsP",
        "title": "Leveraging Contrastive Learning and Knowledge Distillation for Incomplete Modality Rumor Detection",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Rumor detection;Contrastive learning;Knowledge distillation;Incomplete modality",
        "author": "",
        "aff": "Institute for Infocomm Research, A*STAR; Jiangxi Normal University",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/fupinyun/CLKD-IMRD"
    },
    {
        "id": "9GxP2Kw8IC",
        "title": "Synthesize, if you do not have: Effective Synthetic Dataset Creation Strategies for Self-Supervised Opinion Summarization in E-commerce",
        "track": "main",
        "status": "Short Findings",
        "keywords": "opinion summarization;summarization;ecommerce;nlp",
        "author": "",
        "aff": "Flipkart, India; Department of Computer Science and Engineering, IIT Bombay, India",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "9HbJGoe4a8",
        "title": "Sound of Story: Multi-modal Storytelling with Audio",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multi-modal;Story understanding;Audio-video retrieval;Audio generation",
        "author": "",
        "aff": "School of Liberal Arts, Ulsan National Institute of Science and Technology, Korea; Artificial Intelligence Graduate School, Ulsan National Institute of Science and Technology, Korea; Artificial Intelligence Graduate School, Department of Computer Science and Engineering, Ulsan National Institute of Science and Technology, Korea; Department of Computer Science and Engineering, Ulsan National Institute of Science and Technology, Korea",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Sosdatasets/SoS_Dataset"
    },
    {
        "id": "9HjxuDwTNG",
        "title": "Towards a Unified Conversational Recommendation System: Multi-task Learning via Contextualized Knowledge Distillation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Recommendation;Multi-task learning",
        "author": "",
        "aff": "The Hong Kong University of Science and Technology",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/yeongseoj/ConKD"
    },
    {
        "id": "9K1urVN7ti",
        "title": "DueT: Image-Text Contrastive Transfer Learning with Dual-adapter Tuning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Vision and Language",
        "author": "",
        "aff": "Tokyo Institute of Technology; NTT Human Informatics Laboratories",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "9LPJK81xy1",
        "title": "Conversation Chronicles: Towards Diverse Temporal and Relational Dynamics in Multi-Session Conversations",
        "track": "main",
        "status": "Long Main",
        "keywords": "Multi-Session Dialogue;Long-Term Conversation",
        "author": "",
        "aff": "Artificial Intelligence Graduate School, UNIST",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://conversation-chronicles.github.io/"
    },
    {
        "id": "9NGR4GdLII",
        "title": "Coarse-to-Fine Dual Encoders are Better Frame Identification Learners",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Frame Identification;Frame Semantics;Contrastive Learning;Metric Learing",
        "author": "",
        "aff": "National Key Laboratory for Multimedia Information Processing, School of Computer Science, Peking University; National Key Laboratory for Multimedia Information Processing, School of Computer Science, Peking University; School of Software & Microelectronics, Peking University",
        "rating": "",
        "confidence": "3;1;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/pkunlp-icler/COFFTEA"
    },
    {
        "id": "9OPtgQlxVD",
        "title": "BioDEX: Large-Scale Biomedical Adverse Drug Event Extraction for Real-World Pharmacovigilance",
        "track": "main",
        "status": "Long Findings",
        "keywords": "pharmacovigilance;datasets;healthcare;adverse drug events",
        "author": "",
        "aff": "Stanford University; Aarhus University; Ghent University \u2013 imec; Parexel AI Labs",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/KarelDO/BioDEX"
    },
    {
        "id": "9RFBVLwiOn",
        "title": "SEER : A Knapsack approach to Exemplar Selection for In-Context HybridQA",
        "track": "main",
        "status": "Long Main",
        "keywords": "Hybrid Question Answering;In-Context Learning;Integer Linear Programming",
        "author": "",
        "aff": "Ubiquitous Knowledge Processing Lab (UKP Lab), Department of Computer Science and Hessian Center for AI (hessian.AI), TU Darmstadt; IESEG School of Management, 3 Rue de la Digue, 59000 Lille, France; Department of Decision Analytics and Risk, University of Southampton; Research Centre for Information Systems Engineering (LIRIS), Faculty of Economics and Business, KU Leuven",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "www.ukp.tu-darmstadt.de",
        "github": "github.com/jtonglet/SEER"
    },
    {
        "id": "9RugvdmIBa",
        "title": "PARROT: Zero-Shot Narrative Reading Comprehension via Parallel Reading",
        "track": "main",
        "status": "Long Findings",
        "keywords": "narrative reading comprehension;zero-shot learning",
        "author": "",
        "aff": "Department of Computer Science, UNC Chapel Hill",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/zhaochaocs/Parrot"
    },
    {
        "id": "9S0MFwEkc3",
        "title": "Rethinking the Construction of Effective Metrics for Understanding the Mechanisms of Pretrained Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Metrics;Probe;Mechanisms;Pretrained Language Models",
        "author": "",
        "aff": "Guangxi Key Laboratory of Trusted Software, Guilin University of Electronic Technology",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/cclx/Effective_Metrics"
    },
    {
        "id": "9V0M45lJAs",
        "title": "Towards a Better Understanding of Variations in Zero-Shot Neural Machine Translation Performance",
        "track": "main",
        "status": "Long Main",
        "keywords": "Zero-shot Machine Translation;Multilingual Machine Translation",
        "author": "",
        "aff": "Language Technology Lab, University of Amsterdam",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Smu-Tan/ZS-NMT-Variations/"
    },
    {
        "id": "9cALtYoAEy",
        "title": "Vector-Quantized Prompt Learning for Paraphrase Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Natural Language Processing;Natural Language Generation;Text generation;Paraphrase",
        "author": "",
        "aff": "Sichuan University",
        "rating": "",
        "confidence": "3;3;3;2",
        "correctness": "3;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "9edEJfhOFL",
        "title": "Towards Unsupervised Recognition of Token-level Semantic Differences in Related Documents",
        "track": "main",
        "status": "Short Main",
        "keywords": "recognizing semantic differences;semantic similarity;multilinguality",
        "author": "",
        "aff": "Department of Computational Linguistics, University of Zurich",
        "rating": "",
        "confidence": "3;4;2",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ZurichNLP/recognizing-semantic-differences"
    },
    {
        "id": "9qydIw5ux1",
        "title": "Ethical Reasoning over Moral Alignment: A Case and Framework for In-Context Ethical Policies in LLMs",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Ethics in NLP;Ethical Reasoning;Value Pluralism;Large Language Models",
        "author": "",
        "aff": "Carnegie Mellon University; Microsoft Corporation",
        "rating": "",
        "confidence": "2;4;3",
        "correctness": "2;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "9r8WwpJv7M",
        "title": "Ling-CL: Understanding NLP Models through Linguistic Curricula",
        "track": "main",
        "status": "Long Main",
        "keywords": "linguistic index;curriculum learning",
        "author": "",
        "aff": "University of Massachusetts Lowell",
        "rating": "",
        "confidence": "1;4;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "9rWqOgvGpc",
        "title": "PTP: Boosting Stability and Performance of Prompt Tuning with Perturbation-Based Regularizer",
        "track": "main",
        "status": "Long Main",
        "keywords": "prompt tuning; training with regularizers",
        "author": "",
        "aff": "University of Maryland; HKUST",
        "rating": "",
        "confidence": "3;4;5",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "9s7QooDInQ",
        "title": "SGP-TOD: Building Task Bots Effortlessly via Schema-Guided LLM Prompting",
        "track": "main",
        "status": "Long Findings",
        "keywords": "schema-guided LLM prompting;task bot;zero-shot dialog generation",
        "author": "",
        "aff": "Tencent AI Lab, Bellevue; The Chinese University of Hong Kong, Hong Kong; The Chinese University of Hong Kong, Hong Kong; Centre for Perceptual and Interactive Intelligence, Hong Kong",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "2;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/zhangxy-2019/sgp-tod"
    },
    {
        "id": "9z2yznFVw5",
        "title": "Decomposed Prompt Tuning via Low-Rank Reparameterization",
        "track": "main",
        "status": "Long Findings",
        "keywords": "prompt tuning;parameter-efficient tuning",
        "author": "",
        "aff": "Singapore University of Technology and Design; Institute for Infocomm Research, A*Star, Singapore",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/XYaoooo/DPT"
    },
    {
        "id": "9zZWPEo8et",
        "title": "LogicAttack: Adversarial Attacks for Evaluating Logical Consistency of Natural Language Inference",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Logical Reasoning;Large Language Models;Natural Language Inference;Adversarial Attacks",
        "author": "",
        "aff": "School of Computing and AI, Arizona State University",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/msantoshmadhav/LogicAttack"
    },
    {
        "id": "A0xVOahTiw",
        "title": "MaNtLE: Model-agnostic Natural Language Explainer",
        "track": "main",
        "status": "Long Main",
        "keywords": "explainable AI;interpretability",
        "author": "",
        "aff": "UNC Chapel Hill",
        "rating": "",
        "confidence": "3;3;4;3",
        "correctness": "4;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/rrmenon/MaNtLE"
    },
    {
        "id": "A2oBdekFgv",
        "title": "Dialogue Medical Information Extraction with Medical-Item Graph and Dialogue-Status Enriched Representation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Dialogue medical information extraction;Multi-label text classification;Graph neural network;Natural language processing",
        "author": "",
        "aff": "Tencent Youtu Lab, Jarvis Research Center",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/nlpir2020/MIE-ACL-2020"
    },
    {
        "id": "A68W11vA8o",
        "title": "Skill-Based Few-Shot Selection for In-Context Learning",
        "track": "main",
        "status": "Long Main",
        "keywords": "In-Context Learning;Few-Shot Selection;Semantic Parsing",
        "author": "",
        "aff": "National Key Laboratory of Human-Machine Hybrid Augmented Intelligence, National Engineering Research Center of Visual Information and Applications, Institute of Arti\ufb01cial Intelligence and Robotics, Xi\u2019an Jiaotong University; Northeastern University; Microsoft Corporation",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "A6FGmwsH7x",
        "title": "ByteSized32: A Corpus and Challenge Task for Generating Task-Specific World Models Expressed as Text Games",
        "track": "main",
        "status": "Long Main",
        "keywords": "text games;code generation;simulation",
        "author": "",
        "aff": "New York University; Microsoft Research Montr\u00e9al, Johns Hopkins University; University of Arizona; Microsoft Research Montr\u00e9al",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/cognitiveailab/BYTESIZED32"
    },
    {
        "id": "AAYXFyvNbr",
        "title": "Tokenization Consistency Matters for Generative Models on Extractive NLP Tasks",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Tokenization;Question Answering",
        "author": "",
        "aff": "AWS AI Labs; Paul G. Allen School of Computer Science & Engineering, University of Washington",
        "rating": "",
        "confidence": "4;3;4;4",
        "correctness": "3;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/KaiserWhoLearns/ConsistentTokenization"
    },
    {
        "id": "AAnYBhWKRv",
        "title": "FOCUS: Effective Embedding Initialization for Monolingual Specialization of Multilingual Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "model transfer;multilingual;crosslingual",
        "author": "Konstantin Dobler, Gerard de Melo",
        "aff": "Hasso Plattner Institute / University of Potsdam",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/konstantinjdobler/focus"
    },
    {
        "id": "AAuVIl8Aeo",
        "title": "Characterizing and Verifying Scientific Claims: Qualitative Causal Structure is All You Need",
        "track": "main",
        "status": "Long Main",
        "keywords": "Scientific Claim Verification;Heterogeneous Graph;reasoning",
        "author": "",
        "aff": "School of Computer Science and Engineering, Beihang University; Information Research Center of Military Science, PLA Academy of Military Science",
        "rating": "",
        "confidence": "2;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/VulnDetector/VerQCS"
    },
    {
        "id": "ACogU4OVFK",
        "title": "From Speculation Detection to Trustworthy Relational Tuples in Information Extraction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "speculation detection;text classification;information extraction",
        "author": "",
        "aff": "School of Computer Science and Engineering, Nanyang Technological University, Singapore; Institute for Infocomm Research, A*STAR, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore; Institute for Infocomm Research, A*STAR, Singapore; A*STAR Centre for Frontier AI Research, Singapore; Institute for Infocomm Research, A*STAR, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore",
        "rating": "",
        "confidence": "3;5;3;3",
        "correctness": "4;3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "AD0o090nDJ",
        "title": "An Exploration of Left-Corner Transformations",
        "track": "main",
        "status": "Long Main",
        "keywords": "left-corner transformation;top-down parsing;left-recursion;grammar transformations;speculation;formal language theory;weighted CFG;left-corner transform",
        "author": "",
        "aff": "ETH Z\u00fcrich; ETH Z\u00fcrich, University of Cambridge; ETH Z\u00fcrich, Max Planck ETH Center for Learning Systems",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/rycolab/left-corner"
    },
    {
        "id": "ADHMUuN7CE",
        "title": "EXPLAIN, EDIT, GENERATE: Rationale-Sensitive Counterfactual Data Augmentation for Multi-hop Fact Verification",
        "track": "main",
        "status": "Long Main",
        "keywords": "multi-hop fact verification;counterfactual data augmentation;out-of-domain generalization",
        "author": "",
        "aff": "School of Computer Science and Engineering, Key Laboratory of Computer Network and Information Integration, Ministry of Education, Southeast University, China; Department of Informatics, King\u2019s College London, UK; The Alan Turing Institute, UK",
        "rating": "",
        "confidence": "3;2;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/AAAndy-Zhu/RACE"
    },
    {
        "id": "ADsEdyI32n",
        "title": "LLMLingua: Compressing Prompts for Accelerated Inference of Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Prompt Compression;LLMs;Inference Acceleration;Black-box LLMs;Efficient LLMs",
        "author": "",
        "aff": "Microsoft Corporation",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://aka.ms/LLMLingua"
    },
    {
        "id": "AEkFAAprvF",
        "title": "ViStruct: Visual Structural Knowledge Extraction via Curriculum Guided Code-Vision Representation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Visual Structural Knowledge Extraction;Code-Vision Representation;Curriculum-based Learning",
        "author": "",
        "aff": "University of Illinois Urbana-Champaign; Northwestern University",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "3;4;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Yangyi-Chen/vi-struct"
    },
    {
        "id": "AGVANImv7S",
        "title": "Systematic Assessment of Factual Knowledge in Large Language Models",
        "track": "main",
        "status": "Short Findings",
        "keywords": "large language models;hallucination;knowledge graph",
        "author": "",
        "aff": "Department of Data Science and AI, Faculty of Information Technology, Monash University, Australia",
        "rating": "",
        "confidence": "5;4;4;4",
        "correctness": "3;2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/RManLuo/llm-facteval"
    },
    {
        "id": "AJDSZ2YVI6",
        "title": "PALS: Personalized Active Learning for Subjective Tasks in NLP",
        "track": "main",
        "status": "Long Main",
        "keywords": "personalization;user modeling;active learning;natural language processing;subjective NLP tasks;subjective NLP",
        "author": "",
        "aff": "Wroc\u0142aw University of Science and Technology, Wroc\u0142aw, Poland",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "AQiuwWLvim",
        "title": "Conditioning on Dialog Acts improves Empathy Style Transfer",
        "track": "main",
        "status": "Long Findings",
        "keywords": "empathy style transfer;text style transfer;empathy;GPT-4;large language models;dialog acts;pragmatics;prompt engineering;in-context learning;few-shot prompting",
        "author": "",
        "aff": "New York University; University of Pennsylvania",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "ARtBIBAmNR",
        "title": "Visually Guided Generative Text-Layout Pre-training for Document Intelligence",
        "track": "main",
        "status": "Reject",
        "keywords": "Multimodal Pre-training;Visual Document Understanding",
        "author": "",
        "aff": "The Chinese University of Hong Kong, MoE Key Laboratory of High Confidence Software Technologies; Noah\u2019s Ark Lab, Huawei Technologies",
        "rating": "",
        "confidence": "4;4;3;4",
        "correctness": "2;2;2;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 1.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "AU2Oq0z4xA",
        "title": "IMU2CLIP: Language-grounded Motion Sensor Translation with Multimodal Contrastive Learning",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Contrastive Learning;NLP Applications in Sensor Signals",
        "author": "",
        "aff": "Meta Reality Labs & FAIR, Meta",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "AXY8GJzm2K",
        "title": "Learn From One Specialized Sub-Teacher: One-to-One Mapping for Feature-Based Knowledge Distillation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Knowledge Distillation;Compression;NLP;Large Language Models;Feature Distillation",
        "author": "",
        "aff": "University of Passau, Germany",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "AYOfbWMRSd",
        "title": "To Build Our Future, We Must Know Our Past: Contextualizing Paradigm Shifts in Natural Language Processing",
        "track": "main",
        "status": "Long Main",
        "keywords": "paradigm shift;future of nlp research;incentives;benchmarking;software;science of science",
        "author": "",
        "aff": "Digital Life Initiative, Cornell Tech, Cornell University, New York City, NY, USA; Language Technologies Institute, Carnegie Mellon University, Pittsburgh, PA, USA and Allen Institute for Artificial Intelligence, Seattle, WA, USA; Language Technologies Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;1;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "AZ8sFZtLHD",
        "title": "Difference-Masking: Choosing What to Mask in Continued Pretraining",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Machine Learning;Self-Supervised Learning;Multimodal;NLP",
        "author": "",
        "aff": "Carnegie Mellon University",
        "rating": "",
        "confidence": "3;1;4",
        "correctness": "2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "AZfRWT1dOa",
        "title": "Not All Demonstration Examples are Equally Beneficial: Reweighting Demonstration Examples for In-Context Learning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "In-Context Learning;Training Example Reweighting",
        "author": "",
        "aff": "National Key Laboratory for Multimedia Information Processing, School of Computer Science, Peking University",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Zhe-Young/WICL"
    },
    {
        "id": "AajIIYMm0d",
        "title": "Subspace Chronicles: How Linguistic Information Emerges, Shifts and Interacts during Language Model Training",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Language Modelling;Representation Learning;Learning Dynamics;Probing;Subspace Analysis",
        "author": "",
        "aff": "ILCC, University of Edinburgh, United Kingdom; ILLC, University of Amsterdam, The Netherlands; Department of Computer Science, IT University of Copenhagen, Denmark; Center for Information and Language Processing (CIS), LMU Munich, Germany",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "AbXA40kggY",
        "title": "BLESS: Benchmarking Large Language Models on Sentence Simplification",
        "track": "main",
        "status": "Long Main",
        "keywords": "text simplification;sentence simplification;large language models;evaluation;in-context learning",
        "author": "",
        "aff": "University of Maryland, US; Cardiff University, UK; Manchester Metropolitan University, UK; Cohere, US; National Tsing Hua University, Taiwan; University of Zurich, Switzerland; Idiap Research Institute, Switzerland",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ZurichNLP/BLESS"
    },
    {
        "id": "AfEowGM3qG",
        "title": "NameGuess: Column Name Expansion for Tabular Data",
        "track": "main",
        "status": "Long Main",
        "keywords": "Column Name Expansion;Natural Language Generation;Datasets",
        "author": "",
        "aff": "Amazon Web Services",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/amazon-science/nameguess"
    },
    {
        "id": "AfnJBOXfAU",
        "title": "COFFEE: Counterfactual Fairness for Personalized Text Generation in Explainable Recommendation",
        "track": "main",
        "status": "Long Main",
        "keywords": "personalized text generation;fairness;bias;explanation for recommendation;human evaluation;counterfactual fairness",
        "author": "",
        "aff": "Meta AI, Menlo Park, CA, USA; University of Virginia, V A, USA; Netflix Inc., Los Gatos, California, USA",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "AgsLcJ9KaX",
        "title": "How do languages influence each other? Studying cross-lingual data sharing during LM fine-tuning",
        "track": "main",
        "status": "Long Main",
        "keywords": "cross-lingual influence;data sharing;training data attribution",
        "author": "",
        "aff": "University of Amsterdam; Google Research",
        "rating": "",
        "confidence": "3;3;3;3",
        "correctness": "4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Ai0oBKlJP2",
        "title": "ChatGPT Beyond English: Towards a Comprehensive Evaluation of Large Language Models in Multilingual Learning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "ChatGPT;Multilingual Evaluation;Large Language Models",
        "author": "",
        "aff": "Adobe Research, USA; Dept. of Computer Science, University of Oregon, OR, USA",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;5;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "AjGXZIgvIb",
        "title": "Towards Concept-Aware Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Concepts;Pretrained Large Language Models",
        "author": "",
        "aff": "The Hebrew University of Jerusalem, Israel; CISPA Helmholtz Center for Information Security, Germany",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Akk5ep2gQx",
        "title": "Semantic Space Grounded Weighted Decoding for Multi-Attribute Controllable Dialogue Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "dialogue response generation;chatbot;controllable generation;multi-attributes",
        "author": "",
        "aff": "University of Texas at Arlington, Arlington, Texas, USA; Shanghai Jiao Tong University, Shanghai, China",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/blmoistawinde/DASC"
    },
    {
        "id": "AlEeMxkgsi",
        "title": "A Scalable Framework for Table of Contents Extraction from Complex ESG Annual Reports",
        "track": "main",
        "status": "Long Main",
        "keywords": "Table of Contents Extraction;Tree",
        "author": "",
        "aff": "Department of Informatics, King\u2019s College London; The Alan Turing Institute; Department of Computer Science, University of Warwick; Department of Informatics, King\u2019s College London",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/xnyuwg/cmm"
    },
    {
        "id": "AoGdaivPEh",
        "title": "Natural Language Decompositions of Implicit Content Enable Better Text Representations",
        "track": "main",
        "status": "Long Main",
        "keywords": "computational social science;implicit;decompositions;decompose;propositions;generation;political science;sentence embeddings;clustering",
        "author": "",
        "aff": "Linguistics, UMIACS, University of Maryland; Computer Science, University of Maryland",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ahoho/inferential-decompositions"
    },
    {
        "id": "AptTXihnhH",
        "title": "Character-LLM: A Trainable Agent for Role-Playing",
        "track": "main",
        "status": "Long Main",
        "keywords": "human simulacra;LLM",
        "author": "",
        "aff": "School of Computer Science, Fudan University; Shanghai Key Laboratory of Intelligent Information Processing, Fudan University; School of Computer Science, Fudan University; Shanghai AI Laboratory; School of Computer Science, Fudan University",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/choosewhatulike/trainable-agents"
    },
    {
        "id": "ArSMQ3dCUx",
        "title": "Noise-Robust Semi-Supervised Learning for Distantly Supervised Relation Extraction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Relation Extraction;Distant Supervision;Semi-Supervised-Learning",
        "author": "",
        "aff": "University of Science and Technology of China; CRIPAC & MAIS, Institute of Automation, Chinese Academy of Sciences; University of Chinese Academy of Sciences",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Ariw9I14zZ",
        "title": "XLM-V: Overcoming the Vocabulary Bottleneck in Multilingual Masked Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Multilingual;Masked Language Models",
        "author": "",
        "aff": "Meta AI",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "AtjErbRsg2",
        "title": "Reconstruct Before Summarize: An Efficient Two-Step Framework for Condensing and Summarizing Meeting Transcripts",
        "track": "main",
        "status": "Long Main",
        "keywords": "meeting summarization;essential content extraction;long-text compression",
        "author": "",
        "aff": "Department of Computer Science and Engineering, The Chinese University of Hong Kong; Department of Computer Science, City University of Hong Kong; SenseTime Research",
        "rating": "",
        "confidence": "4;4;4;3",
        "correctness": "4;4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "AxPGO36LfE",
        "title": "X-SNS: Cross-Lingual Transfer Prediction through Sub-Network Similarity",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Cross-lingual transfer;Multilingual Language Model",
        "author": "",
        "aff": "Dept. of Computer Science, Hanyang University; Dept. of AI Application, Hanyang University; Hyundai Motor Company; Dept. of Computer Science & Dept. of AI Application, Hanyang University",
        "rating": "",
        "confidence": "5;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "B01gPP5YCh",
        "title": "Parameter-Efficient Prompt Tuning Makes Generalized and Calibrated Neural Text Retrievers",
        "track": "main",
        "status": "Long Findings",
        "keywords": "information retrieval;prompt tuning;generalization",
        "author": "",
        "aff": "Meituan; Tsinghua University",
        "rating": "",
        "confidence": "2;3;2",
        "correctness": "2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/THUDM/P-tuning-v2/tree/main/PT-Retrieval"
    },
    {
        "id": "B14ohp9mPU",
        "title": "On Evaluation of Bangla Word Analogies",
        "track": "main",
        "status": "Short Main",
        "keywords": "Bangla;Word Analogy;Evaluation",
        "author": "",
        "aff": "Big Data Intelligence (BDI) Lab, Department of Computer Science & Software Engineering, Auburn University, Alabama, USA",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://paperswithcode.com/dataset/bangla-word-analogy",
        "github": ""
    },
    {
        "id": "B3Muf1R1UD",
        "title": "NLMs: Augmenting Negation in Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Language Models;Negation",
        "author": "",
        "aff": "Samsung R&D Institute India, Bangalore",
        "rating": "",
        "confidence": "2;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "B3SjWgXHzM",
        "title": "Token Prediction as Implicit Classification to Identify LLM-Generated Text",
        "track": "main",
        "status": "Short Main",
        "keywords": "Machine-generated text detection;Text-to-Text Transfer Transformer (T5);Large language model;Transfer learning;Large language model",
        "author": "",
        "aff": "Carnegie Mellon University",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "2;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/MarkChenYutian/T5-Sentinel-public"
    },
    {
        "id": "B3rTZovgaA",
        "title": "Doolittle: Benchmarks and Corpora for Academic Writing Formalization",
        "track": "main",
        "status": "Long Main",
        "keywords": "grammar error correction;large language models;academic writing formalization",
        "author": "",
        "aff": "Toyota Research Institute; National University of Singapore; The Hong Kong University of Science and Technology; University of California, Santa Barbara; ETH Z\u00fcrich",
        "rating": "",
        "confidence": "3;2;3;4",
        "correctness": "3;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/shizhediao/Doolittle"
    },
    {
        "id": "B6BXB4g8eQ",
        "title": "Be Selfish, But Wisely: Investigating the Impact of Agent Personality in Mixed-Motive Human-Agent Interactions",
        "track": "main",
        "status": "Long Main",
        "keywords": "dialogue;negotiation;personality;reinforcement learning",
        "author": "",
        "aff": "University of Southern California, Los Angeles, USA",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "B6Gdg7u04y",
        "title": "LLMaAA: Making Large Language Models as Active Annotators",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large language model;psuedo labeling;active learning",
        "author": "",
        "aff": "Wangxuan Institute of Computer Technology, Peking University, Beijing, China; Langboat Technology, Beijing, China",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ridiculouz/LLMAAA"
    },
    {
        "id": "B8Hz9HqnFm",
        "title": "Towards Zero-shot Learning for End-to-end Cross-modal Translation Models",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Zero-Shot;End-to-End;Speech Translation",
        "author": "",
        "aff": "Alibaba DAMO Academy; The Hong Kong Polytechnic University",
        "rating": "",
        "confidence": "3;4;3;3",
        "correctness": "3;2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "B8mdHlqNfw",
        "title": "Large Language Models and Multimodal Retrieval for Visual Word Sense Disambiguation",
        "track": "main",
        "status": "Long Main",
        "keywords": "visual word sense disambiguation;large language models;multimodal retrieval",
        "author": "",
        "aff": "School of Electrical and Computer Engineering, National Technical University of Athens; Artificial Intelligence and Learning Systems Laboratory, School of Electrical and Computer Engineering, National Technical University of Athens",
        "rating": "",
        "confidence": "5;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "BAA4209PGJ",
        "title": "Set Learning for Generative Information Extraction",
        "track": "main",
        "status": "Short Main",
        "keywords": "Information Extraction",
        "author": "",
        "aff": "Harbin Insitute of Technology, Shenzhen, China; The Chinese University of Hong Kong, Hong Kong, China",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "BB1qrcPgRu",
        "title": "Survival of the Most Influential Prompts: Efficient Black-Box Prompt Search via Clustering and Pruning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "large language models;black-box;discrete prompt learning",
        "author": "",
        "aff": "Language Technology Lab, University of Cambridge; Machine Learning Research Group, University of Oxford",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/cambridgeltl/ClaPS"
    },
    {
        "id": "BEFiYM5Vtx",
        "title": "Multi-Task Knowledge Distillation with Embedding Constraints for Scholarly Keyphrase Boundary Classification",
        "track": "main",
        "status": "Long Main",
        "keywords": "keyphrase boundary classification;multi-task learning;knowledge distillation",
        "author": "",
        "aff": "Computer Science, University of Illinois Chicago",
        "rating": "",
        "confidence": "4;5;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "BFbdO9GwTZ",
        "title": "Generative Adversarial Training with Perturbed Token Detection for Model Robustness",
        "track": "main",
        "status": "Long Main",
        "keywords": "generative adversarial training;adversarial defense;adversarial detection;discriminative pre-trained model",
        "author": "",
        "aff": "Institute of Automation, Chinese Academy of Sciences; School of Artificial Intelligence, University of Chinese Academy of Sciences",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "BGsssE3E4i",
        "title": "Efficient Data Learning for Open Information Extraction with Pre-trained Language Models",
        "track": "main",
        "status": "Short Findings",
        "keywords": "information extraction;efficient;low-resource",
        "author": "",
        "aff": "The Laboratory of Cognition and Decision Intelligence for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China and Tianjin University, Tianjin, China; The Laboratory of Cognition and Decision Intelligence for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China and School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China",
        "rating": "",
        "confidence": "4;3;2;3",
        "correctness": "4;4;1;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "BKchhwhNh3",
        "title": "Roles of Scaling and Instruction Tuning in Language Perception: Model vs. Human Attention",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large Language Models;Attention;Human Resemblance;Instruction Tuning",
        "author": "",
        "aff": "Department of Linguistics and Translation, City University of Hong Kong; National Key Laboratory for Novel Software Technology, Nanjing University",
        "rating": "",
        "confidence": "3;5;3",
        "correctness": "2;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "Available on GitHub"
    },
    {
        "id": "BMIjPXooNq",
        "title": "Harnessing Dataset Cartography for Improved Compositional Generalization in Transformers",
        "track": "main",
        "status": "Long Findings",
        "keywords": "dataset cartography;compositional generalization;training dynamics",
        "author": "",
        "aff": "Hacettepe University, Computer Engineering Department; University of Tehran, Iran; Ko\u00e7 University, KUIS AI Center; Ko\u00e7 University, Computer Engineering Department; University of Tehran, Iran; Tehran Institute for Advanced Studies, Khatam University, Iran",
        "rating": "",
        "confidence": "2;3;4;4",
        "correctness": "4;2;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/cyberiada/cartography-for-compositionality"
    },
    {
        "id": "BNcTB8RZfG",
        "title": "Explicit Alignment and Many-to-many Entailment Based Reasoning for Conversational Machine Reading",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Conversational Machine Reading;Task-oriented dialogue;Textual Entailment",
        "author": "",
        "aff": "School of Artificial Intelligence, Beijing University of Posts and Telecommunications",
        "rating": "",
        "confidence": "5;3;4;2;4;3",
        "correctness": "3;3;4;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "BSApuhuM87",
        "title": "Beware of Model Collapse! Fast and Stable Test-time Adaptation for Robust Question Answering",
        "track": "main",
        "status": "Long Main",
        "keywords": "Question Answering;Roboustness;Test-time adaptation",
        "author": "",
        "aff": "Institute of Computer Science and Technology, Soochow University, China; Department of Computer Science, National University of Singapore",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/yisunlp/Anti-CF"
    },
    {
        "id": "BViIHjzvoY",
        "title": "Data-efficient Active Learning for Structured Prediction with Partial Annotation and Self-Training",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Active Learning;Structured Prediction;Partial Annotation;Self-training",
        "author": "",
        "aff": "Language Technologies Institute, Carnegie Mellon University",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "BYkD1gjbxm",
        "title": "Optimized Tokenization for Transcribed Error Correction",
        "track": "main",
        "status": "Long Main",
        "keywords": "NLP;Speech Recognition;Error Correction",
        "author": "",
        "aff": "OriginAI",
        "rating": "",
        "confidence": "5;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "BYxHeGsiay",
        "title": "From Words to Wires: Generating Functioning Electronic Devices from Natural Language Descriptions",
        "track": "main",
        "status": "Long Findings",
        "keywords": "applications;code generation;electronics;language models",
        "author": "",
        "aff": "University of Arizona",
        "rating": "",
        "confidence": "4;4;3;3",
        "correctness": "3;1;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/cognitiveailab/words2wires"
    },
    {
        "id": "BacLV3QUi8",
        "title": "AniEE: A Dataset of Animal Experimental Literature for Event Extraction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Information Extraction;Event Extraction;Named Entity Recognition;Biomedical Corpus;Scientific Literature;Animal Experiments",
        "author": "",
        "aff": "Kookmin University; KAIST AI; Advanced Institute of Convergence Technology",
        "rating": "",
        "confidence": "3;5;3",
        "correctness": "4;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/domyown/AniEE"
    },
    {
        "id": "BcYvkVgkZy",
        "title": "On Event Individuation for Document-Level Information Extraction",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Information Extraction;Template Filling;Events;Reproducibility",
        "author": "",
        "aff": "University of Rochester; Johns Hopkins University",
        "rating": "",
        "confidence": "3;2;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/wgantt/event_individuation"
    },
    {
        "id": "BdpoEj33DZ",
        "title": "MailEx: Email Event and Argument Extraction",
        "track": "main",
        "status": "Long Main",
        "keywords": "Event Extraction;Email;Information Extraction",
        "author": "",
        "aff": "George Mason University; University of Maryland ARLIS",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "4;4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/salokr/Email-Event-Extraction"
    },
    {
        "id": "Beho3ly3qx",
        "title": "COMET-M: Reasoning about Multiple Events in Complex Sentences",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Reasoning about events;Complex contexts;Discourse",
        "author": "",
        "aff": "University of British Columbia; University of British Columbia, Vector Institute for AI",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "BoKg2pcF0H",
        "title": "DiffusionSL: Sequence Labeling via Tag Diffusion Process",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Generative Models;Sequence Labeling;Tag Diffusion Process",
        "author": "",
        "aff": "School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; The Laboratory of Cognition and Decision Intelligence for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://www.github.com/hzy312/DiffusionSL"
    },
    {
        "id": "Bou2YHsRvG",
        "title": "Code-Switching with Word Senses for Pretraining in Neural Machine Translation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Word Sense Disambiguation;Pretraining approaches;Neural Machine Translation",
        "author": "",
        "aff": "School of Informatics, University of Edinburgh; Sapienza NLP Group, Sapienza University of Rome",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "BpibUh0aB3",
        "title": "Probing the \u201cCreativity\u201d of Large Language Models: Can models produce divergent semantic association?",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Creativity;Semantic association;Text generation",
        "author": "",
        "aff": "Key Laboratory for Biomedical Engineering of Ministry of Education, College of Biomedical Engineering and Instrument Sciences, Zhejiang University / Hangzhou, China",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/DingNLab/probing_creativity"
    },
    {
        "id": "BpsWrnfIIn",
        "title": "Misery Loves Complexity: Exploring Linguistic Complexity in the Context of Emotion Detection",
        "track": "main",
        "status": "Long Findings",
        "keywords": "emotion detection;complexity;readability",
        "author": "",
        "aff": "CLiPS, University of Antwerp; LT3, Language and Translation Technology Team, Ghent University",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "hf.co/datasets/pranaydeeps/CAMEO",
        "github": ""
    },
    {
        "id": "BrqDTTga8J",
        "title": "Multi-view Contrastive Learning for Entity Typing over Knowledge Graphs",
        "track": "main",
        "status": "Long Main",
        "keywords": "Knowledge Graphs;Entity Typing;Knowledge-based Typing",
        "author": "",
        "aff": "ILCC, School of Informatics, University of Edinburgh, UK; School of Computer and Information Technology, Shanxi University, China; School of Computer Science and Informatics, Cardiff University, UK",
        "rating": "",
        "confidence": "5;3;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "BscCXmZopv",
        "title": "SODA: Million-scale Dialogue Distillation with Social Commonsense Contextualization",
        "track": "main",
        "status": "Long Main",
        "keywords": "social commonsense;distillation;dialogue;dataset",
        "author": "",
        "aff": "University of Washington; Carnegie Mellon University; University of Southern California; University of Pittsburgh; Seoul National University; Allen Institute for Artificial Intelligence",
        "rating": "",
        "confidence": "4;4;4;4;3",
        "correctness": "4;4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.8,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://hyunw.kim/sodaverse",
        "github": ""
    },
    {
        "id": "BxY99WBKSV",
        "title": "Ties Matter: Meta-Evaluating Modern Metrics with Pairwise Accuracy and Tie Calibration",
        "track": "main",
        "status": "Long Main",
        "keywords": "meta-evaluation;metrics;kendall's tau",
        "author": "",
        "aff": "Google",
        "rating": "",
        "confidence": "2;4;4",
        "correctness": "4;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/google-research/mt-metrics-eval"
    },
    {
        "id": "C68cYdgLUs",
        "title": "We are Who We Cite: Bridges of Influence Between Natural Language Processing and Other Academic Fields",
        "track": "main",
        "status": "Long Main",
        "keywords": "responsible nlp;scientific influence;interdisciplinarity;bibliometrics",
        "author": "",
        "aff": "National Research Council Canada, University of G\u00f6ttingen Germany; University of G\u00f6ttingen, G\u00f6ttingen, Germany; Institute for Better Health, Toronto, Canada; National Research Council Canada, Ottawa, Canada",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "CEPkRTOlut",
        "title": "Speech Recognition and Meaning Interpretation: Towards Disambiguation of Structurally Ambiguous Spoken Utterances in Indonesian",
        "track": "main",
        "status": "Long Main",
        "keywords": "structural ambiguity in sentences;prosodic information;speech recognition;speech-to-text mapping;meaning\u00a0interpretation",
        "author": "",
        "aff": "Bandung Institute of Technology, Indonesia; Japan Advanced Institute of Science and Technology, Japan; University of Indonesia, Indonesia",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ha3ci-lab/struct_amb_ind"
    },
    {
        "id": "CHffPbQXjX",
        "title": "Towards Being Parameter-Efficient: A Stratified Sparsely Activated Transformer with Dynamic Capacity",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Stratified Mixture-of-Experts;Parameter-efficiency;Dynamic capacity",
        "author": "",
        "aff": "Meta AI; Johns Hopkins University",
        "rating": "",
        "confidence": "4;5;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/fe1ixxu/Stratified_Mixture_of_Experts"
    },
    {
        "id": "CK9mApdZFW",
        "title": "DISCO: A Large Scale Human Annotated Corpus for Disfluency Correction in Indo-European Languages",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Disfluency Correction;Machine Translation;Dataset",
        "author": "",
        "aff": "Indian Institute of Technology Bombay, India",
        "rating": "",
        "confidence": "3;2;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/vineet2104/DISCO"
    },
    {
        "id": "CLVOAHdybT",
        "title": "HFMRE: Constructing Huffman Tree in Bags to Find Excellent Instances for Distantly Supervised Relation Extraction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "multi-instance learning; relation extraction; Huffman Tree; aggregation strategies",
        "author": "",
        "aff": "Key Laboratory of Computing Power Network and Information Security, Ministry of Education, Shandong Computer Science Center (National Supercomputer Center in Jinan), Qilu University of Technology (Shandong Academy of Sciences), Jinan, China; Key Laboratory of Computing Power Network and Information Security, Ministry of Education, Shandong Computer Science Center (National Supercomputer Center in Jinan), Qilu University of Technology (Shandong Academy of Sciences), Jinan, China; Faculty of Data Science, City University of Macau, Macau, China",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/shaocong-qy/HFMRE"
    },
    {
        "id": "CLq5tqZ5SK",
        "title": "A Computational Interface to Translate Strategic Intent from Unstructured Language in a Low-Data Setting",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Text Classification;ChatGPT;Human-Evaluation;Low-Data",
        "author": "",
        "aff": "School of Interactive Computing, Georgia Institute of Technology; Massachusetts Institute of Technology, Lincoln Laboratory; Computer Science Department, Brown University",
        "rating": "",
        "confidence": "2;4;2;3",
        "correctness": "3;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "CMm4w1A4Yd",
        "title": "A Deeper (Autoregressive) Approach to Non-Convergent Discourse Parsing",
        "track": "main",
        "status": "Long Main",
        "keywords": "Discourse;dialogue;style",
        "author": "",
        "aff": "Ben Gurion University of the Negev",
        "rating": "",
        "confidence": "4;4;3;2",
        "correctness": "4;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "CO40wNIY5i",
        "title": "A Unified View of Evaluation Metrics for Structured Prediction",
        "track": "main",
        "status": "Long Main",
        "keywords": "structured prediction;information extraction;evaluation metrics;template extraction;n-ary relation extraction",
        "author": "",
        "aff": "University of Rochester; Johns Hopkins University; Microsoft",
        "rating": "",
        "confidence": "3;3;5",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/wanmok/metametric"
    },
    {
        "id": "CP1PLnFzbr",
        "title": "Context Compression for Auto-regressive Transformers with Sentinel Tokens",
        "track": "main",
        "status": "Short Main",
        "keywords": "context compression;key-value cache compression",
        "author": "",
        "aff": "Shanghai Jiao Tong University, China; University of Texas at Arlington, USA",
        "rating": "",
        "confidence": "4;3;1;3",
        "correctness": "3;3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/DRSY/KV_Compression"
    },
    {
        "id": "CPBEn5mGle",
        "title": "CQE: A Comprehensive Quantity Extractor",
        "track": "main",
        "status": "Long Main",
        "keywords": "quantities;quantity extraction;information extraction",
        "author": "",
        "aff": "Institute of Computer Science, Heidelberg University, Germany",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/vivkaz/CQE"
    },
    {
        "id": "CQgmBmRBMb",
        "title": "Don\u2019t Add, don\u2019t Miss: Effective Content Preserving Generation from Pre-Selected Text Spans",
        "track": "main",
        "status": "Long Findings",
        "keywords": "NLG;Controlled Generation;RL;Controlled Decoding;Distillation",
        "author": "",
        "aff": "Bar-Ilan University, Google Research; Bar-Ilan University",
        "rating": "",
        "confidence": "1;3;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/lovodkin93/CDR_CTR"
    },
    {
        "id": "CblASBV3d4",
        "title": "\"Are Your Explanations Reliable?\" Investigating the Stability of LIME in Explaining Text Classifiers by Marrying XAI and Adversarial Attack",
        "track": "main",
        "status": "Long Main",
        "keywords": "Interpretability;Stability;Robustness;Explainability",
        "author": "",
        "aff": "University of Mississippi, Oxford, MS, USA; Wright State University, Dayton, OH, USA",
        "rating": "",
        "confidence": "4;2;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/cburgerOlemiss/XAIFooler"
    },
    {
        "id": "Cc5yhA1PrC",
        "title": "A Joint Matrix Factorization Analysis of Multilingual Representations",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Representation analysis;Multilingual pre-trained models;Matrix factorization;Morphosyntactic features",
        "author": "",
        "aff": "School of Informatics, University of Edinburgh; Institute for Language, Cognition and Computation, School of Informatics, University of Edinburgh",
        "rating": "",
        "confidence": "4;1;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/zsquaredz/joint_multilingual_analysis"
    },
    {
        "id": "CdcdyN4cvL",
        "title": "Improving Multi-Criteria Chinese Word Segmentation through Learning Sentence Representation",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Chinese Word Segmentation",
        "author": "",
        "aff": "Department of Computer Science and Information Engineering, National Cheng Kung University, Taiwan (R.O.C)",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "CfJiBuysQQ",
        "title": "CLEVR-Implicit: A Diagnostic Dataset for Implicit Reasoning in Referring Expression Comprehension",
        "track": "main",
        "status": "Long Main",
        "keywords": "referring expression comprehension;implicit reasoning;prompt tuning",
        "author": "",
        "aff": "School of Software Engineering, South China University of Technology; School of Software Engineering, South China University of Technology; Key Laboratory of Big Data and Intelligent Robot (South China University of Technology) Ministry of Education",
        "rating": "",
        "confidence": "3;3;3;4",
        "correctness": "4;4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "CgAfbI4kGS",
        "title": "CompleQA: Benchmarking the Impacts of Knowledge Graph Completion Methods on Question Answering",
        "track": "main",
        "status": "Short Findings",
        "keywords": "knowledge graph;link prediction;question answering",
        "author": "",
        "aff": "The Ohio State University; Carnegie Mellon University",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "2;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/PlusRoss/CompleQA"
    },
    {
        "id": "Cib0JSAVwW",
        "title": "Language-Agnostic Bias Detection in Language Models with Bias Probing",
        "track": "main",
        "status": "Long Findings",
        "keywords": "bias detection;nationality bias;multilinguality",
        "author": "",
        "aff": "Language Technology Lab, University of Cambridge; Center for Information and Language Processing, LMU Munich; Munich Center for Machine Learning; Middle East Initiative, Harvard Kennedy School; Marmara University; Harvard Kennedy School; Data Analytics and Computational Social Science, University of Massachusetts Amherst",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/akoksal/LABDet"
    },
    {
        "id": "CihCvXPiEG",
        "title": "Re-weighting Tokens: A Simple and Effective Active Learning Strategy for Named Entity Recognition",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Named entity recognition;active learning",
        "author": "",
        "aff": "Department of Data Science and AI, Monash University",
        "rating": "",
        "confidence": "2;5;5",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Ck3JPqoEeE",
        "title": "Linguistically Motivated Sign Language Segmentation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "sign language;sign language segmentation",
        "author": "",
        "aff": "Bar-Ilan University, University of Zurich; University of Zurich; Bar-Ilan University",
        "rating": "",
        "confidence": "2;4;3",
        "correctness": "2;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "CkvfJdb7mw",
        "title": "Cultural Compass: Predicting Transfer Learning Success in Offensive Language Detection with Cultural Features",
        "track": "main",
        "status": "Long Findings",
        "keywords": "culture;transfer learning;offensive language detection",
        "author": "",
        "aff": "University of Electronic Science and Technology of China; Department of Computer Science, University of Copenhagen",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/lizhou21/cultural-compass"
    },
    {
        "id": "CluDBdRhUp",
        "title": "Probing Representations for Document-level Event Extraction",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Information Extraction;Interpretability;Embedding;Probing;Document-Level Information Extraction",
        "author": "",
        "aff": "Department of Computer Science, University of Texas at Dallas; Department of Computer Science, Cornell University",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Cn3HNSzh14",
        "title": "Controlling Pre-trained Language Models for Grade-Specific Text Simplification",
        "track": "main",
        "status": "Long Main",
        "keywords": "Controllable Text generation;Text Simplification",
        "author": "",
        "aff": "Department of Computer Science, University of Maryland",
        "rating": "",
        "confidence": "4;3;4;4",
        "correctness": "2;3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "CnLpDkgnCn",
        "title": "Mandarin classifier systems optimize to accommodate communicative pressures",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Mandarin Chinese;classifiers;noun classes;noun class processing;word embeddings;mutual information;GAM",
        "author": "",
        "aff": "George Mason University",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "CoEuk8SNI1",
        "title": "Enhancing Emotion Recognition in Conversation via Multi-view Feature Alignment and Memorization",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Emotion Recognition in Conversation;Multi-view Feature Alignment;Memorization",
        "author": "",
        "aff": "College of Computer Science and Technology, Zhejiang University",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/gyhou123/MFAM"
    },
    {
        "id": "Coh1A4iSsl",
        "title": "Revisiting Sparse Retrieval for Few-shot Entity Linking",
        "track": "main",
        "status": "Short Main",
        "keywords": "entity linking;sparse retrieval",
        "author": "",
        "aff": "Harbin Institute of Technology (Shenzhen), Shenzhen, China",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/HITsz-TMG/Sparse-Retrieval-Fewshot-EL"
    },
    {
        "id": "CsCRTvEZg1",
        "title": "MISCA: A Joint Model for Multiple Intent Detection and Slot Filling with Intent-Slot Co-Attention",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multiple Intent Detection;Slot Filling;Intent-Slot Co-Attention;Label Attention",
        "author": "",
        "aff": "VinAI Research, Vietnam",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Cu4Jn4Xt22",
        "title": "Joint Geometrical and Statistical Domain Adaptation for Cross-domain Code Vulnerability Detection",
        "track": "main",
        "status": "Long Main",
        "keywords": "Contrastive Learning;Code Vulnerability;Cross-domain Detection",
        "author": "",
        "aff": "Department of Computer Science and Technology, Tsinghua University; National Key Laboratory of Science and Technology on Information System Security; Department of Automation, Tsinghua University",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "CuI1xfhxaJ",
        "title": "Question Answering as Programming for Solving Time-Sensitive Questions",
        "track": "main",
        "status": "Long Main",
        "keywords": "large language models;reasoning;question answering",
        "author": "",
        "aff": "Shenzhen International Graduate School, Tsinghua University; Microsoft",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/TianHongZXY/qaap"
    },
    {
        "id": "Cx5vVkpsOY",
        "title": "Pragmatics in Language Grounding: Phenomena, Tasks, and Modeling Approaches",
        "track": "main",
        "status": "Long Findings",
        "keywords": "grounding;pragmatics;multimodality;survey",
        "author": "",
        "aff": "MIT; Brown University; DeepMind; Carnegie Mellon; UC Berkeley",
        "rating": "",
        "confidence": "5;5;5",
        "correctness": "4;3;1",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 5.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "CyDf6Q619o",
        "title": "Enabling Unsupervised Neural Machine Translation with Word-level Visual Representations",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Unsupervised Machine Translation;Cross-modal Machine Translation;Word-level Image",
        "author": "",
        "aff": "Pengcheng Laboratory, Shenzhen, China; Harbin Institution of Technology, Harbin, China",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Brianmax99/UNMT-WVR"
    },
    {
        "id": "D0Mp7ILZME",
        "title": "SuperTweetEval: A Challenging, Unified and Heterogeneous Benchmark for Social Media NLP Research",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Social Media;Benchmark;Twitter",
        "author": "",
        "aff": "School of Information, University of Michigan, USA; Snap Inc., Santa Monica, CA, USA; Cardiff NLP, Cardiff University, UK",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://huggingface.co/datasets/cardiffnlp/super_tweeteval",
        "github": ""
    },
    {
        "id": "D0gAwtclWk",
        "title": "Rethinking Negative Pairs in Code Search",
        "track": "main",
        "status": "Long Main",
        "keywords": "Code Search;Contrastive Learning",
        "author": "",
        "aff": "Alibaba-NTU Singapore Joint Research Institute, Nanyang Technological University, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore",
        "rating": "",
        "confidence": "4;2;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Alex-HaochenLi/Soft-InfoNCE"
    },
    {
        "id": "D1kF1Eq7Mv",
        "title": "System Combination via Quality Estimation for Grammatical Error Correction",
        "track": "main",
        "status": "Long Main",
        "keywords": "Grammatical Error Correction;Quality Estimation;System Combination",
        "author": "",
        "aff": "Department of Computer Science, National University of Singapore",
        "rating": "",
        "confidence": "3;3;5",
        "correctness": "4;3;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/nusnlp/greco"
    },
    {
        "id": "D4Cb4gAWro",
        "title": "Predictive Chemistry Augmented with Text Retrieval",
        "track": "main",
        "status": "Long Main",
        "keywords": "information retrieval;chemistry",
        "author": "",
        "aff": "Department of Electrical Engineering and Computer Science, MIT; Department of Electrical Engineering and Computer Science, MIT & Department of Chemical Engineering, MIT; Computer Science and Artificial Intelligence Lab, MIT & Department of Electrical Engineering and Computer Science, MIT",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "D4CoZQY1nt",
        "title": "The Less the Merrier? Investigating Language Representation in Multilingual Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multilingual;low-resource;pre-trained models;linguistic diversity;embedding space;dialect;writing script",
        "author": "",
        "aff": "University of Colorado, Colorado Springs, USA; University of California Berkeley, USA",
        "rating": "",
        "confidence": "3;3;5",
        "correctness": "3;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "D70lPh24o6",
        "title": "Explaining Interactions Between Text Spans",
        "track": "main",
        "status": "Long Main",
        "keywords": "explainability;interactions;spans",
        "author": "",
        "aff": "University of Copenhagen; University of Michigan",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://huggingface.co/datasets/copenlu/spanex",
        "github": "https://github.com/copenlu/spanex"
    },
    {
        "id": "D7omx8QyFP",
        "title": "The CoT Collection: Improving Zero-shot and Few-shot Learning of Language Models via Chain-of-Thought Fine-Tuning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Chain-of-Thought Fine-tuning;Zero-shot Generalization;Few-shot Learning;Large Language Models",
        "author": "",
        "aff": "KAIST AI; KAIST AI, NAVER AI Lab; KAIST AI, University of Washington; NAVER AI Lab",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/kaistAI/CoT-Collection"
    },
    {
        "id": "D97Zfgv4em",
        "title": "MeaeQ: Mount Model Extraction Attacks with Efficient Queries",
        "track": "main",
        "status": "Long Main",
        "keywords": "Model Extraction Attack; Efficient Query Sampling Strategy; Limited Query Budgets",
        "author": "",
        "aff": "Institute of Information Engineering, Chinese Academy of Sciences; Institute of Information Engineering, Chinese Academy of Sciences; School of Cyber Security, University of Chinese Academy of Sciences",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/C-W-D/MeaeQ"
    },
    {
        "id": "D9oq45WsKq",
        "title": "Ensemble-Instruct: Instruction Tuning Data Generation with a Heterogeneous Mixture of LMs",
        "track": "main",
        "status": "Long Findings",
        "keywords": "instruction tuning data generation;prompt learning;ensemble learning",
        "author": "",
        "aff": "IBM Research AI",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/IBM/ensemble-instruct"
    },
    {
        "id": "DDvcWpZNgl",
        "title": "PIEClass: Weakly-Supervised Text Classification with Prompting and Noise-Robust Iterative Ensemble Training",
        "track": "main",
        "status": "Long Main",
        "keywords": "Text Classification;Weak Supervision;Pre-Trained Language Model;Prompt-Based Learning",
        "author": "",
        "aff": "University of Illinois Urbana-Champaign, IL, USA",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/yzhan238/PIEClass"
    },
    {
        "id": "DOlbbJhJ1A",
        "title": "Large Language Models: The Need for Nuance in Current Debates and a Pragmatic Perspective on Understanding",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Models;Critical Analysis;Interpretation;Explanation;Philosophy;Understanding;Pragmatism;NLP",
        "author": "",
        "aff": "Leiden Institute of Advanced Computer Science; Leiden Institute of Advanced Computer Science, Leiden University Medical Centre",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "DPhTTeoyjC",
        "title": "LM vs LM: Detecting Factual Errors via Cross Examination",
        "track": "main",
        "status": "Long Main",
        "keywords": "knowledge;factuality;LLM;question answering;interpretability;interactivity;multi-agent;consistency;fact checking;dialogue",
        "author": "",
        "aff": "Google DeepMind; Blavatnik School of Computer Science, Tel Aviv University; Google Research, Blavatnik School of Computer Science, Tel Aviv University",
        "rating": "",
        "confidence": "4;2;5",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "DQ9WeXpgJt",
        "title": "Unsupervised Sounding Pixel Learning",
        "track": "main",
        "status": "Long Main",
        "keywords": "unsupervised;cross-modal learning;sound source localization;semantic affinity refinement",
        "author": "",
        "aff": "School of Computer Science and Engineering, UESTC; Institute of Electronic and Information Engineering of UESTC in Guangdong, China; Shenzhen Institute for Advanced Study, UESTC",
        "rating": "",
        "confidence": "4;3;4;3",
        "correctness": "4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "DQVGhBdAPG",
        "title": "Identification of Multimodal Stance Towards Frames of Communication",
        "track": "main",
        "status": "Long Main",
        "keywords": "stance detection;covid-19;social media;twitter;multimodal;images;multimedia",
        "author": "",
        "aff": "Human Language Technology Research Institute, The University of Texas at Dallas",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "1;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "DRpZjTJKZh",
        "title": "Probabilistic Tree-of-thought Reasoning for Answering Knowledge-intensive Complex Questions",
        "track": "main",
        "status": "Long Findings",
        "keywords": "LLMs; Probabilistic Tree-of-thought Reasoning; Hallucination; Knowledge-intensive Complex QA",
        "author": "",
        "aff": "Department of Computer Science and Technology, Tsinghua University, Beijing, China; Cloud BU, Huawei Technologies",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "DSmHC8bi3j",
        "title": "Noise-Robust Fine-Tuning of Pretrained Language Models via External Guidance",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Pretrained Language Models;Large-scale Language Models;Learning from Noisy Labels",
        "author": "",
        "aff": "University of Virginia; ByteDance Research; Arizona State University",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "DTELCDufzE",
        "title": "Large Language Models Are Better Adversaries: Exploring Generative Clean-Label Backdoor Attacks Against Text Classifiers",
        "track": "main",
        "status": "Long Findings",
        "keywords": "adversarial machine learning;backdoor attacks;large language models;natural language processing",
        "author": "",
        "aff": "University of Oregon",
        "rating": "",
        "confidence": "3;4;1",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "DTyMi3ReQU",
        "title": "You Are What You Annotate: Towards Better Models through Annotator Representations",
        "track": "main",
        "status": "Long Findings",
        "keywords": "annotator disagreement;annotator representation",
        "author": "",
        "aff": "University of Hawai\u2018i at Hilo, USA; University of Michigan \u2013 Ann Arbor, USA",
        "rating": "",
        "confidence": "3;4;5;3",
        "correctness": "2;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "DVDGNFn1Jm",
        "title": "Reinforced Target-driven Conversational Promotion",
        "track": "main",
        "status": "Long Main",
        "keywords": "Conversational Promotion;Conversational Recommendation;Target-driven Recommenders",
        "author": "",
        "aff": "FPT Software AI Center, Singapore Management University; College of Engineering and Computer Science, VinUniversity; Hong Kong University of Science and Technology; Singapore Management University",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/huyquangdao/RTCP"
    },
    {
        "id": "DgB01RzOqo",
        "title": "Multilingual Large Language Models Are Not (Yet) Code-Switchers",
        "track": "main",
        "status": "Long Main",
        "keywords": "code-switching;benchmark;multilingual large language models",
        "author": "",
        "aff": "Brown University; Samsung R&D Institute Philippines; Bloomberg; MBZUAI; HKUST",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "DgNnVebNPy",
        "title": "LLMs -- the Good, the Bad or the Indispensable?: A Use Case on Legal Statute Prediction and Legal Judgment Prediction on Indian Court Cases",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Legal judgement prediction;Legal Statute prediction;LLMs;explainability;bias;fairness;ethics",
        "author": "",
        "aff": "IIT Madras; IIT Kharagpur; IIT Kanpur; NUJS; IISER Kolkata",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "3;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/somsubhra04/LLM_Legal_Prompt_Generation"
    },
    {
        "id": "Dil6z5sZkD",
        "title": "Adversarial Robustness for Large Language NER models using Disentanglement and Word Attributions",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Adversarial Robustness;Adversarial Attacks;Named Entity Recognition;Large Language Models",
        "author": "",
        "aff": "Amazon Alexa AI; University of Illinois, Urbana Champaign",
        "rating": "",
        "confidence": "2;4;4;3",
        "correctness": "4;4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "DjwSceRw7B",
        "title": "Macedon: Minimizing Representation Coding Rate Reduction for Cross-Lingual Natural Language Understanding",
        "track": "main",
        "status": "Long Findings",
        "keywords": "cross-lingual;rate reduction",
        "author": "",
        "aff": "UNC-Chapel Hill, Chapel Hill, NC, USA; Purdue University, West Lafayette, IN, USA; Google Research, New York, NY, USA",
        "rating": "",
        "confidence": "4;4;3;3",
        "correctness": "3;3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Dl3YgoOh2c",
        "title": "Identifying Statements Crucial for Awareness of Interpretive Nonsense to Prevent Communication Breakdowns",
        "track": "main",
        "status": "Long Main",
        "keywords": "Communication breakdowns;dialogue;context;rephrasing;language model",
        "author": "",
        "aff": "Keio University, Yokohama, Japan",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "DlQeSfGYfS",
        "title": "Focus Your Attention (with Adaptive IIR Filters)",
        "track": "main",
        "status": "Long Main",
        "keywords": "IIR Filters;dynamic Filtering;Transformers",
        "author": "",
        "aff": "The School of Computer Science, Tel Aviv University",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "DmrIEHJxN5",
        "title": "From Complex to Simple: Unraveling the Cognitive Tree for Reasoning with Small Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Reasoning;Cognition;Dual Process Theory",
        "author": "",
        "aff": "Alibaba Group; School of Computer Science and Technology, East China Normal University; Shanghai Institute for AI Education",
        "rating": "",
        "confidence": "2;4;4",
        "correctness": "3;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/alibaba/EasyNLP"
    },
    {
        "id": "DpNUrB6SeZ",
        "title": "Multi-Source Multi-Type Knowledge Exploration and Exploitation for Dialogue Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Dialogue Generation;Natural Language Processing;Dialogue Knowledge",
        "author": "",
        "aff": "Shandong University, Qingdao, China; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, China; MIIT Key Laboratory of Pattern Analysis and Machine Intelligence, Nanjing, China",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Patrick-Ni/KnowEE"
    },
    {
        "id": "Dq023aV4Ih",
        "title": "Hallucination Mitigation in Natural Language Generation from Large-Scale Open-Domain Knowledge Graphs",
        "track": "main",
        "status": "Long Main",
        "keywords": "graph-to-text generation;knowledge graphs",
        "author": "",
        "aff": "Department of Computer Science and Engineering, The University of Texas at Arlington, Arlington, TX, USA",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/idirlab/graphnarrator"
    },
    {
        "id": "Dqg9SLOXZu",
        "title": "Multi-Source Probing for Open-Domain Conversational Understanding",
        "track": "main",
        "status": "Long Main",
        "keywords": "Open-domain dialogue systems;Dialogue comprehension;Dialogue probing;Prompt Learning",
        "author": "",
        "aff": "Department of Computer Science and Technology, Tsinghua University, Beijing, China; The CoAI group, Tsinghua University, Beijing, China; University of Illinois at Urbana-Champaign, IL, USA; Pattern Recognition Center, WeChat Al, Tencent Inc., China",
        "rating": "",
        "confidence": "2;4;4;3",
        "correctness": "4;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "DxYDP3B31K",
        "title": "Enhancing Generative Retrieval with Reinforcement Learning from Relevance Feedback",
        "track": "main",
        "status": "Long Main",
        "keywords": "Generative retrieval; Reinforcement learning; Document retrieval;",
        "author": "",
        "aff": "School of Information, Renmin University of China; Gaoling School of Artificial Intelligence, Renmin University of China",
        "rating": "",
        "confidence": "3;2;2",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Dy2mbQIdMz",
        "title": "DetectLLM: Leveraging Log Rank Information for Zero-Shot Detection of Machine-Generated Text",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Machine-generated Text; Large Language models; LLMs; zero-shot",
        "author": "",
        "aff": "Monash University and CSIRO\u2019s Data61; Mohamed bin Zayed University of Artificial Intelligence, Cornell Unversity; King Abdullah University of Science and Technology; Mohamed bin Zayed University of Artificial Intelligence",
        "rating": "",
        "confidence": "2;5;1",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/mbzuai-nlp/DetectLLM"
    },
    {
        "id": "DzCc4mpH1m",
        "title": "Faster Minimum Bayes Risk Decoding with Confidence-based Pruning",
        "track": "main",
        "status": "Short Main",
        "keywords": "Machine translation;minimum Bayes risk decoding",
        "author": "",
        "aff": "Department of Computer Science and Technology, University of Cambridge",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "5;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 4.666666666666667,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "E4ebDehO3O",
        "title": "Not All Languages Are Created Equal in LLMs: Improving Multilingual Capability by Cross-Lingual-Thought Prompting",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large language models; multilingual capability; cross-lingual-thought prompting;",
        "author": "",
        "aff": "Gaoling School of Artificial Intelligence, Renmin University of China; Microsoft Research Asia, China",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/microsoft/unilm"
    },
    {
        "id": "E5r96sfKO0",
        "title": "AutoTrial: Prompting Language Models for Clinical Trial Design",
        "track": "main",
        "status": "Long Main",
        "keywords": "Drug Development;Clinical Trial;Large Language Model",
        "author": "",
        "aff": "UIUC, Urbana, IL, USA; GE Healthcare, Seattle, WA, USA",
        "rating": "",
        "confidence": "1;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "E9dH0BP5VW",
        "title": "Scaling Laws vs Model Architectures: How does Inductive Bias Influence Scaling?",
        "track": "main",
        "status": "Long Findings",
        "keywords": "language models;architectures;scaling laws",
        "author": "",
        "aff": "Google",
        "rating": "",
        "confidence": "3;3;4;3",
        "correctness": "3;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "EDuKP7DqCk",
        "title": "Text Embeddings Reveal (Almost) As Much As Text",
        "track": "main",
        "status": "Long Main",
        "keywords": "text embeddings;text retrieval;privacy;inversion;leakage attack",
        "author": "",
        "aff": "Department of Computer Science, Cornell University",
        "rating": "",
        "confidence": "4;3;3;3",
        "correctness": "4;3;3;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "github.com/jxmorris12/vec2text"
    },
    {
        "id": "EFML9BJcIH",
        "title": "Can Foundation Models Watch, Talk and Guide You Step by Step to Make a Cake?",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Visual Task Guidance;Multimodal;Large Language Model;Foundation Model",
        "author": "",
        "aff": "Syracuse University; University of Michigan",
        "rating": "",
        "confidence": "4;5;2",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "EG7gjHZ8cm",
        "title": "Geographical Erasure in Language Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "large language models;fairness;language generation;bias;world knowledge",
        "author": "",
        "aff": "Helsing, Berlin, Germany; Amazon, Berlin, Germany; Indian Institute of Science (IISc), Bangalore, India",
        "rating": "",
        "confidence": "3;3;3;4",
        "correctness": "4;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/amazon-science/geographical-erasure-in-language-generation"
    },
    {
        "id": "EJ4N7PX6dm",
        "title": "Improved Pseudo Data for Machine Translation Quality Estimation with Constrained Beam Search",
        "track": "main",
        "status": "Long Main",
        "keywords": "Quality Estimation;Machine Translation;Pseudo Data",
        "author": "",
        "aff": "Huawei Translation Services Center, Beijing, China; National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China",
        "rating": "",
        "confidence": "4;3;1;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/NJUNLP/njuqe"
    },
    {
        "id": "ESGY2Ftbfg",
        "title": "Pre-training Language Models for Comparative Reasoning",
        "track": "main",
        "status": "Long Main",
        "keywords": "language model pre-training;question answering;question generation;summarization;comparative reasoning",
        "author": "",
        "aff": "University of Notre Dame, Tencent AI Seattle Lab; University of Notre Dame",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "ESgkAKGUJP",
        "title": "Bridging Information-Theoretic and Geometric Compression in Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "compression;information theory;language models",
        "author": "",
        "aff": "ICREA / Barcelona; Universitat Pompeu Fabra / Barcelona",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "ESyts8YSub",
        "title": "Efficiently Enhancing Zero-Shot Performance of Instruction Following Model via Retrieval of Soft Prompt",
        "track": "main",
        "status": "Long Findings",
        "keywords": "natural language processing;zeroshot language models;prompt tuning",
        "author": "",
        "aff": "KAIST",
        "rating": "",
        "confidence": "3;2;5;3",
        "correctness": "2;4;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "github.com/seonghyeonye/RoSPr"
    },
    {
        "id": "ETNa4Wb65J",
        "title": "Let's Sample Step by Step: Adaptive-Consistency for Efficient Reasoning and Coding with LLMs",
        "track": "main",
        "status": "Long Main",
        "keywords": "LLMs;reasoning;efficient reasoning;sampling in llms",
        "author": "",
        "aff": "Department of Computer Science, Indian Institute of Technology, Delhi; Department of Computer Science, Indian Institute of Technology, Delhi; Yardi School of Artificial Intelligence, Indian Institute of Technology, Delhi; Language Technologies Institute, Carnegie Mellon University",
        "rating": "",
        "confidence": "3;4;4;4",
        "correctness": "4;3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://sample-step-by-step.info/",
        "github": ""
    },
    {
        "id": "EV5dNDiC7I",
        "title": "BLM-s/lE: A structured dataset of English spray-load verb alternations for testing generalization in LLMs",
        "track": "main",
        "status": "Long Findings",
        "keywords": "verb alternation;generating rules;sentence embeddings",
        "author": "",
        "aff": "; Department of Linguistics, University of Geneva",
        "rating": "",
        "confidence": "2;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "EVfHUvhRra",
        "title": "Large Language Models Only Pass Primary School Exams in Indonesia: A Comprehensive Test on IndoMMLU",
        "track": "main",
        "status": "Long Main",
        "keywords": "large language models;Indonesian school exam problems;evaluation;local languages and cultures",
        "author": "",
        "aff": "Quantic School of Business and Technology; The University of Melbourne; Department Natural Language Processing, MBZUAI",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/fajri91/IndoMMLU"
    },
    {
        "id": "EY9k2x5qWB",
        "title": "KRLS: Improving End-to-End Response Generation in Task Oriented Dialog with Reinforced Keywords Learning",
        "track": "main",
        "status": "Long Main",
        "keywords": "task-oriented dialogues;reinforcement learning",
        "author": "",
        "aff": "Columbia University",
        "rating": "",
        "confidence": "4;5;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/jasonyux/KRLS"
    },
    {
        "id": "EhPYwBBFYb",
        "title": "UPRISE: Universal Prompt Retrieval for Improving Zero-Shot Evaluation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Prompt Engineering;Large Language Model;Zero-shot Evaluation",
        "author": "",
        "aff": "Microsoft Corporation",
        "rating": "",
        "confidence": "4;4;2",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/microsoft/LMOps"
    },
    {
        "id": "Eib6OOeVJI",
        "title": "Pre-training Multi-task Contrastive Learning Models for Scientific Literature Understanding",
        "track": "main",
        "status": "Long Findings",
        "keywords": "scientific literature understanding;multi-task learning;contrastive learning;language model pre-training",
        "author": "",
        "aff": "University of Illinois at Urbana-Champaign; Microsoft Research; Microsoft Search, Assistant and Intelligence",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://scimult.github.io/"
    },
    {
        "id": "Ek87791lcO",
        "title": "Prompt as Triggers for Backdoor Attack: Examining the Vulnerability in Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Backdoor Attack; Prompt; Large Language Model",
        "author": "",
        "aff": "Zhejiang University, Zhejiang, China; Nanyang Technological University, Singapore; Hong Kong University of Science and Technology, Hong Kong, China; Jinan University, Guangzhou, China; Jinan University, Guangzhou, China; Nanyang Technological University, Singapore",
        "rating": "",
        "confidence": "5;5;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/shuaizhao95/Prompt_attack"
    },
    {
        "id": "EkftL7NgtW",
        "title": "DNA: Denoised Neighborhood Aggregation for Fine-grained Category Discovery",
        "track": "main",
        "status": "Long Main",
        "keywords": "Fine-grained Category Discovery;Denoised Neighborhood Contrastive Learning",
        "author": "",
        "aff": "Department of Engineering, University of Massachusetts Boston; School of Automation Science and Engineering, Xi\u2019an Jiaotong University; School of Computer Science and Technology, MOEKLNNS Lab, Xi\u2019an Jiaotong University; Lenovo Research",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Lackel/DNA"
    },
    {
        "id": "EnUgSeghBl",
        "title": "Impressions: Visual Semiotics and Aesthetic Impact Understanding",
        "track": "main",
        "status": "Long Main",
        "keywords": "Visual Semiotics;Stylistic Analysis;Computational Aesthetics;Image Captioning;Multimodal Datasets",
        "author": "",
        "aff": "Stanford University; Georgia Institute of Technology",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/SALT-NLP/Impressions"
    },
    {
        "id": "EpBNf4Arod",
        "title": "PR-MCS: Perturbation Robust Metric for MultiLingual Image Captioning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Image Captioning metric;Perturbation Robustness",
        "author": "",
        "aff": "IPAI, Seoul National University; Adobe Research; Dept. of Electrical and Computer Engineering, Seoul National University",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/yong1-kim/PR-MCS"
    },
    {
        "id": "EpJ7qqR0ad",
        "title": "MetaReVision: Meta-Learning with Retrieval for Visually Grounded Compositional Concept Acquisition",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Compositional Learning;Meta-Learning;Retrieval-enhance Learning;Visual-Language Models",
        "author": "",
        "aff": "Michigan State University; University of Michigan",
        "rating": "",
        "confidence": "2;3;4;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "EtC8wfjSw4",
        "title": "Human Raters Cannot Distinguish English Translations from Original English Texts",
        "track": "main",
        "status": "Short Main",
        "keywords": "translationese;human evaluation;translation",
        "author": "",
        "aff": "Georgetown University",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "EtNebdSBpe",
        "title": "Learning under Label Proportions for Text Classification",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Label Proportions;Privacy;Weak Supervision;Theory",
        "author": "",
        "aff": "UCLA",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "{{project link not provided}}",
        "github": "{{github link not provided}}"
    },
    {
        "id": "EuMmDTVFjL",
        "title": "Dimensions of Online Conflict: Towards Modeling Agonism",
        "track": "main",
        "status": "Long Findings",
        "keywords": "online conversations;conflict;agonism;content moderation",
        "author": "",
        "aff": "Digital Democracies Institute, Simon Fraser University, Canada; Department of Computer Science, University of Sheffield, UK",
        "rating": "",
        "confidence": "5;4;5",
        "correctness": "4;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "EvVWHQ5l6X",
        "title": "One For All $\\&$ All For One: Bypassing Hyperparameter Tuning with Model Averaging for Cross-Lingual Transfer",
        "track": "main",
        "status": "Short Findings",
        "keywords": "zero-shot cross-lingual transfer;multilingual representation learning",
        "author": "",
        "aff": "Language Technology Lab, University of Cambridge, UK; Center For Artificial Intelligence and Data Science, University of W\u00fcrzburg, Germany",
        "rating": "",
        "confidence": "4;2;5",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "EwNVh5fuRF",
        "title": "Select, Prompt, Filter: Distilling Large Language Models for Summarizing Conversations",
        "track": "main",
        "status": "Short Main",
        "keywords": "Text Summarization;Generative AI;Knowledge distillation;Data filtering",
        "author": "",
        "aff": "Zoom Video Communications",
        "rating": "",
        "confidence": "3;3;2",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Exh156fVSS",
        "title": "Exploiting Contrastive Learning and Numerical Evidence for Confusing Legal Judgment Prediction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "legal artificial intelligence;legal judgment prediction;contrastive learning;information extraction",
        "author": "",
        "aff": "Alibaba Group; Shanghai AI Laboratory and Shanghai Institute for Advanced Study of Zhejiang University; Nanyang Technological University; Zhejiang University; University of Massachusetts at Amherst",
        "rating": "",
        "confidence": "1;5;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/leileigan/ContrastiveLJP"
    },
    {
        "id": "ExpskenHdP",
        "title": "StereoMap: Quantifying the Awareness of Human-like Stereotypes in Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Stereotype;Bias;Social perception in language models",
        "author": "",
        "aff": "University of Illinois at Urbana-Champaign",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "F1G7y94K02",
        "title": "Dissecting Recall of Factual Associations in Auto-Regressive Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "language models;knowledge tracing;knowledge localization;interpretability",
        "author": "",
        "aff": "Google DeepMind; Tel Aviv University and Google Research",
        "rating": "",
        "confidence": "3;1;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/google-research/google-research/tree/master/dissecting_factual_predictions"
    },
    {
        "id": "F4qNZtkk3V",
        "title": "An Empirical Study on Multiple Knowledge from ChatGPT for Emotion Recognition in Conversations",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Emotion Recognition in Conversations;Graph Network;Supervised Contrastive Learning",
        "author": "",
        "aff": "Harbin Institute of Technology, Shenzhen, China; Guangdong Provincial Key Laboratory of Novel Security Intelligence Technologies; Harbin Institute of Technology, Shenzhen, China; Guangdong Provincial Key Laboratory of Novel Security Intelligence Technologies; Peng Cheng Laboratory, Shenzhen, China; Harbin Institute of Technology, Harbin, China; The Chinese University of Hong Kong, Hong Kong, China",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/TuGengs/MKFM"
    },
    {
        "id": "FAiFBfFTGZ",
        "title": "Accelerating Toeplitz Neural Network with Constant-time Inference Complexity",
        "track": "main",
        "status": "Long Main",
        "keywords": "Toeplitz Neural Network;inference;constant-time complexity",
        "author": "",
        "aff": "OpenNLPLab, Shanghai Artificial Intelligence Laboratory",
        "rating": "",
        "confidence": "2;2;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/OpenNLPLab/ETSC-Exact-Toeplitz-to-SSM-Conversion"
    },
    {
        "id": "FAimEpR9Fh",
        "title": "What Makes it Ok to Set a Fire? Iterative Self-distillation of Contexts and Rationales for Disambiguating Defeasible Social and Moral Situations",
        "track": "main",
        "status": "Long Findings",
        "keywords": "moral reasoning;defeasible reasoning;commonsense reasoning;language groundings;knowledge distillation",
        "author": "",
        "aff": "Paul G. Allen School of Computer Science & Engineering, University of Washington; Allen Institute for Artificial Intelligence",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://huggingface.co/datasets/kavelrao/d-Rules-of-Thumb",
        "github": ""
    },
    {
        "id": "FGBEoz9WzI",
        "title": "Automatic Prompt Augmentation and Selection with Chain-of-Thought from Labeled Data",
        "track": "main",
        "status": "Long Findings",
        "keywords": "large language models;chain-of-thought;prompt tuning;few-shot prompting",
        "author": "",
        "aff": "The Hong Kong University of Science and Technology",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/SHUMKASHUN/Automate-CoT"
    },
    {
        "id": "FGBWDf7Z19",
        "title": "XLS-R fine-tuning on noisy word boundaries for unsupervised speech segmentation into words",
        "track": "main",
        "status": "Short Findings",
        "keywords": "unsupervised speech segmentation into words;self-supervised Learning;self-training",
        "author": "",
        "aff": "Inria; ENS, INSERM, UPEC, PSL, Inria, Paris, Meta AI",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://gitlab.cognitive-ml.fr/ralgayres/wav2boundaries"
    },
    {
        "id": "FKNtgr0qQy",
        "title": "Emergence of Abstract State Representations in Embodied Sequence Modeling",
        "track": "main",
        "status": "Long Main",
        "keywords": "Interpretability and Analysis; Decision Making via Sequence Modeling; Language Grounding to Vision and Beyond",
        "author": "",
        "aff": "Brown University; Google Research",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://abstract-state-seqmodel.github.io",
        "github": ""
    },
    {
        "id": "FLSQjYmzIp",
        "title": "Language Guided Visual Question Answering: Elevate Your Multimodal Language Model Using Knowledge-Enriched Prompts",
        "track": "main",
        "status": "Short Findings",
        "keywords": "VQA;Multimodal Language Models;Question Answering",
        "author": "",
        "aff": "Singapore University of Technology and Design, Singapore; University of Michigan, USA",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/declare-lab/LG-VQA"
    },
    {
        "id": "FMWVtVct0V",
        "title": "Towards Anytime Fine-tuning: Continually Pre-trained Language Models with Hypernetwork Prompts",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Continual learning; Pre-trained language model; Prompt learning",
        "author": "",
        "aff": "Nanyang Technological University; University of Science and Technology of China; Ant Group",
        "rating": "",
        "confidence": "2;3;3;3",
        "correctness": "3;4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "FMwflM9yVJ",
        "title": "CONTRASTE: Supervised Contrastive Pre-training With Aspect-based Prompts For Aspect Sentiment Triplet Extraction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "supervised contrastive learning;pretraining;t5;encoder-decoder;generative;aste;acos;aesc;tasd;absa",
        "author": "",
        "aff": "Indian Institute Of Technology Kharagpur",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "FRRlmKxuf2",
        "title": "Cue-CoT: Chain-of-thought Prompting for Responding to In-depth Dialogue Questions with LLMs",
        "track": "main",
        "status": "Long Findings",
        "keywords": "chain-of-thoughts;in-context learning;personalized dialogue system;empathetic dialogue system;large language models",
        "author": "",
        "aff": "Huawei Noah\u2019s Ark Lab; Harbin Institute of Technology, Shenzhen, China; Peng Cheng Laboratory, Shenzhen, China; National University of Singapore; MoE Key Laboratory of High Confidence Software Technologies, The Chinese University of Hong Kong",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "FS1a4CDZsP",
        "title": "PAC-tuning: Fine-tuning Pre-trained Language Models with PAC-driven Perturbed Gradient Descent",
        "track": "main",
        "status": "Long Main",
        "keywords": "language model;fine-tuning;pac-bayesian bound;perturbed gradient descent",
        "author": "",
        "aff": "Michigan State University; UC Santa Barbara",
        "rating": "",
        "confidence": "2;4;3;4",
        "correctness": "3;4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/MSU-NLP-CSS/PAC-tuningNLP"
    },
    {
        "id": "FTiXh63BVO",
        "title": "Uniform Complexity for Text Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "text complexity;natural language generation;evaluation;narrative generation",
        "author": "",
        "aff": "National University, Philippines; University of Bath, UK",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/imperialite/uniform-complexity-textgen"
    },
    {
        "id": "FXObwPWgUc",
        "title": "Leveraging GPT-4 for Automatic Translation Post-Editing",
        "track": "main",
        "status": "Long Findings",
        "keywords": "automatic post editing;neural machine translation;large language models;application",
        "author": "",
        "aff": "Microsoft Azure AI, Redmond, Washington",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Faxkz2V56o",
        "title": "Noisy Self-Training with Synthetic Queries for Dense Retrieval",
        "track": "main",
        "status": "Long Findings",
        "keywords": "dense retrieval;self training;synthetic queries",
        "author": "",
        "aff": "School of Computing and Information Systems, The University of Melbourne, Victoria, Australia; School of Computing and Information Systems, The University of Melbourne, Victoria, Australia\u2217Now at Google DeepMind",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Fantabulous-J/Self-Training-DPR2008"
    },
    {
        "id": "FgEM735i5M",
        "title": "Scene Graph Enhanced Pseudo-Labeling for Referring Expression Comprehension",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Referring Expression Comprehension;Visual Grounding",
        "author": "",
        "aff": "School of Software Engineering, South China University of Technology; School of Software Engineering, South China University of Technology; Key Laboratory of Big Data and Intelligent Robot (South China University of Technology) Ministry of Education",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "FghDWBBsIm",
        "title": "Target-to-Source Augmentation for Aspect Sentiment Triplet Extraction",
        "track": "main",
        "status": "Long Main",
        "keywords": "Aspect-Based Sentiment Analysis;Data Augmentation;Reinforcement Learning",
        "author": "",
        "aff": "Harbin Insitute of Technology, Shenzhen, China; Peng Cheng Laboratory, Shenzhen, China; The Chinese University of Hong Kong, Hong Kong, China",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/HITSZ-HLT/T2S-Augmentation"
    },
    {
        "id": "Fj07R03qkz",
        "title": "IAEval: A Comprehensive Evaluation of Instance Attribution on Natural Language Understanding",
        "track": "main",
        "status": "Long Findings",
        "keywords": "evaluation; instance attribution",
        "author": "",
        "aff": "MOE Key Laboratory of Trustworthy Distributed Computing and Service, Beijing University of Posts and Telecommunications, Beijing, China; Baidu Inc., Beijing, China; University of Science and Technology of China, Hefei, China",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Fm0Brp3cTS",
        "title": "UPTON: Preventing Authorship Leakage from Public Text Release via Data Poisoning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Authorship Attribution",
        "author": "",
        "aff": "The University of Mississippi, USA; University of Maryland, USA; The Pennsylvania State University, USA",
        "rating": "",
        "confidence": "4;1;5",
        "correctness": "5;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Fqv0rgvkol",
        "title": "Paraphrase Types for Generation and Detection",
        "track": "main",
        "status": "Long Main",
        "keywords": "paraphrase generation and detection;paraphrase types;paraphrasing tasks",
        "author": "",
        "aff": "University of G\u00f6ttingen, Germany",
        "rating": "",
        "confidence": "3;5;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "G0ZGGpSj7i",
        "title": "Defining a New NLP Playground",
        "track": "main",
        "status": "Long Findings",
        "keywords": "position paper; theme track; large language models",
        "author": "",
        "aff": "University of Illinois Urbana-Champaign; Northwestern University; Dataminr, Inc.; University of Melbourne",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "5;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "G12y1Pz3vJ",
        "title": "Improving Unsupervised Relation Extraction by Augmenting Diverse Sentence Pairs",
        "track": "main",
        "status": "Long Main",
        "keywords": "unsupervised relation extraction;relation representation learning;contrastive learning",
        "author": "",
        "aff": "Department of Computer Science, Iowa State University, Ames, Iowa, USA",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/qingwang-isu/AugURE"
    },
    {
        "id": "G13P9iWzKc",
        "title": "When Language Models Fall in Love: Animacy Processing in Transformer Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "animacy;language models;selectional constraints;semantics;discourse context",
        "author": "",
        "aff": "Technion\u2014IIT, Israel; ILLC, University of Amsterdam",
        "rating": "",
        "confidence": "4;4;4;3",
        "correctness": "4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "G3IjhUERrD",
        "title": "CoF-CoT: Enhancing Large Language Models with Coarse-to-Fine Chain-of-Thought Prompting for Multi-domain NLU Tasks",
        "track": "main",
        "status": "Short Main",
        "keywords": "large language model;natural language understanding;chain-of-thought;multi-step reasoning;slot filling;intent detection;semantic parsing;abstract meaning representation",
        "author": "",
        "aff": "Department of Computer Science, University of Illinois at Chicago, Chicago, IL, USA; Amazon, Seattle, WA, USA; Salesforce Research, Palo Alto, CA, USA",
        "rating": "",
        "confidence": "3;2;2",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/nhhoang96/CoF-CoT"
    },
    {
        "id": "G6E3uzABf1",
        "title": "Improving Consistency for Text Summarization with Energy Functions",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Document Summarization;Consistent Summarization",
        "author": "",
        "aff": "University of Illinois Urbana-Champaign; Amazon",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "G6gj7Dydc5",
        "title": "HEAR: Hearing Enhanced Audio Response for Video-grounded Dialogue",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Video-grounded Dialouge;Video Scene Understanding;Open-ended Video Question Answering",
        "author": "",
        "aff": "Chung-Ang University; Korea Advanced Institute of Science and Technology (KAIST)",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "G7IbRKrAOE",
        "title": "Calc-X and Calcformers: Empowering Arithmetical Chain-of-Thought through Interaction with Symbolic Systems",
        "track": "main",
        "status": "Short Main",
        "keywords": "arithmetic reasoning;multistep reasoning;dataset;generation",
        "author": "",
        "aff": "Faculty of Informatics, Masaryk University, Czech Republic; The Central European Institute of Technology, Masaryk University, Czech Republic",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "2;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/prompteus/calc-x"
    },
    {
        "id": "GDPMVALXqv",
        "title": "Using In-Context Learning to Improve Dialogue Safety",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Dialogue Safety;Toxicity in NLP;Bias in NLP;Dialogue Systems;In-Context Learning;Retrieval",
        "author": "",
        "aff": "Amazon Alexa AI; Mila and McGill University; Language Technologies Institute, Carnegie Mellon University",
        "rating": "",
        "confidence": "3;5;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "GEZW6VqQNg",
        "title": "Can ChatGPT Defend its Belief in Truth? Evaluating LLM Reasoning via Debate",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Reasoning;Large Language Models;ChatGPT",
        "author": "",
        "aff": "The Ohio State University, Columbus, OH",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/OSU-NLP-Group/Auto-Dialectical-Evaluation"
    },
    {
        "id": "GFgPmhLVhC",
        "title": "Syntax Matters: Towards Spoken Language Understanding via Syntax-Aware Attention",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Spoken Language understanding;Syntactic Dependency Parsing;Feature Fusion",
        "author": "",
        "aff": "Peking University; Guangdong University of Technology",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "GLA4ablO3M",
        "title": "FActScore: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Text Generation;Factuality;Evaluation;Large Language Models",
        "author": "",
        "aff": "University of Massachusetts Amherst; University of Washington; Meta AI",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/shmsw25/FActScore"
    },
    {
        "id": "GOBxWdRpfz",
        "title": "Re-ViLM: Retrieval-Augmented Visual Language Model for Zero and Few-Shot Image Captioning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Retrieval;Visual Language Model;Image-to-Text",
        "author": "",
        "aff": "3UT Austin; 4University of Wisconsin\u2013Madison; 2NVIDIA; 5California Institute of Technology; 1UIUC",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "GQ1rtVVIy2",
        "title": "Identifying {Early Maladaptive Schemas} from Mental Health Question Texts",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Mental Health;Schema Therapy;Early Maladaptive Schema;Personality Disorders;Classification",
        "author": "",
        "aff": "Integrative Sciences and Engineering Programme, National University of Singapore; Institute of Data Science, National University of Singapore",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "GSNoZKqHgO",
        "title": "Let's Synthesize Step by Step: Iterative Dataset Synthesis with Large Language Models by Extrapolating Errors from Small Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Dataset Synthesis;large language models;efficiency",
        "author": "",
        "aff": "ETH Z\u00fcrich; AIWaves Inc.; HKUST; AIWaves Inc.; ETH Z\u00fcrich",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/RickySkywalker/Synthesis_Step-by-Step_Official"
    },
    {
        "id": "GSnAO2qUHy",
        "title": "Multiview Clickbait Detection via Jointly Modeling Subjective and Objective Preference",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Clickbait Detection;Subjective Feeling;Objective Content Relevance;Heterogeneous Dynamic Graph Network",
        "author": "",
        "aff": "James Cook University, Australia; Tongji University, China; Beijing Institute of Technology, China; University of Technology Sydney, Australia",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "GTqt0X2Swn",
        "title": "Affective and Dynamic Beam Search for Story Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Discourse Analysis;Sentiment Analysis;Affective Computing",
        "author": "",
        "aff": "Columbia University; University of Southern California; Allen Institute for Artificial Intelligence; University of North Carolina; University of California, Davis",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/tenghaohuang/AFFGEN.git"
    },
    {
        "id": "GWOCiRkjCF",
        "title": "Precedent-Enhanced Legal Judgment Prediction with LLM and Domain-Model Collaboration",
        "track": "main",
        "status": "Long Main",
        "keywords": "NLP;Large Language Model;Model Collaboration",
        "author": "",
        "aff": "Zhejiang University, Hangzhou, China; Alibaba Group, Hangzhou, China; Worcester Polytechnic Institute, USA",
        "rating": "",
        "confidence": "5;5;4",
        "correctness": "2;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "GbApUL7sDL",
        "title": "Do \u201cEnglish\u201d Named Entity Recognizers Work Well on Global Englishes?",
        "track": "main",
        "status": "Long Findings",
        "keywords": "NER;global english",
        "author": "",
        "aff": "Department of Computer Science, Stanford University, Stanford, CA 94305-9030, U.S.A.",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "GeFFYOCkvS",
        "title": "Multilingual Coarse Political Stance Classification of Media. The Editorial Line of a ChatGPT and Bard Newspaper",
        "track": "main",
        "status": "Short Findings",
        "keywords": "political bias;news;stance classification;instruction-following language models;chatGPT;Bard",
        "author": "",
        "aff": "DFKI GmbH, Saarland Informatics Campus, Saarbr\u00fcken, Germany",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "GgriuyaTZU",
        "title": "Ultra-Fine Entity Typing with Prior Knowledge about Labels: A Simple Clustering Based Strategy",
        "track": "main",
        "status": "Long Findings",
        "keywords": "ultra-fine entity typing;word embeddings;conceptual neighbourhood",
        "author": "",
        "aff": "CRIL CNRS & Univ. Artois, France; USST, Shanghai, China; Cardiff University, UK",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/lina-luck/ufet_with_domains"
    },
    {
        "id": "GnEGvlOcwr",
        "title": "Error Detection for Text-to-SQL Semantic Parsing",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Semantic Parsing;Text-to-SQL;Error Detection",
        "author": "",
        "aff": "The Ohio State University",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "5;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/OSU-NLP-Group/Text2SQL-Error-Detection"
    },
    {
        "id": "Gp8EmdJLUj",
        "title": "Simplicity Level Estimate (SLE): A Learned Reference-Less Metric for Sentence Simpli\ufb01cation",
        "track": "main",
        "status": "Short Main",
        "keywords": "simplification;evaluation;quality estimation",
        "author": "",
        "aff": "Universit\u00e9 de Lorraine, CNRS/LORIA; Universit\u00e9 de Lorraine, Centrale Sup\u00e9lec, CNRS/LORIA; CNRS/LORIA, Universit\u00e9 de Lorraine",
        "rating": "",
        "confidence": "3;1;4;4",
        "correctness": "3;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/liamcripwell/sle"
    },
    {
        "id": "GprvtTwOxy",
        "title": "Unlearn What You Want to Forget: Efficient Unlearning for LLMs",
        "track": "main",
        "status": "Long Main",
        "keywords": "Efficient Unlearning;Large Language Model",
        "author": "",
        "aff": "Stanford University; Georgia Institute of Technology",
        "rating": "",
        "confidence": "2;3;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/SALT-NLP/Efficient_Unlearning"
    },
    {
        "id": "Grj9GJUcuZ",
        "title": "SimCSE++: Improving Contrastive Learning for Sentence Embeddings from Two Perspectives",
        "track": "main",
        "status": "Long Main",
        "keywords": "sentence embedding;contrastive learning;dimention-wise contrastive learning",
        "author": "",
        "aff": "Nanyang Technological University; Tencent AI Lab; City University of Hong Kong",
        "rating": "",
        "confidence": "3;5;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Jiahao004/SimCSE-plus-plus"
    },
    {
        "id": "Gzuzpl4Jje",
        "title": "Continual Learning for Multilingual Neural Machine Translation via Dual Importance-based Model Division",
        "track": "main",
        "status": "Long Main",
        "keywords": "Multilingual Neural Machine Translation;Continual Learning;Model Pruning",
        "author": "",
        "aff": "Xiamen University; Dalian University of Technology; Institute for AI Industry Research, Tsinghua University",
        "rating": "",
        "confidence": "4;3;4;3",
        "correctness": "4;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/raburabu91/BVP4CL"
    },
    {
        "id": "H0SoE2ch5l",
        "title": "Context Quality Matters in Training Fusion-in-Decoder for Extractive Open-Domain Question Answering",
        "track": "main",
        "status": "Long Findings",
        "keywords": "retrieval-augmented generation models;fusion-in-decoder;question answering",
        "author": "",
        "aff": "NEC Corporation",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "H5vtCpKisA",
        "title": "Visually-Situated Natural Language Understanding with Contrastive Reading Model and Frozen Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Visual Document Understanding;OCR;Contrastive Learning;Multimodal Language Models;Document Visual Question Answering;Transformer-based Models",
        "author": "",
        "aff": "Korea University; NAVER AI Lab; NAVER Cloud AI; NAVER Cloud AI, KAIST AI; NAVER Cloud AI, Korea University",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/naver-ai/cream"
    },
    {
        "id": "HFbtrmefx7",
        "title": "FedTherapist: Mental Health Monitoring with User-Generated Linguistic Expressions on Smartphones via Federated Learning",
        "track": "main",
        "status": "Short Main",
        "keywords": "mental health monitoring;federated learning;mobile healthcare;on-device ML;speech",
        "author": "",
        "aff": "KAIST; Emory University; SoftlyAI; Tsinghua University",
        "rating": "",
        "confidence": "1;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "HGLvAAKNKx",
        "title": "An Empirical Study of Translation Hypothesis Ensembling with Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Translation;Large Language Models;hypothesis ensembling;reranking;MBR decoding",
        "author": "",
        "aff": "Instituto de Telecomunica\u00e7\u00f5es; Unbabel; Instituto Superior T\u00e9cnico (Lisbon ELLIS Unit)",
        "rating": "",
        "confidence": "3;3;5",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/deep-spin/translation-hypothesis-ensembling"
    },
    {
        "id": "HIBDxkl5n4",
        "title": "Continual Event Extraction with Semantic Confusion Rectification",
        "track": "main",
        "status": "Long Main",
        "keywords": "Event extraction;Continual learning;Semantic confusion;Knowledge transfer",
        "author": "",
        "aff": "State Key Laboratory for Novel Software Technology, Nanjing University, China; State Key Laboratory for Novel Software Technology, Nanjing University, China; National Institute of Healthcare Data Science, Nanjing University, China",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "HIPPG2SH3u",
        "title": "Unified Representation for Non-compositional and Compositional Expressions",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Potentially Idiomatic Expression; Non-compositionality; Phrase Embedding; Idiomatic Expression Processing",
        "author": "",
        "aff": "Department of Electrical and Computer Engineering, University of Illinois Urbana-Champaign, Urbana, Illinois, USA",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "2;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "HJTbcidL5a",
        "title": "TokenDrop + BucketSampler: Towards Efficient Padding-free Fine-tuning of Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Efficient training of LLMs;Efficient fine-tuning of LLMs;Padding-free variable sequence length batching;Token pruning;Regularizer for LLM training;TokenDrop;BucketSampler",
        "author": "",
        "aff": "School of ECE, Purdue University",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/amrnag/TokenDrop-BucketSampler"
    },
    {
        "id": "HKMvR1UaWH",
        "title": "SYMPTOMIFY: Transforming Symptom Annotations with Language Model Knowledge Harvesting",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Symptom Recognition",
        "author": "",
        "aff": "Computer Science and Engineering, University of California, San Diego, La Jolla, CA 92093",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/bosung/SYMPTOMIFY"
    },
    {
        "id": "HMVNu8oKAK",
        "title": "Enhancing Textbooks with Visuals from the Web for Improved Learning",
        "track": "main",
        "status": "Long Main",
        "keywords": "textbooks;learning;education;images",
        "author": "",
        "aff": "School of Interactive Computing, Georgia Institute of Technology; ETH Z\u00fcrich, Department of Computer Science",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "5;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/eth-nlped/textbook-enrichment"
    },
    {
        "id": "HNfwD7QOaq",
        "title": "Large-scale similarity search with Optimal Transport",
        "track": "main",
        "status": "Short Main",
        "keywords": "Optimal transport;Wasserstein distance;Document Classification",
        "author": "",
        "aff": "Kyoto University; Okinawa Institute of Science and Technology",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "HQfzPDZJAL",
        "title": "Expository Text Generation: Imitate, Retrieve, Paraphrase",
        "track": "main",
        "status": "Long Main",
        "keywords": "Text Generation;Factuality;Style-guided Generation;Retrieval-augmented Generation",
        "author": "",
        "aff": "University of Illinois at Urbana-Champaign, USA",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "5;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/nbalepur/expository-text-generation"
    },
    {
        "id": "HR90GXVHUn",
        "title": "Once Upon a ${\\it Time}$ in ${\\it Graph}$: Relative-Time Pretraining for Complex Temporal Reasoning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Temporal Question Answering;Time-aware Pre-training",
        "author": "",
        "aff": "The Chinese University of Hong Kong; DAMO Academy, Alibaba Group",
        "rating": "",
        "confidence": "4;2;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/DAMO-NLP-SG/RemeMo"
    },
    {
        "id": "HS5BWSqK5I",
        "title": "Efficient Cross-Task Prompt Tuning for Few-Shot Conversational Emotion Recognition",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Prompt Tuning;Emotion Recognition in Conversation;Large Language Models",
        "author": "",
        "aff": "Joint NTU-UBC Research Centre of Excellence in Active Living for the Elderly, School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "HUzbEPMd6v",
        "title": "SPT: Learning to Selectively Insert Prompts for Better Prompt Tuning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Prompt tuning;neural architecture search;parameter efficient tuning",
        "author": "",
        "aff": "East China Normal University; Southern University of Science and Technology",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "HYxJoAWLgT",
        "title": "Decoding Stumpers: Large Language Models vs. Human Problem-Solvers",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Large Language Models;Problem-solving abilities;Stumpers;Cognitive abilities;Human performance;Riddles",
        "author": "",
        "aff": "The Hebrew University Business School, Jerusalem, Israel; Xoltar Inc; Faculty of Data and Decision Sciences, Technion; Department of Cognitive and Brain Sciences, Hebrew University, Jerusalem, Israel",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Alon-Go/Stumpers-LLMs"
    },
    {
        "id": "HaSS8a3Oe7",
        "title": "Can Language Models Understand Physical Concepts?",
        "track": "main",
        "status": "Long Main",
        "keywords": "large language models;embodied concept understanding",
        "author": "",
        "aff": "The University of Hong Kong; Peking University; Shanghai AI Lab",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/TobiasLee/VEC"
    },
    {
        "id": "Hbqsmv4jqY",
        "title": "Beyond Labels: Empowering Human Annotators with Natural Language Explanations through a Novel Active-Learning Architecture",
        "track": "main",
        "status": "Long Findings",
        "keywords": "active learning;low-resource learning;explanation generation;natural language explanations",
        "author": "",
        "aff": "Rensselaer Polytechnic Institute; IBM Research; Northeastern University; UNC Chapel Hill; Apple",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "HewtRLig9V",
        "title": "Cabbage Sweeter than Cake? Analysing the Potential of Large Language Models for Learning Conceptual Spaces",
        "track": "main",
        "status": "Short Main",
        "keywords": "conceptual spaces;large language models;knowledge representation",
        "author": "",
        "aff": "CardiffNLP, Cardiff University, UK",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ExperimentsLLM/EMNLP2023_PotentialOfLLM_LearningConceptualSpace"
    },
    {
        "id": "HhoG04UD3E",
        "title": "PMIndiaSum: Multilingual and Cross-lingual Headline Summarization for Languages in India",
        "track": "main",
        "status": "Long Findings",
        "keywords": "multilingual;cross-lingual;summarization;dataset;benchmark;languages in India",
        "author": "",
        "aff": "IIIT Hyderabad; University of Edinburgh",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://huggingface.co/datasets/PMIndiaData/PMIndiaSum",
        "github": ""
    },
    {
        "id": "HickNiCqk9",
        "title": "Detrimental Contexts in Open-Domain Question Answering",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Retrieval;Reasoning;Question Answering;DPR;KILT;Fusion In Decoder",
        "author": "",
        "aff": "KAIST AI",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/xfactlab/emnlp2023-damaging-retrieval"
    },
    {
        "id": "HjBDSop3ME",
        "title": "Consonant is all you need: a compact representation of English text for efficient NLP",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Text Representation;Tokenization;Language Modeling;Text Classification;POS Tagging;NER;NMT",
        "author": "",
        "aff": "ICS Department, KFUPM, Dhahran 31261, Saudi Arabia; SDAIA\u2013KFUPM Joint Research Center for AI, Dhahran 31261, Saudi Arabia",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/MagedSaeed/EnglishConsonants"
    },
    {
        "id": "HkXbOUaL4W",
        "title": "Back Transcription as a Method for Evaluating Robustness of Natural Language Understanding Models to Speech Recognition Errors",
        "track": "main",
        "status": "Long Main",
        "keywords": "ASR;NLU;Speech Recognition;TTS;Back Transcription;Evaluation;Robustness",
        "author": "",
        "aff": "Samsung Research Poland, Warsaw, Poland; Adam Mickiewicz University, Pozna\u0144, Poland",
        "rating": "",
        "confidence": "4;3;4;4",
        "correctness": "2;4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Hkj3WyR1JB",
        "title": "EconBERTa: Towards Robust Extraction of Named Entities in Economics",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Named Entity Recognition;Large Language Model;Domain Adaptation;Generalization",
        "author": "",
        "aff": "The World Bank",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "4;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "HsGirsKN5l",
        "title": "Addressing the Length Bias Challenge in Document-Level Neural Machine Translation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Document;Machine Translation;Length Bias",
        "author": "",
        "aff": "School of Future Science and Engineering, Soochow University, China; Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences (ICT/CAS) and University of Chinese Academy of Sciences, China",
        "rating": "",
        "confidence": "3;4;3;3",
        "correctness": "3;3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ictnlp/LengthBiasDNMT"
    },
    {
        "id": "HsvZUde6wT",
        "title": "Asking Clarification Questions to Handle Ambiguity in Open-Domain QA",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Clarification Question;Open-domain Question Answering",
        "author": "",
        "aff": "NA VER AI Lab, University of Richmond; NA VER AI Lab, NA VER Cloud, KAIST AI; Chung-Ang University; Dept. of ECE, Seoul National University; Samsung Electronics Mobile eXperience",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "HtNQXg979A",
        "title": "Models See Hallucinations: Evaluating the Factuality in Video Captioning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Hallucination;Factuality Evaluation;Video Captioning",
        "author": "",
        "aff": "Wangxuan Institute of Computer Technology, Peking University",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "5;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/PKULiuHui/FactVC"
    },
    {
        "id": "HtQvhCRTxo",
        "title": "CORE: A Few-Shot Company Relation Classification Dataset for Robust Domain Adaptation.",
        "track": "main",
        "status": "Long Main",
        "keywords": "Few-shot learning;Relation classification;Business application of NLP;Information extraction",
        "author": "",
        "aff": "Research Centre for Information Systems Engineering, KU Leuven, Belgium; IESEG School of Management, Univ. Lille, CNRS, UMR 9221 - LEM - Lille Economie Management, F-59000 Lille, France; Department of Computer Science, KU Leuven, Belgium",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/pnborchert/CORE"
    },
    {
        "id": "HvYxdKPqYt",
        "title": "A Frustratingly Easy Plug-and-Play Detection-and-Reasoning Module for Chinese Spelling Check",
        "track": "main",
        "status": "Long Findings",
        "keywords": "natural language processing;chinese spelling check",
        "author": "",
        "aff": "Tsinghua Shenzhen International Graduate School, Tsinghua University; OPPO Research Institute; Tsinghua Shenzhen International Graduate School, Tsinghua University, Peng Cheng Laboratory",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/THUKElab/DR-CSC"
    },
    {
        "id": "HzecOxOGAS",
        "title": "KeFVP: Knowledge-enhanced Financial Volatility Prediction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Volatility forecasting;Finance;Text mining",
        "author": "",
        "aff": "Shanghai Yuanlu Jiajia Information and Technology Co., Ltd.; Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University",
        "rating": "",
        "confidence": "4;2;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/hankniu01/KeFVP"
    },
    {
        "id": "I13VHLJjLO",
        "title": "Reward-Augmented Decoding: Efficient Controlled Text Generation With a Unidirectional Reward Model",
        "track": "main",
        "status": "Short Main",
        "keywords": "controllable text generation;reward modeling;weighted decoding",
        "author": "",
        "aff": "UNC-Chapel Hill; University of Toronto, Vector Institute",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "I4BFSevtRv",
        "title": "Domain Adaptation for Sentiment Analysis Using Robust Internal Representations",
        "track": "main",
        "status": "Long Findings",
        "keywords": "domain adaptation;sentiment analysis",
        "author": "",
        "aff": "University of Southern California",
        "rating": "",
        "confidence": "3;4;2",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "I5BnQIgQIM",
        "title": "From Parse-Execute to Parse-Execute-Refine: Improving Semantic Parser for Complex Question Answering over Knowledge Base",
        "track": "main",
        "status": "Long Main",
        "keywords": "KBQA;Logical Form;BART",
        "author": "",
        "aff": "School of Computer Science and Engineering, Sun Yat-Sen University",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "5;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "I5NWLjXbQl",
        "title": "ACQUIRED: A Dataset for Answering Counterfactual Questions In Real-Life Videos",
        "track": "main",
        "status": "Long Main",
        "keywords": "Counterfactual reasoning;Video Question Answering;Commonsense;Multimodal",
        "author": "",
        "aff": "University of California, Los Angeles; University of Maryland, College Park; Information Sciences Institute, University of Southern California",
        "rating": "",
        "confidence": "3;5;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/PlusLabNLP/acquired"
    },
    {
        "id": "I5hTganf3z",
        "title": "VECHR: A Dataset for Explainable and Robust Classification of Vulnerability Type in the European Court of Human Rights",
        "track": "main",
        "status": "Short Main",
        "keywords": "nlp for social good;in legal domain;vulnerability classification;rationale dataset;robustness",
        "author": "",
        "aff": "Technical University of Munich, Germany; LMU Munich, Germany; Graduate Institute of International and Development Studies, Switzerland; Technical University of Munich, Germany; Faculty of Law, University of Z\u00fcrich, Switzerland",
        "rating": "",
        "confidence": "4;3;3;4",
        "correctness": "4;3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/TUMLegalTech/vechr_emnlp23"
    },
    {
        "id": "I8VTNsq5eB",
        "title": "CESAR: Automatic Induction of Compositional Instructions for Multi-turn Dialogs",
        "track": "main",
        "status": "Long Main",
        "keywords": "Instruction Tuning;Open Domain Dialog;Controlled text generation;Task unification;Unified grounding;Compositional learning;Compositional instructions;CESAR",
        "author": "",
        "aff": "Amazon Alexa AI; National University of Singapore",
        "rating": "",
        "confidence": "3;3;4;2;4",
        "correctness": "3;2;2;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.2,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "I9DVeu8XKa",
        "title": "CodeFusion: A Pre-trained Diffusion Model for Code Generation",
        "track": "main",
        "status": "Short Main",
        "keywords": "Text-to-code generation;Diffusion models;Program synthesis;Language models",
        "author": "",
        "aff": "Microsoft, Redmond, US; Microsoft, Delhi, India; Microsoft Research, Cambridge, UK; Microsoft, Keerbergen, Belgium",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "IEH9YsR5Ty",
        "title": "mAggretriever: A Simple yet Effective Approach to Zero-Shot Multilingual Dense Retrieval",
        "track": "main",
        "status": "Short Main",
        "keywords": "Multilingual Dense Retrieval;Zero-Shot Language Transferability;Lexical and Semantic Matching",
        "author": "",
        "aff": "Vectara; University of Waterloo",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/castorini/dhr"
    },
    {
        "id": "IFNbElsnCi",
        "title": "Generating Summaries with Controllable Readability Levels",
        "track": "main",
        "status": "Long Main",
        "keywords": "readability;abstractive summarization;controllable text generation",
        "author": "",
        "aff": "UNC Chapel Hill; Amazon",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/amazon-science/controllable-readability-summarization"
    },
    {
        "id": "IIfdKVyeVh",
        "title": "Vicarious Offense and Noise Audit of Offensive Speech Classifiers: Unifying Human and Machine Disagreement on What is Offensive",
        "track": "main",
        "status": "Long Main",
        "keywords": "human annotation;fairness;noise audit",
        "author": "",
        "aff": "George Mason University; Rochester Institute of Technology; Aston University",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Homan-Lab/voiced1"
    },
    {
        "id": "IKz1dWj0I5",
        "title": "Physician Detection of Clinical Harm in Machine Translation: Quality Estimation Aids in Reliance and Backtranslation Identifies Critical Errors",
        "track": "main",
        "status": "Long Main",
        "keywords": "medical machine translation;clinical harm;human-centered NLP",
        "author": "",
        "aff": "University of California, Berkeley; University of California, San Francisco; University of Maryland",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "ILQnct9H4H",
        "title": "TRIGO: Benchmarking Formal Mathematical Proof Reduction for Generative Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Trigonometric Expression Reduction;Automated Theorem Proving;Formal Mathematical Proof Reduction;Complex Number Combination Reasoning;Generative Language Models",
        "author": "",
        "aff": "Sun Yat-Sen University; Huawei Noah\u2019s Ark Lab; Peking University; City University of Hong Kong; Shenzhen Campus of Sun Yat-Sen University; The Chinese University of Hong Kong",
        "rating": "",
        "confidence": "4;2;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "ILxXKWHkIB",
        "title": "BioFEG: Generate Latent Features for Biomedical Entity Linking",
        "track": "main",
        "status": "Long Main",
        "keywords": "Biomedical entity linking;Unseen entities",
        "author": "",
        "aff": "Institute of Automation, Chinese Academy of Sciences, China; College of Computer Science, VCIP, TMCC, TBI Center, Nankai University, China",
        "rating": "",
        "confidence": "5;3;3",
        "correctness": "5;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.666666666666667,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "IPPURnxK2S",
        "title": "Improving generalization in large langue model by learning prefix subspaces",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Deep learning;parameter efficient fine-tuning;prefix-tuning;subspace learning;natural language processing",
        "author": "",
        "aff": "Sorbonne Universit\u00e9, CNRS, ISIR, 75005 Paris, France; AgroParisTech, UMR MIA-PS, 91120 Palaiseau, France",
        "rating": "",
        "confidence": "1;4;3",
        "correctness": "3;5;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Liloulou/prefix_subspace"
    },
    {
        "id": "IRUGqnZQwt",
        "title": "Diversifying language models for lesser-studied languages and language-usage contexts: A case of second language Korean",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multilinguality;DEI;NLP applications;L2 Korean;Morpheme parsing/tagging",
        "author": "",
        "aff": "Department of Linguistics, University of Oregon; Department of Linguistics, University of Illinois at Chicago",
        "rating": "",
        "confidence": "2;4;4",
        "correctness": "4;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "IT2bT8UigY",
        "title": "Enhancing Accessible Communication: from European Portuguese to Portuguese Sign Language",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Portuguese Sign Language;Machine Translation;Computational Linguistics;Natural Language Processing;Deep Learning",
        "author": "",
        "aff": "INESC-ID, Lisbon, Portugal; Instituto Superior T\u00e9cnico, University of Lisbon, Portugal; Universidade Cat\u00f3lica Portuguesa, Portugal",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/lcoheur/EP2LGP5.0"
    },
    {
        "id": "IUKw6SyCxv",
        "title": "DiffS2UT: A Semantic Preserving Diffusion Model for Textless Direct Speech-to-Speech Translation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Speech to Speech Translation;Diffusion Models",
        "author": "",
        "aff": "iFlytek Research; School of Computer Science and Technology, University of Science and Technology of China; School of Data Science, University of Science and Technology of China",
        "rating": "",
        "confidence": "3;4;2;4",
        "correctness": "4;2;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "IXuCeFnnxU",
        "title": "Noisy Pair Corrector for Dense Retrieval",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Dense Retrieval;Noisy Pair",
        "author": "",
        "aff": "; College of Computer Science, Sichuan University; Engineering Research Center of Machine Learning and Industry Intelligence; The University of Hong Kong; Sun Yat-sen University; IDEA Research, China",
        "rating": "",
        "confidence": "5;4;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "IZjyMygbw4",
        "title": "Eyes Show the Way: Modelling Gaze Behaviour for Hallucination Detection",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Cognition;Hallucination;NLG;Gaze;Human Attention",
        "author": "",
        "aff": "University of Texas at Austin, Texas, United States; Indian Institute of Technology Bombay, Mumbai, India",
        "rating": "",
        "confidence": "3;3;2",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 1.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "IZzZnp7IUs",
        "title": "Crystal: Introspective Reasoners Reinforced with Self-Feedback",
        "track": "main",
        "status": "Long Main",
        "keywords": "introspective reasoning;commonsense reasoning;question answering;reinforcement learning",
        "author": "",
        "aff": "Paul G. Allen School of Computer Science & Engineering, University of Washington; FAIR, Meta; Allen Institute for Artificial Intelligence",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/liujch1998/crystal"
    },
    {
        "id": "IaBBd8Fod8",
        "title": "Breaking through Deterministic Barriers: Randomized Pruning Mask Generation and Selection",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Pruning;Random;Language Models",
        "author": "",
        "aff": "North Carolina State University; New York University",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "IadylMsom5",
        "title": "Beyond Detection: A Defend-and-Summarize Strategy for Robust and Interpretable Rumor Analysis on Social Media",
        "track": "main",
        "status": "Long Main",
        "keywords": "rumor detection;social network analysis;adversarial attack;interpretability;summarization;unsupervised learning;self-supervised learning",
        "author": "",
        "aff": "National Yang Ming Chiao Tung University, Taiwan",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/joshchang0111/EMNLP2023-RumorDAS"
    },
    {
        "id": "IdSrFSqhHl",
        "title": "Self-Polish: Enhance Reasoning in Large Language Models via Problem Refinement",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Reasoning;Large Language Models;Mathematical Problems",
        "author": "",
        "aff": "Institute of Modern Languages and Linguistics, Fudan University, Shanghai, China; School of Computer Science, Fudan University, Shanghai, China",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/WooooDyy/Self-Polish"
    },
    {
        "id": "IdXpzsTWRs",
        "title": "StoryAnalogy: Deriving Story-level Analogies from Large Language Models to Unlock Analogical Understanding",
        "track": "main",
        "status": "Long Main",
        "keywords": "Analogy;Semantic similarity",
        "author": "",
        "aff": "Westlake University; The Hong Kong University of Science and Technology; Amazon AWS AI",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "4;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/loginaway/StoryAnalogy"
    },
    {
        "id": "Ie040B4nFm",
        "title": "Integrating Language Models into Direct Speech Translation: An Inference-Time Solution to Control Gender Inflection",
        "track": "main",
        "status": "Short Main",
        "keywords": "Speech translation;Gender Bias;Language Model",
        "author": "",
        "aff": "Fondazione Bruno Kessler; University of Trento",
        "rating": "",
        "confidence": "4;2;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/hlt-mt/FBK-fairseq"
    },
    {
        "id": "IgPf3oLp6B",
        "title": "Query2Triple: Unified Query Encoding for Answering Diverse Complex Queries over Knowledge Graphs",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Knowledge Graph;Complex Query Answering;CQA",
        "author": "",
        "aff": "Meituan, Beijing, China; The Laboratory of Cognition and Decision Intelligence for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; The Laboratory of Cognition and Decision Intelligence for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; Shanghai Artificial Intelligence Laboratory, Shanghai, China",
        "rating": "",
        "confidence": "5;5;5",
        "correctness": "4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 5.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "IhHB1l1mwp",
        "title": "Seq2seq is All You Need for Coreference Resolution",
        "track": "main",
        "status": "Long Main",
        "keywords": "coreference resolution; sequence-to-sequence models;",
        "author": "",
        "aff": "Duke University; Rutgers University",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Ihgea6IIWo",
        "title": "Countering Misinformation via Emotional Response Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Misinformation Countering;Automated Fact-Checking;Knowledge-Driven NLG;Automatic Text Summarization;Human-Machine Collaboration;Data Collection",
        "author": "",
        "aff": "Fondazione Bruno Kessler; University of Trento; Fondazione Bruno Kessler, University of Trento",
        "rating": "",
        "confidence": "4;4;4;4;3",
        "correctness": "4;3;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.8,
        "correctness_avg": 3.4,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "IksoHnq4rC",
        "title": "End-to-end Adversarial Sample Generation for Data Augmentation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "adversarial sample;data augmentation",
        "author": "",
        "aff": "Shandong University",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "IlgpELdUeK",
        "title": "Axiomatic Preference Modeling for Longform Question Answering",
        "track": "main",
        "status": "Long Main",
        "keywords": "reward modeling;preference modeling;RLHF;Large Language Models;long form question answering",
        "author": "",
        "aff": "Microsoft Research",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "In4L79U5n7",
        "title": "$\\textit{``Don't Take This Out of Context!''}$ On the Need for Contextual Models and Evaluations for Stylistic Rewriting",
        "track": "main",
        "status": "Long Main",
        "keywords": "stylistic rewriting;contextual evaluation;contextual generation",
        "author": "",
        "aff": "Allen Institute for AI; Google DeepMind; Language Technologies Institute, Carnegie Mellon University",
        "rating": "",
        "confidence": "3;3;2;4",
        "correctness": "4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "InhYJzIuBi",
        "title": "Aspect-Category Enhanced Learning with a Neural Coherence Model for Implicit Sentiment Analysis",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Aspect-Based Sentiment Analysis;Implicit Sentiment;Coherence",
        "author": "",
        "aff": "University of Yamanashi, Kofu, Japan; Hangzhou Dianzi University, Hangzhou, China",
        "rating": "",
        "confidence": "5;5;3",
        "correctness": "4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/cuijin-23/ELCoM"
    },
    {
        "id": "IpJ5rAFLv7",
        "title": "Scaling Vision-Language Models with Sparse Mixture of Experts",
        "track": "main",
        "status": "Long Findings",
        "keywords": "vision language;scaling",
        "author": "",
        "aff": "\u2020UC Berkeley; \u2021Microsoft",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://vlmoe.github.io"
    },
    {
        "id": "Ipo264MKyt",
        "title": "PersonaLM: Language Model Personalization via Domain-distributed Span Aggregated K-Nearest N-gram Retrieval Augmentation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "speech recognition;language modeling;personalization;domain adaptation;retrieval augmentation",
        "author": "",
        "aff": "University of Maryland, College Park; Meta",
        "rating": "",
        "confidence": "3;3;1",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "IpzCUvade7",
        "title": "Interventional Rationalization",
        "track": "main",
        "status": "Long Main",
        "keywords": "Rationalization;Causal intervention",
        "author": "",
        "aff": "Anhui Province Key Laboratory of Big Data Analysis and Application, University of Science and Technology of China; Anhui Province Key Laboratory of Big Data Analysis and Application, University of Science and Technology of China; State Key Laboratory of Cognitive Intelligence; ByteDance",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "3;3;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/yuelinan/Codes-of-Inter-RAT"
    },
    {
        "id": "IqEy2fbpt5",
        "title": "Do LLMs Understand Social Knowledge? Evaluating the Sociability of Large Language Models with SocKET Benchmark",
        "track": "main",
        "status": "Long Main",
        "keywords": "large language models;social information;benchmark",
        "author": "",
        "aff": "University of Cambridge, Cambridge, UK; University of Michigan, Ann Arbor, MI, USA; Northeastern University, Boston, MA, USA",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/minjechoi/SOCKET"
    },
    {
        "id": "IsDxBXUEd8",
        "title": "GRI: Graph-based Relative Isomorphism of Word Embedding Spaces",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Attentive graph Convolutions;Isomorphim;Bi-lingual Induction",
        "author": "",
        "aff": "King Abdullah University of Science and Technology, KSA; Shenzhen University, China",
        "rating": "",
        "confidence": "1;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/asif6827/GRI"
    },
    {
        "id": "Itnbse9MMW",
        "title": "An Integrative Survey on Mental Health Conversational Agents to Bridge Computer Science and Medical Perspectives",
        "track": "main",
        "status": "Long Main",
        "keywords": "Conversational Agent;Chatbot;Mental health",
        "author": "",
        "aff": "New York University; University of Pennsylvania",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "5;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/JeffreyCh0/mental_chatbot_survey"
    },
    {
        "id": "IvwcvJHLpc",
        "title": "IdealGPT: Iteratively Decomposing Vision and Language Reasoning via Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Vision-Language Learning;Vision-Language Model;Large Language Model;Zero-Shot Evaluation",
        "author": "",
        "aff": "University of California, Los Angeles; HKUST; Columbia University",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Hxyou/IdealGPT"
    },
    {
        "id": "IwI7Wpkzm7",
        "title": "Deciphering Stereotypes in Pre-Trained Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Stereotype Examination;Stereotype Dataset Construction;Probing and Other Interpretations",
        "author": "",
        "aff": "Computer Science Department, Stanford University; Department of Computer Science, Dartmouth College",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "J2l0R8N3ks",
        "title": "Zero-shot Sharpness-Aware Quantization for Pre-trained Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "zero-shot quantization;minimax optimization;pre-trained language model",
        "author": "",
        "aff": "JD Explore Academy, China; The University of Sydney, Australia; School of Computer Science, National Engineering Research Center for Multimedia Software, Institute of Artificial Intelligence and Hubei Key Laboratory of Multimedia and Network Communication Engineering, Wuhan University, China",
        "rating": "",
        "confidence": "4;3;4;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "J5FFUHZjNx",
        "title": "SteerLM: Attribute Conditioned SFT as an (User-Steerable) Alternative to RLHF",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Steerable AI;Large Language Model;Alignment;Supervised Fine-tuning",
        "author": "",
        "aff": "NVIDIA",
        "rating": "",
        "confidence": "5;4;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://huggingface.co/nvidia/SteerLM-llama2-13B",
        "github": ""
    },
    {
        "id": "J6pq6AcmbE",
        "title": "A Zero-Shot Language Agent for Computer Control with Structured Reflection",
        "track": "main",
        "status": "Long Findings",
        "keywords": "planning;reflection;action;grounding",
        "author": "",
        "aff": "Google Research, Mountain View, U.S.A.; University of Toronto, Ontario, Canada",
        "rating": "",
        "confidence": "3;3;4;2",
        "correctness": "3;4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "J6uWPjukdR",
        "title": "Data Similarity is Not Enough to Explain Language Model Performance",
        "track": "main",
        "status": "Short Main",
        "keywords": "similarity;dataset difficulty;pretraining data analysis",
        "author": "",
        "aff": "Cornell University; Google Research",
        "rating": "",
        "confidence": "5;5;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "J8iaZda5aG",
        "title": "Words, Subwords, and Morphemes: What Really Matters in the Surprisal-Reading Time Relationship?",
        "track": "main",
        "status": "Short Findings",
        "keywords": "psycholinguistics;sentence processing;tokenization",
        "author": "",
        "aff": "Linguistics & Institute for Advanced Computer Studies, University of Maryland",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "J9Vx7eTuWb",
        "title": "TATA: Stance Detection via Topic-Agnostic and Topic-Aware Embeddings",
        "track": "main",
        "status": "Long Main",
        "keywords": "Zero-shot;Few-shot;Stance Detection;Topic-Agnostic;Topic-Aware",
        "author": "",
        "aff": "Stanford University",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/hanshanley/tata"
    },
    {
        "id": "J9vgDEDjAw",
        "title": "UDAPDR: Unsupervised Domain Adaptation via LLM Prompting and Distillation of Rerankers",
        "track": "main",
        "status": "Long Main",
        "keywords": "Natural Language Processing;Information Retrieval;Domain Adaptation",
        "author": "",
        "aff": "Stanford University; IBM Research AI",
        "rating": "",
        "confidence": "4;4;3;4",
        "correctness": "4;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "JC7uPaMwpW",
        "title": "KBioXLM: A Knowledge-anchored Biomedical Multilingual Pretrained Language Model",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Biomedical;Cross-lingual;Multi-lingual;Pretrained Language Model",
        "author": "",
        "aff": "Pharmcube; Peking University; Institute of Artificial Intelligence, Soochow University; The Hong Kong Polytechnic University; Changping Laboratory",
        "rating": "",
        "confidence": "2;4;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ngwlh-gl/KBioXLM"
    },
    {
        "id": "JHd4FSJSC5",
        "title": "Anchoring Fine-tuning of Sentence Transformer with Semantic Label Information for Efficient Truly Few-shot Classification",
        "track": "main",
        "status": "Short Main",
        "keywords": "few-shot;sentence transformer;classification;efficiency",
        "author": "",
        "aff": "IT University of Copenhagen, Denmark; Department of Computer Science, Aarhus University, Denmark",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/AmaliePauli/AncSetfit"
    },
    {
        "id": "JI5lhPHVbK",
        "title": "Battle of the Large Language Models: Dolly vs LLaMA vs Vicuna vs Guanaco vs Bard vs ChatGPT - A Text-to-SQL Parsing Comparison",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Text-to-SQL;large language model",
        "author": "",
        "aff": "National University of Singapore; Nanyang Technology University; Institute for Infocomm Research (I2R), A*STAR, Singapore",
        "rating": "",
        "confidence": "4;4;4;5",
        "correctness": "2;4;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "JIrP8CIvx6",
        "title": "Improving Sequential Model Editing with Fact Retrieval",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Model Editing; Sequential Model Editing; Pre-trained Language model",
        "author": "",
        "aff": "ILCC, School of Informatics, University of Edinburgh, UK; School of Computer and Information Technology, Shanxi University, China",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/sev777/RASE"
    },
    {
        "id": "JKmsjKJ0Q8",
        "title": "Long-Horizon Dialogue Understanding for Role Identification in the Game of Avalon with Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Dialogue Understanding;Multimodal Reasoning;Long-Horizon Games",
        "author": "",
        "aff": "Carnegie Mellon University; University of Pittsburgh",
        "rating": "",
        "confidence": "4;5;5",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://sstepput.github.io/Avalon-NLU/",
        "github": "https://github.com/sstepput/Avalon-NLU"
    },
    {
        "id": "JMSkoIYFSn",
        "title": "Improving Span Representation by Efficient Span-Level Attention",
        "track": "main",
        "status": "Short Findings",
        "keywords": "representation learning;efficient methods",
        "author": "",
        "aff": "School of Information Science and Technology, ShanghaiTech University, Shanghai Engineering Research Center of Intelligent Vision and Imaging; School of Information Science and Technology, ShanghaiTech University",
        "rating": "",
        "confidence": "3;5;5",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/jipy0222/Span-Level-Attention"
    },
    {
        "id": "JMbJeMTFos",
        "title": "Improving word mover's distance by leveraging self-attention matrix",
        "track": "main",
        "status": "Long Findings",
        "keywords": "word embeddings;word mover's distance;optimal transport;Gromov-Wasserstein distance;Fused Gromov-Wasserstein distance;Self-Attention;paraphrase identification;semantic textual similarity",
        "author": "",
        "aff": "Tohoku University; RIKEN AIP; Kyoto University",
        "rating": "",
        "confidence": "2;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ymgw55/WSMD"
    },
    {
        "id": "JNd6XPdaXj",
        "title": "Polyglot or Not? Measuring Multilingual Encyclopedic Knowledge in Foundation Models",
        "track": "main",
        "status": "Short Main",
        "keywords": "NLP;machine learning;LLMs;language modeling;multilingual;datasets;benchmarks",
        "author": "",
        "aff": "School of Information, University of California, Berkeley",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "JPUx2nVgWa",
        "title": "How Many Demonstrations Do You Need for In-context Learning?",
        "track": "main",
        "status": "Long Findings",
        "keywords": "In-context learning: Large language model",
        "author": "",
        "aff": "University of Maryland",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "JRHhpw77q3",
        "title": "Steering Large Language Models for Machine Translation with Finetuning and In-Context Learning",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Machine Translation; In-Context Learning; Efficient Finetuning",
        "author": "",
        "aff": "Instituto de Telecomunica\u00e7\u00f5es, Lisbon, Portugal; MICS, CentraleSup\u00e9lec, Universit\u00e9 Paris-Saclay, France; Unbabel, Lisbon, Portugal; INESC-ID, Lisbon, Portugal",
        "rating": "",
        "confidence": "4;5;3;3;3",
        "correctness": "4;3;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6,
        "correctness_avg": 3.4,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/deep-spin/translation_llm"
    },
    {
        "id": "JW3UKn4bmG",
        "title": "Is ChatGPT a Good Causal Reasoner? A Comprehensive Evaluation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Causal Reasoning;Large Language Models;Performance Evaluation",
        "author": "",
        "aff": "Research Center for Social Computing and Information Retrieval, Harbin Institute of Technology, China",
        "rating": "",
        "confidence": "3;3;5",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ArrogantL/ChatGPT4CausalReasoning"
    },
    {
        "id": "JWMIm1EyaE",
        "title": "Explaining with Contrastive Phrasal Highlighting: A Case Study in Assisting Humans to Detect Translation Differences",
        "track": "main",
        "status": "Long Main",
        "keywords": "explainability;human-centered evaluation;machine translation evaluation;cross-lingual semantics;contrastive highlights",
        "author": "",
        "aff": "Google; University of Maryland",
        "rating": "",
        "confidence": "4;4;2",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "JaP8ZnOxmi",
        "title": "Mitigating Framing Bias with Polarity Minimization Loss",
        "track": "main",
        "status": "Short Findings",
        "keywords": "framing bias",
        "author": "",
        "aff": "Centre for Artificial Intelligence Research (CAiRE), The Hong Kong University of Science and Technology",
        "rating": "",
        "confidence": "2;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Jc0sVyM0JP",
        "title": "Semantic Parsing by Large Language Models for Intricate Updating Strategies of Zero-Shot Dialogue State Tracking",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Dialogue State Tracking;Zero-Shot;Large Language Models;In-Context Learning;Semantic Parsing",
        "author": "",
        "aff": "Beijing University of Posts and Telecommunications, Beijing, China",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "JhC3lwWDhZ",
        "title": "Treepiece: Faster Semantic Parsing via Tree Tokenization",
        "track": "main",
        "status": "Short Findings",
        "keywords": "semantic parsing;decoding;tokenization algorithm;parse tree",
        "author": "",
        "aff": "Meta Inc. USA",
        "rating": "",
        "confidence": "3;4;2",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "JhzzvJnL9t",
        "title": "Out-of-Domain Intent Detection Considering Multi-turn Dialogue Contexts",
        "track": "main",
        "status": "Reject",
        "keywords": "OOD Detection;Multi-turn Dialogue Contexts",
        "author": "",
        "aff": "EMNLP submission",
        "rating": "",
        "confidence": "3;3;2",
        "correctness": "2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "JiUTJJrkL4",
        "title": "clembench: Using Game Play to Evaluate Chat-Optimized Language Models as Conversational Agents",
        "track": "main",
        "status": "Long Main",
        "keywords": "large language models; evaluation; dialogue; dialogue games; interaction",
        "author": "",
        "aff": "Computational Linguistics, Department of Linguistics, University of Potsdam, Germany; German Research Center for Artificial Intelligence (DFKI), Berlin, Germany",
        "rating": "",
        "confidence": "4;2;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/clembench"
    },
    {
        "id": "Jk6LA0NGOU",
        "title": "Explicit Planning Helps Language Models in Logical Reasoning",
        "track": "main",
        "status": "Long Main",
        "keywords": "logical reasoning;large language model;planning",
        "author": "",
        "aff": "University of Chicago; Toyota Technological Institute at Chicago; WeChat AI",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "JnJsaXfVte",
        "title": "Architectural Sweet Spots for Modeling Human Label Variation by the Example of Argument Quality: It\u2019s Best to Relate Perspectives!",
        "track": "main",
        "status": "Long Main",
        "keywords": "argument quality;perspectivism;inter-annotator-disagreement;LLM;recommender;argument mining",
        "author": "",
        "aff": "Department of Social Sciences, Heinrich Heine University D\u00fcsseldorf, Germany; Center for Cognitive Interaction Technology (CITEC), Bielefeld University, Germany",
        "rating": "",
        "confidence": "5;5;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Jo9P7hrDdy",
        "title": "SpEL: Structured Prediction for Entity Linking",
        "track": "main",
        "status": "Long Main",
        "keywords": "Structured Prediction;Entity Linking;AIDA dataset;AIDA/testc;SpEL",
        "author": "",
        "aff": "School of Computing Science, Simon Fraser University, BC, Canada",
        "rating": "",
        "confidence": "2;5;3",
        "correctness": "4;5;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/shavarani/SpEL"
    },
    {
        "id": "JotVdrvFtJ",
        "title": "Collaborative Generative AI: Integrating GPT-k for Efficient Editing in Text-to-Image Generation",
        "track": "main",
        "status": "Short Main",
        "keywords": "Text-to-image;LLM;Efficiency",
        "author": "",
        "aff": "UC Santa Cruz; UC Santa Barbara",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "JrlSX4nHTv",
        "title": "Natural Response Generation for Chinese Reading Comprehension",
        "track": "main",
        "status": "Long Findings",
        "keywords": "machine reading comprehension;dataset",
        "author": "",
        "aff": "Hong Kong University of Science and Technology (Guangzhou); Hong Kong University of Science and Technology; Xiaobing.AI",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "2;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/nuochenpku/Penguin"
    },
    {
        "id": "Js80TDwMfY",
        "title": "Argument-based Detection and Classification of Fallacies in Political Debates",
        "track": "main",
        "status": "Long Main",
        "keywords": "Fallacy Detection;NLP;Token Classification;Political Debates;Machine Learning;Transformers;Argumantation",
        "author": "",
        "aff": "Universit\u00e9 C\u00f4te d\u2019Azur, CNRS, Inria, I3S, France",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "JwbEwhL3VP",
        "title": "Boosting Inference Efficiency: Unleashing the Power of Parameter-Shared Pre-trained Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "pre-trained language model;parameter sharing;inference acceleration",
        "author": "",
        "aff": "Gaoling School of Artificial Intelligence, Renmin University of China, Beijing; NLP Group, DCST, IAI, BNRIST, Tsinghua University, Beijing; Pattern Recognition Center, WeChat AI, Tencent Inc.",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "JyvycLG00G",
        "title": "EMO-KNOW: A Large Scale Dataset on Emotion-Cause",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Dataset;Emotion Analysis;Emotion-Cause;Large-scale",
        "author": "",
        "aff": "School of Computing, National University of Singapore; School of Computing, University of Colombo",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;2;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "K1ih2El1IO",
        "title": "A Predictive Factor Analysis of Social Biases and Task-Performance in Pretrained Masked Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "mask language models;social bias;task performance;model size;model type;training corpora;tokenisation;language",
        "author": "",
        "aff": "Cardiff University; University of Liverpool, Amazon",
        "rating": "",
        "confidence": "5;3;2",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "K2CrJIcFqg",
        "title": "Grounded and well-rounded: a methodological approach to the study of cross-modal and cross-lingual grounding",
        "track": "main",
        "status": "Long Findings",
        "keywords": "grounding;crosslingual grounding;multimodality",
        "author": "",
        "aff": "Silo AI; University of Helsinki; Utrecht University",
        "rating": "",
        "confidence": "2;2;1",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 1.6666666666666667,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "K35sqjeg5J",
        "title": "Semi-supervised multimodal coreference resolution in image narrations",
        "track": "main",
        "status": "Long Main",
        "keywords": "Coreference Resolution;Vision Language Understanding;Narrative Grounding;Semi-Supervised Learning",
        "author": "",
        "aff": "CFAR, IHPC, A*STAR, Singapore; School of Informatics, University of Edinburgh, UK",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "K5DBkivtyO",
        "title": "Diffusion Language Model with Query-Document Relevance for Query-Focused Summarization",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Query-Focused Summarization;Diffusion Language Model;Query-Document Relevance",
        "author": "",
        "aff": "Institute of Artificial Intelligence, Soochow University",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "K5o8oDa0Z0",
        "title": "Chain-of-Thought Reasoning in Tabular Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Tabular mathematical reasoning;Chain-of-thought reasoning;Tabular language models",
        "author": "",
        "aff": "Baidu Inc; Institute of Information Engineering, Chinese Academy of Sciences; Institute of Information Engineering, Chinese Academy of Sciences; School of Cyber Security, University of Chinese Academy of Sciences",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/SpursGoZmy/TaCo"
    },
    {
        "id": "K6KcA4ODql",
        "title": "Improving Bias Mitigation through Bias Experts in Natural Language Understanding",
        "track": "main",
        "status": "Long Main",
        "keywords": "Debiasing;natural language understanding;spurious correlation",
        "author": "",
        "aff": "Department of Artificial Intelligence, Korea University, Seoul, Republic of Korea; Department of Computer Science and Engineering, Korea University, Seoul, Republic of Korea",
        "rating": "",
        "confidence": "4;4;2",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/jej127/Bias-Experts"
    },
    {
        "id": "K7p2SnqFoN",
        "title": "Toward Human Readable Prompt Tuning: Kubrick\u2019s The Shining is a good movie, and a good prompt too?",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Prompt tuning;Analysis;Interpretability",
        "author": "",
        "aff": "Paul G. Allen School of Computer Science & Engineering, University of Washington, Seattle, WA",
        "rating": "",
        "confidence": "3;3;3;2;3;2;3",
        "correctness": "4;3;4;5;3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.7142857142857144,
        "correctness_avg": 3.4285714285714284,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "github.com/swj0419/FluentPrompt"
    },
    {
        "id": "K8ixbJPkMQ",
        "title": "TaskWeb: Selecting Better Source Tasks for Multi-task NLP",
        "track": "main",
        "status": "Long Main",
        "keywords": "NLP;machine learning;task transfer;task selection;multi-task training",
        "author": "",
        "aff": "University of Washington; Allen Institute for AI",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/danieljkim0118/TaskWeb"
    },
    {
        "id": "KCe98ynJl3",
        "title": "Zero-shot Faithfulness Evaluation for Text Summarization with Foundation Language Model",
        "track": "main",
        "status": "Long Main",
        "keywords": "Faithfulness Evaluation;Summarization Evaluation;Hallucination Detection",
        "author": "",
        "aff": "Shanghai Jiao Tong University, China; Meituan, China; University of Texas at Arlington, USA",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "KE5QunlXcr",
        "title": "Incorporating Syntactic Knowledge into Pre-trained Language Model using Optimization for Overcoming Catastrophic Forgetting",
        "track": "main",
        "status": "Long Findings",
        "keywords": "syntax;BERT;language model;optimization;catastrophic forgetting",
        "author": "",
        "aff": "IBM Research - Tokyo, Keio University; IBM Research - Tokyo",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "KE9MKZOOca",
        "title": "ConPrompt: Pre-training a Language Model with Machine-Generated Data for Implicit Hate Speech Detection",
        "track": "main",
        "status": "Long Findings",
        "keywords": "implicit hate speech detection;pre-training;pre-trained language model;machine-generated data;contrastive learning;prompt",
        "author": "",
        "aff": "KT, Seoul, Republic of Korea; Yonsei University, Seoul, Republic of Korea",
        "rating": "",
        "confidence": "5;2;3;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/youngwook06/ConPrompt"
    },
    {
        "id": "KEH6Cqjdw2",
        "title": "Legally Enforceable Hate Speech Detection for Public Forums",
        "track": "main",
        "status": "Long Findings",
        "keywords": "hate speech;legal AI;human in the loop;large language models;prompt tuning",
        "author": "",
        "aff": "Department of Electrical and Computer Engineering & Ingenuity Labs Research Institute, Queen\u2019s University; Conflict Analytics Lab, Queen\u2019s University, Cornell Law School",
        "rating": "",
        "confidence": "3;3;5",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/chufeiluo/legalhatespeech"
    },
    {
        "id": "KFieG8rclT",
        "title": "Contrastive Learning-based Sentence Encoders Implicitly Weight Informative Words",
        "track": "main",
        "status": "Short Findings",
        "keywords": "sentence embedding;contrastive learning;information gain;integrated gradients",
        "author": "",
        "aff": "MBZUAI, Tohoku University, RIKEN; Tohoku University, RIKEN",
        "rating": "",
        "confidence": "3;4;2;2",
        "correctness": "4;2;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/kuriyan1204/sentence-encoder-word-weighting"
    },
    {
        "id": "KHfQKygNSc",
        "title": "Robustness of Named-Entity Replacements for In-Context Learning",
        "track": "main",
        "status": "Short Findings",
        "keywords": "large language models;in-context learning;named entities;robustness;natural language understanding",
        "author": "",
        "aff": "University of Massachusetts Amherst; FAIR, Meta; NVIDIA; Universitat Pompeu Fabra",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/DennisMinn/entities-in-context"
    },
    {
        "id": "KIysY1fMCJ",
        "title": "Aspect-to-Scope Oriented Multi-view Contrastive Learning for Aspect-based Sentiment Analysis",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Graph contrastive learning;aspect-based sentiment analysis",
        "author": "",
        "aff": "National University of Defense Technology, China; Harbin Institute of Technology, Shenzhen, China; Peng Cheng Laboratory, Shenzhen, China; Harbin Institute of Technology, Shenzhen, China",
        "rating": "",
        "confidence": "4;3;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "KNFG5KLXD3",
        "title": "We Are What We Repeatedly Do: Inducing and Deploying Habitual Schemas in Persona-Based Responses",
        "track": "main",
        "status": "Long Main",
        "keywords": "Dialogue;Response;Generation;Persona;Schema;LLM",
        "author": "",
        "aff": "University of Rochester",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "KOxEqQzvOZ",
        "title": "Debias NLU Datasets via Training-free Perturbations",
        "track": "main",
        "status": "Long Findings",
        "keywords": "natural language understanding; out-of-distribution generalization; data-centric debiasing;",
        "author": "",
        "aff": "Institute for AI Industry Research (AIR), Tsinghua University; National Key Laboratory for Novel Software Technology, Nanjing University",
        "rating": "",
        "confidence": "5;4;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "KRQADH68fG",
        "title": "HuatuoGPT, Towards Taming Language Model to Be a Doctor",
        "track": "main",
        "status": "Long Findings",
        "keywords": "large language models;medical application;ChatGPT",
        "author": "",
        "aff": "Shenzhen Research Institue of Big Data, The Chinese University of Hong Kong, Shenzhen, University of Science and Technology of China; The Chinese University of Hong Kong, Shenzhen; Shenzhen Research Institue of Big Data, The Chinese University of Hong Kong, Shenzhen",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "KSjnVt9awC",
        "title": "Revisiting the Knowledge Injection Frameworks",
        "track": "main",
        "status": "Long Main",
        "keywords": "language models;knowledge pruning;large language models for downstream task",
        "author": "",
        "aff": "Yale University, New Haven, America; Zhejiang University, Hangzhou, China",
        "rating": "",
        "confidence": "3;3;3;4",
        "correctness": "4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "KTFxOnrbvu",
        "title": "Argument mining as a multi-hop generative machine reading comprehension task",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Argument mining; Machine reading comprehension; Generative model; Chain of thought",
        "author": "",
        "aff": "Department of Computer Science, The University of Manchester, UK; Artificial Intelligence Research Center, AIST; Department of Computer Science, The University of Manchester, UK; ASUS Intelligent Cloud Services (AICS), Singapore; Department of Computer Science, The University of Manchester, UK",
        "rating": "",
        "confidence": "3;2;2",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Boyang-L/MRC-GEN4AM"
    },
    {
        "id": "KUSzNKRI2g",
        "title": "Improving Pacing in Long-Form Story Planning",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Story Generation;Pacing;Hierarchical Planning",
        "author": "",
        "aff": "University of California, Berkeley; Xi\u2019an Jiaotong University; University of California, Berkeley and Xi\u2019an Jiaotong University",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/YichenZW/Pacing"
    },
    {
        "id": "KfJffhdWO1",
        "title": "Evaluating Evaluation Metrics: A Framework for Analyzing NLG Evaluation Metrics using Measurement Theory",
        "track": "main",
        "status": "Long Main",
        "keywords": "Evaluation;Evaluation Metrics;Measurement Theory;NLG;Large Language Model",
        "author": "",
        "aff": "University of Illinois Urbana-Champaign; Microsoft Research Montr\u00e9al; Johns Hopkins University; Visa Research",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/isle-dev/MetricEval"
    },
    {
        "id": "KgcuY2KIkf",
        "title": "Systematic word meta-sense extension",
        "track": "main",
        "status": "Long Main",
        "keywords": "lexical creativity;regular polysemy;systematicity;contextualized language model;analogical inference;figurative language processing",
        "author": "",
        "aff": "Department of Computer Science, University of Toronto",
        "rating": "",
        "confidence": "4;5;5",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/jadeleiyu/sworme"
    },
    {
        "id": "KivNpBsfAS",
        "title": "NLP Evaluation in trouble: On the Need to Measure LLM Data Contamination for each Benchmark",
        "track": "main",
        "status": "Short Findings",
        "keywords": "evaluation;data contamination;large language models;benchmark",
        "author": "",
        "aff": "HiTZ Center - Ixa, University of the Basque Country UPV/EHU; Cohere",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://hitz-zentroa.github.io/lm-contamination/",
        "github": ""
    },
    {
        "id": "Kjs0mpGJwb",
        "title": "A Structure-Aware Generative Adversarial Network for Bilingual Lexicon Induction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Cross-lingual word embedding;unsupervised;low isomorphic;bilingual lexicon induction",
        "author": "",
        "aff": "Baidu Inc., Beijing, China; South China University of Technology, Guangzhou, China; Old Dominion University, Norfolk, USA",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/scutBCH/SAGAN"
    },
    {
        "id": "KkHY1WGDII",
        "title": "Grammar-Constrained Decoding for Structured NLP Tasks without Finetuning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Grammar-Constrained Decoding;Large Language Model;LLM;Structured NLP;Information Extraction;Entity Disambiguation",
        "author": "",
        "aff": "EPFL; Universit\u00e9 Grenoble Alpes, CNRS, Grenoble INP, LIG",
        "rating": "",
        "confidence": "2;4;3;4",
        "correctness": "4;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/epfl-dlab/GCD"
    },
    {
        "id": "KkR8wahYQN",
        "title": "FaMeSumm: Investigating and Improving Faithfulness of Medical Summarization",
        "track": "main",
        "status": "Long Main",
        "keywords": "Medical Summarization;Factuality;Faithful Summarization;Abstractive Summarization",
        "author": "",
        "aff": "Children\u2019s Hospital Affiliated of Zhengzhou University; The Pennsylvania State University",
        "rating": "",
        "confidence": "3;5;3;4",
        "correctness": "4;3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/psunlpgroup/FaMeSumm"
    },
    {
        "id": "KxGI7hLxAo",
        "title": "Mind the Gap Between Conversations for Improved Long-Term Dialogue Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Dialogue system;time-aware dialogue model;long-term conversation generation;multi-session dialogue",
        "author": "",
        "aff": "Department of Computer Science, The University of Tokyo",
        "rating": "",
        "confidence": "2;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "L0SEfyrLsW",
        "title": "SELFOOD: Self-Supervised Out-Of-Distribution Detection via Learning to Rank",
        "track": "main",
        "status": "Long Findings",
        "keywords": "OOD detection;self-supervised;ranking",
        "author": "",
        "aff": "University of California San Diego; Hal\u0131c\u0131o\u011flu Data Science Institute, University of California San Diego",
        "rating": "",
        "confidence": "3;3;3;4;3",
        "correctness": "3;2;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.2,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "L0u9Dkito7",
        "title": "Image and Text: Fighting the same Battle? Super Resolution Learning for Imbalanced Text Classification",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Data Augmentation;Social media;Crisis management",
        "author": "",
        "aff": "IRIT, Universit\u00e9 de Toulouse, CNRS, Toulouse INP, UT3, Toulouse, France; IRIT, Universit\u00e9 de Toulouse, CNRS, Toulouse INP, UT3, Toulouse, France and IPAL, CNRS-NUS-ASTAR, Singapore",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "L4yVLb6cLu",
        "title": "Hi-ToM: A Benchmark for Evaluating Higher-Order Theory of Mind Reasoning in Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Higher Order Theory of Mind;Chain of Thought Prompting;Large Language Models;Deception",
        "author": "",
        "aff": "Westlake University; University of Michigan",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "L7IW2foTq4",
        "title": "Attention-Enhancing Backdoor Attacks Against BERT-based Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Backdoor Attack;BERT;Attention Loss;natural language processing",
        "author": "",
        "aff": "Department of Computer Science, Stony Brook University; Morgan Stanley",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "L7YoWxQq5t",
        "title": "Program Translation via Code Distillation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Program Translation;Intermediate Representations;Neural Machine Translation;Multilingual Code Generation;Pre-training",
        "author": "",
        "aff": "School of Artificial Intelligence, Jilin University; Microsoft Cloud and AI",
        "rating": "",
        "confidence": "3;4;2",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "L7ZBpZZ8Va",
        "title": "Orthogonal Subspace Learning for Language Model Continual Learning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "continual learning;orthogonal subspace;paramemter efficient tuning",
        "author": "",
        "aff": "Institute of Modern Languages and Linguistics, Fudan University, Shanghai, China; International Human Phenome Institutes (Shanghai); School of Computer Science, Fudan University, Shanghai, China",
        "rating": "",
        "confidence": "4;4;5;5",
        "correctness": "4;2;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "L8Cxea5krb",
        "title": "BERTie Bott's Every Flavor Labels: A Tasty Introduction to Semantic Role Labeling for Galician",
        "track": "main",
        "status": "Long Main",
        "keywords": "semantic role labeling;semantic parsing;Galician;Spanish;srl",
        "author": "",
        "aff": "Uppsala University",
        "rating": "",
        "confidence": "4;2;4;4",
        "correctness": "3;3;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "L8W6RyMRmL",
        "title": "Reduce Human Labor On Evaluating Conversational Information Retrieval System: A Human-Machine Collaboration Approach",
        "track": "main",
        "status": "Long Main",
        "keywords": "Interactive Evaluation;Human-Machine Collaboration;Conversational Information Retrieval",
        "author": "",
        "aff": "College of Computer Science, Sichuan University",
        "rating": "",
        "confidence": "1;2;3;3",
        "correctness": "4;3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "LCEbV5nsb8",
        "title": "SummIt: Iterative Text Summarization via ChatGPT",
        "track": "main",
        "status": "Long Findings",
        "keywords": "summarization;large language model;text editing",
        "author": "",
        "aff": "IFM Lab, Department of Computer Science, University of California, Davis, CA, USA",
        "rating": "",
        "confidence": "4;2;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/hpzhang94/summ_it"
    },
    {
        "id": "LDAgFeA55o",
        "title": "A Benchmark for Semi-Inductive Link Prediction in Knowledge Graphs",
        "track": "main",
        "status": "Short Findings",
        "keywords": "semi-inductive;link prediction;knowledge graph;unseen entity",
        "author": "",
        "aff": "University of Mannheim, Germany",
        "rating": "",
        "confidence": "4;3;3;3",
        "correctness": "4;3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "LGX5hFWPK2",
        "title": "CoMPosT: Characterizing and Evaluating Caricature in LLM Simulations",
        "track": "main",
        "status": "Long Main",
        "keywords": "large language models;caricatures;language model simulations;survey replication",
        "author": "",
        "aff": "Stanford University, Department of Computer Science",
        "rating": "",
        "confidence": "4;4;2;4",
        "correctness": "4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "LNKGWaRtlE",
        "title": "Ecologically Valid Explanations for Label Variation in NLI",
        "track": "main",
        "status": "Short Findings",
        "keywords": "annotation disagreement;explanation;interpretability;natural language inference;human label variation;textual inferences",
        "author": "",
        "aff": "FNRS, UCLouvain; Department of Linguistics, The Ohio State University; Department of Computer Science, The University of Chicago",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "2;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/njjiang/LiveNLI"
    },
    {
        "id": "LPtO1evrGa",
        "title": "Prompting and Evaluating Large Language Models for Proactive Dialogues: Clarification, Target-guided, and Non-collaboration",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Proactive Dialogue;Asking Clarification Question;Target-guided Conversation",
        "author": "",
        "aff": "Sichuan University; National University of Singapore; Singapore Management University; The Chinese University of Hong Kong",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "LQqlapYGeR",
        "title": "An Iteratively Parallel Generation Method with the Pre-Filling Strategy for Document-level Event Extraction",
        "track": "main",
        "status": "Long Main",
        "keywords": "natural language processing;information extraction;document-level event extraction;parallel generation",
        "author": "",
        "aff": "University of Science and Technology of China; Peking University; Bytedance",
        "rating": "",
        "confidence": "5;3;1",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/CarlanLark/IPGPF"
    },
    {
        "id": "LRRThBBiov",
        "title": "PRESTO: A Multilingual Dataset for Parsing Realistic Task-Oriented Dialogs",
        "track": "main",
        "status": "Long Main",
        "keywords": "task oriented dialogs;semantic parsing;nlp",
        "author": "",
        "aff": "Columbia University; Google Inc., Holistic Intelligence for Global Good; Google Inc.; Google Inc., University of Rochester; Google Inc., University of California, Santa Barbara",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/google-research-datasets/presto"
    },
    {
        "id": "LUDljw5VVD",
        "title": "Large Language Model Is Not a Good Few-shot Information Extractor, but a Good Reranker for Hard Samples!",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large Language Models;Information Extraction",
        "author": "",
        "aff": "Singapore Management University; S-Lab, Nanyang Technological University",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/mayubo2333/LLM-IE"
    },
    {
        "id": "LZq3crn3Bv",
        "title": "Cross-Lingual Cross-Target Stance Detection with Dual Knowledge Distillation Framework",
        "track": "main",
        "status": "Long Main",
        "keywords": "cross-lingual cross-target stance detection;dual knowledge distillation;category-oriented contrastive learning",
        "author": "",
        "aff": "Institute of Automation, Chinese Academy of Sciences; School of Artificial Intelligence, University of Chinese Academy of Sciences",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ALUKErnel/CCSD"
    },
    {
        "id": "LawAC9vh8q",
        "title": "Enhancing the Ranking Context of Dense Retrieval through Reciprocal Nearest Neighbors",
        "track": "main",
        "status": "Long Main",
        "keywords": "dense retrieval;reciprocal nearest neighbors;ranking context;contrastive learning;list-wise loss;false negatives;label smoothing;transformers;Large Language Models;information retrieval;natural language processing;deep learning",
        "author": "",
        "aff": "University of T\u00fcbingen, Germany; Brown University, USA; JKU Linz, LIT AI Lab, Austria",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/gzerveas/CODER"
    },
    {
        "id": "LepuyCeWcw",
        "title": "Causal Inference from Text: Unveiling Interactions between Variables",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Causal Inference;Natural Language Processing;Non-confounding Covariates;Disentanglement",
        "author": "",
        "aff": "King\u2019s College London; The Alan Turing Institute",
        "rating": "",
        "confidence": "5;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/zyxnlp/DIVA"
    },
    {
        "id": "Lk1KaQcjaM",
        "title": "AD-NLP: A Benchmark for Anomaly Detection in Natural Language Processing",
        "track": "main",
        "status": "Long Main",
        "keywords": "NLP;anomaly detection;deep learning;machine learning;dataset;benchmark",
        "author": "",
        "aff": "University of Bucharest; Bitdefender, University of Stuttgart",
        "rating": "",
        "confidence": "3;3;3;4",
        "correctness": "3;2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/mateibejan1/ad-nlp/"
    },
    {
        "id": "LkV7Xx06yq",
        "title": "MEGClass: Extremely Weakly Supervised Text Classification via Mutually-Enhancing Text Granularities",
        "track": "main",
        "status": "Long Findings",
        "keywords": "text classification;extremely weak supervision;weakly-supervised learning;document representations;representation learning;pseudo-document generation",
        "author": "",
        "aff": "Department of Computer Science, University of Illinois at Urbana-Champaign; Department of Computer Science at Virginia Tech",
        "rating": "",
        "confidence": "4;4;4;3",
        "correctness": "3;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Lp4CMWnSyb",
        "title": "Always the Best Fit: Adaptive Domain Gap Filling from Causal Perspective for Few-Shot Relation Extraction",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Cross domain;Causal Inference;Few-Shot;Relation Extraction",
        "author": "",
        "aff": "Beijing University of Posts and Telecommunications, China",
        "rating": "",
        "confidence": "3;2;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "M1GRz46Ahz",
        "title": "SHARCS: Efficient Transformers Through Routing with Dynamic Width Sub-networks",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Efficiency;Routing;hardness",
        "author": "",
        "aff": "University of Washington",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "M1Nogs3zR5",
        "title": "DemoNSF: A Multi-task Demonstration-based Generative Framework for Noisy Slot Filling Task",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Noisy Slot Filling;Input Perturbations;Multi-task Learning;Generative Framework;Large Language Model;Demonstration Learning",
        "author": "",
        "aff": "Meituan, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/dongguanting/Demo-NSF"
    },
    {
        "id": "M3uTqtEgNo",
        "title": "Rethinking and Improving Multi-task Learning for End-to-end Speech Translation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Speech translation;multi-modal translation;machine translation",
        "author": "",
        "aff": "School of Computer Science and Engineering, Northeastern University, Shenyang, China; School of Computer Science and Engineering, Northeastern University, Shenyang, China; NiuTrans Research, Shenyang, China",
        "rating": "",
        "confidence": "3;4;4;3",
        "correctness": "3;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "M51c00VxiJ",
        "title": "AMR Parsing is Far from Solved: GrAPES, the Granular AMR Parsing Evaluation Suite",
        "track": "main",
        "status": "Long Main",
        "keywords": "evaluation;dataset;corpus;semantic parsing;AMR;sentence-level semantics;semantic graphs",
        "author": "",
        "aff": "Vrij Universiteit Amsterdam; University of Amsterdam; University of Edinburgh; Utrecht University",
        "rating": "",
        "confidence": "3;5;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "M5knJ7ovgz",
        "title": "MRRL: Modifying the Reference via Reinforcement Learning for Non-Autoregressive Joint Multiple Intent Detection and Slot Filling",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Non-Autoregressive;Intent Detection and Slot Filling;Reinforcement Learning",
        "author": "",
        "aff": "School of ECE, Peking University, China",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "M6BJfQ9oup",
        "title": "Conceptor-Aided Debiasing of Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Natural Language Processing;Large Language Model;Fairness",
        "author": "",
        "aff": "New York University; University of Pennsylvania",
        "rating": "",
        "confidence": "3;1;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/realliyifei/conceptor-debias-llm"
    },
    {
        "id": "M9NdVElcbs",
        "title": "Bridging the Digital Divide: Performance Variation across Socio-Economic Factors in Vision-Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Multimodal;Income;Geodiversity;Evaluation;Analysis",
        "author": "",
        "aff": "University of Michigan - Ann Arbor, USA",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Analysis-for-Bridging-the-Digital-Divide"
    },
    {
        "id": "MEByW1upLk",
        "title": "Learning from Mistakes via Cooperative Study Assistant for Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Models;Reflection and Feedback",
        "author": "",
        "aff": "Computer Science Department, University of California Santa Barbara; Language Technology Institute, Carnegie Mellon University",
        "rating": "",
        "confidence": "4;3;4;2",
        "correctness": "3;3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://dqwang122.github.io/projects/SALAM"
    },
    {
        "id": "MFimS05rLW",
        "title": "Investigating the Effect of Pre-finetuning BERT Models on NLI Involving Presuppositions",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Presupposition;natural language inference;discourse;pragmatics",
        "author": "",
        "aff": "Massachusetts Institute of Technology, Cambridge, MA, USA; McGill University & Mila, Montreal, QC, Canada",
        "rating": "",
        "confidence": "3;2;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "MKjGklW9TP",
        "title": "ClusterPrompt: Cluster Semantic Enhanced Prompt Learning for New Intent Discovery",
        "track": "main",
        "status": "Long Findings",
        "keywords": "dialogue systems;intent discovery;prompt learning;contrastive learning",
        "author": "",
        "aff": "Singapore Management University",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "MLKLYoXypN",
        "title": "Cross-Lingual Consistency of Factual Knowledge in Multilingual Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Model Consistency;Multilinguality;Knowledge Incorporation;Large-scale Pre-trained Language Model;Model Evaluation;Knowledge Probing",
        "author": "",
        "aff": "Institute for Logic, Language and Computation, University of Amsterdam; Center for Language and Cognition, University of Groningen",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "5;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.666666666666667,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Betswish/Cross-Lingual-Consistency"
    },
    {
        "id": "MLzoMwlxTh",
        "title": "Goal-Driven Explainable Clustering via Language Descriptions",
        "track": "main",
        "status": "Long Main",
        "keywords": "clustering;explainability;large language models",
        "author": "",
        "aff": "UC San Diego; UC Berkeley",
        "rating": "",
        "confidence": "3;2;3;3",
        "correctness": "4;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "MMrqu8SD6y",
        "title": "\"A Tale of Two Movements\": Identifying and Comparing Perspectives in \\#BlackLivesMatter and \\#BlueLivesMatter Movements-related Tweets using Weakly Supervised Graph-based Structured Prediction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "characterization of social movements;social media;discourse analysis;perspective identification",
        "author": "",
        "aff": "Purdue University",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "MNTCi0i3cU",
        "title": "InstructSafety: A Unified Framework for Building Multidimensional and Explainable Safety Detector through Instruction Tuning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "safety detection;unified framework;instruction tuning",
        "author": "",
        "aff": "The CoAI group, DCST; Institute for Artificial Intelligence; State Key Lab of Intelligent Technology and Systems; Beijing National Research Center for Information Science and Technology; Tsinghua University, Beijing 100084, China.",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/thu-coai/InstructSafety"
    },
    {
        "id": "MQsvD6YOan",
        "title": "Improving Low-resource Question Answering by Augmenting Question Information",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Question Answering;Data augmentation;Low-resource domains",
        "author": "",
        "aff": "Minzu University of China, Beijing, China; Harbin Institute of Technology (Shenzhen), Shenzhen, China; Harbin Institute of Technology, Harbin, China; Pengcheng Laboratory, Shenzhen, China; Brunel University Uxbridge, London, UK",
        "rating": "",
        "confidence": "3;4;2",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/andongBlue/PQQ_QA"
    },
    {
        "id": "MRehcsVc4y",
        "title": "RSVP: Customer Intent Detection via Agent Response Contrastive and Generative Pre-Training",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Intent Detection;Task Adaptive Fine-Tuning;Contrastive Learning;Question Answering",
        "author": "",
        "aff": "Department of Computer Science, National Yang Ming Chiao Tung University, Taiwan",
        "rating": "",
        "confidence": "4;4;4;4;3",
        "correctness": "3;3;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.8,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/tommytyc/RSVP"
    },
    {
        "id": "MSQrAoa7iy",
        "title": "3DRP-Net: 3D Relative Position-aware Network for 3D Visual Grounding",
        "track": "main",
        "status": "Long Main",
        "keywords": "3D visual grounding",
        "author": "",
        "aff": "Zhejiang University; ByteDance",
        "rating": "",
        "confidence": "3;5;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "MWhwZjFCcq",
        "title": "StyleBART: Decorate Pretrained Model with Style Adapters for Unsupervised Stylistic Headline Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Headline generation; Style transfer; Efficient NLP; Unsupervised learning",
        "author": "",
        "aff": "Southern University of Science and Technology; Shanghai University of Finance and Economics",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/sufenlp/StyleBART"
    },
    {
        "id": "MWisc5Amup",
        "title": "ALDi: Quantifying the Arabic Level of Dialectness of Text",
        "track": "main",
        "status": "Long Main",
        "keywords": "Arabic Dialects;Arabic Dialect Identification;Dialectal Variation;Code-switching;Level of Dialectness",
        "author": "",
        "aff": "Institute for Language, Cognition and Computation, School of Informatics, University of Edinburgh",
        "rating": "",
        "confidence": "5;4;5",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "MXMA6vQtSZ",
        "title": "Entity-Based Evaluation of Political Bias in Automatic Summarization",
        "track": "main",
        "status": "Short Findings",
        "keywords": "summarization;political bias",
        "author": "",
        "aff": "The University of Chicago",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "MYdmanqfvm",
        "title": "What do Deck Chairs and Sun Hats Have in Common? Uncovering Shared Properties in Large Concept Vocabularies",
        "track": "main",
        "status": "Short Main",
        "keywords": "lexical semantics;commonality detection;ultra-fine entity typing;ontology learning",
        "author": "",
        "aff": "University of Shanghai for Science and Technology, China; CRIL CNRS & University of Artois, France; CardiffNLP, Cardiff University, UK",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/amitgajbhiye/concept_commonality"
    },
    {
        "id": "MZwFbA3DSF",
        "title": "Pit One Against Many: Leveraging Attention-head Embeddings for Parameter-efficient Multi-head Attention",
        "track": "main",
        "status": "Long Findings",
        "keywords": "multi-head attention; memory efficiency",
        "author": "",
        "aff": "Department of Computer Science, University of Sheffield, United Kingdom",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/HUIYINXUE/simpleMHE"
    },
    {
        "id": "MbKRJUowYX",
        "title": "E-CORE: Emotion Correlation Enhanced Empathetic Dialogue Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "empathetic dialogue generation;graph network;emotion perception;natural language generation",
        "author": "",
        "aff": "University of Science and Technology of China; Beijing University of Posts and Telecommunications",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Md1YdfqAed",
        "title": "Balance Act: Mitigating Hubness in Cross-Modal Retrieval with Query and Gallery Banks",
        "track": "main",
        "status": "Long Main",
        "keywords": "Cross-modal Retrieval;Hubness",
        "author": "",
        "aff": "City University of Hong Kong; University of Waterloo",
        "rating": "",
        "confidence": "3;2;4",
        "correctness": "5;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/yimuwangcs/Better_Cross_Modal_Retrieval"
    },
    {
        "id": "Mefvmgkb9G",
        "title": "CAPSTONE: Curriculum Sampling for Dense Retrieval with Document Expansion",
        "track": "main",
        "status": "Long Main",
        "keywords": "Dense Retrieval;Document Expansion",
        "author": "",
        "aff": "The University of Hong Kong; Microsoft Research Asia; Microsoft",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "MhEJqeCzgE",
        "title": "Unraveling Feature Extraction Mechanisms in Neural Networks",
        "track": "main",
        "status": "Long Main",
        "keywords": "Interpretability;Infinite-width;Feature extraction;Learning dynamics;Neural tangent kernel",
        "author": "",
        "aff": "Singapore University of Technology and Design; StatNLP Research Group, Singapore University of Technology and Design",
        "rating": "",
        "confidence": "3;3;2",
        "correctness": "5;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "MhU0zxuZ5K",
        "title": "On the Dimensionality of Sentence Embeddings",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Sentence embedding;dimension reduction",
        "author": "",
        "aff": "Tencent AI Lab Seattle",
        "rating": "",
        "confidence": "5;4;4;3",
        "correctness": "3;4;5;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "MhbiD5FVPF",
        "title": "People Make Better Edits: Measuring the Efficacy of LLM-Generated Counterfactually Augmented Data for Harmful Language Detection",
        "track": "main",
        "status": "Long Main",
        "keywords": "hate speech;sexism;counterfactually augmented data;data augmentation;model robustness",
        "author": "",
        "aff": "RWTH Aachen University; Sapienza University of Rome; University of Copenhagen; RWTH Aachen University, University of Konstanz; GESIS - Leibniz Institute for Social Sciences",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Indiiigo/automatedCADData"
    },
    {
        "id": "MkD0VGShAq",
        "title": "GazeVQA: A Video Question Answering Dataset for Multiview Eye-Gaze Task-Oriented Collaborations",
        "track": "main",
        "status": "Long Main",
        "keywords": "video question answering;human-robot collaboration",
        "author": "",
        "aff": "Institute for Infocomm Research, Agency for Science, Technology, and Research (A*STAR), Singapore; Show Lab, National University of Singapore",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/mfurkanilaslan/GazeVQA"
    },
    {
        "id": "Mm5GXKvpXm",
        "title": "CReTIHC: Designing Causal Reasoning Tasks about Temporal Interventions and Hallucinated Confoundings",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Causality;Commonsense reasoning;Large Language Models;Temporal Interventions;Hallucinated Confoundings",
        "author": "",
        "aff": "Hyundai Motor Company; Department of Computer Science and Engineering, Korea University",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ChangwooChun/CReTIHC"
    },
    {
        "id": "MmBjKmHIND",
        "title": "Synthetic Data Generation with Large Language Models for Text Classification: Potential and Limitations",
        "track": "main",
        "status": "Long Main",
        "keywords": "Synthetic Data Generation;Data Augmentation;Large Language Models",
        "author": "",
        "aff": "Purdue University; Washington University in St. Louis",
        "rating": "",
        "confidence": "4;4;4;3",
        "correctness": "2;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "huggingface.co/datasets/xfleezy/human_annotation_emnlp23",
        "github": ""
    },
    {
        "id": "MnPnE4xV0H",
        "title": "Pretraining Language Models with Text-Attributed Heterogeneous Graphs",
        "track": "main",
        "status": "Long Findings",
        "keywords": "language model pretraining;text-attributed heterogeneous graphs;graph neural networks",
        "author": "",
        "aff": "SKLSDE Lab, Beihang University, Beijing, China; Zhongguancun Laboratory, Beijing, China; School of Transportation Science and Engineering, Beihang University, Beijing, China; SKLSDE Lab, Beihang University, Beijing, China",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Hope-Rita/THLM"
    },
    {
        "id": "MoEfm3iPMy",
        "title": "Self-Knowledge Guided Retrieval Augmentation for Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "self-knowledge;retrieval augmentation;large language models",
        "author": "",
        "aff": "Institute for AI Industry Research (AIR), Tsinghua University, Beijing, China; Dept. of Comp. Sci. & Tech., Institute for AI, Tsinghua University, Beijing, China",
        "rating": "",
        "confidence": "4;3;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/THUNLP-MT/SKR"
    },
    {
        "id": "Mq5cyRMGlD",
        "title": "VERVE: Template-based ReflectiVE Rewriting for MotiVational IntErviewing",
        "track": "main",
        "status": "Long Findings",
        "keywords": "motivational interviewing;rewriting;counseling",
        "author": "",
        "aff": "Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI, USA; School of Public Health, University of Michigan, Ann Arbor, MI, USA",
        "rating": "",
        "confidence": "2;4;5",
        "correctness": "4;2;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Mte6BK69zv",
        "title": "Unraveling Downstream Gender Bias from Large Language Models: A Study on AI Educational Writing Assistance",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large Language Models;Gender Bias;Writing Support;Human-AI Collaboration",
        "author": "",
        "aff": "Bern University of Applied Sciences; EPFL, Lausanne, Switzerland",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/epfl-ml4ed/unraveling-llm-bias"
    },
    {
        "id": "Mtgbc9XFPU",
        "title": "Pre-training Intent-Aware Encoders for Zero- and Few-Shot Intent Classification",
        "track": "main",
        "status": "Long Main",
        "keywords": "intent classification;task-oriented dialogue system",
        "author": "",
        "aff": "AWS AI Labs; Korea University",
        "rating": "",
        "confidence": "4;4;4;3",
        "correctness": "4;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "MxhTQC9AYV",
        "title": "RealBehavior: A Framework for Faithfully Characterizing Foundation Models\u2019 Human-like Behavior Mechanisms",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Foundation Model;Human-like Behavior;Faithfulness",
        "author": "",
        "aff": "School of Computer Science, Fudan University; Institute of Modern Languages and Linguistics, Fudan University; Department of Chinese Language and Literature, Fudan University",
        "rating": "",
        "confidence": "4;5;3",
        "correctness": "3;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "My6Rgv7xXV",
        "title": "Contextual Interaction for Argument Post Quality Assessment",
        "track": "main",
        "status": "Long Main",
        "keywords": "argument;argument quality;contrastive learning;large language models",
        "author": "",
        "aff": "Institute of Software, Chinese Academy of Sciences; University of Chinese Academy of Sciences, Institute of Software, Chinese Academy of Sciences",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ucasYW/Contextual-Interaction-for-AQA"
    },
    {
        "id": "MyTyc69kKK",
        "title": "TSTR: Target Similarity Tuning Meets the Real World",
        "track": "main",
        "status": "Short Findings",
        "keywords": "prompt engineering;code generation;target similarity tuning;example selection",
        "author": "",
        "aff": "Microsoft, Bangalore, India; Microsoft, Redmond, US; Microsoft, Delhi, India; Microsoft, Keerbergen, Belgium",
        "rating": "",
        "confidence": "2;3;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "MzDakXdBbM",
        "title": "Can Large Language Models Fix Data Annotation Errors? An Empirical Study Using Debatepedia for Query-Focused Text Summarization",
        "track": "main",
        "status": "Short Findings",
        "keywords": "ChatGPT;PaLM;Large Language Models;Query Focused Abstractive Text Summarization",
        "author": "",
        "aff": "York University; Dialpad Canada Inc., York University; Royal Bank of Canada, York University",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/tahmedge/CQSUMDP"
    },
    {
        "id": "N3a2vVk8vu",
        "title": "Hierarchical Prompting Assists Large Language Model on Web Navigation",
        "track": "main",
        "status": "Short Findings",
        "keywords": "LLM Prompting;Web Navigation",
        "author": "",
        "aff": "School of Computer Science, Carnegie Mellon University",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/robert1003/ash-prompting"
    },
    {
        "id": "N4VUOeVOfS",
        "title": "Hidding the Ghostwriters: An Adversarial Evaluation of AI-Generated Student Essay Detection",
        "track": "main",
        "status": "Long Main",
        "keywords": "AIGC detection;AI-generated student essay;education",
        "author": "",
        "aff": "Institute of Software, Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, Beijing, China; Institute of Software, Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, Beijing, China",
        "rating": "",
        "confidence": "4;3;4;4",
        "correctness": "4;2;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/xinlinpeng/AIG-ASAP"
    },
    {
        "id": "N58BZj5JB7",
        "title": "Improving Diversity of Demographic Representation in Large Language Models via Collective-Critiques and Self-Voting",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large language models;Fairness;Diversity;Language model reasoning",
        "author": "",
        "aff": "Google DeepMind; OpenAI; Google Research",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "N6f1iHjWvB",
        "title": "Automatic Analysis of Substantiation in Scientific Peer Reviews",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Peer review;Substantiation;Argument mining;Dataset",
        "author": "",
        "aff": "LIX, \u00c9cole Polytechnique, Institut Polytechnique de Paris, France; Linagora, France; LIX, \u00c9cole Polytechnique, Institut Polytechnique de Paris, France; Linagora, France; LTCI, T\u00e9l\u00e9com-Paris, Institut Polytechnique de Paris, France; Inria, Paris, France",
        "rating": "",
        "confidence": "3;4;2;3;4",
        "correctness": "2;4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.2,
        "correctness_avg": 3.6,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/YanzhuGuo/SubstanReview"
    },
    {
        "id": "N6sXsHuWDE",
        "title": "ROME: Evaluating Pre-trained Vision-Language Models on Reasoning beyond Visual Common Sense",
        "track": "main",
        "status": "Long Findings",
        "keywords": "commonsense reasoning;multimodality;pre-trained vision-language models",
        "author": "",
        "aff": "School of Computing and Information Systems, Singapore Management University",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "N7R2emgl67",
        "title": "Learning to Rank Context for Named Entity Recognition Using a Synthetic Dataset",
        "track": "main",
        "status": "Long Main",
        "keywords": "ner;transformers;context retrieval",
        "author": "",
        "aff": "Laboratoire Informatique d\u2019Avignon; Laboratoire des Sciences du Num\u00e9rique de Nantes",
        "rating": "",
        "confidence": "4;4;4;3",
        "correctness": "4;3;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "N8TTwaIBId",
        "title": "CCEval: A Representative Evaluation Benchmark for the Chinese-centric Multilingual Machine Translation",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Multilingual Machine Translation;Low-resource Languages;Evaluation Benchmark;Evaluation Dataset;Chinese-centric;Translation Evaluation;Test Set",
        "author": "",
        "aff": "International Digital Economy Academy, Shenzhen, China; Peng Cheng Laboratory, Shenzhen, China",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://bright.pcl.ac.cn/en/offlineTasks",
        "github": ""
    },
    {
        "id": "N8nQjYuyhO",
        "title": "Using Artificial French Data to Understand the Emergence of Gender Bias in Transformer Language Models",
        "track": "main",
        "status": "Short Main",
        "keywords": "Language Model;Transformer;LM Analysis;Gender Bias",
        "author": "",
        "aff": "Fondazione Bruno Kessler, Italy; University of Trento, Italy; Universit\u00e9 Paris Cit\u00e9, LLF, CNRS, 75013 Paris, France",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/lina-conti/artificial-data-gender"
    },
    {
        "id": "N924k3YM8V",
        "title": "The ACL OCL Corpus: Advancing Open Science in Computational Linguistics",
        "track": "main",
        "status": "Long Main",
        "keywords": "scholarly corpus;computational linguistics;topic trend analysis;acl anthology",
        "author": "",
        "aff": "School of Computing, National University of Singapore; College of Information Sciences and Technology, Pennsylvania State University",
        "rating": "",
        "confidence": "4;4;3;4",
        "correctness": "3;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://huggingface.co/datasets/WINGNUS/ACL-OCL",
        "github": ""
    },
    {
        "id": "NAmRjAIMkz",
        "title": "Pointwise Mutual Information Based Metric and Decoding Strategy for Faithful Generation in Document Grounded Dialogs",
        "track": "main",
        "status": "Long Main",
        "keywords": "docuemnt grounded dialogs;dialog response generation;faithful response generation",
        "author": "",
        "aff": "IBM Research, AI",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "NBH3x0u5oQ",
        "title": "MixEdit: Revisiting Data Augmentation and Beyond for Grammatical Error Correction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "natural language processing;grammatical error correction;data augmentation",
        "author": "",
        "aff": "Peng Cheng Laboratory; Tsinghua Shenzhen International Graduate School, Tsinghua University",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/THUKElab/MixEdit"
    },
    {
        "id": "NHeAUKlTO8",
        "title": "PartialFormer: Modeling Part Instead of Whole for Machine Translation",
        "track": "main",
        "status": "Reject",
        "keywords": "Lightweight Transformer;",
        "author": "",
        "aff": "EMNLP submission",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "NMMRH80gha",
        "title": "Simple and Effective Input Reformulations for Translation",
        "track": "main",
        "status": "Long Main",
        "keywords": "natural language processing;data efficiency;input reformulations;multilingual;translation;foundation language models;finetuning;machine learning",
        "author": "",
        "aff": "University of California, Berkeley",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/your-repo-link"
    },
    {
        "id": "NMMnxhQm01",
        "title": "The Distributional Hypothesis Does Not Fully Explain the Benefits of Masked Language Model Pretraining",
        "track": "main",
        "status": "Long Main",
        "keywords": "Distributional Hypothesis;MLM;Pretraining",
        "author": "",
        "aff": "University of Southern California",
        "rating": "",
        "confidence": "2;4;4;3",
        "correctness": "2;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/usc-tamagotchi/DH-MLM"
    },
    {
        "id": "NO5dc8Ljvj",
        "title": "C2D2 Dataset: A Resource for the Cognitive Distortion Analysis and Its Impact on Mental Health",
        "track": "main",
        "status": "Long Findings",
        "keywords": "cognitive distortion;mental health;text analysis",
        "author": "",
        "aff": "Research Center for Social Computing and Information Retrieval, Harbin Institute of Technology, Heilongjiang, China",
        "rating": "",
        "confidence": "4;4;4;3",
        "correctness": "3;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "NPJznfA7ZC",
        "title": "Demystifying Prompts in Language Models via Perplexity Estimation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "LLM;perplexity;prompts",
        "author": "",
        "aff": "Paul G. Allen School of Computer Science & Engineering, University of Washington; Meta AI Research; Allen Institute for Artificial Intelligence",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "NPkkvrv2Vp",
        "title": "Who is Speaking? Speaker-Aware Multiparty Dialogue Act Classification",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Dialogue acts;multiparty dialogues;speaker modeling",
        "author": "",
        "aff": "Texas A&M University; University of Arizona",
        "rating": "",
        "confidence": "3;4;3;4",
        "correctness": "3;2;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Ayesha55/Speaker-graph-model-for-DAs-EMNLP"
    },
    {
        "id": "NT4ehxCifo",
        "title": "Large Language Models Meet Open-World Intent Discovery and Recognition: An Evaluation of ChatGPT",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Models;Evaluation;Out of Domain;Intent Recognition",
        "author": "",
        "aff": "Meituan, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/songxiaoshuai/OOD-Evaluation"
    },
    {
        "id": "NW09xt3kvH",
        "title": "HutCRS: Hierarchical User-Interest Tracking for Conversational Recommender System",
        "track": "main",
        "status": "Long Main",
        "keywords": "Conversational Recommender Rystem;Multi-round Conversations;Hierarchical Interest Tree;Graph Neural Network",
        "author": "",
        "aff": "Sun Yat-sen University; Guangdong University of Technology",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/xinle1129/HutCRS"
    },
    {
        "id": "NXXrvcilq8",
        "title": "Are NLP Models Good at Tracing Thoughts: An Overview of Narrative Understanding",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Narrative Understanding;Reading Comprehension;Summarization;Question Answering",
        "author": "",
        "aff": "The Alan Turing Institute, UK; Department of Informatics, King\u2019s College London",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "NYlL3oACU2",
        "title": "Comparing Biases and the Impact of Multilingual Training across Multiple Languages",
        "track": "main",
        "status": "Long Main",
        "keywords": "Fairness;Biases;Multilinguality",
        "author": "",
        "aff": "AWS AI Labs; University of California, Santa Barbara",
        "rating": "",
        "confidence": "5;3;4",
        "correctness": "5;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.666666666666667,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "NYstQhld8J",
        "title": "MarkQA: A large scale KBQA dataset with numerical reasoning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Knowledge base;Question answering;Numerical reasoning",
        "author": "",
        "aff": "State Key Laboratory for Novel Software Technology, Nanjing University, China",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "NZK22y40DS",
        "title": "Towards Enhancing Relational Rules for Knowledge Graph Link Prediction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Knowledge Graph Reasoning;Graph Neural Network;Inductive Reasoning",
        "author": "",
        "aff": "School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China; School of Software Engineering, Beijing Jiaotong University, Beijing, China",
        "rating": "",
        "confidence": "3;5;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "NZZB3UGcd8",
        "title": "Editing Large Language Models: Problems, Methods, and Opportunities",
        "track": "main",
        "status": "Long Main",
        "keywords": "Model Editing;Large Language Model;Editing Factual Knowledge",
        "author": "",
        "aff": "Zhejiang University\u2660Zhejiang University - Ant Group Joint Laboratory of Knowledge Graph\u2662Donghai Laboratory; Zhejiang University\u2660Zhejiang University - Ant Group Joint Laboratory of Knowledge Graph\u2020; National University of Singapore; Zhejiang University\u2660Zhejiang University - Ant Group Joint Laboratory of Knowledge Graph",
        "rating": "",
        "confidence": "2;1;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/zjunlp/EasyEdit"
    },
    {
        "id": "Na4DonsjLx",
        "title": "Contrastive Learning for Inference in Dialogue",
        "track": "main",
        "status": "Long Main",
        "keywords": "inference in dialogue;commonsense reasoning in dialogue;contrastive learning;semantic gap;dialogue comprehension;information gap;inductive reasoning",
        "author": "",
        "aff": "The Hong Kong University of Science and Technology",
        "rating": "",
        "confidence": "4;4;5;3;4",
        "correctness": "3;3;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/HLTCHKUST/contrastive_inference_dialogue"
    },
    {
        "id": "NbkVQsbaqJ",
        "title": "Exploring In-Context Learning for Knowledge Grounded Dialog Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "dialog;knowledge;large language models;in-context learning;retrieval system",
        "author": "",
        "aff": "School of Computer Science, Peking University; National Key Laboratory for Multimedia Information Processing, Peking University",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Nc6U1Z0DDt",
        "title": "Balaur: Language Model Pretraining with Lexical Semantic Relations",
        "track": "main",
        "status": "Long Findings",
        "keywords": "language model;lm;pretraining;lexical semantics;lexical semantic relations;hypernymy;semantic specialization;wordnet",
        "author": "",
        "aff": "Mila/McGill University",
        "rating": "",
        "confidence": "3;3;2",
        "correctness": "3;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "github.com/mirandrom/balaur"
    },
    {
        "id": "NeOsOzNMiS",
        "title": "LayoutDIT: Layout-Aware End-to-End Document Image Translation with Multi-Step Conductive Decoder",
        "track": "main",
        "status": "Long Findings",
        "keywords": "document image;machine translation;layout;multi-step;conductive;end-to-end",
        "author": "",
        "aff": "State Key Laboratory of Multimodal Artificial Intelligence Systems (MAIS), Institute of Automation, Chinese Academy of Sciences, Beijing, China; Fanyu AI Laboratory, Zhongke Fanyu Technology Co., Ltd, Beijing, China; State Key Laboratory of Multimodal Artificial Intelligence Systems (MAIS), Institute of Automation, Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China",
        "rating": "",
        "confidence": "2;4;4",
        "correctness": "3;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "NfN3ZDCcsO",
        "title": "SAMRank: Unsupervised Keyphrase Extraction using Self-Attention Map in BERT and GPT-2",
        "track": "main",
        "status": "Long Main",
        "keywords": "Unsupervised Keyphrase Extraction;Pre-trained Language Model;Self-Attention Map;BERT;GPT-2",
        "author": "",
        "aff": "Department of Computer Science and Engineering, Incheon National University",
        "rating": "",
        "confidence": "5;5;4;3",
        "correctness": "4;2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/kangnlp/SAMRank"
    },
    {
        "id": "Ni57pgQVqq",
        "title": "APoLLo : Unified Adapter and Prompt Learning for Vision Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Vision Language Models;Prompt Tuning;Adapter Tuning;Contrastive Learning",
        "author": "",
        "aff": "University of Maryland, College Park; University of Toronto",
        "rating": "",
        "confidence": "4;4;2;3",
        "correctness": "3;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://gamma.umd.edu/pro/vision_language/apollo/",
        "github": ""
    },
    {
        "id": "NiEYKbNnQO",
        "title": "Text Rendering Strategies for Pixel Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Pixel-based language modelling;isotropy;word frequency bias",
        "author": "",
        "aff": "Johns Hopkins University; Department of Computer Science, University of Copenhagen",
        "rating": "",
        "confidence": "4;2;4",
        "correctness": "3;3;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Nijnhwu1Uz",
        "title": "PromptST: Abstract Prompt Learning for End-to-End Speech Translation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Speech-to-Text Translation;Linguistic Probing Benchmark;Prompt Learning",
        "author": "",
        "aff": "JD Explore Academy, JD.com, Beijing, China; The University of Sydney, Sydney, Australia; Institute of Computing and Intelligence, Harbin Institute of Technology, Shenzhen, China",
        "rating": "",
        "confidence": "3;5;4;3;4",
        "correctness": "4;4;2;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.8,
        "correctness_avg": 3.6,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ytf-philp/PromptST"
    },
    {
        "id": "Nk2vfZa4lX",
        "title": "Appraising the Potential Uses and Harms of LLMs for Medical Systematic Reviews",
        "track": "main",
        "status": "Long Main",
        "keywords": "LLMs;Biomedical;Systematic Reviews;Qualitative Study;User Research",
        "author": "",
        "aff": "King\u2019s College London; Northeastern University; Brown University",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "NlWH0Kvptf",
        "title": "FactSpotter: Evaluating the Factual Faithfulness of Graph-to-Text Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Graph-to-text;Factual Faithfulness;Constrained Text Generation",
        "author": "",
        "aff": "Inria, Institut Polytechnique de Paris",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/guihuzhang/FactSpotter"
    },
    {
        "id": "NnVIFpsMAy",
        "title": "Make Every Example Count: On the Stability and Utility of Self-Influence for Learning from Noisy NLP Datasets",
        "track": "main",
        "status": "Long Main",
        "keywords": "data filtering;influence functions;self-influence;curriculum learning;noisy data;machine translation;question answering",
        "author": "",
        "aff": "Google DeepMind",
        "rating": "",
        "confidence": "4;4;2",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "NomitcTG87",
        "title": "Transformer-based Live Update Generation for Soccer Matches from Microblog Posts",
        "track": "main",
        "status": "Short Main",
        "keywords": "Timeline Summarization;Social Media",
        "author": "",
        "aff": "Graduate School of Informatics, Nagoya University, Japan",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "NphKIYvm9D",
        "title": "Investigating Multilingual Coreference Resolution by Universal Annotations",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multilingual coreference resolution;coreference analysis",
        "author": "",
        "aff": "Heidelberg Institute for Theoretical Studies gGmbH",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/HaixiaChai/multi-coref"
    },
    {
        "id": "NrCLVmq0KD",
        "title": "LLM aided semi-supervision for efficient Extractive Dialog Summarization",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Dialog Summarization;Large Language Models;Semi-supervised learning;Transformers;BART;GPT;Rouge",
        "author": "",
        "aff": "ServiceNow Research and University of British Columbia; University of Waterloo and ServiceNow Research; Amsterdam UMC, Department of Medical Informatics, University of Amsterdam and Amsterdam Public Health, Methodology, Amsterdam, The Netherlands",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "NrmYYAO7N4",
        "title": "Expand, Highlight, Generate: RL-driven Document Generation for Passage Reranking",
        "track": "main",
        "status": "Long Main",
        "keywords": "Synthetic document generation;Data augmentation;Information retrieval",
        "author": "",
        "aff": "University of Amsterdam; Leiden University",
        "rating": "",
        "confidence": "4;3;4;3",
        "correctness": "4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/arian-askari/doc"
    },
    {
        "id": "NtHfJrjkiv",
        "title": "ReCEval: Evaluating Reasoning Chains via Correctness and Informativeness",
        "track": "main",
        "status": "Long Main",
        "keywords": "reasoning;multi-step reasoning;evaluation;information-gain",
        "author": "",
        "aff": "UNC Chapel Hill",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/archiki/ReCEval"
    },
    {
        "id": "NuMemgzPYT",
        "title": "LLM-in-the-loop: Leveraging Large Language Model for Thematic Analysis",
        "track": "main",
        "status": "Short Findings",
        "keywords": "thematic analysis;NLP applications;qualitative research",
        "author": "",
        "aff": "University of Texas at Austin; Pennsylvania State University; Academia Sinica",
        "rating": "",
        "confidence": "4;3;4;5",
        "correctness": "3;3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/sjdai/LLM-thematic-analysis"
    },
    {
        "id": "NwJVbDxfTd",
        "title": "Semantic Similarity Covariance Matrix Shrinkage",
        "track": "main",
        "status": "Long Findings",
        "keywords": "semantics;embeddings;knowledge graphs;covariance;finance;portfolio optimization",
        "author": "",
        "aff": "Bloomberg",
        "rating": "",
        "confidence": "4;4;2",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Nx9D21g1lW",
        "title": "PivotFEC: Enhancing Few-shot Factual Error Correction with a Pivot Task Approach using Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Factual Error Correction;Large Language Models;Few-shot",
        "author": "",
        "aff": "School of Computer Science and Engineering, Beihang University, Beijing, China; The University of Hong Kong, Hong Kong, China",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "NxOeOxe6qs",
        "title": "Variator: Accelerating Pre-trained Models with Plug-and-Play Compression Modules",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large language model;model compression;plugins",
        "author": "",
        "aff": "Tencent Inc.; Gaoling School of Artificial Intelligence, Renmin University of China, Beijing; NLP Group, DCST, IAI, BNRIST, Tsinghua University, Beijing; Zhili College, Tsinghua University, Beijing",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/thunlp/Compression-Plugin"
    },
    {
        "id": "O1IEUXd4SI",
        "title": "Do Stochastic Parrots have Feelings Too? Improving Neural Detection of Synthetic Text via Emotion Recognition",
        "track": "main",
        "status": "Long Findings",
        "keywords": "synthetic text detection;neural text detection;emotion;affective deficit",
        "author": "",
        "aff": "School of Computer Science and Statistics, Trinity College Dublin; School of Computing, Dublin City University; SFI Centre for Research Training in Machine Learning at Dublin City University",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/alanagiasi/emoPLMsynth"
    },
    {
        "id": "O36QcmUEDM",
        "title": "JWSign: A Highly Multilingual Corpus of Bible Translations for more Diversity in Sign Language Processing",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Machine Translation;Sign Languages;Dataset;Multilinguality",
        "author": "",
        "aff": "University of Zurich, Switzerland; EFREI Paris, France; University of Dayton, USA; Kwame Nkrumah University of Science and Technology, Ghana",
        "rating": "",
        "confidence": "2;3;2",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "O4gELC78Bq",
        "title": "Towards Detecting Contextual Real-Time Toxicity for In-Game Chat",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Real-Time Toxicity Detection;Game Chat Toxicity;Game Chat Moderation",
        "author": "",
        "aff": "Ubisoft La Forge, McGill University, Mila; Ubisoft UDO; McGill University, Mila, CIFAR AI chair",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "O4kDO3yS9B",
        "title": "Rethinking the Evaluation for Conversational Recommendation in the Era of Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Conversational Recommendation;Large Language Model;Evaluation",
        "author": "",
        "aff": "Gaoling School of Artificial Intelligence, Renmin University of China; Gaoling School of Artificial Intelligence, Renmin University of China; School of Information, Renmin University of China; School of Computer Science and Engineering, Beihang University",
        "rating": "",
        "confidence": "4;4;2;3",
        "correctness": "4;3;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/RUCAIBox/iEvaLM-CRS"
    },
    {
        "id": "O7eKiJpePJ",
        "title": "Instruct and Extract: Instruction Tuning for On-Demand Information Extraction",
        "track": "main",
        "status": "Long Main",
        "keywords": "information extraction;instruction-tuning;language model;open scenario",
        "author": "",
        "aff": "University of Illinois Urbana-Champaign",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/yzjiao/On-Demand-IE"
    },
    {
        "id": "O9zrG7NB3X",
        "title": "Learn Your Tokens: Word-Pooled Tokenization for Language Modeling",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Tokenization;Language Modeling;BPE;Subword;Segmentation;Numeracy;Multilingual",
        "author": "",
        "aff": "USC; USC / ISI",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "Github link not provided, but mentioned in the abstract"
    },
    {
        "id": "OC4OLQGtIR",
        "title": "Reducing Sequence Length by Predicting Edit Spans with Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large language model;efficiency;instruction tuning;Local sequence transduction task",
        "author": "",
        "aff": "Tokyo Institute of Technology; MBZUAI",
        "rating": "",
        "confidence": "5;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "ODeHH5FBwx",
        "title": "M2C: Towards Automatic Multimodal Manga Complement",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Manga data;Vision and Language;Chain of Thought Prompting",
        "author": "",
        "aff": "Beihang University",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/HC-Guo/M2C"
    },
    {
        "id": "OETPPc15XG",
        "title": "Whispering LLaMA: A Cross-Modal Generative Error Correction Framework for Speech Recognition",
        "track": "main",
        "status": "Short Main",
        "keywords": "Multimodal Learning;Parameter-Efficient Adaptation;Speech Recognition;Generative Error Correction",
        "author": "",
        "aff": "King Abdullah University of Science and Technology, Karolinska Institute; King Abdullah University of Science and Technology, Georgia Institute of Technology, NVIDIA Research; King Abdullah University of Science and Technology, SDAIA-KAUST Center of Excellence in Data Science and Artificial Intelligence; King Abdullah University of Science and Technology, Manipal Institute of Technology; King Abdullah University of Science and Technology; Karolinska Institute",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Srijith-rkr/Whispering-LLaMA"
    },
    {
        "id": "OGdl9d3BEC",
        "title": "Revisiting Block-based Quantisation: What is Important for Sub-8-bit LLM Inference?",
        "track": "main",
        "status": "Long Main",
        "keywords": "large language model;LLM;quantization;NLP",
        "author": "",
        "aff": "University of Oxford; Imperial College London",
        "rating": "",
        "confidence": "3;3;3;3",
        "correctness": "4;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ChengZhang-98/llm-mixed-q"
    },
    {
        "id": "OK5yv6Fhl9",
        "title": "MULTITuDE: Large-Scale Multilingual Machine-Generated Text Detection Benchmark",
        "track": "main",
        "status": "Long Main",
        "keywords": "text generation;large language models;multilinguality;machine-generated text detection;benchmark",
        "author": "",
        "aff": "University of Mississippi; The Pennsylvania State University, University Park, PA, USA; MIT Lincoln Laboratory; Kempelen Institute of Intelligent Technologies",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://zenodo.org/records/10013755",
        "github": "https://github.com/kinit-sk/mgt-detection-benchmark"
    },
    {
        "id": "OLcDbSRjbx",
        "title": "DiffuSeq-v2: Bridging Discrete and Continuous Text Spaces for Accelerated Seq2Seq Diffusion Models",
        "track": "main",
        "status": "Short Findings",
        "keywords": "diffusion model;sequence to sequence;text generation",
        "author": "",
        "aff": "The University of Hong Kong; Independent Researcher; Shanghai AI Lab",
        "rating": "",
        "confidence": "3;5;5",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Shark-NLP/DiffuSeq/tree/diffuseq-v2"
    },
    {
        "id": "ORHg3RKho0",
        "title": "Auto-Instruct: Automatic Instruction Generation and Ranking for Black-Box Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large Language Model;Instruction Generation;Instruction Ranking;Multi-Task Learning;In-Context Learning",
        "author": "",
        "aff": "Microsoft Azure AI; University of Notre Dame",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ytyz1307zzh/Auto-Instruct"
    },
    {
        "id": "OUiW2DzpzT",
        "title": "Characterizing Mechanisms for Factual Recall in Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Interpretability;NLP;mechanistic interpretability",
        "author": "",
        "aff": "Brown University, Department of Computer Science",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "OUmxBN45Gl",
        "title": "Do All Languages Cost the Same? Tokenization in the Era of Commercial Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Tokenization;LLMs;under-resourced languages;equitable LLMs",
        "author": "",
        "aff": "Paul G. Allen School of Computer Science & Engineering, University of Washington; Language Technologies Institute, Carnegie Mellon University; Allen Institute for Artificial Intelligence",
        "rating": "",
        "confidence": "3;2;5",
        "correctness": "2;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/orevaahia/lm_tokenizer_cost"
    },
    {
        "id": "OVLnZliSHs",
        "title": "MultiTurnCleanup: A Benchmark for Multi-Turn Spoken Conversational Transcript Cleanup",
        "track": "main",
        "status": "Short Main",
        "keywords": "Multi-Turn Spoken Conversations;Crowdsourcing;Transcript Cleanup;Disfluency Detection",
        "author": "",
        "aff": "University of Michigan; Google Research",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/huashen218/MultiTurnCleanup.git"
    },
    {
        "id": "OVmOQs85Xb",
        "title": "Dynamic Open-book Prompt for Conversational Recommender System",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Conversational Recommender System;Graph Learning;Prompt Learning",
        "author": "",
        "aff": "School of Computer Science, Wuhan University, China; School of Computer Science, Wuhan University, China; Intellectual Computing Laboratory for Cultural Heritage, Wuhan University, China",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "3;2;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/NLPWM-WHU/DOP"
    },
    {
        "id": "OVt2dIwxR1",
        "title": "Re$^3$Dial: Retrieve, Reorganize and Rescale Conversations for Long-Turn Open-Domain Dialogue Pre-training",
        "track": "main",
        "status": "Long Main",
        "keywords": "Dialogue;Large-scale Pre-training;Pre-training data;Multi-turn Dialogue",
        "author": "",
        "aff": "The CoAI group, Tsinghua University, Beijing, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China; Pattern Recognition Center, WeChat AI, Tencent Inc., China",
        "rating": "",
        "confidence": "3;4;5;3;3",
        "correctness": "3;4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6,
        "correctness_avg": 3.8,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/thu-coai/Re3Dial"
    },
    {
        "id": "OXQFcwKrTM",
        "title": "Salespeople vs SalesBot: Exploring the Role of Educational Value in Conversational Recommender Systems",
        "track": "main",
        "status": "Long Findings",
        "keywords": "conversational recommender systems;mixed-initiative conversational agents;mixed-type conversational dataset",
        "author": "",
        "aff": "Salesforce AI Research",
        "rating": "",
        "confidence": "5;4;3",
        "correctness": "5;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/salesforce/salesbot"
    },
    {
        "id": "OYWeQdQiIn",
        "title": "Identifying Conspiracy Theories News based on Event Relation Graph",
        "track": "main",
        "status": "Long Findings",
        "keywords": "conspiracy theory;misinformation;event relation graph",
        "author": "",
        "aff": "Department of Computer Science and Engineering, Texas A&M University, College Station, TX",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/yuanyuanlei-nlp/conspiracy_theories_emnlp_2023"
    },
    {
        "id": "OZOrQQBDou",
        "title": "TCRA-LLM: Token Compression Retrieval Augmented Large Language Model for Inference Cost Reduction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large language model;Retrieval augmented;Knowledge compression;Question Answering",
        "author": "",
        "aff": "Agency for Science, Technology and Research (A*STAR); Osaka University; Meetyou AI Lab, Xiamen Key Laboratory of Women\u2019s Internet Health Management",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "OcaifDZKkA",
        "title": "Active Learning for Natural Language Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "active learning;NLG;generation",
        "author": "",
        "aff": "IBM Research AI",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Of2xc2GVid",
        "title": "On the Calibration of Large Language Models and Alignment",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large Language Models;Calibration",
        "author": "",
        "aff": "MOE Key Laboratory of Trustworthy Distributed Computing and Service, Beijing University of Posts and Telecommunications, Beijing, China; University of Science and Technology of China, Hefei, China",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "2;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "OfBAABKH5X",
        "title": "Beyond Denouncing Hate: Strategies for Countering Implied Biases and Stereotypes in Language",
        "track": "main",
        "status": "Long Findings",
        "keywords": "counterspeech;stereotypes",
        "author": "",
        "aff": "Princeton University; Columbia University; University of Washington; Carnegie Mellon University; Allen Institute for AI",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "OgK0kMz5Va",
        "title": "Prompting Scientific Names for Zero-Shot Species Recognition",
        "track": "main",
        "status": "Short Main",
        "keywords": "vision-language model;fine-grained recognition;zero-shot recognition;prompt engineering;species recognition",
        "author": "",
        "aff": "Texas A&M University; Carnegie Mellon University; Zhejiang Lab; Institute of Collaborative Innovation, University of Macau",
        "rating": "",
        "confidence": "4;5;5",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "OhZLO1yunf",
        "title": "NEWTON: Are Large Language Models Capable of Physical Reasoning?",
        "track": "main",
        "status": "Long Findings",
        "keywords": "physical reasoning;robotics;object-centric;evaluation;benchmark;reasoning",
        "author": "",
        "aff": "NVIDIA; University of Washington",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;2;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://newtonreasoning.github.io",
        "github": "https://github.com/newtonreasoning"
    },
    {
        "id": "OkQD6RMUK5",
        "title": "Label Words are Anchors: An Information Flow Perspective for Understanding In-Context Learning",
        "track": "main",
        "status": "Long Main",
        "keywords": "in-context learning;label words;anchors;large language models",
        "author": "",
        "aff": "National Key Laboratory for Multimedia Information Processing, School of Computer Science, Peking University; Pattern Recognition Center, WeChat AI, Tencent Inc., China",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "5;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.666666666666667,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/lancopku/label-words-are-anchors"
    },
    {
        "id": "Ov6OZ2TFKI",
        "title": "A Video Is Worth 4096 Tokens: Verbalize Story Videos To Understand Them In Zero Shot",
        "track": "main",
        "status": "Long Main",
        "keywords": "video understanding;large language models;persuasion strategies;zero-shot;long video understanding",
        "author": "",
        "aff": "IIIT-Delhi; State University of New York at Buffalo; Adobe Media and Data Science Research (MDSR)",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "OwWIl6gb1z",
        "title": "CRoW: Benchmarking Commonsense Reasoning in Real-World Tasks",
        "track": "main",
        "status": "Long Main",
        "keywords": "commonsense reasoning;benchmark;real-world task",
        "author": "",
        "aff": "Google DeepMind; EPFL, Switzerland",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/mismayil/crow"
    },
    {
        "id": "OwxjgsX68V",
        "title": "CASSI: Contextual and Semantic Structure-based Interpolation Augmentation for Low-Resource NER",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Named Entity Recognition;Text Augmentation;Low-Resource;Structure-Based Augmentation;Language Model;Context Diversity",
        "author": "",
        "aff": "Nanyang Technological University, Singapore",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/tanmaysurana/CASSI"
    },
    {
        "id": "Ox0OoyLass",
        "title": "How Well Do Text Embedding Models Understand Syntax?",
        "track": "main",
        "status": "Long Findings",
        "keywords": "sentence embedding;compositional understanding",
        "author": "",
        "aff": "Angelalign Inc., China; National University of Singapore; The Chinese University of Hong Kong, Shenzhen, China; Nanyang Technological University; Zhejiang University",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "OxoP1qFotz",
        "title": "Quality > Quantity: Synthetic Corpora from Foundation Models for Closed-Domain Extractive Question Answering",
        "track": "main",
        "status": "Reject",
        "keywords": "Closed Domain Question Answering;Prompt Engineering;Foundational Models;Domain Adaptation",
        "author": "",
        "aff": "EMNLP submission",
        "rating": "",
        "confidence": "3;3;4;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "P04rLpllH7",
        "title": "A Black-Box Attack on Code Models via Representation Nearest Neighbor Search",
        "track": "main",
        "status": "Long Findings",
        "keywords": "black box attacks;code models;robustness;code adversarial example",
        "author": "",
        "aff": "The Interdisciplinary Centre for Security, Reliability and Trust, University of Luxembourg; Noah\u2019s Ark Lab, Huawei; School of Computing and Information Systems, Singapore Management University; School of Computer Science and Engineering, Nanyang Technological University",
        "rating": "",
        "confidence": "2;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "P2jDML1Ub6",
        "title": "Are Personalized Stochastic Parrots More Dangerous? Evaluating Persona Biases in Dialogue Systems",
        "track": "main",
        "status": "Long Findings",
        "keywords": "dialogue model persona;fairness;evaluation",
        "author": "",
        "aff": "Computer Science Department, University of California, Los Angeles; Stanford University, Amazon AI",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "P5hYS77k10",
        "title": "Quantifying the redundancy between prosody and text",
        "track": "main",
        "status": "Long Main",
        "keywords": "Prosody;Psycholinguistics;Language Models;Information Theory",
        "author": "",
        "aff": "ETH Z\u00fcrich; University of Cambridge; MIT",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "5;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.666666666666667,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/lu-wo/quantifying-redundancy"
    },
    {
        "id": "P9V2jcotAF",
        "title": "Beyond Shared Vocabulary: Increasing Representational Word Similarities across Languages for Multilingual Machine Translation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Multilingual Machine Translation;Shared Vocabulary",
        "author": "",
        "aff": "Language Technology Lab, University of Amsterdam",
        "rating": "",
        "confidence": "4;4;3;4",
        "correctness": "4;3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/moore3930/BeyondSharedVocabulary"
    },
    {
        "id": "PAByut8fMZ",
        "title": "A Quality-based Syntactic Template Retriever for Syntactically-Controlled Paraphrase Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Paraphrase generation;Syntactic template retrievers;Mutual diversity",
        "author": "",
        "aff": "Beijing Key Lab of Traffic Data Analysis and Mining, Beijing Jiaotong University, Beijing, China",
        "rating": "",
        "confidence": "5;4;5",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "PBvSGqYCSa",
        "title": "Bridging Background Knowledge Gaps in Translation with Automatic Explicitation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Explicitation;translation;cross\u2011cultural NLP;pragmatic explicitation;multi-cultural NLP;explanatory translation",
        "author": "",
        "aff": "Computer Science, University of Maryland; CS, UMIACS, iSchool, LCS, University of Maryland; Computer Science, UMIACS, University of Maryland",
        "rating": "",
        "confidence": "3;2;3;3;3",
        "correctness": "4;4;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.8,
        "correctness_avg": 3.8,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/h-j-han/automatic_explicitation"
    },
    {
        "id": "PBwotNgvp3",
        "title": "Zero-shot Topical Text Classification with LLMs - an Experimental Study",
        "track": "main",
        "status": "Long Findings",
        "keywords": "topic classification;zero-shot classification;text classification;LLMs",
        "author": "",
        "aff": "IBM Research",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/IBM/zero-shot-topical-text-classification"
    },
    {
        "id": "PCNsizlhRU",
        "title": "Towards Conceptualization of ``Fair Explanation'': Disparate Impacts of anti-Asian Hate Speech Explanations on Content Moderators",
        "track": "main",
        "status": "Long Main",
        "keywords": "fairness;explainability;human study;hate speech prediction;content moderators;crowdworkers",
        "author": "",
        "aff": "Department of Computer Science, University of Maryland; Robert H. Smith School of Business, University of Maryland",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "2;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/jiannan-xu/EMNLP23_Fair_Explanation"
    },
    {
        "id": "PCyB5LUF4z",
        "title": "Learning to Follow Object-Centric Image Editing Instructions Faithfully",
        "track": "main",
        "status": "Long Findings",
        "keywords": "natural language instruction;image editing;stable diffusion;diffusion model;text-to-image;multimodal",
        "author": "",
        "aff": "Department of Computer Science, Columbia University; Department of Computer Science, Columbia University; Data Science Institute, Columbia University",
        "rating": "",
        "confidence": "4;3;5;4",
        "correctness": "4;4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "PHh1s8dNlY",
        "title": "DIVE: Towards Descriptive and Diverse Visual Commonsense Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Visual commonsense generation;descriptive and diverse text generation;commonsense inference;vision-language model",
        "author": "",
        "aff": "Department of Artificial Intelligence, Korea University, Seoul, Republic of Korea; BK21 FOUR R&E Center for Artificial Intelligence, Korea University, Seoul, Republic of Korea; Department of Computer Science and Engineering, Korea University, Seoul, Republic of Korea",
        "rating": "",
        "confidence": "4;2;3;4;3",
        "correctness": "4;3;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.2,
        "correctness_avg": 3.8,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Park-ing-lot/DIVE"
    },
    {
        "id": "PHtXqUNGUA",
        "title": "SummEdits: Measuring LLM Ability at Factual Reasoning Through The Lens of Summarization",
        "track": "main",
        "status": "Long Main",
        "keywords": "factual consistency;faithfulness;summarization;LLMs;benchmark",
        "author": "",
        "aff": "Salesforce AI",
        "rating": "",
        "confidence": "3;2;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "PNpRxOhVut",
        "title": "A Spectral Viewpoint on Continual Relation Extraction",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Relation Extraction;Information Extraction;Continual Learning;Spectral Analysis",
        "author": "",
        "aff": "VinAI Research, Vietnam; Department of Computer Science, University of Oregon, Eugene, OR, USA; Nanyang Technological University, Singapore; Hanoi University of Science and Technology, Hanoi, Vietnam",
        "rating": "",
        "confidence": "4;3;2",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "PPwRa7Wmg1",
        "title": "VIP5: Towards Multimodal Foundation Models for Recommendation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multimodal Foundation Model;Recommender Systems;Large Language Model;Parameter-efficient Tuning;Personalized Prompt",
        "author": "",
        "aff": "Department of Computer Science, Rutgers University, NJ 08854, US",
        "rating": "",
        "confidence": "4;4;3;4",
        "correctness": "3;2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/jeykigung/VIP5"
    },
    {
        "id": "PSlrVYPTAX",
        "title": "Conversational Recommender System and Large Language Model Are Made for Each Other in E-commerce Pre-sales Dialogue",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Conversational recommendation;large language model;collaboration method",
        "author": "",
        "aff": "Independent, China; Research Center for Social Computing and Information Retrieval, Harbin Institute of Technology, China",
        "rating": "",
        "confidence": "4;3;3;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "PT63nNpyKg",
        "title": "Large Language Models are biased to overestimate profoundness",
        "track": "main",
        "status": "Short Main",
        "keywords": "Large language models;reasoning;bias;nonsensical statements",
        "author": "",
        "aff": "Brown University, United States; Centro Nacional de Inteligencia Artificial (CENIA), Chile; Leiden University, the Netherlands; Pontificia Universidad Cat\u00f3lica de Chile, Chile",
        "rating": "",
        "confidence": "4;2;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "PT6lSdWEgw",
        "title": "Toxicity in Multilingual Machine Translation at Scale",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Toxicity;Multilingual Machine Translation;Scale",
        "author": "",
        "aff": "FAIR, Meta; Universitat Polit\u00e8cnica de Catalunya",
        "rating": "",
        "confidence": "4;4;2",
        "correctness": "3;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "PTko0qsiA4",
        "title": "Large Language Models as Source Planner for Personalized Knowledge-grounded Dialogues",
        "track": "main",
        "status": "Long Findings",
        "keywords": "knowledge-grounded dialogue system;personalized dialogue system;large lanuage models",
        "author": "",
        "aff": "Department of Computer Science and Engineering, The Chinese University of Hong Kong; Huawei Noah\u2019s Ark Lab; National University of Singapore; Department of Systems Engineering and Engineering Management, The Chinese University of Hong Kong",
        "rating": "",
        "confidence": "4;3;3;4",
        "correctness": "4;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "PWWg9q3S0C",
        "title": "From Multilingual Complexity to Emotional Clarity: Leveraging Commonsense to Unveil Emotions in Code-Mixed Dialogues",
        "track": "main",
        "status": "Long Main",
        "keywords": "Emotion Recognition in Conversation;Code-mix dialogues;Commonsense",
        "author": "",
        "aff": "NVIDIA, India; IIIT Delhi, India; IIT Delhi, India",
        "rating": "",
        "confidence": "4;2;5",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "PXkS70nuNp",
        "title": "CRaSh: Clustering, Removing, and Sharing Enhance Fine-tuning without Full Large Language Model",
        "track": "main",
        "status": "Long Main",
        "keywords": "large language models;transfer learning;representation similarity;model privacy",
        "author": "",
        "aff": "Department of Electronic Engineering, Tsinghua University, Beijing, China; Frontis.AI, Beijing, China; Department of Electronic Engineering, Tsinghua University, Beijing, China; Department of Electronic Engineering, Tsinghua University, Beijing, China; Frontis.AI, Beijing, China; School of Astronautics, Harbin Institute of Technology, Harbin, China",
        "rating": "",
        "confidence": "4;2;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/TsinghuaC3I/CRaSh"
    },
    {
        "id": "PaVP2Sc6pJ",
        "title": "A Novel Contrastive Learning Method for Clickbait Detection on RoCliCo: A Romanian Clickbait Corpus of News Articles",
        "track": "main",
        "status": "Short Findings",
        "keywords": "clickbait detection;low-resource language;Romanian corpus;contrastive learning",
        "author": "",
        "aff": "Department of Computer Science, University of Bucharest, Romania",
        "rating": "",
        "confidence": "4;5;4;4",
        "correctness": "2;3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/dariabroscoteanu/RoCliCo"
    },
    {
        "id": "Pb1DhkTVLZ",
        "title": "Estimating Large Language Model Capabilities without Labeled Test Data",
        "track": "main",
        "status": "Long Findings",
        "keywords": "large language model;accuracy prediction;confidence;calibration;in-context learning",
        "author": "",
        "aff": "University of Southern California, Los Angeles, CA, USA",
        "rating": "",
        "confidence": "2;4;4;4",
        "correctness": "3;3;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "github.com/harvey-fin/icl-estimate"
    },
    {
        "id": "PffUQuD8sn",
        "title": "Statistical Depth for Ranking and Characterizing Transformer-Based Text Embeddings",
        "track": "main",
        "status": "Long Main",
        "keywords": "text embeddings;transformers;statistical inference;corpus analysis;statistical depth;in-context learning;synthetic data augmentation",
        "author": "",
        "aff": "Department of Computer Science, Dartmouth College, Hanover, NH, USA",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "PnAmH1silV",
        "title": "On Bilingual Lexicon Induction with Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Bilingual Lexicon Induction;Large Language Models",
        "author": "",
        "aff": "Language Technology Lab, TAL, University of Cambridge",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "PoMCId4iez",
        "title": "From Dissonance to Insights: Dissecting Disagreements in Rationale Construction for Case Outcome Classification",
        "track": "main",
        "status": "Long Main",
        "keywords": "legal judgement prediction;case outcome classification;disagreement;explainability;rationale dataset",
        "author": "",
        "aff": "Graduate Institute of International and Development Studies, Switzerland; Technical University of Munich, Germany; IT University of Copenhagen, Denmark; Faculty of Law, Ruhr University Bochum, Germany",
        "rating": "",
        "confidence": "2;3;5",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/TUMLegalTech/RaVE_emnlp23"
    },
    {
        "id": "PomhVDrvco",
        "title": "EpiK-Eval: Evaluation for Language Models as Epistemic Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "large language models;large language model;LLMs;LLM;language model;language models;LM;LMs;EpiK-Eval;knowledge consolidation;story;benchmark;knowledge-base;KB;theory-of-mind;epistemic;hallucination;hallucinate;dataset;task;scale;scaling;knowledge representation;reasoning;consolidation;knowledge;context;evaluation;limitations;limitation;narrative;narratives;training objective;causal language modeling;masked language modeling",
        "author": "",
        "aff": "Mila, Universit\u00e9 de Montr\u00e9al; Meta AI; Polytechnique Montr\u00e9al, CIFAR AI Chair",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/chandar-lab/EpiK-Eval"
    },
    {
        "id": "Pu5tJykUeT",
        "title": "ART: rule bAsed futuRe-inference deducTion",
        "track": "main",
        "status": "Long Main",
        "keywords": "cross-modal;deductive reasoning;deep learning",
        "author": "",
        "aff": "Zhejiang University; Shanghai Institute for Advanced Study of Zhejiang University, Shanghai AI Laboratory",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Pw9vYSPJKk",
        "title": "DiffusionRet: Diffusion-Enhanced Generative Retriever using Constrained Decoding",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Infromation Retrieval;Diffusion Model;Generative Retrieval;Model-based Retrieval",
        "author": "",
        "aff": "Center for Advanced Image and Information Technology, Department of Computer Science and Artificial Intelligence, Jeonbuk National University",
        "rating": "",
        "confidence": "3;4;5",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Miracle0814/DiffusionRet"
    },
    {
        "id": "PxEhoPiBB0",
        "title": "Is GPT-4 a Good Data Analyst?",
        "track": "main",
        "status": "Long Findings",
        "keywords": "data analyst;GPT4",
        "author": "",
        "aff": "DAMO Academy, Alibaba Group, Singapore; Hupan Lab, 310023, Hangzhou, China; DAMO Academy, Alibaba Group, Singapore; Nanyang Technological University, Singapore",
        "rating": "",
        "confidence": "4;4;4;3",
        "correctness": "3;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/DAMO-NLP-SG/GPT4-as-DataAnalyst"
    },
    {
        "id": "PyAzL6Z802",
        "title": "Multilingual estimation of political-party positioning: From label aggregation to long-input Transformers",
        "track": "main",
        "status": "Long Main",
        "keywords": "computational social science;scaling analysis;political science;political party positioning",
        "author": "",
        "aff": "Institute for Natural Language Processing, University of Stuttgart",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "PyJ78pUMEE",
        "title": "Just Adjust One Prompt: Enhancing In-Context Dialogue Scoring via Constructing the Optimal Subgraph of Demonstrations and Prompts",
        "track": "main",
        "status": "Long Main",
        "keywords": "dialogue evaluation;in-context learning;large language models;prompt generation",
        "author": "",
        "aff": "The Hong Kong Polytechnic University, Kowloon, Hong Kong, China; Fuxi AI Lab, NetEase Inc., Hangzhou, China; Fuxi AI Lab, NetEase Inc., Hangzhou, China; Zhejiang University, Hangzhou, China; Singapore Management University, Singapore",
        "rating": "",
        "confidence": "3;4;4;3",
        "correctness": "4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/EMNLP2023-ADOROR"
    },
    {
        "id": "PzINxIyV9o",
        "title": "InterFair: Debiasing with Natural Language Feedback for Fair Interpretable Predictions",
        "track": "main",
        "status": "Short Main",
        "keywords": "Debiasing;Language Models;Rationale;Interactions;User Interventions",
        "author": "",
        "aff": "University of San Diego; Allen Institute for AI",
        "rating": "",
        "confidence": "2;4;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Q2IInBu2kz",
        "title": "PCMID: Multi-Intent Detection through Supervised Prototypical Contrastive Learning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Dialogue System;Multi-Intent Detection",
        "author": "",
        "aff": "UC Irvine; Aktify. Inc",
        "rating": "",
        "confidence": "5;5;4;4",
        "correctness": "4;2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Q2Wu2Cfp2x",
        "title": "Practical Computational Power of Linear Transformers and Their Recurrent and Self-Referential Extensions",
        "track": "main",
        "status": "Short Main",
        "keywords": "recurrent neural networks;RNNs;transformers;computational power;automata;counter machines;formal languages;linear transformers;self-reference;self-referential weight matrix",
        "author": "",
        "aff": "Harvard University; The Swiss AI Lab IDSIA, USI & SUPSI; AI Initiative, KAUST",
        "rating": "",
        "confidence": "2;1;2;1;2",
        "correctness": "4;2;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 1.6,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/IDSIA/fwp-formal-lang"
    },
    {
        "id": "Q4u18Ui7YS",
        "title": "Explore-Instruct: Enhancing Domain-Specific Instruction Coverage through Active Exploration",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Models;Instruction-Tuning",
        "author": "",
        "aff": "School of Computer Science and Engineering, Sun Yat-sen University, China; Tencent AI Lab",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/fanqiwan/Explore-Instruct"
    },
    {
        "id": "Q5nM3rpiVm",
        "title": "Towards Better Representations for Multi-Label Text Classification with Multi-granularity Information",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multi-label text classification;Text representation;Contrastive learning;Multi-granularity information",
        "author": "",
        "aff": "School of Computer Science and Engineering, Central South University; Science and Technology on Information Systems Engineering Laboratory, National University of Defense Technology",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Q93hLxLKLB",
        "title": "We Need to Talk About Reproducibility in NLP Model Comparison",
        "track": "main",
        "status": "Long Main",
        "keywords": "reproducibility;NLP model comparison;corpus splitting strategy",
        "author": "",
        "aff": "School of Mathematical Sciences, Shanxi University, Taiyuan, 030006; School of Modern Education Technology, Shanxi University, Taiyuan, 030006; School of Computer and Information Technology, Shanxi University, Taiyuan, 030006; School of Automation and Software Engineering, Shanxi University, Taiyuan, 030006",
        "rating": "",
        "confidence": "2;3;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Q9BLbN1p6h",
        "title": "Mixture-of-Linguistic-Experts Adapters for Improving and Interpreting Pre-trained Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "adapters;graph neural networks;parameter-efficient fine-tuning;interpretability;dependency trees",
        "author": "",
        "aff": "University of Fraser Valley, Abbotsford, BC, Canada; University of British Columbia, Vancouver, BC, Canada",
        "rating": "",
        "confidence": "4;5;3",
        "correctness": "2;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "QA1jlb1VG7",
        "title": "CITB: A Benchmark for Continual Instruction Tuning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Instruction tuning;continual learning;benchmark;evaluation",
        "author": "",
        "aff": "University of Wollongong; University of Liverpool; University of Technology Sydney",
        "rating": "",
        "confidence": "3;5;3;4",
        "correctness": "3;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/hyintell/CITB"
    },
    {
        "id": "QAT5suGpNL",
        "title": "Breaking the Language Barrier: Improving Cross-Lingual Reasoning with Structured Self-Attention",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Cross-lingual;Multilingual;Reasoning",
        "author": "",
        "aff": "EPFL",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/negar-foroutan/multilingual-code-switched-reasoning"
    },
    {
        "id": "QAZ2QV8SqN",
        "title": "KG-GPT: A General Framework for Reasoning on Knowledge Graphs Using Large Language Models",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Large Language Model;Knowledge Graph;Reasoning;Question Answering;Fact Verification",
        "author": "",
        "aff": "KAIST; Seoul National University",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/jiho283/KG-GPT"
    },
    {
        "id": "QEf1MyZGZu",
        "title": "Target-Aware Spatio-Temporal Reasoning via Answering Questions in Dynamic Audio-Visual Scenarios",
        "track": "main",
        "status": "Long Findings",
        "keywords": "audio-visual question answering;spatio-temporal reasoning;multimodal learning;video question answering",
        "author": "",
        "aff": "School of Artificial Intelligence, Beijing University of Posts and Telecommunications",
        "rating": "",
        "confidence": "4;3;4;3",
        "correctness": "3;3;1;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Bravo5542/TJSTG"
    },
    {
        "id": "QG4BWnsX6m",
        "title": "Multilingual Lottery Tickets to Pretrain Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "lottery ticket hypothesis;negative interference;zero-shot neural architecture search;multilingual pretrained language model",
        "author": "",
        "aff": "Computer Science and Engineering, Seoul National University",
        "rating": "",
        "confidence": "4;1;2",
        "correctness": "3;5;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "Available"
    },
    {
        "id": "QH19wfJrX1",
        "title": "mLongT5: A Multilingual and Efficient Text-To-Text Transformer for Longer Sequences",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Multilinguality;Efficient model;Long inputs",
        "author": "",
        "aff": "Google Research",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/google/flaxformer/tree/main/flaxformer/t5x/configs/longt5/models"
    },
    {
        "id": "QH4EMvwF8I",
        "title": "Query2doc: Query Expansion with Large Language Models",
        "track": "main",
        "status": "Short Main",
        "keywords": "query expansion;large language models;information retrieval",
        "author": "",
        "aff": "Microsoft Research",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "QMCjppVJbB",
        "title": "SEAHORSE: A Multilingual, Multifaceted Dataset for Summarization Evaluation",
        "track": "main",
        "status": "Long Main",
        "keywords": "summarization;evaluation;multilingual;human evaluation;automatic metrics;NLG",
        "author": "",
        "aff": "Google DeepMind; Google Research",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "5;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://goo.gle/seahorse",
        "github": ""
    },
    {
        "id": "QPP8wNMBBk",
        "title": "Unsupervised Lexical Simplification with Context Augmentation",
        "track": "main",
        "status": "Short Findings",
        "keywords": "lexical simplification;lexical substitution;lexical semantics;unsupervised",
        "author": "",
        "aff": "School of Computing and Information Systems, The University of Melbourne; School of Computing and Information Systems, The University of Melbourne; Department of Natural Language Processing, MBZUAI",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/twadada/lexsub_decontextualised"
    },
    {
        "id": "QV79qiKAjD",
        "title": "On the Benefits of Learning to Route in Mixture-of-Experts Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "mixture-of-experts;transformer;router;efficiency;conditional compute;sparsely activated models;theory",
        "author": "",
        "aff": "Harvard University\u2217; UC Berkeley\u2217; UCLA\u2217; Google Research",
        "rating": "",
        "confidence": "3;3;2",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "QVnlBmGrWS",
        "title": "ORCHID: A Chinese Debate Corpus for Target-Independent Stance Detection and Argumentative Dialogue Summarization",
        "track": "main",
        "status": "Long Main",
        "keywords": "dialogue dataset;long dialogue summarization;target-independent stance detection",
        "author": "",
        "aff": "Huawei IT Innovation and Research Center",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/xiutian/OrChiD"
    },
    {
        "id": "QVuVwt1QLh",
        "title": "Unifying Text, Tables, and Images for Multimodal Question Answering",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multimodal Question Answering;Modality Unification;Image Caption",
        "author": "",
        "aff": "School of Intelligent Systems Engineering, Sun Yat-sen University; National University of Singapore",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "QYSPlIZ6bV",
        "title": "TalkUp: Paving the Way for Understanding Empowering Language",
        "track": "main",
        "status": "Long Findings",
        "keywords": "natural language processing;empowerment",
        "author": "",
        "aff": "University of Washington; Carnegie Mellon University",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/chan0park/TalkUp"
    },
    {
        "id": "QYvFUlF19n",
        "title": "In-Context Learning Creates Task Vectors",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Large Language Models;In-Context Learning;Interpretability",
        "author": "",
        "aff": "Tel Aviv University; Tel Aviv University, Google; Google DeepMind",
        "rating": "",
        "confidence": "5;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/roeehendel/icl_task_vectors"
    },
    {
        "id": "QdhjuI19nv",
        "title": "Compositional Generalization for Data-to-Text Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Compositional Generalization;Data-to-Text Generation;Natural Language Generation;Clustering;Reinforcement Learning;Benchmark",
        "author": "",
        "aff": "ILCC, School of Informatics, University of Edinburgh and ILLC, University of Amsterdam; ILCC, School of Informatics, University of Edinburgh",
        "rating": "",
        "confidence": "2;4;2;4",
        "correctness": "4;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "github.com/XinnuoXu/CG_DTG"
    },
    {
        "id": "QkCYv3TlGk",
        "title": "Non-parallel Accent Transfer based on Fine-grained Controllable Accent Modelling",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Accent Transfer\uff0cFine-grained Controllable Accent Modelling\uff0cNon-parallel",
        "author": "",
        "aff": "Faculty of Information Engineering and Automation, Kunming University of Science and Technology, Kunming, China",
        "rating": "",
        "confidence": "5;2;3",
        "correctness": "3;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "QlY0TSxVIl",
        "title": "Revisiting Automated Topic Model Evaluation with Large Language Models",
        "track": "main",
        "status": "Short Main",
        "keywords": "topic model evaluation;interpretability;large language models;text clustering",
        "author": "",
        "aff": "ETH Z\u00fcrich; University of Maryland",
        "rating": "",
        "confidence": "4;2;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/dominiksinsaarland/evaluating-topic-model-output"
    },
    {
        "id": "QnXfnQ3MFe",
        "title": "Dynamic Low-rank Estimation for Transformer-based Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "low-rank estimation; matrix factorization;",
        "author": "",
        "aff": "University of Michigan, Ann Arbor; Samsung Research America",
        "rating": "",
        "confidence": "3;2;3;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "QoiOmXy3A7",
        "title": "Describe Me an Auklet: Generating Grounded Perceptual Category Descriptions",
        "track": "main",
        "status": "Long Main",
        "keywords": "language-and-vision;grounding;zero-shot;cognitive theories of categorisation;natural language generation;natural language interpretation",
        "author": "",
        "aff": "Centre for Linguistic Theory and Studies in Probability (CLASP), Department of Philosophy, Linguistics, and Theory of Science (FLoV), University of Gothenburg, Sweden",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "2;2;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "QtOybganmT",
        "title": "Enhancing Retrieval-Augmented Large Language Models with Iterative Retrieval-Generation Synergy",
        "track": "main",
        "status": "Long Findings",
        "keywords": "retrieval-augmented language model;prompting;retrieval",
        "author": "",
        "aff": "Microsoft Research Asia; Microsoft Azure AI; The CoAI Group, DCST, Institute for Artificial Intelligence, State Key Lab of Intelligent Technology and Systems, Beijing National Research Center for Information Science and Technology, Tsinghua University, Beijing 100084, China",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "QtyJZe9Sfz",
        "title": "When and Why Does Bias Mitigation Work?",
        "track": "main",
        "status": "Long Findings",
        "keywords": "debiasing;lexical biases;natural language understanding",
        "author": "",
        "aff": "Allen Institute for Artificial Intelligence; Imperial College London",
        "rating": "",
        "confidence": "4;3;1",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Qu0OZXL29t",
        "title": "Centering the Margins: Outlier-Based Identification of Harmed Populations in Toxicity Detection",
        "track": "main",
        "status": "Long Main",
        "keywords": "AI fairness;AI ethics;toxicity detection;hate speech detection;outlier analysis;marginalization;harm measurement",
        "author": "",
        "aff": "UC Berkeley",
        "rating": "",
        "confidence": "3;5;4",
        "correctness": "4;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Qv2CTIcCPJ",
        "title": "The language of prompting: What linguistic properties make a prompt successful?",
        "track": "main",
        "status": "Long Findings",
        "keywords": "prompting;evaluation;LLMs;zero-shot;robustness;instability;instruction-tuning",
        "author": "anonymous",
        "aff": "Institute for Logic, Language and Computation, University of Amsterdam",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/aleidinger/language_of_prompting"
    },
    {
        "id": "QwejPcX96r",
        "title": "Large language models effectively leverage document-level context for literary translation, but critical errors persist",
        "track": "main",
        "status": "Reject",
        "keywords": "machine translation;paragraph-level translation;literary translation;large language models",
        "author": "",
        "aff": "University of Massachusetts Amherst",
        "rating": "",
        "confidence": "2;4;3",
        "correctness": "3;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 1.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://litmt.org/",
        "github": "https://github.com/marzenakrp/LiteraryTranslation"
    },
    {
        "id": "Qyw4k4ohgr",
        "title": "Epsilon Sampling Rocks: Investigating Sampling Strategies for Minimum Bayes Risk Decoding for Machine Translation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "machine translation;mbr decoding;decoding strategies;bleurt;automatic evaluation",
        "author": "",
        "aff": "Carnegie Mellon University, Instituto Superior T\u00e9cnico; OpenAI; Google Research",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "R0XABYPVKI",
        "title": "Knowledge Corpus Error in Question Answering",
        "track": "main",
        "status": "Short Findings",
        "keywords": "large language models;open-domain question answering;retrieval;qa;odqa",
        "author": "",
        "aff": "KAIST AI; Seoul National University",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "2;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/... (the actual link is not provided in the text)"
    },
    {
        "id": "R2PwXB08i4",
        "title": "WordNet Is All You Need: A Surprisingly Effective Unsupervised Method for Graded Lexical Entailment",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Graded Lexical Entailment;WordNet",
        "author": "",
        "aff": "Univ. Lille, Inria, CNRS, Centrale Lille, UMR 9189 - CRIStAL, F-59000, Lille, France",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/cambridgeltl/hyperlex"
    },
    {
        "id": "R4N3RNBNzJ",
        "title": "STINMatch: Semi-Supervised Semantic-Topological Iteration Network for Financial Risk Detection via News Label Diffusion",
        "track": "main",
        "status": "Long Main",
        "keywords": "semi-supervised;text-graph joint learning;risk detection",
        "author": "",
        "aff": "Zhejiang University, China; Alibaba Group, China; Worcester Polytechnic Institute, USA; Northeastern University, China; Purdue University, USA; Indiana University Bloomington, USA",
        "rating": "",
        "confidence": "3;3;4;3",
        "correctness": "3;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/curryli/Semi-Supervised-Financial-Risk-Detection.git"
    },
    {
        "id": "R4VfYDluYi",
        "title": "Learning Co-Speech Gesture for Multimodal Aphasia Type Detection",
        "track": "main",
        "status": "Long Main",
        "keywords": "Aphasia;NLP;Applications;Speech;Multimodality",
        "author": "",
        "aff": "Department of Computer Science & Engineering, University of South Florida, Tampa, FL, USA; Department of Applied Artificial Intelligence, Sungkyunkwan University, Seoul, South Korea; Department of Human-AI Interaction, Sungkyunkwan University, Seoul, South Korea",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/DSAIL-SKKU/Multimodal-Aphasia-Type-Detection_EMNLP_2023"
    },
    {
        "id": "R4yb4m7Nus",
        "title": "Model-tuning Via Prompts Makes NLP Models Adversarially Robust",
        "track": "main",
        "status": "Long Main",
        "keywords": "Natural Language Processing;Language Models;BERT;RoBERTa;Prompting;Adversarial Robustness",
        "author": "",
        "aff": "Indian Institute of Science (IISc); Carnegie Mellon University",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/acmi-lab/mvp"
    },
    {
        "id": "R5NzXYY7S2",
        "title": "Modeling Legal Reasoning: LM Annotation at the Edge of Human Agreement",
        "track": "main",
        "status": "Long Main",
        "keywords": "language modeling;annotation;legal reasoning;United States Supreme Court",
        "author": "",
        "aff": "Cornell Law School; Cornell University",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "R635gF7lXD",
        "title": "StructGPT: A General Framework for Large Language Model to Reason over Structured Data",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Model;Structured Data",
        "author": "",
        "aff": "School of Information, Renmin University of China; Gaoling School of Artificial Intelligence, Renmin University of China; University of Electronic Science and Technology of China; Gaoling School of Artificial Intelligence, School of Information, Renmin University of China",
        "rating": "",
        "confidence": "3;5;3",
        "correctness": "3;5;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/RUCAIBox/StructGPT"
    },
    {
        "id": "R7Op9CHdPz",
        "title": "Causal Reasoning through Two Cognition Layers for Improving Generalization in Visual Question Answering",
        "track": "main",
        "status": "Long Main",
        "keywords": "visual question answering;generalization;casual reasoning;human cognition",
        "author": "",
        "aff": "Tokyo Institute of Technology",
        "rating": "",
        "confidence": "2;3;4;3",
        "correctness": "4;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "R7f5euZ9RA",
        "title": "Ranking LLM-Generated Loop Invariants for Program Verification",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Large Language Model;Loop Invariant Synthesis;Re-ranking",
        "author": "",
        "aff": "Microsoft Research",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "RAtrnAtAsM",
        "title": "LEGO: A Multi-agent Collaborative Framework with Role-playing and Iterative Feedback for Causality Explanation Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Causality explanation generation; Commonsense reasoning; Large language model",
        "author": "",
        "aff": "Ant Group, Hangzhou, China; The Laboratory of Cognition and Decision Intelligence for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "RE4oyAdAvM",
        "title": "Domain Adaptation for Conversational Query Production with the RAG Model Feedback",
        "track": "main",
        "status": "Long Findings",
        "keywords": "conversational query production;knowledge-aided dialogue system;text generation",
        "author": "",
        "aff": "School of Informatics, Xiamen University, China; Key Laboratory of Digital Protection and Intelligent Processing of Intangible Cultural Heritage of Fujian and Taiwan (Xiamen University), Ministry of Culture and Tourism, China; College of Computer and Control Engineering, Minjiang University, China; Tencent AI Lab, Bellevue, WA",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/DeepLearnXMU/DAMF"
    },
    {
        "id": "RGmQOhSGp0",
        "title": "Beneath the Surface: Unveiling Harmful Memes with Multimodal Reasoning Distilled from Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Harmful meme detection;multimodal reasoning;knowledge distillation;large language models",
        "author": "",
        "aff": "Hong Kong Baptist University; The Hong Kong University of Science and Technology",
        "rating": "",
        "confidence": "3;5;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "RJRCWXGtds",
        "title": "Understanding Computational Models of Semantic Change: New Insights from the Speech Community",
        "track": "main",
        "status": "Short Main",
        "keywords": "semantic change detection;semantic shifts;word embeddings;BERT;language contact",
        "author": "",
        "aff": "CLLE, CNRS & University of Toulouse; Institute for Natural Language Processing, University of Stuttgart",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "http://redac.univ-tlse2.fr/misc/canenTestset.html",
        "github": ""
    },
    {
        "id": "RJq3hJlK6w",
        "title": "Example-based Hypernetworks for Multi-source Adaptation to Unseen Domains",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Domain adaptation;our of distribution;cross-lingual;hypernetworks;prompting",
        "author": "",
        "aff": "Bar Ilan University, Israel; Faculty of Data and Decision Sciences, Technion, IIT",
        "rating": "",
        "confidence": "3;3;3;2",
        "correctness": "2;3;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.75,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/TomerVolk/Hyper-PADA"
    },
    {
        "id": "RKqtOoMC1M",
        "title": "Multilingual \\textit{k}-Nearest-Neighbor Machine Translation",
        "track": "main",
        "status": "Short Main",
        "keywords": "multilingual machine translation;semi-parametric;kNN-MT",
        "author": "",
        "aff": "Language Technology Lab, University of Amsterdam",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/davidstap/multilingual-kNN-mt"
    },
    {
        "id": "RLmpJ4xol2",
        "title": "Learning Preference Model for LLMs via Automatic Preference Data Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Model;Reward Model;Preference Model",
        "author": "",
        "aff": "Department of Computer Science and Engineering, The Chinese University of Hong Kong",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "RMDZNIjTt7",
        "title": "IBADR: an Iterative Bias-Aware Dataset Refinement Framework for Debiasing NLU models",
        "track": "main",
        "status": "Long Main",
        "keywords": "debiased models; dataset refinement; spurious correlation",
        "author": "",
        "aff": "School of Informatics, Xiamen University, Xiamen 361005, China; Baidu Inc., Beijing 100085, China",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "http://github.com/DeepLearnXMU/IBADR"
    },
    {
        "id": "RN5KLywTll",
        "title": "What's \"up\" with vision-language models? Investigating their struggle with spatial reasoning",
        "track": "main",
        "status": "Long Main",
        "keywords": "vision-language;spatial relations;interpretability",
        "author": "",
        "aff": "University of California, Los Angeles; Allen Institute for AI",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/amitakamath/whatsup_vlms"
    },
    {
        "id": "RO460OVpev",
        "title": "Chinese Metaphorical Relation Extraction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Metaphor understanding;metaphorical relation extraction;linguistic metaphor;cognitive metaphor",
        "author": "",
        "aff": "College of Information Engineering, Capital Normal University, Beijing, China; State Key Laboratory of Cognitive Intelligence, iFLYTEK Research, China",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/cnunlp/CMRE"
    },
    {
        "id": "RSuN6p3wXR",
        "title": "APrompt: Attention Prompt Tuning for Efficient Adaptation of Pre-trained Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Prompt Tuning;Parameter Efficient Learning;Attention Prompt",
        "author": "",
        "aff": "Meituan Lab; Virginia Tech; University of Science and Technology of China; Sun Yat-sen University; Peng Chen Lab; Rochester Institute of Technology; Meta AI",
        "rating": "",
        "confidence": "5;4;5",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "RVQccn8rcr",
        "title": "Polar Ducks and Where to Find Them: Enhancing Entity Linking with Duck Typing and Polar Box Embeddings",
        "track": "main",
        "status": "Long Main",
        "keywords": "Entity linking;Entity disambiguation;Box embeddings",
        "author": "",
        "aff": "Meta AI; Meta AI, EPFL",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "RWH1WazQqE",
        "title": "Democratizing LLMs: An Exploration of Cost-Performance Trade-offs in Self-Refined Open-Source Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "large-language-model;open-source;self-refinement;ranking-metric;cost-analysis",
        "author": "",
        "aff": "Department of Computer Science, University of Illinois Urbana-Champaign",
        "rating": "",
        "confidence": "1;4;3",
        "correctness": "3;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "RWJYEeaW1d",
        "title": "EasyQuant: An Efficient Data-free Quantization Algorithm for LLMs",
        "track": "main",
        "status": "Long Main",
        "keywords": "model quantization",
        "author": "",
        "aff": "Tencent",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "RXIYmRUWGD",
        "title": "Improved Unsupervised Chinese Word Segmentation Using Pre-trained Knowledge and Pseudo-labeling Transfer",
        "track": "main",
        "status": "Short Main",
        "keywords": "Unsupervised Chinese Word Segmentation",
        "author": "",
        "aff": "Intelligent Knowledge Management Lab, Department of Computer Science and Information Engineering, National Cheng Kung University, Tainan, Taiwan",
        "rating": "",
        "confidence": "5;5;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "RYvNvCU109",
        "title": "Energy and Carbon Considerations of Fine-Tuning BERT",
        "track": "main",
        "status": "Short Findings",
        "keywords": "energy costs;fine-tuning;efficiency evaluation;efficiency;BERT;transformer",
        "author": "",
        "aff": "Hugging Face; Carnegie Mellon University; Haverford College; Carnegie Mellon University, Allen Institute for AI",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Ra6gfR3XuI",
        "title": "Understanding the Role of Input Token Characters in Language Models: How Does Information Loss Affect Performance?",
        "track": "main",
        "status": "Long Main",
        "keywords": "LLMs;Interpretability;Pretraining",
        "author": "",
        "aff": "Department of Computer Science, University of Sheffield, UK",
        "rating": "",
        "confidence": "5;4;5",
        "correctness": "3;5;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/aajrami/emnlp2023-token-characters-role"
    },
    {
        "id": "RbE83Pmtfk",
        "title": "DeTiME: Diffusion-Enhanced Topic Modeling using Encoder-decoder based LLM",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Topic Modeling;Diffusion;Encoder-Decoder LLM;FlanT5;CNN",
        "author": "",
        "aff": "Amazon",
        "rating": "",
        "confidence": "5;3;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "RcvJnskt0n",
        "title": "Detection of Multiple Mental Disorders from Social Media with Two-Stream Psychiatric Experts",
        "track": "main",
        "status": "Long Main",
        "keywords": "Mental disease detection;symptom;multi-task learning;interpretability;social media",
        "author": "",
        "aff": "University of Texas at Arlington, Arlington, Texas, USA; Shanghai Jiao Tong University, Shanghai, China; X-LANCE Lab, Department of Computer Science and Engineering, MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University, Shanghai, China",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/chesiy/EMNLP23-PsyEx"
    },
    {
        "id": "ReGzwoL3Sl",
        "title": "Semi-Structured Object Sequence Encoders",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Structured object encoders;long sequences",
        "author": "",
        "aff": "Microsoft India Development Center; IBM Research AI",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/murthyrudra/SemiStructuredEncoders"
    },
    {
        "id": "RenTc1sUb7",
        "title": "On Task-personalized Multimodal Few-shot Learning for Visually-rich Document Entity Retrieval",
        "track": "main",
        "status": "Long Findings",
        "keywords": "document understanding;multiple modalities;entity retrieval;few shots;meta learning;out of distribution",
        "author": "",
        "aff": "Google, Mountain View, USA; University of Virginia; Georgia Institute of Technology; Accenture",
        "rating": "",
        "confidence": "1;4;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "RgA1tcrxan",
        "title": "M2DF: Multi-grained Multi-curriculum Denoising Framework for Multimodal Aspect-based Sentiment Analysis",
        "track": "main",
        "status": "Long Main",
        "keywords": "aspect-based sentiment analysis",
        "author": "",
        "aff": "Institute for AI Industry Research (AIR), Tsinghua University; National Key Laboratory for Novel Software Technology, Nanjing University, China",
        "rating": "",
        "confidence": "5;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/grandchicken/M2DF"
    },
    {
        "id": "RkqyZj5QNN",
        "title": "Text Classification via Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large Language Model;Text Classification;Intermediate Rationale Explanations",
        "author": "",
        "aff": "Chongqing University; Shannon.AI; Nanyang Technological University; Zhejiang University; Amazon",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "github.com/ShannonAI/GPT-CLS-CARP"
    },
    {
        "id": "RlPI6mERbr",
        "title": "Pre-trained Speech Processing Models Contain Human-Like Biases that Propagate to Speech Emotion Recognition",
        "track": "main",
        "status": "Long Findings",
        "keywords": "AI bias;speech processing;embeddings;representation learning;bias propagation",
        "author": "",
        "aff": "NIST; University of Washington",
        "rating": "",
        "confidence": "3;2;3;3",
        "correctness": "4;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Rn1k3Na4Cn",
        "title": "CLAD-ST: Contrastive Learning with Adversarial Data for Robust Speech Translation",
        "track": "main",
        "status": "Short Main",
        "keywords": "robust speech translation;contrastive learning",
        "author": "",
        "aff": "Zoom Video Communications",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "RndkyLWLHc",
        "title": "Natural Language Annotations for Reasoning about Program Semantics",
        "track": "main",
        "status": "Short Findings",
        "keywords": "program understanding;natural language reasoning;dataset",
        "author": "",
        "aff": "UnfoldML, G\u00f6teborg, Sweden",
        "rating": "",
        "confidence": "2;3;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://doi.org/10.5281/zenodo.7893113",
        "github": ""
    },
    {
        "id": "Ro3x3mCAkD",
        "title": "Connecting the Dots: What Graph-Based Text Representations Work Best for Text Classification using Graph Neural Networks?",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Graph-Based Text Representation;Graph Neural Networks;Text Classification",
        "author": "Margarita Bugue\u00f1o, Gerard de Melo",
        "aff": "Hasso Plattner Institute (HPI) / University of Potsdam, Potsdam, Germany",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Ror9xJhbdc",
        "title": "Revisiting Instruction Fine-tuned Model Evaluation to Guide Industrial Applications",
        "track": "main",
        "status": "Short Main",
        "keywords": "Instruction Finetuning;Evaluation Metrics;Large Language Models",
        "author": "",
        "aff": "Illuin Technology, Paris, France; MICS, CentraleSup\u00e9lec, Universit\u00e9 Paris-Saclay, France; Illuin Technology, Paris, France; Equall, Paris, France; MICS, CentraleSup\u00e9lec, Universit\u00e9 Paris-Saclay, France; MICS, CentraleSup\u00e9lec, Universit\u00e9 Paris-Saclay, France",
        "rating": "",
        "confidence": "3;2;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "RsK483IRuO",
        "title": "A Closer Look into Using Large Language Models for Automatic Evaluation",
        "track": "main",
        "status": "Short Findings",
        "keywords": "LLM;automatic evaluation;LLM evaluaiton",
        "author": "",
        "aff": "National Taiwan University, Taiwan",
        "rating": "",
        "confidence": "4;5;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "RubWYFBZbG",
        "title": "Fair Without Leveling Down: A New Intersectional Fairness Definition",
        "track": "main",
        "status": "Long Main",
        "keywords": "Fairness; Intersectional; Leveling Down",
        "author": "",
        "aff": "Univ. Lille, Inria, CNRS, Centrale Lille, UMR 9189 - CRIStAL, F-59000 Lille, France",
        "rating": "",
        "confidence": "2;3;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Rvz7LvHcdX",
        "title": "Type-Aware Decomposed Framework for Few-Shot Named Entity Recognition",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Named Entity Recognition;Few-Shot Learning",
        "author": "",
        "aff": "School of Computer Science, Wuhan University, China; School of Computer Science, Wuhan University, China; Intellectual Computing Laboratory for Cultural Heritage, Wuhan University, China",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/NLPWM-WHU/TadNER"
    },
    {
        "id": "RwzFNbJ3Ez",
        "title": "SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "generative-AI hallucination;fact-checking;trustworthy artificial intelligence",
        "author": "",
        "aff": "",
        "rating": "",
        "confidence": "4;4;2;5",
        "correctness": "4;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "RxvMKDgZH6",
        "title": "Accelerating Multiple Intent Detection and Slot Filling via Targeted Knowledge Distillation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multiple Intent Detection and Slot Filling;Knowledge Distillation;Non-Autoregressive",
        "author": "",
        "aff": "School of ECE, Peking University, China",
        "rating": "",
        "confidence": "3;3;5",
        "correctness": "2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Rz5eVgy8Sd",
        "title": "An Intent-based and Annotation-free Method for Duplicate Question Detection in CQA Forums",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Sentence-level Semantics;Textual Inference;Data deduplicating;Instruct-tuning",
        "author": "",
        "aff": "Seattle, United States; Fudan University, Shanghai, China",
        "rating": "",
        "confidence": "5;5;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "RzWrY4KYg8",
        "title": "Uncovering Limitations in Text-to-Image Generation: A Contrastive Approach with Structured Semantic Alignment",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multi-modal generation;Semantic consistency;Structure information learning",
        "author": "",
        "aff": "Chongqing University; University of New South Wales; MatrixVerse, University of Newcastle",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "S0eqbM16k2",
        "title": "Instances and Labels: Hierarchy-aware Joint Supervised Contrastive Learning for Hierarchical Multi-Label Text Classification",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Natural language processing;Multi-label Classification;Contrastive Learning in NLP",
        "author": "",
        "aff": "University of Edinburgh; Cardiff University",
        "rating": "",
        "confidence": "3;4;2",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/simonucl/HJCL"
    },
    {
        "id": "S5eTDhfjHM",
        "title": "tagE: Enabling an Embodied Agent to Understand Human Instructions",
        "track": "main",
        "status": "Long Findings",
        "keywords": "human-robot interaction; NLP for robotics; task and argument extraction; task and argument grounding;",
        "author": "",
        "aff": "TCS Research, India",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "S81zso7Imh",
        "title": "IC3: Image Captioning by Committee Consensus",
        "track": "main",
        "status": "Long Main",
        "keywords": "Image Captioning;Large Language Models;Prompt Engineering;Visual Description",
        "author": "",
        "aff": "University of California, Berkeley; Google Research",
        "rating": "",
        "confidence": "3;3;4;3",
        "correctness": "4;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://davidmchan.github.io/caption-by-committee"
    },
    {
        "id": "SAM1HFH6iB",
        "title": "Self-Evolution Learning for Mixup: Enhance Data Augmentation on Few-Shot Text Classification Tasks",
        "track": "main",
        "status": "Long Main",
        "keywords": "self-evolution learning;mixup;pretrained language model;few-shot text classification",
        "author": "",
        "aff": "School of Computer Science, Wuhan University; JD Explore Academy; University of Sydney; College of Computer, National University of Defense Technology",
        "rating": "",
        "confidence": "5;4;3;3",
        "correctness": "3;2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "SEFD0G4kf0",
        "title": "USB: A Unified Summarization Benchmark Across Tasks and Domains",
        "track": "main",
        "status": "Long Findings",
        "keywords": "summarization;large language models;pretraining;benchmarks;factual correctness",
        "author": "",
        "aff": "Carnegie Mellon University; Northeastern University",
        "rating": "",
        "confidence": "4;4;4;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/kukrishna/usb"
    },
    {
        "id": "SFTvQQA4KJ",
        "title": "FLatS: Principled Out-of-Distribution Detection with Feature-Based Likelihood Ratio Score",
        "track": "main",
        "status": "Short Main",
        "keywords": "OOD Detection;Likelihood Ratio;Intent Classification",
        "author": "",
        "aff": "Yuanpei College, Peking University; Institute for Artificial Intelligence, Peking University; School of Intelligence Science and Technology, Peking University; Yuanpei College, Peking University",
        "rating": "",
        "confidence": "4;3;2;3",
        "correctness": "4;3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/linhaowei1/FLatS"
    },
    {
        "id": "SHkMYY26KP",
        "title": "On General Language Understanding",
        "track": "main",
        "status": "Short Findings",
        "keywords": "NLU;evaluation;benchmarking;semantics;dialogue;modelling;measurement",
        "author": "",
        "aff": "Computational Linguistics / Department of Linguistics, University of Potsdam, Germany",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;1",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "SI2CXa5eok",
        "title": "AMR Parsing with Causal Hierarchical Attention and Pointers",
        "track": "main",
        "status": "Long Main",
        "keywords": "semantic parsing;AMR parsing;hierarical attention;pointer mechanism",
        "author": "",
        "aff": "School of Information Science and Technology, ShanghaiTech University, Shanghai Engineering Research Center of Intelligent Vision and Imaging; School of Information Science and Technology, ShanghaiTech University",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "SJ0Da0j8n7",
        "title": "Exploring Linguistic Probes for Morphological Inflection",
        "track": "main",
        "status": "Short Main",
        "keywords": "morphology;inflection;linguistic probes;English;Spanish;Swahili",
        "author": "",
        "aff": "Department of Linguistics & Institute for Advanced Computational Science, Stony Brook University, Stony Brook, NY, USA",
        "rating": "",
        "confidence": "4;3;2",
        "correctness": "5;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "SJYTfbI59J",
        "title": "Open-source Large Language Models are Strong Zero-shot Query Likelihood Models for Document Ranking",
        "track": "main",
        "status": "Short Findings",
        "keywords": "large language model;query likelihood model;zero-shot ranking model",
        "author": "",
        "aff": "CSIRO; The University of Queensland; CSIRO, The University of Queensland",
        "rating": "",
        "confidence": "3;4;4;3",
        "correctness": "4;2;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ielab/llm-qlm"
    },
    {
        "id": "SNB6BwY2zy",
        "title": "Detecting and Mitigating Hallucinations in Multilingual Summarisation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Summarisation;Multilingual NLP;Hallucination;Natural Language Generation;Faithfulness Evaluation",
        "author": "",
        "aff": "Language Technology Lab, University of Cambridge; Institute for Language, Cognition and Computation, University of Edinburgh",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/yfqiu-nlp/mfact-summ"
    },
    {
        "id": "SP8zIwanHD",
        "title": "$\\textbf{\\emph{CLMSM}}$: A Multi-Task Learning Framework for Pre-training on Procedural Text",
        "track": "main",
        "status": "Long Findings",
        "keywords": "pre-training;procedural reasoning;contrastive learning;masked language modeling;multi-task learning;nlp",
        "author": "",
        "aff": "Indian Institute of Technology Kharagpur, India",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "SPtskxPEiV",
        "title": "Role of Context in Unsupervised Sentence Representation Learning: the Case of Dialog Act Modeling",
        "track": "main",
        "status": "Short Findings",
        "keywords": "unsupervised learning;sentence representation;dialog act modeling",
        "author": "",
        "aff": "Jheronimus Academy of Data Science, Sint Janssingel 92, 5211 DA \u2019s-Hertogenbosch, Netherlands; Tilburg University, Warandelaan 2, 5037 AB Tilburg, Netherlands",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "SQodZvCM5g",
        "title": "Neuro-Symbolic Sentiment Analysis with Dynamic Word Sense Disambiguation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "sentiment analysis;neuro-symbolic AI;word sense disambiguation",
        "author": "",
        "aff": "National University of Singapore, Singapore; Nanyang Technological University, Singapore",
        "rating": "",
        "confidence": "3;4;2",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "SS44Mrv21o",
        "title": "EARA: Improving Biomedical Semantic Textual Similarity with Entity-Aligned Attention and Retrieval Augmentation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Biomedical semantic textual similarity;entity-aligned regularization;retrival augmentation",
        "author": "",
        "aff": "Harbin Institute of Technology, Shenzhen; Peng Cheng Laboratory; City University of Hong Kong",
        "rating": "",
        "confidence": "4;4;3;2",
        "correctness": "4;3;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/xy-always/EARA"
    },
    {
        "id": "ST0ejo0mnc",
        "title": "A Rewriting Approach for Gender Inclusivity in Portuguese",
        "track": "main",
        "status": "Long Findings",
        "keywords": "nlp;portuguese;gender neutrality;gender inclusivity;machine translation",
        "author": "",
        "aff": "INESC-ID, Lisbon, Portugal; Instituto Superior T\u00e9cnico, University of Lisbon, Portugal",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "4;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/leonorv/pt-gn-datasets"
    },
    {
        "id": "STHKApXVMH",
        "title": "Unnatural Error Correction: GPT-4 Can Almost Perfectly Handle Unnatural Scrambled Text",
        "track": "main",
        "status": "Short Main",
        "keywords": "Large Language Models;Emergent Ability;Scrambled Text;GPT-4",
        "author": "",
        "aff": "The University of Tokyo, Japan",
        "rating": "",
        "confidence": "4;3;4;4",
        "correctness": "4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ccqq77/unnatural-error-correction"
    },
    {
        "id": "SUAeMJKg6b",
        "title": "\u201cMistakes Help Us Grow\u201d: Facilitating and Evaluating Growth Mindset Supportive Language in Classrooms",
        "track": "main",
        "status": "Long Main",
        "keywords": "Growth mindset;Language models;Education;Applications",
        "author": "",
        "aff": "Stanford University; Vanderbilt University; Brown University; UT Austin",
        "rating": "",
        "confidence": "5;5;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/kunhanda/growth_mindset"
    },
    {
        "id": "SViJgzox1z",
        "title": "Parameter Efficient Multi-task Fine-tuning by Learning to Transfer Token-wise Prompts",
        "track": "main",
        "status": "Long Findings",
        "keywords": "multi-task learning;token-wise;memory network;instance-dependent prompt",
        "author": "",
        "aff": "Alibaba Group, Zhejiang, China; School of Computer Science, Fudan University, Shanghai, China",
        "rating": "",
        "confidence": "3;4;3;4",
        "correctness": "3;2;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/mlwu22/TPT"
    },
    {
        "id": "SdpSaw26XT",
        "title": "Mirror: A Universal Framework for Various Information Extraction Tasks",
        "track": "main",
        "status": "Long Main",
        "keywords": "Information Extraction;Non-Autoregressive Decoding;Multi-task",
        "author": "",
        "aff": "Institute of Artificial Intelligence, School of Computer Science and Technology, Soochow University, China; Huawei Cloud, China",
        "rating": "",
        "confidence": "5;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Spico197/Mirror"
    },
    {
        "id": "SfI8GT3xdb",
        "title": "Chain-of-Questions Training with Latent Answers for Robust Multistep Question Answering",
        "track": "main",
        "status": "Long Main",
        "keywords": "multistep reasoning;question answering;latent variable learning",
        "author": "",
        "aff": "University of Southern California, Los Angeles, CA, USA",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "ShQoWnMu1b",
        "title": "Learning to Predict Task Transferability via Soft Prompt",
        "track": "main",
        "status": "Long Main",
        "keywords": "transfer learning;prompt tuning",
        "author": "",
        "aff": "China Mobile Information Technology Center",
        "rating": "",
        "confidence": "5;3;5",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "SihQ9bBLWa",
        "title": "Annotations Are Not All You Need: A Cross-modal Knowledge Transfer Network for Unsupervised Temporal Sentence Grounding",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Cross-modal Knowledge Transfer;Unsupervised Temporal Sentence Grounding",
        "author": "",
        "aff": "Hubei Key Laboratory of Distributed System Security, Hubei Engineering Research Center on Big Data Security, School of Cyber Science and Engineering, Huazhong University of Science and Technology; Peking University; Protagolabs Inc.; Guangzhou University; Henan University; The Chinese University of Hong Kong",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "1;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "SkWgL49qwI",
        "title": "A Language Model with Limited Memory Capacity Captures Interference in Human Sentence Processing",
        "track": "main",
        "status": "Long Findings",
        "keywords": "cue-based retrieval;working memory;interference;attention;agreement attraction;neural networks;cognitive modeling;surprisal;attention",
        "author": "",
        "aff": "New York University",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;3;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "SlL3dr0Xa9",
        "title": "Show, Write, and Retrieve: Entity-aware Article Generation and Retrieval",
        "track": "main",
        "status": "Long Findings",
        "keywords": "article generation;article retrieval;named entity recognition",
        "author": "",
        "aff": "Boston University",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "http://this.http.URL"
    },
    {
        "id": "Sm3RzRKCel",
        "title": "Dialogizer: Context-aware Conversational-QA Dataset Generation from Textual Sources",
        "track": "main",
        "status": "Long Main",
        "keywords": "Dialog System;Conversational Question Answering;Dataset Generation",
        "author": "",
        "aff": "SNU-LG AI Research Center; LG AI Research; IPAI, Seoul National University; Chung-Ang University; Dept. of ECE, Seoul National University",
        "rating": "",
        "confidence": "3;1;4;3",
        "correctness": "2;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "SnFmGmKTn1",
        "title": "KICGPT: Large Language Model with Knowledge in Context for Knowledge Graph Completion",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Knowledge Graph Completion;Large Language Model",
        "author": "",
        "aff": "Hong Kong University of Science and Technology; University of Surrey; Southern University of Science and Technology",
        "rating": "",
        "confidence": "4;3;3;4",
        "correctness": "4;3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "SoypWgmvqP",
        "title": "Detecting Propaganda Techniques in Code-Switched Social Media Text",
        "track": "main",
        "status": "Long Main",
        "keywords": "propaganda detection;code-switching;low-resource languages;multilinguality;roman-urdu;natural language processing",
        "author": "",
        "aff": "Mohamed Bin Zayed University of Artificial Intelligence (MBZUAI)",
        "rating": "",
        "confidence": "4;4;4;3;4;5",
        "correctness": "2;2;3;4;2;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/mbzuai-nlp/propaganda-codeswitched-text"
    },
    {
        "id": "Srxf1V2jPa",
        "title": "RobustGEC: Robust Grammatical Error Correction Against Subtle Context Perturbation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Grammatical Error Correction;Robustness",
        "author": "",
        "aff": "Tencent AI Lab, Shenzhen, China; Institute of Artificial Intelligence, School of Computer Science and Technology, Soochow University, Suzhou, China; Tencent AI Lab, Shenzhen, China",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/hillzhang1999/RobustGEC"
    },
    {
        "id": "SvmlxXMLYr",
        "title": "COUNT: COntrastive UNlikelihood Text Style Transfer for Text Detoxification",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Text Style Transfer;Detoxification;Unlikelihood Training",
        "author": "",
        "aff": "University of Toronto, Canada; LG Electronics, Toronto AI Lab",
        "rating": "",
        "confidence": "4;5;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/D3Mlab/count-style-transfer2023"
    },
    {
        "id": "SwphsE7hYO",
        "title": "Retrieval-based Knowledge Transfer: An Effective Approach for Extreme Large Language Model Compression",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Model Compression;LLM",
        "author": "",
        "aff": "Wangxuan Institute of Computer Technology, Peking University; Center for Data Science, AAIS, Peking University; National Key Laboratory of General Artificial Intelligence; BIGAI, Beijing, China; Meta AI; Gaoling School of Artificial Intelligence, Renmin University of China; Meituan; Wangxuan Institute of Computer Technology, Peking University; Center for Data Science, AAIS, Peking University",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "SxrA1okPXY",
        "title": "Event-Location Tracking in Narratives: A Case Study on Holocaust Testimonies",
        "track": "main",
        "status": "Long Main",
        "keywords": "Location tracking;Narrative understanding;Holocaust testimonies",
        "author": "",
        "aff": "Faculty of Law and Digital Humanities, Hebrew University of Jerusalem; Department of Computer Science, Hebrew University of Jerusalem",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/eitanwagner/location-tracking"
    },
    {
        "id": "SyEwsV52Dk",
        "title": "Evaluation Metrics in the Era of GPT-4: Reliably Evaluating Large Language Models on Sequence to Sequence Tasks",
        "track": "main",
        "status": "Short Main",
        "keywords": "evaluation;human evaluation;LLM;summarization;simplification;grammatical error correction;ChatGPT;GPT-4;Sequence to sequence",
        "author": "",
        "aff": "NetMind.AI; Department of Informatics, King\u2019s College London",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "SzH7d4617q",
        "title": "The Intended Uses of Automated Fact-Checking Artefacts: Why, How and Who",
        "track": "main",
        "status": "Long Findings",
        "keywords": "fact-checking;automated fact-checking;content analysis;intended use;natural language processing;artefacts",
        "author": "",
        "aff": "Department of Computer Science and Technology, University of Cambridge/Cardiff University; Department of Computer Science and Technology, University of Cambridge",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;1",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "T3kZcQ2ivs",
        "title": "Are Embedded Potatoes Still Vegetables? On the Limitations of WordNet Embeddings for Lexical Semantics",
        "track": "main",
        "status": "Long Main",
        "keywords": "Knowledge Base Embedding;Lexical Semantics;WordNet;Link Prediction",
        "author": "",
        "aff": "University of Cambridge",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "T3n9nbeIKc",
        "title": "Dataset Bias Mitigation in Multiple-Choice Visual Question Answering and Beyond",
        "track": "main",
        "status": "Long Findings",
        "keywords": "vision language;vcr;vqa;snli-ve;visual question answering;commonsense reasoning;pretraining;multimodal;robust;low-shot;zero-shot;domain-shift;debiased;shortcut",
        "author": "",
        "aff": "University of California, Los Angeles; HKUST; Microsoft Research; Columbia University",
        "rating": "",
        "confidence": "4;2;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "T6GJ2Y0dn7",
        "title": "Intersectional Stereotypes in Large Language Models: Dataset and Analysis",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Stereotype Examination;Intersectional Stereotype;Dataset",
        "author": "",
        "aff": "Department of Computer Science, Dartmouth College",
        "rating": "",
        "confidence": "5;3;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "T8ABT8q3FS",
        "title": "SegAugment: Maximizing the Utility of Speech Translation Data with Segmentation-based Augmentations",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Speech Translation;Data Augmentation",
        "author": "",
        "aff": "FAIR Meta, Paris; Universitat Polit\u00e8cnica de Catalunya, Barcelona",
        "rating": "",
        "confidence": "4;2;4;4",
        "correctness": "3;4;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "T9jJsFUGtI",
        "title": "Citance-Contextualized Summarization of Scientific Papers",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Summarization;Scholarly Document Processing;Scientific Papers;Large Language Models",
        "author": "",
        "aff": "University of Groningen; Leipzig University, ScaDS.AI; Leipzig University",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/webis-de/EMNLP-23"
    },
    {
        "id": "T9wuVnNa5v",
        "title": "SIR-ABSC: Incorporating Syntax into RoBERTa-based Sentiment Analysis Models with a Special Aggregator Token",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Aspect-based sentiment analysis;Pre-trained Language Models;RoBERTa",
        "author": "",
        "aff": "University of Illinois at Urbana-Champaign",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "2;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ihcho2/SIR-ABSC"
    },
    {
        "id": "THr9aJ3z9k",
        "title": "Quick Back-Translation for Unsupervised Machine Translation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "unsupervised machine translation;back-translation;non-autoregressive generation;Transformer",
        "author": "",
        "aff": "Harvard University; Columbia University",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "TKGgLVYRqJ",
        "title": "Seeing through the mess: evolutionary dynamics of lexical polysemy",
        "track": "main",
        "status": "Long Main",
        "keywords": "polysemy;language change;mathematical modeling;adaptive dynamics;senses;frequency;non-conformism;discriminability",
        "author": "",
        "aff": "Faculty of Philological and Cultural Studies, University of Vienna, Austria; Faculty of Computer Science, University of Vienna, Austria",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "5;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "TKo2JXw7vL",
        "title": "Large Language Models Meet Harry Potter: A Dataset for Aligning Dialogue Agents with Characters",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Personalized dialogue systems;dataset",
        "author": "",
        "aff": "\u2021Tencent AI Lab; \u2020DSA, Hong Kong University of Science and Technology (Guangzhou), Hong Kong University of Science and Technology",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://nuochenpku.github.io/HPD.github.io",
        "github": "https://github.com/nuochenpku/HPD"
    },
    {
        "id": "TKzERU0kq1",
        "title": "Guiding LLM to Fool Itself: Automatically Manipulating Machine Reading Comprehension Shortcut Triggers",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Shortcuts;Large language models;Question answering",
        "author": "",
        "aff": "Bar-Ilan University, Allen Institute for AI; Bar-Ilan University",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "TSdWY9GaHA",
        "title": "CHiLL: Zero-shot Custom Interpretable Feature Extraction from Clinical Notes with Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Interpretability;Large Language Models;Healthcare;Electronic Health Records;Feature Extraction;Zero-shot",
        "author": "",
        "aff": "Northeastern University; Brigham and Women\u2019s Hospital; University of Amsterdam",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "TW2cBze4ZB",
        "title": "Contrastive Deterministic Autoencoders For Language Modeling",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Autoencoders;Contrastive;Transformers",
        "author": "",
        "aff": "David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, Canada; David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, Canada; Vector Institute, Toronto, Canada",
        "rating": "",
        "confidence": "3;3;2",
        "correctness": "2;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "TW831RjYQO",
        "title": "MedEval: A Multi-Level, Multi-Task, and Multi-Domain Medical Benchmark for Language Model Evaluation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Curated Datasets;NLP for Healthcare;Pre-trained Language Models",
        "author": "",
        "aff": "University of California, San Diego, La Jolla, CA, United States",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ZexueHe/MedEval"
    },
    {
        "id": "TZW4nzgtQ8",
        "title": "Locally Differentially Private Document Generation Using Zero Shot Prompting",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Language Models;Local Differential Privacy;Deanonymization Attacks;Zero Shot Prompting",
        "author": "",
        "aff": "Cohere For AI; IBM Research",
        "rating": "",
        "confidence": "4;4;4;4;4",
        "correctness": "4;4;3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/SaitejaUtpala/dp_prompt"
    },
    {
        "id": "Td9LjgO91J",
        "title": "Unleashing the Power of Language Models in Text-Attributed Graph",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Hierarchical Text-attributed Graph;Pre-training;Self-supervised Tasks",
        "author": "",
        "aff": "School of Data Science, Fudan University, China; Research Institute of Intelligent Complex Systems, Fudan University, China; School of Computer Science, Fudan University, China; School of Management, Fudan University, China; School of Data Science, Fudan University, China; Huawei Technologies Co.,Ltd, China",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "TdrI4F7wS8",
        "title": "Regulation and NLP (RegNLP): Taming Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "LLM;regulation;ethics;safety;public policy;science influencers",
        "author": "",
        "aff": "Tilburg University; Utrecht University; University of Copenhagen; Maastricht University; University of Sheffield",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "TemPqRDMJ8",
        "title": "SOUL: Towards Sentiment and Opinion Understanding of Language",
        "track": "main",
        "status": "Short Main",
        "keywords": "sentiment analysis;sentiment classification;sentiment and opinion understanding",
        "author": "",
        "aff": "Nanyang Technological University, Singapore & The Chinese University of Hong Kong; DAMO Academy, Alibaba Group, Singapore & Hupan Lab, Hangzhou, China; DAMO Academy, Alibaba Group, Singapore & Nanyang Technological University",
        "rating": "",
        "confidence": "5;5;3;4",
        "correctness": "3;3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/DAMO-NLP-SG/SOUL"
    },
    {
        "id": "Tha4jW8er9",
        "title": "Machine Reading Comprehension using Case-based Reasoning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "question answering;case-based reasoning",
        "author": "",
        "aff": "University of Massachusetts Amherst; AWS AI Labs; University of Washington; Seoul National University",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/dungtn/cbr-txt"
    },
    {
        "id": "TioAqBt8lz",
        "title": "Structure-aware Knowledge Graph-to-text Generation with Planning Selection and Similarity Distinction",
        "track": "main",
        "status": "Long Main",
        "keywords": "KG-to-text generation;Pre-trained language model;Planning Selection;Similarity Distinction",
        "author": "",
        "aff": "Natural Language Processing and Knowledge Graph Lab, School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Tk4tvmdKVP",
        "title": "Not all quantifiers are equal: Probing Transformer-based language models' understanding of generalised quantifiers",
        "track": "main",
        "status": "Long Main",
        "keywords": "Natural Language Inference;Transformer-based language models",
        "author": "",
        "aff": "Department of Computer Science, The University of Manchester",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;5;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "TkJkSkmhUy",
        "title": "Injecting structural hints: Using language models to study inductive biases in language learning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "transfer learning;pretraining;recursion;context-sensitivity",
        "author": "",
        "aff": "Computer Science Department, Stanford University",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Tn5hALAaA4",
        "title": "Crosslingual Transfer Learning for Low-Resource Languages Based on Multilingual Colexification Graphs",
        "track": "main",
        "status": "Long Findings",
        "keywords": "multilingual;colexification;transfer learning",
        "author": "",
        "aff": "Center for Information and Language Processing, LMU Munich",
        "rating": "",
        "confidence": "4;3;3;4",
        "correctness": "4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "TnpFFjHCcw",
        "title": "Conversational Semantic Parsing using Dynamic Context Graphs",
        "track": "main",
        "status": "Long Main",
        "keywords": "semantic parsing;SPARQL;Knowledge Graphs;Conversational Semantic Parsing",
        "author": "",
        "aff": "Institute for Language, Cognition and Computation, School of Informatics, University of Edinburgh",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Tnx0922coo",
        "title": "Disentangling Transformer Language Models as Superposed Topic Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Topic Modelling;Mechanistic Interpretability;Pre-trained Language Models;Transformers",
        "author": "",
        "aff": "Singapore Management University",
        "rating": "",
        "confidence": "2;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "ToGkF2nCNG",
        "title": "Measure Children's Mindreading Ability with Machine Reading",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Natural Language Processing;Machine Reading Comprehension;Multimodal;Psychology;Mind-reading",
        "author": "",
        "aff": "School of Computer Science, Fudan University, Shanghai, China; Shanghai Key Laboratory of Intelligent Information Processing",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/manic-dolphin/emnlp2023-unifm-mindreading"
    },
    {
        "id": "ToMdTqVIb5",
        "title": "Monte Carlo Thought Search: Large Language Model Querying for Complex Scientific Reasoning in Catalyst Design",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Chain-of-Thought;Large Language Model;Reasoning;Scientific Discovery;Chemistry;Catalysis",
        "author": "",
        "aff": "University of Illinois Urbana-Champaign, Urbana, Illinois, USA; Pacific Northwest National Laboratory, Richland, Washington, USA",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "5;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/pnnl/chemreasoner"
    },
    {
        "id": "Tpd5RuSzpq",
        "title": "PUNR: Pre-training with User Behavior Modeling for News Recommendation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "News Recommendation;Pre-training;User Behavior Modeling",
        "author": "",
        "aff": "Du Xiaoman Finance, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "TqIDmoIzLT",
        "title": "CleanCoNLL: A Nearly Noise-Free Named Entity Recognition Dataset",
        "track": "main",
        "status": "Long Main",
        "keywords": "Dataset Relabeling and Evaluation;Label Error Detection and Correction;Named Entity Recognition;CoNLL-03;Entity Linking",
        "author": "",
        "aff": "Humboldt-Universit\u00e4t zu Berlin",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/flairNLP/CleanCoNLL"
    },
    {
        "id": "TtQfZwf5s5",
        "title": "MT2: Towards a Multi-Task Machine Translation Model with Translation-Specific In-Context Learning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Machine Translation;In-Context Learning",
        "author": "",
        "aff": "Beijing Lanzhou Technology Co., Ltd., Beijing, China; Beijing Key Lab of Traffic Data Analysis and Mining, Beijing Jiaotong University, Beijing, China",
        "rating": "",
        "confidence": "3;4;4;4",
        "correctness": "4;3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "TubO0kgAeL",
        "title": "This is not a Dataset: A Large Negation Benchmark to Challenge Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "negation;dataset;LLM;commonsense;evaluation;foundation models;WordNet;real-word knowledge;Large Language models",
        "author": "",
        "aff": "HiTZ Center - Ixa, University of the Basque Country UPV/EHU; LoRea Group, University of the Basque Country UPV/EHU",
        "rating": "",
        "confidence": "5;3;5",
        "correctness": "5;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/hitz-zentroa/This-is-not-a-Dataset"
    },
    {
        "id": "TvTwz12BZN",
        "title": "Segmented Recurrent Transformer: An Efficient Sequence-to-Sequence Model",
        "track": "main",
        "status": "Long Findings",
        "keywords": "abstractive summarization;transformers;language models",
        "author": "",
        "aff": "Purdue University",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "TxEV8D0z0r",
        "title": "trlX: A Framework for Large Scale Reinforcement Learning from Human Feedback",
        "track": "main",
        "status": "Long Main",
        "keywords": "RLHF;LLM;Framework",
        "author": "",
        "aff": "Independent Researcher; Stability AI; Ohio State University; EleutherAI; CarperAI; CarperAI, Georgia Tech; vectorshift.ai; Booz Allen Hamilton",
        "rating": "",
        "confidence": "3;2;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "U1rj4p5aKa",
        "title": "Automatic Pronunciation Assessment - A Review",
        "track": "main",
        "status": "Long Findings",
        "keywords": "computer aided pronunciation training (CAPT);pronunciation assessment;second language learning;pronunciation error detection",
        "author": "",
        "aff": "Qatar Computing Research Institute, HBKU, Qatar",
        "rating": "",
        "confidence": "4;2;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "U6SEUS76IE",
        "title": "FedID: Federated Interactive Distillation for Large-Scale Pretraining Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "decentralized learning;federated learning;federated distillation;pre-trained language model",
        "author": "",
        "aff": "School of Information Science and Engineering, Yunnan University, Kunming, China",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "5;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/maxinge8698/FedID"
    },
    {
        "id": "U78nBY8hRi",
        "title": "DALE: Generative Data Augmentation for Low-Resource Legal NLP",
        "track": "main",
        "status": "Long Main",
        "keywords": "legal;low-resource;augmentation;generation;efficient",
        "author": "",
        "aff": "NVIDIA, Bangalore, India; UMass, Amherst, USA; University of Maryland, College Park, USA",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Sreyan88/DALE"
    },
    {
        "id": "U7mWHBoTfb",
        "title": "Improving Language Models\u2019 Meaning Understanding and Consistency by Learning Conceptual Roles from Dictionary",
        "track": "main",
        "status": "Long Main",
        "keywords": "Language Model;Consistency;Conceptual Role Theory",
        "author": "",
        "aff": "Institute of Logic and Computation, Vienna University of Technology, Austria; Department of Computer Science, University of Oxford, UK",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "U8PL5FzvrV",
        "title": "Improving Dialogue Discourse Parsing via Reply-to Structures of Addressee Recognition",
        "track": "main",
        "status": "Long Main",
        "keywords": "Dialogue Discourse Parsing;Reinforcement Learning;Task-aware Structure Transformer",
        "author": "",
        "aff": "School of Computer Science and Technology, Soochow University, Suzhou, China; School of Data Science, The Chinese University of Hong Kong, Shenzhen, China",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/yxfanSuda/RLTST"
    },
    {
        "id": "UECSdvL8U7",
        "title": "Evaluating Bias and Fairness in Gender-Neutral Pretrained Vision-and-Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "bias;fairness;multimodal",
        "author": "",
        "aff": "Department of Computer Science, University of Copenhagen, Denmark",
        "rating": "",
        "confidence": "3;4;3;4",
        "correctness": "4;3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "UEx5dZqXvr",
        "title": "Scaling Law for Document Neural Machine Translation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Document Machine Translation;NMT;Scaling",
        "author": "",
        "aff": "School of Future Science and Engineering, Soochow University, China; Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences (ICT/CAS) and University of Chinese Academy of Sciences, Beijing, China",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "UEzKGW4U39",
        "title": "Isotropy-Enhanced Conditional Masked Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Non-autoregressive;Anisotropic Problem;Neural Machine Translation;Natural Language Processing",
        "author": "",
        "aff": "; Institute of Computer Science and Technology, Soochow University, China",
        "rating": "",
        "confidence": "5;4;5;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/AllForward/Isotropy-Enhanced-CMLM"
    },
    {
        "id": "UGd9eSwsvn",
        "title": "Zero-Shot Data Maps. Efficient Dataset Cartography Without Model Training",
        "track": "main",
        "status": "Long Findings",
        "keywords": "data maps;bi-encoders;zero-shot;training dynamics",
        "author": "",
        "aff": "Symanto Research; Symanto Research, Universitat Polit\u00e8cnica de Val\u00e8ncia; PRHLT Research Center, Universitat Polit\u00e8cnica de Val\u00e8ncia",
        "rating": "",
        "confidence": "4;3;3;3",
        "correctness": "5;2;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/symanto-research/zeroshot-cartography"
    },
    {
        "id": "UIIi9hBNW8",
        "title": "\"You Are An Expert Linguistic Annotator\": Limits of LLMs as Analyzers of Abstract Meaning Representation",
        "track": "main",
        "status": "Short Findings",
        "keywords": "semantic structure;AMR;linguistic annotation;LLMs;few-shot;zero-shot",
        "author": "",
        "aff": "Allen Institute for AI; Allen Institute for AI and University of Washington",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "UMywlqrW3n",
        "title": "Getting MoRE out of Mixture of Language Model Reasoning Experts",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large Language Models;Reasoning;Prompting;Generalization;Calibration;Interpretability",
        "author": "",
        "aff": "Stanford University; NYU Shanghai; University of Washington; University of Maryland",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/NoviScl/MoRE"
    },
    {
        "id": "UNFR2Y6Xx0",
        "title": "IDTraffickers: An Authorship Attribution Dataset to link and connect Potential Human-Trafficking Operations on Text Escort Advertisements",
        "track": "main",
        "status": "Long Main",
        "keywords": "Human Trafficking;Authorship Attribution;Natural Language Processing;Dataset;Benchmarks",
        "author": "",
        "aff": "Bashpole Software, Inc.; Law & Tech Lab, Maastricht University",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/maastrichtlawtech/IDTraffickers.git"
    },
    {
        "id": "UNvLur0th4",
        "title": "Finding Common Ground: Annotating and Predicting Common Ground in Spoken Conversations",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Common Ground;Belief Extraction;Corpus Construction;Cognitive state;T5 Language Model",
        "author": "",
        "aff": "University of Guilan, Rasht, Guilan, Iran; Stony Brook University, Stony Brook, NY, USA",
        "rating": "",
        "confidence": "2;4;3;4",
        "correctness": "4;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "UQpbq4v8Xi",
        "title": "Generating Data for Symbolic Language with Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Model;Data Generation;Symbolic Language;Code Generation",
        "author": "",
        "aff": "The University of Hong Kong; University of Cambridge",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/HKUNLP/SymGen"
    },
    {
        "id": "UTMwcLMhso",
        "title": "Increasing Probability Mass on Answer Choices Does Not Always Improve Accuracy",
        "track": "main",
        "status": "Long Main",
        "keywords": "analysis of language models; probability; surface form competition; multiple-choice tasks; text generation; few-shot prompting",
        "author": "",
        "aff": "Allen Institute for AI; University of Southern California",
        "rating": "",
        "confidence": "3;4;3;2",
        "correctness": "4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/allenai/revisiting_surface_form_competition"
    },
    {
        "id": "UVoA0rALMC",
        "title": "Few-shot Unified Question Answering: Tuning Models or Prompts?",
        "track": "main",
        "status": "Long Findings",
        "keywords": "unified question answering;QA;universal QA;paramter efficient QA;model tuning . prompt tuning",
        "author": "",
        "aff": "Salesforce Research; Carnegie Mellon University",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;5;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "UXSqUOMwbE",
        "title": "QA-NatVer: Question Answering for Natural Logic-based Fact Verification",
        "track": "main",
        "status": "Long Main",
        "keywords": "fact-checking;fact extraction and verification;claim verification;natural logic;natural language inference;faithfulness",
        "author": "",
        "aff": "Department of Computer Science and Technology, University of Cambridge",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "UaZe4SwQF2",
        "title": "Gender Biases in Automatic Evaluation Metrics for Image Captioning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Automatic Evaluation Metrics;Fairness",
        "author": "",
        "aff": "University of California, Los Angeles; Meta AI Research",
        "rating": "",
        "confidence": "3;2;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/PlusLabNLP/clipscore-bias"
    },
    {
        "id": "Ud2UQ9ZCep",
        "title": "Open Domain Multi-document Summarization: A Comprehensive Study of Model Brittleness under Retrieval",
        "track": "main",
        "status": "Long Findings",
        "keywords": "summarization;multi-document summarization;retrieval;open-domain",
        "author": "",
        "aff": "University of Toronto, Terrence Donnelly Centre, Vector Institute for AI; University of Washington; Yale University; University of Toronto, Vector Institute for AI; Allen Institute for AI; University of Toronto, Terrence Donnelly Centre",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/allenai/open-mds"
    },
    {
        "id": "Ue9i6qgiCw",
        "title": "DecipherPref: Analyzing Influential Factors in Human Preference Judgments via GPT-4",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Models;Summarization Evaluation;Human Preference Judgments;GPT-4",
        "author": "",
        "aff": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "UhuizFH1Hx",
        "title": "GSAP-NER: A Novel Task, Corpus, and Baseline for Scholarly Entity Extraction Focused on Machine Learning Models and Datasets",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Information Extraction (IE);ML models;datasets;Named Entity Recognition (NER)",
        "author": "",
        "aff": "GESIS \u2013 Leibniz Institute for the Social Sciences, Cologne, Germany; Heinrich-Heine-University D\u00fcsseldorf, Germany",
        "rating": "",
        "confidence": "3;4;4;4",
        "correctness": "3;4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://data.gesis.org/gsap/gsap-ner",
        "github": ""
    },
    {
        "id": "UixzK8evk5",
        "title": "DistillCSE: Distilled Contrastive Learning for Sentence Embeddings",
        "track": "main",
        "status": "Long Findings",
        "keywords": "sentence embedding;self-training;contrastive learning",
        "author": "",
        "aff": "Nanyang Technological University; Tencent AI Lab; City University of Hong Kong",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Jiahao004/DistillCSE"
    },
    {
        "id": "UjOPUHPoTM",
        "title": "Blackbird language matrices (BLM), a new task for rule-like generalization in neural networks: Can Large Language Models pass the test?",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Rule-based learning;generalisation;intrinsic evaluation;cognitive modelling;benchmarking",
        "author": "",
        "aff": "University of Geneva",
        "rating": "",
        "confidence": "4;2;4",
        "correctness": "2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "UlewKJFkUV",
        "title": "Memorisation Cartography: Mapping out the Memorisation-Generalisation Continuum in Neural Machine Translation",
        "track": "main",
        "status": "Long Main",
        "keywords": "interpretability;neural machine translation;memorization",
        "author": "",
        "aff": "ILCC, University of Edinburgh; FAIR, Meta AI; ILLC, University of Amsterdam",
        "rating": "",
        "confidence": "4;4;3;3",
        "correctness": "4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "UlgNWOzMz2",
        "title": "Isotropic Representation Can Improve Zero-Shot Cross-Lingual Transfer on Multilingual Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "isotropic representation;cross-lingual;multilingual",
        "author": "",
        "aff": "Institute of Computer Science and Technology, Soochow University, China; Department of Computer Science, National University of Singapore",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Dereck0602/IsoZCL"
    },
    {
        "id": "UmKaHvjkiu",
        "title": "PreWoMe: Exploiting Presuppositions as Working Memory for Long Form Question Answering",
        "track": "main",
        "status": "Short Main",
        "keywords": "Long-Form QA;Large Language Models;Presuppositions",
        "author": "",
        "aff": "LG AI Research; Carnegie Mellon University; Columbia University",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Upk6WrdJYM",
        "title": "Efficient k-NN Search with Cross-Encoders using Adaptive Multi-Round CUR Decomposition",
        "track": "main",
        "status": "Short Findings",
        "keywords": "cross-encoder;nearest neighbor search;k-NN;retrieval",
        "author": "",
        "aff": "University of Massachusetts Amherst; Google Research",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Uuqv7iSNif",
        "title": "New Datasets and Controllable Iterative Data Augmentation Method for Code-switching ASR Error Correction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "ASR Error Correction;Code Switching;Data Augmentation",
        "author": "",
        "aff": "Artificial Intelligence Application Research Center, Huawei Technologies; Wangxuan Institute of Computer Technology, Peking University",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "UxdVVhWVq2",
        "title": "Knowledge-Selective Pretraining for Attribute Value Extraction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "attribute value extraction;pretraining",
        "author": "",
        "aff": "Amazon.com Inc, Palo Alto, CA, USA; Ingenuity Labs Research Institute & ECE, Queen\u2019s University, Canada",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "UyLaqZ6PHA",
        "title": "How Do Large Language Models Capture the Ever-changing World Knowledge? A Review of Recent Advances",
        "track": "main",
        "status": "Long Main",
        "keywords": "large language models;survey;knowledge",
        "author": "",
        "aff": "University of Wollongong; University of Liverpool; University of Technology Sydney; University College London",
        "rating": "",
        "confidence": "4;4;1",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/hyintell/awesome-refreshing-llms"
    },
    {
        "id": "V3O0NNaPNW",
        "title": "Speaking Style Conversion in the Waveform Domain Using Discrete Self-Supervised Units",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Voice Conversion;Audio Processing;Self-Supervised Learning",
        "author": "",
        "aff": "School of Computer Science and Engineering, The Hebrew University of Jerusalem",
        "rating": "",
        "confidence": "3;4;5",
        "correctness": "4;4;1",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://pages.cs.huji.ac.il/adiyoss-lab/dissc/",
        "github": ""
    },
    {
        "id": "V49Jx2Lj04",
        "title": "IfQA: A Dataset for Open-domain Question Answering under Counterfactual Presuppositions",
        "track": "main",
        "status": "Long Main",
        "keywords": "open-domain question answering;counterfactual reasoning",
        "author": "",
        "aff": "Tecent AI Seattle Lab; Allen Institute for AI; University of Notre Dame",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://allenai.org/data/ifqa",
        "github": ""
    },
    {
        "id": "V76kMIJI37",
        "title": "Retrieval-Generation Alignment for End-to-End Task-Oriented Dialogue System",
        "track": "main",
        "status": "Long Main",
        "keywords": "Knowledge Retrieval;End-to-End Task-Oriented Dialogue System",
        "author": "",
        "aff": "School of Computer Science and Engineering, Sun Yat-sen University, China; Tencent AI Lab",
        "rating": "",
        "confidence": "4;4;3;4",
        "correctness": "4;4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/shenwzh3/MK-TOD"
    },
    {
        "id": "V9xsOja2oC",
        "title": "Homophone Disambiguation Reveals Patterns of Context Mixing in Speech Transformers",
        "track": "main",
        "status": "Long Main",
        "keywords": "speech transformers;context mixing;model interpretability for spoken language",
        "author": "",
        "aff": "CSAI, Tilburg University; ILLC, University of Amsterdam",
        "rating": "",
        "confidence": "3;4;4;4",
        "correctness": "3;5;5;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 4.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/hmohebbi/ContextMixingASR"
    },
    {
        "id": "VC2vPPetCU",
        "title": "Open-ended Commonsense Reasoning with Unrestricted Answer Candidates",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Commonsense Reasoning;Question Answering",
        "author": "",
        "aff": "NEC Labs America; NEC Corporation; Microsoft; Emory University",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/lingchen0331/KEEP"
    },
    {
        "id": "VCyOXC8RfQ",
        "title": "Measuring bias in Instruction-Following models with P-AT",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large Language Models;Instruction-Following;Bias",
        "author": "",
        "aff": "Sapienza University of Rome, Italy; University of Rome Tor Vergata, Italy; Idiap Research Institute, Switzerland",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ART-Group-it/P-AT"
    },
    {
        "id": "VGb2RhMFAI",
        "title": "Air-Decoding: Attribute Distribution Reconstruction for Decoding-Time Controllable Text Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "controllable;text generation;decoding-time",
        "author": "",
        "aff": "University of Science and Technology of China; MOE Key Laboratory of Trustworthy Distributed Computing and Service, Beijing University of Posts and Telecommunications",
        "rating": "",
        "confidence": "4;5;4;3",
        "correctness": "4;4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/R1047/Air-Decoding"
    },
    {
        "id": "VIDDZO2f0A",
        "title": "Editing Common Sense in Transformers",
        "track": "main",
        "status": "Long Main",
        "keywords": "Commonsense;Transformers;Language Models;Model Editing;GPT;Plausibility Judgements",
        "author": "",
        "aff": "University of Massachusetts Amherst; University of Pittsburgh; Allen Institute for AI",
        "rating": "",
        "confidence": "2;4;5",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/anshitag/memit_csk"
    },
    {
        "id": "VJenYElbmY",
        "title": "Addressing Linguistic Bias through a Contrastive Analysis of Academic Writing in the NLP Domain",
        "track": "main",
        "status": "Long Main",
        "keywords": "contrastive analysis;linguistic bias;lexis;morphology;syntax;cohesion",
        "author": "",
        "aff": "National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "2;5;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "VKHWtusV6H",
        "title": "DSI++: Updating Transformer Memory with New Documents",
        "track": "main",
        "status": "Long Main",
        "keywords": "Differentiable Search Index;Transformer Memory;Catastrophic Forgetting;Continual Learning;Lifelong Learning;Semi-Supervised Learning",
        "author": "",
        "aff": "Google DeepMind; Google; Carnegie Mellon University; Google Research",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "VLrtaSXOWP",
        "title": "Continual Named Entity Recognition without Catastrophic Forgetting",
        "track": "main",
        "status": "Long Main",
        "keywords": "Continual Named Entity Recognition without Catastrophic Forgetting",
        "author": "",
        "aff": "Australian Artificial Intelligence Institute, University of Technology Sydney; Baidu Inc; Shenyang Institute of Automation, Chinese Academy of Sciences; University of Chinese Academy of Sciences; Department of Computer Science, Hong Kong Baptist University",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/BladeDancer957/CPFD"
    },
    {
        "id": "VN298kRz91",
        "title": "Romanization-based Large-scale Adaptation of Multilingual Language Models",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Multilinguality;Parameter Efficiency;Transliteration",
        "author": "",
        "aff": "Language Technology Lab, University of Cambridge; Google DeepMind; Ubiquitous Knowledge Processing Lab, Department of Computer Science and Hessian Center for AI (hessian.AI), Technical University of Darmstadt",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "www.ukp.tu-darmstadt.de",
        "github": ""
    },
    {
        "id": "VQQeyiAqtv",
        "title": "Data Selection Curriculum for Abstractive Text Summarization",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Data Selection;Curriculum Learning;Abstractive Text Summarization",
        "author": "",
        "aff": "Soochow University; The Hong Kong Polytechnic University; City University of Hong Kong",
        "rating": "",
        "confidence": "4;4;4;5",
        "correctness": "3;3;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "VSBBOEUcmD",
        "title": "LLM-enhanced Self-training for Cross-domain Constituency Parsing",
        "track": "main",
        "status": "Long Main",
        "keywords": "constituency parsing",
        "author": "",
        "aff": "School of New Media and Communication, Tianjin University, China; Institute of Computing and Intelligence, Harbin Institute of Technology (Shenzhen), China; School of Engineering, Westlake University, China",
        "rating": "",
        "confidence": "4;2;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/jianlingl/LLM_ST_ConstParsing"
    },
    {
        "id": "VTWWvYtF1R",
        "title": "Reasoning with Language Model is Planning with World Model",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Model;Reasoning",
        "author": "",
        "aff": "University of Florida; UC San Diego",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Ber666/llm-reasoners"
    },
    {
        "id": "VWFKRxsgt3",
        "title": "ZeroSCROLLS: A Zero-Shot Benchmark for Long Text Understanding",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Long lexts;summarization;question answering;benchmark;zero-shot",
        "author": "",
        "aff": "Meta AI; The Blavatnik School of Computer Science, Tel Aviv University",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://www.zero.scrolls-benchmark.com/",
        "github": ""
    },
    {
        "id": "VacjehPkIU",
        "title": "Superlim: A Swedish Language Understanding Evaluation Benchmark",
        "track": "main",
        "status": "Long Main",
        "keywords": "Swedish;benchmark;large language models;natural language understanding;transfer learning;evaluation",
        "author": "",
        "aff": "AI Sweden; KBLab, National Library of Sweden; Spr\u00e5kbanken Text, University of Gothenburg; Embark Studios; iguanodon.ai; University of Gothenburg",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "5;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 4.666666666666667,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "VdvdRfwTtk",
        "title": "Background Summarization of Event Timelines",
        "track": "main",
        "status": "Long Main",
        "keywords": "text summarization;events;timelines;dataset;evaluation metrics",
        "author": "",
        "aff": "Amazon; Language Technology Institute, Carnegie Mellon University",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/amazon-science/background-summaries"
    },
    {
        "id": "VeBoHwiA7g",
        "title": "SmartSpanNER: Making SpanNER Robust in Low Resource Scenarios",
        "track": "main",
        "status": "Long Findings",
        "keywords": "SpanNER;Named Entity Head;SmartSpanNER;Multi-task Learning",
        "author": "",
        "aff": "Huawei Translation Services Center, Beijing, China",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "VecgMidd4I",
        "title": "Find-2-Find: Multitask Learning for Anaphora Resolution and Object Localization",
        "track": "main",
        "status": "Long Main",
        "keywords": "Anaphora Resolution;Object Localization",
        "author": "",
        "aff": "German Research Center for Artificial Intelligence (DFKI), Saarland Informatics; Univ. Lille, Inria, CNRS, Centrale Lille, UMR 9189 CRIStAL, F-59000 Lille, France; Universit\u00e9 de Lorraine, CNRS, Inria, LORIA, F-54000 Nancy, France",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "VgLBPLvHuK",
        "title": "Revisiting Source Context in Nearest Neighbor Machine Translation",
        "track": "main",
        "status": "Long Main",
        "keywords": "nearest neighbor machine translation; source context; retrieval-augmented machine translation",
        "author": "",
        "aff": "Institute for AI Industry Research (AIR), Tsinghua University, Beijing, China; Hubei Provincial Key Laboratory of Artificial Intelligence and Smart Learning, Central China Normal University, Wuhan, Hubei, China",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/li-xuanhong/source-context-knn-mt"
    },
    {
        "id": "VhL4lZXY1U",
        "title": "Beyond Candidates : Adaptive Dialogue Agent Utilizing Persona and Knowledge",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Dialogue System;Adaptive;Candidate-agnostic;Persona;Knowledge",
        "author": "",
        "aff": "Department of Computer Science and Engineering, Korea University",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/dlawjddn803/BeCand"
    },
    {
        "id": "VjSxQNhdKs",
        "title": "MCLF: A Multi-grained Contrastive Learning Framework for ASR-robust Spoken Language Understanding",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Spoken Language Understanding;ASR Robustness;Multi-grained Contrastive Learning;Data Augmentation",
        "author": "",
        "aff": "Peking University, China",
        "rating": "",
        "confidence": "5;3;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "VmoWVc04KY",
        "title": "Linguistic Compression in Single-Sentence Human-Written Summaries",
        "track": "main",
        "status": "Long Findings",
        "keywords": "summary writing;linguistic compression;text summarization",
        "author": "",
        "aff": "Department of Linguistics, Cornell University; Department of Information Science, Cornell University",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "VnMfQuDSgG",
        "title": "Analysis of Style-Shifting on Social Media: Using Neural Language Model Conditioned by Social Meanings",
        "track": "main",
        "status": "Long Findings",
        "keywords": "style-shifting;speech accommodation theory;neural language model",
        "author": "",
        "aff": "Graduate School of Science and Engineering, Doshisha University, Kyoto, Japan; Guardian Robot Project (GRP), RIKEN, Kyoto, Japan; Tokyo University of Science",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Vp8WwRMWfv",
        "title": "Recurrent Neural Language Models as Probabilistic Finite-state Automata",
        "track": "main",
        "status": "Long Main",
        "keywords": "Language Models;Formal Language Theory;Recurrent Neural Networks;Finite-state Automata;Minsky",
        "author": "",
        "aff": "Department of Computer Science, ETH Zurich",
        "rating": "",
        "confidence": "3;2;4",
        "correctness": "5;5;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 5.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/rycolab/weighted-minsky"
    },
    {
        "id": "VqGX02f2lS",
        "title": "On the Transferability of Visually Grounded PCFGs",
        "track": "main",
        "status": "Long Findings",
        "keywords": "unsupervised grammar induction;grounded language learning;syntactic parsing;transfer learning",
        "author": "",
        "aff": "EILCC, University of Edinburgh; ILLC, University of Amsterdam",
        "rating": "",
        "confidence": "3;3;2",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "VyIe1iVHZ4",
        "title": "TR-Rules: Rule-based Model for Link Forecasting on Temporal Knowledge Graph Considering Temporal Redundancy",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Knowledge Graph;Temporal Knowledge Graph;Link forecasting;Temporal Rules",
        "author": "",
        "aff": "National Computer Network Emergency Response Technical Team/Coordination Center of China; Lianyang Guorong (Beijing) Technology Co., Ltd.; Beijing University of Posts and Telecommunications",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/JasonLee-22/TR-Rules"
    },
    {
        "id": "VyjNXY2wgi",
        "title": "DialCoT Meets PPO: Decomposing and Exploring Reasoning Paths in Smaller Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Chain-of-Thought;PPO;Reasoning",
        "author": "",
        "aff": "Xiaobing.AI; School of Data Science and Engineering, East China Normal University; School of Software & Microelectronics, Peking University",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/hccngu/DialCoT"
    },
    {
        "id": "W0WeKrnfbX",
        "title": "A Self-enhancement Multitask Framework for Unsupervised Aspect Category Detection",
        "track": "main",
        "status": "Long Main",
        "keywords": "Sentiment Analysis;Aspect Category Detection;unsupervised learning;weakly supervised learning;Aspect-based Sentiment Analysis",
        "author": "",
        "aff": "School of Information and Communications Technology, Hanoi University of Science and Technology; VinAI Research",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "W1w2eovejY",
        "title": "Uncertainty-aware Parameter-Efficient Self-training for Semi-supervised Language Understanding",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Self-Training;Uncertainty Estimation;Pre-trained Language Models;Parameter-Efficient Learning",
        "author": "",
        "aff": "Alibaba Group; School of Data Science and Engineering, East China Normal University; KLATASDS-MOE, School of Statistics, East China Normal University",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "2;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/wjn1996/UPET"
    },
    {
        "id": "W2ka7qsx1j",
        "title": "A Diffusion Weighted Graph Framework for New Intent Discovery",
        "track": "main",
        "status": "Long Main",
        "keywords": "New Intent Discovery;Contrastive Learning;Graph Structure Learning",
        "author": "",
        "aff": "Department of Engineering, University of Massachusetts Boston; School of Automation Science and Engineering, Xi\u2019an Jiaotong University; School of Computer Science and Technology, MOEKLNNS Lab, Xi\u2019an Jiaotong University; Lenovo Research",
        "rating": "",
        "confidence": "4;3;2;3",
        "correctness": "2;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/yibai-shi/DWGF"
    },
    {
        "id": "W4GlqAnXqv",
        "title": "Frequency Balanced Datasets Lead to Better Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Language Models;word frequency;pre-training corpus;low-resource languages",
        "author": "",
        "aff": "Universitat Pompeu Fabra, Barcelona, Spain; Universitat de Barcelona, Barcelona, Spain",
        "rating": "",
        "confidence": "3;4;4;2",
        "correctness": "3;3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "W4Vk1ufh7l",
        "title": "TRIP: Accelerating Document-level Multilingual Pre-training via Triangular Document-level Pre-training on Parallel Data Triplets",
        "track": "main",
        "status": "Long Findings",
        "keywords": "multilingual pre-training; machine translation; cross-lingual summarization",
        "author": "",
        "aff": "Microsoft Corporation; The Chinese University of Hong Kong",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "W6ijeWfHFU",
        "title": "Improving Factual Consistency for Knowledge-Grounded Dialogue Systems via Knowledge Enhancement and Alignment",
        "track": "main",
        "status": "Long Findings",
        "keywords": "knowledge-grounded dialogue system;factual consistency;knowledge enhancement",
        "author": "",
        "aff": "Huawei Noah\u2019s Ark Lab; Harbin Institute of Technology, Shenzhen, China; The Chinese University of Hong Kong",
        "rating": "",
        "confidence": "4;4;3;3",
        "correctness": "3;4;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/AmourWaltz/FactDial"
    },
    {
        "id": "W76aMA1x9l",
        "title": "Detecting Erroneously Recognized Handwritten Byzantine Text",
        "track": "main",
        "status": "Long Findings",
        "keywords": "text classification;error detection;handwritten text recognition",
        "author": "",
        "aff": "Department of Philology, School of Philosophy, University of Athens, Greece; Department of Informatics, Athens University of Economics and Business, Greece; Faculty of Computer Science, University of Vienna, Austria, UniVie Doctoral School Computer Science; Department of Humanities, Ca\u2019Foscari University of Venice, Italy",
        "rating": "",
        "confidence": "5;4;2",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "WAhhZcaA3R",
        "title": "Enhancing Biomedical Lay Summarisation with External Knowledge Graphs",
        "track": "main",
        "status": "Long Main",
        "keywords": "Summarisation;Knowledge Graphs",
        "author": "",
        "aff": "College of Economics and Management, Beijing University of Technology, China; Department of Computer Science, University of Sheffield, UK; Department of Computer Science, The University of Surrey, UK; Department of Computer Science, The University of Manchester, UK",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/TGoldsack1/Enhancing_Biomedical_Lay_Summarisation_with_External_Knowledge_Graphs"
    },
    {
        "id": "WC1jbtEwRS",
        "title": "Flatness-Aware Prompt Selection Improves Accuracy and Sample Efficiency",
        "track": "main",
        "status": "Long Findings",
        "keywords": "prompt selection;flatness of prompt",
        "author": "",
        "aff": "Center for Language and Speech Processing and Computer Science Department, Johns Hopkins University, Baltimore MD",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/shadowkiller33/flatness"
    },
    {
        "id": "WC9yjSosSA",
        "title": "ESPVR: Entity Spans Position Visual Regions for Multimodal Named Entity Recognition",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multimodal named entity recognition;Local visual information;Global visual information",
        "author": "",
        "aff": "Harbin University of Science and Technology, Harbin, China",
        "rating": "",
        "confidence": "4;3;3;2",
        "correctness": "2;2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "WCxfj3PsWb",
        "title": "Multi-level Adaptive Contrastive Learning for Knowledge Internalization in Dialogue Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "knowledge-grounded dialogue generation;contrastive learning;text degeneration;pre-trained language model",
        "author": "",
        "aff": "Mohamed bin Zayed University of AI; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China; Institute of Computing Technology, CAS",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/iie-ycx/MACL"
    },
    {
        "id": "WEHwc4hSQR",
        "title": "GD-COMET: A Geo-Diverse Commonsense Inference Model",
        "track": "main",
        "status": "Short Main",
        "keywords": "commonsense reasoning;culture-aware NLP;geo-diverse applications",
        "author": "",
        "aff": "Vector Institute for AI; University of British Columbia",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "github.com/meharbhatia/GD-COMET"
    },
    {
        "id": "WLIFsPSq3t",
        "title": "Beyond Layout Embedding: Layout Attention with Gaussian Biases for Structured Document Understanding",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Structured Document Understanding;Layout Attention;Spatial Relationships;Polar Coordinates",
        "author": "",
        "aff": "JIUTIAN Team, China Mobile Research Institute, Beijing, China",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/zxilucky/LAGaBi"
    },
    {
        "id": "WLV8cm80DB",
        "title": "$\\textit{Swap and Predict}$ -- Predicting the Semantic Changes in Words across Corpora by Context Swapping",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Computational Semantics;Contextualised Word Embeddings;Semantic Change Detection",
        "author": "",
        "aff": "Amazon, University of Liverpool; Tokyo Metropolitan University",
        "rating": "",
        "confidence": "3;3;5;4",
        "correctness": "3;4;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/a1da4/svp-swap"
    },
    {
        "id": "WLZX3et7VT",
        "title": "Active Retrieval Augmented Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Retrieval Augmented Language Model;Long-form Generation;Active Retrieval",
        "author": "",
        "aff": "FAIR, Meta; Sea AI Lab; Language Technologies Institute, Carnegie Mellon University",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/jzbjyb/FLARE"
    },
    {
        "id": "WQR3xpEJRJ",
        "title": "CTQScorer: Combining Multiple Features for In-context Example Selection for Machine Translation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "few-shot prompting;machine translation;example selection",
        "author": "",
        "aff": "IIT Madras, India; Institute for Infocomm Research (I2R), A\u2217STAR, Singapore; Microsoft, India; National Institute of Information and Communications Technology, Kyoto, Japan",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "WQamRhhbsf",
        "title": "Impact of Co-occurrence on Factual Knowledge of Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Factual Knowledge;Large Language Models;Co-occurrence;Term Frequency;Data Statistics",
        "author": "",
        "aff": "KAIST",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/CheongWoong/impact_of_cooccurrence"
    },
    {
        "id": "WRYhaSrThy",
        "title": "Automatic Prompt Optimization with \"Gradient Descent\" and Beam Search",
        "track": "main",
        "status": "Long Main",
        "keywords": "LLM;Prompt;Prompt Optimization;Prompt Engineering;Optimization;Gradient Descent",
        "author": "",
        "aff": "Microsoft",
        "rating": "",
        "confidence": "2;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/microsoft/LMOps/tree/main/prompt_optimization"
    },
    {
        "id": "WVs1qhIUms",
        "title": "Empirical Study of Zero-Shot NER with ChatGPT",
        "track": "main",
        "status": "Long Main",
        "keywords": "ChatGPT;Named Entity Recognition;Zero-Shot;Reasoning;Large Language Models",
        "author": "",
        "aff": "ZJU-UIUC Institute, Zhejiang University, China; National University of Singapore, Singapore; College of Computer Science and Technology, Zhejiang University, China; ZJU-UIUC Institute, Zhejiang University, China",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Emma1066/Zero-Shot-NER-with-ChatGPT"
    },
    {
        "id": "Weszm4zCzP",
        "title": "M$^3$Seg: A Maximum-Minimum Mutual Information Paradigm for Unsupervised Topic Segmentation in ASR Transcripts",
        "track": "main",
        "status": "Short Main",
        "keywords": "Unsupervised topic segmentation;mutual information maximization/minimization;automatic-speech-recognition (ASR) transcripts structuring",
        "author": "",
        "aff": "Huawei IT Innovation and Research Center",
        "rating": "",
        "confidence": "3;1;3;5",
        "correctness": "4;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "WiKLXsWzBy",
        "title": "Don\u2019t Trust ChatGPT when your Question is not in English: A Study of Multilingual Abilities and Types of LLMs",
        "track": "main",
        "status": "Long Main",
        "keywords": "multilingual;LLM;GPT",
        "author": "",
        "aff": "Alberta Machine Intelligence Institute, Department of Computing Science, University of Alberta, Edmonton, Canada",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "WkpTWlXGHC",
        "title": "Scalable-DSC: A Structural Template Prompt Approach to Scalable Dialogue State Correction",
        "track": "main",
        "status": "Long Main",
        "keywords": "Dialogue state tracking;Error propagation;Dialogue state correction",
        "author": "",
        "aff": "Xinjiang Provincial Key Laboratory of Multi-lingual Information Technology, Urumqi, China; JD AI Research, Beijing, China; China Telecom Corporation Ltd. AI Technology Company; School of Computer Science and Technology, Xinjiang University, Urumqi, China",
        "rating": "",
        "confidence": "4;5;5",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/xjuspeech/Scalable-DSC"
    },
    {
        "id": "WmpyDkTHvI",
        "title": "Text2Tree: Aligning Text Representation to the Label Tree Hierarchy for Imbalanced Medical Classification",
        "track": "main",
        "status": "Long Findings",
        "keywords": "text mining;medical text representation;imbalanced text classification",
        "author": "",
        "aff": "School of Medicine, Zhejiang University, Hangzhou, China; Polytechnic Institute, Zhejiang University, Hangzhou, China; Department of Computer Science and Engineering, University of Notre Dame, IN, USA; College of Computer Science and Technology, Zhejiang University, Hangzhou, China; Computer Science Department, University of Illinois Urbana-Champaign, IL, USA",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "2;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/jyansir/Text2Tree"
    },
    {
        "id": "Wom397PB55",
        "title": "TheoremQA: A Theorem-driven Question Answering Dataset",
        "track": "main",
        "status": "Long Main",
        "keywords": "Language Model;Question Answering;Math;Theorem",
        "author": "",
        "aff": "University of California, Los Angeles, United States; University of Waterloo, Canada; University of California, Santa Barbara, United States",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "WuuxbObghx",
        "title": "Federated Learning of Large Language Models with Parameter-Efficient Prompt Tuning and Adaptive Optimization",
        "track": "main",
        "status": "Long Main",
        "keywords": "Federated learning;Large Language Models;Prompt tuning;Prefix tuning",
        "author": "",
        "aff": "Hithink RoyalFlush Information Network Co., Ltd., Hangzhou, Zhejiang, China; Texas Tech University, Lubbock, United States; North Carolina State University, United States; Auburn University, Auburn, United States; Boston Consulting Group, United States; Baidu Inc. Beijing, China",
        "rating": "",
        "confidence": "3;3;3;3",
        "correctness": "4;3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/llm-eff/FedPepTAO"
    },
    {
        "id": "WxxYSpsv97",
        "title": "Generating Extractive Answers: Gated Recurrent Memory Reader for Conversational Question Answering",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Conversational Question Answering;Machine Reading Comprehension;Attention",
        "author": "",
        "aff": "Du Xiaoman Financial, Beijing, China",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "2;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Wy4adj2FUJ",
        "title": "A Sequence-to-Structure Approach to Document-level Targeted Sentiment Analysis",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Aspect-based Sentiment Analysis;Document-level;Targeted Sentiment Analysis",
        "author": "",
        "aff": "School of Computer Science and Engineering, Nanjing University of Science and Technology, China; National Key Laboratory for Novel Software Technology, Nanjing University, China",
        "rating": "",
        "confidence": "4;4;3;4;4",
        "correctness": "3;4;3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.8,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/NUSTM/Doc-TSA-Seq2Struct"
    },
    {
        "id": "Wyod73NboS",
        "title": "Are Language Models Worse than Humans at Following Prompts? It's Complicated",
        "track": "main",
        "status": "Short Findings",
        "keywords": "instruction following;prompting;human study;natural language inference",
        "author": "",
        "aff": "Department of Computer Science, Brown University; Department of Philosophy, Brown University; Program in Linguistics, Brown University",
        "rating": "",
        "confidence": "4;2;2;2",
        "correctness": "4;4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Wz1jEwvpGO",
        "title": "Logic Unveils Truth, While Disguise Obscures It: Transition Logic Augmented Response Selection for Multi-Turn Dialogue",
        "track": "main",
        "status": "Long Findings",
        "keywords": "multi-turn dialogue;dialogue retrieval",
        "author": "",
        "aff": "Beijing Key Laboratory of Big Data Management and Analysis Methods, Engineering Research Center of Next-Generation Intelligent Search and Recommendation, Ministry of Education; Gaoling School of Artificial Intelligence, Renmin University of China; Peking University; Tencent AI Lab",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "X2R4yhtenj",
        "title": "Effects of Human Adversarial and Affable Samples on BERT Generalization",
        "track": "main",
        "status": "Long Findings",
        "keywords": "BERT;Generalization;Robustness in NLP",
        "author": "",
        "aff": "The University of Melbourne, Australia; RMIT University, Australia",
        "rating": "",
        "confidence": "3;2;4",
        "correctness": "2;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "X570XzeYSW",
        "title": "Task-Agnostic Low-Rank Adapters for Unseen English Dialects",
        "track": "main",
        "status": "Long Main",
        "keywords": "Low-resource;Dialects;Hypernetworks;LoRA;Cross-dialectal Alignment",
        "author": "",
        "aff": "Stanford University; Harvard University; Georgia Institute of Technology",
        "rating": "",
        "confidence": "5;3;4;2",
        "correctness": "4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "X597Q58y1U",
        "title": "Enhancing Code-Switching for Cross-lingual SLU: A Unified View of Semantic and Grammatical Coherence",
        "track": "main",
        "status": "Short Main",
        "keywords": "Cross-lingual SLU;Semantic Coherence;Grammatical Coherence",
        "author": "",
        "aff": "School of ECE, Peking University, China",
        "rating": "",
        "confidence": "3;4;4;4",
        "correctness": "4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "X6DrwxlMD9",
        "title": "Evaluating Dependencies in Fact Editing for Language Models: Specificity and Implication Awareness",
        "track": "main",
        "status": "Long Findings",
        "keywords": "knowledge editing;large language models;knowledge base",
        "author": "",
        "aff": "McGill University; Mila, McGill University",
        "rating": "",
        "confidence": "3;4;2",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/McGill-NLP/LogicalKnowEdit"
    },
    {
        "id": "X6HDI4cqWF",
        "title": "End-to-End Autoregressive Retrieval via Bootstrapping for Smart Reply Systems",
        "track": "main",
        "status": "Long Findings",
        "keywords": "dialog;smart reply;reply suggestion",
        "author": "",
        "aff": "University of Nottingham, Nokia Bell Labs; University of Nottingham",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/BenjaminTowle/STAR"
    },
    {
        "id": "XB0u7RTXrV",
        "title": "SCENE: Self-Labeled Counterfactuals for Extrapolating to Negative Examples",
        "track": "main",
        "status": "Long Main",
        "keywords": "Question Answering;Counterfactual Generation;Data Augmentation",
        "author": "",
        "aff": "University of Southern California",
        "rating": "",
        "confidence": "3;5;4",
        "correctness": "4;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "XEBHsJpFY9",
        "title": "Culturally Aware Natural Language Inference",
        "track": "main",
        "status": "Long Findings",
        "keywords": "cultural norms;natural language inference",
        "author": "",
        "aff": "Stanford University, Department of Computer Science",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "3;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/SALT-NLP/CulturallyAwareNLI"
    },
    {
        "id": "XEwQ1fDbDN",
        "title": "Examining Inter-Consistency of Large Language Models Collaboration: An In-depth Analysis via Debate",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large Language Models;Inconsistency;Debate;Commonsense Reasoning",
        "author": "",
        "aff": "Singapore Management University, Singapore; Research Center for Social Computing and Information Retrieval, Harbin Institute of Technology, China",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Waste-Wood/FORD"
    },
    {
        "id": "XHftyT3k4j",
        "title": "Enhancing Argument Structure Extraction with Efficient Leverage of Contextual Information",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Argument Mining;Argument structure extraction;Discourse Structure of Arguments",
        "author": "",
        "aff": "Pattern Recognition Center, WeChat AI, Tencent Inc, Beijing, China.; School of Engineering, Westlake University, Hangzhou, China.; School of Engineering, Westlake University, Hangzhou, China.; Institute of Advanced Technology, Westlake Institute for Advanced Study, Hangzhou, China.",
        "rating": "",
        "confidence": "5;3;3",
        "correctness": "2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "XIHl40UylS",
        "title": "STEER: Unified Style Transfer with Expert Reinforcement",
        "track": "main",
        "status": "Long Findings",
        "keywords": "style transfer;natural language generation;reinforcement learning;controllable decoding",
        "author": "",
        "aff": "Language Technologies Institute, Carnegie Mellon University; Paul G. Allen School of Computer Science & Engineering, University of Washington; Allen Institute for AI",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/shallinan1/STEERStyleTransfer"
    },
    {
        "id": "XILoK6g4va",
        "title": "Hierarchical Fusion for Online Multimodal Dialog Act Classification",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Dialog Act Classification;Multimodality;Early Fusion;Online Inference",
        "author": "",
        "aff": "Texas A&M University; University of Arizona",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "XJRNw74kXK",
        "title": "POSQA: Probe the World Models of LLMs with Size Comparisons",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Embodied language comprehension;World Model;Large Language Models;AI Alignment",
        "author": "",
        "aff": "University of Cambridge; Monash University; Google DeepMind",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/cambridgeltl/POSQA"
    },
    {
        "id": "XLXCWNNWvL",
        "title": "Training Simultaneous Speech Translation with Robust and Random Wait-k-Tokens Strategy",
        "track": "main",
        "status": "Long Main",
        "keywords": "Simultaneous Speech Translation;Robust and Random Wait-k;Cross-modal alignment",
        "author": "",
        "aff": "Alibaba DAMO Academy; Zhejiang University",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "XMpzcC9L5z",
        "title": "How Predictable Are Large Language Model Capabilities? A Case Study on BIG-bench",
        "track": "main",
        "status": "Long Findings",
        "keywords": "large language models;performance prediction;benchmarking",
        "author": "",
        "aff": "University of Southern California, Los Angeles, CA, USA",
        "rating": "",
        "confidence": "3;5;3",
        "correctness": "3;5;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/INK-USC/predicting-big-bench"
    },
    {
        "id": "XNnFTKCacy",
        "title": "Coherent Entity Disambiguation via Modeling Topic and Categorical Dependency",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Entity disambiguation;Knowledge base;Entity linking",
        "author": "",
        "aff": "Microsoft STCA; Rice University",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "XQm8tlPKgY",
        "title": "SCITAB: A Challenging Benchmark for Compositional Reasoning and Claim Verification on Scientific Tables",
        "track": "main",
        "status": "Long Main",
        "keywords": "Scientific Fact-Checking;Table Reasoning;Compositional Reasoning;Dataset",
        "author": "",
        "aff": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "XT1hoHqs12",
        "title": "ReadPrompt: A Readable Prompting Method for Reliable Knowledge Probing",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Prompt;Pre-trained Language Model;Readability;Knowledge Probing;Fact Retrieval;LAMA Dataset.",
        "author": "",
        "aff": "The Chinese University of Hong Kong, Hong Kong, China; MoE Key Laboratory of High Confidence Software Technologies, China; Central China Normal University, Wuhan, China",
        "rating": "",
        "confidence": "1;3;4",
        "correctness": "4;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/XM-WANG/ReadPrompt"
    },
    {
        "id": "XW4t7P2hpN",
        "title": "Shall We Pretrain Autoregressive Language Models with Retrieval? A Comprehensive Study",
        "track": "main",
        "status": "Long Main",
        "keywords": "large language model;pretraining;retrieval augmentation;retro;knowledge retrieval",
        "author": "",
        "aff": "NVIDIA; UIUC; University of Wisconsin, Madison",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/NVIDIA/Megatron-LM#retro"
    },
    {
        "id": "XX73vFMemG",
        "title": "Co-training and Co-distillation for Quality Improvement and Compression of Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Knowledge Distillation",
        "author": "",
        "aff": "Meta AI; KAIST; Abridge AI",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "XbcprEi57p",
        "title": "Referring Image Segmentation via Joint Mask Contextual Embedding Learning and Progressive Alignment Network",
        "track": "main",
        "status": "Long Main",
        "keywords": "segmentation;multi-modality",
        "author": "",
        "aff": "The University of Tokyo; National Institute of Informatics, Japan",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "XcNXOVhNlN",
        "title": "Reasoning Makes Good Annotators : An Automatic Task-specific Rules Distilling Framework for Low-resource Relation Extraction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "relation extraction;language model;rule mining and pattern mining",
        "author": "",
        "aff": "Zhejiang University; Universit\u00e9 de Montr\u00e9al",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "4;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "XclSRY9Wp8",
        "title": "Modeling Conceptual Attribute Likeness and Domain Inconsistency for Metaphor Detection",
        "track": "main",
        "status": "Long Main",
        "keywords": "Metaphor detection;Attribute likeness;Attribute siamese network;Conceptual metaphor theory",
        "author": "",
        "aff": "Institute of Automation, Chinese Academy of Sciences; School of Artificial Intelligence, University of Chinese Academy of Sciences; Institute of Automation, Chinese Academy of Sciences; Beijing Wenge Technology Co., Ltd",
        "rating": "",
        "confidence": "4;2;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Xd2A31vcLd",
        "title": "ReSee: Responding through Seeing Fine-grained Visual Knowledge in Open-domain Dialogue",
        "track": "main",
        "status": "Long Main",
        "keywords": "visual dialogue;multimodal dataset;knowledge-enhanced dialogue;pre-trained language model",
        "author": "",
        "aff": "University of Chinese Academy of Sciences; Huawei Technologies Ltd.; Beijing University of Post and Telecommunications; Huawei Noah\u2019s Ark Lab",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ImKeTT/ReSee"
    },
    {
        "id": "XhR6ebeEXo",
        "title": "Good Meta-tasks Make A Better Cross-lingual Meta-transfer Learning for Low-resource Languages",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Few-shot Cross-lingual Transfer Learning;Low-resource Languages;Model-agnostic Meta-learning",
        "author": "",
        "aff": "Alibaba International Digital Commerce Group, China; College of Computer Science and Technology, Zhejiang University; Alibaba Group, China",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/wulinjuan/MeTaCo-XMT"
    },
    {
        "id": "XjwNxSE0v8",
        "title": "Learning Easily Updated General Purpose Text Representations with Adaptable Task-Specific Prefix",
        "track": "main",
        "status": "Short Findings",
        "keywords": "text representations;prefix tuning",
        "author": "",
        "aff": "University of California, Los Angeles; Meta AI",
        "rating": "",
        "confidence": "4;4;3;3",
        "correctness": "4;4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "XkexLrJDss",
        "title": "Exploring the Potential of Large Language Models in Generating Code-Tracing Questions for Introductory Programming Courses",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Large Language Model;Natural Language Processing;Computer Science Education;Novice Programming",
        "author": "",
        "aff": "University of Illinois at Urbana-Champaign; Penn State University",
        "rating": "",
        "confidence": "5;5;3",
        "correctness": "4;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/aysafanxm/llm_code_tracing_question_generation"
    },
    {
        "id": "XlIrJUKTgS",
        "title": "Improving Seq2Seq Grammatical Error Correction via Decoding Interventions",
        "track": "main",
        "status": "Long Findings",
        "keywords": "grammatical error correction;decoding;sequence-to-sequence;seq2seq",
        "author": "",
        "aff": "Institute of Artificial Intelligence, School of Computer Science and Technology, Soochow University, China; DAMO Academy, Alibaba Group, China",
        "rating": "",
        "confidence": "5;3;3;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "XmS9J3Lvip",
        "title": "Towards Formality-Aware Neural Machine Translation by Leveraging Context Information",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Neural Machine Translation;Context-Aware Translation;Formality-Aware Translation;Formality Control",
        "author": "",
        "aff": "KAIST AI",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "XpK2LCt8iM",
        "title": "Turn-Level Active Learning for Dialogue State Tracking",
        "track": "main",
        "status": "Long Main",
        "keywords": "dialogue state tracking;active learning;data annotation",
        "author": "",
        "aff": "University of Wollongong; University of Liverpool; University of Technology Sydney; University College London",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/hyintell/AL-DST"
    },
    {
        "id": "Xqhdpk0Qrj",
        "title": "GLEN: Generative Retrieval via Lexical Index Learning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Generative retrieval;Document retrieval;Lexical index",
        "author": "",
        "aff": "Sungkyunkwan University, Republic of Korea",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;5;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/skleee/GLEN"
    },
    {
        "id": "Xt1JbFofwP",
        "title": "TabPrompt: Graph-based Pre-training and Prompting for Few-shot Table Understanding",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Table Understanding;Prompt-based Learning;Graph Contrastive Learning;Graph Neural Network",
        "author": "",
        "aff": "Alibaba Group; School of Computer Science and Engineering, Southeast University, Nanjing, China; Key Laboratory of New Generation Artificial Intelligence Technology and Its Interdisciplinary Applications (Southeast University), Ministry of Education, China",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "XtlquCY7qs",
        "title": "MADNet: Maximizing Addressee Deduction Expectation for Multi-Party Conversation Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Dialogue System;Multi-Party Conversation;Addressee Deduction;Latent Edge;Expectation-Maximization",
        "author": "",
        "aff": "iFLYTEK Research, Hefei, China; National Engineering Research Center of Speech and Language Information Processing, University of Science and Technology of China, Hefei, China; Peking University, Beijing, China",
        "rating": "",
        "confidence": "4;3;4;4;3",
        "correctness": "4;4;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6,
        "correctness_avg": 3.8,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "XySNnzF9Ir",
        "title": "Automatic Evaluate Dialogue Appropriateness by Using Dialogue Act",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Automatic Dialogue System Evaluation; Dialogue Evaluation; Dialogue System",
        "author": "",
        "aff": "School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China; School of Computer Science and Engineering, Beihang University, Beijing, 100191, China",
        "rating": "",
        "confidence": "3;3;4;4",
        "correctness": "3;2;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/xba0/DAA"
    },
    {
        "id": "XySq36VD0U",
        "title": "A Lightweight Method to Generate Unanswerable Questions in English",
        "track": "main",
        "status": "Short Findings",
        "keywords": "extractive question answering;machine reading comprehension;data augmentation",
        "author": "",
        "aff": "Saarland Informatics Campus, Saarland University",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "3;4;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Xyb8Qh6vxU",
        "title": "A Comprehensive Evaluation of Large Language Models on Legal Judgment Prediction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Language Model;Law;Legal Judgment Prediction;Large Language Model;Language Model Evaluation",
        "author": "",
        "aff": "University of Science and Technology of China; National University of Singapore; Singapore Management University",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/srhthu/LM-CompEval-Legal"
    },
    {
        "id": "Xyy1p1IGvn",
        "title": "Semantic matching for text classification with complex class descriptions",
        "track": "main",
        "status": "Long Main",
        "keywords": "natural language processing;few-shot learning;zero-shot learning;semantic matching",
        "author": "",
        "aff": "Amazon",
        "rating": "",
        "confidence": "3;1;4",
        "correctness": "5;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Y0PN9Eic8T",
        "title": "Dynamic Stashing Quantization for Efficient Transformer Training",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Transformer;Training;Dynamic Stashing Quantization",
        "author": "",
        "aff": "Imperial College London, London, UK; University of Cambridge, Cambridge, UK; Microsoft Research, Redmond, Washington, USA",
        "rating": "",
        "confidence": "3;3;4;2",
        "correctness": "4;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Y13EvAJlhQ",
        "title": "Instructive Dialogue Summarization with Query Aggregations",
        "track": "main",
        "status": "Long Main",
        "keywords": "Dialogue Summarization;Query-based Dialogue Summarizaiton;Dialogue Reading Comprehension",
        "author": "",
        "aff": "Institute for Infocomm Research (I2R), A*STAR, Singapore",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Y28GzovPql",
        "title": "RoBoCoP: A Comprehensive ROmance BOrrowing COgnate Package and Benchmark for Multilingual Cognate Identification",
        "track": "main",
        "status": "Long Main",
        "keywords": "cognates;borrowings;historical lingusitics;database;romance languages;language resources;lexicon",
        "author": "",
        "aff": "University of Bucharest, Faculty of Mathematics and Computer Science; University of Bucharest, Faculty of Foreign Languages and Literatures; University of Bucharest, HLT Research Center",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Y2wUa9n7sr",
        "title": "VISTA: Visual-Textual Knowledge Graph Representation Learning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Knowledge Graph;Multimodality;Representation Learning;Knowledge Graph Completion;Transformer",
        "author": "",
        "aff": "School of Computing, KAIST",
        "rating": "",
        "confidence": "3;4;5;3;3;2;3",
        "correctness": "3;2;5;3;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.2857142857142856,
        "correctness_avg": 3.142857142857143,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Y30NTg87od",
        "title": "Implicit Sense-labeled Connective Recognition as Text Generation",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Implicit Discourse Relation Recognition;Implicit Sense-labeled Connective Recognition;Encoder-Decoder;PDTB-3.0",
        "author": "",
        "aff": "NTT Communication Science Laboratories, NTT Corporation",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Y6w2prqvjM",
        "title": "On the Challenges of Using Black-Box APIs for Toxicity Evaluation in Research",
        "track": "main",
        "status": "Long Main",
        "keywords": "toxicity;black-box API;HELM;evaluation;Real Toxicity Prompts;benchmarking",
        "author": "",
        "aff": "Cohere For AI; Cohere For AI, School of Electrical and Computer Engineering and the Artificial Intelligence Lab, Recod.ai, University of Campinas (UNICAMP); Cohere",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/for-ai/black-box-api-challenges"
    },
    {
        "id": "Y7Wx7usMtc",
        "title": "Natural Disaster Tweets Classification Using Multimodal Data",
        "track": "main",
        "status": "Long Main",
        "keywords": "Multimodal Data;Multi task learning;NLP of Social Media data;AI for social good",
        "author": "",
        "aff": "Department of Computer Engineering, Jamia Millia Islamia, India; Department of Electronics and Communication Engineering, IIIT-Delhi, India; King Abdullah University of Science and Technology, Saudi Arabia",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Y7kK2HcxDK",
        "title": "GDA: Grammar-based Data Augmentation for Text Classification using Slot Information",
        "track": "main",
        "status": "Long Findings",
        "keywords": "data augmentation;rules of grammar;text classification",
        "author": "",
        "aff": "Yonsei University; Kangwon National University; University of Seoul",
        "rating": "",
        "confidence": "3;3;3;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "YGK9cd0bHz",
        "title": "WiCE: Real-World Entailment for Claims in Wikipedia",
        "track": "main",
        "status": "Long Main",
        "keywords": "natural language inference;textual entailment;fact-checking",
        "author": "",
        "aff": "Department of Computer Science, The University of Texas at Austin; Applied Research Laboratories, The University of Texas at Austin",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ryokamoi/wice"
    },
    {
        "id": "YGUUT6CkbB",
        "title": "StrAE: Autoencoding for Pre-Trained Embeddings using Explicit Structure",
        "track": "main",
        "status": "Long Main",
        "keywords": "NLP;Representation Learning;Structure;Semantics;Syntax;Induction;Composition",
        "author": "",
        "aff": "The Alan Turing Institute, UK; University of Edinburgh, UK",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "YGYaxZVsJK",
        "title": "Pseudointelligence: A Unifying Lens on Language Model Evaluation",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Evaluation;Large Language Models;Learning Theory;Computational Complexity",
        "author": "",
        "aff": "Stanford University; MIT; UC Berkeley",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "YHWXlESeS8",
        "title": "Have LLMs Advanced Enough? A Challenging Problem Solving Benchmark For Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Reasoning;Large Language Model;Benchmark;Problem Solving",
        "author": "",
        "aff": "IIT Delhi; Microsoft Research; UC Berkeley",
        "rating": "",
        "confidence": "3;4;5",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "YJMUVwLcEi",
        "title": "Lexical Repetitions Lead to Rote Learning: Unveiling the Impact of Lexical Overlap in Train and Test Reference Summaries",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Lexical Diversity;Summarization;Data-Centric AI",
        "author": "",
        "aff": "Salesforce AI Research",
        "rating": "",
        "confidence": "3;2;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "YKKcbwztwH",
        "title": "Parameter-Efficient Cross-lingual Transfer of Vision and Language Models via Translation-based Alignment",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Cross-lingual Transfer;Vision and Language;Parameter Efficiency",
        "author": "",
        "aff": "UC Santa Cruz; UC Santa Barbara",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/eric-ai-lab/PECTVLM"
    },
    {
        "id": "YMlYb8cWgE",
        "title": "RECAL: Sample-Relation Guided Confidence Calibration over Tabular Data",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Confidence Calibration;Tabular Data;Element-Wise Temperature Scaling",
        "author": "",
        "aff": "School of Computer Science and Engineering, Sun Yat-Sen University; College of Software, Nankai University; Tencent AI Lab",
        "rating": "",
        "confidence": "3;2;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "YN6FtojPxD",
        "title": "Quantifying the Dialect Gap and its Correlates Across Languages",
        "track": "main",
        "status": "Long Findings",
        "keywords": "dialect gap;machine translation;automatic speech recognition;performance correlation;multilingual",
        "author": "",
        "aff": "Language Technology Lab, University of Cambridge",
        "rating": "",
        "confidence": "5;4;4;2",
        "correctness": "3;4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "YO2VZBcinK",
        "title": "Topic-DPR: Topic-based Prompts for Dense Passage Retrieval",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Continuous Prompt;Dense Passage Retrieval;Topic Modeling",
        "author": "",
        "aff": "South China Normal University; The Hong Kong University of Science and Technology, The Hong Kong University of Science and Technology (Guangzhou)",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "YQzgk43sFB",
        "title": "Entity Disambiguation on a Tight Labeling Budget",
        "track": "main",
        "status": "Short Findings",
        "keywords": "entity linking;learning under a budget;tensor bilinear model",
        "author": "",
        "aff": "Universitat Polit\u00e8cnica de Catalunya / Barcelona, Spain",
        "rating": "",
        "confidence": "3;2;2",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "YSWLs0G5va",
        "title": "Joint Entity and Relation Extraction with Span Pruning and Hypergraph Neural Networks",
        "track": "main",
        "status": "Long Main",
        "keywords": "Entity and Relation Extraction;high-order inference;hypergraph neural network",
        "author": "",
        "aff": "MIT CSAIL; School of Information Science and Technology, ShanghaiTech University; Shanghai Engineering Research Center of Intelligent Vision and Imaging",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/yanzhh/HGERE"
    },
    {
        "id": "YTo9KGNZ3U",
        "title": "Measuring and Mitigating Constraint Violations of In-Context Learning for Utterance-to-API Semantic Parsing",
        "track": "main",
        "status": "Long Findings",
        "keywords": "executable semantic parsing;task-oriented semantic parsing;utterance-to-API generation;in-context learning",
        "author": "",
        "aff": "WS AI Labs; University of Massachusetts, Amherst",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "YWbEDZh5ga",
        "title": "On Robustness of Finetuned Transformer-based NLP Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Transformers;Language Models;finetuning;Perturbations;Robustness;Representation Similarity;CKA;STIR",
        "author": "",
        "aff": "IIIT Hyderabad, India; Microsoft, India; NIT Warangal, India; IIIT Hyderabad, India; INRIA, Bordeaux, France",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/PavanNeerudu/Robustness-of-Transformers-models"
    },
    {
        "id": "YZJ3oewPcu",
        "title": "Language Model Quality Correlates with Psychometric Predictive Power in Multiple Languages",
        "track": "main",
        "status": "Short Main",
        "keywords": "Cognitive Modeling;Language Models;Eye Tracking Data;Cross-linguistic Analysis",
        "author": "",
        "aff": "ETH Z\u00fcrich; University of Cambridge",
        "rating": "",
        "confidence": "5;4;5",
        "correctness": "5;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/rycolab/quality-power-hypothesis"
    },
    {
        "id": "YaxyQwG2TP",
        "title": "Content- and Topology-Aware Representation Learning for Scientific Multi-Literature",
        "track": "main",
        "status": "Long Main",
        "keywords": "Representation Learning;Graph-Text Joint Learning;Wasserstein Distance",
        "author": "",
        "aff": "Worcester Polytechnic Institute, Worcester, USA; Alibaba Group, Hangzhou, China",
        "rating": "",
        "confidence": "4;2;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/MatthewKKai/SMRC2"
    },
    {
        "id": "YbCkHTqZGn",
        "title": "Faithful Model Evaluation for Model-Based Metrics",
        "track": "main",
        "status": "Short Main",
        "keywords": "Evaluation;Model-Based Metrics",
        "author": "",
        "aff": "Amazon Alexa AI",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Yg5uDwWQti",
        "title": "Beat LLMs at Their Own Game: Zero-Shot LLM-Generated Text Detection via Querying ChatGPT",
        "track": "main",
        "status": "Short Main",
        "keywords": "LLM-generated text detection;large language model",
        "author": "",
        "aff": "School of Software, Tsinghua University, China; University of Illinois Urbana-Champaign, USA; Zhejiang University, China; Department of Computer Science and Technology, Tsinghua University, China",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/thunlp/LLM-generated-text-detection"
    },
    {
        "id": "YiITnAhKQd",
        "title": "Somali Information Retrieval Corpus: Bridging the Gap between Query Translation and Dedicated Language Resources",
        "track": "main",
        "status": "Short Main",
        "keywords": "Somali language;low-resource;information retrieval",
        "author": "",
        "aff": "University of Electronic Science and Technology of China, Chengdu, Sichuan, China; Kashi Institute of Electronics and Information Industry, Kashi, Xinjiang, China; University of Electronic Science and Technology of China, Chengdu, Sichuan, China",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "YivRtscaFW",
        "title": "Universal Self-Adaptive Prompting",
        "track": "main",
        "status": "Long Main",
        "keywords": "large language models;prompting;zero-shot;in-context learning",
        "author": "",
        "aff": "Google; Google, University of Oxford",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "YllS5zEzVq",
        "title": "Probing LLMs for Joint Encoding of Linguistic Categories",
        "track": "main",
        "status": "Long Findings",
        "keywords": "language model;transformer;interpretability;probing;syntax;pos;dependency;multilingual",
        "author": "",
        "aff": "Institute for Logic, Language and Computation, University of Amsterdam",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Ynxo6lene2",
        "title": "Symbolic Planning and Code Generation for Grounded Dialogue",
        "track": "main",
        "status": "Long Main",
        "keywords": "dialogue;information;planning;code;grounding",
        "author": "",
        "aff": "Cornell University; Carnegie Mellon University; Cornell Tech; Columbia University",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "YoKptDpMtt",
        "title": "Effects of sub-word segmentation on performance of transformer language models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Language modeling;Natural language processing;Morphological segmentation",
        "author": "",
        "aff": "Department of Digital Humanities, University of Helsinki, Finland; Department of Computer Science, University of Helsinki, Finland",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "YokfK5VOoz",
        "title": "Copyright Violations and Large Language Models",
        "track": "main",
        "status": "Short Main",
        "keywords": "language models;copyright;NLP;LLMs",
        "author": "",
        "aff": "University of Electronic Science and Technology of China; Department of Computer Science, University of Copenhagen",
        "rating": "",
        "confidence": "4;2;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/coastalcph/CopyrightLLMs"
    },
    {
        "id": "Yt4QAWQJ2o",
        "title": "Stylized Dialogue Generation with Feature-Guided Knowledge Augmentation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Stylized Dialogue Generation;Knowledge Augmentation;Feature-guided Selection",
        "author": "",
        "aff": "Gaoling School of Artifical Intelligence, Renmin University of China; State Key Laboratory of Media Convergence Production Technology and Systems, Institute for Artificial Intelligence, Peking University; King Abdullah University of Science and Technology; Wangxuan Institute of Computer Technology, Peking University",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ZekaiGalaxy/KASDG"
    },
    {
        "id": "YvzA0hFCF3",
        "title": "A Challenging Multimodal Video Summary: Simultaneously Extracting and Generating Keyframe-Caption Pairs from Video",
        "track": "main",
        "status": "Long Main",
        "keywords": "Video Summarization;Multimodality",
        "author": "",
        "aff": "Tohoku University; LY Corporation",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "5;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/keitokudo/Multi-VidSum"
    },
    {
        "id": "Yz4VKLeZMG",
        "title": "From Heuristic to Analytic: Cognitively Motivated Strategies for Coherent Physical Commonsense Reasoning",
        "track": "main",
        "status": "Long Main",
        "keywords": "commonsense reasoning;physical commonsense;language model analysis;cognitive modeling",
        "author": "",
        "aff": "LG AI Research; University of Michigan; University of Michigan, LG AI Research",
        "rating": "",
        "confidence": "4;4;3;3",
        "correctness": "4;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Yzi6LM20E2",
        "title": "Two Directions for Clinical Data Generation with Large Language Models: Data-to-Label and Label-to-Data",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large language model;clinical text processing;Alzheimer's Disease;data augmentation",
        "author": "",
        "aff": "Umass Amherst, V A Bedford Healthcare System, Umass Lowell; Microsoft",
        "rating": "",
        "confidence": "2;5;3",
        "correctness": "2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Z1wGHeHBrk",
        "title": "VIPHY: Probing \u201cVisible\u201d Physical Commonsense Knowledge",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Commonsense;Evaluation;Vision-Language Model",
        "author": "",
        "aff": "University of Southern California",
        "rating": "",
        "confidence": "3;4;3;3",
        "correctness": "3;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/luka-group/ViPhy"
    },
    {
        "id": "Z2JBNkaJ7k",
        "title": "CiteBench: A Benchmark for Scientific Citation Text Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "related work generation;citation text generation;scientific document processing;multi-document summarization;summarization;benchmark;evaluation",
        "author": "",
        "aff": "Link\u00f6ping University; IBM Research Europe - Ireland; UKP Lab, Department of Computer Science and Hessian Center for AI (hessian.AI), Technical University of Darmstadt",
        "rating": "",
        "confidence": "5;5;4",
        "correctness": "4;3;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/UKPLab/citebench"
    },
    {
        "id": "Z5VthlliRt",
        "title": "A Study on Accessing Linguistic Information in Pre-Trained Language Models by Using Prompts",
        "track": "main",
        "status": "Short Main",
        "keywords": "prompting for linguistic information;morphology;morphological features",
        "author": "",
        "aff": "Center for Information and Language Processing, LMU Munich, Germany; Munich Center for Machine Learning, Germany; Center for Information and Language Processing, LMU Munich, Germany",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Z65Wq2dvxB",
        "title": "Speak, Memory: An Archaeology of Books Known to ChatGPT/GPT-4",
        "track": "main",
        "status": "Long Main",
        "keywords": "membership inference;memorization;cultural analytics;large language models",
        "author": "",
        "aff": "University of California, Berkeley; Emory University",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Z7O1kA3pjB",
        "title": "Summarizing Multiple Documents with Conversational Structure for Meta-Review Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multi-document Summarization;Text Generation;Multi-task Learning;Meta-review Generation;Inter-document Relationships",
        "author": "",
        "aff": "School of Computing and Information Systems, The University of Melbourne; School of Computing and Information Systems, The University of Melbourne; Language Technologies Institute, Carnegie Mellon University",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/oaimli/PeerSum"
    },
    {
        "id": "Z8p4FX15fa",
        "title": "Simple Temporal Adaptation to Changing Label Sets: Hashtag Prediction via Dense KNN",
        "track": "main",
        "status": "Short Main",
        "keywords": "Retrieval Based Models;Ethics;Deletion;Temporal Adaptation;non-parametric",
        "author": "",
        "aff": "Twitter; University of California San Diego; Carnegie Mellon University; LatinX in AI",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "ZAHyZ3CBds",
        "title": "JointMatch: A Unified Approach for Diverse and Collaborative Pseudo-Labeling to Semi-Supervised Text Classification",
        "track": "main",
        "status": "Long Main",
        "keywords": "Semi-supervised learning;text classification;pseudo-labeling;adaptive local thresholding;cross-labeling;weighted disagreement and agreement update.",
        "author": "",
        "aff": "Computer Science, University of Illinois Chicago",
        "rating": "",
        "confidence": "5;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/HenryPengZou/JointMatch"
    },
    {
        "id": "ZB66oX17CQ",
        "title": "A Fine-Grained Taxonomy of Replies to Hate Speech",
        "track": "main",
        "status": "Long Main",
        "keywords": "counterspeech;hate speech;taxonomy",
        "author": "",
        "aff": "TAMS, University of North Texas; University of Arizona; University of North Texas",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "ZBi4ijmOzs",
        "title": "End-to-End Single-Channel Speaker-Turn Aware Conversational Speech Translation",
        "track": "main",
        "status": "Long Main",
        "keywords": "speech translation;conversation;speaker-turn detection",
        "author": "",
        "aff": "Idiap Research Institute & EPFL; AWS AI Labs",
        "rating": "",
        "confidence": "3;4;5;3;4;4",
        "correctness": "4;4;3;3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.8333333333333335,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/amazon-science/stac-speech-translation"
    },
    {
        "id": "ZE6fN4OO18",
        "title": "Leveraging Multiple Teachers for Test-Time Adaptation of Language-Guided Classifiers",
        "track": "main",
        "status": "Long Findings",
        "keywords": "test-time adaptation;learning from language;data programming",
        "author": "",
        "aff": "Department of Computer Science, UNC Chapel Hill; Department of Computer Science and Engineering, Texas A&M University",
        "rating": "",
        "confidence": "3;2;2",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/WeiKangda/TALC.git"
    },
    {
        "id": "ZF8Ye9xWZc",
        "title": "RoMQA: A Benchmark for Robust, Multi-evidence, Multi-answer Question Answering",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Question answering",
        "author": "",
        "aff": "Meta AI; University of Washington, Meta AI",
        "rating": "",
        "confidence": "4;1;3",
        "correctness": "4;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "ZJrEDp19kC",
        "title": "Visually Grounded Continual Language Learning with Selective Specialization",
        "track": "main",
        "status": "Long Findings",
        "keywords": "continual learning;lifelong learning;vision-language;language grounding",
        "author": "",
        "aff": "University of Hamburg",
        "rating": "",
        "confidence": "3;4;3;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ky-ah/selective-lilac"
    },
    {
        "id": "ZJua8VeHCh",
        "title": "OssCSE: Overcoming Surface Structure Bias in Contrastive Learning for Unsupervised Sentence Embedding",
        "track": "main",
        "status": "Long Main",
        "keywords": "Unsupervised Sentence Embedding;Contrastive Learning",
        "author": "",
        "aff": "Duke University; Queen\u2019s University; Bytedance; Zhejiang University; Amazon",
        "rating": "",
        "confidence": "5;4;4;3",
        "correctness": "4;3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "ZNQh02cCxt",
        "title": "Enhancing Abstractiveness of Summarization Models through Calibrated Distillation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "abstractive summarization;knowledge distillation",
        "author": "",
        "aff": "AWS AI Labs",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://c1kj.short.gy/discal"
    },
    {
        "id": "ZQV5iRPAua",
        "title": "Evaluating Verifiability in Generative Search Engines",
        "track": "main",
        "status": "Long Findings",
        "keywords": "generative;search;engines;verifiability",
        "author": "",
        "aff": "Computer Science Department, Stanford University",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "ZQrRDCxfhW",
        "title": "Task-Attentive Transformer Architecture for Continual Learning of Vision-and-Language Tasks Using Knowledge Distillation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multimodal Learning;Continual Learning;Catastrophic forgetting",
        "author": "",
        "aff": "University of Southern California",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/YuliangCai2022/TAM-CL.git"
    },
    {
        "id": "ZSHcpMXWxX",
        "title": "DUMB: A Dutch Model Benchmark",
        "track": "main",
        "status": "Long Main",
        "keywords": "Dutch;Benchmark;GLUE;Evaluation;Language Models",
        "author": "",
        "aff": "University of Groningen, The Netherlands",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "dumbench.nl",
        "github": ""
    },
    {
        "id": "ZT3yJWAsrq",
        "title": "'Person' == Light-skinned, Western Man, and Sexualization of Women of Color: Stereotypes in Stable Diffusion",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Stable Diffusion;text-to-image generation;representation;bias;stereotypes;sexualization;national identity;nonbinary gender",
        "author": "",
        "aff": "University of Washington, Seattle",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "ZTM90jlGAm",
        "title": "Sentiment Analysis on Streaming User Reviews via Dual-Channel Dynamic Graph Neural Network",
        "track": "main",
        "status": "Long Main",
        "keywords": "Sentiment Analysis; Streaming User Reviews; Dynamic Graph Neural Network; Online Review Websites",
        "author": "",
        "aff": "School of Computer Science and Engineering, Key Laboratory of Computer Network and Information Integration, Ministry of Education, Southeast University, China",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "ZVy8L79f5f",
        "title": "Linking Surface Facts to Large-Scale Knowledge Graphs",
        "track": "main",
        "status": "Long Main",
        "keywords": "information extraction;fact linking;knowledge graphs;open information extraction",
        "author": "",
        "aff": "CAIDAS, University of W\u00fcrzburg, W\u00fcrzburg, Germany; NEC Laboratories Europe, Heidelberg, Germany; CAIR, Ss. Cyril and Methodius University, Skopje, North Macedonia; NEC Laboratories Europe, Heidelberg, Germany; NEC Laboratories Europe, Heidelberg, Germany; KU Leuven, Leuven, Belgium",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/nec-research/fact-linking"
    },
    {
        "id": "ZWpJFq6RRU",
        "title": "Accented Speech Recognition With Accent-specific Codebooks",
        "track": "main",
        "status": "Long Main",
        "keywords": "accented speech recognition;cross-attention;codebooks;conformer;domain adaptation",
        "author": "",
        "aff": "Indian Institute of Science, Bangalore, India; Indian Institute of Technology Bombay, Mumbai, India",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "ZZ3PL3qT9f",
        "title": "Causal Document-Grounded Dialogue Pre-training",
        "track": "main",
        "status": "Long Main",
        "keywords": "Document-grounded dialogue;task specific pretraining;causal effect",
        "author": "",
        "aff": "Alibaba Group; The Hong Kong University of Science and Technology",
        "rating": "",
        "confidence": "1;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "Ze2IIzaSF3",
        "title": "HiddenTables and PyQTax: A Cooperative Game and Dataset For TableQA to Ensure Scale and Data Privacy Across a Myriad of Taxonomies",
        "track": "main",
        "status": "Long Main",
        "keywords": "table question answering;dataset;large language models;data privacy;agents;cooperative game",
        "author": "",
        "aff": "J.P. Morgan AI Research, New York, NY, USA",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "ZgJSDBU3px",
        "title": "CaseEncoder: A Knowledge-enhanced Pre-trained Model for Legal Case Encoding",
        "track": "main",
        "status": "Long Main",
        "keywords": "Legal case retrieval;pre-trained language model;knowledge",
        "author": "",
        "aff": "Quan Cheng Laboratory, Institute for Internet Judiciary, DCST, Tsinghua University; Quan Cheng Laboratory, DCST, Tsinghua University, Institute for Internet Judiciary, Tsinghua University; Huawei Cloud BU, Shenzhen, Guangdong, China",
        "rating": "",
        "confidence": "2;5;3",
        "correctness": "3;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/myx666/CaseEncoder"
    },
    {
        "id": "ZhZFUOV5hb",
        "title": "Auto Search Indexer for End-to-End Document Retrieval",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Document Retrieval;Generative Retrieval;End to End",
        "author": "",
        "aff": "STCA, Microsoft Corporation",
        "rating": "",
        "confidence": "4;3;4;3",
        "correctness": "4;3;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "ZjWkQz9qXn",
        "title": "Query-based Image Captioning from Multi-context 360\u00b0 Images",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Image Captioning;360-degree image;Vision and Language",
        "author": "",
        "aff": "Tokyo Institute of Technology; RIKEN AIP; ATR",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "ZjfclaOF7M",
        "title": "UniMath: A Foundational and Multimodal Mathematical Reasoner",
        "track": "main",
        "status": "Short Main",
        "keywords": "Multimodal Math Reasoning;Math Word Problem Solving;Geometry Problem Solving",
        "author": "",
        "aff": "Hong Kong University of Science and Technology; University of Notre Dame",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "ZkR2bWvRpZ",
        "title": "Prompt-Based Monte-Carlo Tree Search for Goal-oriented Dialogue Policy Planning",
        "track": "main",
        "status": "Short Main",
        "keywords": "Prompting;MCTS;Dialogue Policy Planning",
        "author": "",
        "aff": "Department of Computer Science, Columbia University, New York, NY",
        "rating": "",
        "confidence": "3;2;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/jasonyux/GDPZero"
    },
    {
        "id": "Zlm7F7g9FK",
        "title": "NLI4CT: Multi-Evidence Natural Language Inference for Clinical Trial Reports",
        "track": "main",
        "status": "Long Main",
        "keywords": "NLI;Clinical Trial;Textual entailment;Evidence retrieval;NLP",
        "author": "",
        "aff": "Department of Computer Science, University of Manchester, United Kingdom; Department of Computer Science, University of Manchester, United Kingdom; Digital Experimental Cancer Medicine Team, Cancer Research UK Manchester Institute; Idiap Research Institute, Switzerland; Department of Computer Science, University of Manchester, United Kingdom; Digital Experimental Cancer Medicine Team, Cancer Research UK Manchester Institute; Digital Experimental Cancer Medicine Team, Cancer Research UK Manchester Institute; Idiap Research Institute, Switzerland",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "CodaLab",
        "github": "GitHub1"
    },
    {
        "id": "ZskD7TlNVZ",
        "title": "Translating away Translationese without Parallel Data",
        "track": "main",
        "status": "Long Main",
        "keywords": "Translationese Mitigation;Text Style Transfer;Unsupervised Training;Bias Mitigation",
        "author": "",
        "aff": "Saarland University, German Research Center for Artificial Intelligence (DFKI); Saarland University, AppTek GmbH; German Research Center for Artificial Intelligence (DFKI); Saarland University",
        "rating": "",
        "confidence": "3;2;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "ZsuPbCxPnA",
        "title": "Non-autoregressive Text Editing with Copy-aware Latent Alignments",
        "track": "main",
        "status": "Long Main",
        "keywords": "text generation;text editing;grammatical error correction;sentence fusion",
        "author": "",
        "aff": "Tencent AI Lab; Institute of Artificial Intelligence, School of Computer Science and Technology, Soochow University, Suzhou, China",
        "rating": "",
        "confidence": "3;4;1",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/yzhangcs/ctc-copy"
    },
    {
        "id": "a0yFO9gKc5",
        "title": "Benchmarking and Improving Text-to-SQL Generation under Ambiguity",
        "track": "main",
        "status": "Long Main",
        "keywords": "Semantic Parsing;Text-to-SQL;Ambiguity;Beam Search;ChatGPT;LLMs for Text-to-SQL",
        "author": "",
        "aff": "IIT Bombay",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/testzer0/AmbiQT"
    },
    {
        "id": "aB3Hwh4UzP",
        "title": "A Mechanistic Interpretation of Arithmetic Reasoning in Language Models using Causal Mediation Analysis",
        "track": "main",
        "status": "Long Main",
        "keywords": "LLMs;Arithmetic Reasoning;Interpretability;Causality;Causal Mediation Analysis;Reasoning",
        "author": "",
        "aff": "ETH Z\u00fcrich; Technion \u2013 IIT, Israel",
        "rating": "",
        "confidence": "4;3;3;3",
        "correctness": "4;3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/alestolfo/lm-arithmetic"
    },
    {
        "id": "aBvwASLqMg",
        "title": "On the Representational Capacity of Recurrent Neural Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "RNN;LM;Turing machine;formal languages;probabilistic;language model",
        "author": "",
        "aff": "ETH Z\u00fcrich; Johns Hopkins University",
        "rating": "",
        "confidence": "3;4;2",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/rycolab/rnn-turing-completeness"
    },
    {
        "id": "aCHq10rQiH",
        "title": "CREATOR: Tool Creation for Disentangling Abstract and Concrete Reasoning of Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large Language Models;Tool Creation;Model Reasoning",
        "author": "",
        "aff": "University of Illinois at Urbana-Champaign; Tsinghua University",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/qiancheng0/CREATOR2022"
    },
    {
        "id": "aE7feUD7o7",
        "title": "Unified Low-Resource Sequence Labeling by Sample-Aware Dynamic Sparse Finetuning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Sequence Labeling;Low Resource Learning;Sparse Finetuning",
        "author": "",
        "aff": "Pennsylvania State University; University of Waterloo",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/psunlpgroup/FISH-DIP"
    },
    {
        "id": "aFIx8T43LU",
        "title": "Log-FGAER: Logic-Guided Fine-Grained Address Entity Recognition from Multi-Turn Spoken Dialogue",
        "track": "main",
        "status": "Long Main",
        "keywords": "Fine-grained address entity recognition;probabilistic soft logic;address extraction;data augmentation",
        "author": "",
        "aff": "JIUTIAN Team, China Mobile Research Institute, Beijing, China; The Xinjiang Technical Institute of Physics and Chemistry, Urumqi, China",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "aICXDsoH3O",
        "title": "Towards large language model-based personal agents in the enterprise: Current trends and open problems",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large language models;task-oriented;chatbots;multi-modal",
        "author": "",
        "aff": "Persistent Systems; IBM Research",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "aIp5EZeO3f",
        "title": "ZGUL: Zero-shot Generalization to Unseen Languages using Multi-source Ensembling of Language Adapters",
        "track": "main",
        "status": "Long Main",
        "keywords": "Multilinguality;Low Resource Languages;Parameter-Efficient Fine-Tuning (PEFT)",
        "author": "",
        "aff": "Indian Institute of Technology, New Delhi, India",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "aJILUuANbs",
        "title": "Multi-Stage Pre-training Enhanced by ChatGPT for Multi-Scenario Multi-Domain Dialogue Summarization",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multi-Scenario Multi-Domain Dialogue Summarization;Multi-Stage Pre-training;ChatGPT",
        "author": "",
        "aff": "School of Artificial Intelligence, University of Chinese Academy of Sciences; Fanyu AI Research, Zhongke Fanyu Technology Co., Ltd; State Key Lab of Multimodal Artificial Intelligence Systems, Institute of Automation, CAS; State Key Lab of Software Development Environment, Beihang University",
        "rating": "",
        "confidence": "4;4;2",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/zhouweixiao/MP4"
    },
    {
        "id": "aLkknJNdl6",
        "title": "Towards Low-Resource Automatic Program Repair with Meta-Learning and Pretrained Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Low-resource APR",
        "author": "",
        "aff": "Salesforce AI Research, Nanyang Technological University, Singapore; Salesforce AI Research",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "aN8zkE15Nx",
        "title": "An Investigation of LLMs\u2019 Inefficacy in Understanding Converse Relations",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large language models;inverse scaling;converse relation",
        "author": "",
        "aff": "The University of Hong Kong; Shanghai AI Laboratory; 3B Group; Beihang University",
        "rating": "",
        "confidence": "3;4;4;3",
        "correctness": "3;4;5;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/3B-Group/ConvRe"
    },
    {
        "id": "aNFWz8zubu",
        "title": "EtiCor: Corpus for Analyzing LLMs for Etiquettes",
        "track": "main",
        "status": "Short Main",
        "keywords": "Social Norms;Etiquette;LLMs",
        "author": "",
        "aff": "Indian Institute of Technology Kanpur (IIT Kanpur)",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "aP5f7cgY1M",
        "title": "Rather a Nurse than a Physician - Contrastive Explanations under Investigation",
        "track": "main",
        "status": "Long Main",
        "keywords": "explainability;contrastive explanations;human annotations",
        "author": "",
        "aff": "Department of Computer Science, University of Copenhagen, Denmark; Machine Learning Group, Technische Universit\u00e4t Berlin, Germany\u25e6BIFOLD, Germany",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "aPZ7AjA5YV",
        "title": "Revisiting Large Language Models as Zero-shot Relation Extractors",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Relation Extraction;Large Language Models;Zero-shot Learning",
        "author": "",
        "aff": "School of Computer Science and Engineering, Southeast University, China; Key Laboratory of New Generation Artificial Intelligence Technology and Its Interdisciplinary Applications (Southeast University), Ministry of Education, China",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "aRlH9AkiEA",
        "title": "KEPLET: Knowledge-Enhanced Pretrained Language Model with Topic Entity Awareness",
        "track": "main",
        "status": "Long Findings",
        "keywords": "language model;knowledge enhanced language model",
        "author": "",
        "aff": "Worcester Polytechnic Institute; Airbnb Inc.; Amazon Alexa AI",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/bigheiniu/KEPLET"
    },
    {
        "id": "aURCCzSuhc",
        "title": "Taxonomy Expansion for Named Entity Recognition",
        "track": "main",
        "status": "Long Main",
        "keywords": "named entity recognition;taxonomy",
        "author": "",
        "aff": "AWS AI Labs; Department of Computer Science, Duke University",
        "rating": "",
        "confidence": "3;4;4;4",
        "correctness": "4;4;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "aUn1BAzo7q",
        "title": "Weakly Supervised Semantic Parsing with Execution-based Spurious Program Filtering",
        "track": "main",
        "status": "Long Main",
        "keywords": "weakly supervised semantic parsing;spurious programs",
        "author": "",
        "aff": "Dept. of ECE, Seoul National University; IPAI, Seoul National University; Samsung Electronics Mobile eXperience",
        "rating": "",
        "confidence": "4;2;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/klee972/exec-filter"
    },
    {
        "id": "aVejMt2gYN",
        "title": "Inference-Time Policy Adapters (IPA): Tailoring Extreme-Scale LMs without Fine-tuning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Language Model;Text Generation;Reinforcement Learning;Inference-time Algorithm",
        "author": "",
        "aff": "University of Southern California; University of Washington; Allen Institute for Artificial Intelligence",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/GXimingLu/IPA"
    },
    {
        "id": "aVqGqTyky7",
        "title": "Contrastive Distant Supervision for Debiased and Denoised Machine Reading Comprehension",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Distant Supervision;Machine Reading Comprehension;Contrastive Learning",
        "author": "",
        "aff": "Institute of Software, Chinese Academy of Sciences; University of Chinese Academy of Sciences, Institute of Software, Chinese Academy of Sciences",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "aXi6UwdygV",
        "title": "Cognate Transformer for Automated Phonological Reconstruction and Cognate Reflex Prediction",
        "track": "main",
        "status": "Long Main",
        "keywords": "Computational historical linguistics;Phonological reconstruction;Cognate reflex prediction;Transformer",
        "author": "",
        "aff": "Dept. of Computer Science and Engineering, Indian Institute of Technology Kanpur",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "5;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "aY4avQ0ItI",
        "title": "A Systematic Study of Performance Disparities in Multilingual Task-Oriented Dialogue Systems",
        "track": "main",
        "status": "Long Main",
        "keywords": "multilingual task-oriented dialogue systems;analysis of performance disparities",
        "author": "",
        "aff": "Department of Computer Science and Technology, University of Cambridge, UK; Language Technology Lab, University of Cambridge, UK; Huawei Noah\u2019s Ark Lab, London, UK",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "aaMwMjrDz0",
        "title": "Conditional Natural Language Inference",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Natural language inference;NLI;explanation;contradictory aspect;token-level explanation;interpretable model",
        "author": "",
        "aff": "University of Massachusetts Amherst",
        "rating": "",
        "confidence": "4;2;3",
        "correctness": "2;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/youngwoo-umass/cond-nli"
    },
    {
        "id": "adIeh9ZsfC",
        "title": "An Empirical Study of Frame Selection for Text-to-Video Retrieval",
        "track": "main",
        "status": "Long Findings",
        "keywords": "text-to-video retrival;frame selection",
        "author": "",
        "aff": "Harbin Institute of Technology, Shenzhen; Institute of Automation, Chinese Academy of Sciences; Soochow University",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "adjZtG9bDM",
        "title": "Evaluation of African American Language Bias in Natural Language Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "benchmarking large language models;african american language;bias and fairness;language generation",
        "author": "",
        "aff": "University of Michigan, Department of Linguistics; University of Pennsylvania, School of Social Policy and Practice, Annenberg School for Communications; Columbia University, Department of Computer Science",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "4;1;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "ae6MmBuX6k",
        "title": "MCC-KD: Multi-CoT Consistent Knowledge Distillation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Knowledge Distillation;Chain of Thought;Reasoning",
        "author": "",
        "aff": "School of Computer Science and Engineering, Sun Yat-sen University, China; Alibaba Group, China; Nyonic AI",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "aeLyo8GAco",
        "title": "Hierarchical Catalogue Generation for Literature Review: A Benchmark",
        "track": "main",
        "status": "Long Findings",
        "keywords": "scientific document processing;multi-document summarization;datasets;metrics",
        "author": "",
        "aff": "Harbin Institute of Technology, Peng Cheng Laboratory; Harbin Institute of Technology",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "ahVTS392C3",
        "title": "JASMINE: Arabic GPT Models for Few-Shot Learning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Arabic;Arabic dialects varieties;GPT;Few-shot learning",
        "author": "",
        "aff": "Deep Learning & Natural Language Processing Group, The University of British Columbia; Department of Natural Language Processing & Department of Machine Learning, MBZUAI",
        "rating": "",
        "confidence": "2;4;5",
        "correctness": "5;5;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "ai6kjD6cyX",
        "title": "Event Causality Extraction via Implicit Cause-Effect Interactions",
        "track": "main",
        "status": "Long Main",
        "keywords": "Event Causality Extraction;Generative Language Models;Knowledge Distillation;Optimal Transport",
        "author": "",
        "aff": "Key Laboratory of Network Information System Technology, Aerospace Information Research Institute, Chinese Academy of Sciences; School of Electronic, Electrical and Communication Engineering, University of Chinese Academy of Sciences, Beijing, China",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "aipbZ5obaz",
        "title": "Comparing Styles across Languages",
        "track": "main",
        "status": "Long Main",
        "keywords": "NLP;Style;Cross-Cultural;Multilingual;Explainability;Lexica",
        "author": "",
        "aff": "University of Pennsylvania",
        "rating": "",
        "confidence": "2;3;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "ajzFrKT3U7",
        "title": "Leveraging Structured Information for Explainable Multi-hop Question Answering and Reasoning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Natural Language Processing;Multi-hop Question Answering",
        "author": "",
        "aff": "Department of Computer Science, University of Texas at Dallas",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/bcdnlp/Structure-QA"
    },
    {
        "id": "ak6PQPmmEK",
        "title": "The student becomes the master: Outperforming GPT3 on Scientific Factual Error Correction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Factual Error Correction;GPT;Domain Adaptation;Distribution Shift",
        "author": "",
        "aff": "School of Computer Science, Carnegie Mellon University",
        "rating": "",
        "confidence": "4;4;3;3",
        "correctness": "4;3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "akJUrevmwI",
        "title": "Do Language Models Have a Common Sense regarding Time? Revisiting Temporal Commonsense Reasoning in the Era of Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Benchmarking;Temporal Reasoning;LLMs",
        "author": "",
        "aff": "Department of Computer Science and Engineering, Indian Institute of Technology Patna; University of Innsbruck, Austria; Microsoft, India",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "alxWMBcNVN",
        "title": "Personalized Distillation: Empowering Open-Sourced LLMs with Adaptive Learning for Code Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Distillation;code generation;adaptive learning",
        "author": "",
        "aff": "Salesforce Research; Nanyang Technological University, Singapore",
        "rating": "",
        "confidence": "4;2;5",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/salesforce/PersDistill"
    },
    {
        "id": "aolJqJ50ZA",
        "title": "Explore the Way: Exploring Reasoning Path by Bridging Entities for Effective Cross-Document Relation Extraction",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Cross-document relation extraction;Document relation extraction;Reasoning Path Construction",
        "author": "",
        "aff": "Computer Science and Engineering, Korea University, Republic of Korea",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "asYObzj0IT",
        "title": "Comparing Prompt-Based and Standard Fine-Tuning for Urdu Text Classification",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Prompt-based Fine-tuning;Urdu Text Classification;Pre-trained Language Models",
        "author": "",
        "aff": "Computer Science, Information Technology University (ITU), Lahore, Pakistan; Computer Science, Lahore University of Management Sciences (LUMS), Lahore, Pakistan",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "ayoGdkXi4V",
        "title": "Lazy-k Decoding: Constrained Decoding for Information Extraction",
        "track": "main",
        "status": "Long Main",
        "keywords": "structured prediction;constrained decoding;token classification;information extraction;beam search",
        "author": "",
        "aff": "; Shift Technology\u2217, Paris, France; L3i\u2020, La Rochelle, France",
        "rating": "",
        "confidence": "2;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ArthurDevNL/lazyk"
    },
    {
        "id": "ayzVnzaUzB",
        "title": "When the Majority is Wrong: Modeling Annotator Disagreement for Subjective Tasks",
        "track": "main",
        "status": "Long Main",
        "keywords": "annotator disagreement;hate speech;toxicity detection;offensive content detection;AI fairness",
        "author": "",
        "aff": "Harvard University; UC Berkeley",
        "rating": "",
        "confidence": "4;2;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "b07c10sXzN",
        "title": "Lifelong Sequence Generation with Dynamic Module Expansion and Adaptation",
        "track": "main",
        "status": "Long Main",
        "keywords": "lifelong learning;sequence generation;dynamic module;forward knowledge transfer",
        "author": "",
        "aff": "Nanyang Technological University; Salesforce AI",
        "rating": "",
        "confidence": "4;3;4;5",
        "correctness": "4;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "b1J3WplfgM",
        "title": "SKD-NER: Continual Named Entity Recognition via Span-based Knowledge Distillation with Reinforcement Learning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Continual learning;Named Entity Recognition;Knowledge Distillation;Reinforcement Learning",
        "author": "",
        "aff": "School of Computer Science and Technology, Xinjiang University, Urumqi 830017, China; Xinjiang Key Laboratory of Signal Detection and Processing, Urumqi 830017, China; School of Computer Science and Technology, Xinjiang University, Urumqi 830017, China; Xinjiang Key Laboratory of Signal Detection and Processing, Urumqi 830017, China; Department of Electronic Engineering, and Beijing National Research Center for Information Science and Technology, Tsinghua University, Beijing 100084, China",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "3;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/YChen2637/SKD"
    },
    {
        "id": "b1XS87j323",
        "title": "A Multi-Task Dataset for Assessing Discourse Coherence in Chinese Essays: Structure, Theme, and Logic Analysis",
        "track": "main",
        "status": "Long Main",
        "keywords": "discourse coherence assessment",
        "author": "",
        "aff": "School of Computer Science and Technology, East China Normal University, Shanghai, China; Shanghai Institute of AI for Education, East China Normal University, Shanghai, China; Department of Chinese Language and Literature, East China Normal University, Shanghai, China; Microsoft Research Asia, Beijing, China; School of Computer Science and Technology, East China Normal University, Shanghai, China",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/cubenlp/CEDCC_corpus"
    },
    {
        "id": "b3lGS64ZZK",
        "title": "A Fair and In-Depth Evaluation of Existing End-to-End Entity Linking Systems",
        "track": "main",
        "status": "Long Main",
        "keywords": "entity linking;entity linking evaluation;entity linking benchmarks",
        "author": "",
        "aff": "Karlsruhe Institute of Technology, Institute for Automation and Applied Informatics, Germany; University of Freiburg, Department of Computer Science, Germany",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://elevant.cs.uni-freiburg.de/emnlp2023",
        "github": "https://github.com/ad-freiburg/fair-entity-linking-benchmarks"
    },
    {
        "id": "b5pbHYNJnX",
        "title": "Rethinking Model Selection and Decoding for Keyphrase Generation with Pre-trained Sequence-to-Sequence Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Keyphrase Generation;Pre-trained Language Models;Text Generation Decoding;Performance Evaluation",
        "author": "",
        "aff": "University of California, Los Angeles",
        "rating": "",
        "confidence": "4;4;3;5",
        "correctness": "4;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "b6JnUJxOpN",
        "title": "Temporal Extrapolation and Knowledge Transfer for Lifelong Temporal Knowledge Graph Reasoning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Temporal Knowledge Graph;Lifelong Reasoning;Temporal Extrapolation;Knowledge Transfer.",
        "author": "",
        "aff": "National Key Laboratory of Parallel and Distributed Computing, College of Computer, National University of Defense Technology; National University of Defense Technology; International Digital Economy Academy (IDEA)",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "b6e1wV03hy",
        "title": "Retrieval-Augmented Few-shot Text Classification",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Retrieval-augmented methods;Few-shot text classification",
        "author": "",
        "aff": "Tencent AI Lab, China.; Key Lab of Intelligent Information Processing of Chinese Academy of Sciences (CAS), Institute of Computing Technology, CAS, Beijing 100190, China. \u2020Corresponding authors.; Key Lab of Intelligent Information Processing of Chinese Academy of Sciences (CAS), Institute of Computing Technology, CAS, Beijing 100190, China. *Work done while this author was an intern at Tencent.; Peng Cheng Laboratory. University of Chinese Academy of Sciences, Beijing 100049, China. Tencent AI Lab, China. \u2020Corresponding authors.; Institute of Intelligent Computing Technology, Suzhou, CAS.",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "b7ZJcAkjC3",
        "title": "Enhancing Structured Evidence Extraction for Fact Verification",
        "track": "main",
        "status": "Long Main",
        "keywords": "fact verification; evidence extraction",
        "author": "",
        "aff": "Wangxuan Institute of Computer Technology, Peking University, China",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/WilliamZR/see-st"
    },
    {
        "id": "b7gtyaaM2y",
        "title": "Towards General Error Diagnosis via Behavioral Testing in Machine Translation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "behavioral testing;machine translation",
        "author": "",
        "aff": "The Hong Kong University of Science and Technology, Hong Kong SAR, China; Tencent AI Lab",
        "rating": "",
        "confidence": "4;2;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/wujunjie1998/BTPGBT"
    },
    {
        "id": "bB32QLrpu4",
        "title": "Granularity Matters: Pathological Graph-driven Cross-modal Alignment for Brain CT Report Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Medical Report Generation;Contrastive Learning;Knowledge Graph;Brain CT",
        "author": "",
        "aff": "Department of Statistics and Actuarial Science, University of Hong Kong, Hong Kong, China; Faculty of Information Technology, Beijing University of Technology, Beijing, China; Department of Radiology, Peking University Third Hospital, Beijing, China",
        "rating": "",
        "confidence": "3;4;2",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "bNeDLx5O6w",
        "title": "MAF: Multi-Aspect Feedback for Improving Reasoning in Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "large language models;feedback generation;reasoning;self-correction;in-context learning;prompting;prompt engineering;error correction",
        "author": "",
        "aff": "University of California, Santa Barbara, Santa Barbara, CA",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "Not provided",
        "github": "Not provided"
    },
    {
        "id": "bQLMv4v0Gc",
        "title": "Construction Artifacts in Metaphor Identification Datasets",
        "track": "main",
        "status": "Short Main",
        "keywords": "metaphors;resources;bias",
        "author": "",
        "aff": "Cardiff NLP, School of Computer Science and Informatics, Cardiff University, United Kingdom; AMPLYFI, United Kingdom; Cardiff NLP, School of Computer Science and Informatics, Cardiff University, United Kingdom",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "bSfBgrmabV",
        "title": "Dual-Feedback Knowledge Retrieval for Task-Oriented Dialogue Systems",
        "track": "main",
        "status": "Long Main",
        "keywords": "End-to-End Task-Oriented Dialogue System;Knowledge Retrieval;Retriever training",
        "author": "",
        "aff": "School of Computer Science and Engineering, Sun Yat-sen University, China; Meta AI; Meetyou AI Lab",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Stycoo/Dual-Feedback-TOD"
    },
    {
        "id": "bVO1sWgnTx",
        "title": "Efficient Classification of Long Documents via State-Space Models",
        "track": "main",
        "status": "Short Main",
        "keywords": "Long Document Classification;State Space Models;Efficient NLP",
        "author": "",
        "aff": "Huawei Noah\u2019s Ark Lab, Canada; Huawei Noah\u2019s Ark Lab, Canada and Department of Computer Science and Operations Research, Universit\u00e9 de Montr\u00e9al; Department of Computer Science and Operations Research, Universit\u00e9 de Montr\u00e9al",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "bWXIut4pNM",
        "title": "INGENIOUS: Using Informative Data Subsets for Efficient Pre-Training of Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Efficient training;Language Models;Data selection",
        "author": "",
        "aff": "Indian Institute of Technology Bombay, India; University of Texas at Dallas, USA; Media and Data Science Research (MDSR) Lab, Adobe Inc., India",
        "rating": "",
        "confidence": "2;4;3;4",
        "correctness": "2;2;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Efficient-AI/ingenious"
    },
    {
        "id": "bZel7wM6fN",
        "title": "Understanding the Inner-workings of Language Models Through Representation Dissimilarity",
        "track": "main",
        "status": "Short Main",
        "keywords": "language models;interpretability;stitching",
        "author": "",
        "aff": "University of Washington; Duke University; Paci\ufb01c Northwest National Laboratory; Thomson Reuters Labs",
        "rating": "",
        "confidence": "3;3;3;1;5",
        "correctness": "4;4;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.8,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "bc2xgl7oGf",
        "title": "The Iron(ic) Melting Pot: Reviewing Human Evaluation in Humour, Irony and Sarcasm Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "human evaluation;humour;sarcasm;irony;natural language generation;position paper;critical survey;sociology",
        "author": "",
        "aff": "Department of Computer Science, The University of Sheffield, UK; LT3, Ghent University, Belgium; Department of Computer Science, The University of Manchester, UK",
        "rating": "",
        "confidence": "5;5;4",
        "correctness": "3;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "bdgUPZhF9b",
        "title": "InstructoR: Instructing Unsupervised Conversational Dense Retrieval with Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Conversational Dense Retrieval;Unsupervised Information Retrieval;Large Language Models",
        "author": "",
        "aff": "School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; The Laboratory of Cognition and Decision Intelligence for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China",
        "rating": "",
        "confidence": "3;4;4;4",
        "correctness": "4;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/jinzhuoran/InstructoR/"
    },
    {
        "id": "bflAMCWJh8",
        "title": "PerturbScore: Connecting Discrete and Continuous Perturbations in NLP",
        "track": "main",
        "status": "Long Findings",
        "keywords": "perturbation in NLP;robustness in NLP",
        "author": "",
        "aff": "School of Computer Science, Fudan University; Shanghai Key Laboratory of Intelligent Information Processing, Fudan University",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 1.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/renke999/PerturbScore"
    },
    {
        "id": "bgskDuMqcz",
        "title": "Adapt in Contexts: Retrieval-Augmented Domain Adaptation via In-Context Learning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Domain Adaptation;in-context learning;Retrieval Augmentation",
        "author": "",
        "aff": "Nanyang Technological University, Singapore and The Chinese University of Hong Kong; Nanyang Technological University, Singapore",
        "rating": "",
        "confidence": "4;4;2;4",
        "correctness": "2;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "bkGVmCE3UJ",
        "title": "Counting the Bugs in ChatGPT's Wugs: A Multilingual Investigation into the Morphological Capabilities of a Large Language Model",
        "track": "main",
        "status": "Long Main",
        "keywords": "wug-testing;morphology;chatGPT;morphological generalization",
        "author": "",
        "aff": "LMU Munich; Carnegie Mellon University; IIT Delhi",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "bmeKrAzRqz",
        "title": "Pre-Trained Language Models Augmented with Synthetic Scanpaths for Natural Language Understanding",
        "track": "main",
        "status": "Short Main",
        "keywords": "Human gaze data;synthetic scanpaths;gaze-augmented language model;natural language understanding;transformer;deep neural networks",
        "author": "",
        "aff": "Department of Computer Science, University of Potsdam, Germany; Department of Computational Linguistics, University of Zurich, Switzerland; Department of Computer Science, University of Potsdam, Germany",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/aeye-lab/EMNLP-SyntheticScanpaths-NLU-PretrainedLM"
    },
    {
        "id": "bpArUWbkUF",
        "title": "Argue with Me Tersely: Towards Sentence-Level Counter-Argument Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Counter-Argument Generation;ArgTersely;Arg-LLaMA;Arg-Judge",
        "author": "",
        "aff": "Huawei Poisson Lab; ByteDance; Fudan University",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/amazingljy1206/ArgTersely"
    },
    {
        "id": "bqaW5sGZOq",
        "title": "Revisiting Machine Translation for Cross-lingual Classification",
        "track": "main",
        "status": "Long Main",
        "keywords": "multilinguality;cross-lingual classification;machine translation",
        "author": "",
        "aff": "Meta AI; Reka AI, HiTZ Center, University of the Basque Country (UPV/EHU)",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "bt9Ho2FMxd",
        "title": "Unmasking the Hidden Meaning: Bridging Implicit and Explicit Hate Speech Embedding Representations",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Hate Speech Detection;Implicit Hate Embeddings",
        "author": "",
        "aff": "Universite C\u00f4te d\u2019Azur, CNRS, Inria, I3S, France",
        "rating": "",
        "confidence": "3;5;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/benjaminocampo/bridging_ie_hs_embs"
    },
    {
        "id": "bvl3p6JUlv",
        "title": "Mitigating Biases in Hate Speech Detection from A Causal Perspective",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Hate speech detection;Causal inference;Bias mitigation",
        "author": "",
        "aff": "Stanford University; Georgia Institute of Technology; Dartmouth College",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/SALT-NLP/Bias_Hate_Causal"
    },
    {
        "id": "bxFwIn0wZ0",
        "title": "Enabling Large Language Models to Generate Text with Citations",
        "track": "main",
        "status": "Long Main",
        "keywords": "large language model;llm;citation;attribution;qa;evaluation;benchmark",
        "author": "",
        "aff": "Department of Computer Science & Princeton Language and Intelligence, Princeton University",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/princeton-nlp/ALCE"
    },
    {
        "id": "bxltAqTJe2",
        "title": "$\\textit{From Chaos to Clarity}$: Claim Normalization to Empower Fact-Checking",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Claim Normalization;Social Media;Claims;Misinformation",
        "author": "",
        "aff": "Indraprastha Institute of Information Technology Delhi, India; Indian Institute of Technology Delhi, India; Mohammed Bin Zayed University of Artificial Intelligence",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/LCS2-IIITD/CACN-EMNLP-2023"
    },
    {
        "id": "bxsrykzSnq",
        "title": "HaluEval: A Large-Scale Hallucination Evaluation Benchmark for Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Models;Hallucination",
        "author": "",
        "aff": "School of Information, Renmin University of China; Gaoling School of Artificial Intelligence, Renmin University of China; DIRO, Universit\u00e9 de Montr\u00e9al",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/RUCAIBox/HaluEval"
    },
    {
        "id": "c0utj9Q4YY",
        "title": "Toward Joint Language Modeling for Speech Units and Text",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Language modeling;Speech processing;Spoken Language Understanding",
        "author": "",
        "aff": "Meta AI; Character AI; OpenAI; Toyota Technological Institute at Chicago",
        "rating": "",
        "confidence": "2;3;5",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "c27QqxALfo",
        "title": "MM-Reasoner: A Multi-Modal Knowledge-Aware Framework for Knowledge-Based Visual Question Answering",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Vision-Language Models;Large Language Models;Visual Question Answering",
        "author": "",
        "aff": "Microsoft Cognitive Services Research Group",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "c2xBtTNceS",
        "title": "Inverse Reinforcement Learning for Text Summarization",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Abstractive Summarization;Inverse Reinforcement Learning;Reward Function Optimization",
        "author": "",
        "aff": "University of California Riverside; Tianjin University",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "cBhzqp8WlV",
        "title": "Advancements in Arabic Grammatical Error Detection and Correction: An Empirical Investigation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Grammatical Error Correction;Grammatical Error Detection;Arabic",
        "author": "",
        "aff": "\u2020Mohamed bin Zayed University of Artificial Intelligence; Computational Approaches to Modeling Language Lab, New York University Abu Dhabi",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/CAMeL-Lab/arabic-gec"
    },
    {
        "id": "cCJGuKJYG8",
        "title": "Towards Reliable Misinformation Mitigation: Generalization, Uncertainty, and GPT-4",
        "track": "main",
        "status": "Long Main",
        "keywords": "misinformation;LLM;GPT-4;uncertainty quantification;generalization",
        "author": "",
        "aff": "McGill University; Universit\u00e9 de Montr\u00e9al; European University Institute; Eindhoven University of Technology; University of Pennsylvania",
        "rating": "",
        "confidence": "4;5;3",
        "correctness": "2;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "cD9blNBYF2",
        "title": "DialogQAE: N-to-N Question Answer Pair Extraction from Customer Service Chatlog",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Dialogue QA Extraction",
        "author": "",
        "aff": "Alibaba Group; Institute of Software, Chinese Academy of Sciences, China; Tencent Cloud AI; National Key Laboratory for Multimedia Information Processing, Peking University",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/MrZhengXin/DialogQAE"
    },
    {
        "id": "cFXHe1mW7V",
        "title": "Can You Follow Me? Testing Situational Understanding for ChatGPT",
        "track": "main",
        "status": "Long Main",
        "keywords": "Situational Understanding;Analysis of Models;ChatGPT",
        "author": "",
        "aff": "University of Chicago; Allen Institute for AI",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "5;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/yangalan123/SituationalTesting"
    },
    {
        "id": "cFsfgaEMlw",
        "title": "4 and 7-bit Labeling for Projective and Non-Projective Dependency Trees",
        "track": "main",
        "status": "Short Main",
        "keywords": "parsing;dependency parsing;sequence labeling;parsing as sequence labeling;encoding",
        "author": "",
        "aff": "Universidade da Coru\u00f1a, CITIC, Departamento de Ciencias de la Computaci\u00f3n y Tecnolog\u00edas de la Informaci\u00f3n, Campus de Elvi\u00f1a s/n, 15071 A Coru\u00f1a, Spain",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "cI6oe7i5mj",
        "title": "GPT Deciphering Fedspeak: Quantifying Dissent Among Hawks and Doves",
        "track": "main",
        "status": "Short Findings",
        "keywords": "FOMC;Fed;GPT;LLM;dissent",
        "author": "",
        "aff": "Sociology and OPR, Princeton University; Office of Population Research, Princeton University; Computer Science, Princeton University; Economics, Princeton University; Computer Science, University of Maryland; Sociology, University of Washington",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "cMMxJxzYkZ",
        "title": "Harnessing the Power of Large Language Models for Empathetic Response Generation: Empirical Investigations and Improvements",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Empathetic Response Generation;Large Language Models;ChatGPT",
        "author": "",
        "aff": "Research Center for Social Computing and Information Retrieval, Harbin Institute of Technology, China",
        "rating": "",
        "confidence": "4;3;4;5;4",
        "correctness": "4;4;4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.8,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "cOxL1tlSQw",
        "title": "Dynamic Stance: Modeling Discussions by Labeling the Interactions",
        "track": "main",
        "status": "Long Findings",
        "keywords": "stance;corpus;multi-lingual;cross-topic",
        "author": "",
        "aff": "HiTZ Center - Ixa, University of the Basque Country UPV/EHU; CLCG, University of Groningen, The Netherlands; Barcelona Supercomputing Center",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "cVAHzYRVUO",
        "title": "Inductive Relation Inference of Knowledge Graph Enhanced by Ontology Information",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Ontology Information;Inductive Relation Inference;Knowledge Graph",
        "author": "",
        "aff": "School of Computer Science, Fudan University; International Human Phenome Institutes (Shanghai); Institute of Modern Languages and Linguistics, Fudan University",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "cWw5FfVhvl",
        "title": "MoT: Memory-of-Thought Enables ChatGPT to Self-Improve",
        "track": "main",
        "status": "Long Main",
        "keywords": "LLM;ChatGPT;Self-Improve;Large Language Model;Memory",
        "author": "",
        "aff": "School of Computer Science, Fudan University; Shanghai Key Laboratory of Intelligent Information Processing, Fudan University",
        "rating": "",
        "confidence": "2;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "cgmlfA1sPl",
        "title": "Late Fusion of Transformers for Sentiment Analysis of Code-Switched Data",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Code-switched;Transformer;Sentiment Analysis;GLUECoS benchmark dataset;Late Fusion;Neural Network",
        "author": "",
        "aff": "Indian Insitute of Technology Roorke, Roorkee, Uttarakhand, India",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "4;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "chCrhE2kl4",
        "title": "TK-KNN: A Balanced Distance-Based Pseudo Labeling Approach for Semi-Supervised Intent Classification",
        "track": "main",
        "status": "Long Findings",
        "keywords": "semi-supervised learning;intent classification;contrastive learning",
        "author": "",
        "aff": "ServiceNow Research; University of Notre Dame",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ServiceNow/tk-knn"
    },
    {
        "id": "ci6cexmrmD",
        "title": "DepWiGNN: A Depth-wise Graph Neural Network for Multi-hop Spatial Reasoning in Text",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Spatial Reasoning;Tensor Product Representation;Graph Neural Network",
        "author": "",
        "aff": "National University of Singapore; The Chinese University of Hong Kong",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "cjbdRN8Yxy",
        "title": "Compressing Context to Enhance Inference Efficiency of Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Model;Input Compression",
        "author": "",
        "aff": "Department of Computer Science, University of Surrey, UK; Department of Computer Science, The University of Manchester, UK",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/liyucheng09/Selective_Context"
    },
    {
        "id": "ckKuQDW2RZ",
        "title": "Conic10K: A Challenging Math Problem Understanding and Reasoning Dataset",
        "track": "main",
        "status": "Long Findings",
        "keywords": "math problem;reasoning",
        "author": "",
        "aff": "School of Information Science and Technology, University of Science and Technology of China; Shanghai Innovation Center for Processor Technologies; School of Information Science and Technology, ShanghaiTech University; Shanghai Engineering Research Center of Intelligent Vision and Imaging; School of Information Science and Technology, University of Science and Technology of China; National Engineering Laboratory for Brain-inspired Intelligence Technology and Application; Key Laboratory of Brain, Cognition and Education Sciences, Ministry of Education; Department of Computer Science and Engineering, Shanghai Jiao Tong University",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/whyNLP/Conic10K"
    },
    {
        "id": "clTPP37Rpu",
        "title": "Beyond Factuality: A Comprehensive Evaluation of Large Language Models as Knowledge Generators",
        "track": "main",
        "status": "Long Main",
        "keywords": "Evaluation framework;Knowledge generation;Large language model;",
        "author": "",
        "aff": "National University of Singapore; The Hong Kong University of Science and Technology; Tencent AI Lab; The Chinese University of Hong Kong",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ChanLiang/CONNER"
    },
    {
        "id": "clxLDVanxO",
        "title": "ReTAG: Reasoning Aware Table to Analytic Text Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Table to Text Generation;Table Understanding;Structured Reasoning",
        "author": "",
        "aff": "DeCLaRe Lab, Singapore University of Technology and Design, Singapore; Google Research, India",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/deepanwayghosal/ReTAG"
    },
    {
        "id": "cmQj1FdsOJ",
        "title": "Evaluating the Knowledge Base Completion Potential of GPT",
        "track": "main",
        "status": "Short Findings",
        "keywords": "knowledge base completion;knowledge graphs;probing language models;evaluation",
        "author": "",
        "aff": "University of Amsterdam; Bosch Center for AI; Max Planck Institute for Informatics",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "cooAE3hYUC",
        "title": "BasahaCorpus: An Expanded Linguistic Resource for Readability Assessment in Central Philippine Languages",
        "track": "main",
        "status": "Short Main",
        "keywords": "readability assessment;corpus;linguistic resource;cross-lingual;Philippine languages;low-resource NLP",
        "author": "",
        "aff": "MBZUAI, UAE; University of Bath, UK",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/imperialite/BasahaCorpus-HierarchicalCrosslingualARA"
    },
    {
        "id": "crfQrbxWAK",
        "title": "Schema-adaptable Knowledge Graph Construction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Knowledge Graph Construction;Information Extraction",
        "author": "",
        "aff": "Zhejiang University, Zhejiang Lab; Zhejiang University; Platform and Content Group, Tencent",
        "rating": "",
        "confidence": "2;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/zjunlp/AdaKGC"
    },
    {
        "id": "csBtifBXKo",
        "title": "Adaptive End-to-End Metric Learning for Zero-Shot Cross-Domain Slot Filling",
        "track": "main",
        "status": "Long Main",
        "keywords": "end-to-end;zero-shot learning;metric learning;slot filling",
        "author": "",
        "aff": "School of Life Science and Technology, University of Electronic Science and Technology of China, Chengdu, China; School of New Media and Communication, Tianjin University, Tianjin, China",
        "rating": "",
        "confidence": "2;3;2",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Switchsyj/AdaE2ML-XSF"
    },
    {
        "id": "cvRvFj3Pyv",
        "title": "Empathy Intent Drives Empathy Detection",
        "track": "main",
        "status": "Long Main",
        "keywords": "Empathy detection;Empathy intent recognition;Cascaded interactive attention;Label signal enhancement",
        "author": "",
        "aff": "School of Computer Science and Technology, Xinjiang University, Urumqi, China; Resource Monitoring and Research Center on Minority Languages, Urumqi, China; Xinjiang Laboratory of Multi-language Information Technology, Urumqi, China",
        "rating": "",
        "confidence": "5;4;3;3",
        "correctness": "4;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/JiangT7/CLSN"
    },
    {
        "id": "cw6v58yo6s",
        "title": "Baize: An Open-Source Chat Model with Parameter-Efficient Tuning on Self-Chat Data",
        "track": "main",
        "status": "Long Main",
        "keywords": "large language model;knowledge disillation;data generation;chatbot;chat model;text generation",
        "author": "",
        "aff": "Microsoft Research Asia; Sun Yat-sen University; University of California, San Diego",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/project-baize/baize-chatbot"
    },
    {
        "id": "czxX6jjpVJ",
        "title": "Discovering Highly Influential Shortcut Reasoning: An Automated Template-Free Approach",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Shortcut Reasoning;Inference;Robustness",
        "author": "",
        "aff": "Japan Advanced Institute of Science and Technology, RIKEN; Japan Advanced Institute of Science and Technology",
        "rating": "",
        "confidence": "3;4;5",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/homoscribens/shortcut_reasoning.git"
    },
    {
        "id": "d00kbjbYv2",
        "title": "How to Train Your Dragon: Diverse Augmentation Towards Generalizable Dense Retrieval",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Generalizable Dense Retrieval;Data Augmentation;Progressive Training",
        "author": "",
        "aff": "Meta AI; University of Washington; University of Waterloo",
        "rating": "",
        "confidence": "2;4;3;4",
        "correctness": "2;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/facebookresearch/dpr-scale"
    },
    {
        "id": "d0qmGnKfXa",
        "title": "From Relevance to Utility: Evidence Retrieval with Feedback for Fact Verification",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Utility; Evidence Retrieval; Fact Verification",
        "author": "",
        "aff": "School of Computer Science and Technology, University of Chinese Academy of Sciences; CAS Key Laboratory of Network Data Science and Technology, Institute of Computing Technology, Chinese Academy of Sciences; University of Amsterdam",
        "rating": "",
        "confidence": "5;3;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ict-bigdatalab/FER"
    },
    {
        "id": "d0zla3M3LI",
        "title": "Tree Prompting: Efficient Task Adaptation without Fine-Tuning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Decision tree;large language model;chain prompting;prompt engineering",
        "author": "",
        "aff": "Harvard University; Cornell University; Microsoft Research",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/csinva/tree-prompt"
    },
    {
        "id": "d94iPelgSD",
        "title": "Intra-Event and Inter-Event Dependency-Aware Graph Network for Event Argument Extraction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "event argument extraction;intra-event dependency;inter-event dependency;dependency-aware graph network",
        "author": "",
        "aff": "Institute of Computing Technology, Chinese Academy of Sciences; Institute of Information Engineering, Chinese Academy of Sciences; School of Cyber Security, University of Chinese Academy of Sciences",
        "rating": "",
        "confidence": "3;4;5",
        "correctness": "2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "dABNxI5c1X",
        "title": "Modeling Empathic Similarity in Personal Narratives",
        "track": "main",
        "status": "Long Main",
        "keywords": "empathy;semantic similarity;personal narratives",
        "author": "",
        "aff": "Massachusetts Institute of Technology, Cambridge, MA, USA; Carnegie Mellon University, Pittsburgh, PA, USA",
        "rating": "",
        "confidence": "3;3;3;4",
        "correctness": "4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.25,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "dFlGP1l65l",
        "title": "When it Rains, it Pours: Modeling Media Storms and the News Ecosystem",
        "track": "main",
        "status": "Long Findings",
        "keywords": "political communication;news media;political science",
        "author": "",
        "aff": "School of Information and Computer Science & Engineering, University of Michigan; School of Information, University of Michigan",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "dFvwxdSj0B",
        "title": "Retrieval-Augmented Parsing for Complex Graphs by Exploiting Structure and Uncertainty",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Uncertainty Quantification;Retrieval;Semantic Parsing",
        "author": "",
        "aff": "UC San Diego; Google Research & Harvard University; Google Research",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "dHHumVX2XV",
        "title": "Efficient Continue Training of Temporal Language Model with Structural Information",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Temporal Generalization;Syntactic Change;Temporal Language Model;Pre-trained Language Model",
        "author": "",
        "aff": "Institute of Computer Science and Technology, Soochow University, China; Department of Chinese Language and Literature, Peking University",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/zhaochen0110/TempoLM"
    },
    {
        "id": "dJ5yzTX4rZ",
        "title": "Solving Hard Analogy Questions with Relation Embedding Chains",
        "track": "main",
        "status": "Long Main",
        "keywords": "relation embedding;analogy questions;ConceptNet;knowledge graphs",
        "author": "",
        "aff": "Cardiff NLP, School of Computer Science and Informatics, Cardiff University, United Kingdom",
        "rating": "",
        "confidence": "5;4;2",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/niteshroyal/SolvingHardAnalogyQuestions"
    },
    {
        "id": "dQxLtay1M3",
        "title": "HyperNetwork-based Decoupling to Improve Model Generalization for Few-Shot Relation Extraction",
        "track": "main",
        "status": "Long Main",
        "keywords": "Relation Extraction;Few-Shot Relation Extraction",
        "author": "",
        "aff": "School of Informatics, Xiamen University, China; Key Laboratory of Digital Protection and Intelligent Processing of Intangible Cultural Heritage of Fujian and Taiwan (Xiamen University), Ministry of Culture and Tourism, China; Pattern Recognition Center, WeChat AI, Tencent Inc, China",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/DeepLearnXMU/FSRE-HDN"
    },
    {
        "id": "dRlYuG3bj7",
        "title": "SentiStream: A Co-Training Framework for Adaptive Online Sentiment Analysis in Evolving Data Streams",
        "track": "main",
        "status": "Long Main",
        "keywords": "Online Sentiment analysis;Streaming learning",
        "author": "",
        "aff": "Singapore University of Technology and Design; University of Sri Jayewardenepura",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "1;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/intellistream/SentiStream"
    },
    {
        "id": "dVOXsyVcik",
        "title": "Dynamic Top-k Estimation Consolidates Disagreement between Feature Attribution Methods",
        "track": "main",
        "status": "Short Main",
        "keywords": "interpretability;explainability;top-k;ranking;agreement;feature attribution",
        "author": "",
        "aff": "Computational Linguistics and Text Mining Lab, Vrije Universiteit Amsterdam; Computational Linguistics and Text Mining Lab, Vrije Universiteit Amsterdam; Dept. of Mathematics and Computer Science, Eindhoven University of Technology",
        "rating": "",
        "confidence": "3;3;2;2",
        "correctness": "3;3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "dVfeS1pp2e",
        "title": "Strong and Efficient Baselines for Open Domain Conversational Question Answering",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Open Domain Conversational Question Answering",
        "author": "",
        "aff": "Amazon Alexa AI; Idiap Research Institute, EPFL",
        "rating": "",
        "confidence": "2;3;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "dZWiI6A09u",
        "title": "Explainable Claim Verification via Knowledge-Grounded Reasoning with Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Claim Verification;Natural Language Reasoning;Large Language Model",
        "author": "",
        "aff": "Illinois Institute of Technology, Chicago, IL, USA",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/wang2226/FOLKClaim"
    },
    {
        "id": "daGbpBMkoy",
        "title": "Narrative Order Aware Story Generation via Bidirectional Pretraining Model with Optimal Transport Reward",
        "track": "main",
        "status": "Long Findings",
        "keywords": "story generation;narrative order;optimal transport",
        "author": "",
        "aff": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "dbRZyDxYlL",
        "title": "Improving Speech Translation by Fusing Speech and Text",
        "track": "main",
        "status": "Long Findings",
        "keywords": "speech translation;multimodal",
        "author": "",
        "aff": "ByteDance; Department of Computer Science and Technology, Nanjing University",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/WenbiaoYin/FuseST"
    },
    {
        "id": "dcYt9ByOOK",
        "title": "Responsible AI Considerations in Text Summarization Research: A Review of Current Practices",
        "track": "main",
        "status": "Long Findings",
        "keywords": "responsible AI;automatic summarization",
        "author": "",
        "aff": "Microsoft Research, Montr\u00e9al, Canada; Mila \u2013 Quebec Arti\ufb01cial Intelligence Institute, McGill University, Canada CIFAR AI Chair; Mila \u2013 Quebec Arti\ufb01cial Intelligence Institute, McGill University",
        "rating": "",
        "confidence": "3;5;4",
        "correctness": "3;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "ddldNozhnM",
        "title": "CLEME: Debiasing Multi-reference Evaluation for Grammatical Error Correction",
        "track": "main",
        "status": "Long Main",
        "keywords": "natural language processing;grammatical error correction;evaluation metric",
        "author": "",
        "aff": "Tsinghua Shenzhen International Graduate School, Tsinghua University; OPPO Research Institute; School of Intelligent Systems Engineering, Sun-Yat Sen University",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/THUKElab/CLEME"
    },
    {
        "id": "di1Foopybz",
        "title": "CoSyn: Detecting Implicit Hate Speech in Online Conversations Using a Context Synergized Hyperbolic Network",
        "track": "main",
        "status": "Long Main",
        "keywords": "hate-speech;hyperbolic;social-good;implicit",
        "author": "",
        "aff": "MIDAS Labs, IIIT-Delhi, India; University of Maryland College Park, USA",
        "rating": "",
        "confidence": "5;5;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Sreyan88/CoSyn"
    },
    {
        "id": "diItUQ1idA",
        "title": "Abstractive Open Information Extraction",
        "track": "main",
        "status": "Long Main",
        "keywords": "Open Information Extraction;Relation Extraction;Natural Language Generation",
        "author": "",
        "aff": "University of Illinois at Urbana-Champaign; IBM Research",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/kevinpei/AbstractiveOpenIE"
    },
    {
        "id": "diUHb3jt3j",
        "title": "Uncovering the Root of Hate Speech: A Dataset for Identifying Hate Instigating Speech",
        "track": "main",
        "status": "Long Findings",
        "keywords": "hate speech;hate instigating speech;machine learning;natural language processing",
        "author": "Stephanie L",
        "aff": "Department of Information Systems, Korea University Business School, Seoul, Republic of Korea",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "1;2;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 1.6666666666666667,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "djmjglxOZ7",
        "title": "Finding Support Examples for In-Context Learning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "In-Context Learning;ICL;Language Model",
        "author": "",
        "aff": "School of Computer Science, Fudan University; Shanghai Key Laboratory of Intelligent Information Processing, Fudan University",
        "rating": "",
        "confidence": "3;4;5",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "dl4e3EBz5j",
        "title": "GlotLID: Language Identification for Low-Resource Languages",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Language Identification;Low-Resource Languages",
        "author": "",
        "aff": "Center for Information and Language Processing, LMU Munich, Germany; Munich Center for Machine Learning (MCML), Germany; Sorbonne Universit\u00e9, CNRS, ISIR, France",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/cisnlp/GlotLID"
    },
    {
        "id": "dnIfD7RJLU",
        "title": "GEM: Gestalt Enhanced Markup Language Model for Web Understanding via Render Tree",
        "track": "main",
        "status": "Long Main",
        "keywords": "Gestalt;Markup Language;Web Understanding;Language Model",
        "author": "",
        "aff": "Worcester Polytechnic Institute; Alibaba Group; Zhejiang Provincial Key Laboratory of Service Robot, Zhejiang University",
        "rating": "",
        "confidence": "3;5;4",
        "correctness": "4;5;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "dnQI76LKQy",
        "title": "MultiCMET: A Novel Chinese Benchmark for Understanding Multimodal Metaphor",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multimodal metaphor;Benchmark;Chinese language;Domain lexicon;Metaphor understanding",
        "author": "",
        "aff": "School of Software, Dalian University of Technology, China; School of Software, School of Foreign Languages, Dalian University of Technology, China; School of Computer Science and Technology, Dalian University of Technology, China",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/PedaloJSY/MultiCMET"
    },
    {
        "id": "dp9jTeKXec",
        "title": "From Simple to Complex: A Progressive Framework for Document-level Informative Argument Extraction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Document-level event extraction;informative argument extraction;simple-to-complex prediction",
        "author": "",
        "aff": "Wangxuan Institute of Computer Technology, Peking University and Center for Data Science, Peking University; Wangxuan Institute of Computer Technology, Peking University and School of Intelligence Science and Technology, Peking University; Wangxuan Institute of Computer Technology, Peking University and National Key Laboratory of General Artificial Intelligence",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/zhangyx0417/simple_to_complex"
    },
    {
        "id": "dpS5VxAwuF",
        "title": "Multimodal Embodied Plan Prediction Augmented with Synthetic Embodied Dialogue",
        "track": "main",
        "status": "Long Main",
        "keywords": "Embodied AI;Embodied Task Completion;Language and Robotics;Plan Prediction;Dialog Simulation",
        "author": "",
        "aff": "University of Illinois Urbana-Champaign; Northeastern University; Amazon",
        "rating": "",
        "confidence": "4;1;5",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "dq25TkeI1W",
        "title": "Probing LLMs for hate speech detection: strengths and vulnerabilities",
        "track": "main",
        "status": "Long Findings",
        "keywords": "hate speech;explanation;large language models;detection",
        "author": "",
        "aff": "Indian Institute of Technology, Kharagpur",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "drG2ScCe4C",
        "title": "Spoiler Detection as Semantic Text Matching",
        "track": "main",
        "status": "Short Main",
        "keywords": "dataset;spoiler detection;semantic text matching",
        "author": "",
        "aff": "University of California, San Diego",
        "rating": "",
        "confidence": "4;5;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/bobotran/spoiler-matching"
    },
    {
        "id": "du1t38uXPA",
        "title": "DeCrisisMB: Debiased Semi-Supervised Learning for Crisis Tweet Classification via Memory Bank",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Semi-Supervised Learning;Debiasing;Crisis Tweet Classification",
        "author": "",
        "aff": "Computer Science, University of Illinois Chicago",
        "rating": "",
        "confidence": "4;4;3;4",
        "correctness": "4;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/HenryPengZou/DeCrisisMB"
    },
    {
        "id": "dvDi1Oc2y7",
        "title": "GBT: Generative Boosting Training Approach for Paraphrase Identification",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Paraphrase Identification;Data Augmentation;Text Semantic Matching",
        "author": "",
        "aff": "School of Computer Science and Technology, Soochow University, SuZhou, China",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "2;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "dwGKBFXiy2",
        "title": "NASH: A Simple Unified Framework of Structured Pruning for Accelerating Encoder-Decoder Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Model Compression;Structured Pruning;Encoder-Decoder Language Model",
        "author": "",
        "aff": "Michigan State University; KT; KAIST AI",
        "rating": "",
        "confidence": "4;1;3;4",
        "correctness": "3;4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/jongwooko/NASH-Pruning-Official"
    },
    {
        "id": "dwj886NUqy",
        "title": "GreedyCAS: Unsupervised Scientific Abstract Segmentation with Normalized Mutual Information",
        "track": "main",
        "status": "Long Main",
        "keywords": "Abstract Segmentation;Mutual Information;Argument Mining",
        "author": "",
        "aff": "Institute of Neuroinformatics, University of Zurich and ETH Zurich, Switzerland; Linguistic Research Infrastructure, University of Zurich, Switzerland",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/CharizardAcademy/GreedyCAS.git"
    },
    {
        "id": "dxCviFd7rj",
        "title": "Visual Elements Mining as Prompts for Instruction Learning for Target-Oriented Multimodal Sentiment Classification",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Target-oriented multimodal sentiment classification;Instruction learning",
        "author": "",
        "aff": "University of Science and Technology of China",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/long8181/VEMP"
    },
    {
        "id": "e2B31gDhnj",
        "title": "Domain Private Transformers for Multi-Domain Dialog Systems",
        "track": "main",
        "status": "Short Findings",
        "keywords": "differential privacy;language models;dialogue;multi-domain language models",
        "author": "",
        "aff": "Toyota Technicological Institute, Chicago, IL; ASAPP Inc, New York, New York",
        "rating": "",
        "confidence": "2;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "e3eIqCPCT9",
        "title": "Learning to Rank Generation with Pairwise Partial Rewards",
        "track": "main",
        "status": "Long Main",
        "keywords": "Reinforcement learning;learning to rank;reward shaping;conditional text generation",
        "author": "",
        "aff": "Seoul National University",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/jinulee-v/PairwisePartialReward"
    },
    {
        "id": "e3gXrvjGys",
        "title": "A Unified Framework for Synaesthesia Analysis",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Synaesthesia Analysis;Generation Model;Lingusitic",
        "author": "",
        "aff": "Institute of Linguistics, Chinese Academy of Social Sciences; Natural Language Processing Lab, Soochow University",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "e4dXIBRQ9u",
        "title": "Grammatical Error Correction via Mixed-Grained Weighted Training",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Grammatical Error Correction;Weighted Training",
        "author": "",
        "aff": "MOE Key Laboratory of Trustworthy Distributed Computing and Service, Beijing University of Posts and Telecommunications, Beijing, China; University of Science and Technology of China, Hefei, China",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "e4m1Gu6rVP",
        "title": "Distilling ChatGPT for Explainable Automated Student Answer Assessment",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Student answer assessment;Rationale generation;Large language model",
        "author": "",
        "aff": "AQA, UK; Department of Informatics, King\u2019s College London, UK and The Alan Turing Institute, UK; Department of Informatics, King\u2019s College London, UK",
        "rating": "",
        "confidence": "2;3;4",
        "correctness": "4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/lijiazheng99/aera"
    },
    {
        "id": "e5UzmaR8EE",
        "title": "Towards Interpretable Mental Health Analysis with Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "mental health analysis;large language models;prompt engineering;explainability",
        "author": "",
        "aff": "University of Helsinki; Jiangxi Normal University; The University of Manchester, Artificial Intelligence Research Center, AIST; Yale University (formerly The University of Manchester); The University of Manchester",
        "rating": "",
        "confidence": "5;3;5;4",
        "correctness": "4;3;5;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/SteveKGYang/MentalLLaMA"
    },
    {
        "id": "e8jvAr4Aaj",
        "title": "Enhancing Conversational Search: Large Language Model-Aided Informative Query Rewriting",
        "track": "main",
        "status": "Long Findings",
        "keywords": "conversational search;conversational passage retrieval;query rewriting;query reformulation",
        "author": "",
        "aff": "University of Liverpool; University College London; Uppsala University",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/smartyfh/InfoCQR"
    },
    {
        "id": "e8wYLib8HC",
        "title": "Transformer Working Memory Enables Regular Language Reasoning And Natural Language Length Extrapolation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Transformer;Algorithmic reasoning;Length extrapolation;Working memory",
        "author": "",
        "aff": "Princeton University; Carnegie Mellon University",
        "rating": "",
        "confidence": "3;4;4;2",
        "correctness": "4;4;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "eBUgomB8uo",
        "title": "Towards Multilingual Interlinear Morphological Glossing",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Computational Language Documentation; Interlinear Morphological Glosses; Structured Prediction;",
        "author": "",
        "aff": "Universit\u00e9 Paris-Saclay & CNRS, LISN, rue du Belv\u00e9d\u00e8re, 91405 Orsay, France; Sorbonne Universit\u00e9 & CNRS, ISIR, 5 Place Jussieu, 75005 Paris, France",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "2;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "eCXfUq3RDf",
        "title": "Miracle: Towards Personalized Dialogue Generation with Latent-Space Multiple Personal Attribute Control",
        "track": "main",
        "status": "Long Findings",
        "keywords": "personalized response generaion;dialogue;Natural language generation",
        "author": "",
        "aff": "Cognitive Computing and Intelligent Information Processing (CCIIP) Laboratory, School of Computer Science and Technology, Huazhong University of Science and Technology; Beijing Institute of Technology; Ping An Property & Casualty Insurance company of China, Ltd.; Brilliance Technology Co. Ltd.",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "2;4;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/LZY-the-boys/MIRACLE"
    },
    {
        "id": "eEV5S2EIp9",
        "title": "Transfer-Free Data-Efficient Multilingual Slot Labeling",
        "track": "main",
        "status": "Long Main",
        "keywords": "Dialogue NLU;Multilingual;Slot Labeling;Data Efficient",
        "author": "",
        "aff": "Language Technology Lab, University of Cambridge",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "eFnBXtZXIH",
        "title": "When Reviewers Lock Horns: Finding Disagreements in Scientific Peer Reviews",
        "track": "main",
        "status": "Short Main",
        "keywords": "Contradiction Detection;Peer Reviews;NLP",
        "author": "",
        "aff": "Indian Institute of Technology Patna, India; National Center for Computational Sciences, Oak Ridge National Laboratory, USA",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "4;2;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://www.iitp.ac.in/~ai-nlp-ml/resources.html#ContraSciView",
        "github": "https://github.com/sandeep82945/Contradiction-in-Peer-Review"
    },
    {
        "id": "eGNwWBfqqs",
        "title": "CCSRD: Content-Centric Speech Representation Disentanglement Learning for End-to-End Speech Translation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "speech translation;representation disentanglement",
        "author": "",
        "aff": "College of Intelligence and Computing, Tianjin University, Tianjin, China",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "eHqrdft1wn",
        "title": "Aligning Language Models to User Opinions",
        "track": "main",
        "status": "Long Findings",
        "keywords": "personalization;large language model",
        "author": "",
        "aff": "University of British Columbia, Vector Institute for AI; Allen Institute of AI",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/eujhwang/personalized-llms"
    },
    {
        "id": "eNu9odz1sz",
        "title": "Universal Domain Adaptation for Robust Handling of Distributional Shifts in NLP",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Domain Adaptation;Universal Domain Adaptation;Out-of-Distribution Detection",
        "author": "",
        "aff": "Seoul National University, NA VER Cloud, NA VER AI Lab; Seoul National University, NA VER Cloud; Seoul National University, IntelliSys; NA VER Cloud, NA VER AI Lab, KAIST; Seoul National University; Hanyang University",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "eSM4RWpuJF",
        "title": "A Hierarchical Encoding-Decoding Scheme for Abstractive Multi-document Summarization",
        "track": "main",
        "status": "Long Findings",
        "keywords": "multi-document summarization;abstractive summarization;pre-trained language models;hierarchical",
        "author": "",
        "aff": "DAMO Academy, Alibaba Group, Singapore & National University of Singapore; National University of Singapore; DAMO Academy, Alibaba Group, Singapore & Hupan Lab, Hangzhou, China",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "2;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/DAMO-NLP-SG/HierEncDec"
    },
    {
        "id": "eTDs4UY52h",
        "title": "Automatic Debate Evaluation with Argumentation Semantics and Natural Language Argument Graph Networks",
        "track": "main",
        "status": "Long Main",
        "keywords": "Argument Evaluation;Debate Analysis;Argumentation Theory;Computational Argumentation",
        "author": "",
        "aff": "Centre for Argument Technology, University of Dundee, Dundee DD1 4HN, United Kingdom; VRAIN, Universitat Polit\u00e8cnica de Val\u00e8ncia, 46022 Val\u00e8ncia, Spain",
        "rating": "",
        "confidence": "3;4;5",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "eWW0KQhsHe",
        "title": "CHEF in the Language Kitchen: A Generative Data Augmentation Leveraging Korean Morpheme Ingredients",
        "track": "main",
        "status": "Long Main",
        "keywords": "Data Augmentation;Morpheme Blender;Label Discriminator;Contrastive Learning;Korean Language",
        "author": "",
        "aff": "Department of Computer Science and Engineering, Korea University; Upstage",
        "rating": "",
        "confidence": "3;2;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "eXV8sdO5HL",
        "title": "Multi-level Contrastive Learning for Script-based Character Understanding",
        "track": "main",
        "status": "Long Main",
        "keywords": "Natural Language Processing;Character Understanding;Contrastive Learning",
        "author": "",
        "aff": "Shenzhen International Graduate School, Tsinghua University; School of Computer Science, Beijing University of Posts and Telecommunications; Halicio \u02d8glu Data Science Institute, University of California, San Diego; Independent Researcher",
        "rating": "",
        "confidence": "4;4;3;3",
        "correctness": "3;4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "eaUi1mcvrM",
        "title": "INSTRUCTSCORE: Towards Explainable Text Generation Evaluation with Automatic Feedback",
        "track": "main",
        "status": "Long Main",
        "keywords": "Text generation evaluation;Explainable metric",
        "author": "",
        "aff": "Carnegie Mellon University; University of California, Santa Barbara; Google Research",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "ebSOK1nV2r",
        "title": "Answering Questions by Meta-Reasoning over Multiple Chains of Thought",
        "track": "main",
        "status": "Long Main",
        "keywords": "Question Answering;Multi-hop Question Answering;Reasoning;Few-shot;Chain of Thought",
        "author": "",
        "aff": "Tel Aviv University, Allen Institute for AI; Tel Aviv University; Bar Ilan University",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "edwSiVzFpU",
        "title": "End-to-end Task-oriented Dialogue: A Survey of Tasks, Methods, and Future Directions",
        "track": "main",
        "status": "Long Main",
        "keywords": "End-to-End Task-Oriented Dialogue (EToD);Task-oriented Dialogue Systems (ToD);Pre-trained Models in Dialogue Systems",
        "author": "",
        "aff": "Department of Computer Science, Columbia University; School of Computer Science and Engineering, Central South University; Research Center for Social Computing and Information Retrieval; Singapore Management University; School of Engineering, Westlake University; Harbin Institute of Technology, China",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://etods.net/",
        "github": ""
    },
    {
        "id": "eeP1y7zPQ7",
        "title": "Fast and Robust Early-Exiting Framework for Autoregressive Language Models with Synchronized Parallel Decoding",
        "track": "main",
        "status": "Long Main",
        "keywords": "Efficient Decoding of Language Model;Early-Exiting Framework;Parallel Decoding;Adaptive Confidence Estimation",
        "author": "",
        "aff": "AWS AI; KAIST AI",
        "rating": "",
        "confidence": "4;3;4;4",
        "correctness": "4;5;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/raymin0223/fast_robust_early_exit"
    },
    {
        "id": "eiFRPhpsW6",
        "title": "Why Should This Article Be Deleted? Transparent Stance Detection in Multilingual Wikipedia Editor Discussions",
        "track": "main",
        "status": "Long Main",
        "keywords": "Wikipedia;deletion discussion;stance detection;content moderation;policy;multilingual",
        "author": "",
        "aff": "Hasso Plattner Institute, Germany; University of Copenhagen, Denmark",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://huggingface.co/datasets/copenlu/wiki-stance",
        "github": "https://github.com/copenlu/wiki-stance"
    },
    {
        "id": "eiHT1VAs4K",
        "title": "Preserving Knowledge Invariance: Rethinking Robustness Evaluation of Open Information Extraction",
        "track": "main",
        "status": "Long Main",
        "keywords": "open information extraction;robustness evaluation;high-quality paraphrase",
        "author": "",
        "aff": "Department of Computer Science and Technology, BNRist, Tsinghua University; University of International Business and Economics",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/qijimrc/ROBUST"
    },
    {
        "id": "erorKQYQ7P",
        "title": "Co$^2$PT: Mitigating Bias in Pre-trained Language Models through Counterfactual Contrastive Prompt Tuning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "bias;contrastive learning;prompt tuning",
        "author": "",
        "aff": "Texas A&M University; George Mason University",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "euYA3EmI0e",
        "title": "Learning to Correct Noisy Labels for Fine-Grained Entity Typing via Co-Prediction Prompt Tuning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "fine-grained entity typing;natural language processing;noisy labels;co-prediction prompt tuning;large language model",
        "author": "",
        "aff": "Institute of Information Engineering, CAS, China; Meituan, China; Institute of Information Engineering, CAS, China; School of Cyber Security, UCAS, China",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "ev8dLLwScW",
        "title": "Ditto: A Simple and Efficient Approach to Improve Sentence Embeddings",
        "track": "main",
        "status": "Short Main",
        "keywords": "Sentence embeddings;BERT;Transformer;Self-attention",
        "author": "",
        "aff": "Speech Lab, Alibaba Group",
        "rating": "",
        "confidence": "4;2;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/alibaba-damo-academy/SpokenNLP/tree/main/ditto"
    },
    {
        "id": "ewedHtUI5X",
        "title": "ASSERT: Automated Safety Scenario Red Teaming for Evaluating the Robustness of Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "robustness;safety;red teaming;large language models",
        "author": "",
        "aff": "University of California, Santa Barbara, Santa Barbara, CA",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "eyuTFB2CBM",
        "title": "KEPL: Knowledge Enhanced Prompt Learning for Chinese Hypernym-Hyponym Extraction",
        "track": "main",
        "status": "Long Main",
        "keywords": "Knowledge Base;prompt;Hypernym discovery",
        "author": "",
        "aff": "Tencent Machine Learning Platform, Tencent, Beijing, China; China University of Mining & Technology, Beijing; Institute of Automation, Chinese Academy of Sciences, Beijing, China",
        "rating": "",
        "confidence": "5;3;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "f05z3XqUeu",
        "title": "RainProof: An Umbrella to Shield Text Generator from Out-Of-Distribution Data",
        "track": "main",
        "status": "Long Main",
        "keywords": "NLP;OOD detection;natural language generation",
        "author": "",
        "aff": "ILLS, MILA - Quebec AI Institute, McGill University, Paris-Saclay University; ILLS, MILA - Quebec AI Institute, CNRS, CentraleSup\u00e9lec, Paris-Saclay University; MICS, CentraleSup\u00e9lec, Paris-Saclay University, Equall, Paris",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "f10SqktqkF",
        "title": "Investigating Online Community Engagement through Stancetaking",
        "track": "main",
        "status": "Long Findings",
        "keywords": "stancetaking; community variation; sociolinguistics; community identity",
        "author": "",
        "aff": "Department of Computer Science, University of Toronto",
        "rating": "",
        "confidence": "5;4;2",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "f1y1tG5pAE",
        "title": "The BLA Benchmark: Investigating Basic Language Abilities of Pre-Trained Multimodal Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Dataset;Evaluation;Zero-shot;Prompting;Visual Grounding;Language Constructions",
        "author": "",
        "aff": "IvI, University of Amsterdam; ILLC, University of Amsterdam",
        "rating": "",
        "confidence": "5;5;4",
        "correctness": "4;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "f34v92a86l",
        "title": "Efficient Grammatical Error Correction Via Multi-Task Training and Optimized Training Schedule",
        "track": "main",
        "status": "Long Main",
        "keywords": "Grammatical error correction;Multi-task training;Sequence-to-sequence;Fine-tuning",
        "author": "",
        "aff": "Huawei Noah\u2019s Ark Lab; St. Petersburg Department of the Steklov Institute of Mathematics",
        "rating": "",
        "confidence": "4;5;5;4",
        "correctness": "2;4;5;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "f42iMss8J3",
        "title": "Visual Storytelling with Question-Answer Plans",
        "track": "main",
        "status": "Long Findings",
        "keywords": "visual storytelling;multimodaility;story generation",
        "author": "",
        "aff": "Institute for Language, Cognition and Computation, School of Informatics, University of Edinburgh",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "f6S1411OlZ",
        "title": "Towards a Unified Framework for Reference Retrieval and Related Work Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "related work generation;lexicon-enhance retrieval;instruction tuning",
        "author": "",
        "aff": "Leiden University, Leiden, The Netherlands; Computational Bioscience Research Center, KAUST; Shandong University, Qingdao, China",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "f7eqyX0nJP",
        "title": "ZEROTOP: Zero-Shot Task-Oriented Semantic Parsing using Large Language Models",
        "track": "main",
        "status": "Short Main",
        "keywords": "zero-shot;semantic parsing;mtop;large language models;llm;QA datasets",
        "author": "",
        "aff": "Microsoft Semantic Machines; UC San Diego; OpenAI",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "fCvJrponuK",
        "title": "Sparse Black-Box Multimodal Attack for Vision-Language Adversary Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Vision-and-Language;adversarial learning;multimodal attack;black-box attack",
        "author": "",
        "aff": "Alibaba Group; School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China",
        "rating": "",
        "confidence": "4;3;4;4",
        "correctness": "2;3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/JHL-HUST/SparseMA"
    },
    {
        "id": "fEuslEGN0j",
        "title": "Fine-tuned LLMs Know More, Hallucinate Less with Few-Shot Sequence-to-Sequence Semantic Parsing over Wikidata",
        "track": "main",
        "status": "Long Main",
        "keywords": "knowledge base question answering;Wikidata;semantic parsing;large language models",
        "author": "",
        "aff": "Computer Science Department, Stanford University; Ailly.ai",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/stanford-oval/wikidata-emnlp23"
    },
    {
        "id": "fG6zH1LBHE",
        "title": "MediaHG: Rethinking Eye-catchy Features in Social Media Headline Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "headline generation\uff0cstyle-content attractiveness\uff0csocial media",
        "author": "",
        "aff": "Zhejiang University",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Rosenn2000/MediaHG"
    },
    {
        "id": "fK6N4R6TpF",
        "title": "NERvous About My Health: Constructing a Bengali Medical Named Entity Recognition Dataset",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Named Entity Recognition;Natural Language Processing;Consumer Health",
        "author": "",
        "aff": "Islamic University of Technology, Queen\u2019s University; Islamic University of Technology",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/alvi-khan/Bangla-HealthNER"
    },
    {
        "id": "fL8AKDvELp",
        "title": "HyperRouter: Towards Efficient Training and Inference of Sparse Mixture of Experts",
        "track": "main",
        "status": "Short Main",
        "keywords": "Sparse mixture of experts;hypernetwork;efficient training of LLMs;large language models",
        "author": "",
        "aff": "Independent Researcher; AISIA Lab, University of Science, Vietnam National University Ho Chi Minh City; Univ. Grenoble Alpes, Inria, CNRS, Grenoble INP, LJK, 38000 Grenoble, France; University of Tennessee at Chattanooga; Institute for Infocomm Research (I2R), A*STAR, Singapore; VinUniversity; Salesforce Research Asia; Singapore Management University",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/giangdip2410/HyperRouter"
    },
    {
        "id": "fLJVvFGFEE",
        "title": "Representativeness as a Forgotten Lesson for Multilingual and Code-switched Data Collection and Preparation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multilingualism;Code-switching;representativeness;data preparation;annotation;transcription",
        "author": "",
        "aff": "Universiteit Gent, Gent, Belgium; Microsoft Research India, Bangalore, India; Brown University",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "fM7x9Lvb9r",
        "title": "Controllable Contrastive Generation for Multilingual Biomedical Entity Linking",
        "track": "main",
        "status": "Long Main",
        "keywords": "Multilingual Biomedical Entity Linking;Controllable Generation;Contrastive Learning",
        "author": "",
        "aff": "Peng Cheng Laboratory, Shenzhen, China; The Hong Kong University of Science and Technology, Hong Kong, China; Harbin Institute of Technology (Shenzhen), Shenzhen, China",
        "rating": "",
        "confidence": "4;4;3;4",
        "correctness": "3;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "fNi7eet4Qc",
        "title": "Prompt-Based Editing for Text Style Transfer",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Text style transfer; Prompt-based editing; Large language models",
        "author": "",
        "aff": "Dept. Computing Science, Alberta Machine Intelligence Institute (Amii), University of Alberta, Canada; Dept. Computing Science, Alberta Machine Intelligence Institute (Amii), University of Alberta, Canada; Canada CIFAR AI Chair, Amii",
        "rating": "",
        "confidence": "4;5;5",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/MANGA-UOFA/Prompt-Edit"
    },
    {
        "id": "fNlSVIsbIT",
        "title": "HoneyBee: Progressive Instruction Finetuning of Large Language Models for Materials Science",
        "track": "main",
        "status": "Long Findings",
        "keywords": "materials science;LLaMa;instructions based finetuning;progressive finetuning;feedback based instructions",
        "author": "",
        "aff": "University of Montreal / Mila - Quebec AI; Intel Labs; University of Waterloo",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/BangLab-UdeM-Mila/NLP4MatSci-HoneyBee"
    },
    {
        "id": "fONyQKyvsY",
        "title": "Analysing State-Backed Propaganda Websites: a New Dataset and Linguistic Study",
        "track": "main",
        "status": "Short Main",
        "keywords": "misinformation;disinformation;social media;dataset;social science",
        "author": "",
        "aff": "Department of Computer Science, University of Sheffield, Sheffield, UK",
        "rating": "",
        "confidence": "4;3;2",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "fOoZipX9z3",
        "title": "Grounding Visual Illusions in Language: Do Vision-Language Models Perceive Illusions Like Humans?",
        "track": "main",
        "status": "Long Main",
        "keywords": "vision-language model;visual illusion;grounding",
        "author": "",
        "aff": "The New School; Northwestern University; University of California, Berkeley; University of Michigan",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "5;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "github.com/vl-illusion/dataset"
    },
    {
        "id": "fRpif5Sflc",
        "title": "Rumor Detection on Social Media with Crowd Intelligence and ChatGPT-Assisted Networks",
        "track": "main",
        "status": "Long Main",
        "keywords": "Rumor Detection; Crowd Intelligence; Large Language Model; Heterogeneous Graph; Semantic Feature Learning",
        "author": "",
        "aff": "School of New Media and Communication, Tianjin University, Tianjin, China; College of Intelligence and Computing, Tianjin University, Tianjin, China; College of Information Science and Engineering, Shenyang University of Technology, China",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "5;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "fXyoHAVffT",
        "title": "Unsupervised Candidate Answer Extraction through Differentiable Masker-Reconstructor Model",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Candidate Answer Extraction;Self-consitency Learning;Unsupervised Learning;Masker-Reconstructor Model",
        "author": "",
        "aff": "Texas A&M University; George Mason University",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://edillower.github.io/"
    },
    {
        "id": "fbbbbfhAxC",
        "title": "Cross-lingual Transfer Can Worsen Bias in Sentiment Analysis",
        "track": "main",
        "status": "Long Main",
        "keywords": "bias;fairness;multilingual;sentiment analysis;counterfactual;contrastive",
        "author": "",
        "aff": "School of Informatics, University of Edinburgh; Cohere; School of Informatics, University of Edinburgh",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/seraphinatarrant/multilingual_sentiment_analysis"
    },
    {
        "id": "feiAVaSXdb",
        "title": "Measuring and Narrowing the Compositionality Gap in Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "language modeling;prompting;question answering;language model tool use",
        "author": "",
        "aff": "Paul G. Allen School of Computer Science & Engineering, University of Washington; Allen Institute for AI; Meta AI Research",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ofirpress/self-ask"
    },
    {
        "id": "fgQ7JQoBIM",
        "title": "C-STS: Conditional Semantic Textual Similarity",
        "track": "main",
        "status": "Long Main",
        "keywords": "Conditional similarity;Sentence similarity;Dataset",
        "author": "",
        "aff": "The Allen Institute for AI; Princeton University; Georgia Tech",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "www.github.com/princeton-nlp/c-sts"
    },
    {
        "id": "fhEkqMyvb0",
        "title": "Disentangling Structure and Style: Political Bias Detection in News by Inducing Document Hierarchy",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Natural Language Processing;NLP Applications;Political Bias;Journalism",
        "author": "",
        "aff": "KAIST AI; KAIST Moon Soul Graduate School of Future Strategy",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/xfactlab/emnlp2023-Document-Hierarchy"
    },
    {
        "id": "fi90p5364y",
        "title": "Generating Commonsense Counterfactuals for Stable Relation Extraction",
        "track": "main",
        "status": "Long Main",
        "keywords": "Counterfactual Data Augmentation;Commonsense-constrained Generation;Relation Extraction",
        "author": "",
        "aff": "School of Computer Science, Wuhan University, China; School of Computer Science, Wuhan University, China; Intellectual Computing Laboratory for Cultural Heritage, Wuhan University, China",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/NLPWM-WHU/CCG"
    },
    {
        "id": "fkAKjbRvxj",
        "title": "Information Value: Measuring Utterance Predictability as Distance from Plausible Alternatives",
        "track": "main",
        "status": "Long Main",
        "keywords": "surprisal;alternatives;acceptability;reading times;predictability",
        "author": "",
        "aff": "Institute for Logic, Language and Computation, University of Amsterdam; Centre for Speech Technology Research, University of Edinburgh",
        "rating": "",
        "confidence": "5;4;2;4",
        "correctness": "4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/dmg-illc/information-value"
    },
    {
        "id": "fkmSyrSjnq",
        "title": "Topic-Informed Dialogue Summarization using Topic Distribution and Prompt-based Modeling",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Dialogue Summarization;Topic Distribution;Topic-Informed Prompt",
        "author": "",
        "aff": "Department of Artificial Intelligence, Sungkyunkwan University; Department of Computer Science and Engineering, Sungkyunkwan University",
        "rating": "",
        "confidence": "2;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "flkXLt9WKn",
        "title": "Dialogue Chain-of-Thought Distillation for Commonsense-aware Conversational Agents",
        "track": "main",
        "status": "Long Main",
        "keywords": "Commonsense Reasoning;Dialogue;Large Language Model",
        "author": "",
        "aff": "Yonsei University; University of Minnesota",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "3;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://dialoguecot.web.app/",
        "github": "https://github.com/kyle8581/DialogueCoT"
    },
    {
        "id": "fonxcS8gqM",
        "title": "Improving Long Document Topic Segmentation Models With Enhanced Coherence Modeling",
        "track": "main",
        "status": "Long Main",
        "keywords": "topic segmentation;text coherence;semantic similarity;sentence structure;contrastive learning",
        "author": "",
        "aff": "Speech Lab, Alibaba Group",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/alibaba-damo-academy/SpokenNLP/parts"
    },
    {
        "id": "fqKoLPfCba",
        "title": "Large-Scale and Multi-Perspective Opinion Summarization with Diverse Review Subsets",
        "track": "main",
        "status": "Long Findings",
        "keywords": "opinion summarization;multi-document summarization;large-scale;multi-perspective;contrastive learning",
        "author": "",
        "aff": "Department of Computer Science and Technology, Tongji University, Shanghai, China",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "fqWbXPX99P",
        "title": "CT-GAT: Cross-Task Generative Adversarial Attack based on Transferability",
        "track": "main",
        "status": "Long Main",
        "keywords": "Adversarial Attacks;Transferability;Generative Methods",
        "author": "",
        "aff": "Institute of Information Engineering, Chinese Academy of Sciences; Institute of Information Engineering, Chinese Academy of Sciences; School of Cyber Security, University of Chinese Academy of Sciences",
        "rating": "",
        "confidence": "3;4;2;3",
        "correctness": "3;2;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/xiaoxuanNLP/CT-GAT"
    },
    {
        "id": "fsGowIsscZ",
        "title": "A Diachronic Perspective on User Trust in AI under Uncertainty",
        "track": "main",
        "status": "Long Main",
        "keywords": "trust;calibration;confidence;collaboration",
        "author": "",
        "aff": "Department of Computer Science, ETH Z\u00fcrich",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "github.com/zouharvi/trust-intervention"
    },
    {
        "id": "ft0c1K3492",
        "title": "SciRepEval: A Multi-Format Benchmark for Scientific Document Representations",
        "track": "main",
        "status": "Long Main",
        "keywords": "Scientific tasks benchmark;multi task learning;task specific embeddings",
        "author": "",
        "aff": "Allen Institute for Artificial Intelligence, Seattle, WA, USA; Yale University, CT, USA; Northwestern University, IL, USA",
        "rating": "",
        "confidence": "3;2;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "fvGJOVkm0b",
        "title": "EntSUMv2: Dataset, Models and Evaluation for More Abstractive Entity-Centric Summarization",
        "track": "main",
        "status": "Short Main",
        "keywords": "summarization;entity;dataset;evaluation",
        "author": "",
        "aff": "Amazon Alexa AI; Bloomberg",
        "rating": "",
        "confidence": "4;2;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "fwA8iKyIlk",
        "title": "Elaborative Simplification as Implicit Questions Under Discussion",
        "track": "main",
        "status": "Long Main",
        "keywords": "text simplification;elaborative simplification;questions under discussion",
        "author": "",
        "aff": "Linguistics, The University of Texas at Austin; Electrical and Computer Engineering, The University of Texas at Austin",
        "rating": "",
        "confidence": "5;3;5",
        "correctness": "4;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "fwmZinFwgX",
        "title": "Enhancing Reasoning Capabilities by Instruction Learning and Chain-of-Thoughts for Implicit Discourse Relation Recognition",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Implicit discourse relation recognition;Instruction learning;In-context learning;Chain-of-Thoughts",
        "author": "",
        "aff": "School of Computer Science and Technology, Soochow University, SuZhou, China",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "fxdvWG4rJe",
        "title": "Towards Making the Most of ChatGPT for Machine Translation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Machine Translation;Large Language Model;Prompt Engineering",
        "author": "",
        "aff": "JD Explore Academy; The University of Sydney; Beihang University; Harbin Institute of Technology, Shenzhen; Wuhan University",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "4;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Romainpkq/ChatGPT4MT"
    },
    {
        "id": "fxotfo1j8T",
        "title": "Navigating the Grey Area: How Expressions of Uncertainty and Overconfidence Affect Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "expressions of uncertainty;analysis of language models",
        "author": "",
        "aff": "Stanford University",
        "rating": "",
        "confidence": "2;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "fyza2OQ9NI",
        "title": "MathDial: A Dialogue Tutoring Dataset with Rich Pedagogical Properties Grounded in Math Reasoning Problems",
        "track": "main",
        "status": "Long Findings",
        "keywords": "dialogue;dataset;collection;response generation;natural language generation;math;reasoning;tutoring",
        "author": "",
        "aff": "National Institute of Education, Nanyang Technological University; Department of Computer Science, ETH Zurich; Professorship for Learning Sciences and Higher Education, ETH Zurich; ETH AI Center; Ubiquitous Knowledge Processing Lab (UKP Lab), Department of Computer Science and Hessian Center for AI (hessian.AI), TU Darmstadt",
        "rating": "",
        "confidence": "3;4;4;4",
        "correctness": "3;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/eth-nlped/mathdial"
    },
    {
        "id": "fzb2sxexWN",
        "title": "Semi-automatic Data Enhancement for Document-Level Relation Extraction with Distant Supervision from Large Language Models",
        "track": "main",
        "status": "Short Main",
        "keywords": "Long Context\uff0cDocument-level\uff0cRelation Extraction;Large Language Model",
        "author": "",
        "aff": "National Key Laboratory of General Artificial Intelligence, BIGAI",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/bigai-nlco/DocGNRE"
    },
    {
        "id": "g04NBFnIxb",
        "title": "ViPE: Visualise Pretty-much Everything",
        "track": "main",
        "status": "Long Main",
        "keywords": "Visual metaphors;music video generation;text-to-image synthesis;abstract visualization;diffusion models for abstract art;synthetic data generation;unsupervised label generation",
        "author": "",
        "aff": "University of T\u00fcbingen",
        "rating": "",
        "confidence": "4;3;4;2",
        "correctness": "3;3;5;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "g0wzziJSmN",
        "title": "The Effect of Scaling, Retrieval Augmentation and Form on the Factual Consistency of Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "consistency;evaluation;large language models;retrieval-augmentation;causal analysis",
        "author": "",
        "aff": "Chalmers University of Technology, University of Gothenburg; Chalmers University of Technology",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "g1LLeiHX0P",
        "title": "Representative Demonstration Selection for In-Context Learning with Two-Stage Determinantal Point Process",
        "track": "main",
        "status": "Long Main",
        "keywords": "In-Context Learning;Representative Subset Selection;Determinantal Point Process",
        "author": "",
        "aff": "School of Artificial Intelligence, University of Chinese Academy of Sciences; The Laboratory of Cognition and Decision Intelligence for Complex Systems, Institute of Automation, Chinese Academy of Sciences; Meituan, Beijing; School of Artificial Intelligence, University of Chinese Academy of Sciences; The Laboratory of Cognition and Decision Intelligence for Complex Systems, Institute of Automation, Chinese Academy of Sciences; Shanghai Artificial Intelligence Laboratory; Harbin Institute of Technology, Weihai",
        "rating": "",
        "confidence": "2;4;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "g1Q9Uu8lCp",
        "title": "xDial-Eval: A Multilingual Open-Domain Dialogue Evaluation Benchmark",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Automatic Dialogue Evaluation;Multilingual Dialogue;Large Language Models",
        "author": "",
        "aff": "Shenzhen Research Institute of Big Data, School of Data Science, The Chinese University of Hong Kong, Shenzhen, China; National University of Singapore, Singapore; Tencent AI Lab, China; Universidad Polit\u00e9cnica de Madrid, Spain",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/e0397123/xDial-Eval"
    },
    {
        "id": "g3VOQpuqlF",
        "title": "Adapting Pretrained Text-to-Text Models for Long Text Sequences",
        "track": "main",
        "status": "Long Findings",
        "keywords": "long context;summarization",
        "author": "",
        "aff": "Meta AI",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/facebookresearch/bart_ls"
    },
    {
        "id": "g3faCfrwm7",
        "title": "Just Ask for Calibration: Strategies for Eliciting Calibrated Confidence Scores from Language Models Fine-Tuned with Human Feedback",
        "track": "main",
        "status": "Short Main",
        "keywords": "calibration;RLHF;language model;verbalized probability",
        "author": "",
        "aff": "Stanford University; Harvard University",
        "rating": "",
        "confidence": "3;4;4;4",
        "correctness": "3;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "g4FAvRcSuf",
        "title": "Self-Supervised Behavior Cloned Transformers are Path Crawlers for Text Games",
        "track": "main",
        "status": "Short Findings",
        "keywords": "text games;reinforcement learning;behavior cloning;self-supervision",
        "author": "",
        "aff": "University of Arizona, USA",
        "rating": "",
        "confidence": "3;3;2",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/cognitiveailab/pathfinding-rl"
    },
    {
        "id": "g84UrdUwBA",
        "title": "Harnessing Black-Box Control to Boost Commonsense in LM's Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "controllable text generation;generative commonsense reasoning",
        "author": "",
        "aff": "Department of Computer Science, University of California, Los Angeles",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/PlusLabNLP/BOOST_EMNLP23"
    },
    {
        "id": "g8OqNaz6dY",
        "title": "Efficient Algorithms for Recognizing Weighted Tree-Adjoining Languages",
        "track": "main",
        "status": "Long Main",
        "keywords": "algorithms;parsing;semirings;tree adjoining grammars;linear indexed grammars;embedded pushdown automata",
        "author": "",
        "aff": "ETH Z\u00fcrich; University of Notre Dame",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;5;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "gAzBhetShk",
        "title": "Exploring Chain of Thought Style Prompting for Text-to-SQL",
        "track": "main",
        "status": "Long Main",
        "keywords": "Text-to-Sql;Prompt engineering;Chain-of-Thought;Least-to-Most;Question Decomposition.",
        "author": "",
        "aff": "The Ohio State University",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "gBI7thSo0X",
        "title": "Values, Ethics, Morals? On the Use of Moral Concepts in NLP Research",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Ethics;Morality;Moral Values;Natural Language Processing;Survey",
        "author": "",
        "aff": "Ethics in Information Technology, University of Hamburg, Germany; Data Science Group, University of Hamburg, Germany",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "gGmccVXoy2",
        "title": "Decomposing Complex Queries for Tip-of-the-tongue Retrieval",
        "track": "main",
        "status": "Long Findings",
        "keywords": "information retrieval; large language models; query decomposition",
        "author": "",
        "aff": "University of California Berkeley; Allen Institute for AI",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/kl2806/whatsthatbook"
    },
    {
        "id": "gI11vXg1W4",
        "title": "PRCA: Fitting Black-Box Large Language Models for Retrieval Question Answering via Pluggable Reward-Driven Contextual Adapter",
        "track": "main",
        "status": "Long Main",
        "keywords": "Retrieval Question Answering;Black-Box LLMs;Retrieval Augmentation;Pluggable Reward-Driven Contextual Adapter",
        "author": "",
        "aff": "Ping An Technology (Shenzhen) Co., Ltd., China; University of Maryland",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "gJXydPLBkt",
        "title": "QUDeval: The Evaluation of Questions Under Discussion Discourse Parsing",
        "track": "main",
        "status": "Long Main",
        "keywords": "discourse; questions under discussion; QUD; evaluation",
        "author": "",
        "aff": "Linguistics, The University of Texas at Austin; Computer Science, The University of Texas at Austin; Electrical and Computer Engineering, The University of Texas at Austin",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "gJZqSRfV21",
        "title": "ReLM: Leveraging Language Models for Enhanced Chemical Reaction Prediction",
        "track": "main",
        "status": "Short Findings",
        "keywords": "graph neural networks;chemical reaction",
        "author": "",
        "aff": "University of Science and Technology of China, Institute of Artificial Intelligence, Institute of Dataspace, Hefei Comprehensive National Science Center; University of Science and Technology of China; National University of Singapore; Hokkaido University",
        "rating": "",
        "confidence": "5;4;5",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/syr-cn/ReLM"
    },
    {
        "id": "gQUDsNE3Lh",
        "title": "HARE: Explainable Hate Speech Detection with Step-by-Step Reasoning",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Hate Speech Detection;Large Language Models",
        "author": "",
        "aff": "KAIST AI",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/joonkeekim/hare-hate-speech.git"
    },
    {
        "id": "gQeZoe2j3v",
        "title": "Mulan: A Multi-Level Alignment Model for Video Question Answering",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Video Question Answering;Multi-Level Alignment;Contrastive Learning",
        "author": "",
        "aff": "Institute of Information Engineering, Chinese Academy of Sciences; School of Cyber Security, University of Chinese Academy of Sciences; China Academy of Information and Communications Technology",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "2;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/fuyu1998/Mulan"
    },
    {
        "id": "gUKVyjoQBG",
        "title": "COHESENTIA: A Novel Benchmark of Incremental versus Holistic Assessment of Coherence in Generated Texts",
        "track": "main",
        "status": "Long Main",
        "keywords": "coherence;benchmark;cohesion;consistency;relevance;linguistic theory;gpt;nlp applications",
        "author": "",
        "aff": "Department of Computer Science, Bar Ilan University",
        "rating": "",
        "confidence": "3;4;5",
        "correctness": "4;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "gVTtkPJbRq",
        "title": "GPT-4 as an Effective Zero-Shot Evaluator for Scientific Figure Captions",
        "track": "main",
        "status": "Short Findings",
        "keywords": "text generation;scientific figure caption;caption evaluation",
        "author": "",
        "aff": "Adobe Research, San Francisco, CA, USA.; Pennsylvania State University, University Park, PA, USA.",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Crowd-AI-Lab/SciCap-Eval"
    },
    {
        "id": "gWWjz9NBo9",
        "title": "PromptMix: A Class Boundary Augmentation Method for Large Language Model Distillation",
        "track": "main",
        "status": "Long Main",
        "keywords": "large language models;knowledge distillation;text classification;few-shot learning",
        "author": "",
        "aff": "ServiceNow Research, Mila, McGill University, Canada CIFAR AI Chair; ServiceNow Research; University of Waterloo",
        "rating": "",
        "confidence": "4;5;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ServiceNow/PromptMix-EMNLP-2023"
    },
    {
        "id": "gXq1cwkUZc",
        "title": "Query Rewriting in Retrieval-Augmented Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "large language model;retrieval augmentation;query rewriting.",
        "author": "",
        "aff": "Microsoft Research Asia; Microsoft Azure AI; Department of Computer Science and Engineering, Shanghai Jiao Tong University; Key Laboratory of Shanghai Education Commission for Intelligent Interaction and Cognitive Engineering, Shanghai Jiao Tong University",
        "rating": "",
        "confidence": "4;3;4;3",
        "correctness": "2;3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/xbmxb/RAG-query-rewriting"
    },
    {
        "id": "gZhvtIRu7i",
        "title": "MILDSum: A Novel Benchmark Dataset for Multilingual Summarization of Indian Legal Case Judgments",
        "track": "main",
        "status": "Short Main",
        "keywords": "Cross-Lingual Summarization;Multilingual corpus for Summarization;Summarization-Translation Pipeline;Legal NLP",
        "author": "",
        "aff": "Indian Institute of Technology Kharagpur",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Law-AI/MILDSum"
    },
    {
        "id": "gZykO63OUh",
        "title": "DREAM: Deployment of Recombination and Ensembles in Argument Mining",
        "track": "main",
        "status": "Long Main",
        "keywords": "Argument Mining;Recombination;Ensemble Methods",
        "author": "",
        "aff": "University of Zurich, Switzerland",
        "rating": "",
        "confidence": "4;4;2",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "gccSE5vDZ7",
        "title": "Multilingual Simplification of Medical Texts",
        "track": "main",
        "status": "Long Main",
        "keywords": "Simplification;Medical Simplification;Multilingual",
        "author": "",
        "aff": "Georgia Institute of Technology; Northeastern University; The University of Texas at Austin",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "gd8TxhKoLv",
        "title": "PROTEGE: Prompt-based Diverse Question Generation from Web Articles",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large Language Models;Question Generation;Question Answering;Diversity;Fidelity",
        "author": "",
        "aff": "Amazon",
        "rating": "",
        "confidence": "2;3;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "gdUBK65fwn",
        "title": "LLM-Adapters: An Adapter Family for Parameter-Efficient Fine-Tuning of Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Parameter-Efficient Fine-Tuning;Large Language Models",
        "author": "",
        "aff": "Southwest Jiaotong University; Singapore University of Technology and Design; Singapore Management University; University of Electronic Science and Technology of China; DAMO Academy, Alibaba Group, Singapore",
        "rating": "",
        "confidence": "3;4;4;4",
        "correctness": "4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/AGI-Edgerunners/LLM-Adapters"
    },
    {
        "id": "ggTNeg2fem",
        "title": "Multimodal Automated Fact-Checking: A Survey",
        "track": "main",
        "status": "Long Findings",
        "keywords": "fact checking;multimodality;survey",
        "author": "",
        "aff": "Department of Computer Science and Technology, University of Cambridge; Department of Informatics, King\u2019s College London",
        "rating": "",
        "confidence": "5;3;3",
        "correctness": "3;2;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "ghF1EB6APx",
        "title": "Cross-Modal Conceptualization in Bottleneck Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "interpretability;cross-modal learning;concept-based models;cross-attention mechanism;robustness",
        "author": "",
        "aff": "DCS, University of Copenhagen; Research Center for AI, Innopolis University; ILCC, University of Edinburgh",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "gjrs5oF8TC",
        "title": "INVITE: a Testbed of Automatically Generated Invalid Questions to Evaluate Large Language Models for Hallucinations",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Large Language Models;Hallucinations;Question Answering",
        "author": "",
        "aff": "Amazon Alexa AI",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "gkQo3CoPLd",
        "title": "GeoLM: Empowering Language Models for Geospatially Grounded Language Understanding",
        "track": "main",
        "status": "Long Main",
        "keywords": "geospatial grounding;language model",
        "author": "",
        "aff": "Department of Computer Science and Engineering, University of Minnesota, Twin Cities; Department of Computer Science, University of Southern California; Department of Computer Science, University of California, Davis",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/knowledge-computing/geolm"
    },
    {
        "id": "glxrubmH91",
        "title": "RAPL: A Relation-Aware Prototype Learning Approach for Few-Shot Document-Level Relation Extraction",
        "track": "main",
        "status": "Long Main",
        "keywords": "Document-Level Relation Extraction;Few-Shot Learning;Metric-Based Meta-Learning;Relation-Aware Prototype Learning",
        "author": "",
        "aff": "School of Software, Tsinghua University",
        "rating": "",
        "confidence": "3;4;2",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/THU-BPM/RAPL"
    },
    {
        "id": "gmVEVn0Qi5",
        "title": "InterroLang: Exploring NLP Models and Datasets through Dialogue-based Explanations",
        "track": "main",
        "status": "Long Findings",
        "keywords": "explainability;dialogue;interpretability;dataset analysis;conversational ai;simulatability",
        "author": "",
        "aff": "Saarland Informatics Campus, Saarbr\u00fccken, Germany; Technische Universit\u00e4t Berlin, Germany; German Research Center for Artificial Intelligence (DFKI)",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "goH9e5Vd44",
        "title": "Licon: A Diverse, Controllable and Challenging Linguistic Concept Learning Benchmark",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Concept Learning;Zero-shot Learning;Linguistic Description",
        "author": "",
        "aff": "College of Computer Science, VCIP, TMCC, TBI Center, Nankai University, China",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/yushenglong1/Licon"
    },
    {
        "id": "gqkg54QNDY",
        "title": "ViSoBERT: A Pre-Trained Language Model for Vietnamese Social Media Text Processing",
        "track": "main",
        "status": "Long Main",
        "keywords": "Language Models;Social Media Processing;Low resource",
        "author": "",
        "aff": "Multimedia Communications Laboratory, University of Information Technology, Ho Chi Minh City, Vietnam; Vietnam National University, Ho Chi Minh City, Vietnam; Faculty of Information Science and Engineering, University of Information Technology, Ho Chi Minh City, Vietnam; Vietnam National University, Ho Chi Minh City, Vietnam",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://huggingface.co/uitnlp/visobert"
    },
    {
        "id": "gslZifaE3t",
        "title": "How to Determine the Most Powerful Pre-trained Language Model without Brute Force Fine-tuning? An Empirical Survey",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Pre-trained Language Models;Transfer Learning;Transferability Estimation;Model Selection",
        "author": "",
        "aff": "School of Computer Science and Engineering, Beihang University, China; Department of Computer Science, University of Manchester, United Kingdom; Faculty of Information Technology, Beijing University of Technology, China",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "gybvlVXT6z",
        "title": "Black-Box Tuning of Vision-Language Models with Effective Gradient Approximation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Prompt Tuning;Black-box Model;Vision-language Model",
        "author": "",
        "aff": "Independent Researcher; Harbin Institute of Technology, Pazhou Lab, Guangzhou; Harbin Institute of Technology; Tomorrow Advancing Life",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "gzRBs4gIbz",
        "title": "Non-autoregressive Streaming Transformer for Simultaneous Translation",
        "track": "main",
        "status": "Long Main",
        "keywords": "simultaneous translation;non-autoregressive generation",
        "author": "",
        "aff": "Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences; University of Chinese Academy of Sciences; School of Future Science and Engineering, Soochow University",
        "rating": "",
        "confidence": "4;5;2",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ictnlp/NAST"
    },
    {
        "id": "h00GHjWDEp",
        "title": "LINC: A Neurosymbolic Approach for Logical Reasoning by Combining Language Models with First-Order Logic Provers",
        "track": "main",
        "status": "Long Main",
        "keywords": "large language models;logical reasoning;neuro-symbolic AI",
        "author": "",
        "aff": "MIT CSAIL; MIT CSAIL/MIT BCS; MIT BCS",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/benlipkin/linc"
    },
    {
        "id": "h1YhUpPKEq",
        "title": "Non-Programmers Can Label Programs Indirectly via Active Examples: A Case Study with Text-to-SQL",
        "track": "main",
        "status": "Long Main",
        "keywords": "Semantic Parsing; Annotation; Code generation",
        "author": "",
        "aff": "Microsoft Semantic Machines; University of California, Berkeley",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "5;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.666666666666667,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "h1nUUpmvpf",
        "title": "Cross-Cultural Analysis of Human Values, Morals, and Biases in Folk Tales",
        "track": "main",
        "status": "Long Main",
        "keywords": "values;morality;bias;folk tales",
        "author": "",
        "aff": "Department of Computer Science, University of Hawai\u2018i at Hilo; Computer Science and Engineering, University of Michigan \u2013 Ann Arbor",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "github.com/wswu/folktales"
    },
    {
        "id": "h4NNcIZUHT",
        "title": "DiSTRICT: Dialogue State Tracking with Retriever Driven In-Context Tuning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Dialogue state tracking;in-context tuning;semantic retrieval",
        "author": "",
        "aff": "IBM Research",
        "rating": "",
        "confidence": "4;5;5",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "h5gum6ximf",
        "title": "Don't waste a single annotation: improving single-label classifiers through soft labels",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Don't Waste a Single Annotation: Improving Single-Label Classifiers Through Soft Labels",
        "author": "",
        "aff": "Department of Computer Science, The University of Sheffield, Sheffield, UK",
        "rating": "",
        "confidence": "5;4;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/GateNLP/dont-waste-single-annotation"
    },
    {
        "id": "h96N32OkAx",
        "title": "CoLT5: Faster Long-Range Transformers with Conditional Computation",
        "track": "main",
        "status": "Long Main",
        "keywords": "long context;conditional computation;efficient nlp",
        "author": "",
        "aff": "Google Research",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "hA8h2KtSv2",
        "title": "Stop Uploading Test Data in Plain Text: Practical Strategies for Mitigating Data Contamination by Evaluation Benchmarks",
        "track": "main",
        "status": "Short Main",
        "keywords": "data contamination;contamination;evaluation;test data;benchmarks;closed models;pretraining",
        "author": "",
        "aff": "Google Research; Allen Institute for Artificial Intelligence; Bar Ilan University",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "hCsppacsqS",
        "title": "MuG: A Multimodal Classification Benchmark on Game Data with Tabular, Textual, and Visual Fields",
        "track": "main",
        "status": "Long Findings",
        "keywords": "multimodal classification benchmark;resources and evaluation;multimodal graph neural network",
        "author": "",
        "aff": "Emory University",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/lujiaying/MUG-Bench"
    },
    {
        "id": "hDzfqmLrol",
        "title": "DeltaScore: Fine-Grained Story Evaluation with Perturbations",
        "track": "main",
        "status": "Long Findings",
        "keywords": "story;evaluation;metric;PLM",
        "author": "",
        "aff": "School of Computing and Information Systems, The University of Melbourne",
        "rating": "",
        "confidence": "3;3;2",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ZhuohanX/DeltaScore"
    },
    {
        "id": "hEWgNQF1TM",
        "title": "Parameter-Efficient Language Model Tuning with Active Learning in Low-Resource Settings",
        "track": "main",
        "status": "Long Main",
        "keywords": "parameter-efficient fine-tuning;active learning;low-resource settings",
        "author": "",
        "aff": "TakeLab, Faculty of Electrical Engineering and Computing, University of Zagreb, Croatia",
        "rating": "",
        "confidence": "3;2;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/josipjukic/adapter-al"
    },
    {
        "id": "hEglNMGeqj",
        "title": "Better Together: Enhancing Generative Knowledge Graph Completion with Language Models and Neighborhood Information",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Knowledge graphs;Knowledge graph completion;Language models;Graph neighborhood;Transformer",
        "author": "",
        "aff": "Neural Networks and Deep Learning Lab, MIPT, Dolgoprudny, Russia; London Institute for Mathematical Sciences, London, UK; Neural Networks and Deep Learning Lab, MIPT, Dolgoprudny, Russia; AIRI, Moscow, Russia",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "hGUu750pcx",
        "title": "Exploring Large Language Models for Multi-Modal Out-of-Distribution Detection",
        "track": "main",
        "status": "Long Findings",
        "keywords": "OOD Detection",
        "author": "",
        "aff": "Department of Computer Science and Technology, Tsinghua University; Alibaba Group",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "2;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "hInB4JIQ5P",
        "title": "CoEdIT: Text Editing by Task-Specific Instruction Tuning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Text Editing;Instruction Tuning;Large Language Models",
        "author": "",
        "aff": "Grammarly; University of Minnesota",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/vipulraheja/coedit"
    },
    {
        "id": "hMqRphmoM9",
        "title": "Prompting is not a substitute for probability measurements in large language models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Models;Behavioral Testing of Language Models;Metalinguistic Judgment;Prompting;Minimal Pairs",
        "author": "",
        "aff": "Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology; Kempner Institute, Harvard University",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/jennhu/metalinguistic-prompting"
    },
    {
        "id": "hNSbSaD1WC",
        "title": "The Cost of Compression: Investigating the Impact of Compression on Parametric Knowledge in Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Pruning;Quantization;Language Models",
        "author": "",
        "aff": "University of Wisconsin - Madison",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/NamburiSrinath/LLMCompression"
    },
    {
        "id": "hPr1QC623H",
        "title": "Is Probing All You Need? Indicator Tasks as an Alternative to Probing Embedding Spaces",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Probing;Probe;Indicator;Word Representations;Embedding Space;Interpretability;Context;Social Bias;Morphology;Semantics;Gender;Concept Erasure",
        "author": "",
        "aff": "Bar-Ilan University",
        "rating": "",
        "confidence": "2;2;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "hRJZIsC9VU",
        "title": "Introducing Rhetorical Parallelism Detection: A New Task with Datasets, Metrics, and Baselines",
        "track": "main",
        "status": "Long Main",
        "keywords": "rhetorical parallelism;sequence labeling;NLP;Latin;Chinese;resource",
        "author": "",
        "aff": "Villanova University; University of Notre Dame",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "5;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "hTLIAYTi5w",
        "title": "ClozEx: A Task toward Generation of English Cloze Explanation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "language assessment;english education;text generation;dataset",
        "author": "",
        "aff": "Tokyo Metropolitan University. 6-6 Asahigaoka, Hino, Tokyo 191-0065, Japan; Hitotsubashi University. 2-1 Naka, Kunitachi, Tokyo 186-8601, Japan; CyberAgent, Inc. 2-24-12 Shibuya Shibuya-ku, Tokyo 150-6121, Japan",
        "rating": "",
        "confidence": "4;5;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/zz-zhang/ClozEx"
    },
    {
        "id": "hUWrmo7nNh",
        "title": "Bi-Drop: Enhancing Fine-tuning Generalization via Synchronous sub-net Estimation and Optimization",
        "track": "main",
        "status": "Long Findings",
        "keywords": "pretrained language model;adaptive sub-net Optimization",
        "author": "",
        "aff": "National Key Laboratory for Multimedia Information Processing, Peking University; School of Software & Microelectronics, Peking University; National Key Laboratory for Multimedia Information Processing, Peking University; School of Computer Science, Peking University; Alibaba Group; Tencent Cloud AI",
        "rating": "",
        "confidence": "3;3;2",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "hWNsvpWfhy",
        "title": "Localizing Active Objects from Egocentric Vision with Symbolic World Knowledge",
        "track": "main",
        "status": "Long Main",
        "keywords": "Object state change;Pre-conditions;Post-conditions;Egocentric videos;Active grounding;Multimodal",
        "author": "",
        "aff": "University of California, Los Angeles",
        "rating": "",
        "confidence": "4;5;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/PlusLabNLP/ENVISION"
    },
    {
        "id": "hXXyBtlo4D",
        "title": "MMNMT: Modularizing Multilingual Neural Machine Translation with Flexibly Assembled MoE and Dense Blocks",
        "track": "main",
        "status": "Long Main",
        "keywords": "MoE;Multilingual Machine Translation;Modularizing",
        "author": "",
        "aff": "; Tianjin University",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/lishangjie1/MMNMT"
    },
    {
        "id": "haPIkA8aOk",
        "title": "Adaptation with Self-Evaluation to Improve Selective Prediction in LLMs",
        "track": "main",
        "status": "Long Findings",
        "keywords": "large language models;selective prediction;adaptation with self-evaluation",
        "author": "",
        "aff": "University of Wisconsin-Madison; Google LLC; University of Wisconsin-Madison and Google LLC",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "hcDE6sOEfu",
        "title": "Ignore This Title and HackAPrompt: Exposing Systemic Vulnerabilities of LLMs Through a Global Prompt Hacking Competition",
        "track": "main",
        "status": "Long Main",
        "keywords": "Ignore This Title: Expose Systemic Vulnerabilities of LLMs through a Global Scale Prompt Hacking Competition",
        "author": "",
        "aff": "University of Milan; Technical University of Sofia; NYU; Towards AI; Stanford; University of Arizona; Mila; University of Maryland",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "4;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "hdxMdgKddK",
        "title": "DocTrack: A Visually-Rich Document Dataset Really Aligned with Human Eye Movement for Machine Reading",
        "track": "main",
        "status": "Long Findings",
        "keywords": "visually-rich document;dataset;eye tracking;human reading order;preordering",
        "author": "",
        "aff": "School of Computer Engineering and Science, Shanghai University, China; Department of Computer Science and Engineering, Shanghai Jiao Tong University, China; Graduate School of Informatics, Kyoto University, Japan",
        "rating": "",
        "confidence": "2;3;4;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/hint-lab/doctrack"
    },
    {
        "id": "hfZKiBh4zS",
        "title": "MPrompt: Exploring Multi-level Prompt Tuning for Machine Reading Comprehension",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Question Answering;Prompt Learning;Soft Prompt;Machine Reading Comprehension",
        "author": "",
        "aff": "Agency for Science, Technology and Research (A*STAR); Osaka University; Meetyou AI Lab, University of Chinese Academy of Sciences, Xiamen Key Laboratory of Women\u2019s Internet Health Management",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Chen-GX/MPrompt"
    },
    {
        "id": "hfmmVWJecp",
        "title": "Non-Compositionality in Sentiment: New Data and Analyses",
        "track": "main",
        "status": "Short Findings",
        "keywords": "sentiment analysis;compositionality;data annotation",
        "author": "",
        "aff": "Institute for Language, Cognition and Computation, University of Edinburgh",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;3;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "hgF8In32gL",
        "title": "Text encoders bottleneck compositionality in contrastive vision-language models",
        "track": "main",
        "status": "Long Main",
        "keywords": "vision-language;text encoders;interpretability",
        "author": "",
        "aff": "University of California, Los Angeles; Allen Institute for AI",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "hiJ2hzwghq",
        "title": "BiasX: \u201cThinking Slow\u201d in Toxic Content Moderation with Explanations of Implied Social Biases",
        "track": "main",
        "status": "Short Main",
        "keywords": "Social biases;Toxicity moderation;Human-AI collaboration;Free-text explanations",
        "author": "",
        "aff": "University of Washington; Carnegie Mellon University",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Y0mingZhang/biasx"
    },
    {
        "id": "hjEnagXGYV",
        "title": "Time-Considerable Dialogue Models via Reranking by Time Dependency",
        "track": "main",
        "status": "Long Findings",
        "keywords": "dialogue model;dialogue system;response generation;time information",
        "author": "",
        "aff": "NTT Communication Science Laboratories",
        "rating": "",
        "confidence": "2;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/nttcslab/time-considerable-dialogue-model"
    },
    {
        "id": "hl6TVdQjeh",
        "title": "Robustness Tests for Automatic Machine Translation Metrics with Adversarial Attacks",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Automatic metric;textual adversarial attack;machine translation",
        "author": "",
        "aff": "MBZUAI, The University of Melbourne; MBZUAI",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "hlqIu07ics",
        "title": "Towards a Mechanistic Interpretation of Multi-Step Reasoning Capabilities of Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "model interpretation;reasoning;attention mechanism;large language model",
        "author": "",
        "aff": "UC Irvine; AIWaves; EPFL; SUTD; ETH Z\u00fcrich",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/yifan-h/MechanisticProbe"
    },
    {
        "id": "hmOwOZWzYE",
        "title": "GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints",
        "track": "main",
        "status": "Short Main",
        "keywords": "efficient nlp;multi-query attention;fast inference",
        "author": "",
        "aff": "Google Research, University of Southern California; Google Research",
        "rating": "",
        "confidence": "4;2;2",
        "correctness": "4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "hn0B3jTlwE",
        "title": "Goodtriever: Adaptive Toxicity Mitigation with Retrieval-augmented Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "toxicity mitigation;retrieval-augmented;continual learning",
        "author": "",
        "aff": "Cohere For AI; Cohere For AI, School of Electrical and Computer Engineering and the Artificial Intelligence Lab, Recod.ai, University of Campinas (UNICAMP); Cohere",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/for-ai/goodtriever"
    },
    {
        "id": "hoO5anfnRk",
        "title": "EDIS: Entity-Driven Image Search over Multimodal Web Content",
        "track": "main",
        "status": "Long Main",
        "keywords": "Image search; Cross-modal retrieval; Multimodality fusion",
        "author": "",
        "aff": "Cornell University; University of Waterloo, Vector Institute; UC Santa Barbara",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/emerisly/EDIS"
    },
    {
        "id": "hpUNou0UaJ",
        "title": "impact of sample selection on in-context learning for entity extraction from scientific writing",
        "track": "main",
        "status": "Long Findings",
        "keywords": "GPT-3.5;in-context learning;sample selection;entity;scientific",
        "author": "",
        "aff": "CSIRO Data61",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/adalin16/ICL_EE"
    },
    {
        "id": "hsjQHAM8MV",
        "title": "Can We Edit Factual Knowledge by In-Context Learning?",
        "track": "main",
        "status": "Long Main",
        "keywords": "In-Context Learning;Knowledge Editing;Large Language Models",
        "author": "",
        "aff": "National Key Laboratory for Multimedia Information Processing, School of Computer Science, Peking University; Shanghai Artificial Intelligence Laboratory",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/pkunlp-icler/IKE"
    },
    {
        "id": "hsptWISmi6",
        "title": "Post-hoc Utterance Refining Method by Entity Mining for Faithful Knowledge Grounded Conversations",
        "track": "main",
        "status": "Long Main",
        "keywords": "Utterance Refining;Knowledge Grounded Conversation;Entity Mining;Entity-level Hallucination",
        "author": "",
        "aff": "Department of Computer Science and Engineering, Korea University",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/YOONNAJANG/REM"
    },
    {
        "id": "htulPWUheU",
        "title": "Cross-Document Event Coreference Resolution on Discourse Structure",
        "track": "main",
        "status": "Long Main",
        "keywords": "Event Coreference Resolution;Discourse Structure;Shortest Dependency Path",
        "author": "",
        "aff": "School of Computer Science and Technology, Soochow University, China",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "hv3VpXDIh8",
        "title": "CodeTransOcean: A Comprehensive Multilingual Benchmark for Code Translation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Code translation;Multilingual datasets;Multilingual modeling;Large language models",
        "author": "",
        "aff": "The University of Hong Kong; University of Illinois at Urbana-Champaign; Speech Lab, Alibaba Group; University of California, Santa Barbara",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/WeixiangYAN/CodeTransOcean"
    },
    {
        "id": "hxExXDMwcc",
        "title": "PlugMed: Improving Specificity in Patient-Centered Medical Dialogue Generation using In-Context Learning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Medical;Dialogue Generation;In-context Learning",
        "author": "",
        "aff": "School of Computer Science, Peking University; Key Laboratory of High Confidence Software Technologies(PKU), MOE, China",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "hyBwGem8OS",
        "title": "InteMATs: Integrating Granularity-Specific Multilingual Adapters for Cross-Lingual Transfer",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multilingual Language Model Enhancement;Cross-lingual Transfer;Parameter-Efficient Method",
        "author": "",
        "aff": "Shandong University; Nanyang Technological University",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "i0RfSS9CUU",
        "title": "Active Learning Principles for In-Context Learning with Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "active learning;in-context learning;few-shot learning;large language models",
        "author": "",
        "aff": "University of Sheffield; FAIR, Meta",
        "rating": "",
        "confidence": "4;4;2",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "i0vMIpaEn4",
        "title": "Adaptive Policy with Wait-k Model for Simultaneous Translation",
        "track": "main",
        "status": "Long Main",
        "keywords": "simultaneous machine translation;wait-k;adaptive policy;read/write supervision signals",
        "author": "",
        "aff": "Shien-Ming Wu School of Intelligent Engineering, South China University of Technology; Alibaba DAMO Academy; ZheJiang University",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/lbzhao970/DaP-SiMT"
    },
    {
        "id": "i17SCD0YDI",
        "title": "KEBAP: Korean Error Explainable Benchmark Dataset for ASR and Post-processing",
        "track": "main",
        "status": "Long Main",
        "keywords": "Automatic Speech Recognition (ASR);Error Explainable Benchmark;Post-procssing;Recognition Accuracy;User Readability",
        "author": "",
        "aff": "Upstage AI; Korea University, Department of Computer Science and Engineering",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "i1KSRMVlST",
        "title": "Cognitive Dissonance: Why Do Language Model Outputs Disagree with Internal Representations of Truthfulness?",
        "track": "main",
        "status": "Short Main",
        "keywords": "language models;truthfulness;question answering;interpretability",
        "author": "",
        "aff": "MIT CSAIL",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "github.com/lingo-mit/lm-truthfulness"
    },
    {
        "id": "i65hZUPwuQ",
        "title": "Mirages. On Anthropomorphism in Dialogue Systems",
        "track": "main",
        "status": "Long Main",
        "keywords": "Dialogue systems;conversational AI;anthropomorphism;ethics",
        "author": "",
        "aff": "Heriot-Watt University; Bocconi University; Mohamed Bin Zayed University of Artificial Intelligence; Heriot-Watt University\u2020",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "i7ifZu49kW",
        "title": "Improving Neural Machine Translation by Multi-Knowledge Integration with Prompting",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Machine Translation;Multi-Knowledge Integration;Prompting",
        "author": "",
        "aff": "Alibaba Group",
        "rating": "",
        "confidence": "4;5;3",
        "correctness": "3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "iAeDYlEXrM",
        "title": "A Critical Analysis of Document Out-of-Distribution Detection",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Document Understanding;Pretraining;Out-of-Distribution;Document intelligence;Robustness",
        "author": "",
        "aff": "University of Wisconsin-Madison; Johns Hopkins University; Adobe Research",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "iBv0M8WrFi",
        "title": "A Cheaper and Better Diffusion Language Model with Soft-Masked Noise",
        "track": "main",
        "status": "Long Main",
        "keywords": "Diffusion Language Model;Soft-masked Noise",
        "author": "",
        "aff": "Stanford University; Georgia Institute of Technology; Meta GenAI",
        "rating": "",
        "confidence": "4;3;5;4",
        "correctness": "4;3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/SALT-NLP/Masked_Diffusioin_LM"
    },
    {
        "id": "iCLJHkE5s1",
        "title": "TRAMS: Training-free Memory Selection for Long-range Language Modeling",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Language Model; Inference Strategy; Long-context Modeling",
        "author": "",
        "aff": "Language Technologies Institute, Carnegie Mellon University, USA; Tencent AI Lab, China; School of Engineering, Westlake University, China",
        "rating": "",
        "confidence": "2;3;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "iCNoSVJl2y",
        "title": "CCIM: Cross-modal Cross-lingual Interactive Image Translation",
        "track": "main",
        "status": "Short Findings",
        "keywords": "cross-modal cross-lingual interactive decoding;text image machine translation;text image recogntion",
        "author": "",
        "aff": "Samsung Research China - Beijing (SRC-B); State Key Laboratory of Multimodal Artificial Intelligence Systems (MAIS), Institute of Automation, Chinese Academy of Sciences; Fanyu AI Laboratory, Zhongke Fanyu Technology Co., Ltd; School of Artificial Intelligence, University of Chinese Academy of Sciences; State Key Laboratory of Multimodal Artificial Intelligence Systems (MAIS), Institute of Automation, Chinese Academy of Sciences",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/EriCongMa/CCIM"
    },
    {
        "id": "iDBUssVu5Z",
        "title": "Text Fact Transfer",
        "track": "main",
        "status": "Long Main",
        "keywords": "Text Generation;Factuality;Text Style Transfer;Information Extraction",
        "author": "",
        "aff": "University of Illinois at Urbana-Champaign, USA",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/nbalepur/text-fact-transfer"
    },
    {
        "id": "iDQBP0cvzX",
        "title": "Best of Both Worlds: Towards Improving Temporal Knowledge Base Question Answering via Targeted Fact Extraction",
        "track": "main",
        "status": "Short Main",
        "keywords": "Temporal KBQA;Fact Extraction;Semantic Parsing;Questional Answering",
        "author": "",
        "aff": "IBM Research, India; Amazon Alexa AI, UK",
        "rating": "",
        "confidence": "1;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "iDZQG9aUGH",
        "title": "Bayesian Multi-Task Transfer Learning for Soft Prompt Tuning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "prompt tuning;parameter-efficient fine-tuning;transfer learning;bayesian method",
        "author": "",
        "aff": "Kim Jaechul Graduate School of AI, KAIST",
        "rating": "",
        "confidence": "4;3;3;5",
        "correctness": "3;4;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/heyzude/BMTPT"
    },
    {
        "id": "iEACF99lQz",
        "title": "Merging Generated and Retrieved Knowledge for Open-Domain QA",
        "track": "main",
        "status": "Long Main",
        "keywords": "large language model;retrieval-augmented language model;open-domain question answering",
        "author": "",
        "aff": "University of Michigan, LG AI Research; LG AI Research; University of Michigan; University of Illinois at Chicago",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/yunx-z/COMBO"
    },
    {
        "id": "iHb4MOMyOd",
        "title": "Bipartite Graph Pre-training for Unsupervised Extractive Summarization with Graph Convolutional Auto-Encoders",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Bipartite Graph;Graph Pre-training;Unsupervised Extractive Summarization;Graph Convolutional Auto-Encoders",
        "author": "",
        "aff": "Zhongguancun Laboratory, Beijing, P.R.China.; School of Computer Science and Engineering, Beihang University, Beijing, P.R.China.; School of Software, Beihang University, Beijing, P.R.China.; Institute of Automation, Chinese Academy of Sciences, Beijing, P.R.China.",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "iIoHir5Hyg",
        "title": "Well Begun is Half Done: Generator-agnostic Knowledge Pre-Selection for Knowledge-Grounded Dialogue",
        "track": "main",
        "status": "Long Main",
        "keywords": "Knowledge-grounded Dialogue;Knowledge Selection;Generator-agnostic",
        "author": "",
        "aff": "School of Statistics and Data Science, LPMC, KLMDASR & LEBPS, Nankai University; TKLNDST, CS, Nankai University; Key Laboratory of DISSec, Ministry of Education, China; College of Computer Science, Sichuan University; College of Mathematics and Statistics Science, Shandong Key Laboratory of Language Resource Development and Application, Ludong University; Education Field Integrated & Publishing Knowledge Mining & Service Key Laboratory, National Press and Publication Administration, China",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "iIpnncYQZb",
        "title": "Toward a Critical Toponymy Framework for Named Entity Recognition: A Case Study of Airbnb in New York City",
        "track": "main",
        "status": "Long Main",
        "keywords": "critical toponymy;named entity recognition;geographic information science;gentrification;new york city;airbnb;place",
        "author": "",
        "aff": "Department of Sociology, Columbia University; Platial Analysis Lab, Department of Geography, McGill University; Platial Analysis Lab, Department of Geography, McGill University; Urban Planning and Governance Lab, School of Urban Planning, McGill University; Department of Computer Science, Columbia University",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "iLTNcB3601",
        "title": "Improving End-to-End Speech Processing by Efficient Text Data Utilization with Latent Synthesis",
        "track": "main",
        "status": "Long Findings",
        "keywords": "joint speech-text learning;spoken language understanding;speech recognition",
        "author": "",
        "aff": "The University of Hong Kong; Huawei Noah\u2019s Ark Lab",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "iMnwXQemEr",
        "title": "Discovering Universal Geometry in Embeddings with ICA",
        "track": "main",
        "status": "Long Main",
        "keywords": "Embeddings;Independent Component Analysis;Principal Component Analysis;Cross-lingual;Interpretability;Isotropy;Whitening",
        "author": "",
        "aff": "Kyoto University, RIKEN; Kyoto University",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/shimo-lab/Universal-Geometry-with-ICA"
    },
    {
        "id": "iO5YOddOyG",
        "title": "Is ChatGPT a Good Multi-Party Conversation Solver?",
        "track": "main",
        "status": "Long Findings",
        "keywords": "large language models;multi-party conversations;zero-shot;in-context learning",
        "author": "",
        "aff": "National Engineering Research Center of Speech and Language Information Processing, University of Science and Technology of China, Hefei, China",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "iRISsJCzTA",
        "title": "Controllable Chest X-Ray Report Generation from Longitudinal Representations",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Controllable Report Generation;Longitudinal Chest X-Rays;Multimodal Transformer",
        "author": "",
        "aff": "Canon Medical Research Europe, Edinburgh, United Kingdom; University of Edinburgh, Edinburgh, United Kingdom; University of Glasgow, Glasgow, United Kingdom",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "iRIj0OvFG1",
        "title": "Intuitive Multilingual Audio-Visual Speech Recognition with a Single-Trained Model",
        "track": "main",
        "status": "Short Findings",
        "keywords": "audio-visual speech recognition;speech recognition;multimodal;multilingual",
        "author": "",
        "aff": "School of Electrical Engineering, KAIST",
        "rating": "",
        "confidence": "4;4;2",
        "correctness": "4;2;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "iVINvItqhb",
        "title": "GradSim: Gradient-Based Language Grouping for Effective Multilingual Training",
        "track": "main",
        "status": "Long Main",
        "keywords": "Effective multilingual learning;language grouping;gradient-based similarity",
        "author": "",
        "aff": "Bosch Center for Artificial Intelligence, Renningen, Germany; Karlsruhe University of Applied Sciences, Germany; Bosch Center for Artificial Intelligence, Renningen, Germany; LMU Munich, Germany; Hochschule der Medien, Stuttgart, Germany; LMU Munich, Germany",
        "rating": "",
        "confidence": "5;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "iWVpissNEP",
        "title": "Towards Building More Robust NER datasets: An Empirical Study on NER Dataset Bias from a Dataset Difficulty View",
        "track": "main",
        "status": "Long Main",
        "keywords": "Robustness;OOD Generalization;Dataset Bias;NER",
        "author": "",
        "aff": "School of Computer Science, Fudan University, Shanghai, China; International Human Phenome Institutes, Shanghai, China; School of Computer Science, Fudan University, Shanghai, China",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "iammae3CbG",
        "title": "Prototype-based HyperAdapter for Sample-Efficient Multi-task Tuning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Multi-task learning;Fine-tuning;Sample-efficiency;Prototype learning",
        "author": "",
        "aff": "Hong Kong University of Science and Technology; Beijing University of Posts and Telecommunications",
        "rating": "",
        "confidence": "4;3;4;4",
        "correctness": "4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Bumble666/PHA"
    },
    {
        "id": "iaxdEnxgju",
        "title": "FaLA: Fast Linear Adaptation for Replacing Backbone Models on Edge Devices",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Foundation Models;Personalization;Efficient Parameter Tuning;On device",
        "author": "",
        "aff": "Faculty of Information and Technology, Monash University",
        "rating": "",
        "confidence": "4;4;2",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "ifuvyCdLro",
        "title": "Medical Text Simplification: Optimizing for Readability with Unlikelihood Training and Reranked Beam Search Decoding",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Medical Text;Simplification;Healthcare;Beam Search Decoding;Unlikelihood Learning",
        "author": "",
        "aff": "Yale School of Medicine; Yale University; Allen Institute for AI",
        "rating": "",
        "confidence": "2;3;4",
        "correctness": "4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ljyflores/simplification-project"
    },
    {
        "id": "ii9ZoryPH2",
        "title": "DecoMT: Decomposed Prompting for Machine Translation Between Related Languages using Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "NLP;LLM;few-shot prompting;Machine Translation",
        "author": "",
        "aff": "Microsoft, India; Institute for Infocomm Research (I2R), A\u2217STAR, Singapore; National Institute of Information and Communications Technology; Institute for Infocomm Research (I2R), A\u2217STAR, Singapore; CNRS@CREATE, Singapore",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "iiWP7khhwP",
        "title": "Long-Range Language Modeling with Selective Cache",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Language Modeling;Long Dependency;Long-term Memory",
        "author": "",
        "aff": "University of Copenhagen",
        "rating": "",
        "confidence": "5;3;2",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/huangxt39/SelectiveCacheForLM"
    },
    {
        "id": "iipuAqcPGL",
        "title": "Can Large Language Models Capture Dissenting Human Voices?",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Model;Natural Language Inference;Human Disagreement",
        "author": "",
        "aff": "KAIST AI",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/xfactlab/emnlp2023-LLM-Disagreement"
    },
    {
        "id": "ilCMZV0Qdl",
        "title": "Exploiting Emotion-Semantic Correlations for Empathetic Response Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Emotion;Semantic;Correlation;Empathetic;Dialogue;Generation",
        "author": "",
        "aff": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "in5xvBrMHv",
        "title": "Complex Event Schema Induction with Knowledge-Enriched Diffusion Model",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Complex Event Schema Induction;Diffusion Model;Large Language Model",
        "author": "",
        "aff": "China Merchants Bank; The Laboratory of Cognition and Decision Intelligence for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China",
        "rating": "",
        "confidence": "2;5;4",
        "correctness": "2;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/hypasd-art/KDM/"
    },
    {
        "id": "inN4TdboJX",
        "title": "Noisy Exemplars Make Large Language Models More Robust: A Domain-Agnostic Behavioral Analysis",
        "track": "main",
        "status": "Short Main",
        "keywords": "Large Language Models;Robustness;Perturbation Analysis;Few-shot Prompting;Chain-of-thought",
        "author": "",
        "aff": "New York University",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Hiroki39/Noisy-Exemplars-Make-Large-Language-Models-More-Robust"
    },
    {
        "id": "islVqaCzfa",
        "title": "InstructCoder: Empowering Language Models to Edit Code",
        "track": "main",
        "status": "Reject",
        "keywords": "Code Edit;Instruction Finetuning",
        "author": "",
        "aff": "Singapore University of Technology and Design; National University of Singapore; Shanghai Jiao Tong University",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/qishenghu/InstructCoder"
    },
    {
        "id": "ivSJdhcuTi",
        "title": "Out-of-Distribution Generalization in Natural Language Processing: Past, Present, and Future",
        "track": "main",
        "status": "Long Main",
        "keywords": "Out-of-Distribution Generalization; OOD Robustness",
        "author": "",
        "aff": "Microsoft Research Asia; Westlake University; MBZUAI; Dublin City University; University of Adelaide; Westlake Institute for Advanced Study",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "iw4zUlc5OF",
        "title": "On the Zero-Shot Generalization of Machine-Generated Text Detectors",
        "track": "main",
        "status": "Short Findings",
        "keywords": "detection;NLG;zero-shot generalization",
        "author": "",
        "aff": "University of Washington; Peking University; Johns Hopkins University",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "2;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/SophiaPx/detectors-generalization"
    },
    {
        "id": "ix6h7Bkq62",
        "title": "Standardizing Distress Analysis: Emotion-Driven Distress Identification and Cause Extraction (DICE) in Multimodal Online Posts",
        "track": "main",
        "status": "Long Main",
        "keywords": "Hate speech;Social media;Multimodal online posts;Distress content;Causal phrases;Emotional information;Zero-shot strategy",
        "author": "",
        "aff": "Department of Computer Science and Engineering, IIT Patna, India",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "2;2;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://www.iitp.ac.in/~ai-nlp-ml/resources.html#DICE",
        "github": ""
    },
    {
        "id": "iytcEQ5I5v",
        "title": "SDOH-NLI: a Dataset for Inferring Social Determinants of Health from Clinical Notes",
        "track": "main",
        "status": "Short Findings",
        "keywords": "social determinants of health;natural language inference;nli;clinical notes;dataset",
        "author": "",
        "aff": "Curai Health; Google Research",
        "rating": "",
        "confidence": "3;5;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/google-research-datasets/SDOH-NLI"
    },
    {
        "id": "j2bP0STpw7",
        "title": "The Vault: A Comprehensive Multilingual Dataset for Advancing Code Understanding and Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "deep-learning;ai4code;dataset;benchmark;code-understanding;code-generation",
        "author": "",
        "aff": "FPT Software AI Center, Hanoi University of Science and Technology; Fulbright University, Viet Nam; School of Computer Science, McGill University, Mila - Quebec AI Institute; FPT Software AI Center",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "j48JCRagwR",
        "title": "Improving Contrastive Learning of Sentence Embeddings with Focal InfoNCE",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Contrastive Learning;Sentence Textual Similarity;Sentence Embdding;Negative Sample Reweighing",
        "author": "",
        "aff": "University of Alberta",
        "rating": "",
        "confidence": "5;2;2",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/puerrrr/Focal-InfoNCE"
    },
    {
        "id": "j61Sx05QRj",
        "title": "NeuSTIP: A Neuro-Symbolic Model for Link and Time Prediction in Temporal Knowledge Graphs",
        "track": "main",
        "status": "Long Main",
        "keywords": "Information Extraction;Neuro-Symbolic Knowledge Graph Completion;Temporal Knowledge Graph Completion",
        "author": "",
        "aff": "Indian Institute of Technology, Delhi",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "j6g3qwoQKU",
        "title": "POE: Process of Elimination for Multiple Choice Reasoning",
        "track": "main",
        "status": "Short Main",
        "keywords": "language models;prompting;scoring;multiple choice reasoning",
        "author": "",
        "aff": "Department of Computer Science, University of Texas at Dallas; School of Computer Science and Engineering, University of Electronic Science and Technology of China",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/KasMasVan/PoE"
    },
    {
        "id": "j9E9xLlTmB",
        "title": "Analyzing Cognitive Plausibility of Subword Tokenization",
        "track": "main",
        "status": "Short Main",
        "keywords": "subword tokenization;subword segmentation;cognitive signals;cognitive plausibility;lexical decision;vocabulary size;morphological segmentation",
        "author": "",
        "aff": "CLTL Lab, Vrije Universiteit Amsterdam, Amsterdam, The Netherlands; Department of Computer Science, Ben-Gurion University of the Negev, Beer Sheva, Israel",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "j9e3WVc49w",
        "title": "Knowledge Distillation \u2248 Label Smoothing: Fact or Fallacy?",
        "track": "main",
        "status": "Short Main",
        "keywords": "knowledge distillation;label smoothing;regularization;interpretation of knowledge distillation",
        "author": "",
        "aff": "IBM Research AI",
        "rating": "",
        "confidence": "3;4;5",
        "correctness": "4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "jAf0gd0ez4",
        "title": "Interactive Text Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Interactivity;Text Generation;RL;IL",
        "author": "",
        "aff": "Cornell University; MIT; Microsoft",
        "rating": "",
        "confidence": "3;2;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "jImeNRfAy2",
        "title": "Self-Detoxifying Language Models via Toxification Reversal",
        "track": "main",
        "status": "Long Main",
        "keywords": "Language Model Detoxification;Language Model Safety;Natural Languge Generation",
        "author": "",
        "aff": "Department of Computing, The Hong Kong Polytechnic University",
        "rating": "",
        "confidence": "2;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/cooperleong00/ToxificationReversal"
    },
    {
        "id": "jLEnVo0RW3",
        "title": "Retrieving Multimodal Information for Augmented Generation: A Survey",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Retrieval-augmented language models;Multimodality",
        "author": "",
        "aff": "Nanyang Technological University, Singapore and Salesforce Research; National University of Singapore, Singapore; Nanyang Technological University, Singapore",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "jLmSsybvkR",
        "title": "Dior-CVAE: Pre-trained Language Models and Diffusion Priors for Variational Dialog Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Dialogue Generation;Diffusion Model;Variational Auto-encoder",
        "author": "",
        "aff": "Ubiquitous Knowledge Processing Lab (UKP Lab), Department of Computer Science and Hessian Center for AI (hessian.AI), Technical University of Darmstadt",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/UKPLab/dior-cvae"
    },
    {
        "id": "jMwvnqKTBG",
        "title": "Mind the Gap: Automated Corpus Creation for Enthymeme Detection and Reconstruction in Learner Arguments",
        "track": "main",
        "status": "Long Findings",
        "keywords": "dataset;argumentation;argument mining;enthymeme",
        "author": "",
        "aff": "Tunghai University; Paderborn University; Leibniz University Hannover",
        "rating": "",
        "confidence": "4;2;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "jPrl18r4RA",
        "title": "Meta-Learning Online Adaptation of Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "meta-learning;question-answering;online learning;knowledge;adaptation",
        "author": "",
        "aff": "Stanford University",
        "rating": "",
        "confidence": "3;4;3;3",
        "correctness": "3;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "jQcShOpcfM",
        "title": "DPP-TTS: Diversifying prosodic features of speech via determinantal point processes",
        "track": "main",
        "status": "Long Main",
        "keywords": "Speech prosody; prosodic segmentation; text-to-speech",
        "author": "",
        "aff": "Seoul National University",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "jQozdfjJSZ",
        "title": "MingOfficial: A Ming Official Career Dataset and a Historical Context-Aware Representation Learning Framework",
        "track": "main",
        "status": "Long Main",
        "keywords": "graph representation learning;graph neural network;Ming Dynasty",
        "author": "",
        "aff": "Department of Computer Science and Information Engineering, National Central University, Taoyuan, Taiwan; Courant Institute of Mathematical Sciences, New York University, NY, USA; Google DeepMind",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://data.depositar.io/en/dataset/ming_official",
        "github": ""
    },
    {
        "id": "jSu7hAIZM0",
        "title": "Preserving Privacy Through Dememorization: An Unlearning Technique For Mitigating Memorization Risks In Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large langauge models;privacy;memorization",
        "author": "",
        "aff": "Applied Artificial Intelligence Institute, Deakin University; School of Computer Science, University of Windsor",
        "rating": "",
        "confidence": "2;3;2",
        "correctness": "2;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "jTiJPDv82w",
        "title": "ToxicChat: Unveiling Hidden Challenges of Toxicity Detection in Real-World User-AI Conversation",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Toxicity;Real-World User-AI Interaction;Domain Adaptation;LLM-based Chatbots",
        "author": "",
        "aff": "UC San Diego",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "2;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "jUgBvYwc50",
        "title": "ZARA: Improving Few-Shot Self-Rationalization for Small Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "free-text explanation;rationale;self-rationalization",
        "author": "",
        "aff": "Academia Sinica, Taiwan; National Taiwan University, Taiwan; National Yang Ming Chiao Tung University, Taiwan",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ntunlplab/ZARA"
    },
    {
        "id": "jUkDEaE0fK",
        "title": "LDM$^2$: A Large Decision Model Imitating Human Cognition with Dynamic Memory Enhancement",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large Language Model;Decision Making;Memory Enhanced",
        "author": "",
        "aff": "School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Multimodal Artificial Intelligence Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Multimodal Artificial Intelligence Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; Beijing Wenge Technology Co.,Ltd",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "jUrRIcedTN",
        "title": "Modeling Highlighting of Metaphors in Multitask Contrastive Learning Paradigms",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Metaphor;Highlighted Aspect;Source Domain;Multitask Learning;Contrastive Learning",
        "author": "",
        "aff": "Leibniz Universit\u00e4t Hannover; Paderborn University",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "jVa7tFQw9N",
        "title": "Automatic Evaluation of Attribution by Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large Language Models; Attribution Evaluation; Attribution of LLMs; Evaluation of LLMs;",
        "author": "",
        "aff": "The Ohio State University",
        "rating": "",
        "confidence": "2;4;3;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/OSU-NLP-Group/AttrScore"
    },
    {
        "id": "jWL2GhQw5D",
        "title": "More than Votes? Voting and Language based Partisanship in the US Supreme Court",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Fairness and Bias; Sociolinguistic; Cultural Analysis; Partisanship Analysis",
        "author": "",
        "aff": "The University of Melbourne, Australia; MBZUAI",
        "rating": "",
        "confidence": "3;4;4;4",
        "correctness": "4;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/biaoyanf/SCOTUS-partisanship"
    },
    {
        "id": "jWqkEB3wJP",
        "title": "RobustEmbed: Robust Sentence Embeddings Using Self-Supervised Contrastive Pre-Training",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Trustworthy Machine Learning;Text Representation;Adversarial Attacks;Self-Supervised Contrastive Learning",
        "author": "",
        "aff": "Georgia State University; University of Arizona; Old Dominion University",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "jZXjHnzPyk",
        "title": "TrojanSQL: SQL Injection against Natural Language Interface to Database",
        "track": "main",
        "status": "Long Main",
        "keywords": "text-to-SQL;NLIDB;security;SQL Injection;NL2Code",
        "author": "",
        "aff": "; Institute of Information Engineering, Chinese Academy of Sciences; School of Cyber Security, University of Chinese Academy of Sciences",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "jbicunmyXh",
        "title": "LATENTLOGIC: Learning Logic Rules in Latent Space over Knowledge Graphs",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Knowledge Graph;Reasoning;Logic Rule",
        "author": "",
        "aff": "Department of Computer Science and Engineering, HKUST, Hong Kong SAR, China.; Zhongguancun Laboratory, Beijing, P.R.China.; School of Computer Science and Engineering, Beihang University, Beijing, P.R.China.; Department of Computer Science, University of Manchester, U.K.",
        "rating": "",
        "confidence": "4;3;4;4",
        "correctness": "3;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "jcqBLHFcYA",
        "title": "MindGames: Targeting Theory of Mind in Large Language Models with Dynamic Epistemic Modal Logic",
        "track": "main",
        "status": "Short Findings",
        "keywords": "logic;epistemic logic;theory of mind;language models",
        "author": "",
        "aff": "Univ. Lille, Inria, CNRS, Centrale Lille, UMR 9189, CRIStAL, F-59000 Lille, France; Univ. Lille, CRIStAL, F-59000 Lille, France",
        "rating": "",
        "confidence": "3;5;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "data:HF-datasets",
        "github": "code:GitHub"
    },
    {
        "id": "jcx5YIN3Sd",
        "title": "That was the last straw, we need more: Are Translation Systems Sensitive to Disambiguating Context?",
        "track": "main",
        "status": "Long Findings",
        "keywords": "model evaluation;model analysis;dataset creation;machine translation;LM",
        "author": "",
        "aff": "Paul G. Allen School of Computer Science & Engineering, University of Washington; Email: hilagnn@gmail.com",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/jaechan-repo/mt-ambiguity"
    },
    {
        "id": "jfaJdk29k4",
        "title": "Prompting Large Language Models with Chain-of-Thought for Few-Shot Knowledge Base Question Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Models;Chain-of-Thought;Few-Shot;Knowledge Base Question Generation",
        "author": "",
        "aff": "East China Normal University; Singapore Management University",
        "rating": "",
        "confidence": "2;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "jg2WCVrjhS",
        "title": "Uncertainty Guided Global Memory Improves Multi-Hop Question Answering",
        "track": "main",
        "status": "Short Main",
        "keywords": "Transformer;Memory;Multi-hop Question Answering",
        "author": "",
        "aff": "London Institute for Mathematical Sciences, London, UK; Moscow Institute of Physics and Technology, Dolgoprudny, Russia",
        "rating": "",
        "confidence": "1;4;4;3",
        "correctness": "3;2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Aloriosa/GEMFormer"
    },
    {
        "id": "jhdVt7rC8k",
        "title": "Large Language Models are Temporal and Causal Reasoners for Video Question Answering",
        "track": "main",
        "status": "Long Main",
        "keywords": "large language models;temporal and causal reasoning",
        "author": "",
        "aff": "Kakao Brain; Department of Computer Science and Engineering, Korea University",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/mlvlab/Flipped-VQA"
    },
    {
        "id": "jjSOGqLT2X",
        "title": "Video-Helpful Multimodal Machine Translation",
        "track": "main",
        "status": "Long Main",
        "keywords": "[Multimodal machine translation;Video]",
        "author": "",
        "aff": "Kyoto University; Google Research",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ku-nlp/video-helpful-MMT.git"
    },
    {
        "id": "jkI9KGEFQz",
        "title": "Support or Refute: Analyzing the Stance of Evidence to Detect Out-of-Context Mis- and Disinformation",
        "track": "main",
        "status": "Long Main",
        "keywords": "out-of-context;stance analysis;misinformation;Internet evidence",
        "author": "",
        "aff": "Institute of Cyber Security for Society (iCSS) & School of Computing, University of Kent, UK; School of Cyber Science and Engineering, Shanghai Jiao Tong University, China",
        "rating": "",
        "confidence": "4;2;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "jmopGajkFY",
        "title": "MEGA: Multilingual Evaluation of Generative AI",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Models;Multilinguality;Evaluation;Low Resource Languages;Benchmarking",
        "author": "",
        "aff": "University of Washington; Carnegie Mellon University; Johns Hopkins University; Microsoft Corporation",
        "rating": "",
        "confidence": "4;3;3;3",
        "correctness": "4;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "jp80nsryCF",
        "title": "Transductive Learning for Textual Few-Shot Classification in API-based Embedding Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "NLP;few shot;text classifiers",
        "author": "",
        "aff": "IRT SystemX Saclay, France; \u00c9TS Montreal, LIVIA, ILLS, Canada; ILLS, MILA, CNRS, CentraleSup\u00e9lec, Canada; MICS, CentraleSupelec, Universite Paris-Saclay, France; Mozilla.ai, Paris, France; Equall, Paris, France",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "jph8GlHueb",
        "title": "MUX-PLMs: Data Multiplexing for High-throughput Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Efficient Inference;Multi-input Multi-output architectures;Data Multiplexing",
        "author": "",
        "aff": "Princeton University; Google Brain",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "jqOIacThP3",
        "title": "Verb Conjugation in Transformers Is Determined by Linear Encodings of Subject Number",
        "track": "main",
        "status": "Short Findings",
        "keywords": "interpretability;analysis;representations;hidden vectors;syntax;subject-verb agreement;transformers;pre-trained models;language models;bert;causal analysis;causality;causal intervention;inlp",
        "author": "",
        "aff": "New York University",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/yidinghao/causal-conjugation"
    },
    {
        "id": "jqOymNqzuB",
        "title": "Ideology Takes Multiple Looks: A High-Quality Dataset for Multifaceted Ideology Detection",
        "track": "main",
        "status": "Long Main",
        "keywords": "Ideology detection;multifaceted ideology schema;dataset;political spectrum",
        "author": "",
        "aff": "School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; School of Journalism and Information Communication, Huazhong University of Science and Technology, Wuhan, China",
        "rating": "",
        "confidence": "5;4;4;3",
        "correctness": "4;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/LST1836/MITweetAuthors"
    },
    {
        "id": "jqbhtSDPz7",
        "title": "The Art of SOCRATIC QUESTIONING: Recursive Thinking with Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Chain of Thought;prompting;large language model;reasoning;multimodal;question answering",
        "author": "",
        "aff": "Meta AI; Virginia Tech; Amazon Inc.",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/VT-NLP/SOCRATIC-QUESTIONING"
    },
    {
        "id": "jsmV1WxXyb",
        "title": "Statistically Profiling Biases in Natural Language Reasoning Datasets and Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "nature language processing;model robustness;bias analysis",
        "author": "",
        "aff": "University of Texas at Arlington, Arlington, Texas, USA; Shanghai Jiao Tong University, Shanghai, China",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "juUEOaH7bK",
        "title": "ULF: Unsupervised Labeling Function Correction using Cross-Validation for Weak Supervision",
        "track": "main",
        "status": "Short Main",
        "keywords": "weak supervision;cross-validation;denoising methods",
        "author": "",
        "aff": "Faculty of Philological and Cultural Studies, University of Vienna, Austria; Faculty of Computer Science, University of Vienna, Austria; UniVie Doctoral School Computer Science, University of Vienna, Austria",
        "rating": "",
        "confidence": "3;3;2",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/knodle"
    },
    {
        "id": "jvNVmkGxiU",
        "title": "Human Learning by Model Feedback: The Dynamics of Iterative Prompting with Midjourney",
        "track": "main",
        "status": "Long Main",
        "keywords": "Interaction;Text-to-Image;alignment;Cognitive Science",
        "author": "",
        "aff": "The Hebrew University of Jerusalem; MIT",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/shachardon/Mid-Journey-to-alignment"
    },
    {
        "id": "jvTV8vSa3X",
        "title": "Text-guided 3D Human Generation from 2D Collections",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Text-guided Visual Generation;3D Human Generation",
        "author": "",
        "aff": "Meta; UC Santa Barbara",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "5;4;1",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://text-3dh.github.io",
        "github": ""
    },
    {
        "id": "jw1iZfW5zN",
        "title": "A Framework for Bidirectional Decoding: Case Study in Morphological Inflection",
        "track": "main",
        "status": "Long Findings",
        "keywords": "morphology;decoding;inflection;transformers",
        "author": "",
        "aff": "University of Illinois at Urbana-Champaign",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/marccanby/bidi_decoding/tree/main"
    },
    {
        "id": "jxgz7FEqWq",
        "title": "Sparse Low-rank Adaptation of Pre-trained Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Parameter-efficient;Sparse Adaptation",
        "author": "",
        "aff": "Department of Computer Science and Technology, Tsinghua University; Department of Statistics, The University of Chicago; Department of Electronic Engineering, Tsinghua University; BNRIST, IAI, Tsinghua University",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "k2VHhq2LH9",
        "title": "Reasoning about Ambiguous Definite Descriptions",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Natural language reasoning;definite descriptions;ambiguity;large language models",
        "author": "",
        "aff": "Vrije Universiteit Amsterdam",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/sfschouten/exploiting-ambiguity"
    },
    {
        "id": "k3i6PKlKY8",
        "title": "mRedditSum: A Multimodal Abstractive Summarization Dataset of Reddit Threads with Images",
        "track": "main",
        "status": "Long Main",
        "keywords": "Multimodal Abstractive Summarization Dataset",
        "author": "",
        "aff": "Seoul National University; University of Richmond, NAVER AI Lab, NAVER Cloud",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "http://vision.snu.ac.kr/projects/mredditsum",
        "github": ""
    },
    {
        "id": "k4QqDDoRyI",
        "title": "ATFormer: A Learned Performance Model with Transfer Learning Across Devices for Deep Learning Tensor Programs",
        "track": "main",
        "status": "Long Main",
        "keywords": "Tensor Program; Performance Model; Efficient Transfer Learning; NLP Application; Model Deployment",
        "author": "",
        "aff": "Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong SAR",
        "rating": "",
        "confidence": "2;2;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "k8rxolXsPE",
        "title": "SuperDialseg: A Large-scale Dataset for Supervised Dialogue Segmentation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Dialogue Segmentation;Dataset;Benchmark",
        "author": "",
        "aff": "National Institute of Informatics; The University of Tokyo; Kyoto University",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Coldog2333/SuperDialseg"
    },
    {
        "id": "k95cAni5Hk",
        "title": "Toxicity, Morality, and Speech Act Guided Stance Detection",
        "track": "main",
        "status": "Long Findings",
        "keywords": "stance detection;toxicity;morality. speech act classification;Twitter",
        "author": "",
        "aff": "L3S Research Center, Leibniz Universit\u00e4t Hannover, Germany",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "2;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "kCzhhVMo4r",
        "title": "Length-Adaptive Distillation: Customizing Small Language Model for Dynamic Token Pruning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "knowledge distillation;language model compression;token pruning",
        "author": "",
        "aff": "AAII, University of Technology Sydney; Institute for Artificial Intelligence, Peking University; Wangxuan Institute of Computer Technology, Peking University; School of Intelligence Science and Technology, Peking University; Microsoft Corporation",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "kEcDQzX3cI",
        "title": "Vicinal Risk Minimization for Few-Shot Cross-lingual Transfer in Abusive Language Detection",
        "track": "main",
        "status": "Long Main",
        "keywords": "Vicinal Risk Minimization;Few-Shot Cross-lingual Transfer;Abusive Language Detection",
        "author": "",
        "aff": "DWS Group, University of Mannheim; CAIDAS, University of W\u00fcrzburg; Universitat Polit\u00e8cnica de Val\u00e8ncia; MaiNLP, LMU Munich",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "kEflZNzau4",
        "title": "Language Model is Suitable for Correction of Handwritten Mathematical Expressions Recognition",
        "track": "main",
        "status": "Long Main",
        "keywords": "LaTeX mathematical expression;handwritten mathematical expression recognition;language model;LaTeX language property",
        "author": "",
        "aff": "Shanghaitech University; University of Science and Technology of China; Shanghaitech University, Shanghai Innovation Center for Processor Technologies",
        "rating": "",
        "confidence": "3;3;3;3",
        "correctness": "3;4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Zui-C/RLFN"
    },
    {
        "id": "kEhBOEsXXx",
        "title": "HPE: Answering Complex Questions over Text by Hybrid Question Parsing and Execution",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multi-hop Question answering; Neuro-Symbolic method; Tree Structure Reasoning; Semantic Parsing",
        "author": "",
        "aff": "Salesforce Research; Yale University",
        "rating": "",
        "confidence": "4;4;3;4",
        "correctness": "4;4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/salesforce/HPE"
    },
    {
        "id": "kEzI6OYXV4",
        "title": "Are All Steps Equally Important? Benchmarking Essentiality Detection in Event Processes",
        "track": "main",
        "status": "Short Main",
        "keywords": "Event Granularities;Essentiality;Event Processes;Goals;Steps",
        "author": "",
        "aff": "Department of Computer Science, USC; Department of Computer and Information Science, UPenn; Department of Electronic Engineering, THU",
        "rating": "",
        "confidence": "5;4;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "http://cogcomp.org/page/publication_view/1023"
    },
    {
        "id": "kFQrpCFanH",
        "title": "Dynosaur: A Dynamic Growth Paradigm for Instruction-Tuning Data Curation",
        "track": "main",
        "status": "Long Main",
        "keywords": "instruction tuning;dynamic;generalizable",
        "author": "",
        "aff": "Peking University; UIUC; UCLA",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "dynosaur-it.github.io",
        "github": "https://github.com/WadeYin9712/Dynosaur"
    },
    {
        "id": "kIRIjRPgfR",
        "title": "MacLaSa: Multi-Aspect Controllable Text Generation via Efficient Sampling from Compact Latent Space",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Natural Language Generation;Controllable Text Generation;Pretrained Language Models",
        "author": "",
        "aff": "Institute of Computing Technology, Chinese Academy of Sciences; University of Chinese Academy of Sciences; Sea-NExT Joint Lab, National University of Singapore",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "kKKzd8SaMy",
        "title": "The Interpreter Understands Your Meaning: End-to-end Spoken Language Understanding Aided by Speech Translation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "spoken language understanding;multilinguality;bayesian transfer learning",
        "author": "",
        "aff": "Idiap Research Institute, Martigny, Switzerland and Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne, Switzerland; Idiap Research Institute, Martigny, Switzerland",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "kKX9X0tMRH",
        "title": "DisCo: Distilled Student Models Co-training for Semi-supervised Text Mining",
        "track": "main",
        "status": "Long Main",
        "keywords": "co-training;semi-supervised learning;knowledge distillation",
        "author": "",
        "aff": "SCSE, Nanyang Technological University, Singapore.; Zhongguancun Laboratory, Beijing, P.R.China.; The School of Computing, University of Leeds, U.K.; School of Computer Science and Engineering, Beihang University, Beijing, P.R.China.; Department of Computer Science, University of Manchester, U.K.",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "kNCHv0NZ69",
        "title": "A Tale of Pronouns: Interpretability Informs Gender Bias Mitigation for Fairer Instruction-Tuned Machine Translation",
        "track": "main",
        "status": "Long Main",
        "keywords": "machine translation;gender bias;ethics;interpretability;instruction fine-tuned language models",
        "author": "",
        "aff": "Bocconi University, Milan, Italy; University of Hamburg, Hamburg, Germany",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/MilaNLProc/interpretability-mt-gender-bias"
    },
    {
        "id": "kNUglj7Kq1",
        "title": "Unifying Cross-Lingual Transfer across Scenarios of Resource Scarcity",
        "track": "main",
        "status": "Long Main",
        "keywords": "cross-lingual transfer;low-resource scenarios;parameter-efficient fine-tuning",
        "author": "",
        "aff": "Language Technology Lab, University of Cambridge; University of Edinburgh",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/parovicm/unified-xlt"
    },
    {
        "id": "kOhxudaIEj",
        "title": "CS2W: A Chinese Spoken-to-Written Style Conversion Dataset with Multiple Conversion Types",
        "track": "main",
        "status": "Long Main",
        "keywords": "Spoken-to-Written Style Conversion;Disfluency Detection;Grammatical Error Correction;ASR",
        "author": "",
        "aff": "College of Intelligence and Computing, Tianjin University, Tianjin, China",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "5;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/guozishan/CS2W"
    },
    {
        "id": "kQSlGF9lH6",
        "title": "Investigating Efficiently Extending Transformers for Long Input Summarization",
        "track": "main",
        "status": "Long Main",
        "keywords": "summarization;nlp;architectures;long context",
        "author": "",
        "aff": "",
        "rating": "",
        "confidence": "5;3;3",
        "correctness": "5;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "kUNzgI1HxN",
        "title": "Frugal Prompting for Dialog Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "dialog;dialog generation;natural language generation;dialogue generation;dialogue;NLP",
        "author": "",
        "aff": "IIT Kharagpur; Microsoft",
        "rating": "",
        "confidence": "3;2;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/bsantraigi/Frugal-Prompting, https://github.com/bsantraigi/Frugal-Prompting-Analysis"
    },
    {
        "id": "kXHDXPubz9",
        "title": "A Rose by Any Other Name would not Smell as Sweet: Social Bias in Names Mistranslation",
        "track": "main",
        "status": "Long Main",
        "keywords": "fairness and bias;NLP-related harms;name translation;evaluation",
        "author": "",
        "aff": "University of Southern California; University of Maryland, Microsoft Research; University of Maryland",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "kY7lpT8z1E",
        "title": "Contrastive Learning of Sentence Embeddings from Scratch",
        "track": "main",
        "status": "Long Main",
        "keywords": "contrastive learning;sentence embeddings",
        "author": "",
        "aff": "The Hong Kong University of Science and Technology; Zhejiang University, School of Engineering, Westlake University; School of Engineering, Westlake University",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/hkust-nlp/SynCSE"
    },
    {
        "id": "kZob2CsZXm",
        "title": "COVID-19 Vaccine Misinformation in Middle Income Countries",
        "track": "main",
        "status": "Long Main",
        "keywords": "COVID-19;vaccine;misinformation;NLP applications;domain-specific pre-training;text augmentation;distributed lag model",
        "author": "",
        "aff": "Dept. of Computer Science, Boston University; Center for Emerging Infectious Diseases Policy & Research, Boston University; Monash University Indonesia; College of Communication, Boston University; Dept. of Economics, Boston University; School of Public Health, Boston University",
        "rating": "",
        "confidence": "5;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "kayoyzcsTa",
        "title": "$\\textit{Lost in Translation, Found in Spans}$: Identifying Claims in Multilingual Social Media",
        "track": "main",
        "status": "Long Main",
        "keywords": "Claim Span Identification;Multilinguality;Social Media;Claims;Low-resource Languages",
        "author": "",
        "aff": "Indraprastha Institute of Information Technology Delhi; Mohammed Bin Zayed University of Artificial Intelligence",
        "rating": "",
        "confidence": "4;2;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/mbzuai-nlp/x-claim"
    },
    {
        "id": "kc2YhavobV",
        "title": "Continual Generalized Intent Discovery: Marching Towards Dynamic and Open-world Intent Recognition",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Out of Domain;Intent classification;Continual Learning",
        "author": "",
        "aff": "Meituan, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/songxiaoshuai/CGID"
    },
    {
        "id": "kda8szucLZ",
        "title": "Continual Dialogue State Tracking via Example-Guided Question Answering",
        "track": "main",
        "status": "Long Main",
        "keywords": "dialogue state tracking;dialogue;natural language processing;continual learning",
        "author": "",
        "aff": "Meta AI; Information Sciences Institute, University of Southern California",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "kdjSXbypKX",
        "title": "TRAVEL: Tag-Aware Conversational FAQ Retrieval via Reinforcement Learning",
        "track": "main",
        "status": "Long Main",
        "keywords": "FAQ retrieval;Conversational FAQ Retrieval;Dialogue System;Human-machine interaction",
        "author": "",
        "aff": "College of Computer Science, Sichuan University; Ant Group, China",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "kgxtMJHe7w",
        "title": "Selective Labeling: How to Radically Lower Data-Labeling Costs for Document Extraction Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "information extraction;selective labeling;data efficiency;annotation efficiency",
        "author": "",
        "aff": "Google Research, Mountain View, USA",
        "rating": "",
        "confidence": "2;2;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "kj4MRgh2K5",
        "title": "Transparency at the Source: Evaluating and Interpreting Language Models With Access to the True Distribution",
        "track": "main",
        "status": "Long Findings",
        "keywords": "language models;perplexity;interpretability;PCFG;learning dynamics;synthetic data",
        "author": "",
        "aff": "Institute for Logic, Language and Computation, University of Amsterdam",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "2;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/clclab/pcfg-lm"
    },
    {
        "id": "kp1U6wBPXq",
        "title": "Adapting Language Models to Compress Contexts",
        "track": "main",
        "status": "Long Main",
        "keywords": "language models;transformers;long-range language modeling;retrieval-augmented language modeling;in-context learning",
        "author": "",
        "aff": "Department of Computer Science & Princeton Language and Intelligence, Princeton University; Department of Computer Science, Princeton University",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/princeton-nlp/AutoCompressors"
    },
    {
        "id": "kqm0SOisFq",
        "title": "Information Extraction from Legal Wills: How Well Does GPT-4 Do?",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Information Extraction;Legal Natural Language Processing",
        "author": "",
        "aff": "School of Information, The University of Arizona; Department of Computer Science, The University of Arizona; James E. Rogers College of Law, The University of Arizona; Department of Linguistics, The University of Arizona",
        "rating": "",
        "confidence": "5;3;4",
        "correctness": "3;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "kspXkK9PtA",
        "title": "Enhancing Task-oriented Dialogue Systems with Generative Post-processing Networks",
        "track": "main",
        "status": "Long Main",
        "keywords": "Task-oriented Dialogue System;Reinforcement Learning;Natural Language Generation",
        "author": "",
        "aff": "Graduate School of Informatics, Nagoya University",
        "rating": "",
        "confidence": "5;4;4;3",
        "correctness": "4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/nu-dialogue/GenPPN"
    },
    {
        "id": "ktzudN7JmJ",
        "title": "ROBBIE: Robust Bias Evaluation of Large Generative Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "bias;fairness;toxicity;natural language generation;large language models;llm;evaluation",
        "author": "",
        "aff": "Meta",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/facebookresearch/ResponsibleNLP/tree/main/robbie"
    },
    {
        "id": "kuYRp78Qnp",
        "title": "Non-compositional Expression Generation Based on Curriculum Learning and Continual Learning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Non-compositional expression;Curriculum learning;continual learning",
        "author": "",
        "aff": "Facebook AI; University of Illinois Urbana-Champaign",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/zhjjn/CL2Gen.git"
    },
    {
        "id": "kuwz9k061u",
        "title": "Measuring the Knowledge Acquisition-Utilization Gap in Pretrained Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Knowledge Acquisition;Knowledge Utilization;Pretrained Language Models",
        "author": "",
        "aff": "Huawei Noah\u2019s Ark Lab; McGill University; Mila - Quebec AI; Mila - Quebec AI; \u00c9cole Polytechnique de Montr\u00e9al; Canada CIFAR AI Chair",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "kyHwalUpPu",
        "title": "Empowering Psychotherapy with Large Language Models: Cognitive Distortion Detection through Diagnosis of Thought Prompting",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Psychotherapy;Cognitive distortion;Cognitive behavior therapy;Large language models",
        "author": "",
        "aff": "Carnegie Mellon University; University of California, Santa Barbara",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "2;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "l4eviuXtBd",
        "title": "HadSkip: Homotopic and Adaptive Layer Skipping of Pre-trained Language Models for Efficient Inference",
        "track": "main",
        "status": "Long Findings",
        "keywords": "language model inference;efficiency",
        "author": "",
        "aff": "Purdue University, West Lafayette, IN, USA; Google Research, New York, NY, USA; Georgia Institute of Technology, Atlanta, GA, USA",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "lBAc5JgyMI",
        "title": "Narrative Style and the Spread of Health Misinformation on Twitter",
        "track": "main",
        "status": "Long Findings",
        "keywords": "narrative communication;misinformation;computational social sciences;natural language processing;linguistic analysis;classification",
        "author": "",
        "aff": "University of Connecticut; University of North Carolina; Virginia Tech; Oakland University",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "lC4vFCM2VA",
        "title": "Towards Zero-shot Relation Extraction in Web Mining: A Multimodal Approach with Relative XML Path",
        "track": "main",
        "status": "Long Findings",
        "keywords": "web mining;xml path;document ai;zero shot;transfer learning",
        "author": "",
        "aff": "University of California, San Diego",
        "rating": "",
        "confidence": "4;3;4;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "lCy3RwscMn",
        "title": "Deep Natural Language Feature Learning for Interpretable Prediction",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Model;Reasoning;Explanability;BERT",
        "author": "",
        "aff": "Centro Nacional de Inteligencia Artificial, Macul, Chile; Centro Nacional de Inteligencia Artificial, Macul, Chile; Department of Computer Science, Universidad de Chile, Santiago, Chile",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/furrutiav/nllf-emnlp-2023"
    },
    {
        "id": "lKPReKSJio",
        "title": "FREDSum: A Dialogue Summarization Corpus for French Political Debates",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Dialogue;Summarization;Corpus;Dataset;Political Debate",
        "author": "",
        "aff": "Grenoble Ecole de Management, France; \u00c9cole Polytechnique, France; Linagora, France; Linagora, France and \u00c9cole Polytechnique, France",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/VRennard/FreDSumNg"
    },
    {
        "id": "lKi1myznJe",
        "title": "ReasoningLM: Enabling Structural Subgraph Reasoning in Pre-trained Language Models for Question Answering over Knowledge Graph",
        "track": "main",
        "status": "Long Main",
        "keywords": "Pre-trained Language Model;Knowledge Graph Question Answering",
        "author": "",
        "aff": "School of Information, Renmin University of China; Gaoling School of Artificial Intelligence, Renmin University of China; Gaoling School of Artificial Intelligence, School of Information, Beijing Key Laboratory of Big Data Management and Analysis Methods, Renmin University of China; Alibaba Group",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/RUCAIBox/ReasoningLM"
    },
    {
        "id": "lOPMuJSVz8",
        "title": "Women Wearing Lipstick: Measuring the Bias Between an Object and Its Related Gender",
        "track": "main",
        "status": "Short Findings",
        "keywords": "image captioning;visual grounding;gender bias",
        "author": "",
        "aff": "Universitat Polit\u00e8cnica de Catalunya, TALP Research Center, Barcelona, Spain",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ahmedssabir/GenderScore"
    },
    {
        "id": "lReh4LaP8f",
        "title": "Structural Priming Demonstrates Abstract Grammatical Representations in Multilingual Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "abstraction;representation;multilingual language models;psychlinguistics;linguistic structure",
        "author": "",
        "aff": "Department of Linguistics, University of California San Diego; Department of Cognitive Science, University of California San Diego",
        "rating": "",
        "confidence": "5;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "lVat423gKI",
        "title": "Language Representation Projection: Can We Transfer Factual Knowledge across Languages in Multilingual Language Models?",
        "track": "main",
        "status": "Short Main",
        "keywords": "multilingual language models;factual knowledge;cross-lingual knowledge transfer",
        "author": "",
        "aff": "School of New Media and Communication, Tianjin University, Tianjin, China; College of Intelligence and Computing, Tianjin University, Tianjin, China",
        "rating": "",
        "confidence": "4;4;2",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "lWlBAJTFOm",
        "title": "Small Language Models Fine-tuned to Coordinate Larger Language Models improve Complex Reasoning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Language Model Reasoning;Problem decomposition;Multistep reasoning",
        "author": "",
        "aff": "DYSL-AI, India; IIT Bombay, India; IIT Delhi, India",
        "rating": "",
        "confidence": "4;5;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "lbtVebcVny",
        "title": "Revisiting De-Identification of Electronic Medical Records: Evaluation of Within- and Cross-Hospital Generalization",
        "track": "main",
        "status": "Short Main",
        "keywords": "De-Identification;Electronic Medical Records;Domain Generalization",
        "author": "",
        "aff": "Ningbo No.2 Hospital; Ningbo Institute of Life and Health Industry, University of Chinese Academy of Sciences",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/lanyangyang93/Revisiting-De-Identification"
    },
    {
        "id": "ldbYAF0ad0",
        "title": "Large Language Models are Not Yet Human-Level Evaluators for Abstractive Summarization",
        "track": "main",
        "status": "Long Findings",
        "keywords": "LLM evaluation;ChatGPT;abstractive summarization evaluation;GPT-4",
        "author": "",
        "aff": "DAMO Academy, Alibaba Group, Singapore & National University of Singapore; National University of Singapore; DAMO Academy, Alibaba Group, Singapore & Hupan Lab, 310023, Hangzhou, China",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/DAMO-NLP-SG/LLM_summeval"
    },
    {
        "id": "ldtjC7TSJ5",
        "title": "Non-Autoregressive Sentence Ordering",
        "track": "main",
        "status": "Long Findings",
        "keywords": "sentence ordering;non-autoregressive transformer",
        "author": "",
        "aff": "National University of Singapore; University of Electronic Science and Technology of China; The Hong Kong Polytechnic University; The Hong Kong university of Science and technology",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/steven640pixel/nonautoregressive-sentence-ordering"
    },
    {
        "id": "lhSLoOYLDv",
        "title": "Joint Semantic and Strategy Matching for Persuasive Dialogue",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Persuasive dialogue;Application of dialogue;Retrieval-based dialogue",
        "author": "",
        "aff": "Meituan, Beijing, China; Gaoling School of Artificial Intelligence, Renmin University of China, Beijing, China",
        "rating": "",
        "confidence": "3;3;3;4",
        "correctness": "3;2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "ljjy0Sw5sx",
        "title": "Descriptive Prompt Paraphrasing for Target-Oriented Multimodal Sentiment Classification",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Target-Oriented Multimodal Sentiment Classification;Prompt Learning;Multimodal Sentiment Analysis",
        "author": "",
        "aff": "Wuhan University of Technology, Wuhan, China; The University of Southern Queensland, Toowoomba, Australia",
        "rating": "",
        "confidence": "4;5;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "ljsGKc8cVR",
        "title": "Longtriever: a Pre-trained Long Text Encoder for Dense Document Retrieval",
        "track": "main",
        "status": "Long Main",
        "keywords": "dense retrieval;document retrieval",
        "author": "",
        "aff": "MSRA, Beijing, China; USTC, Hefei, China",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/SamuelYang1/Longtriever"
    },
    {
        "id": "llv2GnH5bD",
        "title": "Retrofitting Light-weight Language Models for Emotions using Supervised Contrastive Learning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Emotion;Contrastive Learning;Retrofitting",
        "author": "",
        "aff": "Indian Institute of Technology Bombay, Mumbai; TCS Research, Tata Consultancy Services, Pune",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "lojtRAQOls",
        "title": "Using LLM for Improving Key Event Discovery: Temporal-Guided News Stream Clustering with Event Summaries",
        "track": "main",
        "status": "Short Findings",
        "keywords": "news stream clustering;event discovery;political discourse characterization;LLM",
        "author": "",
        "aff": "Purdue University; University of Pennsylvania",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/nnakshat/KeyEvents"
    },
    {
        "id": "lpyU0zyEsS",
        "title": "Identifying Informational Sources in News Articles",
        "track": "main",
        "status": "Long Main",
        "keywords": "computational journalism;source prediction;document-level modeling",
        "author": "",
        "aff": "University of California, Los Angeles; Thomas Lord Department of Computer Science, University of Southern California and Information Sciences Institute, University of Southern California; Information Sciences Institute, University of Southern California",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/alex2awesome/source-exploration"
    },
    {
        "id": "lqe06F5OiU",
        "title": "Chain-of-Thought Embeddings for Stance Detection on Social Media",
        "track": "main",
        "status": "Short Findings",
        "keywords": "chain of thought;prompting;chatgpt;stance detection",
        "author": "",
        "aff": "Department of Computer Science, Dartmouth College",
        "rating": "",
        "confidence": "3;4;4;3",
        "correctness": "4;3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "ls4Pfsl2jZ",
        "title": "Multi-step Jailbreaking Privacy Attacks on ChatGPT",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large language models;privacy;extraction attacks",
        "author": "",
        "aff": "Dept. of CSE, Hong Kong University of Science and Technology; Center for Data Science, AAIS, Peking University; Dept. of Computer Science, University of Illinois at Urbana-Champaign; The Law School, University of Notre Dame",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "m1TV5K9Cvc",
        "title": "Evaluating Emotion Arcs Across Languages: Bridging the Global Divide in Sentiment Analysis",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Emotion Arcs;Sentiment Analysis;Low-Resource NLP;Multilingual;Emotion Lexicons",
        "author": "",
        "aff": "National Research Council Canada; MaiNLP, Center for Information and Language Processing, LMU Munich, Germany; Department of Computing Science, University of Alberta",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/dteodore/EmotionArcs"
    },
    {
        "id": "mAxs9qiXbo",
        "title": "Debiasing Multimodal Models via Causal Information Minimization",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multimodal;Causality;Debiasing;Out-of-distribution",
        "author": "",
        "aff": "UNC Chapel Hill",
        "rating": "",
        "confidence": "2;4;5",
        "correctness": "3;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Vaidehi99/CausalInfoMin"
    },
    {
        "id": "mCnBRLJuhY",
        "title": "The Curious Case of Hallucinatory (Un)answerability: Finding Truths in the Hidden States of Over-Confident Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "LLMs;explainability;answerability;hallucinations",
        "author": "",
        "aff": "Bar-Ilan University, Google Research; Bar-Ilan University",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/lovodkin93/unanswerability"
    },
    {
        "id": "mDPUF7ubAv",
        "title": "An Empirical Study of Instruction-tuning Large Language Models in Chinese",
        "track": "main",
        "status": "Long Findings",
        "keywords": "large language models;instruction fine-tune",
        "author": "",
        "aff": "APUS AiLMe Lab; Institute of Information Engineering, Chinese Academy of Sciences; Institute of Information Engineering, Chinese Academy of Sciences; School of Cyber Security, University of Chinese Academy of Sciences",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/PhoebusSi/Alpaca-CoT"
    },
    {
        "id": "mDgLGrL6ze",
        "title": "ECHo: A Visio-Linguistic Dataset for Event Causality Inference via Human-Centric Reasoning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "visio-linguistic commonsense reasoning;theory of mind;chain of thought",
        "author": "",
        "aff": "National University of Singapore",
        "rating": "",
        "confidence": "4;3;2",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/YuxiXie/ECHo"
    },
    {
        "id": "mERmlOPxPY",
        "title": "Definitions Matter: Guiding GPT for Multi-label Classification",
        "track": "main",
        "status": "Short Findings",
        "keywords": "GPT-3;zero-shot classification;LLM",
        "author": "",
        "aff": "UPV, Ru\u00afder Bo\u0161kovi \u00b4c Institute; Univ. Polit\u00e8cnica de Val\u00e8ncia (UPV); EURECOM; UPV",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/dkorenci/gpt-def-zeroshot"
    },
    {
        "id": "mGEfAu17Rk",
        "title": "Hallucination Detection for Grounded Instruction Generation",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Hallucination detection;multimodality;natural language generation",
        "author": "",
        "aff": "University of Maryland, College Park; University of California, Berkeley; Microsoft Research",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://lingjunzhao.github.io/hallucination_detection.html"
    },
    {
        "id": "mIsrzEjeG4",
        "title": "When Do Decompositions Help for Machine Reading?",
        "track": "main",
        "status": "Short Main",
        "keywords": "decomposition;machine reading;question answering",
        "author": "",
        "aff": "Department of Computer Science, Johns Hopkins University; Department of Computer Science and Engineering, Texas A&M University",
        "rating": "",
        "confidence": "5;4;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/WeiKangda/Question-Decomposition"
    },
    {
        "id": "mJCXoiIeJU",
        "title": "On the Automatic Generation and Simplification of Children's Stories",
        "track": "main",
        "status": "Long Main",
        "keywords": "Natural Language Generation;NLP for Education;LLMs",
        "author": "",
        "aff": "University of Colorado Boulder; Johannes Gutenberg University Mainz",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "mKuH13Oq3x",
        "title": "Adaptive Gating in Mixture-of-Experts based Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Mixture of Experts;Adaptive Computation;Training Efficiency",
        "author": "",
        "aff": "; The Chinese University of Hong Kong; City University of Hong Kong",
        "rating": "",
        "confidence": "4;2;2",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "mLJOMUwQyz",
        "title": "INFORM : Information eNtropy based multi-step reasoning FOR large language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Chain-of-Thoughts;Multi-Step Reasoning;Large Language Models;Prompting;In-context Learning",
        "author": "",
        "aff": "Harbin Institute of Technology, Shenzhen; Institute of Computer Science and Technology, Soochow University, China",
        "rating": "",
        "confidence": "4;5;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/oneningt/INFORM"
    },
    {
        "id": "mLlJavL0PB",
        "title": "InstructExcel: A Benchmark for Natural Language Instruction in Excel",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Code generation;program synthesis;benchmark;large language models",
        "author": "",
        "aff": "Microsoft; Arizona State University; UMass Amherst",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/microsoft/InstructExcel"
    },
    {
        "id": "mN62FSvZVW",
        "title": "Sociocultural Norm Similarities and Differences via Situational Alignment and Explainable Textual Entailment",
        "track": "main",
        "status": "Long Main",
        "keywords": "social norms;culture;chain-of-thought reasoning",
        "author": "",
        "aff": "Department of Computer Science, Columbia University; Data Science Institute, Columbia University",
        "rating": "",
        "confidence": "5;3;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "mNMwIwydgr",
        "title": "Are we biased on bias? Characterizing social bias research in the ACL community",
        "track": "main",
        "status": "Reject",
        "keywords": "Social Bias;Survey;Ethics",
        "author": "",
        "aff": "EMNLP submission",
        "rating": "",
        "confidence": "5;3;4",
        "correctness": "3;2;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 1.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "mPaNp1eglz",
        "title": "Comparing the Evaluation and Production of Loophole Behavior in Humans and Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "theory of mind;pragmatics;social reasoning;loopholes;large-language models;artificial intelligence",
        "author": "",
        "aff": "Department of Psychology, Harvard University; School of Engineering and Applied Sciences, Harvard University; Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "2;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "mQxqo1di63",
        "title": "KAPALM: Knowledge grAPh enhAnced Language Models for Fake News Detection",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Knowledge Graph; Fake news detection",
        "author": "",
        "aff": "College of Computer Science, Nankai University, Tianjin, China; School of CSE, Tianjin University of Technology, Tianjin, China",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "2;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "mRETTyZEJa",
        "title": "GROVE: A Retrieval-augmented Complex Story Generation Framework with A Forest of Evidence",
        "track": "main",
        "status": "Long Findings",
        "keywords": "story generation;large language model;iterative prompting",
        "author": "",
        "aff": "College of Computer, National University of Defense Technology, Hunan, China",
        "rating": "",
        "confidence": "2;3;3",
        "correctness": "4;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "mTiHLHu3sP",
        "title": "GPT-RE: In-context Learning for Relation Extraction using Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large language models;relation extraction;in-context learning",
        "author": "",
        "aff": "Kyoto University, Japan; Zhejiang University, China",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "mU6C04mAJk",
        "title": "ToViLaG: Your Visual-Language Generative Model is Also An Evildoer",
        "track": "main",
        "status": "Long Main",
        "keywords": "Toxicity;text-to-image generation;image-to-text generation;Detoxification;Multimodality;generation",
        "author": "",
        "aff": "Microsoft Research Asia; Department of Computer Science and Technology, Tongji University",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "mW5M8qkAxt",
        "title": "Confidence-based Ensembling of Perspective-aware Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Data perspectivism;irony;hate speech;confidence;ensemble",
        "author": "",
        "aff": "University of Turin, Italy; aequa-tech, Turin, Italy; University of Turin, Italy",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "mYniPxMGLL",
        "title": "Dancing Between Success and Failure: Edit-level Simplification Evaluation using SALSA",
        "track": "main",
        "status": "Long Main",
        "keywords": "model evaluation;text simplification;fine-grained annotation;language model analysis;human evaluation",
        "author": "",
        "aff": "School of Interactive Computing, Georgia Institute of Technology",
        "rating": "",
        "confidence": "4;3;4;4",
        "correctness": "5;3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://salsa-eval.com",
        "github": ""
    },
    {
        "id": "mb35Pb69e8",
        "title": "TCFLE-8: a Corpus of Learner Written Productions for French as a Foreign Language and its Application to Automated Essay Scoring",
        "track": "main",
        "status": "Long Main",
        "keywords": "Learner corpus;AES;French;Learner written essays;French certification exam",
        "author": "",
        "aff": "France \u00c9ducation international; Cental, IL&C, UCLouvain; University of Gothenburg",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "5;5;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 5.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://www.france-education-international.fr/corpus",
        "github": ""
    },
    {
        "id": "mkEkfHveEL",
        "title": "Interview Evaluation: A Novel Approach for Automatic Evaluation of Conversational Question Answering Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Conversational Question Answering;Evaluation metrics;Conversational history;Conversational question generation;Prompting",
        "author": "",
        "aff": "School of Computer Science and Technology, Soochow University, Suzhou, China; Institute for Infocomm Research, A*STAR, Singapore",
        "rating": "",
        "confidence": "3;2;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/cipolee/interview_evaluation"
    },
    {
        "id": "mmlQICRJMc",
        "title": "AdaSent: Efficient Domain-Adapted Sentence Embeddings for Few-Shot Classification",
        "track": "main",
        "status": "Long Main",
        "keywords": "few-shot text classification;sentence embedding;domain adaptation;parameter-efficient fine-tuning",
        "author": "",
        "aff": "Huawei Research Centre, Dublin, Ireland; Ubiquitous Knowledge Processing Lab (UKP Lab), Department of Computer Science and Hessian Center for AI (hessian.AI), Technical University of Darmstadt; Center for AI and Data Science, University of W\u00fcrzburg",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/UKPLab/AdaSent"
    },
    {
        "id": "mnzjuOhkR2",
        "title": "Struct-XLM: A Structure Discovery Multilingual Language Model for Enhancing Cross-lingual Transfer through Reinforcement Learning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Cross-lingual Representaion Alignment;Cross-lingual Transfer Learning;Reinforcement Learning",
        "author": "",
        "aff": "College of Computer Science and Technology, Zhejiang University and Alibaba-Zhejiang University Joint Research Institute of Frontier Technologies; College of Computer Science and Technology, Zhejiang University",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/wulinjuan/Struct-XLM"
    },
    {
        "id": "mpL9ikuYez",
        "title": "Proto-lm: A Prototypical Network-Based Framework for Built-in Interpretability in Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Prototypes;NLP;Interpretability;Faithfulness",
        "author": "",
        "aff": "Department of Computer Science, Dartmouth College; Department of Biomedical Data Science, Dartmouth College",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/yx131/proto-lm"
    },
    {
        "id": "mqnK19Dm80",
        "title": "Generative Emotion Cause Triplet Extraction in Conversations with Commonsense Knowledge",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Emotion Cause Analysis;Commonsense Knowledge;Emotion Recognition in Conversations",
        "author": "",
        "aff": "School of Computer Science and Engineering, Nanjing University of Science and Technology, China",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/NUSTM/SHARK"
    },
    {
        "id": "mrARDvuKi2",
        "title": "2INER: Instructive and In-Context Learning on Few-Shot Named Entity Recognition",
        "track": "main",
        "status": "Long Findings",
        "keywords": "prompt-based learning;instruction finetuning;in-context learning;NER",
        "author": "",
        "aff": "Chongqing University; Shanghai Jiaotong University; Xiaohongshu Inc.",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "mrD5HN7ZNR",
        "title": "APP: Adaptive Prototypical Pseudo-Labeling for Few-shot OOD Detection",
        "track": "main",
        "status": "Long Findings",
        "keywords": "OOD;Intent Detection;Few-shot;Prototype",
        "author": "",
        "aff": "Meituan, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Yupei-Wang/App-OOD"
    },
    {
        "id": "muTWDq9bVs",
        "title": "Speculative Decoding: Exploiting Speculative Execution for Accelerating Seq2seq Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "speculative decoding;efficient seq2seq generation",
        "author": "",
        "aff": "Microsoft Research Asia; National Key Laboratory for Multimedia Information Processing, Peking University; School of Software & Microelectronics, Peking University; National Key Laboratory for Multimedia Information Processing, Peking University; School of Computer Science, Peking University",
        "rating": "",
        "confidence": "3;2;4",
        "correctness": "2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/hemingkx/SpecDec"
    },
    {
        "id": "mvtjk1mlrq",
        "title": "Knowledge Rumination for Pre-trained Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Knowledge rumination;pretrained language model",
        "author": "",
        "aff": "Zhejiang University, Zhejiang University - Ant Group Joint Laboratory of Knowledge Graph; Alibaba Group; Zhejiang University, Zhejiang University - Ant Group Joint Laboratory of Knowledge Graph, Donghai Laboratory",
        "rating": "",
        "confidence": "1;4;3;3",
        "correctness": "4;5;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.75,
        "correctness_avg": 4.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/zjunlp/knowledge-rumination"
    },
    {
        "id": "mx0ltXW10S",
        "title": "TopWORDS-Poetry: Simultaneous Text Segmentation and Word Discovery for Classical Chinese Poetry via Bayesian Inference",
        "track": "main",
        "status": "Long Main",
        "keywords": "Word Discovery;Text Segmentation;Classical Chinese Poetry;Bayesian Inference;Unsupervised Method",
        "author": "",
        "aff": "Center for Statistical Science & Department of Industrial Engineering, Tsinghua University; Department of Chinese Language and Literature, School of Humanities, Tsinghua University",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "n1Sx9ZjJRs",
        "title": "TOD-Flow: Modeling the Structure of Task-Oriented Dialogues",
        "track": "main",
        "status": "Long Main",
        "keywords": "Task-oriented Dialogue;Dialog policy learning;interpretability;precondition inference",
        "author": "",
        "aff": "LG AI Research; University of Michigan, Ann Arbor",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/srsohn/TOD-Flow"
    },
    {
        "id": "n20PghmZaD",
        "title": "A New Benchmark and Reverse Validation Method for Passage-level Hallucination Detection",
        "track": "main",
        "status": "Long Findings",
        "keywords": "hallucination detection; LLM",
        "author": "",
        "aff": "Center for Data Science, Peking University; The MOE Key Laboratory of Computational Linguistics, Peking University; Wangxuan Institute of Computer Technology, Peking University",
        "rating": "",
        "confidence": "3;4;5",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "n6qiOfZVYp",
        "title": "VIBE: Topic-Driven Temporal Adaptation for Twitter Classification",
        "track": "main",
        "status": "Long Main",
        "keywords": "temporal adaptation; neural topic model; social media; twitter classification",
        "author": "",
        "aff": "Department of Computing, The Hong Kong Polytechnic University, HKSAR, China; Department of Computing, The Hong Kong Polytechnic University, HKSAR, China; Research Centre on Data Science & Artificial Intelligence",
        "rating": "",
        "confidence": "4;3;3;4",
        "correctness": "5;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 4.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/CelestineZYJ/VIBE-Temporal-Adaptation"
    },
    {
        "id": "n9y4IDFcCr",
        "title": "GROOViST: A Metric for Grounding Objects in Visual Storytelling",
        "track": "main",
        "status": "Short Main",
        "keywords": "visual storytelling;grounding;NLG evaluation",
        "author": "",
        "aff": "University of Amsterdam; ILLC, University of Amsterdam",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/akskuchi/groovist"
    },
    {
        "id": "nC47EZVfAw",
        "title": "Low-Resource Comparative Opinion Quintuple Extraction by Data Augmentation with Prompting",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Comparative opinion quintuple extraction;Low-resource;Data augmentation;Large language models;Sentiment analysis",
        "author": "",
        "aff": "School of Computer Science and Technology, Soochow University, Suzhou, China; Northeastern University, China; DAMO Academy, Alibaba Group, China",
        "rating": "",
        "confidence": "4;4;3;4",
        "correctness": "4;3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/qtxu-nlp/COQE-DAP"
    },
    {
        "id": "nC8WUrpWjG",
        "title": "Answer-state Recurrent Relational Network (AsRRN) for Constructed Response Assessment and Feedback Grouping",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Writing assessment;relation networks;contrastive learning",
        "author": "",
        "aff": "Department of Computer Science and Engineering, Pennsylvania State University; Department of Statistics, Pennsylvania State University",
        "rating": "",
        "confidence": "1;4;2",
        "correctness": "2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 1.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "nE9aUYqz6k",
        "title": "What Else Do I Need to Know? The Effect of Background Information on Users\u2019 Reliance on QA Systems",
        "track": "main",
        "status": "Long Main",
        "keywords": "human-centered NLP;over-reliance;explainability",
        "author": "",
        "aff": "University of Maryland, Microsoft Research; Google; University of Maryland; U.S. Army Research Lab",
        "rating": "",
        "confidence": "5;3;4",
        "correctness": "3;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "nFagtplIb8",
        "title": "Improving Chinese Pop Song and Hokkien Gezi Opera Singing Voice Synthesis by Enhancing Local Modeling",
        "track": "main",
        "status": "Long Main",
        "keywords": "Singing voice synthesis;local modeling enhancement;local adaptive weights loss;Hokkien Gezi Opera;Chinese pop song",
        "author": "",
        "aff": "Key Laboratory of Digital Protection and Intelligent Processing of Intangible Cultural Heritage of Fujian and Taiwan (Xiamen University), Ministry of Culture and Tourism, China; Institute of Artificial Intelligence, Xiamen University, China; Department of Artificial Intelligence, School of Informatics, Xiamen University, China; Key Laboratory of Digital Protection and Intelligent Processing of Intangible Cultural Heritage of Fujian and Taiwan (Xiamen University), Ministry of Culture and Tourism, China; Institute of Artificial Intelligence, Xiamen University, China",
        "rating": "",
        "confidence": "5;4;3;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/baipeng1/SVSELM"
    },
    {
        "id": "nGCwDjinT8",
        "title": "Adaptive Hinge Balance Loss for Document-Level Relation Extraction",
        "track": "main",
        "status": "Short Findings",
        "keywords": "document-level relation extraction;multi-label classification;balancing methods;loss function design",
        "author": "",
        "aff": "Department of Automation, Shanghai Jiao Tong University; Inspur Genersoft Co., Ltd.",
        "rating": "",
        "confidence": "5;3;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Jize-W/HingeABL"
    },
    {
        "id": "nGFQ7IqOyg",
        "title": "Non-Autoregressive Math Word Problem Solver with Unified Tree Structure",
        "track": "main",
        "status": "Long Main",
        "keywords": "MWP solving;non-autoregressive solver;unified tree structure",
        "author": "",
        "aff": "National University of Singapore; Singapore Management University; University of Electronic Science and Technology of China",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/mengqunhan/MWP-NAS"
    },
    {
        "id": "nI0X5IZOQA",
        "title": "Oolong: Investigating What Makes Transfer Learning Hard with Controlled Studies",
        "track": "main",
        "status": "Short Main",
        "keywords": "crosslingual;knowledge transfer;language model;finetuning",
        "author": "",
        "aff": "Stanford University",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "4;3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "nIp7wkMeMP",
        "title": "Enhancing Low-resource Fine-grained Named Entity Recognition by Leveraging Coarse-grained Datasets",
        "track": "main",
        "status": "Long Main",
        "keywords": "Named Entity Recognition;Fine-grained NER;Low-resource scenario",
        "author": "",
        "aff": "Department of Applied Artificial Intelligence, Hanyang University; Department of Applied Artificial Intelligence, Hanyang University and Ramply Inc.",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/sue991/CoFiNER"
    },
    {
        "id": "nIuJXuSdhn",
        "title": "Can LLMs Facilitate Interpretation of Pre-trained Language Models?",
        "track": "main",
        "status": "Long Main",
        "keywords": "Interpretation;explainability;Large Language Models;Neuron Analysis",
        "author": "",
        "aff": "Qatar Computing Research Institute, HBKU, Doha, Qatar",
        "rating": "",
        "confidence": "4;2;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://neurox.qcri.org/projects/transformers-concept-net/",
        "github": ""
    },
    {
        "id": "nMjktU5AiP",
        "title": "IndiSocialFT: Multilingual Word Representation for Indian languages in code-mixed environment",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Indian Languages;Multilingual Word Embedding;Code-mixed;Social Media Text",
        "author": "",
        "aff": "Department of Computer Science and Engineering, Indian Institute of Technology Guwahati",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "nPzrjWrtlz",
        "title": "The Truth, The Whole Truth, and Nothing but the Truth: A New Benchmark Dataset for Hebrew Text Credibility Assessment",
        "track": "main",
        "status": "Long Findings",
        "keywords": "NLP and social media;NLP application;Fake news detection;Fact Checking;Credibility Assessment",
        "author": "",
        "aff": "Bar-Ilan University",
        "rating": "",
        "confidence": "4;5;3",
        "correctness": "3;1;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "nRB8VpeM7b",
        "title": "Pushdown Layers: Encoding Recursive Structure in Transformer Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "recursive structure;syntactic language models;generalization",
        "author": "",
        "aff": "MIT CSAIL; Computer Science Department, Stanford University",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "nSPsxWVe4k",
        "title": "SLOG: A Structural Generalization Benchmark for Semantic Parsing",
        "track": "main",
        "status": "Long Main",
        "keywords": "compositional generalization;structural generalization;long-distance dependencies;recursion;semantic parsing",
        "author": "",
        "aff": "\u2020Universit\u00e9 Paris Cit\u00e9\u2217; \u00b5New York University; \u2118Saarland University; \u2206Boston University\u2217; \u03bbVrije Universiteit Amsterdam",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "nT4S0wgrwp",
        "title": "Understanding Translationese in Cross-Lingual Summarization",
        "track": "main",
        "status": "Long Findings",
        "keywords": "summarization;multi-lingual summarization;cross-lingual summarization",
        "author": "",
        "aff": "Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University, Shanghai, China; School of Management, Fudan University, Shanghai, China; Beijing Key Lab of Traffic Data Analysis and Mining, Beijing Jiaotong University, Beijing, China; Pattern Recognition Center, WeChat AI, Tencent Inc, China",
        "rating": "",
        "confidence": "4;3;3;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "nTKRAgssvX",
        "title": "SiMFy: A Simple Yet Effective Approach for Temporal Knowledge Graph Reasoning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Temporal Knowledge Graph;Reasoning;Multilayer Perceptron;Historical Frequency",
        "author": "",
        "aff": "National Engineering Research Center for Big Data Technology and System, School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China",
        "rating": "",
        "confidence": "3;4;5",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/CGCL-codes/SiMFy"
    },
    {
        "id": "nWXMv949ZH",
        "title": "Logic-LM: Empowering Large Language Models with Symbolic Solvers for Faithful Logical Reasoning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Logical Reasoning;Language Model;Symbolic Language;Self-Refinement",
        "author": "",
        "aff": "University of California, Santa Barbara",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "3;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/teacherpeterpan/Logic-LLM"
    },
    {
        "id": "nYbOG9EaxD",
        "title": "A Question Answering Framework for Decontextualizing User-facing Snippets from Scientific Documents",
        "track": "main",
        "status": "Long Main",
        "keywords": "decontextualization;snippets;text-simplification",
        "author": "",
        "aff": "University of Washington; Allen Institute for AI",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/bnewm0609/qa-decontext"
    },
    {
        "id": "nYgu408UIo",
        "title": "Why LLMs Hallucinate, and How to Get (Evidential) Closure: Perceptual, Intensional, and Extensional Learning for Faithful Natural Language Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Truth;Semantics;Meaning;Hallucination;Identification;Natural Language Generation",
        "author": "",
        "aff": "UC Berkeley",
        "rating": "",
        "confidence": "1;3;2",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "neRWI1hWyO",
        "title": "Allies: Prompting Large Language Model with Beam Search",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large Language Model;Question Answering;Beam Search",
        "author": "",
        "aff": "Microsoft Research Asia; Peking University; Microsoft",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "4;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/microsoft/SimXNS/tree/main/ALLIES"
    },
    {
        "id": "newk6aDMRi",
        "title": "Teacher Perception of Automatically Extracted Grammar Concepts for L2 Language Learning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "NLP for pedagogy;second language learning;low-resource languages",
        "author": "",
        "aff": "Carnegie Mellon University, Currently works at Google Research; George Mason University; Carnegie Mellon University; Kannada Academy",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "nmSvzxwfRZ",
        "title": "FinePrompt: Unveiling the Role of Finetuned Inductive Bias on Compositional Reasoning in GPT-4",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Large Language Model;Prompt Learning;Fine-tuning;Compositional Reasoning;Question Answering",
        "author": "",
        "aff": "University of Illinois Urbana-Champaign; KAIST; University of Edinburgh",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/wjdghks950/FinePrompt.git"
    },
    {
        "id": "nmnPI4eNuh",
        "title": "DeSIQ: Towards an Unbiased, Challenging Benchmark for Social Intelligence Understanding",
        "track": "main",
        "status": "Long Main",
        "keywords": "Question Answering; Social Intelligence; Multimodal Learning",
        "author": "",
        "aff": "Faculty of Information Technology, Monash University, Melbourne, Australia",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "nntsSuRSPb",
        "title": "TextMixer: Mixing Multiple Inputs for Privacy-Preserving Inference",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Privacy-preserving Inference;Multi-input Multi-output network",
        "author": "",
        "aff": "Institute of Modern Languages and Linguistics, Fudan University, Shanghai, China; School of Computer Science, Fudan University, Shanghai, China; International Human Phenome Institutes, Shanghai, China; School of Computer Science, Fudan University, Shanghai, China",
        "rating": "",
        "confidence": "3;2;4",
        "correctness": "4;4;1",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "noEKNSB8Zq",
        "title": "\u201cKelly is a Warm Person, Joseph is a Role Model\u201d: Gender Biases in LLM-Generated Reference Letters",
        "track": "main",
        "status": "Long Findings",
        "keywords": "fairness;reference letter generation;LLMs",
        "author": "",
        "aff": "University of California, Los Angeles; University Of Southern California; Adobe Research",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "noIvPGG8P1",
        "title": "Search Augmented Instruction Learning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "large language model;instruction tuning;question answering",
        "author": "",
        "aff": "CUHK Centre for Perceptual and Interactive Intelligence, Hong Kong SAR, China; MIT Computer Science and Artificial Intelligence Lab, Cambridge MA, USA",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/luohongyin/SAIL"
    },
    {
        "id": "noPuQXVx8Y",
        "title": "Exploring the Sensitivity of LLMs' Decision-Making Capabilities: Insights from Prompt Variations and Hyperparameters",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Language Models;Decision-Making;Cognitive Psychology;Chain of Thought",
        "author": "",
        "aff": "University of California, Irvine",
        "rating": "",
        "confidence": "3;5;2;4",
        "correctness": "4;4;2;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/..."
    },
    {
        "id": "noUf45O1PX",
        "title": "BanLemma: A Word Formation Dependent Rule and Dictionary Based Bangla Lemmatizer",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Computational Linguistics;Morphology;Bangla NLP;Lemmatization",
        "author": "",
        "aff": "Bangladesh Computer Council, Dhaka, Bangladesh; Fordham University, New York, USA; GigaTechLimited, Dhaka, Bangladesh; University of Dhaka, Bangladesh; NorthSouthUniversity, Dhaka, Bangladesh",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/eblict-gigatech/BanLemma1"
    },
    {
        "id": "nsupkM0ppH",
        "title": "Watermarking PLMs on Classification Tasks by Combining Contrastive Learning with Weight Perturbation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "PLM;Warermarking;backdoor;contrastive learning;weight perturbation",
        "author": "",
        "aff": "School of Computer Science, Fudan University, Shanghai, China; Shanghai Key Laboratory of Intelligent Information Processing; UniDT Technology, Shanghai, China",
        "rating": "",
        "confidence": "3;4;4;4",
        "correctness": "3;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "nuLtpgr9l5",
        "title": "Disfluent Cues for Enhanced Speech Understanding in Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "disfluency detection;disfluencies;self-repairs;large language models;interruptions;contextual cues;spontaneous speech",
        "author": "",
        "aff": "Department of Quantitive Biomedicine, University of Zurich; Department of Engineering Science, University of Oxford",
        "rating": "",
        "confidence": "4;5;2",
        "correctness": "4;1;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "nuPp6jdCgg",
        "title": "Evaluating Large Language Models on Controlled Generation Tasks",
        "track": "main",
        "status": "Long Main",
        "keywords": "Evaluation;Large Language Model;Analysis",
        "author": "",
        "aff": "University of California, Los Angeles; University of Southern California; Google DeepMind; Amazon; ETH Zurich",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/sunjiao123sun/"
    },
    {
        "id": "nucyYJZS5z",
        "title": "Lion: Adversarial Distillation of Proprietary Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "large language models;instruction following;knowledge distillation",
        "author": "",
        "aff": "The Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China; The Hong Kong University of Science and Technology, Hong Kong SAR, China",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/YJiangcm/Lion"
    },
    {
        "id": "nw6JxagUNG",
        "title": "Methodological Insights in Detecting Subtle Semantic Shifts with Contextualized and Static Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "semantic shift detection;contextualized embeddings;static embeddings;political communities",
        "author": "",
        "aff": "Computational Linguistics, Dept. of Linguistics, Bielefeld University; Center for Information and Language Processing, LMU Munich; Computational Linguistics & Text Mining Lab, Vrije Universiteit Amsterdam; Department of Mathematics and Computer Science, Eindhoven University of Technology",
        "rating": "",
        "confidence": "2;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/SanneHoeken/LSVD"
    },
    {
        "id": "nwTqq0XW3w",
        "title": "Language and Mental Health: Measures of Emotion Dynamics from Text as Linguistic Biosocial Markers",
        "track": "main",
        "status": "Long Main",
        "keywords": "Utterance Emotion Dynamics;Mental Health;Social Media;Sentiment Analysis;Emotion Arcs;Emotional Reactivity;Lexicons",
        "author": "",
        "aff": "Carleton University; Dept. Computing Science, Alberta Machine Intelligence Institute (Amii), University of Alberta; Dept. Psychology, University of Alberta; Dept. Computing Science, Alberta Machine Intelligence Institute (Amii), University of Alberta; MaiNLP, Center for Information and Language Processing, LMU Munich, Germany; National Research Council Canada",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "o2HBfgY20b",
        "title": "API-Bank: A Comprehensive Benchmark for Tool-Augmented LLMs",
        "track": "main",
        "status": "Long Main",
        "keywords": "Tool-Augmented LLMs;Large Language Model;Benchmark",
        "author": "",
        "aff": "Alibaba Group; Hong Kong University of Science and Technology; Peking University; Shenzhen Intelligent Strong Technology Co., Ltd",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "4;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/api-bank"
    },
    {
        "id": "o5LeRFe7VS",
        "title": "Test-time Augmentation for Factual Probing",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Factual Probing;TTA;Calibration",
        "author": "",
        "aff": "Tohoku University; RIKEN; MBZUAI",
        "rating": "",
        "confidence": "4;3;2",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/gokamoda/TTA4FactualProbing"
    },
    {
        "id": "o5bOK5a9qz",
        "title": "DemaFormer: Damped Exponential Moving Average Transformer with Energy-Based Modeling for Temporal Language Grounding",
        "track": "main",
        "status": "Long Findings",
        "keywords": "temporal language grounding;energy-based modeling;exponential-moving average;transformer",
        "author": "",
        "aff": "Carnegie Mellon University, USA; National University of Singapore, Singapore; Nanyang Technological University, Singapore",
        "rating": "",
        "confidence": "1;4;3;5",
        "correctness": "2;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/..."
    },
    {
        "id": "o6D5yTpK8w",
        "title": "Exploring Graph Pre-training for Aspect-based Sentiment Analysis",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Aspect-based Sentiment Analysis; Generative model; Graph pre-train",
        "author": "",
        "aff": "Natural Language Processing Lab, Soochow University, Suzhou, China",
        "rating": "",
        "confidence": "4;5;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/HoraceXIaoyiBao/EGP4ABSA-EMNLP2023"
    },
    {
        "id": "o7Cpy0nZZb",
        "title": "Improving Conversational Recommendation Systems via Bias Analysis and Language-Model-Enhanced Data Augmentation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Conversational Recommendation;Bias Mitigation;Generative Data;Data Augmentation",
        "author": "",
        "aff": "The University of Oklahoma, OK, USA; University College London, London, UK",
        "rating": "",
        "confidence": "2;4;3",
        "correctness": "3;2;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.0,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "o7SWorg8EM",
        "title": "S2abEL: A Dataset for Entity Linking from Scientific Tables",
        "track": "main",
        "status": "Long Main",
        "keywords": "Table Entity Linking;Machine Learning;Dataset",
        "author": "",
        "aff": "University of Michigan; Allen Institute for AI",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "2;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/allenai/S2abEL/tree/main"
    },
    {
        "id": "o9wco8bIVN",
        "title": "Unsupervised Grammatical Error Correction Rivaling Supervised Methods",
        "track": "main",
        "status": "Long Main",
        "keywords": "Unsupervised Grammatical Error Correction",
        "author": "",
        "aff": "Department of Computer Science, National University of Singapore; ByteDance",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/nusnlp/ugec"
    },
    {
        "id": "oC5e8mAKAP",
        "title": "Weakly-Supervised Learning of Visual Relations in Multimodal Pretraining",
        "track": "main",
        "status": "Long Main",
        "keywords": "vision-and-language;multimodal;pretraining;zero-shot;fine-grained",
        "author": "",
        "aff": "University of Copenhagen; Google DeepMind",
        "rating": "",
        "confidence": "4;3;3;2",
        "correctness": "4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "oEsYs3WRc3",
        "title": "Enhancing Chat Language Models by Scaling High-quality Instructional Conversations",
        "track": "main",
        "status": "Long Main",
        "keywords": "Instructional Data;Language Models",
        "author": "",
        "aff": "Department of Computer Science and Technology, Tsinghua University; The Chinese University of Hong Kong, Shenzhen; Department of Electronic Engineering, Tsinghua University",
        "rating": "",
        "confidence": "5;2;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "oEsuNpkA8d",
        "title": "Gold: A Global and Local-aware Denoising Framework for Commonsense Knowledge Graph Noise Detection",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Knowledege Graph Denoising;Commonsense Reasoning;Question Answering",
        "author": "",
        "aff": "Department of Computer Science and Engineering, HKUST, Hong Kong SAR, China",
        "rating": "",
        "confidence": "4;4;2",
        "correctness": "2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/HKUST-KnowComp/GOLD"
    },
    {
        "id": "oOKU31j9Q6",
        "title": "A Word Sense Distribution-based approach for Semantic Change Prediction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Semantic Change Detection;Temporal Semantics;Sense Embeddings",
        "author": "",
        "aff": "Cardiff University, United Kingdom.; University of Liverpool, United Kingdom.; Tokyo Metropolitan University, Japan.; University of Liverpool, United Kingdom. Amazon",
        "rating": "",
        "confidence": "5;5;3",
        "correctness": "3;1;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "oSYifZI06H",
        "title": "Generative Spoken Language Model based on continuous word-sized audio tokens",
        "track": "main",
        "status": "Long Main",
        "keywords": "spoken language models;speech generation;zerospeech;textless nlp",
        "author": "",
        "aff": "Meta AI; ENS, INRIA, INSERM, UPEC, PSL Research University; The Hebrew University of Jerusalem",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "oTtA9uIlR8",
        "title": "Detecting Syntactic Change with Pre-trained Transformer Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "BERT;Transformers;language change;syntax;syntactic change",
        "author": "",
        "aff": "Harvard University; Northeastern University",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "oVAod8GRI9",
        "title": "Image Manipulation via Multi-Hop Instructions - A New Dataset and Weakly-Supervised Neuro-Symbolic Approach",
        "track": "main",
        "status": "Long Main",
        "keywords": "Neuro-Symbolic Reasoning;Natural Language Guided Image Manipulation;Visual Question Answering;Weakly Supervised Learning",
        "author": "",
        "aff": "Indian Institute of Technology Delhi; IBM Research AI",
        "rating": "",
        "confidence": "3;5;2",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "oVJXUvXT9b",
        "title": "ASPIRO: Any-shot Structured Parsing-error-Induced ReprOmpting for Consistent Data-to-Text Generation",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Large Language Models;Data-to-Text;data disambiguation;structured data verbalisation;few-shot learning;multi-shot re-prompting",
        "author": "",
        "aff": "Faculty of Engineering, Yokohama National University; Graduate School of Engineering Science, Yokohama National University",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "github.com/vejvarm/ASPIRO"
    },
    {
        "id": "oYRlrDN6uj",
        "title": "Manifold-Preserving Transformers are Effective for Short-Long Range Encoding",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Orthogonal attention;Lipschitz;Entropic Transformer",
        "author": "",
        "aff": "IIIT Delhi, India; IIT Delhi, India",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "oYs7h2dE2e",
        "title": "CombLM: Adapting Black-Box Language Models through Small Fine-Tuned Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "black-box;language models;large language models;adaptation;domain adaptation",
        "author": "",
        "aff": "HiTZ Center, University of the Basque Country (UPV/EHU); Reka AI",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "oaNa4rNIpU",
        "title": "HistAlign: Improving Context Dependency in Language Generation by Aligning with History",
        "track": "main",
        "status": "Long Main",
        "keywords": "generation;language models;summarization;data-to-text",
        "author": "",
        "aff": "UNC Chapel Hill",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/meetdavidwan/histalign"
    },
    {
        "id": "odPKQiL2X8",
        "title": "Exploring All-In-One Knowledge Distillation Framework for Neural Machine Translation",
        "track": "main",
        "status": "Long Main",
        "keywords": "neural machine translation;efficient knowledge distillation;multi-model scenario",
        "author": "",
        "aff": "School of Informatics, Xiamen University, China; Institute of Computer Science and Technology, Soochow University, China; Xiaomi AI Lab, China",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/DeepLearnXMU/AIO-KD"
    },
    {
        "id": "oeZiXoCHgq",
        "title": "ACT-SQL: In-Context Learning for Text-to-SQL with Automatically-Generated Chain-of-Thought",
        "track": "main",
        "status": "Long Findings",
        "keywords": "text-to-SQL;large language models;in-context learning;chain of thought",
        "author": "",
        "aff": "X-LANCE Lab, Department of Computer Science and Engineering, MoE Key Lab of Artificial Intelligence, SJTU AI Institute, Shanghai Jiao Tong University, Shanghai, China",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/X-LANCE/text2sql-GPToverlap"
    },
    {
        "id": "ogh9vskMDH",
        "title": "Open-Ended Instructable Embodied Agents with Memory-Augmented Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Task Planning;Embodied AI;LLMs;Robotics",
        "author": "",
        "aff": "Carnegie Mellon University",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "helper-agent-llm.github.io",
        "github": ""
    },
    {
        "id": "ojgwuBVokp",
        "title": "Random Entity Quantization for Parameter-Efficient Compositional Knowledge Graph Representation",
        "track": "main",
        "status": "Long Main",
        "keywords": "knowledge graph;knowledge representation",
        "author": "",
        "aff": "University of Science and Technology of China; MOE Key Laboratory of Trustworthy Distributed Computing and Service, Beijing University of Posts and Telecommunications; State Key Laboratory of Communication Content Cognition",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "Not provided",
        "github": "Not provided"
    },
    {
        "id": "okV4KG4kMg",
        "title": "Can Language Models Laugh at YouTube Short-form Videos?",
        "track": "main",
        "status": "Long Main",
        "keywords": "video;humor;explanation;youtube;short-form videos;funny",
        "author": "",
        "aff": "Seoul National University; Allen Institute for Artificial Intelligence",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "5;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/dayoon-ko/ExFunTube"
    },
    {
        "id": "olEEp3Phda",
        "title": "Symbolization, Prompt, and Classification: A Framework for Implicit Speaker Identification in Novels",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Speaker Identification;Audiobook Production;Prompting",
        "author": "",
        "aff": "Ximalaya Inc., Shanghai, China; National Engineering Research Center of Speech and Language Information Processing, University of Science and Technology of China, Hefei, China",
        "rating": "",
        "confidence": "2;3;5;2",
        "correctness": "3;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "olzuxDCxMZ",
        "title": "Investigating Bias in Multilingual Language Models: Cross-Lingual Transfer of Debiasing Techniques",
        "track": "main",
        "status": "Short Main",
        "keywords": "bias mitigation;cross-lingual transferability;multilingual BERT",
        "author": "",
        "aff": "University of Applied Sciences Darmstadt; Research Centre for Information Systems Engineering (LIRIS), KU Leuven; Department of Decision Analytics and Risk, University of Southampton; IESEG School of Management, 3 Rue de la Digue, 59000 Lille, France",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "on3Wo4VODO",
        "title": "The Law and NLP: Bridging Disciplinary Disconnects",
        "track": "main",
        "status": "Short Findings",
        "keywords": "legal natural language processing;legal artificial intelligence;legal precedent retrieval;access to justice",
        "author": "",
        "aff": "MIT; ETH Zurich; MIT and Harvard Law School",
        "rating": "",
        "confidence": "5;5;1",
        "correctness": "2;5;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "onr6HrKxn0",
        "title": "DEPN: Detecting and Editing Privacy Neurons in Pretrained Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Privacy Protection;Language Model",
        "author": "",
        "aff": "Department of Computer Science and Technology, Tsinghua University, Beijing, China; School of New Media and Communication, Tianjin University, Tianjin, China; College of Intelligence and Computing, Tianjin University, Tianjin, China",
        "rating": "",
        "confidence": "4;5;2",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "oqqmjw1BD1",
        "title": "Bridging the Gap between Synthetic and Authentic Images for Multimodal Machine Translation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Multimodal Machine Translation;Text-to-image Generation",
        "author": "",
        "aff": "Beijing Language and Culture University, China; Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences (ICT/CAS); University of Chinese Academy of Sciences, Beijing, China; Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences (ICT/CAS); University of Chinese Academy of Sciences, Beijing, China; Beijing Language and Culture University, China",
        "rating": "",
        "confidence": "2;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ictnlp/SAMMT"
    },
    {
        "id": "orSVYeobMr",
        "title": "RoAST: Robustifying Language Models via Adversarial Perturbation with Selective Training",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Language model robustness;adversarial training",
        "author": "",
        "aff": "Virginia Tech; USTC; Meta AI; KAIST; HKUST",
        "rating": "",
        "confidence": "4;5;3",
        "correctness": "4;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "orefzVRWqV",
        "title": "PsyAttention: Psychological Attention Model for Personality Detection",
        "track": "main",
        "status": "Long Findings",
        "keywords": "personality detection; BigFive; PsyAttention; psychological features",
        "author": "",
        "aff": "Beijing Institute of Technology, China",
        "rating": "",
        "confidence": "4;5;2",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "oseYM8qxW4",
        "title": "Critic-Driven Decoding for Mitigating Hallucinations in Data-to-text Generation",
        "track": "main",
        "status": "Short Main",
        "keywords": "data-to-text generation;hallucinations;decoding approaches;natural language genereation",
        "author": "",
        "aff": "Charles University, Faculty of Mathematics and Physics, Institute of Formal and Applied Linguistics, Prague, Czech Republic",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/langus0/critic-aware-decoding"
    },
    {
        "id": "osox1GoFLS",
        "title": "Disentangling Extraction and Reasoning in Multi-hop Spatial Reasoning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Spatial Reasoning;Spatial Role Labeling;Disentangling Extraction and Reasoning;Pretrained Language Models;Large Language Models",
        "author": "",
        "aff": "Michigan State university",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "oueo4cEgSJ",
        "title": "Hierarchical Pretraining on Multimodal Electronic Health Records",
        "track": "main",
        "status": "Long Main",
        "keywords": "Clinical Text;Multimodal Learning;Pretraining;Electronic Health Records",
        "author": "",
        "aff": "The Pennsylvania State University; Google Research",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/XiaochenWang-PSU/MedHMP"
    },
    {
        "id": "ouiQX2XWYc",
        "title": "Watermarking LLMs with Weight Quantization",
        "track": "main",
        "status": "Long Findings",
        "keywords": "watermarking;LLM;model quantization",
        "author": "",
        "aff": "School of Computer Science, Fudan University; Shanghai AI Laboratory",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Twilight92z/Quantize-Watermark"
    },
    {
        "id": "ovkb6woHvT",
        "title": "GLEN: General-Purpose Event Detection for Thousands of Types",
        "track": "main",
        "status": "Long Main",
        "keywords": "event extraction; event detection; dataset",
        "author": "",
        "aff": "University of Illinois Urbana-Champaign; University of Colorado Boulder",
        "rating": "",
        "confidence": "5;3;4",
        "correctness": "5;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ZQS1943/GLEN.git"
    },
    {
        "id": "owc65ImkyU",
        "title": "Plan, Verify and Switch: Integrated Reasoning with Diverse X-of-Thoughts",
        "track": "main",
        "status": "Long Main",
        "keywords": "Math Reasoning;Chain-of-Thought",
        "author": "",
        "aff": "School of Computer Science, Fudan University; School of Engineering, Westlake University; Amazon AWS AI",
        "rating": "",
        "confidence": "4;5;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "oxZKOzePQX",
        "title": "SWEET - Weakly Supervised Person Name Extraction for Fighting Human Trafficking",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Information Extraction;Large Language Models;Generation;NLP Applications;Resources and Evaluation",
        "author": "",
        "aff": "University of Southern California; Mila \u2013 Quebec AI Institute; McGill University; McGill University; Mila \u2013 Quebec AI Institute; Mila \u2013 Quebec AI Institute",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "p0GyMJugcE",
        "title": "Once is Enough: A Light-Weight Cross-Attention for Fast Sentence Pair Modeling",
        "track": "main",
        "status": "Short Main",
        "keywords": "information retrieval;text matching;embedding",
        "author": "",
        "aff": "Meta AI, CA, USA; Harbin Institute of Technology, Shenzhen, China",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ysngki/MixEncoder"
    },
    {
        "id": "p2P1Q4FpEB",
        "title": "A Framework for Vision-Language Warm-up Tasks in Multimodal Dialogue Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "multimodal agent;multimodal dialogue agent;multi-turn dialogue agent;warm-up task",
        "author": "",
        "aff": "Konkuk University",
        "rating": "",
        "confidence": "3;3;3;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/BeneciaLee/VLAW-MDM"
    },
    {
        "id": "pFTBsdZ1UM",
        "title": "Indicative Summarization of Long Discussions",
        "track": "main",
        "status": "Long Main",
        "keywords": "Summarization;Computational Argumentation;Large Language Models;Social Media Discussions",
        "author": "",
        "aff": "University of Groningen; ScaDS.AI; Leipzig University",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://discussion-explorer.web.webis.de/",
        "github": "https://github.com/webis-de/EMNLP-23"
    },
    {
        "id": "pGlnFVmI4x",
        "title": "Boosting Summarization with Normalizing Flows and Aggressive Training",
        "track": "main",
        "status": "Long Main",
        "keywords": "summarization;normalizing flows;posterior collapse;aggressive training",
        "author": "",
        "aff": "University of Minnesota",
        "rating": "",
        "confidence": "4;3;2",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "pHrNmdzX2C",
        "title": "FinGPT: Large Generative Models for a Small Language",
        "track": "main",
        "status": "Long Main",
        "keywords": "large language models;gpt;causal model;finnish;transformers;monolingual language models;BLOOM",
        "author": "",
        "aff": "Hugging Face; AMD; TurkuNLP Group, University of Turku; National Library of Finland",
        "rating": "",
        "confidence": "3;2;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://turkunlp.org/gpt3-finnish",
        "github": ""
    },
    {
        "id": "pHwLbEkB0J",
        "title": "Cross-lingual Prompting: Improving Zero-shot Chain-of-Thought Reasoning across Languages",
        "track": "main",
        "status": "Long Main",
        "keywords": "Chain-of-Thought; Cross-lingual Prompting; Cross-lingual self-consistency Prompting",
        "author": "",
        "aff": "School of Computer Science and Engineering, Central South University, China; Research Center for Social Computing and Information Retrieval, Harbin Institute of Technology, China; Harbin Institute of Technology, Shenzhen, China",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "pJwlMI7AYm",
        "title": "NERetrieve: Dataset for Next Generation Named Entity Recognition and Retrieval",
        "track": "main",
        "status": "Long Findings",
        "keywords": "zero shot ner;retrieval;exhaustive search",
        "author": "",
        "aff": "Bar-Ilan University, Allen Institute for AI; Bar-Ilan University",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/katzurik/NERetrieve"
    },
    {
        "id": "pMCRGmB7Rv",
        "title": "BioPlanner: Automatic Evaluation of LLMs on Protocol Planning in Biology",
        "track": "main",
        "status": "Long Main",
        "keywords": "LLMs;GPT-4;Science;Biology;Evaluation",
        "author": "",
        "aff": "Align to Innovate, Francis Crick Institute, University of Oxford; Francis Crick Institute, Future House; Francis Crick Institute",
        "rating": "",
        "confidence": "4;3;2",
        "correctness": "3;5;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/bioplanner/bioplanner"
    },
    {
        "id": "pO7YD7PADN",
        "title": "Understanding the Effect of Model Compression on Social Bias in Large Language Models",
        "track": "main",
        "status": "Short Main",
        "keywords": "social bias;large language models;model compression;quantization;knowledge distillation",
        "author": "",
        "aff": "Language Technologies Institute, Carnegie Mellon University, Pittsburgh, PA, USA; NOV A LINCS, Universidade NOV A de Lisboa, Lisbon, Portugal; Language Technologies Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Allen Institute for Artificial Intelligence, Seattle, WA, USA",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/gsgoncalves/EMNLP2023_llm_compression_and_social_bias"
    },
    {
        "id": "pPiJykFn0K",
        "title": "Harnessing the power of LLMs: Evaluating human-AI text co-creation through the lens of news headline generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "human-centered NLP;large language model;human-AI collaboration;text summarization",
        "author": "",
        "aff": "University of Maryland, College Park; Dataminr Inc.",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "pQFgViJp77",
        "title": "The Skipped Beat: A Study of Sociopragmatic Understanding in LLMs for 64 Languages",
        "track": "main",
        "status": "Long Main",
        "keywords": "sociopragmatics;benchmark;large language models;social media;ChatGPT;multilinguality",
        "author": "",
        "aff": "Deep Learning & Natural Language Processing Group, The University of British Columbia; Department of Natural Language Processing & Department of Machine Learning, MBZUAI",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/UBC-NLP/SPARROW"
    },
    {
        "id": "pW6xXXnCQu",
        "title": "PsyCoT: Psychological Questionnaire as Powerful Chain-of-Thought for Personality Detection",
        "track": "main",
        "status": "Long Findings",
        "keywords": "personality detection;psychological questionnaire;chain-of-thought",
        "author": "",
        "aff": "School of Computer Science and Engineering, Sun Yat-sen University, China; Meta AI; Tencent AI Lab",
        "rating": "",
        "confidence": "5;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/TaoYang225/PsyCoT"
    },
    {
        "id": "pYRCUypbuq",
        "title": "Did You Mean...? Confidence-based Trade-offs in Semantic Parsing",
        "track": "main",
        "status": "Short Main",
        "keywords": "calibration;semantic parsing;safety;paraphrasing",
        "author": "",
        "aff": "UNC Chapel Hill; Johns Hopkins University",
        "rating": "",
        "confidence": "2;4;3;1",
        "correctness": "4;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "paUJOst3OE",
        "title": "MAPO: Boosting Large Language Model Performance with Model-Adaptive Prompt Optimization",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Prompts Optimization;Large Language Models;Reinforcement Learning",
        "author": "",
        "aff": "University of Montreal; Alibaba Group; Singapore Management University; Ant Group; Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University; Fudan-Aishu Cognitive Intelligence Joint Research Center; Unknown; Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University; Tencent",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "pfeod9GPAw",
        "title": "Extractive Summarization via ChatGPT for Faithful Summary Generation",
        "track": "main",
        "status": "Short Findings",
        "keywords": "summarization;large language model;faithfulness",
        "author": "",
        "aff": "IFM Lab, Department of Computer Science, University of California, Davis, CA, USA",
        "rating": "",
        "confidence": "4;3;3;4",
        "correctness": "3;3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "pgEIr2HY2E",
        "title": "Improving Summarization with Human Edits",
        "track": "main",
        "status": "Long Main",
        "keywords": "Human-aligned AI;  Unlikelihood Training;  Human Edits;  Imitation Edits;  Human Feedback",
        "author": "",
        "aff": "Abridge AI Inc.; University of Massachusetts, Amherst",
        "rating": "",
        "confidence": "4;4;2;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/seasonyao/LearnFromHumanEdit"
    },
    {
        "id": "phJtMADSdy",
        "title": "Multi-User MultiWOZ: Task-Oriented Dialogues among Multiple Users",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multiparty Dialogues;Contextual Query Rewriting;Dialogue Summarization;Dialogue Systems",
        "author": "",
        "aff": "Seoul National University, Korea; Amazon, USA",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/yohanjo/multiuser_multiwoz"
    },
    {
        "id": "pi764D1Xrx",
        "title": "Ask Language Model to Clean Your Noisy Translation Data",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Machine Translation;Large Language Models;Data Generation;Noise",
        "author": "",
        "aff": "Language Technology Lab, University of Amsterdam; Huawei Amsterdam Research Center",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://arxiv.org/abs/2310.13469",
        "github": ""
    },
    {
        "id": "piC2Dm47U1",
        "title": "Novel Relation Detection: Discovering Unknown Relation Types via Multi-Strategy Self-Supervised Learning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Relation Detection;Out-of-Scope Detection;Self-Supervised Learning",
        "author": "",
        "aff": "Zhejiang University & AZFT Joint Lab for Knowledge Engine, Zhejiang, China; Harbin Institute of Technology, Weihai, China; Department of Computer Science, The University of Manchester, UK; Platform and Content Group, Tencent, China",
        "rating": "",
        "confidence": "4;4;4;3",
        "correctness": "4;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "pk0OZZkYMP",
        "title": "Analyzing Modular Approaches for Visual Question Decomposition",
        "track": "main",
        "status": "Long Main",
        "keywords": "Vision\u2013language;visual question answering;modular;neuro-symbolic;prompting;question decomposition",
        "author": "",
        "aff": "Brown University, Department of Computer Science",
        "rating": "",
        "confidence": "2;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/brown-palm/visual-question-decomposition"
    },
    {
        "id": "pkZcvEYZEm",
        "title": "NAIL: Lexical Retrieval Indices with Efficient Non-Autoregressive Decoders",
        "track": "main",
        "status": "Long Main",
        "keywords": "information retrieval;text retrieval;large language models;non-autoregressive decoders",
        "author": "",
        "aff": "Google Deepmind",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "pnnab961TD",
        "title": "Towards Informative Open-ended Text Generation with Dynamic Knowledge Triples",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Informativeness;Knowledge graph;open-ended text generation",
        "author": "",
        "aff": "State Key Laboratory of Multimodal Artificial Intelligence Systems, Institute of Automation, CAS, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "ppaIkXurvg",
        "title": "The Troubling Emergence of Hallucination in Large Language Models - An Extensive Definition, Quantification, and Prescriptive Remediations",
        "track": "main",
        "status": "Long Main",
        "keywords": "large language models;hallucination;dataset;mitigation",
        "author": "",
        "aff": "Stanford University, USA; Amazon AI, USA; AI Institute, University of South Carolina, USA; Islamic University of Technology, Bangladesh; Christ University, India",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "ppb7gyhc7k",
        "title": "Learning Retrieval Augmentation for Personalized Dialogue Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Personalized Dialogue Generation;Retrieval-augmented Dialogue Generation;Persona-Based Dialogue Generation",
        "author": "",
        "aff": "University of Surrey; ByteDance AI Lab; Southern University of Science and Technology",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/hqsiswiliam/LAPDOG"
    },
    {
        "id": "psv7operF8",
        "title": "Adaptive Textual Label Noise Learning based on Pre-trained Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "learning with noisy labels;label noise learning;pre-trained models;text classification",
        "author": "",
        "aff": "School of Computer Science and Engineering, University of Electronic Science and Technology of China",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "ptcFuwr4YD",
        "title": "Can you Summarize my learnings? Towards Perspective-based Educational Dialogue Summarization",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Summarization;Text-generation;AI4Education",
        "author": "",
        "aff": "Veermata Jijabai Technological Institute, India; Dept. of CSE, Indian Institute of Technology Patna, India; University of Liverpool, United Kingdom",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "puLH3BEl93",
        "title": "Improving Zero-shot Reader by Reducing Distractions from Irrelevant Documents in Open-Domain Question Answering",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Open-Domain Question Answering;Large Language Model;Prompt Engineering",
        "author": "",
        "aff": "School of Computing, Korea Advanced Institute of Science and Technology",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "puMfaHb1hY",
        "title": "G-Eval: NLG Evaluation using Gpt-4 with Better Human Alignment",
        "track": "main",
        "status": "Long Main",
        "keywords": "generation evaluation",
        "author": "",
        "aff": "Microsoft Azure AI",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/nlpyang/geval"
    },
    {
        "id": "pvEkYbUPVW",
        "title": "Measuring Faithful and Plausible Visual Grounding in VQA",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Visual Grounding;Visual Question Answering",
        "author": "",
        "aff": "Cognitive Systems Lab., University of Bremen, Germany",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "2;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/dreichCSL/FPVG"
    },
    {
        "id": "pxscU6TidP",
        "title": "AutoPlan: Automatic Planning of Interactive Decision-Making Tasks With Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Planning;Decision Making;Large Language Model",
        "author": "",
        "aff": "Computer Science Department, University of California Santa Barbara; Language Technology Institute, Carnegie Mellon University",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/owaski/AutoPlan"
    },
    {
        "id": "pyjppDCsq7",
        "title": "Influence Scores at Scale for Efficient Language Data Sampling",
        "track": "main",
        "status": "Long Main",
        "keywords": "data effiency;data sampling;difficulty metrics;influence scores;pruning",
        "author": "",
        "aff": "Amazon Alexa AI",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "q09vTY1Cqh",
        "title": "RepoCoder: Repository-Level Code Completion Through Iterative Retrieval and Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "code completion;large pre-trained language model;code repository;retrieval augmented generation",
        "author": "",
        "aff": "Wuhan University; Microsoft Corporation; City University of Hong Kong",
        "rating": "",
        "confidence": "5;5;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/microsoft/CodeT/tree/main/RepoCoder"
    },
    {
        "id": "q0c1JTukWE",
        "title": "On Surgical Fine-tuning for Language Encoders",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Efficient Fine Tuning;Language Models;Language Encoders;Linguistics;Optimization;Distributional Shifts;Temporal Shifts",
        "author": "",
        "aff": "University of Maryland, College Park; Microsoft Corp.; University of Massachusetts, Amherst",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "2;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "Githubfine-tuning"
    },
    {
        "id": "q4oWkMHkQx",
        "title": "Task-Level Thinking Steps Help Large Language Models for Challenging Classification Task",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Models;Prompt Engineering;Text Classification;Chain of Thought",
        "author": "",
        "aff": "MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "q7IvUsjEkb",
        "title": "Dynamic Voting for Efficient Reasoning in Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "large language models;multi-path voting;computational resource;early exiting",
        "author": "",
        "aff": "College of Computer Science, Sichuan University",
        "rating": "",
        "confidence": "5;3;4",
        "correctness": "4;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "q88QSsc75T",
        "title": "Simultaneous Machine Translation with Tailored Reference",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Simultaneous Machine Translation;Machine Translation",
        "author": "",
        "aff": "1Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences (ICT/CAS) 2University of Chinese Academy of Sciences, Beijing, China",
        "rating": "",
        "confidence": "4;4;2;4;4;2;3",
        "correctness": "4;4;4;3;2;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.2857142857142856,
        "correctness_avg": 3.5714285714285716,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ictnlp/Tailored-Ref"
    },
    {
        "id": "q8aTDcIXnO",
        "title": "TempTabQA: Temporal Question Answering for Semi-Structured Tables",
        "track": "main",
        "status": "Long Main",
        "keywords": "Semi-structured;Temporal Reasoning;Inference;Question Answering;New Resource;New Dataset;Wikipedia InfoBox",
        "author": "",
        "aff": "University of Utah; IIT Guwahati; Bloomberg; University of Pennsylvania",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "3;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "qDspFDJEHP",
        "title": "Three Questions Concerning the Use of Large Language Models to Facilitate Mathematics Learning",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Mathematics Learning;Adaptive Feedback;Large Language Models",
        "author": "",
        "aff": "Department of Computer Science, National Yang Ming Chiao Tung University, Taiwan",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "qE5vtBMbCJ",
        "title": "LEXTREME: A Multi-Lingual and Multi-Task Benchmark for the Legal Domain",
        "track": "main",
        "status": "Long Findings",
        "keywords": "legal;nlp;benchmark;multilingual;multitask",
        "author": "",
        "aff": "University of Bern, Bern University of Applied Sciences, Stanford University; University of Bern, Bern University of Applied Sciences; University of Copenhagen; University of Zurich; Bern University of Applied Sciences; University of Bologna",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://www.huggingface.co/spaces/lextreme (Assuming this is the project link as per the abstract)",
        "github": "Not provided"
    },
    {
        "id": "qGr17uesSx",
        "title": "SimCKP: Simple Contrastive Learning of Keyphrase Representations",
        "track": "main",
        "status": "Long Findings",
        "keywords": "keyphrase prediction;contrastive learning;reranking",
        "author": "",
        "aff": "Naver Webtoon AI; KAIST AI",
        "rating": "",
        "confidence": "4;4;5;5",
        "correctness": "4;3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/brightjade/SimCKP"
    },
    {
        "id": "qJqJXpysnh",
        "title": "Handshape-Aware Sign Language Recognition: Extended Datasets and Exploration of Handshape-Inclusive Methods",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Sign language recognition;handshape",
        "author": "",
        "aff": "Johns Hopkins University",
        "rating": "",
        "confidence": "3;3;2;3",
        "correctness": "4;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Este1le/slr_handshape.git"
    },
    {
        "id": "qMSG8S7zh0",
        "title": "On Uncertainty Calibration and Selective Generation in Probabilistic Neural Summarization: A Benchmark Study",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Uncertainty;calibration;ensembles;generation;summarisation",
        "author": "",
        "aff": "Google Research",
        "rating": "",
        "confidence": "4;3;4;3",
        "correctness": "4;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "qOOQW9DcpF",
        "title": "In-context Learning for Few-shot Multimodal Named Entity Recognition",
        "track": "main",
        "status": "Long Findings",
        "keywords": "In-context Learning;Few-shot Multimodal Named Entity Recognition",
        "author": "",
        "aff": "Harbin Institute of Technology, Shenzhen, China; Guangdong Provincial Key Laboratory of Novel Security Intelligence Technologies; Peng Cheng Laboratory, Shenzhen, China; SIAT, Chinese Academy of Science, Shenzhen, China; Harbin Institute of Technology, Shenzhen, China; Guangdong Provincial Key Laboratory of Novel Security Intelligence Technologies; Research Center for SCIR, Harbin Institute of Technology, Harbin, China; Harbin Institute of Technology, Shenzhen, China; Guangdong Provincial Key Laboratory of Novel Security Intelligence Technologies; The Chinese University of Hong Kong, Hong Kong, China; The Chinese University of Hong Kong, Hong Kong, China",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "2;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "qPIV6XQizX",
        "title": "A Reference-free Segmentation Quality Index (SegReFree)",
        "track": "main",
        "status": "Long Findings",
        "keywords": "segmentation;metrics",
        "author": "",
        "aff": "Michigan Technological University / 1400 Townsend Drive, Houghton, Michigan, United States of America",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/evan-person/reference_free_segmentation_metric"
    },
    {
        "id": "qPfQq8c3kv",
        "title": "High-quality argumentative information in low resources approaches improve counter-narrative generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "counter-narratives;argument mining;finetuning",
        "author": "",
        "aff": "Facultad de Filosof\u00eda, Universidad Nacional de C\u00f3rdoba, Argentina; Departamento de Computaci\u00f3n, Universidad de Buenos Aires, Argentina; Consejo Nacional de Investigaciones Cient\u00edficas y T\u00e9cnicas, Argentina; Facultad de Matem\u00e1tica, Astronom\u00eda y F\u00edsica, Universidad Nacional de C\u00f3rdoba, Argentina; Artificial Intelligence Research Institute (IIIA-CSIC), Barcelona, Spain",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "qRbhKhqp0b",
        "title": "The Past, Present and Better Future of Feedback Learning in Large Language Models for Subjective Human Preferences and Values",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large language models;survey;review;human feedback;human preference;human values;alignment",
        "author": "",
        "aff": "Bocconi University; University of Oxford; University of Oxford, Meedan",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "qRg3AxBDnN",
        "title": "Learning the Visualness of Text Using Large Vision-Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "text visualness;vision-language models;multimodal learning",
        "author": "",
        "aff": "Georgia Institute of Technology; Adobe Research",
        "rating": "",
        "confidence": "4;3;3;3",
        "correctness": "4;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "qS1ip2dGH0",
        "title": "The Shifted and The Overlooked: A Task-oriented Investigation of User-GPT Interactions",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large language models;Real-world NLP applications;User-GPT interaction analysis",
        "author": "",
        "aff": "University of Illinois Urbana-Champaign; Microsoft Azure AI",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://sharegpt.com/",
        "github": ""
    },
    {
        "id": "qT4bw58Yl2",
        "title": "MProto: Multi-Prototype Network with Denoised Optimal Transport for Distantly Supervised Named Entity Recognition",
        "track": "main",
        "status": "Long Main",
        "keywords": "Information Extraction;Named Entity Recognition;Distant Supervision",
        "author": "",
        "aff": "College of Computer Science and Technology, Zhejiang University, China; Hikvision Research Institute",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/XiPotatonium/mproto"
    },
    {
        "id": "qWbCkbBN1P",
        "title": "Reducing Spurious Correlations in Aspect-based Sentiment Analysis with Explanation from Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "aspect-based sentiment analysis;spurious correlations;large language models",
        "author": "",
        "aff": "Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences; Harbin Institute of Technology, Shenzhen, China; The Chinese University of Hong Kong",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "qZwsO1Qi3V",
        "title": "Syntactic Substitutability as Unsupervised Dependency Syntax",
        "track": "main",
        "status": "Long Main",
        "keywords": "unsupervised dependency parsing;syntax;syntactic probing;linguistically informed",
        "author": "",
        "aff": "Stanford University; Mila \u2013 Quebec AI Institute and McGill University, Facebook CIFAR AI Chair",
        "rating": "",
        "confidence": "3;5;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/McGill-NLP/syntactic-substitutability"
    },
    {
        "id": "qae0FlfrG6",
        "title": "Does the Correctness of Factual Knowledge Matter for Factual Knowledge-Enhanced Pre-trained Language Models?",
        "track": "main",
        "status": "Long Main",
        "keywords": "factual knowledge;language model;knowledge-enhanced",
        "author": "",
        "aff": "Chinese Information Processing Laboratory, Institute of Software, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, Beijing, China; Chinese Information Processing Laboratory, Institute of Software, Chinese Academy of Sciences, Beijing, China and University of Chinese Academy of Sciences, Beijing, China; Chinese Information Processing Laboratory, Institute of Software, Chinese Academy of Sciences, Beijing, China and State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, Beijing, China",
        "rating": "",
        "confidence": "4;1;2",
        "correctness": "4;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "qegD54EWAl",
        "title": "Hiding in Plain Sight: Tweets with Hate Speech Masked by Homoglyphs",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Homoglyphs;Dataset;Hate Speech Detection;Twitter",
        "author": "",
        "aff": "University of Arizona, Tucson, AZ, USA",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "3;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/pcoopercoder/Offensive-Tweets-with-Homoglyphs-OTH-Dataset2021"
    },
    {
        "id": "qhwYFIrSm7",
        "title": "A Diachronic Analysis of Paradigm Shifts in NLP Research: When, How, and Why?",
        "track": "main",
        "status": "Long Main",
        "keywords": "Scholarly Document Processing;NLP Scientometrics",
        "author": "",
        "aff": "IBM Research Europe, Ireland; National Research Council Canada; Ubiquitous Knowledge Processing Lab (UKP Lab), Department of Computer Science and Hessian Center for AI (hessian.AI)",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/UKPLab/CausalNLPTrends"
    },
    {
        "id": "qiV0mvkVyq",
        "title": "PROSE: A Pronoun Omission Solution for Chinese-English Spoken Language Translation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Chinese-English Spoken Language Translation;Zero-Pronoun;Mention-Aware Semantic Augmentation",
        "author": "",
        "aff": "Huawei IT Innovation and Research Center",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "qlCtkvgQJH",
        "title": "LogiCoT: Logical Chain-of-Thought Instruction Tuning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "instruction tuning;chain-of-thought;large language model;logical reasoning;GPT-4",
        "author": "",
        "aff": "Westlake University; Alibaba Group; Nanyang Technological University; Zhejiang University; Tencent AI lab",
        "rating": "",
        "confidence": "5;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "qlwXv0oHJD",
        "title": "Towards Noise-Tolerant Speech-Referring Video Object Segmentation: Bridging Speech and Text",
        "track": "main",
        "status": "Long Main",
        "keywords": "Noisy Speech;Speech-Referring Video Object Segmentation",
        "author": "",
        "aff": "Ohio State University; Carnegie Mellon University, Mohamed bin Zayed University of Artificial Intelligence; Carnegie Mellon University; University of Michigan Ann Arbor; Microsoft",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "qnHB2SMQLA",
        "title": "Take a Closer Look at Multilinguality! Improve Multilingual Pre-Training Using Monolingual Corpora Only",
        "track": "main",
        "status": "Long Findings",
        "keywords": "multilinguality;mutlilingual pre-training",
        "author": "",
        "aff": "Institute of Automation, Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; Wuhan AI Research, Wuhan, China; Institute of Automation, Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China",
        "rating": "",
        "confidence": "5;5;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/JinliangLu96/Self-Improving-Multilingual-PT"
    },
    {
        "id": "qnO9IRNA9d",
        "title": "Instructed Language Models with Retrievers Are Powerful Entity Linkers",
        "track": "main",
        "status": "Long Main",
        "keywords": "Knowledge Grounding;Entity Linking;Generative Model;Large Language Model",
        "author": "",
        "aff": "Microsoft STCA; Rice University",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "qo17ZiVnH2",
        "title": "Filling the Image Information Gap for VQA: Prompting Large Language Models to Proactively Ask Questions",
        "track": "main",
        "status": "Long Findings",
        "keywords": "visual question answering;knowledge reasoning;in-context learning",
        "author": "",
        "aff": "Department of Computer Science and Technology, Tsinghua University, Beijing, China; Institute for AI Industry Research (AIR), Tsinghua University, Beijing, China",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/THUNLP-MT/FIIG"
    },
    {
        "id": "qq6ctdUwCX",
        "title": "Loose lips sink ships: Mitigating Length Bias in Reinforcement Learning from Human Feedback",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Alignment;Large Language Model;Debias",
        "author": "",
        "aff": "School of Computer Science, Fudan University; School of Computer Science, Fudan University; International Human Phenome Institutes (Shanghai), Shanghai, China; Institute of Modern Languages and Linguistics, Fudan University",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "qtZI5YDe5d",
        "title": "UReader: Universal OCR-free Visually-situated Language Understanding with Multimodal Large Language Model",
        "track": "main",
        "status": "Long Findings",
        "keywords": "OCR-free;visually-situated language understanding;multimodal large language model",
        "author": "",
        "aff": "East China Normal University; Renmin University of China; DAMO Academy, Alibaba Group",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;2;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/LukeForeverYoung/UReader"
    },
    {
        "id": "qvftjm8DNC",
        "title": "The PEACE-Reviews dataset: Modeling Cognitive Appraisals in Emotion Text Analysis",
        "track": "main",
        "status": "Long Findings",
        "keywords": "cognitive appraisals;emotions;language modeling;computational social science",
        "author": "",
        "aff": "NUS Centre for Trusted Internet and Community, National University of Singapore; Institute of Data Science, National University of Singapore",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/GerardYeo/PEACE-Reviews.git"
    },
    {
        "id": "qyvabTsnWg",
        "title": "Document-level Relationship Extraction by Bidirectional Constraints of Beta Rules",
        "track": "main",
        "status": "Long Main",
        "keywords": "Document-level Relation Extraction;Logical Consistency;Beta Distribution;Bidirectional Constraints",
        "author": "",
        "aff": "School of New Media and Communication, Tianjin University; College of Intelligence and Computing, Tianjin University",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Louisliu1999/BCBR"
    },
    {
        "id": "qzYtTabDPY",
        "title": "Revisiting the Optimality of Word Lengths",
        "track": "main",
        "status": "Long Main",
        "keywords": "word length;uniform information density;zipf;law of abbreviation",
        "author": "",
        "aff": "University of Cambridge, ETH Z\u00fcrich; ETH Z\u00fcrich; University of Texas, Austin",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/tpimentelms/optimality-of-word-lengths"
    },
    {
        "id": "r2z3qPltxs",
        "title": "Counter Turing Test (CT2): AI-Generated Text Detection is Not as Easy as You May Think - Introducing AI Detectability Index (ADI)",
        "track": "main",
        "status": "Long Main",
        "keywords": "AI-generated text detection",
        "author": "",
        "aff": "IIIT Delhi, India; NIT Silchar, India; AI Institute, University of South Carolina, USA; BITS Mesra, India; Stanford University, USA; IUT, Bangladesh",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;5;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.666666666666667,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "r3utB5u4zP",
        "title": "Generating and Evaluating Tests for K-12 Students with Language Model Simulations: A Case Study on Sentence Reading Efficiency",
        "track": "main",
        "status": "Long Main",
        "keywords": "language model;student test generation;psychometrics",
        "author": "",
        "aff": "Stanford University",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "r65IWQmsHF",
        "title": "Understanding HTML with Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "html understanding;web navigation;large language models;semantic classification;description generation",
        "author": "",
        "aff": "Google DeepMind",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://sites.google.com/view/llm4html/home",
        "github": ""
    },
    {
        "id": "rBfVlElyVW",
        "title": "MAGNIFICo: Evaluating the In-Context Learning Ability of Large Language Models to Generalize to Novel Interpretations",
        "track": "main",
        "status": "Long Main",
        "keywords": "Benchmarking LLMs;Compositional Generalization;In-Context Learning",
        "author": "",
        "aff": "Mila and McGill University; University of Oxford; Mila and McGill University, Facebook CIFAR AI Chair, Canada CIFAR AI Chair",
        "rating": "",
        "confidence": "4;3;4;3",
        "correctness": "4;4;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 4.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "rBrzSCruKl",
        "title": "Promoting Topic Coherence and Inter-Document Consorts in Multi-Document Summarization via Simplicial Complex and Sheaf Graph",
        "track": "main",
        "status": "Long Main",
        "keywords": "multi document summarization;abstractive summarization",
        "author": "",
        "aff": "Microsoft Research, India; IIT Delhi, India; IIIT-Delhi, India",
        "rating": "",
        "confidence": "3;5;1",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/LCS2-IIITD/FABRIC"
    },
    {
        "id": "rDuv0LGf3T",
        "title": "Prompting ChatGPT in MNER: Enhanced Multimodal Named Entity Recognition with Auxiliary Refined Knowledge",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multimodal Named Entity Recognition;Information Extraction;Large Language Model",
        "author": "",
        "aff": "School of New Media and Communication, Tianjin University; Tianjin University of Science and Technology; College of Mathematics, Taiyuan University of Technology; University of Copenhagen; College of Intelligence and Computing, Tianjin University",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/JinYuanLi0012/PGIM"
    },
    {
        "id": "rG3QZA7JXV",
        "title": "CRT-QA: A Dataset of Complex Reasoning Question Answering over Tabular Data",
        "track": "main",
        "status": "Long Main",
        "keywords": "Table QA;Table analysis;Large language model reasoning;Large language model with tool-use",
        "author": "",
        "aff": "Microsoft Research Asia; Xi\u2019an Jiaotong University; Dartmouth College",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/zzh-SJTU/CRT-QA"
    },
    {
        "id": "rHjZFQvj9k",
        "title": "Norm of Word Embedding Encodes Information Gain",
        "track": "main",
        "status": "Long Main",
        "keywords": "Word embedding;Euclidean norm;Skip-gram with Negative Sampling;Softmax function;Kullback-Leibler divergence;Information geometry;Exponential family of probability distributions",
        "author": "",
        "aff": "Tohoku University, RIKEN AIP; Kyoto University, RIKEN AIP",
        "rating": "",
        "confidence": "3;4;2",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "rI7ebWPRLr",
        "title": "Efficient Long-Range Transformers: You Need to Attend More, but Not Necessarily at Every Layer",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Long-Range Transformer;Attention Mechanism;Mixed Attention Span",
        "author": "",
        "aff": "Amazon Web Service; Georgia Institute of Technology",
        "rating": "",
        "confidence": "5;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "rIc17Kziiq",
        "title": "Larger Probes Tell a Different Story: Extending Psycholinguistic Datasets Via In-Context Learning",
        "track": "main",
        "status": "Short Main",
        "keywords": "Psycholinguistic datasets;Negation;Role Reversal;Larger Dataset;ICL",
        "author": "",
        "aff": "Department of Computer Science, University of Massachusetts Lowell",
        "rating": "",
        "confidence": "5;5;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/text-machine-lab/extending_psycholinguistic_dataset"
    },
    {
        "id": "rJXYb7D4ck",
        "title": "Tagging-Assisted Generation Model with Encoder and Decoder Supervision for Aspect Sentiment Triplet Extraction",
        "track": "main",
        "status": "Long Main",
        "keywords": "ABSA; ASTE; sentiment analysis; generation seq2seq model; sequence tagging;  semantic alignment",
        "author": "",
        "aff": "School of Computer Science and Engineering, Sun Yat-Sen University; Key Laboratory of Machine Intelligence and Advanced Computing (SYSU), Ministry of Education, China",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "rJhk7Fpnvh",
        "title": "Sources of Hallucination by Large Language Models on Inference Tasks",
        "track": "main",
        "status": "Long Findings",
        "keywords": "LLM;LM;language model;hallucination;natural language inference;NLI;entailment;directional;attestation;relative frequency;predicate",
        "author": "",
        "aff": "Macquarie University; University of Edinburgh; Google Research",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Teddy-Li/LLM-NLI-Analysis"
    },
    {
        "id": "rKjzOYrXKd",
        "title": "GRENADE: Graph-Centric Language Model for Self-Supervised Representation Learning on Text-Attributed Graphs",
        "track": "main",
        "status": "Long Findings",
        "keywords": "textual attributed graph;text rich network;representation learning;graph neural network;language model",
        "author": "",
        "aff": "Worcester Polytechnic Institute; Northwestern University",
        "rating": "",
        "confidence": "2;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/bigheiniu/GRENADE"
    },
    {
        "id": "rLx2eDYcMK",
        "title": "VivesDebate-Speech: A Corpus of Spoken Argumentation to Leverage Audio Features for Argument Mining",
        "track": "main",
        "status": "Short Main",
        "keywords": "Argument Mining;Argument Segmentation;Argument Classification;Speech Corpus",
        "author": "",
        "aff": "VRAIN-MLLP, Universitat Polit\u00e8cnica de Val\u00e8ncia, 46022 Val\u00e8ncia, Spain; Centre for Argument Technology, University of Dundee, Dundee DD1 4HN, United Kingdom",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "rMLnxh4oT5",
        "title": "CASE: Commonsense-Augmented Score with an Expanded Answer Space",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Commonsense Reasoning;Question Answering;Language Model;Zero-shot",
        "author": "",
        "aff": "Vector Institute for AI; University of British Columbia",
        "rating": "",
        "confidence": "4;4;3;3",
        "correctness": "4;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "rQJAaOh4nr",
        "title": "Self-prompted Chain-of-Thought on Large Language Models for Open-domain Multi-hop Reasoning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Chain-of-Thought;Large Language Models;In-context-Learning;Open-domain question-answering;Multi-hop question-answering",
        "author": "",
        "aff": "SJTU-Paris Elite Institute of Technology, Shanghai Jiao Tong University; Department of Computer Science and Engineering, Shanghai Jiao Tong University",
        "rating": "",
        "confidence": "2;1;5",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "rRwPzcSFeL",
        "title": "TrueTeacher: Learning Factual Consistency Evaluation with Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "factuality;attribution;consistency;hallucinations",
        "author": "",
        "aff": "Technion - Israel Institute of Technology; Google Research",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/google-research/google-research/tree/master/true_teacher"
    },
    {
        "id": "rTAIgZe3wo",
        "title": "ACTOR: Active Learning with Annotator-specific Classification Heads to Embrace Human Label Variation",
        "track": "main",
        "status": "Short Main",
        "keywords": "Active Learning;Human Label Variation;Multi-task Learning",
        "author": "",
        "aff": "MaiNLP, Center for Information and Language Processing, LMU Munich, Germany; Munich Center for Machine Learning (MCML), Munich, Germany",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "rVsnAmxnR9",
        "title": "Ask To The Point: Open-Domain Entity-Centric Question Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Question Generation;Entity-Centric;Multi-Task",
        "author": "",
        "aff": "University of Illinois at Urbana-Champaign, USA",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/liuyuxiang512/ECQG"
    },
    {
        "id": "rXn9WO4M2p",
        "title": "Self-Influence Guided Data Reweighting for Language Model Pre-training",
        "track": "main",
        "status": "Long Main",
        "keywords": "pre-training;multilingual pretraining;self-influence;language models;data reweighting",
        "author": "",
        "aff": "Google Research India; Google Deepmind; Mila \u2013 Quebec AI Institute",
        "rating": "",
        "confidence": "5;5;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "rbaK24KnIO",
        "title": "Combining Denoising Autoencoders with Contrastive Learning to fine-tune Transformer Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "transfer learning;contrastive learning;denoising autoencoders;NLU",
        "author": "",
        "aff": "Huawei Ireland Research Center, Dublin, Ireland; Huawei London Research Centre, London, UK",
        "rating": "",
        "confidence": "3;2;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "rd0C4kD0o4",
        "title": "Efficient Latent Variable Modeling for Knowledge-Grounded Dialogue Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "knowledge-grounded dialogue generation",
        "author": "",
        "aff": "Korea University; Georgia Institute of Technology; Kakao Brain; KRAFTON; KAIST",
        "rating": "",
        "confidence": "4;2;4;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "rgKfPzAF2j",
        "title": "Byte Pair Encoding for Symbolic Music",
        "track": "main",
        "status": "Long Main",
        "keywords": "Symbolic music;BPE;Music generation;MIR",
        "author": "",
        "aff": "University of Angers, LERIA, 49000 Angers, France; Sorbonne University, CNRS, LIP6, F-75005 Paris; ESEO, ERIS, 49100 Angers, France",
        "rating": "",
        "confidence": "3;4;2;3",
        "correctness": "4;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://Natooz.github.io/BPE-Symbolic-Music/",
        "github": "https://github.com/Natooz/bpe-symbolic-music"
    },
    {
        "id": "rgos321qpD",
        "title": "PEFTDebias : Capturing debiasing information using PEFTs",
        "track": "main",
        "status": "Short Main",
        "keywords": "paramter-efficient finetuning (PEFT);bias mitigation;debias;bias;gender;group;language model;debiasing;LoRA debias;prompt debias;adapter debias",
        "author": "",
        "aff": "Language Technologies Institute, Carnegie Mellon University, Pittsburgh, PA",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/sumit-agrwl/peft-debias"
    },
    {
        "id": "rhGh8jLOPd",
        "title": "MaXM: Towards Multilingual Visual Question Answering",
        "track": "main",
        "status": "Long Findings",
        "keywords": "VQA;multilinguality",
        "author": "",
        "aff": "Google Research",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/google-research-datasets/maxm"
    },
    {
        "id": "rjDaTBwEBX",
        "title": "In What Languages are Generative Language Models the Most Formal? Analyzing Formality Distribution across Languages",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multilingual language models;language models;formality bias analysis;bias analysis in language models",
        "author": "",
        "aff": "North South University; Sorbonne Universit\u00e9; Banco de Cr\u00e9dito e Inversiones; Huawei T\u00fcrkiye R&D Center",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "rjd8AqRyW3",
        "title": "OpenAsp: A Benchmark for Multi-document Open Aspect-based Summarization",
        "track": "main",
        "status": "Long Main",
        "keywords": "Aspect-based Summarization;Datasets;Annotation;Multi-document Summarization",
        "author": "",
        "aff": "Amazon; One AI; Bar-Ilan University",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "rmhSMGjWPp",
        "title": "Multi-label and Multi-target Sampling of Machine Annotation for Computational Stance Detection",
        "track": "main",
        "status": "Short Findings",
        "keywords": "stance detection;machine annotation;computational social science",
        "author": "",
        "aff": "DSO National Laboratories, Singapore; Institute for Infocomm Research (I2R), A*STAR, Singapore",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "rn7Fn3CV7b",
        "title": "CoVariance-based Causal Debiasing for Entity and Relation Extraction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Causal Debiasing;Entity and Relation Extraction;Covariance Optimizing;Variance Optimizing",
        "author": "",
        "aff": "Singapore Management University; University of South China",
        "rating": "",
        "confidence": "4;2;4;4",
        "correctness": "3;4;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/HomuraT/OVO"
    },
    {
        "id": "rq4UfmpRA9",
        "title": "Democratizing Reasoning Ability: Tailored Learning from Large Language Model",
        "track": "main",
        "status": "Long Main",
        "keywords": "large language model;reasoning;distillation;open-source",
        "author": "",
        "aff": "School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China; Peking University; Microsoft",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Raibows/Learn-to-Reason"
    },
    {
        "id": "rs78DlnUB8",
        "title": "Complexity-Guided Curriculum Learning for Text Graphs",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Curriculum Learning;Graph Neural Network;Text Graph",
        "author": "",
        "aff": "Department of Computer Science, University of Massachusetts Lowell",
        "rating": "",
        "confidence": "3;3;2",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "rwHOXIBFwq",
        "title": "Combining Counting Processes and Classification Improves a Stopping Rule for Technology Assisted Review",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Technology assisted review;TAR;total recall;stopping criteria;counting processes;classification",
        "author": "",
        "aff": "Department of Computer Science, University of Sheffield, United Kingdom; Information Systems Department, Princess Nourah bint Abdulrahman University, Saudi Arabia; Department of Computer Science, University of Sheffield, United Kingdom",
        "rating": "",
        "confidence": "2;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ReemBinHezam/TAR_Stopping_CP_CLF"
    },
    {
        "id": "rwcLHjtUmn",
        "title": "A Suite of Generative Tasks for Multi-Level Multimodal Webpage Understanding",
        "track": "main",
        "status": "Long Main",
        "keywords": "Webpage Understanding;Multimodal Data;Text Generation",
        "author": "",
        "aff": "Boston University; Google; Boston University, FAIR",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "5;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.666666666666667,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/google-research-datasets/wit/blob/main/wikiweb2m.md"
    },
    {
        "id": "rwcTxeSsVI",
        "title": "For Generated Text, Is NLI-Neutral Text the Best Text?",
        "track": "main",
        "status": "Short Findings",
        "keywords": "generation;natural language inference",
        "author": "",
        "aff": "Department of Computer Science, The University of Texas at Austin; Department of Linguistics, The University of Texas at Austin",
        "rating": "",
        "confidence": "2;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Michael-Mersinias/nli_text_generation"
    },
    {
        "id": "rwpv2kCt4X",
        "title": "Accuracy is not enough: Evaluating Personalization in Summarizers",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Personalized Summarization Evaluation;Meta Evaluation;Automated Accuracy Metrics",
        "author": "",
        "aff": "Indian Institute of Technology, Delhi, India; KDM Lab, Dhirubhai Ambani Institute of Information & Communication Technology, India",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "rzW3RouIXc",
        "title": "Query-as-context Pre-training for Dense Passage Retrieval",
        "track": "main",
        "status": "Long Main",
        "keywords": "Query prediction;Dense passage retrieval;Pre-training",
        "author": "",
        "aff": "Du Xiaoman Financial; Institute of Information Engineering, Chinese Academy of Sciences; School of Cyber Security, University of Chinese Academy of Sciences; Kuaishou Technology",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "rzdqmUFVnv",
        "title": "Multi-Granularity Information Interaction Framework for Incomplete Utterance Rewriting",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Incomplete Utterance Rewriting;Information Interaction;Multi-Granularity",
        "author": "",
        "aff": "Wangxuan Institute of Computer Technology, Peking University and Institute for Artificial Intelligence, Peking University; Wangxuan Institute of Computer Technology, Peking University and Institute for Artificial Intelligence, Peking University and Ant Group; Ant Group",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "s1Lrw1HTcT",
        "title": "ChatGPT to Replace Crowdsourcing of Paraphrases for Intent Classification: Higher Diversity and Comparable Model Robustness",
        "track": "main",
        "status": "Long Main",
        "keywords": "natural language generation;paraphrase generation;crowdsourcing;large language models;intent classification;text diversity",
        "author": "",
        "aff": "Kempelen Institute of Intelligent Technologies, Bratislava, Slovakia; Faculty of Information Technology, Brno University of Technology, Brno, Czechia; University of Pittsburgh, Pittsburgh, USA",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "s4xIeYimGQ",
        "title": "Large Language Models are Better Reasoners with Self-Verification",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large Language Models;Self-verification;Reasoning Ability;Chain of Thought;Backward Verification",
        "author": "",
        "aff": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "s7Vh8OIIm6",
        "title": "Hybrid Inverted Index Is a Robust Accelerator for Dense Retrieval",
        "track": "main",
        "status": "Long Main",
        "keywords": "Dense Retrieval;ANN Index;Inverted Index",
        "author": "",
        "aff": "Microsoft Research Asia; Gaoling School of Artificial Intelligence, Renmin University of China; Beijing Academy of Artificial Intelligence",
        "rating": "",
        "confidence": "2;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/namespace-Pt/Adon/tree/HI2"
    },
    {
        "id": "sCtJmxhvJe",
        "title": "\"Fifty Shades of Bias\": Normative Ratings of Gender Bias in GPT Generated English Text",
        "track": "main",
        "status": "Long Main",
        "keywords": "Gender bias;NLP;LLMs;GPT",
        "author": "",
        "aff": "Microsoft Research India; Carnegie Mellon University; School of Information, University of Michigan",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "sCu26OfxxZ",
        "title": "INA: An Integrative Approach for Enhancing Negotiation Strategies with Reward-Based Dialogue Agent",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Negotiation;Dialogue Agent;Prompting",
        "author": "",
        "aff": "Accenture Labs, Bangalore, India; Department of Computer Science and Engineering, Indian Institute of Technology Patna, India",
        "rating": "",
        "confidence": "5;2;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://www.iitp.ac.in/~ai-nlp-ml/resources.html#INA",
        "github": "https://github.com/zishan-ai/neg"
    },
    {
        "id": "sCxiD2Rx4l",
        "title": "DUnE: Dataset for Unified Editing",
        "track": "main",
        "status": "Long Main",
        "keywords": "Model Editing;Editing Large Language Models;Learning from Human Feedback",
        "author": "",
        "aff": "Boston University; Yale University; Monash University Indonesia",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "sEvU6r8e7N",
        "title": "RefGPT: Dialogue Generation of GPT, by GPT, and for GPT",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Dialogue Generation;GPT;Model Hallucination;LLM",
        "author": "",
        "aff": "Hong Kong Polytechnic University; Shanghai Jiao Tong University; Beijing University of Posts and Telecommunications",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/mutonix/RefGPT"
    },
    {
        "id": "sFtyaTTtap",
        "title": "Towards Example-Based NMT with Multi-Levenshtein Transformers",
        "track": "main",
        "status": "Long Main",
        "keywords": "Neural Machine Translation;Non Autoregressive Transformers;Levenshtein Transformer;Translation Memory;Computer Assisted Translation",
        "author": "",
        "aff": "Systran, 5 rue Feydeau, F-75002 Paris, France; Sorbonne Universit\u00e9, CNRS, ISIR, F-75005 Paris, France",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "5;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "sGrYJQZMQo",
        "title": "Active Instruction Tuning: Improving Cross-Task Generalization by Training on Prompt Sensitive Tasks",
        "track": "main",
        "status": "Long Main",
        "keywords": "Instruction Tuning;Large Language Models;Active Learning",
        "author": "",
        "aff": "University of California, Los Angeles",
        "rating": "",
        "confidence": "4;3;4;5",
        "correctness": "4;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/PlusLabNLP/Active-IT"
    },
    {
        "id": "sJUCMYtgIK",
        "title": "Augmenting Zero-Shot Dense Retrievers with Plug-in Mixture-of-Memories",
        "track": "main",
        "status": "Long Main",
        "keywords": "Retrieval Augmented Language Model;Zero-shot Dense Retrieval;Mixture of Memory",
        "author": "",
        "aff": "University of Illinois Urbana-Champaign; Carnegie Mellon University; Microsoft Research; Spotify",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/gesy17/MoMA"
    },
    {
        "id": "sJb43ykK3o",
        "title": "RegaVAE: A Retrieval-Augmented Gaussian Mixture Variational Auto-Encoder for Language Modeling",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Retrieval-Augmented Language Model;Hallucination;Variational Auto-Encoder",
        "author": "",
        "aff": "Institute of Computing Technology, Chinese Academy of Sciences; University of Chinese Academy of Sciences",
        "rating": "",
        "confidence": "5;2;3",
        "correctness": "2;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/TrustedLLM/RegaVAEModelFuture"
    },
    {
        "id": "sKdsBUAnts",
        "title": "Building Persona Consistent Dialogue Agents with Offline Reinforcement Learning",
        "track": "main",
        "status": "Long Main",
        "keywords": "NLP;persona consistent dialogue;offline reinforcement learning",
        "author": "",
        "aff": "Columbia University, NY",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "sM9NTLjsUh",
        "title": "Failures Pave the Way: Enhancing Large Language Models through Tuning-free Rule Accumulation",
        "track": "main",
        "status": "Long Main",
        "keywords": "large langauge models;zero-shot learning;prompt",
        "author": "",
        "aff": "Institute for AI Industry Research (AIR), Tsinghua University, Beijing, China; Shanghai Artificial Intelligence Laboratory, Shanghai, China; Dept. of Comp. Sci. & Tech., Institute for AI, Tsinghua University, Beijing, China",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "sOTbFCUrDj",
        "title": "A Generation-based Deductive Method for Math Word Problems",
        "track": "main",
        "status": "Long Main",
        "keywords": "math word problem;natural language processing",
        "author": "",
        "aff": "School of Information, Renmin University of China, Beijing, China; Key Laboratory of Data Engineering and Knowledge Engineering, MOE, China; School of Information, Renmin University of China, Beijing, China; Engineering Research Center of Database and Business Intelligence, MOE, China",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/hyx1999/GeDe"
    },
    {
        "id": "sOngusZCsN",
        "title": "Knowledge-Augmented Language Model Verification",
        "track": "main",
        "status": "Long Main",
        "keywords": "Knowledge-Augmented Language Models;Verification",
        "author": "",
        "aff": "KAIST",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/JinheonBaek/KALMV"
    },
    {
        "id": "sPB354cbmL",
        "title": "Improved Training of Deep Text Clustering",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Text Clustering;Deep Clustering",
        "author": "",
        "aff": "Information Research Center of Military Science, PLA Academy of Military Science",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 1.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/yangzonghao1024/DCGLU"
    },
    {
        "id": "sPpft5DQJN",
        "title": "Interpreting Embedding Spaces by Conceptualization",
        "track": "main",
        "status": "Long Main",
        "keywords": "Interpretability;knowledge tracing",
        "author": "",
        "aff": "The Henry and Marilyn Taub Faculty of Computer Science, Technion \u2013 Israel Institute of Technology",
        "rating": "",
        "confidence": "3;5;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/adiSimhi/Interpreting-Embedding-Spaces-by-Conceptualization"
    },
    {
        "id": "sQ1iTreITk",
        "title": "Density-Aware Prototypical Network for Few-Shot Relation Classification",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Few-shot relation classification;None-of-the-above challenge;Density estimation",
        "author": "",
        "aff": "School of Journalism and Communication, Nankai University; College of Computer Science, Nankai University; College of Software, Nankai University; Tencent AI Lab",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Pisces-29/DProto"
    },
    {
        "id": "sRHVpB7GE6",
        "title": "Fast and Accurate Factual Inconsistency Detection Over Long Documents",
        "track": "main",
        "status": "Long Main",
        "keywords": "Hallucination detection;Inconsistency detection;hallucination;automatic evaluation;metric;long document;efficient;fast;accurate;long;natural language generation;task agnostic;nlp;nlg",
        "author": "",
        "aff": "ASAPP; Abstractive Health",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/asappresearch/scale-score"
    },
    {
        "id": "sS02W7Sloj",
        "title": "Diversify Question Generation with Retrieval-Augmented Style Transfer",
        "track": "main",
        "status": "Long Main",
        "keywords": "Question Generation; Retrieval Augmented Generation;Style Transfer",
        "author": "",
        "aff": "Alibaba Group; State Key Laboratory for Novel Software Technology, Nanjing University, China",
        "rating": "",
        "confidence": "3;2;1",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/gouqi666/RAST"
    },
    {
        "id": "sTeoqvTH2j",
        "title": "HiCL: Hierarchical Contrastive Learning of Unsupervised Sentence Embeddings",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Contrastive Learning;Semantic Textual Similarity;Hierarchical Training",
        "author": "",
        "aff": "University of Wisconsin, Madison; University of Michigan, Ann Arbor",
        "rating": "",
        "confidence": "3;3;4;2",
        "correctness": "2;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/CSerxy/HiCL"
    },
    {
        "id": "sVSeGRCZT8",
        "title": "Three Stream Based Multi-level Event Contrastive Learning for Text-Video Event Extraction",
        "track": "main",
        "status": "Long Main",
        "keywords": "Event extraction; Multimodal",
        "author": "",
        "aff": "School of Computer Science and Engineering, Southeast University, Nanjing, China; College of Artificial Intelligence and Automation, Hohai University, Nanjing, China",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "sX4yqbYlRm",
        "title": "Beneath Surface Similarity: Large Language Models Make Reasonable Scientific Analogies after Structure Abduction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Analogical Reasoning;Large Language Models;Resources and Benchmark",
        "author": "",
        "aff": "Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University; School of Data Science, Fudan University; Fudan-Aishu Cognitive Intelligence Joint Research Center",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/siyuyuan/scar"
    },
    {
        "id": "sXErPfdA7Q",
        "title": "Document-Level Machine Translation with Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Models;Document-Level Machine Translation;Evaluation and Explaination",
        "author": "",
        "aff": "Dublin City University; Tencent AI Lab; MBZUAI",
        "rating": "",
        "confidence": "5;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/longyuewangdcu/Document-MT-LLM"
    },
    {
        "id": "sYYRTVaG3n",
        "title": "Meta-Learning of Prompt Generation for Lightweight Prompt Engineering on Language-Model-as-a-Service",
        "track": "main",
        "status": "Long Findings",
        "keywords": "prompt tuning;prompt engineering;in-context learning;language model",
        "author": "",
        "aff": "Seoul National University; Columbia University; FriendliAI",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "sZEAMUizsd",
        "title": "Outlier Suppression+: Accurate quantization of large language models by equivalent and effective shifting and scaling",
        "track": "main",
        "status": "Long Main",
        "keywords": "quantization;large language models;outlier",
        "author": "",
        "aff": "SenseTime Research; Yale University; State Key Lab of Software Development Environment, Beihang University",
        "rating": "",
        "confidence": "3;4;3;4;4",
        "correctness": "2;4;4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6,
        "correctness_avg": 3.4,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ModelTC/Outlier_Suppression_Plus"
    },
    {
        "id": "sZGAxcUcNU",
        "title": "Memory-Based Invariance Learning for Out-of-Domain Text Classification",
        "track": "main",
        "status": "Long Main",
        "keywords": "Domain generalization; key-value memory; invariance learning; transfer learning",
        "author": "",
        "aff": "SI-TECH Information Technology, Fudan University; Westlake University, Westlake Institute for Advanced Study",
        "rating": "",
        "confidence": "3;3;2",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "sbLFUT4DaG",
        "title": "Increasing Coverage and Precision of Textual Information in Multilingual Knowledge Graphs",
        "track": "main",
        "status": "Long Main",
        "keywords": "knowledge graph;multilingual;entity linking;knowledge graph completion",
        "author": "",
        "aff": "University of Calgary; Sapienza University of Rome; Apple",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "sbuO0s1r71",
        "title": "Evaluating Cross-Domain Text-to-SQL Models and Benchmarks",
        "track": "main",
        "status": "Long Main",
        "keywords": "Text-to-SQL;Natural language interfaces to databases;Benchmarks;Evaluation",
        "author": "",
        "aff": "University of Alberta",
        "rating": "",
        "confidence": "3;5;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "scAXKWMJR3",
        "title": "Automated Few-Shot Classification with Instruction-Finetuned Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "few-shot classification;prompt automation;large language models",
        "author": "",
        "aff": "Amazon Web Services; University of Cambridge; Boson AI; New York University",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "sdC55K8cP0",
        "title": "WikiChat: Stopping the Hallucination of Large Language Model Chatbots by Few-Shot Grounding on Wikipedia",
        "track": "main",
        "status": "Long Findings",
        "keywords": "large language models;hallucination;knowledge-grounded dialogue",
        "author": "",
        "aff": "Computer Science Department, Stanford University, Stanford, CA",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/stanford-oval/WikiChat"
    },
    {
        "id": "se0YmUUfPs",
        "title": "Manipulating the Perceived Personality Traits of Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "nlp",
        "author": "",
        "aff": "UNC Chapel Hill",
        "rating": "",
        "confidence": "4;4;3;4",
        "correctness": "2;5;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "sfkpJxeDzk",
        "title": "The Framework Tax: Disparities Between Inference Efficiency in NLP Research and Deployment",
        "track": "main",
        "status": "Long Main",
        "keywords": "efficiency;latency;inference",
        "author": "",
        "aff": "Language Technologies Institute, Carnegie Mellon University, Allen Institute for Artificial Intelligence; FAIR; Language Technologies Institute, Carnegie Mellon University",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/JaredFern/Framework-Tax"
    },
    {
        "id": "siiVduxdRz",
        "title": "Condensing Multilingual Knowledge with Lightweight Language-Specific Modules",
        "track": "main",
        "status": "Long Main",
        "keywords": "Multilingual Machine Translation;Lightweight;Language interference;Distillation",
        "author": "",
        "aff": "Johns Hopkins University",
        "rating": "",
        "confidence": "5;4;3",
        "correctness": "4;3;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/fe1ixxu/LMS_FD"
    },
    {
        "id": "sriK75T3kd",
        "title": "No offence, Bert - I insult only humans! Multilingual sentence-level attack on toxicity detection networks",
        "track": "main",
        "status": "Short Findings",
        "keywords": "toxicity detection;adversarial attack;multilingual;neural networks",
        "author": "",
        "aff": "SAMOV AR, T\u00e9l\u00e9com SudParis, Institut Polytechnique de Paris, 91120 Palaiseau, France",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "st5RaWdLTn",
        "title": "AdaTranS: Adapting with Boundary-based Shrinking for End-to-End Speech Translation",
        "track": "main",
        "status": "Short Findings",
        "keywords": "speech translation;modality adaptation",
        "author": "",
        "aff": "Huawei Noah\u2019s Ark Lab",
        "rating": "",
        "confidence": "3;4;4;4",
        "correctness": "2;4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "sthusQGkef",
        "title": "Chain of Thought with Explicit Evidence Reasoning for Few-shot Relation Extraction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Relation Extraction;In-context Learning;Few Shot Learning",
        "author": "",
        "aff": "Harbin Institute of Technology, Shenzhen, China",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "svSNikfCs1",
        "title": "Exploiting Asymmetry for Synthetic Training Data Generation: SynthIE and the Case of Information Extraction",
        "track": "main",
        "status": "Long Main",
        "keywords": "LLM;Synthetic Data Generation;Information Extraction;Closed Information Extraction;Parsing;Structured Output",
        "author": "",
        "aff": "EPFL",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/epfl-dlab/SynthIE"
    },
    {
        "id": "svUOik2Xu1",
        "title": "Robust Prompt Optimization for Large Language Models Against Distribution Shifts",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Model; prompt optimization; distribution shifts; sentiment analysis; question answering;",
        "author": "",
        "aff": "University of Science and Technology of China; National University of Singapore; Singapore Management University",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "sxJU7X2ZG0",
        "title": "Generative Calibration for In-context Learning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Calibration;In-context Learning",
        "author": "",
        "aff": "The Laboratory of Cognition and Decision Intelligence for Complex Systems, Institute of Automation, Chinese Academy of Sciences; School of Artificial Intelligence, University of Chinese Academy of Sciences; The Laboratory of Cognition and Decision Intelligence for Complex Systems, Institute of Automation, Chinese Academy of Sciences; School of Artificial Intelligence, University of Chinese Academy of Sciences; Shanghai Artificial Intelligence Laboratory; Meituan",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/changmenseng/generative_calibration"
    },
    {
        "id": "syj9VaxutQ",
        "title": "A Framework for Exploring Player Perceptions of LLM-Generated Dialogue in Commercial Video Games",
        "track": "main",
        "status": "Long Findings",
        "keywords": "human-centered;dialogue generation;video games;interactive storytelling",
        "author": "",
        "aff": "University of Massachusetts Amherst; Cornell University",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "t035Emm4Vt",
        "title": "WSDMS: Debunk Fake News via Weakly Supervised Detection of Misinforming Sentences with Contextualized Social Wisdom",
        "track": "main",
        "status": "Long Main",
        "keywords": "Fake News Detection;Weakly Supervised Learning;Misinformation;Social Network",
        "author": "",
        "aff": "Hong Kong Baptist University, Hong Kong SAR, China; Jinan University, Guangzhou, Guangdong, China; Singapore Management University, Singapore",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "t42YUsyv3d",
        "title": "DRAFT: Dense Retrieval Augmented Few-shot Topic classifier Framework",
        "track": "main",
        "status": "Long Findings",
        "keywords": "few-shot topic classification;real-world application",
        "author": "",
        "aff": "Neosapience; Seoul National University, VRCREW Inc.",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 1.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "t6p5LtTlqr",
        "title": "Enhancing Neural Machine Translation with Semantic Units",
        "track": "main",
        "status": "Long Findings",
        "keywords": "machine translation",
        "author": "",
        "aff": "Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences; University of Chinese Academy of Sciences; Institute of Computing Technology, Chinese Academy of Sciences; Beijing Academy of Artificial Intelligence",
        "rating": "",
        "confidence": "4;5;4;1",
        "correctness": "4;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ictnlp/SU4MT"
    },
    {
        "id": "tBtc4Ousge",
        "title": "Intervention-Based Alignment of Code Search with Execution Feedback",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Code Search;Misalignment;Reinforcement Learning;Intervention",
        "author": "",
        "aff": "Microsoft Research Asia; Seoul National University",
        "rating": "",
        "confidence": "4;4;2",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "tCEtFcrq8n",
        "title": "Generalizing Few-Shot Named Entity Recognizers to Unseen Domains with Type-Related Features",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Named entity recognition;Few-shot learning;Domain generalization;Prompt learning",
        "author": "",
        "aff": "Leiden University, Leiden, The Netherlands; University of Amsterdam, Amsterdam, The Netherlands; Shandong University, Qingdao, China",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/WZH-NLP/PLTR"
    },
    {
        "id": "tCGyM6CpRI",
        "title": "Optimizing Retrieval-augmented Reader Models via Token Elimination",
        "track": "main",
        "status": "Long Main",
        "keywords": "fusion in decoder;efficiency;long-form question answering",
        "author": "",
        "aff": "Bar-Ilan University, Israel; Intel Labs, Israel; Google Research",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/mosheber/token_elimination"
    },
    {
        "id": "tEN5ONyUre",
        "title": "Interpreting Indirect Answers to Yes-No Questions in Multiple Languages",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multilinguality;Question Answering;Yes-no Question",
        "author": "",
        "aff": "University of Arizona; Amazon; Walmart Global Tech; Arizona State University",
        "rating": "",
        "confidence": "4;2;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "tJt1v8eugw",
        "title": "Multi-Defendant Legal Judgment Prediction via Hierarchical Reasoning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "legal text mining;legal judgment prediction;legal reasoning",
        "author": "",
        "aff": "Leiden University, Leiden, The Netherlands; Shandong University, Qingdao, China; Georgia State University, Atlanta, USA",
        "rating": "",
        "confidence": "5;5;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "tL7hS11keH",
        "title": "CoAnnotating: Uncertainty-Guided Work Allocation between Human and Large Language Models for Data Annotation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Human\u2013Artificial Intelligence Collaboration;Large Language Model;Data Annotation;Weak Supervision",
        "author": "",
        "aff": "Stanford University; Institute for Infocomm Research (I2R), A*STAR; National University of Singapore; University of Southern California",
        "rating": "",
        "confidence": "5;4;3;4",
        "correctness": "3;5;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/SALT-NLP/CoAnnotating"
    },
    {
        "id": "tNN3ToWzCM",
        "title": "Smart \u201cChef\u201d: Verifying the Effect of Role-based Paraphrasing for Aspect Term Extraction",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Information Extraction;Aspect Term Extraction;ChatGPT",
        "author": "",
        "aff": "School of Computer Science and Technology, Soochow University, SuZhou, China",
        "rating": "",
        "confidence": "4;3;3;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "tPJDg5G9SR",
        "title": "Attack Prompt Generation for Red Teaming and Defending Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large Language Models;Red Teaming Attack;Defense;Safety",
        "author": "",
        "aff": "Meta AI; University of Science and Technology of China; National University of Singapore",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Aatrox103/SAP"
    },
    {
        "id": "tQOncmMEVO",
        "title": "G-SPEED: General SParse Efficient Editing MoDel",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Text Editing",
        "author": "",
        "aff": "Soochow University",
        "rating": "",
        "confidence": "3;2;4",
        "correctness": "2;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Banner-Z/G-SPEED"
    },
    {
        "id": "tRYqTsaSyZ",
        "title": "Causal Intervention for Abstractive Related Work Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Related work generation;text summarization;causal intervention",
        "author": "",
        "aff": "James Cook University, Australia; CFAR, Agency for Science, Technology and Research, Singapore; Tongji University, China; DeepBlue Academy of Science, China; University of Technology Sydney, Australia; Beijing Institute of Technology, China",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "tSfZo6nSN1",
        "title": "RECAP: Towards Precise Radiology Report Generation via Dynamic Disease Progression Reasoning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "radiology report generation;text generation grounded on vision",
        "author": "",
        "aff": "Department of Computing, The Hong Kong Polytechnic University, HKSAR, China; Research Institute of Trustworthy Autonomous Systems and Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen, China; Department of Computing, The Hong Kong Polytechnic University, HKSAR, China; Research Institute of Trustworthy Autonomous Systems and Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen, China",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "2;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/wjhou/Recap"
    },
    {
        "id": "tZXaHWfsXB",
        "title": "Transcending Scaling Laws with 0.1% Extra Compute",
        "track": "main",
        "status": "Long Main",
        "keywords": "language models;scaling laws;emergent abilities;efficiency;pretraining",
        "author": "",
        "aff": "Google",
        "rating": "",
        "confidence": "4;3;4;3",
        "correctness": "4;5;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 4.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "taXJRZs43y",
        "title": "Where to start? Analyzing the potential value of intermediate models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Intertraining;fine tuned;intermediate;finetune",
        "author": "",
        "aff": "IBM Research; The Hebrew University",
        "rating": "",
        "confidence": "4;4;4;2",
        "correctness": "4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://ibm.github.io/model-recycling/"
    },
    {
        "id": "tauoKi9IWO",
        "title": "LLMDet: A Third Party Large Language Models Generated Text Detection Tool",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Text Detection;Large Language Model;Fine-grained Tracing;Proxy Perplexity",
        "author": "",
        "aff": "Institute of Computing Technology, Chinese Academy of Sciences; University of Chinese Academy of Sciences; Institute of Computing Technology, Chinese Academy of Sciences; Sea-NExT Joint Lab, National University of Singapore",
        "rating": "",
        "confidence": "3;4;4;4;4",
        "correctness": "3;3;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.8,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/TrustedLLM/LLMDet"
    },
    {
        "id": "tbHe97ENFD",
        "title": "Exploring the Impact of Corpus Diversity on Financial Pretrained Language Models",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Financial NLP;Pre-trained Language Model;Generalization",
        "author": "",
        "aff": "Ramply Inc.; Division of Computer Science, Hanyang University; Department of Applied Artificial Intelligence, Hanyang University",
        "rating": "",
        "confidence": "5;3;2;5",
        "correctness": "3;3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/deep-over/FiLM"
    },
    {
        "id": "tbRPPWDy76",
        "title": "MEEP: Is this Engaging? Prompting Large Language Models for Dialogue Evaluation in Multilingual Settings",
        "track": "main",
        "status": "Long Findings",
        "keywords": "automatic evaluation of dialogue;dialogue evaluation;multilingual;metrics;engagingness;prompting;LLM;large language model;multilinguality",
        "author": "",
        "aff": "Department of Computer Science, Portland State University",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/PortNLP/MEEP"
    },
    {
        "id": "te3pXuiVk3",
        "title": "MemeCap: A Dataset for Captioning and Interpreting Memes",
        "track": "main",
        "status": "Long Main",
        "keywords": "meme;captioning;image;large multimodal model",
        "author": "",
        "aff": "University of British Columbia, Vector Institute for AI",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "tfHJ9uLNlR",
        "title": "BiSPN: Generating Entity Set and Relation Set Coherently in One Pass",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Information Extraction;Joint Entity-Relation Extraction;Non-autoregressive Generation",
        "author": "",
        "aff": "Department of Computer Science, Harbin Institute of Technology, Shenzhen, China; Peng Cheng Laboratory, Shenzhen, China; Department of Computer Science, Harbin Institute of Technology, Shenzhen, China",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "tkY0l8mHii",
        "title": "A Query-Parallel Machine Reading Comprehension Framework for Low-resource NER",
        "track": "main",
        "status": "Long Findings",
        "keywords": "NER;low-resource;in-domain transfer;cross-domain transfer",
        "author": "",
        "aff": "Alibaba Group",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "tm5UxNFrlD",
        "title": "Location-Aware Visual Question Generation with Lightweight Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Location-aware Visual Question Generation;Visual Question Generation;Question Generation;Lightweight Models",
        "author": "",
        "aff": "Institute of Information Science, Academia Sinica; National Taiwan University; Pennsylvania State University; Hon Hai Research Institute",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/AcademiaSinicaNLPLab/LocaVQG"
    },
    {
        "id": "toUPGCAMic",
        "title": "ALCUNA: Large Language Models Meet New Knowledge",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Model;Model Evaluation;Knowledge",
        "author": "",
        "aff": "Center for Data Science, Peking University; The MOE Key Laboratory of Computational Linguistics, Peking University; Wangxuan Institute of Computer Technology, Peking University",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "tquKyw04gE",
        "title": "MultiCoNER v2: a Large Multilingual dataset for Fine-grained and Noisy Named Entity Recognition",
        "track": "main",
        "status": "Short Findings",
        "keywords": "ner;multilingual ner;fine-grained ner;noisy ner",
        "author": "",
        "aff": "Amazon.com, Inc., Seattle, WA, USA",
        "rating": "",
        "confidence": "3;5;4",
        "correctness": "3;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://registry.opendata.aws/multiconer",
        "github": "https://huggingface.co/datasets/MultiCoNER/multiconer_v2"
    },
    {
        "id": "tueh30tKiv",
        "title": "Length is a Curse and a Blessing for Document-level Semantics",
        "track": "main",
        "status": "Long Main",
        "keywords": "contrastive learning;sentence representation learning;document representation learning;semantics;document length",
        "author": "",
        "aff": "Department of Computer Science, Durham University, UK; Department of Computer Science, The University of Manchester, UK",
        "rating": "",
        "confidence": "3;3;4;5",
        "correctness": "3;4;3;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "Not provided",
        "github": "Not provided"
    },
    {
        "id": "u03xn1COsO",
        "title": "Is ChatGPT a General-Purpose Natural Language Processing Task Solver?",
        "track": "main",
        "status": "Long Main",
        "keywords": "Chatgpt evaluation;general-purpose task solver;zero-shot learning",
        "author": "",
        "aff": "Nanyang Technological University; Georgia Institute of Technology; Shanghai Jiao Tong University; Stanford University",
        "rating": "",
        "confidence": "4;5;2;3",
        "correctness": "3;4;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "u14dVx4rMW",
        "title": "ImageNetVC: Zero- and Few-Shot Visual Commonsense Evaluation on 1000 ImageNet Categories",
        "track": "main",
        "status": "Long Findings",
        "keywords": "visual commonsense;large language model;visually-augmented language model",
        "author": "",
        "aff": "National Key Laboratory for Multimedia Information Processing, Peking University; School of Software & Microelectronics, Peking University; National Key Laboratory for Multimedia Information Processing, Peking University; School of Computer Science, Peking University; Alibaba; Shanghai AI Lab",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/hemingkx/ImageNetVC"
    },
    {
        "id": "u69aCtohTC",
        "title": "Unveiling the Implicit Toxicity in Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Model;Toxicity;Safety;Reinforcement Learning",
        "author": "",
        "aff": "TAL Education Group, Beijing, China; The CoAI group, Tsinghua University, Beijing, China",
        "rating": "",
        "confidence": "3;4;2;4",
        "correctness": "4;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/thu-coai/Implicit-Toxicity"
    },
    {
        "id": "u9Fvsy8Brx",
        "title": "mmT5: Modular Multilingual Pre-Training Solves Source Language Hallucinations",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Modularity;Multilinguality;Adapters;Parameter-efficiency",
        "author": "",
        "aff": "Google DeepMind",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "u9gI4JlOSj",
        "title": "How Does Generative Retrieval Scale to Millions of Passages?",
        "track": "main",
        "status": "Long Main",
        "keywords": "generative retrieval;differentiable search index;information retrieval",
        "author": "",
        "aff": "Google Research; University of Waterloo",
        "rating": "",
        "confidence": "3;5;2",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "uB9ZnBCBX6",
        "title": "Text-Transport: Toward Learning Causal Effects of Natural Language",
        "track": "main",
        "status": "Long Main",
        "keywords": "causal inference;causal effects;distribution shift;domain adaptation;transportability",
        "author": "",
        "aff": "Carnegie Mellon University",
        "rating": "",
        "confidence": "2;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "uBnIvIcAFx",
        "title": "Vera: A General-Purpose Plausibility Estimation Model for Commonsense Statements",
        "track": "main",
        "status": "Long Main",
        "keywords": "commonsense;verification;plausibility",
        "author": "",
        "aff": "Paul G. Allen School of Computer Science & Engineering, University of Washington; John A. Paulson School of Engineering and Applied Sciences, Harvard University; Allen Institute for Artificial Intelligence",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "uDMyRJw6ty",
        "title": "Clinical Contradiction Detection",
        "track": "main",
        "status": "Long Main",
        "keywords": "clinical contradiction detection;medical ontologies;clinical distant supervision",
        "author": "",
        "aff": "Tel Aviv University, Tel Aviv, Israel; Technion, Israel Institute of Technology, Haifa, Israel",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "uEAFmlWYig",
        "title": "Towards Robust Pruning: An Adaptive Knowledge-Retention Pruning Strategy for Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Robust Pruning;Language Models",
        "author": "",
        "aff": "North Carolina State University; NEC-Labs; New York University",
        "rating": "",
        "confidence": "2;2;2;4;2",
        "correctness": "3;3;3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.4,
        "correctness_avg": 3.4,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "uPz5a2NvrG",
        "title": "Normal-Abnormal Decoupling Memory for Medical Report Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Medical Report Generation;Normal-Abnormal Decoupling;Semantic Extraction;Abnormal Mode Memory",
        "author": "",
        "aff": "School of Control Science and Engineering, Shandong University; Department of Computer Science, Illinois Institute of Technology",
        "rating": "",
        "confidence": "4;2;5",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/kzzjk/NADM"
    },
    {
        "id": "uQfyuhhHBq",
        "title": "Penalty Decoding: Well Suppress the Self-Reinforcement Effect in Open-Ended Text Generation",
        "track": "main",
        "status": "Short Main",
        "keywords": "decoding algorithm;open-ended text generation;self-reinforcement;repetition penalty",
        "author": "",
        "aff": "Shanghai Jiao Tong University",
        "rating": "",
        "confidence": "5;4;5",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/zwhong714/penalty_decoding"
    },
    {
        "id": "uRIFDS3gtG",
        "title": "LACMA: Language-Aligning Contrastive Learning with Meta-Actions for Embodied Instruction Following",
        "track": "main",
        "status": "Long Main",
        "keywords": "Embodied AI;Vision and Language Navigation",
        "author": "",
        "aff": "National Taiwan University, Nvidia; Microsoft; UCLA",
        "rating": "",
        "confidence": "5;3;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "github.com/joeyy5588/LACMA"
    },
    {
        "id": "uUvlXyriM7",
        "title": "CLASS: A Design Framework for Building Intelligent Tutoring Systems Based on Learning Science principles",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Intelligent Tutoring Systems;NLP for education;AI Tutors;Learning Science",
        "author": "",
        "aff": "OpenStax, Rice University; Rice University",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/luffycodes/Tutorbot-Spock"
    },
    {
        "id": "uZp3i8yEs4",
        "title": "`Don't Get Too Technical with Me': A Discourse Structure-Based Framework for Automatic Science Journalism",
        "track": "main",
        "status": "Long Main",
        "keywords": "automatic scientific journalism;summarization;style transfer",
        "author": "",
        "aff": "IBM Research Europe, Ireland; Northeastern University; Rensselaer Polytechnic Institute; University of Edinburgh",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "uaZQ21cuzW",
        "title": "From Wrong To Right: A Recursive Approach Towards Vision-Language Explanation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Vision-Language Models;Visual Reasoning;Vision-Language Explanation;Self Training",
        "author": "",
        "aff": "UC Berkeley, CA, USA; UC Berkeley, CA, USA; Peking University, Beijing, China",
        "rating": "",
        "confidence": "3;2;5",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/para-lost/ReVisE"
    },
    {
        "id": "ubXaboYnzN",
        "title": "QTSumm: Query-Focused Summarization over Tabular Data",
        "track": "main",
        "status": "Long Main",
        "keywords": "Summarization;Text Generation;Reasoning over Structured Data",
        "author": "",
        "aff": "Harvard University; School of Informatics, University of Edinburgh; Yale University, Allen Institute for AI; Yale University; Zhejiang University",
        "rating": "",
        "confidence": "5;3;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/yale-nlp/QTSumm"
    },
    {
        "id": "uckh15CSS1",
        "title": "ExplainCPE: A Free-text Explanation Benchmark of Chinese Pharmacist Examination",
        "track": "main",
        "status": "Long Findings",
        "keywords": "datasets;interpretability;large language model",
        "author": "",
        "aff": "Harbin Institute of Technology (Shenzhen), Shenzhen, China",
        "rating": "",
        "confidence": "5;2;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/HITsz-TMG/ExplainCPE"
    },
    {
        "id": "udiNCxGKLl",
        "title": "Transformer-Based Language Model Surprisal Predicts Human Reading Times Best with About Two Billion Training Tokens",
        "track": "main",
        "status": "Short Findings",
        "keywords": "surprisal theory;human sentence processing;large language models",
        "author": "",
        "aff": "Department of Linguistics, The Ohio State University",
        "rating": "",
        "confidence": "5;5;5",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 5.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "udl5f2seyU",
        "title": "DiFair: A Benchmark for Disentangled Assessment of Gender Knowledge and Bias",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Bias;Gender-Bias;Transformers;Task;Dataset;Language Modeling",
        "author": "",
        "aff": "Worcester Polytechnic Institute, United States; Tehran Institute for Advanced Studies (TeIAS), Khatam University, Iran",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "uemYdRTVvP",
        "title": "SeqXGPT: Sentence-Level AI-Generated Text Detection",
        "track": "main",
        "status": "Long Main",
        "keywords": "AI generated text detection;security in NLP;LLM",
        "author": "",
        "aff": "School of Computer Science, Fudan University",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Jihuai-wpy/SeqXGPT"
    },
    {
        "id": "ufu4C0bTwB",
        "title": "Target-oriented Proactive Dialogue Systems with Personalization: Problem Formulation and Dataset Curation",
        "track": "main",
        "status": "Short Main",
        "keywords": "Target-oriented dialogue;Proactive dialogue;Personalization;Dataset curation",
        "author": "",
        "aff": "Department of Computing, The Hong Kong Polytechnic University",
        "rating": "",
        "confidence": "4;4;2",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/iwangjian/TopDial"
    },
    {
        "id": "uh5euNmL7t",
        "title": "Hyperpolyglot LLMs: Cross-Lingual Interpretability in Token Embeddings",
        "track": "main",
        "status": "Short Main",
        "keywords": "Multilingual models;cross-lingual representations",
        "author": "",
        "aff": "Cornell University",
        "rating": "",
        "confidence": "3;3;2",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/andreawwenyi/hyperpolyglot"
    },
    {
        "id": "uhVJ3SLq80",
        "title": "BioT5: Enriching Cross-modal Integration in Biology with Chemical Knowledge and Natural Language Associations",
        "track": "main",
        "status": "Long Main",
        "keywords": "cross-modal;biology;text;molecule;protein",
        "author": "",
        "aff": "Gaoling School of Artificial Intelligence, Renmin University of China; University of Science and Technology of China; Huazhong University of Science and Technology; Microsoft Research",
        "rating": "",
        "confidence": "2;4;4;4",
        "correctness": "4;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/QizhiPei/BioT5"
    },
    {
        "id": "ul47tFdRn6",
        "title": "DiffuVST: Narrating Fictional Scenes with Global-History-Guided Denoising Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "visual storytelling;diffusion language models;global history guidance",
        "author": "",
        "aff": "Peking University",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "2;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "ulqYwmcUnL",
        "title": "XTREME-UP: A User-Centric Scarce-Data Benchmark for Under-Represented Languages",
        "track": "main",
        "status": "Long Findings",
        "keywords": "nlp;low-resource;under-represented;scarce data;benchmark",
        "author": "",
        "aff": "Google; University College London; Google\u2020",
        "rating": "",
        "confidence": "5;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/google-research/xtreme-up"
    },
    {
        "id": "unKIy4mpnn",
        "title": "Making Body Movement in Sign Language Corpus Accessible for Linguists and Machines with Three-Dimensional Normalization of MediaPipe",
        "track": "main",
        "status": "Long Findings",
        "keywords": "sign language;pose processing;wlasl;movement processing",
        "author": "",
        "aff": "The Graduate University for Advanced Studies (SOKENDAI), Kanagawa, Japan; National Institute of Informatics, Tokyo, Japan",
        "rating": "",
        "confidence": "3;5;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "up8EYzyrKV",
        "title": "Towards Mitigating LLM Hallucination via Self Reflection",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Hallucination;Large Language Model;Medical Question Answering;Generative Question Answering;Question Answering",
        "author": "",
        "aff": "Center for Artificial Intelligence Research (CAiRE), Hong Kong University of Science and Technology",
        "rating": "",
        "confidence": "3;3;5;4",
        "correctness": "4;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ziweiji/Self_Reflection_Medical"
    },
    {
        "id": "us7p0VsOhl",
        "title": "GLGR: Question-aware Global-to-Local Graph Reasoning for Multi-party Dialogue Reading Comprehension",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multi-party dialogue reading comprehension;Global-to-local graph reasoning",
        "author": "",
        "aff": "School of Computer Science and Technology, Soochow University, Suzhou, China; Institute for Infocomm Research, A*STAR, Singapore",
        "rating": "",
        "confidence": "2;4;3;4",
        "correctness": "4;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "usnEi3Bfnt",
        "title": "Structural generalization in COGS: Supertagging is (almost) all you need",
        "track": "main",
        "status": "Long Main",
        "keywords": "semantic parsing;compositional generalization;graph-based parsing",
        "author": "",
        "aff": "Universit\u00e9 Paris-Saclay, CNRS, LISN, 91400, Orsay, France; Sorbonne Universit\u00e9, CNRS, ISIR, F-75005 Paris, France",
        "rating": "",
        "confidence": "2;3;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "uu6Oq7MN7g",
        "title": "CodeT5+: Open Code Large Language Models for Code Understanding and Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Model;Code Intelligence;Code Understanding and Generation",
        "author": "",
        "aff": "Salesforce AI Research",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/salesforce/CodeT5/tree/main/CodeT5+"
    },
    {
        "id": "uuUQraD4XX",
        "title": "Large Language Models Can Self-Improve",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Models;Commonsense Reasoning;Arithmetic Reasoning;Chain of Thought",
        "author": "",
        "aff": "University of Illinois at Urbana-Champaign; Google",
        "rating": "",
        "confidence": "5;4;4;4",
        "correctness": "3;4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "uvbbsn4l6y",
        "title": "Look-back Decoding for Open-Ended Text Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "open-ended text generation;decoding;story generation;document continuation",
        "author": "",
        "aff": "Meta AI; University of Southern California",
        "rating": "",
        "confidence": "2;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/xunannancy/LookBackDecoding"
    },
    {
        "id": "ux826WlJtt",
        "title": "DemoSG: Demonstration-enhanced Schema-guided Generation for Low-resource Event Extraction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Low-resource;Event Extraction;Few-shot;Domain Adaptation;Demonstration-based Learning",
        "author": "",
        "aff": "School of Artificial Intelligence, Beijing University of Posts and Telecommunications",
        "rating": "",
        "confidence": "4;4;2",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "uxzlH5bLrJ",
        "title": "Can Brain Signals Reveal Inner Alignment with Human Languages?",
        "track": "main",
        "status": "Short Findings",
        "keywords": "EEG;Human Languages;Inner Alignment;Interpretation",
        "author": "",
        "aff": "University of Chicago; Carnegie Mellon University/MIT CSAIL; Carnegie Mellon University",
        "rating": "",
        "confidence": "4;3;4;3",
        "correctness": "3;3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 1.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Jason-Qiu/EEG_Language_Alignment"
    },
    {
        "id": "uyUO80sbm0",
        "title": "Explain-then-translate: an analysis on improving program translation with self-generated explanations",
        "track": "main",
        "status": "Long Findings",
        "keywords": "code generation;machine translation;program translation;large language model;prompting;chain-of-thought",
        "author": "",
        "aff": "MIT; Monash University Indonesia; MIT-IBM Watson AI Lab, IBM Research; UPenn; Boston University",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/PootieT/explain-then-translate"
    },
    {
        "id": "uyl1O2LkAF",
        "title": "TaTA: A Multilingual Table-to-Text Dataset for African Languages",
        "track": "main",
        "status": "Long Findings",
        "keywords": "table-to-text;multilingual;NLG;African languages",
        "author": "",
        "aff": "; Google\u2020; Google\u2020Bloomberg",
        "rating": "",
        "confidence": "3;1;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/google-research/url-nlp"
    },
    {
        "id": "uz4OrlHDA8",
        "title": "Predict the Future from the Past? On the Temporal Data Distribution Shift in Financial Sentiment Classifications",
        "track": "main",
        "status": "Long Main",
        "keywords": "Distribution Shift;Financial Sentiment Classifications;Language Models Robustness",
        "author": "",
        "aff": "The Hong Kong University of Science and Technology",
        "rating": "",
        "confidence": "3;3;2",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "uz89EXE540",
        "title": "Self-Supervised Rule Learning to Link Text Segments to Relational Elements of Structured Knowledge",
        "track": "main",
        "status": "Long Findings",
        "keywords": "self-supervised learning;rule learning;relation linking;question answering",
        "author": "",
        "aff": "IBM Research, T. J. Watson Research Center, Yorktown Heights, New York, United States; IBM Research, Johannesburg, South Africa; IBM Research, Bangalore/Gurugram, India",
        "rating": "",
        "confidence": "3;2;3",
        "correctness": "3;2;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "v15z3FzZGu",
        "title": "Adapter Pruning using Tropical Characterization",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Pruning;Adapters;Parameter Efficient Transfer Learning;Domain Adaptation",
        "author": "",
        "aff": "DeCLaRe; Singapore University of Technology and Design, Singapore; Nanyang Technological University, Singapore",
        "rating": "",
        "confidence": "4;4;3;2",
        "correctness": "3;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "v2wbkddf52",
        "title": "Quality Estimation-Assisted Automatic Post-Editing",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Automaric Post-Editing;Quality Estimation;Multi-task Learning",
        "author": "",
        "aff": "Aston University, Birmingham, United Kingdom; CFILT, Indian Institute of Technology Bombay, Mumbai, India; CFILT, Indian Institute of Technology Bombay, Mumbai, India and Surrey Institute for People-Centred AI, University of Surrey, United Kingdom; Tilburg University, Tilburg, The Netherlands",
        "rating": "",
        "confidence": "3;2;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/cfiltnlp/APE_MTL"
    },
    {
        "id": "v6VbokqzvP",
        "title": "R$^3$ Prompting: Review, Rephrase and Resolve for Chain-of-Thought Reasoning in Large Language Models under Noisy Context",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Chain-of-Thought;Large Language Models;Arithmetic Reasoning;Prompt Learning",
        "author": "",
        "aff": "East China Normal University, Shanghai, China; Singapore Management University, Singapore; Alibaba Group, Beijing, China",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "v6hcCtzAWz",
        "title": "Simple Hardware-Efficient PCFGs with Independent Left and Right Productions",
        "track": "main",
        "status": "Short Findings",
        "keywords": "grammar induction;unsupervised parsing;latent variable models",
        "author": "",
        "aff": "School of Information Science and Technology, ShanghaiTech University; Shanghai Engineering Research Center of Intelligent Vision and Imaging; Massachusetts Institute of Technology",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/sustcsonglin/TN-PCFG"
    },
    {
        "id": "v6iM1bO78t",
        "title": "Incorporating Worker Perspectives into MTurk Annotation Practices for NLP",
        "track": "main",
        "status": "Long Main",
        "keywords": "data collection;annotators;mechanical turk;AI ethics;data quality",
        "author": "",
        "aff": "UC Berkeley",
        "rating": "",
        "confidence": "2;1;4",
        "correctness": "3;3;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "v7JgI9dny2",
        "title": "Simpler neural networks prefer subregular languages",
        "track": "main",
        "status": "Long Findings",
        "keywords": "subregularity;formal language theory;minimum description length;inductive biases",
        "author": "",
        "aff": "University of California, Irvine, Language Science",
        "rating": "",
        "confidence": "3;3;2",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "v8fRIzqeob",
        "title": "Exploring the Cognitive Knowledge Structure of Large Language Models: An Educational Diagnostic Assessment Approach",
        "track": "main",
        "status": "Short Findings",
        "keywords": "large language models;diagnostic assessment;knowledge structure",
        "author": "",
        "aff": "Department of Computer Science and Technology, Tsinghua University, Beijing, 100084, China",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "v9CVjuNlDI",
        "title": "Breaking Boundaries in Retrieval Systems: Unsupervised Domain Adaptation with Denoise-Finetuning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Information Retrieval;Domain adaptation;Denoise-finetuning;Unsupervised",
        "author": "",
        "aff": "Department of Computer Science and Information Engineering, National Cheng Kung University, Tainan, Taiwan; Institute of Medical Informatics, National Cheng Kung University, Tainan, Taiwan",
        "rating": "",
        "confidence": "2;1;4;2",
        "correctness": "2;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 2.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/eric88525/UDADF"
    },
    {
        "id": "vBZ5eBdrgH",
        "title": "$\\textit{SelectNoise:}$ Unsupervised Noise Injection to Enable Zero-Shot Machine Translation for Extremely Low-resource Languages",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Machine Translation;Low resource languages;Noise Injection;Zero-shot;BPE",
        "author": "",
        "aff": "Natural Language and Information Processing Lab (NLIP), Indian Institute of Technology Hyderabad, Hyderabad, India",
        "rating": "",
        "confidence": "5;4;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/maharajbrahma/selectnoise"
    },
    {
        "id": "vDvFT7IX4O",
        "title": "Tree of Clarifications: Answering Ambiguous Questions with Retrieval-Augmented Large Language Models",
        "track": "main",
        "status": "Short Main",
        "keywords": "Question Answering;Large Language Model;Ambiguous QA;Open-domain QA",
        "author": "",
        "aff": "NAVER Cloud, NAVER AI Lab; NAVER AI Lab, University of Richmond; Korea University",
        "rating": "",
        "confidence": "3;4;4;3",
        "correctness": "4;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "github.com/gankim/tree-of-clarifications"
    },
    {
        "id": "vLoSutEAJM",
        "title": "The neural dynamics of word recognition and integration",
        "track": "main",
        "status": "Long Main",
        "keywords": "processing;word recognition;speech comprehension;EEG;neuroscience;cognitive neuroscience;cognitive science;psychology;time series",
        "author": "",
        "aff": "Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/hans/word-recognition-and-integration"
    },
    {
        "id": "vMpmabFTFw",
        "title": "Learning to Compose Representations of Different Encoder Layers towards Improving Compositional Generalization",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Compositional Generalization;Seq2Seq Models;Machine Translation;Semantic Parsing",
        "author": "",
        "aff": "Department of Artificial Intelligence, School of Informatics, Xiamen University; Key Laboratory of Digital Protection and Intelligent Processing of Intangible Cultural Heritage of Fujian and Taiwan (Xiamen University), Ministry of Culture and Tourism, China",
        "rating": "",
        "confidence": "4;4;3;4",
        "correctness": "4;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/thinkaboutzero/COMPOSITION"
    },
    {
        "id": "vOX7Dfwo3v",
        "title": "Symbol tuning improves in-context learning in language models",
        "track": "main",
        "status": "Long Main",
        "keywords": "in-context learning;large language models;natural language processing",
        "author": "",
        "aff": "Google; Google, Stanford University",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "vR1yERC0Wd",
        "title": "Global Structure Knowledge-Guided Relation Extraction Method for Visually-Rich Document",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Visually-Rich Document;Visual relation extraction",
        "author": "",
        "aff": "Worcester Polytechnic Institute; Alibaba Group; Zhejiang University",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/chenxn2020/GOSE"
    },
    {
        "id": "vU0KbvQ91x",
        "title": "Learning to Abstract with Nonparametric Variational Information Bottleneck",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Representation Learning;Analysis of Neural Networks;Nonparametric Variational Information Bottleneck;Deep Learning",
        "author": "",
        "aff": "Idiap Research Institute, Switzerland; Idiap Research Institute, Switzerland and \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne, Switzerland",
        "rating": "",
        "confidence": "1;3;2;3;2;3",
        "correctness": "3;3;3;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 3.1666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/idiap/nvib"
    },
    {
        "id": "vVdRgpC1Oh",
        "title": "An Empirical Study of Multimodal Model Merging",
        "track": "main",
        "status": "Long Findings",
        "keywords": "model merging; vision-and-language",
        "author": "",
        "aff": "UNC Chapel Hill; Apple AI/ML; Microsoft",
        "rating": "",
        "confidence": "3;4;5",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ylsung/vl-merging"
    },
    {
        "id": "vVrwnY76W1",
        "title": "Remember what you did so you know what to do next",
        "track": "main",
        "status": "Short Findings",
        "keywords": "large language models;text games",
        "author": "",
        "aff": "Information Sciences Institute, University of Southern California",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "vW3TFDUKWl",
        "title": "Mitigating Backdoor Poisoning Attacks through the Lens of Spurious Correlation",
        "track": "main",
        "status": "Long Main",
        "keywords": "backdoor attack;backdoor defence;spurious correlation",
        "author": "",
        "aff": "University College London, United Kingdom; University of Melbourne, Australia",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "4;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/xlhex/emnlp2023_z-defence.git"
    },
    {
        "id": "vWol8k64op",
        "title": "A Dataset for Investigating the Impact of Context for Offensive Language Detection in Tweets",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Offensive Language Detection;Twitter Dataset;Language Resources and Evaluation",
        "author": "",
        "aff": "Department of Computer Engineering, Bo\u011fazi\u00e7i University",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "4;3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "vWy66avGPR",
        "title": "Perceptual Structure in the absence of grounding: the impact of abstractedness and subjectivity in color language for LLMs",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Color language;grounding;language models",
        "author": "",
        "aff": "Rakuten Institute of Technology; Rakuten Group, Inc; Tokyo, Japan; National Institute of Advanced Industrial Science and Technology, Japan; Graduate School of Engineering, The University of Tokyo; Rakuten Institute of Technology; Rakuten Group, Inc; Paris, France",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "2;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://colornames.org",
        "github": ""
    },
    {
        "id": "va7nzRsbA4",
        "title": "What Makes Chain-of-Thought Prompting Effective? A Counterfactual Study",
        "track": "main",
        "status": "Long Findings",
        "keywords": "LLMs;Analysis;Chain-of-thought;Reasoning;Prompting;Few-shot Reasoning",
        "author": "",
        "aff": "Google DeepMind; Language Technologies Institute, Carnegie Mellon University",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/reasoning-machines/prompt-lib"
    },
    {
        "id": "vaKgq549Dy",
        "title": "FactKB: Generalizable Factuality Evaluation using Language Models Enhanced with Factual Knowledge",
        "track": "main",
        "status": "Long Main",
        "keywords": "factuality evaluation;knowledge bases;summarization",
        "author": "",
        "aff": "University of Washington; Carnegie Mellon University; Xi\u2019an Jiaotong University",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/BunsenFeng/FactKB"
    },
    {
        "id": "vdLFYqupHA",
        "title": "Enhancing Uncertainty-Based Hallucination Detection with Stronger Focus",
        "track": "main",
        "status": "Long Main",
        "keywords": "hallucination detection;large language model;text generation",
        "author": "",
        "aff": "Shanghai Jiaotong University, China; Westlake University, China; IGSNRR, Chinese Academy of Sciences, China; Amazon AWS AI",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/zthang/focus"
    },
    {
        "id": "vexCLJO7vo",
        "title": "MenatQA: A New Dataset for Testing the Temporal Comprehension and Reasoning Abilities of Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Temporal Reasoning;Large Language Models",
        "author": "",
        "aff": "The Laboratory of Cognition and Decision Intelligence for Complex Systems, CASIA; University of Chinese Academy of Sciences; Shanghai Artificial Intelligence Laboratory; The Laboratory of Cognition and Decision Intelligence for Complex Systems, CASIA; Beijing Institute of Technology; The Laboratory of Cognition and Decision Intelligence for Complex Systems, CASIA; University of Chinese Academy of Sciences; The Laboratory of Cognition and Decision Intelligence for Complex Systems, CASIA; Fuzhou University",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "vg55TCMjbC",
        "title": "Reading Books is Great, But Not if You Are Driving! Visually Grounded Reasoning about Defeasible Commonsense Norms",
        "track": "main",
        "status": "Long Main",
        "keywords": "Multimodal;Commonsense;Dataset;Social Norm;Morality",
        "author": "",
        "aff": "University of Washington; Yonsei University; Seoul National University; Allen Institute for Artificial Intelligence",
        "rating": "",
        "confidence": "5;3;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://seungjuhan.me/normlens"
    },
    {
        "id": "vgaJRhYVje",
        "title": "Coarse-to-Fine Contrastive Learning in Image-Text-Graph Space for Improved Vision-Language Compositionality",
        "track": "main",
        "status": "Long Main",
        "keywords": "Vision-Language Compositionality;Systematic Generalization;Vision-Language Contrastive Learning;Multimodal Foundation Models",
        "author": "",
        "aff": "Meta AI; Anytime.AI",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "vgg3dKoyDH",
        "title": "Analyzing Norm Violations in Live-Stream Chat",
        "track": "main",
        "status": "Long Main",
        "keywords": "Norm Violation;Toxicity Detection;Live Streaming",
        "author": "",
        "aff": "SoftlyAI Research, University of Southern California; Carnegie Mellon University; University of Southern California; Selectstar; SoftlyAI Research",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "4;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/softly-ai/live-NormVio"
    },
    {
        "id": "vjTnfxbkaL",
        "title": "Hierarchical Enhancement Framework for Aspect-based Argument Mining",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Aspect-based Argument Mining;Nested Named Entity Recognition;Argument Unit Recognition and Classification;Aspect Term Extraction",
        "author": "",
        "aff": "Institute for Infocomm Research, A*STAR, Singapore; School of Finance, Shanxi University of Finance and Economics, China; School of Computer and Information Technology, Shanxi University, China; Key Laboratory of Computational Intelligence and Chinese Information Processing of Ministry of Education, Shanxi University, China; School of Computer and Information Technology, Shanxi University, China",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/sxu-fyj/ABAM"
    },
    {
        "id": "vkEYzLIdLX",
        "title": "Dolphin: A Challenging and Diverse Benchmark for Arabic NLG",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Arabic language;Dialectal Arabic;NLG benchmark.",
        "author": "",
        "aff": "Deep Learning & Natural Language Processing Group, The University of British Columbia; Department of Natural Language Processing & Department of Machine Learning, MBZUAI",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://dolphin.dlnlp.ai/",
        "github": ""
    },
    {
        "id": "voBhcwDyPt",
        "title": "On the Risk of Misinformation Pollution with Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large Language Models;Misinformation;Question Answering",
        "author": "",
        "aff": "MBZUAI; University of Waterloo; National University of Singapore; National University of Singapore, Zhejiang University; University of California, Santa Barbara",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/MexicanLemonade/LLM-Misinfo-QA"
    },
    {
        "id": "vooJHgn1Gm",
        "title": "Fidelity-Enriched Contrastive Search: Reconciling the Faithfulness-Diversity Trade-Off in Text Generation",
        "track": "main",
        "status": "Short Main",
        "keywords": "hallucination;faithfulness;decoding",
        "author": "",
        "aff": "National Taiwan University, Taiwan; Artificial Intelligence Research Center, AIST, Japan",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ntunlplab/FECS"
    },
    {
        "id": "vpkEJM9qYR",
        "title": "Unveiling the Multi-Annotation Process: Examining the Influence of Annotation Quantity and Instance Difficulty on Model Performance",
        "track": "main",
        "status": "Long Findings",
        "keywords": "multi-annotation;label-distribution;PVI;annotator-set;$\\mathcal{V}$-Information;entropy;annotation budget;datamaps;cartography",
        "author": "",
        "aff": "Department of Computer Science and Engineering, Indian Institute of Technology Gandhinagar, Gujarat, India",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "3;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "vq4BnrPyPb",
        "title": "Knowledge is a Region in Weight Space for Fine-tuned Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Weight space;loss landscape;loss space;finetuning;fine-tune;loss connectivity;basin;minima",
        "author": "",
        "aff": "UNC Chapel Hill; IBM Research; Technion - IIT",
        "rating": "",
        "confidence": "4;3;2;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "vscmppXqXE",
        "title": "GEMINI: Controlling The Sentence-Level Summary Style in Abstractive Text Summarization",
        "track": "main",
        "status": "Long Main",
        "keywords": "Text Summarization;Summary Style",
        "author": "",
        "aff": "Institute of Advanced Technology, Westlake Institute for Advanced Study; Zhejiang University; School of Engineering, Westlake University",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "5;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/baoguangsheng/gemini"
    },
    {
        "id": "vtC3sLXjDY",
        "title": "How Reliable Are AI-Generated-Text Detectors? An Assessment Framework Using Evasive Soft Prompts",
        "track": "main",
        "status": "Long Findings",
        "keywords": "AI-generated-text detection;soft prompts;Large language models",
        "author": "",
        "aff": "Arizona State University",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "vtqfPW6OSm",
        "title": "Linear-Time Modeling of Linguistic Structure: An Order-Theoretic Perspective",
        "track": "main",
        "status": "Long Main",
        "keywords": "structured prediction;dependency parsing;coreference resolution",
        "author": "",
        "aff": "ETH Zurich",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "5;5;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 5.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/lyutyuh/partial"
    },
    {
        "id": "vuabr8zbCq",
        "title": "Improving the Robustness of Summarization Models by Detecting and Removing Input Noise",
        "track": "main",
        "status": "Long Findings",
        "keywords": "summarization;robustness to noise;safety in ML",
        "author": "",
        "aff": "Carnegie Mellon University, work done while at Google Research; Google Research",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "vvnUi75U9i",
        "title": "Is Explanation the Cure? Misinformation Mitigation in the Short Term and Long Term",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Fake news debunking strategy;misinformation;Counterfactual Explanation;Natural Language Generation;Warning Tag;Longterm study",
        "author": "",
        "aff": "Institute of Information Science, Academia Sinica; Institute of Information Science, Academia Sinica; Department of Computer Science, National Tsing Hua University; The University of Texas at Austin; The Pennsylvania State University",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "w3hL7wFgb3",
        "title": "We're Afraid Language Models Aren't Modeling Ambiguity",
        "track": "main",
        "status": "Long Main",
        "keywords": "evaluation;semantics;ambiguity",
        "author": "",
        "aff": "New York University; Paul G. Allen School of Computer Science & Engineering, University of Washington; University of Southern California; Allen Institute for AI; Saarland University; Massachusetts Institute of Technology; UC Berkeley",
        "rating": "",
        "confidence": "2;4;3;4",
        "correctness": "4;5;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/alisawuffles/ambient"
    },
    {
        "id": "w4FwmICSHZ",
        "title": "Multitask Multimodal Prompted Training for Interactive Embodied Task Completion",
        "track": "main",
        "status": "Long Main",
        "keywords": "Vision and Language;Embodied AI;Natural Language Interaction",
        "author": "",
        "aff": "Heriot-Watt University; Heriot-Watt University; Alana AI",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "Code available on this link"
    },
    {
        "id": "w4YwLzuD29",
        "title": "Selecting Key Views for Zero-Shot Entity Linking",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Zero-shot entity linking;Multi-view",
        "author": "",
        "aff": "Institute of Automation, Chinese Academy of Sciences, China; College of Computer Science, VCIP, TMCC, TBI Center, Nankai University, China",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "w8LoOWsbU7",
        "title": "Learning Language-guided Adaptive Hyper-modality Representation for Multimodal Sentiment Analysis",
        "track": "main",
        "status": "Long Main",
        "keywords": "multimodal sentiment analysis;multimodal representation learning",
        "author": "",
        "aff": "Nanyang Technological University; The Chinese University of Hong Kong, Shenzhen; China University of Geosciences, Wuhan",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "wDfXP6uAkR",
        "title": "Towards LLM-driven Dialogue State Tracking",
        "track": "main",
        "status": "Long Main",
        "keywords": "dialogue state tracking;large language models",
        "author": "",
        "aff": "Department of Computing, The Hong Kong Polytechnic University, Hong Kong S.A.R.",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/WoodScene/LDST"
    },
    {
        "id": "wFILOtxmxU",
        "title": "Syntax-Aware Retrieval Augmented Code Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Code Generation;Retrieval Augmented Generation;Neural-Symbolic",
        "author": "",
        "aff": "Birkbeck, University of London; Nanjing University of Aeronautics and Astronautics",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "wFaBjgGqaL",
        "title": "Conceptual structure coheres in human cognition but not in large language models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Models;Cognitive Science;Semantic Norms;Human conceptual structure;AI conceptual structure",
        "author": "",
        "aff": "University of Wisconsin-Madison; Albany State University",
        "rating": "",
        "confidence": "5;4;3",
        "correctness": "5;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.666666666666667,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "wKqdk1sOMY",
        "title": "Execution-Based Evaluation for Open-Domain Code Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "code generation;open domain;execution-based evaluation",
        "author": "",
        "aff": "Language Technologies Institute, Carnegie Mellon University",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "2;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "https://anonymous.4open.science/r/odex-emnlp",
        "github": ""
    },
    {
        "id": "wRwbv3aWzN",
        "title": "VLIS: Unimodal Language Models Guide Multimodal Language Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "visual-language models;image captioning;multimodal understanding;language model decoding",
        "author": "",
        "aff": "Yonsei University",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/JiwanChung/vlis"
    },
    {
        "id": "wV44qtTJ61",
        "title": "Prompt-based Logical Semantics Enhancement for Implicit Discourse Relation Recognition",
        "track": "main",
        "status": "Long Main",
        "keywords": "implicit discourse relation recognition;logical semantics enhancement;prompt-based connective prediction;mutual information maximization",
        "author": "",
        "aff": "School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China; Beijing Engineering Research Center of High Volume Language Information Processing and Cloud Computing Applications, Beijing Institute of Technology, Beijing, China; School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/lalalamdbf/PLSE_IDRR"
    },
    {
        "id": "wWFWwyXElN",
        "title": "LLM-powered Data Augmentation for Enhanced Cross-lingual Performance",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Models;Data Augmentation;Multilingual Commonsense Reasoning",
        "author": "",
        "aff": "MBZUAI; Microsoft; City, University of London",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/mbzuai-nlp/Gen-X"
    },
    {
        "id": "wWT51dSyBj",
        "title": "Gradient-based Gradual Pruning for Language-Specific Multilingual Neural Machine Translation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Multilingual neural machine translation;language-specific sub-network extraction;model pruning;gradual pruning schedule;gradient-based pruning criterion",
        "author": "",
        "aff": "Zoom Video Communications",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "wYdA8CF94e",
        "title": "HalOmi: A Manually Annotated Benchmark for Multilingual Hallucination and Omission Detection in Machine Translation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Hallucination;Omissions;Dataset;Machine Translation",
        "author": "",
        "aff": "FAIR, Meta",
        "rating": "",
        "confidence": "3;5;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "wZKRStVJJe",
        "title": "Toxicity in chatgpt: Analyzing persona-assigned language models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "AI Safety;Toxicity analysis;LLMs",
        "author": "",
        "aff": "The Allen Institute for AI; Princeton University; Georgia Tech",
        "rating": "",
        "confidence": "5;5;4",
        "correctness": "5;5;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "wZmgpJMdb3",
        "title": "DocAsRef: An Empirical Study on Repurposing Reference-based Summary Quality Metrics as Reference-free Metrics",
        "track": "main",
        "status": "Short Findings",
        "keywords": "summarization;evaluation;zero-shot",
        "author": "",
        "aff": "Department of Computer Science, Iowa State University, Ames, IA, USA; School of Data Science and Engineering, East China Normal University, Shanghai, China; Dept. of Computer Sciences, University of Wisconsin\u2013Madison, Madison, WI, USA; ByteDance, China; Sunnyvale, CA, USA",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "wcgfB88Slx",
        "title": "Explanation Selection Using Unlabeled Data for Chain-of-Thought Prompting",
        "track": "main",
        "status": "Long Main",
        "keywords": "Reasoning; In-Context Learning; Chain-of-Thought; Prompting",
        "author": "",
        "aff": "Department of Computer Science, The University of Texas at Austin",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/xiye17/ExplSelection"
    },
    {
        "id": "wcqBfk4jv6",
        "title": "Improving Biomedical Abstractive Summarisation with Knowledge Aggregation from Citation Papers",
        "track": "main",
        "status": "Long Main",
        "keywords": "Biomedical Text Summarisation;Abstractive Summarisation;Knowledge Aggregation;Citation Graph",
        "author": "",
        "aff": "Department of Computer Science, The University of Sheffield, UK; Department of Computer Science, The University of Surrey, UK; Department of Computer Science, The University of Manchester, UK",
        "rating": "",
        "confidence": "2;3;4",
        "correctness": "4;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "wiI8ycNfgJ",
        "title": "LLM-FP4: 4-Bit Floating-Point Quantized Transformers",
        "track": "main",
        "status": "Long Main",
        "keywords": "Model Compression;Model Quantization",
        "author": "",
        "aff": "Hong Kong University of Science and Technology; Meta Reality Labs",
        "rating": "",
        "confidence": "3;4;4;2",
        "correctness": "3;4;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/nbasyl/LLM-FP4"
    },
    {
        "id": "wirDXDQwYZ",
        "title": "Pragmatic Reasoning Unlocks Quantifier Semantics for Foundation Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Pragmatic Reasoning;Rational Speech Act;Quantifier Understanding;Generalized Quantifiers",
        "author": "",
        "aff": "UNC Chapel Hill",
        "rating": "",
        "confidence": "4;2;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Nativeatom/PRESQUE"
    },
    {
        "id": "wnE8wDd61Z",
        "title": "Knowledge Graph Compression Enhances Diverse Commonsense Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "commonsense generation;knowledge graph compression",
        "author": "",
        "aff": "Stony Brook University; MIT-IBM Watson AI Lab, IBM Research; University of British Columbia, Vector Institute for AI",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/eujhwang/KG-Compression"
    },
    {
        "id": "wpjRa3d9OJ",
        "title": "Temporal Knowledge Graph Forecasting Without Knowledge Using In-Context Learning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Temporal Knowledge Graph;In-context Learning;Large Language Model",
        "author": "",
        "aff": "Department of Computer Science and Information Sciences Institute, University of Southern California; Information Sciences Institute, University of Southern California",
        "rating": "",
        "confidence": "3;4;5",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/usc-isi-i2/isi-tkg-icl"
    },
    {
        "id": "wpsbUYi9nN",
        "title": "Large Language Models Know Your Contextual Search Intent: A Prompting Framework for Conversational Search",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Conversational search; passage retrieval; large language models; contextual search intent understanding",
        "author": "",
        "aff": "Gaoling School of Artificial Intelligence, Renmin University of China and Engineering Research Center of Next-Generation Search and Recommendation, MOE; Gaoling School of Artificial Intelligence, Renmin University of China; Institute of Computing Technology, Chinese Academy of Sciences; Universit\u00e9 de Montr\u00e9al, Qu\u00e9bec, Canada",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/kyriemao/LLM4CS"
    },
    {
        "id": "wrBIS6FOfV",
        "title": "MoqaGPT : Zero-Shot Multi-modal Open-domain Question Answering with Large Language Model",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large Language Model;Multimodal;Open-domain question answering",
        "author": "",
        "aff": "Universit\u00e9 de Montr\u00e9al; Mila - Qu\u00e9bec AI Institute",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/lezhang7/MOQAGPT"
    },
    {
        "id": "wtqb7pNL4e",
        "title": "Can ChatGPT Assess Human Personalities? A General Evaluation Framework",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Human personality assessment;Large language models;ChatGPT;Myers\u2013Briggs Type Indicator",
        "author": "",
        "aff": "LILY Research Centre, Nanyang Technological University, Singapore; Department of Electrical and Computer Engineering, The University of British Columbia, Canada; School of Computer Science and Engineering, Nanyang Technological University, Singapore; LILY Research Centre, Nanyang Technological University, Singapore",
        "rating": "",
        "confidence": "1;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Kali-Hac/ChatGPT-MBTI"
    },
    {
        "id": "wwm55qcNdK",
        "title": "SoulChat: Improving LLMs' Empathy, Listening, and Comfort Abilities through Fine-tuning with Multi-turn Empathy Conversations",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Empathy Conversation;Large Language Model;Mental Health AI;Multi-turn Empathetic Conversation Dataset;Psychological Counseling AI",
        "author": "",
        "aff": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "x2W2dKdNI8",
        "title": "Selectively Answering Ambiguous Questions",
        "track": "main",
        "status": "Long Main",
        "keywords": "question answering;calibration;ambiguity",
        "author": "",
        "aff": "Duke University; Google DeepMind; University of Texas",
        "rating": "",
        "confidence": "1;4;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "x32rlkzM69",
        "title": "The Past, Present, and Future of Typological Databases in NLP",
        "track": "main",
        "status": "Short Findings",
        "keywords": "typology;typological feature prediction;large language models",
        "author": "",
        "aff": "McGill University, Mila Quebec AI Institute; Dept. of Computer Science, Aalborg University",
        "rating": "",
        "confidence": "4;2;4",
        "correctness": "2;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "x3e1zQ1ub1",
        "title": "In-Context Demonstration Selection with Cross Entropy Difference",
        "track": "main",
        "status": "Long Findings",
        "keywords": "in-context learning;data selection;peft",
        "author": "",
        "aff": "Microsoft Cognitive Service Research",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/microsoft/LMOps"
    },
    {
        "id": "x6aiktiAl8",
        "title": "Compressing and Debiasing Vision-Language Pre-Trained Models for Visual Question Answering",
        "track": "main",
        "status": "Long Main",
        "keywords": "visual question answering;out-of-distribution;robustness;debiasing",
        "author": "",
        "aff": "National Key Laboratory for Multimedia Information Processing, School of Computer Science, Peking University; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China",
        "rating": "",
        "confidence": "4;3;2;3",
        "correctness": "3;3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/PhoebusSi/Compress-Robust-VQA"
    },
    {
        "id": "x7zquRQfoB",
        "title": "How to Enhance Causal Discrimination of Utterances: A Case on Affective Reasoning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Causal Discrimination;Conversation;Independent Noise;SCM",
        "author": "",
        "aff": "Du Xiao Man Inc.; Xi\u2019an Jiaotong University",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Zodiark-ch/mater-of-our-EMNLP2023-paper"
    },
    {
        "id": "x9BmfezTvD",
        "title": "Debiasing Made State-of-the-art: Revisiting the Simple Seed-based Weak Supervision for Text Classification",
        "track": "main",
        "status": "Long Main",
        "keywords": "text classification;weak supervision;label noise;label bias",
        "author": "",
        "aff": "University of California San Diego",
        "rating": "",
        "confidence": "2;4;2",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/shwinshaker/SimSeed"
    },
    {
        "id": "xCXlOmGimw",
        "title": "Diversity Enhanced Narrative Question Generation for Storybooks",
        "track": "main",
        "status": "Long Main",
        "keywords": "Question Generation;Natural Language Generation;NLP applications",
        "author": "",
        "aff": "Sungkyunkwan University, Suwon, South Korea",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "5;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/hkyoon95/mQG"
    },
    {
        "id": "xDfyOL1unK",
        "title": "NovaCOMET: Open Commonsense Foundation Models with Symbolic Knowledge Distillation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Knowledge;Commonsense;Distillation;Model;Symbolic",
        "author": "",
        "aff": "Paul G. Allen School of Computer Science & Engineering, University of Washington; Allen Institute for Artificial Intelligence",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "novacomet.dev",
        "github": ""
    },
    {
        "id": "xF6ORNff2k",
        "title": "Adaptive Structure Induction for Aspect-based Sentiment Analysis with Spectral Perspective",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Sentiment analysis;Spectral analysis;Structure induction",
        "author": "",
        "aff": "Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University",
        "rating": "",
        "confidence": "5;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/hankniu01/FLT"
    },
    {
        "id": "xJ3O94DnMZ",
        "title": "Make Your Decision Convincing! A Unified Two-Stage Framework: Self-Attribution and Decision-Making",
        "track": "main",
        "status": "Long Findings",
        "keywords": "rationale;reliable link;two-stage framework",
        "author": "",
        "aff": "Harbin Institute of Technology, Harbin, China",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "xKRg5dfWyv",
        "title": "Bootstrapping Small \\& High Performance Language Models with Unmasking-Removal Training Policy",
        "track": "main",
        "status": "Short Main",
        "keywords": "language models;efficient pre-training;masking policy",
        "author": "",
        "aff": "Department of Software and Information Systems Engineering, Ben-Gurion University of the Negev; Department of Computer and Information Science, University of Pennsylvania",
        "rating": "",
        "confidence": "2;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/yangy96/babyberta_continual"
    },
    {
        "id": "xL8SLt02mt",
        "title": "An Expression Tree Decoding Strategy for Mathematical Equation Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Expression tree;Equation;Parallel Decoding;Math Word Problem",
        "author": "",
        "aff": "College of Computer Science and Technology, Zhejiang University; Zhongxing Telecommunication Equipment Corporation; University of Shanghai for Science and Technology",
        "rating": "",
        "confidence": "3;4;2",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "xMudYCcBum",
        "title": "Using Interpretation Methods for Model Enhancement",
        "track": "main",
        "status": "Long Main",
        "keywords": "interpretation methods;few-shot",
        "author": "",
        "aff": "School of Information Science and Technology, ShanghaiTech University, Shanghai Engineering Research Center of Intelligent Vision and Imaging; School of Information Science and Technology, ShanghaiTech University",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Chord-Chen-30/UIMER"
    },
    {
        "id": "xNzu8DivUj",
        "title": "Continually Improving Extractive QA via Human Feedback",
        "track": "main",
        "status": "Long Main",
        "keywords": "QA;human feedback;bandit learning",
        "author": "",
        "aff": "Department of Computer Science, The University of Texas at Austin; Department of Computer Science and Cornell Tech, Cornell University",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "xOyBEJq0O8",
        "title": "GATITOS: Using a New Multilingual Lexicon for Low-resource Machine Translation",
        "track": "main",
        "status": "Long Main",
        "keywords": "machine translation;low-resource;lexicons;dictionaries;unsupervised;NMT;MT;data augmentation",
        "author": "",
        "aff": "Google Research",
        "rating": "",
        "confidence": "4;4;3;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/google-research/url-nlp/tree/main/gatitos"
    },
    {
        "id": "xQbFsx8usC",
        "title": "Temporal Knowledge Graph Reasoning Based on N-tuple Modeling",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Knowledge graph;n-ary temporal knowledge graph;graph convolution network",
        "author": "",
        "aff": "Tencent Inc.; CAS Key Laboratory of Network Data Science and Technology, Institute of Computing Technology, Chinese Academy of Sciences; School of Computer Science and Technology, University of Chinese Academy of Sciences; CAS Key Laboratory of Network Data Science and Technology, Institute of Computing Technology, Chinese Academy of Sciences",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "xVMV2IYbWH",
        "title": "An Adaptive Prompt Generation Framework for Task-oriented Dialogue System",
        "track": "main",
        "status": "Long Findings",
        "keywords": "adaptive prompt;LLM;task-oriented dialogue;black-box;prompt learning",
        "author": "",
        "aff": "Didi chuxing; School of Computer Science and Engineering, Beihang University; School of Artificial Intelligence, Beijing University of Posts and Telecommunications",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "2;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "xX2KjzdFPH",
        "title": "Improving Image Captioning via Predicting Structured Concepts",
        "track": "main",
        "status": "Long Main",
        "keywords": "Image captioning;GCN",
        "author": "",
        "aff": "University of Science and Technology of China; University of Washington",
        "rating": "",
        "confidence": "3;4;5;5",
        "correctness": "3;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/wangting0/SCP-WGCN"
    },
    {
        "id": "xapBkUt0yf",
        "title": "CompoundPiece: Evaluating and Improving Decompounding Performance of Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "segmentation;multilinguality;tokenization;compound;compounds",
        "author": "",
        "aff": "University of Cambridge; Google DeepMind",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "xarWXEhhdy",
        "title": "Self-supervised Meta-Prompt Learning with Meta-Gradient Regularization for Few-shot Generalization",
        "track": "main",
        "status": "Long Findings",
        "keywords": "prompt tuning;self-supervised meta-learning;meta-gradient regularization",
        "author": "",
        "aff": "Worcester Polytechnic Institute; Zhejiang University; Zhejiang University, DAMO Academy, Alibaba Group; DAMO Academy, Alibaba Group",
        "rating": "",
        "confidence": "4;2;3;3",
        "correctness": "4;3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/beepkh/SUPMER"
    },
    {
        "id": "xbnNgqGefc",
        "title": "Discourse Structures Guided Fine-grained Propaganda Identification",
        "track": "main",
        "status": "Long Main",
        "keywords": "misinformation;propaganda;discourse structure",
        "author": "",
        "aff": "Department of Computer Science and Engineering, Texas A&M University, College Station, TX",
        "rating": "",
        "confidence": "4;5;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/yuanyuanlei-nlp/propaganda_emnlp_2023"
    },
    {
        "id": "xeecFHJ4d4",
        "title": "IRFL: Image Recognition of Figurative Language",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Figurative Language;Multimodal Figurative Language;Resources",
        "author": "",
        "aff": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "xfTQmGPPtQ",
        "title": "Parameter-efficient Tuning for Large Language Model without Calculating Its Gradients",
        "track": "main",
        "status": "Long Main",
        "keywords": "Parameter-efficient Tuning;Large Language Model;Gradient-free",
        "author": "",
        "aff": "Institute of Automation, Chinese Academy of Sciences; School of Artificial Intelligence, University of Chinese Academy of Sciences; Institute of Automation, Chinese Academy of Sciences; School of Artificial Intelligence, University of Chinese Academy of Sciences; Wuhan AI Research; Shanghai Artificial Intelligence Laboratory; Institute of Automation, Chinese Academy of Sciences; School of Artificial Intelligence, University of Chinese Academy of Sciences; PhD student in Peking University",
        "rating": "",
        "confidence": "4;2;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "xhqICRykZk",
        "title": "Text Augmented Spatial Aware Zero-shot Referring Image Segmentation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Zero-shot Referring Image Segmentation;Multi-modal Learning;Visual-text Matching",
        "author": "",
        "aff": "Zhejiang University, Hangzhou, China",
        "rating": "",
        "confidence": "4;3;2",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "xlg5jVmPSg",
        "title": "Towards A Holistic Landscape of Situated Theory of Mind in Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "theory of mind;large language models;mental states",
        "author": "",
        "aff": "Computer Science and Engineering Division, University of Michigan",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "xn8NKZosDV",
        "title": "Event Ontology Completion with Hierarchical Structure Evolution Networks",
        "track": "main",
        "status": "Long Main",
        "keywords": "Event Ontology Completion;Event Type Induction;Hierarchy Expansion;Type Naming",
        "author": "",
        "aff": "China Merchants Bank; The Laboratory of Cognition and Decision Intelligence for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China",
        "rating": "",
        "confidence": "5;2;2",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/CPF-NLPR/HALTON"
    },
    {
        "id": "xozJw0kZXF",
        "title": "Evaluating Object Hallucination in Large Vision-Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Vision-Language Model;Object Hallucination",
        "author": "",
        "aff": "School of Information, Renmin University of China; Gaoling School of Artificial Intelligence, Renmin University of China; Meituan Group",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "xp4wEivhM9",
        "title": "Is a Prestigious Job the same as a Prestigious Country? A Case Study on Multilingual Sentence Embeddings and European Countries",
        "track": "main",
        "status": "Short Findings",
        "keywords": "multilngual language models;nationality bias;sentence representation",
        "author": "",
        "aff": "Institute of Formal and Applied Linguistics, Faculty of Mathematics and Physics, Charles University, Czech Republic",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/jlibovicky/europe-in-sentence-embeddings"
    },
    {
        "id": "xxTtwEuOpS",
        "title": "Understanding Compositional Data Augmentation in Typologically Diverse Morphological Inflection",
        "track": "main",
        "status": "Long Main",
        "keywords": "morphological inflection;computational morphology;data augmentation",
        "author": "",
        "aff": "Natural Language Processing Group, University of British Columbia",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/smfsamir/understanding-augmentation-morphology"
    },
    {
        "id": "xyvTFX7hDs",
        "title": "Cultural Concept Adaptation on Multimodal Reasoning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Cross-cultural;Adaptation;Low-resource;Multi-modal;Data augmentation",
        "author": "",
        "aff": "College of Computer Science and Technology, Zhejiang University, China",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "xzveggFhiQ",
        "title": "Multi-Modal Knowledge Graph Transformer Framework for Multi-Modal Entity Alignment",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multi-Modal Entity Alignment;Multi-Modal Knowledge Graph;Transformer",
        "author": "",
        "aff": "School of Computer Science and Technology, University of Chinese Academy of Sciences; National Computer Network Emergency Response Technical Team/Coordination Center of China; School of Computer Science and Engineering, Beihang University, Beijing, China; Beijing Advanced Innovation Center for Big Data and Brain Computing, Beijing, China",
        "rating": "",
        "confidence": "3;3;5",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "y0P5KXN5X1",
        "title": "Factual Relation Discrimination for Factuality-oriented Abstractive Summarization",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Factuality-oriented Abstractive Summarization;Factual Relation Discrimination",
        "author": "",
        "aff": "School of Computer Science and Technology, Soochow University, Suzhou, China; School of Data Science, The Chinese University of Hong Kong, Shenzhen, China",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "y2V6YgLaW7",
        "title": "The Internal State of an LLM Knows When It's Lying",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large Language Models;hallucination in LLM;LLM veracity;LLM activations",
        "author": "",
        "aff": "School of Computer Science, Ariel University, Israel; Machine Learning Dept., Carnegie Mellon University, Pittsburgh, PA",
        "rating": "",
        "confidence": "4;4;3;2",
        "correctness": "4;3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "y34lg6q50A",
        "title": "Fusing Temporal Graphs into Transformers for Time-Sensitive Question Answering",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Time-sensitive Question Answering;Temporal Graph Fusion;Temporal Reasoning",
        "author": "",
        "aff": "University of Arizona; Intel Labs",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "y5UTUcTQU5",
        "title": "Dual-Channel Span for Aspect Sentiment Triplet Extraction",
        "track": "main",
        "status": "Long Main",
        "keywords": "aspect sentiment triplet extraction;dual-channel;span generation;noise reduction",
        "author": "",
        "aff": "School of Computer Science, Southwest Petroleum University, Chengdu, China; School of Computer Science and Technology, East China Normal University, Shanghai, China",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/bert-ply/Dual_Span"
    },
    {
        "id": "y5ctUSk99X",
        "title": "GPTAraEval: A Comprehensive Evaluation of ChatGPT on Arabic NLP",
        "track": "main",
        "status": "Long Main",
        "keywords": "Arabic NLP;Arabic Dialects;ChatGPT;GPT4",
        "author": "",
        "aff": "Deep Learning & Natural Language Processing Group, The University of British Columbia; Department of Natural Language Processing & Department of Machine Learning, MBZUAI",
        "rating": "",
        "confidence": "5;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "y6Ej5BZkrR",
        "title": "Let's Think Frame by Frame with VIP: A Video Infilling and Prediction Dataset for Evaluating Video Chain-of-Thought",
        "track": "main",
        "status": "Long Main",
        "keywords": "chain of thought;video reasoning;large language models;dataset;vision and language",
        "author": "",
        "aff": "University of California, Santa Barbara",
        "rating": "",
        "confidence": "4;4;2",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/vaishnaviHimakunthala/VIP"
    },
    {
        "id": "y8ebFPsyET",
        "title": "TESTA: Temporal-Spatial Token Aggregation for Long-form Video-Language Understanding",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Video-Language Understanding;Token Aggregation;Long-form Video Understanding",
        "author": "",
        "aff": "National Key Laboratory for Multimedia Information Processing, School of Computer Science, Peking University; Huawei Noah\u2019s Ark Lab; Center for Data Science, Peking University",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/RenShuhuai-Andy/TESTA"
    },
    {
        "id": "yAZSZob2dN",
        "title": "Boot and Switch: Alternating Distillation for Zero-Shot Dense Retrieval",
        "track": "main",
        "status": "Long Findings",
        "keywords": "dense retrieval;iterated learning;alternating distillation;bootstrapping",
        "author": "",
        "aff": "School of Computing and Information Systems, The University of Melbourne, Victoria, Australia",
        "rating": "",
        "confidence": "4;4;2",
        "correctness": "2;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Fantabulous-J/BootSwitch"
    },
    {
        "id": "yB8cQIICqe",
        "title": "EZ-STANCE: A Large Dataset for Zero-Shot Stance Detection",
        "track": "main",
        "status": "Long Findings",
        "keywords": "dataset;stance detection;zero-shot",
        "author": "",
        "aff": "EMNLP submission",
        "rating": "",
        "confidence": "3;4;5",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "Not provided",
        "github": "Not provided"
    },
    {
        "id": "yBd2UREDNL",
        "title": "MixTEA: Semi-supervised Entity Alignment with Mixture Teaching",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Knowledge Graph;Entity Alignment;Knowledge Representation",
        "author": "",
        "aff": "College of Computer, National University of Defense Technology",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "yDeIWA7ICp",
        "title": "Social Commonsense-Guided Search Query Generation for Open-Domain Knowledge-Powered Conversations",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Conversational AI;Knowledge-Powered Dialog;Commonsense Knowledge",
        "author": "",
        "aff": "University of Illinois at Urbana-Champaign",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/gangiswag/dialog-query-generation"
    },
    {
        "id": "yE44WcphJY",
        "title": "Dissecting In-Context Learning of Translations in GPT-3",
        "track": "main",
        "status": "Short Findings",
        "keywords": "translation;large language models;in context learning",
        "author": "",
        "aff": "Microsoft Azure AI, Redmond, Washington",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "yF3lSXb82y",
        "title": "InvGC: Robust Cross-Modal Retrieval by Inverse Graph Convolution",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Cross-Modal Retrieval;Data Degeneration;Graph Convolution",
        "author": "",
        "aff": "University of Waterloo",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "link"
    },
    {
        "id": "yKLUvxMCQ3",
        "title": "Establishing Trustworthiness: Rethinking Tasks and Model Evaluation",
        "track": "main",
        "status": "Short Main",
        "keywords": "Trustworthiness;Tasks;Evaluation;Skills;Trust",
        "author": "",
        "aff": "MaiNLP, Center for Information and Language Processing, LMU Munich, Germany; Department of Computer Science, IT University of Copenhagen, Denmark; Department of Computer Science, IT University of Copenhagen, Denmark; MaiNLP, Center for Information and Language Processing, LMU Munich, Germany; Munich Center for Machine Learning (MCML), Munich, Germany",
        "rating": "",
        "confidence": "4;2;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "yO4cAfFjlp",
        "title": "Theory of Mind for Multi-Agent Collaboration via Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Models;Multi-Agent Reinforcement Learning;Theory of Mind",
        "author": "",
        "aff": "Carnegie Mellon University, Pittsburgh, PA; University of Pittsburgh, Pittsburgh, PA",
        "rating": "",
        "confidence": "2;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "yThuxNysaJ",
        "title": "DelucionQA: Detecting Hallucinations in Domain-specific Question Answering",
        "track": "main",
        "status": "Long Findings",
        "keywords": "hallucination;LLM;large-language-model;natural-language-generation;question-answering",
        "author": "",
        "aff": "Computer Science, University of Illinois Chicago; Bosch Research North America & Bosch Center for Artificial Intelligence (BCAI); UNC Chapel-Hill",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/boschresearch/DelucionQA"
    },
    {
        "id": "yVoLLzLwdp",
        "title": "Is ChatGPT a Financial Expert? Evaluating Language Models on Financial Natural Language Processing",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Financial Natural Language Processing;Large Language Models;ChatGPT",
        "author": "",
        "aff": "The Hong Kong University of Science and Technology",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "2;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "yXVLsdvyg9",
        "title": "Improving Question Generation with Multi-level Content Planning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "questin generation;multi-level content planning",
        "author": "",
        "aff": "Alibaba Group; State Key Laboratory for Novel Software Technology, Nanjing University, China",
        "rating": "",
        "confidence": "3;4;5;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/zeaver/MultiFactor"
    },
    {
        "id": "yXYJPAlLqn",
        "title": "Sparse Universal Transformer",
        "track": "main",
        "status": "Long Main",
        "keywords": "efficient UT;transformers;sparse moe;conditional computation;NLP;wmt14;cfq;compositional generalization;natural language processing;sparse",
        "author": "",
        "aff": "Mila, University of Montreal; MIT-IBM Watson AI Lab",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;5;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "ybc9V6Cbq2",
        "title": "Better Quality Pre-training Data and T5 Models for African Languages",
        "track": "main",
        "status": "Short Main",
        "keywords": "multilingual;low-resource languages;african languages",
        "author": "",
        "aff": "University of Washington; Masakhane; University of Waterloo",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/castorini/AfriTeVa-keji"
    },
    {
        "id": "yjqgHcTLnP",
        "title": "ARKitSceneRefer: Text-based Localization of Small Objects in Diverse Real-World 3D Indoor Scenes",
        "track": "main",
        "status": "Long Findings",
        "keywords": "3D;Dataset;Visual Grounding;Referring Expression Comprehension",
        "author": "",
        "aff": "Kyoto University; RIKEN",
        "rating": "",
        "confidence": "2;5;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/ku-nlp/ARKitSceneRefer"
    },
    {
        "id": "ytQFU2XsBR",
        "title": "Automatic Model Selection with Large Language Models for Reasoning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large Language Models;In-Context Learning;Reasoning",
        "author": "",
        "aff": "National University of Singapore; The Hong Kong University of Science and Technology",
        "rating": "",
        "confidence": "3;4;4;3",
        "correctness": "4;2;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/XuZhao0/Model-Selection-Reasoning"
    },
    {
        "id": "z1RYLqEpuP",
        "title": "Evaluating and Modeling Attribution for Cross-Lingual Question Answering",
        "track": "main",
        "status": "Long Main",
        "keywords": "Attribution;Cross-Lingual Question Answering;Multilingual Modeling;Open-Retrieval Question Answering;Attribution Detection",
        "author": "",
        "aff": "INRIA Paris; Google DeepMind; Google Research",
        "rating": "",
        "confidence": "2;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/google-research/google-research/tree/master/xor_attriqa"
    },
    {
        "id": "z2JVmJ6Tlq",
        "title": "Self-supervised Post-processing Method to Enrich Pretrained Word Vectors",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Retrofitting;Word Embedding;Word Semantics",
        "author": "",
        "aff": "NAVER, Search US",
        "rating": "",
        "confidence": "2;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "http://github.com/hwiyeoljo/SelfExtro"
    },
    {
        "id": "z69tlSxAwf",
        "title": "Novel Slot Detection With an Incremental Setting",
        "track": "main",
        "status": "Long Findings",
        "keywords": "dialog system; novel slot detection; incremental learning",
        "author": "",
        "aff": "Beijing Key Lab of Traffic Data Analysis and Mining, Beijing Jiaotong University, Beijing, China; Tencent AI Lab; Platform and Content Group, Tencent, China",
        "rating": "",
        "confidence": "4;4;4;3",
        "correctness": "3;3;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/cs-liangchen-work/NovelIE"
    },
    {
        "id": "z8gM4ZfK8l",
        "title": "Improving Cross-lingual Transfer through Subtree-aware Word Reordering",
        "track": "main",
        "status": "Long Findings",
        "keywords": "multilingual;cross lingual;cross lingual transfer;reordering;syntax",
        "author": "",
        "aff": "Hebrew University of Jerusalem; IMS, University of Stuttgart",
        "rating": "",
        "confidence": "4;2;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/OfirArviv/ud-based-word-reordering"
    },
    {
        "id": "z9CqYTwOiO",
        "title": "Solving the Right Problem is Key for Translational NLP: A Case Study in UMLS Vocabulary Insertion",
        "track": "main",
        "status": "Long Findings",
        "keywords": "biomedical NLP;translational NLP;synonymy prediction;knowledge base construction",
        "author": "",
        "aff": "The Ohio State University; National Library of Medicine",
        "rating": "",
        "confidence": "3;5;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/OSU-NLP-Group/UMLS-Vocabulary-Insertion"
    },
    {
        "id": "z9l6nHpTyT",
        "title": "Adapter-TST: A Parameter Efficient Method for Multiple-Attribute Text Style Transfer",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Text style transfer;Parameter-efficient;Adapter",
        "author": "",
        "aff": "Singapore University of Technology and Design, Singapore; Institute of Infocomm Research (I2R), A*STAR, Singapore",
        "rating": "",
        "confidence": "4;5;5",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/Social-AI-Studio/Adapter-TST"
    },
    {
        "id": "zByqDt16qZ",
        "title": "Evaluating the Rationale Understanding of Critical Reasoning in Logical Reading Comprehension",
        "track": "main",
        "status": "Long Main",
        "keywords": "natural language understanding;reading comprehension;evaluation;dataset;rationale",
        "author": "",
        "aff": "National Institute of Informatics; The Asahi Shimbun Company",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "zEJFYWWmbG",
        "title": "Primacy Effect of ChatGPT",
        "track": "main",
        "status": "Short Main",
        "keywords": "Primacy Effect;ChatGPT;Large Language Models;Natural Language Understanding",
        "author": "",
        "aff": "University of California, Los Angeles; National University of Singapore; Hong Kong University of Science and Technology (Guangzhou); Meta; University of California, Davis",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/wangywUST/PrimacyEffectGPT"
    },
    {
        "id": "zIb2DlqBxm",
        "title": "PHD: Pixel-Based Language Modeling of Historical Documents",
        "track": "main",
        "status": "Long Main",
        "keywords": "Visual language modelling;Historical documents;Multimodal models",
        "author": "",
        "aff": "Department of Computer Science, University of Copenhagen",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "zIgc1Qeceh",
        "title": "Holistic Inter-Annotator Agreement and Corpus Coherence Estimation in a Large-scale Multilingual Annotation Campaign",
        "track": "main",
        "status": "Long Main",
        "keywords": "persuasion techniques;annotation;inter-annotator agreement;data quality;IAA",
        "author": "",
        "aff": "European Commission Joint Research Centre, Text and Data Mining Unit, Ispra, Italy; Institute for Computer Science, Polish Academy of Sciences, Warsaw, Poland",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;5;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "zLAHDHhgLa",
        "title": "Fine-grained Conversational Decoding via Isotropic and Proximal Search",
        "track": "main",
        "status": "Short Main",
        "keywords": "text generation; dialogue system; decoding strategy",
        "author": "",
        "aff": "City University of Hong Kong",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "zM3mlyflTt",
        "title": "Approximating Two-Layer Feedforward Networks for Efficient Transformers",
        "track": "main",
        "status": "Long Findings",
        "keywords": "transformers;moe;mixture of experts;pkm;product key memories;approximate computation;efficient transformers;language modelling",
        "author": "",
        "aff": "Harvard University; The Swiss AI Lab IDSIA, USI & SUPSI; The Swiss AI Lab IDSIA, USI & SUPSI, AI Initiative, KAUST",
        "rating": "",
        "confidence": "2;4;2;3",
        "correctness": "3;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/robertcsordas/moemethods"
    },
    {
        "id": "zSUOfRVl28",
        "title": "Decoding the Silent Majority: Inducing Belief Augmented Social Graph with Large Language Model for Response Forecasting",
        "track": "main",
        "status": "Long Main",
        "keywords": "Response Forecasting;Social Media;Social Network;Language Model;ChatGPT;Personalization;Response Prediction",
        "author": "",
        "aff": "University of Illinois Urbana-Champaign",
        "rating": "",
        "confidence": "4;3;3;3",
        "correctness": "3;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/chenkaisun/SocialSense"
    },
    {
        "id": "zVi11zjaPe",
        "title": "EIT: Enhanced Interactive Transformer",
        "track": "main",
        "status": "Reject",
        "keywords": "Transformer; Multi-head self-attention; Multi-view learning;",
        "author": "",
        "aff": "EMNLP submission",
        "rating": "",
        "confidence": "4;3;3;4",
        "correctness": "3;4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "zWGDn1AmRH",
        "title": "ReFSQL: A Retrieval-Augmentation Framework for Text-to-SQL Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Text-to-SQL;Retrieval-Augmentation",
        "author": "",
        "aff": "Data Intelligence System Research Center, Institute of Computing Technology, Chinese Academy of Sciences; School of Computer Science and Technology, University of Chinese Academy of Sciences; Big Data Academy, Zhongke; Data Intelligence System Research Center, Institute of Computing Technology, Chinese Academy of Sciences; School of Computer Science and Technology, University of Chinese Academy of Sciences; Ant Group; Big Data Academy, Zhongke",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "zaBPb6Pu21",
        "title": "Chinese Lexical Substitution: Dataset and Method",
        "track": "main",
        "status": "Long Main",
        "keywords": "Lexical substitution;Chinese writing assistance;Substitution generation",
        "author": "",
        "aff": "China Academy of Electronic and Information Technology, Beijing 100041, China; School of Information Engineering, Yangzhou University, Yangzhou, China",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "zdMislOLTv",
        "title": "Zero-Shot-BERT-Adapters: a Zero-Shot Pipeline for Unknown Intent Detection",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Zero Shot;Intent Detection;Emerging Intents;BERT;Adapters;NLP;Multiligual",
        "author": "",
        "aff": "IBM Research Europe; IBM Consulting Italy",
        "rating": "",
        "confidence": "4;2;3",
        "correctness": "3;2;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 1.0,
        "confidence_avg": 3.0,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/GT4SD/zero-shot-bert-adapters"
    },
    {
        "id": "zeGXjQYhXz",
        "title": "Video-Text Retrieval by Supervised Sparse Multi-Grained Learning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Video-Text Retrieval;Multimodal Learning",
        "author": "",
        "aff": "University of Waterloo",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "1;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "link"
    },
    {
        "id": "zpayaLaUhL",
        "title": "Absolute Position Embedding Learns Sinusoid-like Waves for Attention Based on Relative Position",
        "track": "main",
        "status": "Long Main",
        "keywords": "position embedding;attention mechanism;Transformer;BERT;RoBERTa",
        "author": "",
        "aff": "Tokyo University of Science",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "5;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    },
    {
        "id": "zrBrl2iQUr",
        "title": "Crossing the Aisle: Unveiling Partisan and Counter-Partisan Events in News Reporting",
        "track": "main",
        "status": "Short Findings",
        "keywords": "partisan event;media bias",
        "author": "",
        "aff": "Computer Science and Engineering, University of Michigan, Ann Arbor, MI; Department of Computer Science, University of Hawaii at Hilo, Hilo, HI; Department of Political Science, Northeastern University, Boston, MA",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": "https://github.com/launchnlp/Partisan-Event-Dataset"
    },
    {
        "id": "zwqDROxClj",
        "title": "IAG: Induction-Augmented Generation Framework for Answering Reasoning Questions",
        "track": "main",
        "status": "Long Main",
        "keywords": "Open-domain question answering;Inductive reasoning;Prompting",
        "author": "",
        "aff": "Huawei Poisson Lab, China",
        "rating": "",
        "confidence": "4;3;5;4",
        "correctness": "4;3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0,
        "project": "",
        "github": ""
    }
]