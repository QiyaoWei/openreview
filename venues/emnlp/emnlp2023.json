[
    {
        "id": "01wSNY5T60",
        "title": "Are Compressed Language Models Less Subgroup Robust?",
        "track": "main",
        "status": "Short Main",
        "keywords": "Language Model Compression;Subgroup Robustness",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "05vb8rwGct",
        "title": "Towards Informative Few-Shot Prompt with Maximum Information Gain for In-Context Learning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large Language Model;In-context Learning;Information Gain",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "06oozRd4jU",
        "title": "Graph vs. Sequence: An Empirical Study on Knowledge Forms for Knowledge-Grounded Dialogue",
        "track": "main",
        "status": "Long Main",
        "keywords": "Knowledge-Grounded Dialogue;Empirical Study",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "0C5C70C3n8",
        "title": "Mitigating Intrinsic Named Entity-Related Hallucinations of Abstractive Text Summarization",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Abstractive text summarization;named entity-related hallucinations;adaptive margin ranking loss",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4;4",
        "correctness": "3;3;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "0DkaimvWs0",
        "title": "Contrastive Pre-training for Personalized Expert Finding",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Expert Finding;Recommender Systems;Community Question Answering;Pre-training",
        "authors": "",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "0DyJbE93XO",
        "title": "A Thorough Examination on Zero-shot Dense Retrieval",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Zero-shot dense retrieval; Information retrieval",
        "authors": "",
        "rating": "",
        "confidence": "1;2;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "0EQ4z8n5rp",
        "title": "Global Voices, Local Biases: Socio-Cultural Prejudices across Languages",
        "track": "main",
        "status": "Long Main",
        "keywords": "bias;multilinguality;language models",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "0GO8Dtl8lJ",
        "title": "Unleashing the Multilingual Encoder Potential: Boosting Zero-Shot Performance via Probability Calibration",
        "track": "main",
        "status": "Short Findings",
        "keywords": "prompt learning;multilingual encoders;calibration",
        "authors": "",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "0JepdeBcDk",
        "title": "An Attribution Method for Siamese Encoders",
        "track": "main",
        "status": "Short Main",
        "keywords": "feature attribution;interpretability;explainability;siamese encoder;sentence transformer;integrated gradients;integrated Jacobians",
        "authors": "",
        "rating": "",
        "confidence": "3;2;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "0KYSlQdMu6",
        "title": "TacoPrompt: A Collaborative Multi-Task Prompt Learning Method for Self-Supervised Taxonomy Completion",
        "track": "main",
        "status": "Long Main",
        "keywords": "Taxonomy completion;prompt learning;self-supervised learning;multi-task learning",
        "authors": "",
        "rating": "",
        "confidence": "3;4;5;3",
        "correctness": "3;3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "0LXEvcD3dB",
        "title": "SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal Conversational Abilities",
        "track": "main",
        "status": "Long Findings",
        "keywords": "large language model;speech;multi-modal",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "0M2m9GUTLN",
        "title": "Fair Text Classification with Wasserstein Independence",
        "track": "main",
        "status": "Long Main",
        "keywords": "Text Classification;Fairness;Wasserstein",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "0ODPaEbHxG",
        "title": "Measuring Pointwise $\\mathcal{V}$-Usable Information In-Context-ly",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Hardness;Pointwise V-Usable Information;In-Context Learning",
        "authors": "",
        "rating": "",
        "confidence": "2;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "0OtGfwj8eB",
        "title": "Reinforcement Replaces Supervision: Query focused Summarization using Deep Reinforcement Learning",
        "track": "main",
        "status": "Long Main",
        "keywords": "reinforcement learning for long text;query focused summarization;passage embedding;long form question answering",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "0Rdp7a3y2H",
        "title": "Adversarial Text Generation by Search and Learning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Adversarial robustness;Adversarial training;Unsupervised Text Generation",
        "authors": "",
        "rating": "",
        "confidence": "2;4;2",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "0SF6Kr1lrx",
        "title": "Leap-of-Thought: Accelerating Transformers via Dynamic Token Routing",
        "track": "main",
        "status": "Long Main",
        "keywords": "transformer;language models;token routing;token pruning;input length reduction",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "0SIyWZEOmJ",
        "title": "The Linearity of the Effect of Surprisal on Reading Times across Languages",
        "track": "main",
        "status": "Short Findings",
        "keywords": "psycholinguistics;surprisal theory;linearity;reading time;cross-linguistic",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "0ULLuIRdcu",
        "title": "ClimateBERT-NetZero: Detecting and Assessing Net Zero and Reduction Targets",
        "track": "main",
        "status": "Short Main",
        "keywords": "ClimateBERT;BERT;climate change;net zero",
        "authors": "",
        "rating": "",
        "confidence": "4;5;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "0VQImEvjPJ",
        "title": "NormDial: A Comparable Bilingual Synthetic Dialog Dataset for Modeling Social Norm Adherence and Violation",
        "track": "main",
        "status": "Short Main",
        "keywords": "social norms;resources and evaluation;large language models",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "0W2aSP6y3x",
        "title": "Vision-Enhanced Semantic Entity Recognition in Document Images via Visually-Asymmetric Consistency Learning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Visually rich documents;Information extraction;Consistency Learning;Multimodality",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3;4",
        "correctness": "4;2;3;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "0aiFUPYan3",
        "title": "VER: Unifying Verbalizing Entities and Relations",
        "track": "main",
        "status": "Long Findings",
        "keywords": "definition modeling;relation modeling;entity relationships",
        "authors": "",
        "rating": "",
        "confidence": "5;4;2",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "0b2chPXfVG",
        "title": "Orca: A Few-shot Benchmark for Chinese Conversational Machine Reading Comprehension",
        "track": "main",
        "status": "Long Findings",
        "keywords": "dataset;conversational machine reading comprehension",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "0bderX6zwr",
        "title": "FFAEval: Evaluating Dialogue System via Free-For-All Ranking",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Human Evaluation;Dialogue System Evaluation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "3;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "0duz9dhwRc",
        "title": "Stance Detection on Social Media with Background Knowledge",
        "track": "main",
        "status": "Long Main",
        "keywords": "Stance Detection;Knowledge Augmentation;Background Knowledge",
        "authors": "",
        "rating": "",
        "confidence": "5;4;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "0eWQVWvPgu",
        "title": "Unveiling the Power of Argument Arrangement in Online Persuasive Discussions",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Argument Mining;Persuasive Dialogues;Persuasion Strategies;ChangeMyView",
        "authors": "",
        "rating": "",
        "confidence": "5;2;2",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "0hTPJBnncc",
        "title": "MQuAKE: Assessing Knowledge Editing in Language Models via Multi-Hop Questions",
        "track": "main",
        "status": "Long Main",
        "keywords": "Knowledge Editing;Multi-hop Question Answering;Language Models",
        "authors": "",
        "rating": "",
        "confidence": "3;5;4;4",
        "correctness": "4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "0hyn6MJmnP",
        "title": "TADI: Topic-aware Attention and Powerful Dual-encoder Interaction for Recall in News Recommendation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "news recommendation;recommendation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "0iRgUfkwp3",
        "title": "Causal Intervention-based Few-Shot Named Entity Recognition",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Causal Intervention;Few-Shot Learning;Named Entity Recognition",
        "authors": "",
        "rating": "",
        "confidence": "5;3;3",
        "correctness": "2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "0ii51brFyn",
        "title": "Enhanced Simultaneous Machine Translation with Word-level Policies",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Simultaneous Machine Translation;word-level policies",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "0isMLQIUpQ",
        "title": "Is ChatGPT the ultimate Data Augmentation Algorithm?",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Data augmentation;ChatGPT;GPT-3.5;classification;T5",
        "authors": "",
        "rating": "",
        "confidence": "3;2;5",
        "correctness": "3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "0juZSwZLA4",
        "title": "ScdNER: Span-Based Consistency-Aware Document-Level Named Entity Recognition",
        "track": "main",
        "status": "Short Main",
        "keywords": "named entity recognition;span-based;document-level;consistency-aware",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "0kseDcA5Nm",
        "title": "Give Me the Facts! A Survey on Factual Knowledge Probing in Pre-trained Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "factual knowledge probing",
        "authors": "",
        "rating": "",
        "confidence": "1;1;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 2.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "0lE7w8RJDw",
        "title": "Learning Knowledge-Enhanced Contextual Language Representations for Domain Natural Language Understanding",
        "track": "main",
        "status": "Long Main",
        "keywords": "Closed-domain;Pre-trained Language Model;Knowledge Graph",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "0n92zm014A",
        "title": "Self-ICL: Zero-Shot In-Context Learning with Self-Generated Demonstrations",
        "track": "main",
        "status": "Long Main",
        "keywords": "in-context learning;zero-shot;bootstrapping",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "0sDieI5GJh",
        "title": "QUADRo: Dataset and Models for QUestion-Answer Database Retrieval",
        "track": "main",
        "status": "Long Findings",
        "keywords": "question answering;semantic similarity;nlp application;question answering database;question answering resources;question ranking and retrieval",
        "authors": "",
        "rating": "",
        "confidence": "2;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "0tEed0ZiFX",
        "title": "Learning Semantic Role Labeling from Compatible Label Sequences",
        "track": "main",
        "status": "Long Findings",
        "keywords": "SRL",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "0u3O7Ju21x",
        "title": "Calibrated Seq2seq Models for Efficient and Generalizable Ultra-fine Entity Typing",
        "track": "main",
        "status": "Long Findings",
        "keywords": "entity typing;information extraction;probability calibration",
        "authors": "",
        "rating": "",
        "confidence": "3;4;5",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "106xRbVC4k",
        "title": "Revisiting Entropy Rate Constancy in Text",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Uniform Information Density;Entropy Rate;Large Language Models;Linguistic Theories",
        "authors": "",
        "rating": "",
        "confidence": "3;4;2",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "10iYooV68H",
        "title": "A Training-Free Debiasing Framework with Counterfactual Reasoning for Conversational Emotion Detection",
        "track": "main",
        "status": "Long Main",
        "keywords": "Conversational Emotion Detection;Counterfactual Reasoning;Debiasing",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "14WRhMNq7H",
        "title": "MolCA: Molecular Graph-Language Modeling with Cross-Modal Projector and Uni-Modal Adapter",
        "track": "main",
        "status": "Long Main",
        "keywords": "Molecular Language Modeling;Cross-Modal Alignment;Molecule Captioning;Molecule-Text Retrieval",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "16ZOs6YPDT",
        "title": "Variance Matters: Detecting Semantic Differences without Corpus/Word Alignment",
        "track": "main",
        "status": "Long Main",
        "keywords": "Semantic difference;semantic shift;word vectors;variance;concentration parameter",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "18skb5S2Gv",
        "title": "Nearest Neighbor Machine Translation is Meta-Optimizer on Output Projection Layer",
        "track": "main",
        "status": "Long Main",
        "keywords": "Nearest Neighbor Machine Translation;meta-optimization;domain adaptation;Neural Machine Translation",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "19sGqVUxQw",
        "title": "Inverse Scaling Can Become U-Shaped",
        "track": "main",
        "status": "Short Main",
        "keywords": "inverse scaling;scaling;language models;evaluation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "19uudhc1s8",
        "title": "Analyzing Film Adaptation through Narrative Alignment",
        "track": "main",
        "status": "Long Main",
        "keywords": "Text Alignment;Book Movie Alignment",
        "authors": "",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "1BMj6opwbj",
        "title": "From Values to Opinions: Predicting Human Behaviors and Stances Using Value-Injected Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Schwartz Value Theory;Large Language Model;Human Behavior;Personality;Value Injection",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4;4",
        "correctness": "5;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "1CaBi9kEng",
        "title": "ScanDL: A Diffusion Model for Generating Synthetic Scanpaths on Texts",
        "track": "main",
        "status": "Long Main",
        "keywords": "scanpath generation;eye movements;diffusion models;computational psycholinguistics;deep neural networks;transformer;eye tracking",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "5;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "1IRFq6qdke",
        "title": "BanglaAbuseMeme: A Dataset for Bengali Abusive Meme Classification",
        "track": "main",
        "status": "Long Main",
        "keywords": "abusive meme;low-resource language;social media",
        "authors": "",
        "rating": "",
        "confidence": "5;4;5",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "1N5Ia3KLX8",
        "title": "Closed Boundary Learning for Classification Tasks with the Universum Class",
        "track": "main",
        "status": "Long Findings",
        "keywords": "classification tasks;representation learning;the miscellaneous class",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "1PXPP9Gzgc",
        "title": "BERTwich: Extending BERT\u2019s Capabilities to Model Dialectal and Noisy Text",
        "track": "main",
        "status": "Long Findings",
        "keywords": "BERT;language modeling;dialects;noisy text;fine-tuning",
        "authors": "",
        "rating": "",
        "confidence": "5;3;4",
        "correctness": "2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "1RVUxlrFJZ",
        "title": "Can Retriever-Augmented Language Models Reason? The Blame Game Between the Retriever and the Language Model",
        "track": "main",
        "status": "Long Findings",
        "keywords": "retriever-augmented language models;reasoning of language models",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3;4",
        "correctness": "4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "1Sn1dpNaP3",
        "title": "Evaluating Parameter-Efficient Finetuning Approaches for Pre-trained Models on the Financial Domain",
        "track": "main",
        "status": "Short Findings",
        "keywords": "NLP;fine-tuning;parameter efficiency;financial domain",
        "authors": "",
        "rating": "",
        "confidence": "5;4;5;4",
        "correctness": "2;2;1;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.5,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "1UCopEeGz7",
        "title": "Rationale-Enhanced Language Models are Better Continual Relation Learners",
        "track": "main",
        "status": "Short Main",
        "keywords": "continual learning;relation extraction;rationale",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "1VsVZm4DLg",
        "title": "All Things Considered: Detecting Partisan Events from News Media with Cross-Article Comparison",
        "track": "main",
        "status": "Long Main",
        "keywords": "Partisan event detection;media bias",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "1WJoJPXwiG",
        "title": "FinEntity: Entity-level Sentiment Classification for Financial Texts",
        "track": "main",
        "status": "Short Main",
        "keywords": "Named Entity Recognition;Sentiment Analysis;Financial NLP",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "1Xht3SKAoY",
        "title": "ExpNote: Black-box Large Language Models are better Task Solvers with Experience Notebook",
        "track": "main",
        "status": "Short Findings",
        "keywords": "large language model;self-reflection;in-context learning",
        "authors": "",
        "rating": "",
        "confidence": "5;4;3;4",
        "correctness": "2;3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "1cKjvlvR7Z",
        "title": "Test-Time Self-Adaptive Small Language Models for Question Answering",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Language Models;Question Answering;Test-Time Adaption",
        "authors": "",
        "rating": "",
        "confidence": "3;4;5",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "1faXw8rfeq",
        "title": "Anaphor Assisted Document-Level Relation Extraction",
        "track": "main",
        "status": "Long Main",
        "keywords": "relation extraction;document level;anaphor;graph",
        "authors": "",
        "rating": "",
        "confidence": "4;1;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "1gUUznQgVC",
        "title": "SAC$^3$: Reliable Hallucination Detection in Black-Box Language Models via Semantic-aware Cross-check Consistency",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Hallucination;semantic consistency;blackbox;large language models;confidence",
        "authors": "",
        "rating": "",
        "confidence": "3;5;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "1iQMzgmKeD",
        "title": "Extrapolating Multilingual Understanding Models as Multilingual Generators",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multilingual Translation;Prompt Tuning;Non-autoregressive Generation",
        "authors": "",
        "rating": "",
        "confidence": "2;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "1kmIDTfQ4N",
        "title": "BERT Has More to Offer: BERT Layers Combination Yields Better Sentence Embeddings",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Sentence Embedding;BERT;BERT-LC;Layers Combination",
        "authors": "",
        "rating": "",
        "confidence": "5;3;3",
        "correctness": "3;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "1mGD6ZLTwv",
        "title": "Assessing Privacy Risks in Language Models: A Case Study on Summarization Tasks",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Summarization;Membership Inference Attack;Privacy;Language Model",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "1pxxAJwBXj",
        "title": "CorefPrompt: Prompt-based Event Coreference Resolution by Measuring Event Type and Argument Compatibilities",
        "track": "main",
        "status": "Long Main",
        "keywords": "event coreference;event coreference resolution;prompt",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "2;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "1qJgZUAc8j",
        "title": "Exploring the Numerical Reasoning Capabilities of Language Models: A Comprehensive Analysis on Tabular Data",
        "track": "main",
        "status": "Long Findings",
        "keywords": "numerical reasoning;probing language models;numeracy;tables;tabular data",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3;4",
        "correctness": "3;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "1tZxE1WPKz",
        "title": "Incorporating Object-Level Visual Context for Multimodal Fine-Grained Entity Typing",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Fine-Grained Entity Typing;Multimodal Learning.",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "2;5;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "219K9bcUgC",
        "title": "Does Listener Gaze in Face-to-Face Interaction Follow the Entropy Rate Constancy Principle: An Empirical Study",
        "track": "main",
        "status": "Short Findings",
        "keywords": "entropy rate constancy principle;information density;dialogue;nonverbal behaviour;gaze",
        "authors": "",
        "rating": "",
        "confidence": "2;4;3",
        "correctness": "2;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "266rF9DyWk",
        "title": "Automatic Transcription of Handwritten Old Occitan Language",
        "track": "main",
        "status": "Long Main",
        "keywords": "handwritten text recognition;low-resource languages;transformer;computer vision;natural language processing",
        "authors": "",
        "rating": "",
        "confidence": "5;5;1",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "27HNeESZQF",
        "title": "PromptARA: Improving Deep Representation in Hybrid Automatic Readability Assessment with Prompt and Orthogonal Projection",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Readability assessment; Deep learning; Prompt learning; Orthogonal projection layer; Linguistic feature",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3;5",
        "correctness": "3;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "2AF1OrD7Y1",
        "title": "Rethinking Word-Level Auto-Completion in Computer-Aided Translation",
        "track": "main",
        "status": "Long Main",
        "keywords": "machine translation;interactive machine translation;computer assisted translation;word level auto completion",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "2FDty4mLqP",
        "title": "Open Information Extraction via Chunks",
        "track": "main",
        "status": "Long Main",
        "keywords": "Information Extraction;sentence chunking",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "2IfYI3dkX7",
        "title": "RexUIE: A Recursive Method with Explicit Schema Instructor for Universal Information Extraction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Universal Information Extraction;Few-Shot Learning",
        "authors": "",
        "rating": "",
        "confidence": "5;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "2KTvN4Edvl",
        "title": "Guideline Learning for In-Context Information Extraction",
        "track": "main",
        "status": "Long Main",
        "keywords": "information extraction;in-context learning;large language models",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "2MDPYm3FPl",
        "title": "Hallucination Detection for Generative Large Language Models by Bayesian Sequential Estimation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Hallucination dectection;fact checking;Bayesian sequential estimation;generative large language models",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "2MXXycs2T6",
        "title": "QADYNAMICS: Training Dynamics-Driven Synthetic QA Diagnostic for Zero-Shot Commonsense Question Answering",
        "track": "main",
        "status": "Short Findings",
        "keywords": "commonsense reasoning;question-answering;training dynamics;zero shot",
        "authors": "",
        "rating": "",
        "confidence": "3;5;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "2MiTZxLFA9",
        "title": "GRACE: Discriminator-Guided Chain-of-Thought Reasoning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "chain-of-thought;guided decoding;math reasoning;symbolic reasoning;multi-step reasoning;large language models",
        "authors": "",
        "rating": "",
        "confidence": "5;3;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "2O39az85g6",
        "title": "Exploring Context-Aware Evaluation Metrics for Machine Translation",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Machine Translation;Automatic Evaluation Metric;Context Awareness",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3;4",
        "correctness": "3;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "2Rdfdri2oT",
        "title": "Making Large Language Models Better Data Creators",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Model;Data Creation",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "2TtN6DqjWa",
        "title": "Learning Interpretable Style Embeddings via Prompting LLMs",
        "track": "main",
        "status": "Long Findings",
        "keywords": "style;stylometry;representation learning;embeddings;vectors;interpretability;prompting;llm",
        "authors": "",
        "rating": "",
        "confidence": "5;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "2U9hDBaOCn",
        "title": "Specialist or Generalist? Instruction Tuning for Specific NLP Tasks",
        "track": "main",
        "status": "Long Main",
        "keywords": "LLMs;Instruction Tuning;Data Efficiency",
        "authors": "",
        "rating": "",
        "confidence": "2;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "2UJvVc8gnP",
        "title": "Masked Path Modeling for Vision-and-Language Navigation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Vision-and-Language Navigation;Masked Data Modeling",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "2WZ4Wp1OSo",
        "title": "Building Multi-domain Dialog State Trackers from Single-domain Dialogs",
        "track": "main",
        "status": "Long Main",
        "keywords": "dialog state tracking;multi-domain dialog;conversational query rewrite",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "2X5RXTOsLU",
        "title": "Dialect Transfer for Swiss German Speech Translation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "speech to text;speech translation;swiss german;low resource",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "2XDbDwNlTn",
        "title": "FACTIFY3M: A benchmark for multimodal fact verification with explainability through 5W Question-Answering",
        "track": "main",
        "status": "Long Main",
        "keywords": "Multimodality;Fact Verification;Disinformation;Explainability",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "2YEY9SPVEA",
        "title": "Task-Adaptive Tokenization: Enhancing Long-Form Text Generation Efficacy in Mental Health and Beyond",
        "track": "main",
        "status": "Long Main",
        "keywords": "task-adaptive tokenization;text generation;long-form generation;text segmentation",
        "authors": "",
        "rating": "",
        "confidence": "3;2;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "2anfut5geh",
        "title": "Challenges in Context-Aware Neural Machine Translation",
        "track": "main",
        "status": "Long Main",
        "keywords": "neural machine translation;document-level neural machine translation;context-aware neural machine translation",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "2b7aSGxb6M",
        "title": "MSCFFN: A New FFN with Multi-Space Cross to Accelerate Transformer",
        "track": "main",
        "status": "Short Findings",
        "keywords": "New FFN structure;MSCFFN;Multi-Space Cross method;Accelerate Transformers",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "2;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "2bBIY12n43",
        "title": "A State-Vector Framework for Dataset Effects",
        "track": "main",
        "status": "Long Main",
        "keywords": "data influence;probing;fine-tuning;multi-task learning;datasets",
        "authors": "",
        "rating": "",
        "confidence": "4;2;4",
        "correctness": "4;3;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "2c3u5YDUUy",
        "title": "MTGER: Multi-view Temporal Graph Enhanced Temporal Reasoning over Time-Involved Document",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Question Answering;Temporal Reasoning;Natural Language Processing",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "2hYi3mXxqf",
        "title": "T-Projection: High Quality Annotation Projection for Sequence Labeling Tasks",
        "track": "main",
        "status": "Long Findings",
        "keywords": "annotation projection;low-resource;sequence labeling;text2text language models;machine translation;automatic data generation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "2jibzAXJzH",
        "title": "T5Score: Discriminative Fine-tuning of Generative Evaluation Metrics",
        "track": "main",
        "status": "Long Findings",
        "keywords": "text generation;evaluation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "2kSufHoYEi",
        "title": "NORMSAGE: Multi-Lingual Multi-Cultural Norm Discovery from Conversations On-the-Fly",
        "track": "main",
        "status": "Long Main",
        "keywords": "social norms;discovery;grounding",
        "authors": "",
        "rating": "",
        "confidence": "3;4;5",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "2lI1pVL6aj",
        "title": "CRAB: Assessing the Strength of Causal Relationships Between Real-world Events",
        "track": "main",
        "status": "Long Main",
        "keywords": "causal reasoning;benchmark;causal score;event causality",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "2mxzS2Xv2e",
        "title": "A Causal View of Entity Bias in (Large) Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "entity bias;knowledge conflicts;causal analysis;large language models",
        "authors": "",
        "rating": "",
        "confidence": "3;3;2",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "2prcotJejU",
        "title": "Prompting with Pseudo-Code Instructions",
        "track": "main",
        "status": "Long Main",
        "keywords": "Instruction Finetuning;Pseudo-Code Instructions;Large Language Model",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4;3",
        "correctness": "3;4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "2qKRa94sow",
        "title": "Connecting degree and polarity: An artificial language learning study",
        "track": "main",
        "status": "Long Main",
        "keywords": "semantics;degree;polarity;artificial language learning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "2wFVkTDGOZ",
        "title": "Emptying the Ocean with a Spoon: Should We Edit Models?",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Model Editing;LLMs;Factual Knowledge;Continual Learning;Knowledge Representation;Opinion Paper",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4;5",
        "correctness": "2;2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "2z4s0W375H",
        "title": "Tuna: Instruction Tuning using Feedback from Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large Lanugage Models; Instruction Tuning",
        "authors": "",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "2z9o8bMQNd",
        "title": "Conversation Understanding using Relational Temporal Graph Neural Networks with Auxiliary Cross-Modality Interaction",
        "track": "main",
        "status": "Long Main",
        "keywords": "Multimodal Emotion Recognition;Relational Temporal GNNs;Conversation Understanding;Pairwise Cross Modality",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "30kbnyD9hF",
        "title": "Exchange-of-Thought: Enhancing Large Language Model Capabilities through Cross-Model Communication",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Models; Model Communication; Chain-of-Thought",
        "authors": "",
        "rating": "",
        "confidence": "2;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "33aJCNQV1C",
        "title": "A linear time approximation of Wasserstein distance with word embedding selection",
        "track": "main",
        "status": "Long Main",
        "keywords": "optimal transport;group feature selection;document classification;word embedding",
        "authors": "",
        "rating": "",
        "confidence": "3;4;2",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "377w7agYKC",
        "title": "CoRec: An Easy Approach for Coordination Recognition",
        "track": "main",
        "status": "Short Main",
        "keywords": "coordination recognition;shallow parsing",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "38k1q1yyCe",
        "title": "Crossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss Weighting",
        "track": "main",
        "status": "Long Main",
        "keywords": "machine translation;idioms;multi-word expressions;retrieval-based machine translation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4;3",
        "correctness": "4;2;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "3AxESAk0Re",
        "title": "STAIR: Learning Sparse Text and Image Representation in Grounded Tokens",
        "track": "main",
        "status": "Long Main",
        "keywords": "Image text retrieval;sparse embedding;interpretability",
        "authors": "",
        "rating": "",
        "confidence": "3;4;5",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "3CIQIYNGlp",
        "title": "Exploring the Impact of Model Scaling on Parameter-Efficient Tuning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Parameter-efficient fine-tuning;Pre-trained language model",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "3EcjsgPq74",
        "title": "Towards A Unified View of Sparse Feed-Forward Network in Pretraining Large Language Model",
        "track": "main",
        "status": "Long Main",
        "keywords": "Mixture-of-Experts;Efficiency;Transformer;Architecture;Pretraining;LLM",
        "authors": "",
        "rating": "",
        "confidence": "2;3;3;3",
        "correctness": "3;4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "3ErwybEDgt",
        "title": "DiQAD: A Benchmark Dataset for Open-domain Dialogue Quality Assessment",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Dataset;Dialogue Evaluation Dataset;Dialogue Quality Assessment;Dialogue Quality Evaluation;Dialogue Quality Benchmark;Dialogue Evaluation",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "3F1qEXWKFE",
        "title": "PIVOINE: Instruction Tuning for Open-world Entity Profiling",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large Language Model;Information Extraction;Instruction Tuning",
        "authors": "",
        "rating": "",
        "confidence": "4;5;3;5",
        "correctness": "3;3;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "3FNrGv5MKb",
        "title": "$k$NN-LM Does Not Improve Open-ended Text Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "retrieval-augmented language model;text generation;text generation evaluation;kNN-LM",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "3I1A9xAI8S",
        "title": "Dr ChatGPT tell me what I want to hear: How different prompts impact health answer correctness",
        "track": "main",
        "status": "Long Main",
        "keywords": "ChatGPT;LLM;Health Misinformation;Prompt Knowledge;Consumer Health",
        "authors": "",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "3JBKnkUACW",
        "title": "Sub-network Discovery and Soft-masking for Continual Learning of Mixed Tasks",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Continual Learning;Heterogeneous Tasks;Sub-network Discovery",
        "authors": "",
        "rating": "",
        "confidence": "4;4;2",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "3JP1Jsng4G",
        "title": "mReFinED: An Efficient End-to-End Multilingual Entity Linking System",
        "track": "main",
        "status": "Short Findings",
        "keywords": "entity linking;multilingual;end-to-end",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "3LIUMrCKrv",
        "title": "It Ain't Over: A Multi-aspect Diverse Math Word Problem Dataset",
        "track": "main",
        "status": "Long Main",
        "keywords": "Math Word Problem;Arithmetic Reasonong;Natural Language Processing;Dataset;Large Language Model",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "3LdaPmAnji",
        "title": "EDeR: Towards Understanding Dependency Relations Between Events",
        "track": "main",
        "status": "Long Main",
        "keywords": "dataset;event dependency relation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "3MEV3aIDDq",
        "title": "Can Pre-trained Vision and Language Models Answer Visual Information-Seeking Questions?",
        "track": "main",
        "status": "Long Main",
        "keywords": "visual question answering;vision and language;pre-trained multimodal model",
        "authors": "",
        "rating": "",
        "confidence": "2;3;5",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "3Nq9KRcvx5",
        "title": "DiNeR: A Large Realistic Dataset for Evaluating Compositional Generalization",
        "track": "main",
        "status": "Long Main",
        "keywords": "compositional generalization;dish name recognition;large realistic dataset;language model evaluation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "3OvLxe9n9S",
        "title": "Dialogue Act-Aided Backchannel Prediction Using Multi-Task Learning",
        "track": "main",
        "status": "Short Findings",
        "keywords": "backchannel prediction;multi-task learning;dialogue act;pre-trained audio encoder;voice activity projection",
        "authors": "",
        "rating": "",
        "confidence": "4;2;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "3Q6LON8y2I",
        "title": "Is ChatGPT Good at Search? Investigating Large Language Models as Re-Ranking Agents",
        "track": "main",
        "status": "Long Main",
        "keywords": "Passage Re-ranking;Information Retrieval;Large Language Models",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "3QibSyz6Qt",
        "title": "NarrativeXL: a Large-scale Dataset for Long-Term Memory Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "NLP;long-term memory;long term memory;reading comprehension",
        "authors": "",
        "rating": "",
        "confidence": "5;3;3;3",
        "correctness": "3;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "3QzTzulZwY",
        "title": "IMTLab: An Open-Source Platform for Building, Evaluating, and Diagnosing Interactive Machine Translation Systems",
        "track": "main",
        "status": "Long Main",
        "keywords": "Interactive Machine Translation; Neural Machine Translation; Lexical-constrained Translation",
        "authors": "",
        "rating": "",
        "confidence": "4;5;2",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "3RS2T9EPjI",
        "title": "In-Image Neural Machine Translation with Segmented Pixel Sequence-to-Sequence Model",
        "track": "main",
        "status": "Long Findings",
        "keywords": "In-Image Machine Translation;Neural Machine Translation",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "3RTpKMVg0P",
        "title": "Privacy Implications of Retrieval-Based Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Privacy;Retrieval-based language models",
        "authors": "",
        "rating": "",
        "confidence": "3;1;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "3Uu4rZ6hLI",
        "title": "Unveiling the Essence of Poetry: Introducing a Comprehensive Dataset and Benchmark for Poem Summarization",
        "track": "main",
        "status": "Short Main",
        "keywords": "Poem summarization;Creative language summarization;Creative language interpretation;Natural language understanding;Automatic text summarization;Language models",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "3XDDWCu8CF",
        "title": "A Simple Baseline for Knowledge-Based Visual Question Answering",
        "track": "main",
        "status": "Short Main",
        "keywords": "Knowledge-based Visual Question Answering (KB-VQA);Commonsense Reasoning;Few-shot learning",
        "authors": "",
        "rating": "",
        "confidence": "4;3;2",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "3aF1Rv3dHG",
        "title": "One-Model-Connects-All: A Unified Graph Pre-Training Model for Online Community Modeling",
        "track": "main",
        "status": "Long Findings",
        "keywords": "community;pre-train;graph",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "3;3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "3dNeNpmyiO",
        "title": "Learning to Describe for Predicting Zero-shot Drug-Drug Interactions",
        "track": "main",
        "status": "Long Main",
        "keywords": "Reinforcement Learning;Prompt Learning;Drug-Drug Interaction",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "3e8rcsIO7H",
        "title": "Dense Retrieval as Indirect Supervision for Large-space Decision Making",
        "track": "main",
        "status": "Long Findings",
        "keywords": "large decision spaces;dense retrieval;extreme multi-label classification;ultra-fine entity typing;few-shot intent classification",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "3gdG9upo7e",
        "title": "Generative Table Pre-training Empowers Models for Tabular Prediction",
        "track": "main",
        "status": "Long Main",
        "keywords": "tabular prediction;generative table pre-training",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "3k5GFJEGem",
        "title": "ParroT: Translating during Chat using Large Language Models tuned with Human Translation and Feedback",
        "track": "main",
        "status": "Long Findings",
        "keywords": "machine translation;instruction tuning;LoRA;human feedback;LLaMA;BLOOMZ;ChatGPT;GPT-4",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "3l9zUuFo9m",
        "title": "Cache me if you Can: an Online Cost-aware Teacher-Student framework to Reduce the Calls to Large Language Models",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Online Learning;Cost-Efficient;LLMs Applications;Caching;Teacher-Student",
        "authors": "",
        "rating": "",
        "confidence": "5;3;2",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "3pvdo2yHXq",
        "title": "Speech-enriched Memory for Inference-time Adaptation of ASR Models to Word Dictionaries",
        "track": "main",
        "status": "Long Main",
        "keywords": "ASR Adaptation;Inference-time adaptation;Contextual Biasing",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3;3",
        "correctness": "4;4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "3qF5MqUl3Y",
        "title": "R2H: Building Multimodal Navigation Helpers that Respond to Help Requests",
        "track": "main",
        "status": "Long Main",
        "keywords": "Multimodal Understanding;Embodied AI;Vision-and-language Navigation",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "3qG4r6FGWD",
        "title": "Aligning Predictive Uncertainty with Clarification Questions in Grounded Dialog",
        "track": "main",
        "status": "Long Findings",
        "keywords": "predictive uncertainty;calibration;grounded dialog;clarification question;instruction following;collaborative dialog",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3;2",
        "correctness": "4;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "3u3kXSeVvR",
        "title": "Viewing Knowledge Transfer in Multilingual Machine Translation Through a Representational Lens",
        "track": "main",
        "status": "Long Findings",
        "keywords": "multilingual machine translation;cross-lingual knowledge transfer",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "3ymHqvobHJ",
        "title": "Cross-lingual Open-Retrieval Question Answering for African Languages",
        "track": "main",
        "status": "Long Findings",
        "keywords": "African Languages;Question Answering;Information Retrieval;Low-resource Languages",
        "authors": "",
        "rating": "",
        "confidence": "3;4;5",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "40NCUv4I2R",
        "title": "Enhancing Text-to-SQL Capabilities of Large Language Models: A Study on Prompt Design Strategies",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Text-to-SQL;Few-shot;Zero-shot;In-context Learning;Large Language Models",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "41vXNjZbIn",
        "title": "Improving Input-label Mapping with Demonstration Replay for In-context Learning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "in-context learning;causal language modeling",
        "authors": "",
        "rating": "",
        "confidence": "4;5;4;3",
        "correctness": "4;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "4272bEn4Q0",
        "title": "Large Language Models are Complex Table Parsers",
        "track": "main",
        "status": "Long Main",
        "keywords": "Complex Table QA;GPT-3.5;Large language models",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "42Cc5s71zl",
        "title": "D$^2$TV: Dual Knowledge Distillation and Target-oriented Vision Modeling for Many-to-Many Multimodal Summarization",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multimodal Summarization; Cross-lingual Summarization; Many-to-many Multimodal Summarization",
        "authors": "",
        "rating": "",
        "confidence": "2;3;4;4",
        "correctness": "3;2;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "42LIoV0C1h",
        "title": "Qualitative Code Suggestion: A Human-Centric Approach to Qualitative Coding",
        "track": "main",
        "status": "Long Findings",
        "keywords": "qualitative coding;human-centric",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "43SOcneD8W",
        "title": "Chain-of-Thought Tuning: Masked Language Models can also Think Step By Step in Natural Language Understanding",
        "track": "main",
        "status": "Long Main",
        "keywords": "masked language models;multi-step reasoning;Chain-of-Thought;natural language understanding",
        "authors": "",
        "rating": "",
        "confidence": "2;3;3;4",
        "correctness": "4;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "45uZxlMLol",
        "title": "Annotation Sensitivity: Training Data Collection Methods Affect Model Performance",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Annotation sensitivity;human annotation;annotation instrument;task structure effects",
        "authors": "",
        "rating": "",
        "confidence": "3;5;4",
        "correctness": "4;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "46WcPRhRwG",
        "title": "Evaluating and Enhancing the Robustness of Code Pre-trained Models through Structure-Aware Adversarial Samples Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Neural Code Intelligence;Pre-trained Language Models;Adversarial Attack",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "49HfhYU9S6",
        "title": "Assessing Step-by-Step Reasoning against Lexical Negation: A Case Study on Syllogism",
        "track": "main",
        "status": "Short Main",
        "keywords": "Negation;Prompting;Reasoning;Language model;Model Analysis;Probing;Chain-of-thought",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "4AcHxGE6M4",
        "title": "CP-BCS: Binary Code Summarization Guided by Control Flow Graph and Pseudo Code",
        "track": "main",
        "status": "Long Main",
        "keywords": "binary code summarization",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "4AiERjB5JD",
        "title": "Prefix-Tuning Based Unsupervised Text Style Transfer",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Unsupervised text style transfer;Prefix-Tuning",
        "authors": "",
        "rating": "",
        "confidence": "5;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "4EXbwN9Ezw",
        "title": "A Boundary Offset Prediction Network for Named Entity Recognition",
        "track": "main",
        "status": "Long Findings",
        "keywords": "named entity recognition;span-based methods;boundary connections;boundary offset prediction network;type-related boundary offsets",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "4FDx4KMZnu",
        "title": "Mixture of Soft Prompts for Controllable Data Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "data augmentation;parameter efficient training;few-shot learning;structured prediction",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "4Ggw1DsgRQ",
        "title": "Enhancing Computation Efficiency in Large Language Models through Weight and Activation Quantization",
        "track": "main",
        "status": "Long Main",
        "keywords": "Post-training quantization;LLM;Transformers;Numerical format",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "4GmujJSuq0",
        "title": "What to Read in a Contract? Party-Specific Summarization of Legal Obligations, Entitlements, and Prohibitions",
        "track": "main",
        "status": "Long Main",
        "keywords": "Legal NLP;Rights and Obligation Extraction;Summarization;Importance Ranking",
        "authors": "",
        "rating": "",
        "confidence": "5;2;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "4IubiozIFH",
        "title": "Exploring the Effectiveness of Multi-Lingual Commonsense Knowledge-Aware Open-Domain Dialogue Response Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "response generation;dialogue system;commonsense knowledge;multi-lingual",
        "authors": "",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "4Jnjap7NSx",
        "title": "Distance-Based Propagation for Efficient Knowledge Graph Reasoning",
        "track": "main",
        "status": "Long Main",
        "keywords": "knowledge graphs;link prediction;graph neural network",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "4JpybEffzH",
        "title": "Non-Autoregressive Document-Level Machine Translation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "NAT;Document-level MT;Machine Translation",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "4KRiWsfOwn",
        "title": "Merging Experts into One: Improving Computational Efficiency of Mixture of Experts",
        "track": "main",
        "status": "Short Main",
        "keywords": "Mixture of Experts;Computational Efficiency",
        "authors": "",
        "rating": "",
        "confidence": "5;4;3",
        "correctness": "4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "4M4U3uC3Iy",
        "title": "ChatCoT: Tool-Augmented Chain-of-Thought Reasoning on Chat-based Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "large language models;complex reasoning;chain-of-thought",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "4MjZNeTCqZ",
        "title": "UniChart: A Universal Vision-language Pretrained Model for Chart Comprehension and Reasoning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Charts;Pretraining",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "4PPT1An0kY",
        "title": "Self-Ensemble of $N$-best Generation Hypotheses by Lexically Constrained Decoding",
        "track": "main",
        "status": "Short Main",
        "keywords": "Reranking;Lexically Constrained Decoding;Generation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "4WrqZlEK3K",
        "title": "LMGQS: A Large-scale Dataset for Query-focused Summarization",
        "track": "main",
        "status": "Long Findings",
        "keywords": "query-focused summarization;large-scale dataset;zero-shot summarization;large language model",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "4aBxFtqRNa",
        "title": "GNAT: A General Narrative Alignment Tool",
        "track": "main",
        "status": "Long Main",
        "keywords": "Text Alignment",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "4akD4Z2BBg",
        "title": "Biomedical Named Entity Recognition via Dictionary-based Synonym Generalization",
        "track": "main",
        "status": "Long Main",
        "keywords": "Biomedical named entity recognition;NER;BioNLP;Synonym Generalization",
        "authors": "",
        "rating": "",
        "confidence": "2;4;3;3",
        "correctness": "4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "4dJMzjIR2k",
        "title": "Hi-ArG: Exploring the Integration of Hierarchical Argumentation Graphs in Language Pretraining",
        "track": "main",
        "status": "Long Main",
        "keywords": "computational argumentation;knowledge graph;abstract meaning representation",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "4k5BcBYKAS",
        "title": "GTA: Gated Toxicity Avoidance for LM Performance Preservation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "language model;controllable text generation;toxicity avoidance;nontoxic text generation;text generation;natural language generation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;5;4",
        "correctness": "3;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "4kuLaebvKx",
        "title": "ICU: Conquering Language Barriers in Vision-and-Language Modeling by Dividing the Tasks into Image Captioning and Language Understanding",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Cross-lingual Language Understanding;Multimodality",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "4nQN6Z6OY3",
        "title": "Outlier Dimensions Encode Task Specific Knowledge",
        "track": "main",
        "status": "Short Main",
        "keywords": "outlier dimensions;LLMs;fine-tuning;interpretability",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "4sgXjFtnqg",
        "title": "Efficient Multilingual Language Model Compression through Vocabulary Trimming",
        "track": "main",
        "status": "Long Findings",
        "keywords": "multilingual;language model;model compression;efficiency",
        "authors": "",
        "rating": "",
        "confidence": "2;4;5",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "4to6zjnEQV",
        "title": "Bridging Continuous and Discrete Spaces: Interpretable Sentence Representation Learning via Compositional Operations",
        "track": "main",
        "status": "Long Main",
        "keywords": "sentence embedding;representation learning",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "4toYWE7g6U",
        "title": "ChatEdit: Towards Multi-turn Interactive Facial Image Editing via Dialogue",
        "track": "main",
        "status": "Long Main",
        "keywords": "Interactive image editing;Task-oriented dialogue",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "4uylA0mUkk",
        "title": "Data Factors for Better Compositional Generalization",
        "track": "main",
        "status": "Long Main",
        "keywords": "compositional generalization;data factors",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4;4",
        "correctness": "4;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "4wAKqlfV5t",
        "title": "Improving Multimodal Sentiment Analysis: Supervised Angular margin-based Contrastive Learning for Enhanced Fusion Representation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multimodal Sentiment Analysis;Contrastive Learning",
        "authors": "",
        "rating": "",
        "confidence": "4;1;3;5",
        "correctness": "4;2;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "50rXrJNqHQ",
        "title": "API-Assisted Code Generation for Question Answering on Varied Table Structures",
        "track": "main",
        "status": "Long Main",
        "keywords": "table question answering;code generation",
        "authors": "",
        "rating": "",
        "confidence": "5;4;5",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "51BB1xOWq1",
        "title": "GenKIE: Robust Generative Multimodal Document Key Information Extraction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Key information extraction;Multimodal generative model",
        "authors": "",
        "rating": "",
        "confidence": "2;5;4;3",
        "correctness": "2;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "51gbtl2VxL",
        "title": "Incorporating Probing Signals into Multimodal Machine Translation via Visual Question-Answering Pairs",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multimodal machine translation;Large language models;VQA;Probing tasks",
        "authors": "",
        "rating": "",
        "confidence": "3;4;1;4;4",
        "correctness": "3;4;4;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.2,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "54WhV6RTzi",
        "title": "Style-Aware Radiology Report Generation with RadGraph and Few-Shot Prompting",
        "track": "main",
        "status": "Long Findings",
        "keywords": "language model;radiology;report generation;few-shot prompting;in-context learning;radgraph",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "56UYArtXyA",
        "title": "FreeAL: Towards Human-Free Active Learning in the Era of Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Active learning;Large language model;Human-free zero-shot learning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "57yfvVESPE",
        "title": "Tunable Soft Prompts are Messengers in Federated Learning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "federated learning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "58jpJdPgKi",
        "title": "Representation Projection Invariance Mitigates Representation Collapse",
        "track": "main",
        "status": "Long Findings",
        "keywords": "representation learning;generalization;representation collapse",
        "authors": "",
        "rating": "",
        "confidence": "2;3;4;4;4",
        "correctness": "4;3;2;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.4,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "59gI2XQPmH",
        "title": "Alignment Precedes Fusion: Open-Vocabulary Named Entity Recognition as Context-Type Semantic Matching",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Open-Vocabulary;Named Entity Recognition",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "5Az3d5TkMJ",
        "title": "LIMIT: Language Identification, Misidentification, and Translation using Hierarchical Models in 350+ Languages",
        "track": "main",
        "status": "Long Main",
        "keywords": "language identification;resource creation;machine translation;low-resource languages",
        "authors": "",
        "rating": "",
        "confidence": "5;5;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "5BWvVIa5Uz",
        "title": "Emergent Inabilities? Inverse Scaling Over the Course of Pretraining",
        "track": "main",
        "status": "Short Findings",
        "keywords": "language models;inverse scaling;transformers;training dynamics",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "5DUhBxRqKR",
        "title": "Drilling Down into the Discourse Structure with LLMs for Long Document Question Answering",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Long Document Question Answering;Large Language Model;Zero-shot Prompting;Evidence Retrieval",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "5EHI2FGf1D",
        "title": "Unsupervised Binary Code Translation with Application to Code Clone Detection and Vulnerability Discovery",
        "track": "main",
        "status": "Long Findings",
        "keywords": "NLP;Neural Machine Translation;Binary Code Analysis;Vulnerability Discovery;Code Clone Detection",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "5IFMe8TuSy",
        "title": "Exploring Jiu-Jitsu Argumentation for Writing Peer Review Rebuttals",
        "track": "main",
        "status": "Long Main",
        "keywords": "Peer Reviews;Rebuttals;Attitude Roots;Jiu-Jitsu Persuasion",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "5K2fiOlcGG",
        "title": "Sparse Frame Grouping Network with Action Centered for Untrimmed Video Paragraph Captioning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "video paragraph captioning;transformer;grouping;action centered;contrastive learning",
        "authors": "",
        "rating": "",
        "confidence": "5;3;3;4",
        "correctness": "2;3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "5NMl0TYLey",
        "title": "InfoCL: Alleviating Catastrophic Forgetting in Continual Text Classification from An Information Theoretic Perspective",
        "track": "main",
        "status": "Long Findings",
        "keywords": "continual learning;text classification",
        "authors": "",
        "rating": "",
        "confidence": "2;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "5Ob6DsDv2V",
        "title": "A Comprehensive Evaluation of Biomedical Entity Linking Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Entity Linking;Entity Normalization;Candidate Generation;Biomedical Natural Language Processing",
        "authors": "",
        "rating": "",
        "confidence": "3;5;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "5PvFFNRTbp",
        "title": "A Frustratingly Easy Post-Training Quantization Scheme for LLMs",
        "track": "main",
        "status": "Long Main",
        "keywords": "Quantization;Efficient LLM;Model Compression",
        "authors": "",
        "rating": "",
        "confidence": "3;2;4",
        "correctness": "4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "5QNpjtdjD8",
        "title": "Exploring the Boundaries of GPT-4 in Radiology",
        "track": "main",
        "status": "Long Main",
        "keywords": "benchmarking GPT-4;radiology;evaluation;large language model",
        "authors": "",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "5TEfD2GBUc",
        "title": "FANToM: A Benchmark for Stress-testing Machine Theory of Mind in Interactions",
        "track": "main",
        "status": "Long Main",
        "keywords": "theory of mind;benchmark;interaction;conversation;large language model;llm",
        "authors": "",
        "rating": "",
        "confidence": "3;3;1;2",
        "correctness": "4;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "5UW6Mivj9M",
        "title": "Let GPT be a Math Tutor: Teaching Math Word Problem Solvers with Customized Exercise Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Mathematical Reasoning;Large Languague Models;Customized Learning",
        "authors": "",
        "rating": "",
        "confidence": "3;5;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "5ZHznxXCIb",
        "title": "Context-faithful Prompting for Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large language models;knowledge update;prompt",
        "authors": "",
        "rating": "",
        "confidence": "4;3;1",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "5jc17fMzqf",
        "title": "1-PAGER: One Pass Answer Generation and Evidence Retrieval",
        "track": "main",
        "status": "Long Findings",
        "keywords": "retrieval;openbook qa;generative retrieval",
        "authors": "",
        "rating": "",
        "confidence": "1;4;4",
        "correctness": "2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "5kV1ZwKMeQ",
        "title": "A Confederacy of Models: a Comprehensive Evaluation of LLMs on Creative Writing",
        "track": "main",
        "status": "Long Findings",
        "keywords": "LLMs;language models;creative writing;evaluation;text generation;storytelling;creativity",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "5;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "5nHLFcj7Y9",
        "title": "Text Representation Distillation via Information Bottleneck Principle",
        "track": "main",
        "status": "Long Main",
        "keywords": "knowledge distillation;text representation;text retrieval;language model",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "5o4a4OjhQW",
        "title": "What Comes Next? Evaluating Uncertainty in Neural Text Generators Against Human Production Variability",
        "track": "main",
        "status": "Long Main",
        "keywords": "uncertainty;NLG;variability;language production;text generation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "5sGLPiG1vE",
        "title": "When are Lemons Purple? The Concept Association Bias of Vision-Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "vision and language;bias",
        "authors": "",
        "rating": "",
        "confidence": "3;3;2",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "5uZQ6spv9u",
        "title": "BRAINTEASER: Lateral Thinking Puzzles for Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "commonsense reasoning;adversarial robustness;computational creativity",
        "authors": "",
        "rating": "",
        "confidence": "2;3;2",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "5vOHRbLNE7",
        "title": "HierarchicalContrast: A Coarse-to-Fine Contrastive Learning Framework for Cross-Domain Zero-Shot Slot Filling",
        "track": "main",
        "status": "Long Findings",
        "keywords": "slot-filling;task-oriented dialogue;contrastive learning;cross-domain adaption;zero-shot learning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "3;2;1;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "5x5Vxclc1K",
        "title": "SMoP: Towards Efficient and Effective Prompt Tuning with Sparse Mixture-of-Prompts",
        "track": "main",
        "status": "Short Main",
        "keywords": "Natural Language Processing;Prompt Tuning;Parameter-Efficient Fine-tuning;Mixture-of-Experts",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4;3",
        "correctness": "3;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "63UKbaiyAe",
        "title": "Discourse Sense Flows: Modelling the Rhetorical Style of Documents across Various Domains",
        "track": "main",
        "status": "Long Findings",
        "keywords": "rhetorical style;cross-domain;discourse parsing;discourse signals;connecting phrases;sense recognition",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "65teZsn7HR",
        "title": "Exploring Linguistic Properties of Monolingual BERTs with Typological Classification among Languages",
        "track": "main",
        "status": "Long Findings",
        "keywords": "interpretability;CKA;typological similarity;BERT",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "68A4GE4nqf",
        "title": "Evaluating Subjective Cognitive Appraisals of Emotions from Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Emotion;Cognitive Appraisal;Large Language Models",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "6DKS4tb387",
        "title": "Gradually Excavating External Knowledge for Implicit Complex Question Answering",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Question answering;Knowledge Retrieval;Multi-step question answering;Large Language Model",
        "authors": "",
        "rating": "",
        "confidence": "4;5;4;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "6DMhUhx5oy",
        "title": "Fighting Fire with Fire: The Dual Role of LLMs in Crafting and Detecting Elusive Disinformation",
        "track": "main",
        "status": "Long Main",
        "keywords": "LLM;Prompt Engineering;Disinformation Detection;Natural Language Inference;Semantic Reasoning;In-context Learning",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "6Jqa4YmUMf",
        "title": "Investigating the Effectiveness of Multiple Expert Models Collaboration",
        "track": "main",
        "status": "Short Findings",
        "keywords": "machine translation;multi-domain translation;multiple model collaboration",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "6KyZrSp8y3",
        "title": "Unnatural language processing: How do language models handle machine-generated prompts?",
        "track": "main",
        "status": "Long Findings",
        "keywords": "prompting;interpretability;large language modelling;unnatural language processing",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "6LkytBaTy9",
        "title": "Bias Neutralization in Non-Parallel Texts: A Cyclic Approach with Auxiliary Guidance",
        "track": "main",
        "status": "Long Main",
        "keywords": "Bias Correction;Subjective Bias;Generative Adversarial Networks;Unsupervised Learning;Auxiliary Guidance",
        "authors": "",
        "rating": "",
        "confidence": "4;2;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "6P32h3LTC1",
        "title": "A Multi-Modal Multilingual Benchmark for Document Image Classification",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Document AI;layout-aware models;visually-rich document understanding;multilingual document image classification",
        "authors": "",
        "rating": "",
        "confidence": "4;5;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "6RQTvSLbgi",
        "title": "IEKG: A Commonsense Knowledge Graph for Idiomatic Expressions",
        "track": "main",
        "status": "Long Main",
        "keywords": "idiomatic expression;figurative semantics;commonsense knowledge;idiomatic expression comprehension;natural language understanding",
        "authors": "",
        "rating": "",
        "confidence": "3;2;2",
        "correctness": "4;3;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "6RuXWFEQzg",
        "title": "Open-world Semi-supervised Generalized Relation Discovery Aligned in a Real-world Setting",
        "track": "main",
        "status": "Long Main",
        "keywords": "Information extraction;relation extraction",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "6UklbMESHZ",
        "title": "An Empirical Investigation of Implicit and Explicit Knowledge-Enhanced Methods for Ad Hoc Dataset Retrieval",
        "track": "main",
        "status": "Long Findings",
        "keywords": "ad hoc dataset retrieval;dataset search;dense retrieval;semantic search",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "4;3;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "6WcsVlZE5I",
        "title": "Towards a Deep Understanding of Multilingual End-to-End Speech Translation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multilingual Speech Translation;Multilinguality",
        "authors": "",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "3;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "6YQ1uh9IGG",
        "title": "A Survey on Out-of-Distribution Detection in NLP",
        "track": "main",
        "status": "Reject",
        "keywords": "OOD Detection",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "6c2s6HddQ4",
        "title": "The Locality and Symmetry of Positional Encodings",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Positional Encodings;Sentence Representations;Pre-trained Language Models",
        "authors": "",
        "rating": "",
        "confidence": "2;3;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "6dyvFZLRX8",
        "title": "BotPercent: Estimating Bot Populations in Twitter Communities",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Twitter bot detection;social network analysis",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "6eBgIRnlGA",
        "title": "Mitigating Temporal Misalignment by Discarding Outdated Facts",
        "track": "main",
        "status": "Long Main",
        "keywords": "Question Answering;Temporal",
        "authors": "",
        "rating": "",
        "confidence": "4;2;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "6i98agKoZ1",
        "title": "Self-Improvement of Non-autoregressive Model via Sequence-Level Distillation",
        "track": "main",
        "status": "Long Main",
        "keywords": "non-autoregressive transformers;self-improvement;distillation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;2",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "6j7JZnEzf4",
        "title": "Language Models with Rationality",
        "track": "main",
        "status": "Long Main",
        "keywords": "Interpretability;question answering;belief;entailment;belief graphs;consistency",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "6jik3wCbTr",
        "title": "Mitigating Data Imbalance and Representation Degeneration in Multilingual Machine Translation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Data Imbalance;Representation Degeneration;Multilingual Machine Translation",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "2;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "6lXuQBMsyM",
        "title": "DetGPT: Detect What You Need via Reasoning",
        "track": "main",
        "status": "Long Main",
        "keywords": "embodied AI;multi-modal learning;object detection",
        "authors": "",
        "rating": "",
        "confidence": "5;4;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "6mPs06irie",
        "title": "GlobalBench: A Benchmark for Global Progress in Natural Language Processing",
        "track": "main",
        "status": "Long Main",
        "keywords": "Multilingual benchmark;Leaderboard",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "6mZIF4OxSq",
        "title": "K-HATERS: A Hate Speech Detection Corpus in Korean with Target-Specific Ratings",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Hate speech;Offensive language;Dataset construction;Fairness;Explainability",
        "authors": "",
        "rating": "",
        "confidence": "3;5;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "6muz29kMQu",
        "title": "Multilingual Holistic Bias: Extending Descriptors and Patterns to Unveil Demographic Biases in Languages at Scale",
        "track": "main",
        "status": "Long Main",
        "keywords": "Multilingual holistic bias;Machine Translation;Sentence Embeddings",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "6nLdWdTeos",
        "title": "Learning Dynamic Representations for Discourse Dependency Parsing",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Discourse dependency parsing;Transition systems;Dynamic sub-tree representations;Graph attention networks",
        "authors": "",
        "rating": "",
        "confidence": "3;3;2",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "6ne78DBkxl",
        "title": "PaRaDe: Passage Ranking using Demonstrations with LLMs",
        "track": "main",
        "status": "Short Findings",
        "keywords": "in-context learning;demonstration;query likelihood;re-ranking;question generation",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "6pPCKWzYw4",
        "title": "Code-Switching Metrics Using Intonation Units",
        "track": "main",
        "status": "Long Main",
        "keywords": "Computationally-aided linguistic analysis;Linguistic Diversity;Multilingualism and Cross-Lingual NLP;Spanish-English Code-Switching",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "6srsYdjLnV",
        "title": "Hi Guys or Hi Folks? Benchmarking Gender-Neutral Machine Translation with the GeNTE Corpus",
        "track": "main",
        "status": "Long Main",
        "keywords": "inclusivity;machine translation;gender;non-binary;evaluation;benchmark",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4;3",
        "correctness": "4;3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "6tW1WEHIJe",
        "title": "Is the Answer in the Text? Challenging ChatGPT with Evidence Retrieval from Instructive Text",
        "track": "main",
        "status": "Short Findings",
        "keywords": "question answering;hallucination;evidence retrieval;dataset creation;generative language models;chatgpt",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "6wj8Xczqkn",
        "title": "INarIG: Iterative Non-autoregressive Instruct Generation Model For Word-Level Auto Completion",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Word-Level Auto Completion;Computer-Aided Translation",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "6zSuMMtUjO",
        "title": "IntenDD: A Unified Contrastive Learning Approach for Intent Detection and Discovery",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Intent Discovery;Intent Detection;Contrastive Learning;Modified Adsorption;Label Propagation",
        "authors": "",
        "rating": "",
        "confidence": "3;5;5;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "71Lz8HW3NE",
        "title": "Addressing NER Annotation Noises with Uncertainty-Guided Tree-Structured CRFs",
        "track": "main",
        "status": "Long Main",
        "keywords": "Named Entity Recognition (NER);Partial and Incorrect Annotation;Uncertainty;constituency tree parsing",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "73kjtIZ4pt",
        "title": "TELeR: A General Taxonomy of LLM Prompts for Benchmarking Complex Tasks",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Large Language Models;Prompt Engineering;Prompt Taxonomy;Benchmarking",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "77h6pSkw4N",
        "title": "DocSplit: Simple Contrastive Pretraining for Large Document Embeddings",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Natural Language Processing; Machine Learning;Text Embeddings",
        "authors": "",
        "rating": "",
        "confidence": "3;3;5",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "7CTp2gwqin",
        "title": "TLM: Token-Level Masking for Transformers",
        "track": "main",
        "status": "Long Main",
        "keywords": "Token-Level;Masking;Transformers;Overfitting",
        "authors": "",
        "rating": "",
        "confidence": "3;4;5;3",
        "correctness": "3;3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "7D4TPisEBk",
        "title": "Selective Demonstrations for Cross-domain Text-to-SQL",
        "track": "main",
        "status": "Long Findings",
        "keywords": "text-to-SQL;semantic parsing;in-context learning",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "7DueCuvmgM",
        "title": "Incorporating Structured Representations into Pretrained Vision \\& Language Models Using Scene Graphs",
        "track": "main",
        "status": "Long Main",
        "keywords": "Vision and language models; Scene graphs; Visio-linguistic compositionality",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "7F5w5AQrv7",
        "title": "Task-Aware Self-Supervised Framework for Dialogue Discourse Parsing",
        "track": "main",
        "status": "Long Findings",
        "keywords": "dialogue discourse parsing;emotion recognition in conversations;self-supervision;Soft-window triangular mask",
        "authors": "",
        "rating": "",
        "confidence": "5;4;2",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "7FXgefa9lU",
        "title": "This Reads Like That: Deep Learning for Interpretable Natural Language Processing",
        "track": "main",
        "status": "Short Main",
        "keywords": "interpretability;natural language processing;deep learning",
        "authors": "",
        "rating": "",
        "confidence": "3;3;2",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "7FaWK7HpKK",
        "title": "Interpreting Answers to Yes-No Questions in User-Generated Content",
        "track": "main",
        "status": "Long Findings",
        "keywords": "yes-no questions;question answering",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "4;4;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "7GxY4WVBzc",
        "title": "Arabic Mini-ClimateGPT : A Climate Change and Sustainability Tailored Arabic LLM",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Large Language Model;Climate change;Sustainability;Arabic NLP",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "7Gy8FXaTv6",
        "title": "CRUSH4SQL: Collective Retrieval Using Schema Hallucination For Text2SQL",
        "track": "main",
        "status": "Long Main",
        "keywords": "Text-to-SQL;LLM;Retrieval augmentation;Query decomposition",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "7H45HfXsJb",
        "title": "KCTS: Knowledge-Constrained Tree Search Decoding with Token-Level Hallucination Detection",
        "track": "main",
        "status": "Long Main",
        "keywords": "Hallucination;Knowledge Grounding;Natural Language Generation;Constrained Decoding;Controllable Text Generation",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "7IB8gZRptd",
        "title": "SUT: Active Defects Probing for Transcompiler Models",
        "track": "main",
        "status": "Short Main",
        "keywords": "Program translation;LLM Evaluation;Unit Test;Syntax Error Analysis",
        "authors": "",
        "rating": "",
        "confidence": "5;3;1",
        "correctness": "4;3;1",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "7IcVI11lkO",
        "title": "Improving Transformer-based Program Repair Model through False Behavior Diagnosis",
        "track": "main",
        "status": "Long Main",
        "keywords": "Transformer;Program Repair;False Behavior",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "7Jis2yiiEZ",
        "title": "Syllogistic Reasoning for Legal Judgment Analysis",
        "track": "main",
        "status": "Long Main",
        "keywords": "Legal Judgment Analysis;Syllogism;Syllogistic Reasoning",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "3;3;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "7LBhEJ1DII",
        "title": "Quantifying Character Similarity with Vision Transformers",
        "track": "main",
        "status": "Long Main",
        "keywords": "record linkage;homoglyphs;character similarity",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "7MmYaN93lb",
        "title": "Is Robustness Transferable across Languages in Multilingual Neural Machine Translation?",
        "track": "main",
        "status": "Long Findings",
        "keywords": "robustness;transfer learning;multilingual neural machine translation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "7O9bTjLgTQ",
        "title": "VISIT: Visualizing and Interpreting the Semantic Information Flow of Transformers",
        "track": "main",
        "status": "Long Findings",
        "keywords": "attention;interpretability;visualization",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "7QSa2w5Wai",
        "title": "Transitioning Representations between Languages for Cross-lingual Event Detection via Langevin Dynamics",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Event Detection;Information Extraction;Cross-lingual Transfer Learning;Langevin Dynamics",
        "authors": "",
        "rating": "",
        "confidence": "4;4;5;4",
        "correctness": "3;3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "7QSvLXXHQt",
        "title": "Who Wrote it and Why? Prompting Large-Language Models for Authorship Verification",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Authorship Verification;Chain-of-Thought Prompting",
        "authors": "",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "7RzRbVXWPN",
        "title": "AfriSenti: A Twitter Sentiment Analysis Benchmark for African Languages",
        "track": "main",
        "status": "Long Main",
        "keywords": "Africa;Sentiment;Dataset;NLP",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "7SaXczaBpG",
        "title": "RWKV: Reinventing RNNs for the Transformer Era",
        "track": "main",
        "status": "Long Findings",
        "keywords": "large language model;scaling laws;open source;pretraining",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4;5",
        "correctness": "4;2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "7TKKvwyQef",
        "title": "DialGuide: Aligning Dialogue Model Behavior with Developer Guidelines",
        "track": "main",
        "status": "Long Findings",
        "keywords": "dialogue;safety;generation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "7UVOFuNk27",
        "title": "e-THERAPIST: I suggest you to cultivate a mindset of positivity and nurture uplifting thoughts",
        "track": "main",
        "status": "Long Main",
        "keywords": "Dialogue Systems;Psychotherapy;Persona;Sentiment;Politeness;Interpersonal communication Strategy;Rewards;Reinforcement Learning",
        "authors": "",
        "rating": "",
        "confidence": "5;3;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "7UvOkmrB8V",
        "title": "Approximating CKY with Transformers",
        "track": "main",
        "status": "Long Findings",
        "keywords": "transformer;algorithmic reasoning;dynamic programming;constituency parsing",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "7YluNq3HQQ",
        "title": "BYOC: Personalized Few-Shot Classification with Co-Authored Class Descriptions",
        "track": "main",
        "status": "Long Findings",
        "keywords": "text classification;large language models;prompt engineering;few-shot classification;user study;personalization",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "7Z1F0h7gWq",
        "title": "Learn and Consolidate: Continual Adaptation for Zero-Shot and Multilingual Neural Machine Translation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Multilingual Neural Machine Translation;Zero-shot Machine Translation;Continual Learning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "2;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "7cXoueVCoL",
        "title": "CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code",
        "track": "main",
        "status": "Long Main",
        "keywords": "nl2code;code generation;code;evaluation;codebert;bertscore",
        "authors": "",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "2;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "7fdIbXjRSp",
        "title": "Thorny Roses: Investigating the Dual Use Dilemma in Natural Language Processing",
        "track": "main",
        "status": "Long Findings",
        "keywords": "dual use;ai ethics;checklist;harms;survey",
        "authors": "",
        "rating": "",
        "confidence": "5;3;3",
        "correctness": "2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "7gIhLGqyph",
        "title": "Are Structural Concepts Universal in Transformer Language Models? Towards Interpretable Cross-Lingual Generalization",
        "track": "main",
        "status": "Long Findings",
        "keywords": "cross-lingual generalization;syntax;multilinguality;language models",
        "authors": "",
        "rating": "",
        "confidence": "3;2;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "7hSVLwNbWT",
        "title": "Coverage-based Example Selection for In-Context Learning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "In-Context Learning;Demonstration Selection;Large Language Models;Prompting;Compositional Generalization;Semantic Parsing",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "7jYZd05yjJ",
        "title": "ClusterLLM: Large Language Models as a Guide for Text Clustering",
        "track": "main",
        "status": "Long Main",
        "keywords": "text clustering;large language model;sentence relation;entropy-based sampling",
        "authors": "",
        "rating": "",
        "confidence": "2;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "7okuG5JhaM",
        "title": "Can ChatGPT Perform Reasoning Using the IRAC Method in Analyzing Legal Scenarios Like a Lawyer?",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Legal Reasoning;IRAC method;Natural Language Processing;Generative Language Models;In-context Learning;Question Decomposition",
        "authors": "",
        "rating": "",
        "confidence": "3;5;4",
        "correctness": "2;5;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "7qCuicCunf",
        "title": "Learning to love diligent trolls: Accounting for rater effects in the dialogue safety task",
        "track": "main",
        "status": "Short Findings",
        "keywords": "chatbots;trolls;safety;automated essay scoring;latent class analysis",
        "authors": "",
        "rating": "",
        "confidence": "2;3;4;3;4",
        "correctness": "4;3;2;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.2,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "7rjkSqMJ5n",
        "title": "Target-Agnostic Gender-Aware Contrastive Learning for Mitigating Bias in Multilingual Machine Translation",
        "track": "main",
        "status": "Long Main",
        "keywords": "machine translation;bias mitigation;contrastive learning",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "7s8KOmvdJc",
        "title": "InheritSumm: A General, Versatile and Compact Summarizer by Distilling from GPT",
        "track": "main",
        "status": "Long Findings",
        "keywords": "summarization;distillation;zero-shot;few-shot;large language model",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "7umLwqBbvw",
        "title": "A Comprehensive Evaluation of Tool-Assisted Generation Strategies",
        "track": "main",
        "status": "Long Findings",
        "keywords": "tool-assisted;tool-augmented;tool usage;large language models;LLMs;few-shot",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "7vR0fWRwTX",
        "title": "Exploring Discourse Structure in Document-level Machine Translation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Document-level Machine Translation;Discourse Structure;RST Parsing",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3;4",
        "correctness": "3;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "7wJhlDMNH7",
        "title": "Can We Edit Multimodal Large Language Models?",
        "track": "main",
        "status": "Long Main",
        "keywords": "Model Editing;Multimodal Language Models;Large Language Models",
        "authors": "",
        "rating": "",
        "confidence": "1;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "80ZDEuEJVC",
        "title": "A Parallel Corpus for Vietnamese Central-Northern Dialect Text Transfer",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Vietnamese;Dialect;Text Style Transfer",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "83m634EuTW",
        "title": "Re-Examining Summarization Evaluation across Multiple Quality Criteria",
        "track": "main",
        "status": "Short Findings",
        "keywords": "summarization;evaluation;summarization evaluation;confounding variable;spurious correlation;confounding factor",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "855dPxyaex",
        "title": "Finding Authentic Counterhate Arguments: A Case Study with Public Figures",
        "track": "main",
        "status": "Long Main",
        "keywords": "Hate Speech;Counterhate;Social Media",
        "authors": "",
        "rating": "",
        "confidence": "3;5;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "8752c2KVwd",
        "title": "Dialect-to-Standard Normalization: A Large-Scale Multilingual Evaluation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "text normalization;multilingual evaluation;multilingual datasets;linguistic variation;dialects and language varieties;Finnish;Norwegian;Slovene;Swiss German",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "87WEkTIVSh",
        "title": "Multilingual Pixel Representations for Translation and Effective Cross-lingual Transfer",
        "track": "main",
        "status": "Long Main",
        "keywords": "machine translation;pixel representations;multilinguality;cross-lingual transfer;unseen scripts",
        "authors": "",
        "rating": "",
        "confidence": "4;4;2",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "8851TT2R0l",
        "title": "The Benefits of Label-Description Training for Zero-Shot Text Classification",
        "track": "main",
        "status": "Long Main",
        "keywords": "zero-shot;text classification;label description",
        "authors": "",
        "rating": "",
        "confidence": "5;4;5",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "8AKBcTXEd3",
        "title": "Unifying Discrete and Continuous Representations for Unsupervised Paraphrase Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "unsupervised paraphrase generation;discrete variables;VQ-VAE;entity",
        "authors": "",
        "rating": "",
        "confidence": "4;4;1",
        "correctness": "3;5;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "8B9mL26NDT",
        "title": "On the Impact of Cross-Domain Data on German Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "large language models;cross-domain datasets;data diversity;data quality;benchmark",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "8CQ0DUuSAK",
        "title": "Clustering Pseudo Language Family in Multilingual Translation Models with Fisher Information Matrix",
        "track": "main",
        "status": "Short Main",
        "keywords": "Multilingual Translation;Low-resource",
        "authors": "",
        "rating": "",
        "confidence": "2;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "8DKrruapZ5",
        "title": "Boosting Prompt-Based Self-Training With Mapping-Free Automatic Verbalizer for Multi-Class Classification",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Prompt-based Learning;Prompt-based fine-tuning;Prompt-based self-training;Verbalizer;Label Word Mapping",
        "authors": "",
        "rating": "",
        "confidence": "4;4;2",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "8ElstW3DUT",
        "title": "DADA: Dialect Adaptation via Dynamic Aggregation of Linguistic Rules",
        "track": "main",
        "status": "Long Main",
        "keywords": "Dialect Adaptation; Dialect Robustness; Linguistic Diversity; Fairness; Human-Centered NLP",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "8FXeFY5487",
        "title": "Enhancing Scalability of Pre-trained Language Models via Efficient Parameter Sharing",
        "track": "main",
        "status": "Long Findings",
        "keywords": "parameter-efficient;pre-trained language models;scalability",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3;3",
        "correctness": "4;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "8FgdMHbW27",
        "title": "Poisoning Retrieval Corpora by Injecting Adversarial Passages",
        "track": "main",
        "status": "Short Main",
        "keywords": "Dense Retrieval;Corpus Poisoning;Adversarial Attack",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "8IrFLWRvuW",
        "title": "InfoDiffusion: Information Entropy Aware Diffusion Process for Non-Autoregressive Text Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Text generation;Diffusion model;Information entropy",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "8L5SA7ENI4",
        "title": "The Sentiment Problem: A Critical Survey towards Deconstructing Sentiment Analysis",
        "track": "main",
        "status": "Long Main",
        "keywords": "Sentiment Analysis;Natural Language Processing;Critical Survey;Ethics in NLP;Ethics based Auditing.",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "8LSuy5nNmz",
        "title": "Multilingual Generation and Answering of Questions from Texts and Knowledge Graphs",
        "track": "main",
        "status": "Long Findings",
        "keywords": "question generation;question answering;multilinguality;multi-modality;knowledge bases;consistency",
        "authors": "",
        "rating": "",
        "confidence": "3;2;2",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "8NA76tz7Jj",
        "title": "Data Augmentation for Code Translation with Comparable Corpora and Multiple References",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Code translation;Machine learning for code",
        "authors": "",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "8NFU2kLql3",
        "title": "HANSEN: Human and AI Spoken Text Benchmark for Authorship Analysis",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Authorship analysis;Spoken text;Large Language Model;AI text detection",
        "authors": "",
        "rating": "",
        "confidence": "5;3;3",
        "correctness": "2;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "8PNFSDJ3md",
        "title": "Empower Nested Boolean Logic via Self-Supervised Curriculum Learning",
        "track": "main",
        "status": "Long Main",
        "keywords": "nested boolean logic;curriculum learning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;2",
        "correctness": "3;5;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "8POQ904HEc",
        "title": "HeQ: a Large and Diverse Hebrew Reading Comprehension Benchmark",
        "track": "main",
        "status": "Long Findings",
        "keywords": "hebrew;machine reading comprehension;question answering;dataset",
        "authors": "",
        "rating": "",
        "confidence": "3;3;2",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "8Rif7M7Z6A",
        "title": "DepNeCTI: Dependency-based Nested Compound Type Identification for Sanskrit",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Nested compound type identification for Sanskrit;word-level lexical semantics;newly annotated dataset;benchmarking and dependency-based novel framework.",
        "authors": "",
        "rating": "",
        "confidence": "3;2;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "8UWPQboDq9",
        "title": "Multi-Task Learning of Query Generation and Classification for Generative Conversational Question Rewriting",
        "track": "main",
        "status": "Long Findings",
        "keywords": "multi-task learning;follow-up question identification;conversational question rewriting;text generation model",
        "authors": "",
        "rating": "",
        "confidence": "5;2;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "8VK9XXgFHp",
        "title": "A Read-and-Select Framework for Zero-shot Entity Linking",
        "track": "main",
        "status": "Long Findings",
        "keywords": "entity linking;zero-shot learning",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "1;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "8WXwPUBFEb",
        "title": "Reading Order Matters: Information Extraction from Visually-rich Documents by Token Path Prediction",
        "track": "main",
        "status": "Long Main",
        "keywords": "visually-rich document understanding;information extraction;named entity recognition",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "5;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "8Y9G7579DP",
        "title": "You Told Me That Joke Twice: A Systematic Investigation of Transferability and Robustness of Humor Detection Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "humor detection;evaluation;transferability;robustness",
        "authors": "",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "4;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "8cRL5fPwUI",
        "title": "Time-Aware Language Modeling for Historical Text Dating",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Text Dating;Diachronic Text Evaluation;Time-Aware Language Model;Temporal Adaption;Hierarchical Model",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4;4",
        "correctness": "2;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "8e9aFrksRq",
        "title": "Semantic Decomposition of Question and SQL for Text-to-SQL Parsing",
        "track": "main",
        "status": "Long Findings",
        "keywords": "semantic parsing;text-to-sql;question decomposition;compositionality",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "8gYRHspcxK",
        "title": "Aligning Large Language Models through Synthetic Feedback",
        "track": "main",
        "status": "Long Main",
        "keywords": "Alignment Learning;Large Language Models",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "8iB0FJmOfV",
        "title": "q2d: Turning Questions into Dialogs to Teach Models How to Search",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large language models;dialog generation;query generation;external search API;synthetic training data;QReCC dataset;information-seeking dialogs;q2d;data generation pipeline;synthetic dialogs;human-generated dialogs;grounded responses;anaphora;outdated information;hallucinations;factually consistent responses;multi-hop QA;PaLM",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "8l2m7jctGv",
        "title": "Focus on the Core: Efficient Attention via Pruned Token Compression for Document Classification",
        "track": "main",
        "status": "Long Findings",
        "keywords": "document classification;pre-trained transformer;attention;token pruning;token combining",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "8mJujVetQv",
        "title": "Less than One-shot: Named Entity Recognition via Extremely Weak Supervision",
        "track": "main",
        "status": "Long Findings",
        "keywords": "extremely weak supervison;few-shot learning;named entity extraction",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "8oy8hUeem9",
        "title": "InstOptima: Evolutionary Multi-objective Instruction Optimization via Large Language Model-based Instruction Operators",
        "track": "main",
        "status": "Short Findings",
        "keywords": "instruction optimization;automated instruction generation;evolutionary multi-objective optimization;language model-based operators",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "8uSB79mZks",
        "title": "Relation-Aware Question Answering for Heterogeneous Knowledge Graphs",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Question Answering;Knowledge Graph;Heterogeneous",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "8xyd9i1XLb",
        "title": "MoPe: Model Perturbation based Privacy Attacks on Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "large language model;membership inference;data extraction",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "8zQ77tPTMR",
        "title": "Consistency is Key: On Data-Efficient Modality Transfer in Speech Translation",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Speech Translation;Cross-modal Transfer;Efficient Training",
        "authors": "",
        "rating": "",
        "confidence": "4;2;4;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "99msyVXHEq",
        "title": "CLAIR: Evaluating Image Captions with Large Language Models",
        "track": "main",
        "status": "Short Main",
        "keywords": "Image Captioning;Evaluation;Metrics;Large Language Models",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4;3",
        "correctness": "3;3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "9Ax0pyaLgh",
        "title": "Cross-modality Data Augmentation for End-to-End Sign Language Translation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Sign Language Translation;Cross Modality;Data Augmentation",
        "authors": "",
        "rating": "",
        "confidence": "5;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "9BuTdxSfIO",
        "title": "kNN-CM: A Non-parametric Inference-Phase Adaptation of Parametric Text Classifiers",
        "track": "main",
        "status": "Long Findings",
        "keywords": "nearest neighbors;text classification;semi-parametric models;non-parametric models;kNN-CM;kNN-LM",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "9EYS2EEqFq",
        "title": "CAR: Conceptualization-Augmented Reasoner for Zero-Shot Commonsense Question Answering",
        "track": "main",
        "status": "Long Findings",
        "keywords": "commonsense reasoning;conceptualization;zero shot;question answering",
        "authors": "",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "9EYaUfyRYk",
        "title": "Beyond Testers\u2019 Biases: Guiding Model Testing with Knowledge Bases using LLMs",
        "track": "main",
        "status": "Long Findings",
        "keywords": "model testing;knowledge base;large language models;human-centered NLP",
        "authors": "",
        "rating": "",
        "confidence": "5;5;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "9F6h0oIYsP",
        "title": "Leveraging Contrastive Learning and Knowledge Distillation for Incomplete Modality Rumor Detection",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Rumor detection;Contrastive learning;Knowledge distillation;Incomplete modality",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "9GxP2Kw8IC",
        "title": "Synthesize, if you do not have: Effective Synthetic Dataset Creation Strategies for Self-Supervised Opinion Summarization in E-commerce",
        "track": "main",
        "status": "Short Findings",
        "keywords": "opinion summarization;summarization;ecommerce;nlp",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "9HbJGoe4a8",
        "title": "Sound of Story: Multi-modal Storytelling with Audio",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multi-modal;Story understanding;Audio-video retrieval;Audio generation",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "9HjxuDwTNG",
        "title": "Towards a Unified Conversational Recommendation System: Multi-task Learning via Contextualized Knowledge Distillation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Recommendation;Multi-task learning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "9K1urVN7ti",
        "title": "DueT: Image-Text Contrastive Transfer Learning with Dual-adapter Tuning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Vision and Language",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "9LPJK81xy1",
        "title": "Conversation Chronicles: Towards Diverse Temporal and Relational Dynamics in Multi-Session Conversations",
        "track": "main",
        "status": "Long Main",
        "keywords": "Multi-Session Dialogue;Long-Term Conversation",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "9NGR4GdLII",
        "title": "Coarse-to-Fine Dual Encoders are Better Frame Identification Learners",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Frame Identification;Frame Semantics;Contrastive Learning;Metric Learing",
        "authors": "",
        "rating": "",
        "confidence": "3;1;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "9OPtgQlxVD",
        "title": "BioDEX: Large-Scale Biomedical Adverse Drug Event Extraction for Real-World Pharmacovigilance",
        "track": "main",
        "status": "Long Findings",
        "keywords": "pharmacovigilance;datasets;healthcare;adverse drug events",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "9RFBVLwiOn",
        "title": "SEER : A Knapsack approach to Exemplar Selection for In-Context HybridQA",
        "track": "main",
        "status": "Long Main",
        "keywords": "Hybrid Question Answering;In-Context Learning;Integer Linear Programming",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "9RugvdmIBa",
        "title": "PARROT: Zero-Shot Narrative Reading Comprehension via Parallel Reading",
        "track": "main",
        "status": "Long Findings",
        "keywords": "narrative reading comprehension;zero-shot learning",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "9S0MFwEkc3",
        "title": "Rethinking the Construction of Effective Metrics for Understanding the Mechanisms of Pretrained Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Metrics;Probe;Mechanisms;Pretrained Language Models",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "9V0M45lJAs",
        "title": "Towards a Better Understanding of Variations in Zero-Shot Neural Machine Translation Performance",
        "track": "main",
        "status": "Long Main",
        "keywords": "Zero-shot Machine Translation;Multilingual Machine Translation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "9cALtYoAEy",
        "title": "Vector-Quantized Prompt Learning for Paraphrase Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Natural Language Processing;Natural Language Generation;Text generation;Paraphrase",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3;2",
        "correctness": "3;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "9edEJfhOFL",
        "title": "Towards Unsupervised Recognition of Token-level Semantic Differences in Related Documents",
        "track": "main",
        "status": "Short Main",
        "keywords": "recognizing semantic differences;semantic similarity;multilinguality",
        "authors": "",
        "rating": "",
        "confidence": "3;4;2",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "9qydIw5ux1",
        "title": "Ethical Reasoning over Moral Alignment: A Case and Framework for In-Context Ethical Policies in LLMs",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Ethics in NLP;Ethical Reasoning;Value Pluralism;Large Language Models",
        "authors": "",
        "rating": "",
        "confidence": "2;4;3",
        "correctness": "2;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "9r8WwpJv7M",
        "title": "Ling-CL: Understanding NLP Models through Linguistic Curricula",
        "track": "main",
        "status": "Long Main",
        "keywords": "linguistic index;curriculum learning",
        "authors": "",
        "rating": "",
        "confidence": "1;4;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "9rWqOgvGpc",
        "title": "PTP: Boosting Stability and Performance of Prompt Tuning with Perturbation-Based Regularizer",
        "track": "main",
        "status": "Long Main",
        "keywords": "prompt tuning; training with regularizers",
        "authors": "",
        "rating": "",
        "confidence": "3;4;5",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "9s7QooDInQ",
        "title": "SGP-TOD: Building Task Bots Effortlessly via Schema-Guided LLM Prompting",
        "track": "main",
        "status": "Long Findings",
        "keywords": "schema-guided LLM prompting;task bot;zero-shot dialog generation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "2;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "9z2yznFVw5",
        "title": "Decomposed Prompt Tuning via Low-Rank Reparameterization",
        "track": "main",
        "status": "Long Findings",
        "keywords": "prompt tuning;parameter-efficient tuning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "9zZWPEo8et",
        "title": "LogicAttack: Adversarial Attacks for Evaluating Logical Consistency of Natural Language Inference",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Logical Reasoning;Large Language Models;Natural Language Inference;Adversarial Attacks",
        "authors": "",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "A0xVOahTiw",
        "title": "MaNtLE: Model-agnostic Natural Language Explainer",
        "track": "main",
        "status": "Long Main",
        "keywords": "explainable AI;interpretability",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4;3",
        "correctness": "4;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "A2oBdekFgv",
        "title": "Dialogue Medical Information Extraction with Medical-Item Graph and Dialogue-Status Enriched Representation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Dialogue medical information extraction;Multi-label text classification;Graph neural network;Natural language processing",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "A68W11vA8o",
        "title": "Skill-Based Few-Shot Selection for In-Context Learning",
        "track": "main",
        "status": "Long Main",
        "keywords": "In-Context Learning;Few-Shot Selection;Semantic Parsing",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "A6FGmwsH7x",
        "title": "ByteSized32: A Corpus and Challenge Task for Generating Task-Specific World Models Expressed as Text Games",
        "track": "main",
        "status": "Long Main",
        "keywords": "text games;code generation;simulation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "AAYXFyvNbr",
        "title": "Tokenization Consistency Matters for Generative Models on Extractive NLP Tasks",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Tokenization;Question Answering",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4;4",
        "correctness": "3;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "AAnYBhWKRv",
        "title": "FOCUS: Effective Embedding Initialization for Monolingual Specialization of Multilingual Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "model transfer;multilingual;crosslingual",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "AAuVIl8Aeo",
        "title": "Characterizing and Verifying Scientific Claims: Qualitative Causal Structure is All You Need",
        "track": "main",
        "status": "Long Main",
        "keywords": "Scientific Claim Verification;Heterogeneous Graph;reasoning",
        "authors": "",
        "rating": "",
        "confidence": "2;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ACogU4OVFK",
        "title": "From Speculation Detection to Trustworthy Relational Tuples in Information Extraction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "speculation detection;text classification;information extraction",
        "authors": "",
        "rating": "",
        "confidence": "3;5;3;3",
        "correctness": "4;3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "AD0o090nDJ",
        "title": "An Exploration of Left-Corner Transformations",
        "track": "main",
        "status": "Long Main",
        "keywords": "left-corner transformation;top-down parsing;left-recursion;grammar transformations;speculation;formal language theory;weighted CFG;left-corner transform",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ADHMUuN7CE",
        "title": "EXPLAIN, EDIT, GENERATE: Rationale-Sensitive Counterfactual Data Augmentation for Multi-hop Fact Verification",
        "track": "main",
        "status": "Long Main",
        "keywords": "multi-hop fact verification;counterfactual data augmentation;out-of-domain generalization",
        "authors": "",
        "rating": "",
        "confidence": "3;2;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ADsEdyI32n",
        "title": "LLMLingua: Compressing Prompts for Accelerated Inference of Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Prompt Compression;LLMs;Inference Acceleration;Black-box LLMs;Efficient LLMs",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "AEkFAAprvF",
        "title": "ViStruct: Visual Structural Knowledge Extraction via Curriculum Guided Code-Vision Representation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Visual Structural Knowledge Extraction;Code-Vision Representation;Curriculum-based Learning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "3;4;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "AGVANImv7S",
        "title": "Systematic Assessment of Factual Knowledge in Large Language Models",
        "track": "main",
        "status": "Short Findings",
        "keywords": "large language models;hallucination;knowledge graph",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4;4",
        "correctness": "3;2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "AJDSZ2YVI6",
        "title": "PALS: Personalized Active Learning for Subjective Tasks in NLP",
        "track": "main",
        "status": "Long Main",
        "keywords": "personalization;user modeling;active learning;natural language processing;subjective NLP tasks;subjective NLP",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "AQiuwWLvim",
        "title": "Conditioning on Dialog Acts improves Empathy Style Transfer",
        "track": "main",
        "status": "Long Findings",
        "keywords": "empathy style transfer;text style transfer;empathy;GPT-4;large language models;dialog acts;pragmatics;prompt engineering;in-context learning;few-shot prompting",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ARtBIBAmNR",
        "title": "Visually Guided Generative Text-Layout Pre-training for Document Intelligence",
        "track": "main",
        "status": "Reject",
        "keywords": "Multimodal Pre-training;Visual Document Understanding",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3;4",
        "correctness": "2;2;2;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 1.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "AU2Oq0z4xA",
        "title": "IMU2CLIP: Language-grounded Motion Sensor Translation with Multimodal Contrastive Learning",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Contrastive Learning;NLP Applications in Sensor Signals",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "AXY8GJzm2K",
        "title": "Learn From One Specialized Sub-Teacher: One-to-One Mapping for Feature-Based Knowledge Distillation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Knowledge Distillation;Compression;NLP;Large Language Models;Feature Distillation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "AYOfbWMRSd",
        "title": "To Build Our Future, We Must Know Our Past: Contextualizing Paradigm Shifts in Natural Language Processing",
        "track": "main",
        "status": "Long Main",
        "keywords": "paradigm shift;future of nlp research;incentives;benchmarking;software;science of science",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;1;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "AZ8sFZtLHD",
        "title": "Difference-Masking: Choosing What to Mask in Continued Pretraining",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Machine Learning;Self-Supervised Learning;Multimodal;NLP",
        "authors": "",
        "rating": "",
        "confidence": "3;1;4",
        "correctness": "2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "AZfRWT1dOa",
        "title": "Not All Demonstration Examples are Equally Beneficial: Reweighting Demonstration Examples for In-Context Learning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "In-Context Learning;Training Example Reweighting",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "AajIIYMm0d",
        "title": "Subspace Chronicles: How Linguistic Information Emerges, Shifts and Interacts during Language Model Training",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Language Modelling;Representation Learning;Learning Dynamics;Probing;Subspace Analysis",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "AbXA40kggY",
        "title": "BLESS: Benchmarking Large Language Models on Sentence Simplification",
        "track": "main",
        "status": "Long Main",
        "keywords": "text simplification;sentence simplification;large language models;evaluation;in-context learning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "AfEowGM3qG",
        "title": "NameGuess: Column Name Expansion for Tabular Data",
        "track": "main",
        "status": "Long Main",
        "keywords": "Column Name Expansion;Natural Language Generation;Datasets",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "AfnJBOXfAU",
        "title": "COFFEE: Counterfactual Fairness for Personalized Text Generation in Explainable Recommendation",
        "track": "main",
        "status": "Long Main",
        "keywords": "personalized text generation;fairness;bias;explanation for recommendation;human evaluation;counterfactual fairness",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "AgsLcJ9KaX",
        "title": "How do languages influence each other? Studying cross-lingual data sharing during LM fine-tuning",
        "track": "main",
        "status": "Long Main",
        "keywords": "cross-lingual influence;data sharing;training data attribution",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3;3",
        "correctness": "4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Ai0oBKlJP2",
        "title": "ChatGPT Beyond English: Towards a Comprehensive Evaluation of Large Language Models in Multilingual Learning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "ChatGPT;Multilingual Evaluation;Large Language Models",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;5;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "AjGXZIgvIb",
        "title": "Towards Concept-Aware Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Concepts;Pretrained Large Language Models",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Akk5ep2gQx",
        "title": "Semantic Space Grounded Weighted Decoding for Multi-Attribute Controllable Dialogue Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "dialogue response generation;chatbot;controllable generation;multi-attributes",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "AlEeMxkgsi",
        "title": "A Scalable Framework for Table of Contents Extraction from Complex ESG Annual Reports",
        "track": "main",
        "status": "Long Main",
        "keywords": "Table of Contents Extraction;Tree",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "AoGdaivPEh",
        "title": "Natural Language Decompositions of Implicit Content Enable Better Text Representations",
        "track": "main",
        "status": "Long Main",
        "keywords": "computational social science;implicit;decompositions;decompose;propositions;generation;political science;sentence embeddings;clustering",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "AptTXihnhH",
        "title": "Character-LLM: A Trainable Agent for Role-Playing",
        "track": "main",
        "status": "Long Main",
        "keywords": "human simulacra;LLM",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ArSMQ3dCUx",
        "title": "Noise-Robust Semi-Supervised Learning for Distantly Supervised Relation Extraction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Relation Extraction;Distant Supervision;Semi-Supervised-Learning",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Ariw9I14zZ",
        "title": "XLM-V: Overcoming the Vocabulary Bottleneck in Multilingual Masked Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Multilingual;Masked Language Models",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "AtjErbRsg2",
        "title": "Reconstruct Before Summarize: An Efficient Two-Step Framework for Condensing and Summarizing Meeting Transcripts",
        "track": "main",
        "status": "Long Main",
        "keywords": "meeting summarization;essential content extraction;long-text compression",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4;3",
        "correctness": "4;4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "AxPGO36LfE",
        "title": "X-SNS: Cross-Lingual Transfer Prediction through Sub-Network Similarity",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Cross-lingual transfer;Multilingual Language Model",
        "authors": "",
        "rating": "",
        "confidence": "5;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "B01gPP5YCh",
        "title": "Parameter-Efficient Prompt Tuning Makes Generalized and Calibrated Neural Text Retrievers",
        "track": "main",
        "status": "Long Findings",
        "keywords": "information retrieval;prompt tuning;generalization",
        "authors": "",
        "rating": "",
        "confidence": "2;3;2",
        "correctness": "2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "B14ohp9mPU",
        "title": "On Evaluation of Bangla Word Analogies",
        "track": "main",
        "status": "Short Main",
        "keywords": "Bangla;Word Analogy;Evaluation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "B3Muf1R1UD",
        "title": "NLMs: Augmenting Negation in Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Language Models;Negation",
        "authors": "",
        "rating": "",
        "confidence": "2;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "B3SjWgXHzM",
        "title": "Token Prediction as Implicit Classification to Identify LLM-Generated Text",
        "track": "main",
        "status": "Short Main",
        "keywords": "Machine-generated text detection;Text-to-Text Transfer Transformer (T5);Large language model;Transfer learning;Large language model",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "2;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "B3rTZovgaA",
        "title": "Doolittle: Benchmarks and Corpora for Academic Writing Formalization",
        "track": "main",
        "status": "Long Main",
        "keywords": "grammar error correction;large language models;academic writing formalization",
        "authors": "",
        "rating": "",
        "confidence": "3;2;3;4",
        "correctness": "3;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "B6BXB4g8eQ",
        "title": "Be Selfish, But Wisely: Investigating the Impact of Agent Personality in Mixed-Motive Human-Agent Interactions",
        "track": "main",
        "status": "Long Main",
        "keywords": "dialogue;negotiation;personality;reinforcement learning",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "B6Gdg7u04y",
        "title": "LLMaAA: Making Large Language Models as Active Annotators",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large language model;psuedo labeling;active learning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "B8Hz9HqnFm",
        "title": "Towards Zero-shot Learning for End-to-end Cross-modal Translation Models",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Zero-Shot;End-to-End;Speech Translation",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3;3",
        "correctness": "3;2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "B8mdHlqNfw",
        "title": "Large Language Models and Multimodal Retrieval for Visual Word Sense Disambiguation",
        "track": "main",
        "status": "Long Main",
        "keywords": "visual word sense disambiguation;large language models;multimodal retrieval",
        "authors": "",
        "rating": "",
        "confidence": "5;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "BAA4209PGJ",
        "title": "Set Learning for Generative Information Extraction",
        "track": "main",
        "status": "Short Main",
        "keywords": "Information Extraction",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "BB1qrcPgRu",
        "title": "Survival of the Most Influential Prompts: Efficient Black-Box Prompt Search via Clustering and Pruning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "large language models;black-box;discrete prompt learning",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "BEFiYM5Vtx",
        "title": "Multi-Task Knowledge Distillation with Embedding Constraints for Scholarly Keyphrase Boundary Classification",
        "track": "main",
        "status": "Long Main",
        "keywords": "keyphrase boundary classification;multi-task learning;knowledge distillation",
        "authors": "",
        "rating": "",
        "confidence": "4;5;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "BFbdO9GwTZ",
        "title": "Generative Adversarial Training with Perturbed Token Detection for Model Robustness",
        "track": "main",
        "status": "Long Main",
        "keywords": "generative adversarial training;adversarial defense;adversarial detection;discriminative pre-trained model",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "BGsssE3E4i",
        "title": "Efficient Data Learning for Open Information Extraction with Pre-trained Language Models",
        "track": "main",
        "status": "Short Findings",
        "keywords": "information extraction;efficient;low-resource",
        "authors": "",
        "rating": "",
        "confidence": "4;3;2;3",
        "correctness": "4;4;1;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "BKchhwhNh3",
        "title": "Roles of Scaling and Instruction Tuning in Language Perception: Model vs. Human Attention",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large Language Models;Attention;Human Resemblance;Instruction Tuning",
        "authors": "",
        "rating": "",
        "confidence": "3;5;3",
        "correctness": "2;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "BMIjPXooNq",
        "title": "Harnessing Dataset Cartography for Improved Compositional Generalization in Transformers",
        "track": "main",
        "status": "Long Findings",
        "keywords": "dataset cartography;compositional generalization;training dynamics",
        "authors": "",
        "rating": "",
        "confidence": "2;3;4;4",
        "correctness": "4;2;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "BNcTB8RZfG",
        "title": "Explicit Alignment and Many-to-many Entailment Based Reasoning for Conversational Machine Reading",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Conversational Machine Reading;Task-oriented dialogue;Textual Entailment",
        "authors": "",
        "rating": "",
        "confidence": "5;3;4;2;4;3",
        "correctness": "3;3;4;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "BSApuhuM87",
        "title": "Beware of Model Collapse! Fast and Stable Test-time Adaptation for Robust Question Answering",
        "track": "main",
        "status": "Long Main",
        "keywords": "Question Answering;Roboustness;Test-time adaptation",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "BViIHjzvoY",
        "title": "Data-efficient Active Learning for Structured Prediction with Partial Annotation and Self-Training",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Active Learning;Structured Prediction;Partial Annotation;Self-training",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "BYkD1gjbxm",
        "title": "Optimized Tokenization for Transcribed Error Correction",
        "track": "main",
        "status": "Long Main",
        "keywords": "NLP;Speech Recognition;Error Correction",
        "authors": "",
        "rating": "",
        "confidence": "5;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "BYxHeGsiay",
        "title": "From Words to Wires: Generating Functioning Electronic Devices from Natural Language Descriptions",
        "track": "main",
        "status": "Long Findings",
        "keywords": "applications;code generation;electronics;language models",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3;3",
        "correctness": "3;1;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "BacLV3QUi8",
        "title": "AniEE: A Dataset of Animal Experimental Literature for Event Extraction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Information Extraction;Event Extraction;Named Entity Recognition;Biomedical Corpus;Scientific Literature;Animal Experiments",
        "authors": "",
        "rating": "",
        "confidence": "3;5;3",
        "correctness": "4;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "BcYvkVgkZy",
        "title": "On Event Individuation for Document-Level Information Extraction",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Information Extraction;Template Filling;Events;Reproducibility",
        "authors": "",
        "rating": "",
        "confidence": "3;2;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "BdpoEj33DZ",
        "title": "MailEx: Email Event and Argument Extraction",
        "track": "main",
        "status": "Long Main",
        "keywords": "Event Extraction;Email;Information Extraction",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "4;4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Beho3ly3qx",
        "title": "COMET-M: Reasoning about Multiple Events in Complex Sentences",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Reasoning about events;Complex contexts;Discourse",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "BoKg2pcF0H",
        "title": "DiffusionSL: Sequence Labeling via Tag Diffusion Process",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Generative Models;Sequence Labeling;Tag Diffusion Process",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Bou2YHsRvG",
        "title": "Code-Switching with Word Senses for Pretraining in Neural Machine Translation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Word Sense Disambiguation;Pretraining approaches;Neural Machine Translation",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "BpibUh0aB3",
        "title": "Probing the \u201cCreativity\u201d of Large Language Models: Can models produce divergent semantic association?",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Creativity;Semantic association;Text generation",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "BpsWrnfIIn",
        "title": "Misery Loves Complexity: Exploring Linguistic Complexity in the Context of Emotion Detection",
        "track": "main",
        "status": "Long Findings",
        "keywords": "emotion detection;complexity;readability",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "BrqDTTga8J",
        "title": "Multi-view Contrastive Learning for Entity Typing over Knowledge Graphs",
        "track": "main",
        "status": "Long Main",
        "keywords": "Knowledge Graphs;Entity Typing;Knowledge-based Typing",
        "authors": "",
        "rating": "",
        "confidence": "5;3;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "BscCXmZopv",
        "title": "SODA: Million-scale Dialogue Distillation with Social Commonsense Contextualization",
        "track": "main",
        "status": "Long Main",
        "keywords": "social commonsense;distillation;dialogue;dataset",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4;4;3",
        "correctness": "4;4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.8,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "BxY99WBKSV",
        "title": "Ties Matter: Meta-Evaluating Modern Metrics with Pairwise Accuracy and Tie Calibration",
        "track": "main",
        "status": "Long Main",
        "keywords": "meta-evaluation;metrics;kendall's tau",
        "authors": "",
        "rating": "",
        "confidence": "2;4;4",
        "correctness": "4;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "C68cYdgLUs",
        "title": "We are Who We Cite: Bridges of Influence Between Natural Language Processing and Other Academic Fields",
        "track": "main",
        "status": "Long Main",
        "keywords": "responsible nlp;scientific influence;interdisciplinarity;bibliometrics",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "CEPkRTOlut",
        "title": "Speech Recognition and Meaning Interpretation: Towards Disambiguation of Structurally Ambiguous Spoken Utterances in Indonesian",
        "track": "main",
        "status": "Long Main",
        "keywords": "structural ambiguity in sentences;prosodic information;speech recognition;speech-to-text mapping;meaning\u00a0interpretation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "CHffPbQXjX",
        "title": "Towards Being Parameter-Efficient: A Stratified Sparsely Activated Transformer with Dynamic Capacity",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Stratified Mixture-of-Experts;Parameter-efficiency;Dynamic capacity",
        "authors": "",
        "rating": "",
        "confidence": "4;5;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "CK9mApdZFW",
        "title": "DISCO: A Large Scale Human Annotated Corpus for Disfluency Correction in Indo-European Languages",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Disfluency Correction;Machine Translation;Dataset",
        "authors": "",
        "rating": "",
        "confidence": "3;2;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "CLVOAHdybT",
        "title": "HFMRE: Constructing Huffman Tree in Bags to Find Excellent Instances for Distantly Supervised Relation Extraction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "multi-instance learning; relation extraction; Huffman Tree; aggregation strategies",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "CLq5tqZ5SK",
        "title": "A Computational Interface to Translate Strategic Intent from Unstructured Language in a Low-Data Setting",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Text Classification;ChatGPT;Human-Evaluation;Low-Data",
        "authors": "",
        "rating": "",
        "confidence": "2;4;2;3",
        "correctness": "3;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "CMm4w1A4Yd",
        "title": "A Deeper (Autoregressive) Approach to Non-Convergent Discourse Parsing",
        "track": "main",
        "status": "Long Main",
        "keywords": "Discourse;dialogue;style",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3;2",
        "correctness": "4;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "CO40wNIY5i",
        "title": "A Unified View of Evaluation Metrics for Structured Prediction",
        "track": "main",
        "status": "Long Main",
        "keywords": "structured prediction;information extraction;evaluation metrics;template extraction;n-ary relation extraction",
        "authors": "",
        "rating": "",
        "confidence": "3;3;5",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "CP1PLnFzbr",
        "title": "Context Compression for Auto-regressive Transformers with Sentinel Tokens",
        "track": "main",
        "status": "Short Main",
        "keywords": "context compression;key-value cache compression",
        "authors": "",
        "rating": "",
        "confidence": "4;3;1;3",
        "correctness": "3;3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "CPBEn5mGle",
        "title": "CQE: A Comprehensive Quantity Extractor",
        "track": "main",
        "status": "Long Main",
        "keywords": "quantities;quantity extraction;information extraction",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "CQgmBmRBMb",
        "title": "Don\u2019t Add, don\u2019t Miss: Effective Content Preserving Generation from Pre-Selected Text Spans",
        "track": "main",
        "status": "Long Findings",
        "keywords": "NLG;Controlled Generation;RL;Controlled Decoding;Distillation",
        "authors": "",
        "rating": "",
        "confidence": "1;3;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "CblASBV3d4",
        "title": "\"Are Your Explanations Reliable?\" Investigating the Stability of LIME in Explaining Text Classifiers by Marrying XAI and Adversarial Attack",
        "track": "main",
        "status": "Long Main",
        "keywords": "Interpretability;Stability;Robustness;Explainability",
        "authors": "",
        "rating": "",
        "confidence": "4;2;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Cc5yhA1PrC",
        "title": "A Joint Matrix Factorization Analysis of Multilingual Representations",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Representation analysis;Multilingual pre-trained models;Matrix factorization;Morphosyntactic features",
        "authors": "",
        "rating": "",
        "confidence": "4;1;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "CdcdyN4cvL",
        "title": "Improving Multi-Criteria Chinese Word Segmentation through Learning Sentence Representation",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Chinese Word Segmentation",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "CfJiBuysQQ",
        "title": "CLEVR-Implicit: A Diagnostic Dataset for Implicit Reasoning in Referring Expression Comprehension",
        "track": "main",
        "status": "Long Main",
        "keywords": "referring expression comprehension;implicit reasoning;prompt tuning",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3;4",
        "correctness": "4;4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "CgAfbI4kGS",
        "title": "CompleQA: Benchmarking the Impacts of Knowledge Graph Completion Methods on Question Answering",
        "track": "main",
        "status": "Short Findings",
        "keywords": "knowledge graph;link prediction;question answering",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "2;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Cib0JSAVwW",
        "title": "Language-Agnostic Bias Detection in Language Models with Bias Probing",
        "track": "main",
        "status": "Long Findings",
        "keywords": "bias detection;nationality bias;multilinguality",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "CihCvXPiEG",
        "title": "Re-weighting Tokens: A Simple and Effective Active Learning Strategy for Named Entity Recognition",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Named entity recognition;active learning",
        "authors": "",
        "rating": "",
        "confidence": "2;5;5",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Ck3JPqoEeE",
        "title": "Linguistically Motivated Sign Language Segmentation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "sign language;sign language segmentation",
        "authors": "",
        "rating": "",
        "confidence": "2;4;3",
        "correctness": "2;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "CkvfJdb7mw",
        "title": "Cultural Compass: Predicting Transfer Learning Success in Offensive Language Detection with Cultural Features",
        "track": "main",
        "status": "Long Findings",
        "keywords": "culture;transfer learning;offensive language detection",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "CluDBdRhUp",
        "title": "Probing Representations for Document-level Event Extraction",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Information Extraction;Interpretability;Embedding;Probing;Document-Level Information Extraction",
        "authors": "",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Cn3HNSzh14",
        "title": "Controlling Pre-trained Language Models for Grade-Specific Text Simplification",
        "track": "main",
        "status": "Long Main",
        "keywords": "Controllable Text generation;Text Simplification",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4;4",
        "correctness": "2;3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "CnLpDkgnCn",
        "title": "Mandarin classifier systems optimize to accommodate communicative pressures",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Mandarin Chinese;classifiers;noun classes;noun class processing;word embeddings;mutual information;GAM",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "CoEuk8SNI1",
        "title": "Enhancing Emotion Recognition in Conversation via Multi-view Feature Alignment and Memorization",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Emotion Recognition in Conversation;Multi-view Feature Alignment;Memorization",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Coh1A4iSsl",
        "title": "Revisiting Sparse Retrieval for Few-shot Entity Linking",
        "track": "main",
        "status": "Short Main",
        "keywords": "entity linking;sparse retrieval",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "CsCRTvEZg1",
        "title": "MISCA: A Joint Model for Multiple Intent Detection and Slot Filling with Intent-Slot Co-Attention",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multiple Intent Detection;Slot Filling;Intent-Slot Co-Attention;Label Attention",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Cu4Jn4Xt22",
        "title": "Joint Geometrical and Statistical Domain Adaptation for Cross-domain Code Vulnerability Detection",
        "track": "main",
        "status": "Long Main",
        "keywords": "Contrastive Learning;Code Vulnerability;Cross-domain Detection",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "CuI1xfhxaJ",
        "title": "Question Answering as Programming for Solving Time-Sensitive Questions",
        "track": "main",
        "status": "Long Main",
        "keywords": "large language models;reasoning;question answering",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Cx5vVkpsOY",
        "title": "Pragmatics in Language Grounding: Phenomena, Tasks, and Modeling Approaches",
        "track": "main",
        "status": "Long Findings",
        "keywords": "grounding;pragmatics;multimodality;survey",
        "authors": "",
        "rating": "",
        "confidence": "5;5;5",
        "correctness": "4;3;1",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 5.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "CyDf6Q619o",
        "title": "Enabling Unsupervised Neural Machine Translation with Word-level Visual Representations",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Unsupervised Machine Translation;Cross-modal Machine Translation;Word-level Image",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "D0Mp7ILZME",
        "title": "SuperTweetEval: A Challenging, Unified and Heterogeneous Benchmark for Social Media NLP Research",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Social Media;Benchmark;Twitter",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "D0gAwtclWk",
        "title": "Rethinking Negative Pairs in Code Search",
        "track": "main",
        "status": "Long Main",
        "keywords": "Code Search;Contrastive Learning",
        "authors": "",
        "rating": "",
        "confidence": "4;2;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "D1kF1Eq7Mv",
        "title": "System Combination via Quality Estimation for Grammatical Error Correction",
        "track": "main",
        "status": "Long Main",
        "keywords": "Grammatical Error Correction;Quality Estimation;System Combination",
        "authors": "",
        "rating": "",
        "confidence": "3;3;5",
        "correctness": "4;3;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "D4Cb4gAWro",
        "title": "Predictive Chemistry Augmented with Text Retrieval",
        "track": "main",
        "status": "Long Main",
        "keywords": "information retrieval;chemistry",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "D4CoZQY1nt",
        "title": "The Less the Merrier? Investigating Language Representation in Multilingual Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multilingual;low-resource;pre-trained models;linguistic diversity;embedding space;dialect;writing script",
        "authors": "",
        "rating": "",
        "confidence": "3;3;5",
        "correctness": "3;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "D70lPh24o6",
        "title": "Explaining Interactions Between Text Spans",
        "track": "main",
        "status": "Long Main",
        "keywords": "explainability;interactions;spans",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "D7omx8QyFP",
        "title": "The CoT Collection: Improving Zero-shot and Few-shot Learning of Language Models via Chain-of-Thought Fine-Tuning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Chain-of-Thought Fine-tuning;Zero-shot Generalization;Few-shot Learning;Large Language Models",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "D97Zfgv4em",
        "title": "MeaeQ: Mount Model Extraction Attacks with Efficient Queries",
        "track": "main",
        "status": "Long Main",
        "keywords": "Model Extraction Attack; Efficient Query Sampling Strategy; Limited Query Budgets",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "D9oq45WsKq",
        "title": "Ensemble-Instruct: Instruction Tuning Data Generation with a Heterogeneous Mixture of LMs",
        "track": "main",
        "status": "Long Findings",
        "keywords": "instruction tuning data generation;prompt learning;ensemble learning",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "DDvcWpZNgl",
        "title": "PIEClass: Weakly-Supervised Text Classification with Prompting and Noise-Robust Iterative Ensemble Training",
        "track": "main",
        "status": "Long Main",
        "keywords": "Text Classification;Weak Supervision;Pre-Trained Language Model;Prompt-Based Learning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "DOlbbJhJ1A",
        "title": "Large Language Models: The Need for Nuance in Current Debates and a Pragmatic Perspective on Understanding",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Models;Critical Analysis;Interpretation;Explanation;Philosophy;Understanding;Pragmatism;NLP",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "DPhTTeoyjC",
        "title": "LM vs LM: Detecting Factual Errors via Cross Examination",
        "track": "main",
        "status": "Long Main",
        "keywords": "knowledge;factuality;LLM;question answering;interpretability;interactivity;multi-agent;consistency;fact checking;dialogue",
        "authors": "",
        "rating": "",
        "confidence": "4;2;5",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "DQ9WeXpgJt",
        "title": "Unsupervised Sounding Pixel Learning",
        "track": "main",
        "status": "Long Main",
        "keywords": "unsupervised;cross-modal learning;sound source localization;semantic affinity refinement",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4;3",
        "correctness": "4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "DQVGhBdAPG",
        "title": "Identification of Multimodal Stance Towards Frames of Communication",
        "track": "main",
        "status": "Long Main",
        "keywords": "stance detection;covid-19;social media;twitter;multimodal;images;multimedia",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "1;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "DRpZjTJKZh",
        "title": "Probabilistic Tree-of-thought Reasoning for Answering Knowledge-intensive Complex Questions",
        "track": "main",
        "status": "Long Findings",
        "keywords": "LLMs; Probabilistic Tree-of-thought Reasoning; Hallucination; Knowledge-intensive Complex QA",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "DSmHC8bi3j",
        "title": "Noise-Robust Fine-Tuning of Pretrained Language Models via External Guidance",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Pretrained Language Models;Large-scale Language Models;Learning from Noisy Labels",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "DTELCDufzE",
        "title": "Large Language Models Are Better Adversaries: Exploring Generative Clean-Label Backdoor Attacks Against Text Classifiers",
        "track": "main",
        "status": "Long Findings",
        "keywords": "adversarial machine learning;backdoor attacks;large language models;natural language processing",
        "authors": "",
        "rating": "",
        "confidence": "3;4;1",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "DTyMi3ReQU",
        "title": "You Are What You Annotate: Towards Better Models through Annotator Representations",
        "track": "main",
        "status": "Long Findings",
        "keywords": "annotator disagreement;annotator representation",
        "authors": "",
        "rating": "",
        "confidence": "3;4;5;3",
        "correctness": "2;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "DVDGNFn1Jm",
        "title": "Reinforced Target-driven Conversational Promotion",
        "track": "main",
        "status": "Long Main",
        "keywords": "Conversational Promotion;Conversational Recommendation;Target-driven Recommenders",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "DgB01RzOqo",
        "title": "Multilingual Large Language Models Are Not (Yet) Code-Switchers",
        "track": "main",
        "status": "Long Main",
        "keywords": "code-switching;benchmark;multilingual large language models",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "DgNnVebNPy",
        "title": "LLMs -- the Good, the Bad or the Indispensable?: A Use Case on Legal Statute Prediction and Legal Judgment Prediction on Indian Court Cases",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Legal judgement prediction;Legal Statute prediction;LLMs;explainability;bias;fairness;ethics",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "3;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Dil6z5sZkD",
        "title": "Adversarial Robustness for Large Language NER models using Disentanglement and Word Attributions",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Adversarial Robustness;Adversarial Attacks;Named Entity Recognition;Large Language Models",
        "authors": "",
        "rating": "",
        "confidence": "2;4;4;3",
        "correctness": "4;4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "DjwSceRw7B",
        "title": "Macedon: Minimizing Representation Coding Rate Reduction for Cross-Lingual Natural Language Understanding",
        "track": "main",
        "status": "Long Findings",
        "keywords": "cross-lingual;rate reduction",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3;3",
        "correctness": "3;3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Dl3YgoOh2c",
        "title": "Identifying Statements Crucial for Awareness of Interpretive Nonsense to Prevent Communication Breakdowns",
        "track": "main",
        "status": "Long Main",
        "keywords": "Communication breakdowns;dialogue;context;rephrasing;language model",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "DlQeSfGYfS",
        "title": "Focus Your Attention (with Adaptive IIR Filters)",
        "track": "main",
        "status": "Long Main",
        "keywords": "IIR Filters;dynamic Filtering;Transformers",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "DmrIEHJxN5",
        "title": "From Complex to Simple: Unraveling the Cognitive Tree for Reasoning with Small Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Reasoning;Cognition;Dual Process Theory",
        "authors": "",
        "rating": "",
        "confidence": "2;4;4",
        "correctness": "3;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "DpNUrB6SeZ",
        "title": "Multi-Source Multi-Type Knowledge Exploration and Exploitation for Dialogue Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Dialogue Generation;Natural Language Processing;Dialogue Knowledge",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Dq023aV4Ih",
        "title": "Hallucination Mitigation in Natural Language Generation from Large-Scale Open-Domain Knowledge Graphs",
        "track": "main",
        "status": "Long Main",
        "keywords": "graph-to-text generation;knowledge graphs",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Dqg9SLOXZu",
        "title": "Multi-Source Probing for Open-Domain Conversational Understanding",
        "track": "main",
        "status": "Long Main",
        "keywords": "Open-domain dialogue systems;Dialogue comprehension;Dialogue probing;Prompt Learning",
        "authors": "",
        "rating": "",
        "confidence": "2;4;4;3",
        "correctness": "4;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "DxYDP3B31K",
        "title": "Enhancing Generative Retrieval with Reinforcement Learning from Relevance Feedback",
        "track": "main",
        "status": "Long Main",
        "keywords": "Generative retrieval; Reinforcement learning; Document retrieval;",
        "authors": "",
        "rating": "",
        "confidence": "3;2;2",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Dy2mbQIdMz",
        "title": "DetectLLM: Leveraging Log Rank Information for Zero-Shot Detection of Machine-Generated Text",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Machine-generated Text; Large Language models; LLMs; zero-shot",
        "authors": "",
        "rating": "",
        "confidence": "2;5;1",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "DzCc4mpH1m",
        "title": "Faster Minimum Bayes Risk Decoding with Confidence-based Pruning",
        "track": "main",
        "status": "Short Main",
        "keywords": "Machine translation;minimum Bayes risk decoding",
        "authors": "",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "5;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 4.666666666666667,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "E4ebDehO3O",
        "title": "Not All Languages Are Created Equal in LLMs: Improving Multilingual Capability by Cross-Lingual-Thought Prompting",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large language models; multilingual capability; cross-lingual-thought prompting;",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "E5r96sfKO0",
        "title": "AutoTrial: Prompting Language Models for Clinical Trial Design",
        "track": "main",
        "status": "Long Main",
        "keywords": "Drug Development;Clinical Trial;Large Language Model",
        "authors": "",
        "rating": "",
        "confidence": "1;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "E9dH0BP5VW",
        "title": "Scaling Laws vs Model Architectures: How does Inductive Bias Influence Scaling?",
        "track": "main",
        "status": "Long Findings",
        "keywords": "language models;architectures;scaling laws",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4;3",
        "correctness": "3;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "EDuKP7DqCk",
        "title": "Text Embeddings Reveal (Almost) As Much As Text",
        "track": "main",
        "status": "Long Main",
        "keywords": "text embeddings;text retrieval;privacy;inversion;leakage attack",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3;3",
        "correctness": "4;3;3;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "EFML9BJcIH",
        "title": "Can Foundation Models Watch, Talk and Guide You Step by Step to Make a Cake?",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Visual Task Guidance;Multimodal;Large Language Model;Foundation Model",
        "authors": "",
        "rating": "",
        "confidence": "4;5;2",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "EG7gjHZ8cm",
        "title": "Geographical Erasure in Language Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "large language models;fairness;language generation;bias;world knowledge",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3;4",
        "correctness": "4;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "EJ4N7PX6dm",
        "title": "Improved Pseudo Data for Machine Translation Quality Estimation with Constrained Beam Search",
        "track": "main",
        "status": "Long Main",
        "keywords": "Quality Estimation;Machine Translation;Pseudo Data",
        "authors": "",
        "rating": "",
        "confidence": "4;3;1;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ESGY2Ftbfg",
        "title": "Pre-training Language Models for Comparative Reasoning",
        "track": "main",
        "status": "Long Main",
        "keywords": "language model pre-training;question answering;question generation;summarization;comparative reasoning",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ESgkAKGUJP",
        "title": "Bridging Information-Theoretic and Geometric Compression in Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "compression;information theory;language models",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ESyts8YSub",
        "title": "Efficiently Enhancing Zero-Shot Performance of Instruction Following Model via Retrieval of Soft Prompt",
        "track": "main",
        "status": "Long Findings",
        "keywords": "natural language processing;zeroshot language models;prompt tuning",
        "authors": "",
        "rating": "",
        "confidence": "3;2;5;3",
        "correctness": "2;4;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ETNa4Wb65J",
        "title": "Let's Sample Step by Step: Adaptive-Consistency for Efficient Reasoning and Coding with LLMs",
        "track": "main",
        "status": "Long Main",
        "keywords": "LLMs;reasoning;efficient reasoning;sampling in llms",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4;4",
        "correctness": "4;3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "EV5dNDiC7I",
        "title": "BLM-s/lE: A structured dataset of English spray-load verb alternations for testing generalization in LLMs",
        "track": "main",
        "status": "Long Findings",
        "keywords": "verb alternation;generating rules;sentence embeddings",
        "authors": "",
        "rating": "",
        "confidence": "2;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "EVfHUvhRra",
        "title": "Large Language Models Only Pass Primary School Exams in Indonesia: A Comprehensive Test on IndoMMLU",
        "track": "main",
        "status": "Long Main",
        "keywords": "large language models;Indonesian school exam problems;evaluation;local languages and cultures",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "EY9k2x5qWB",
        "title": "KRLS: Improving End-to-End Response Generation in Task Oriented Dialog with Reinforced Keywords Learning",
        "track": "main",
        "status": "Long Main",
        "keywords": "task-oriented dialogues;reinforcement learning",
        "authors": "",
        "rating": "",
        "confidence": "4;5;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "EhPYwBBFYb",
        "title": "UPRISE: Universal Prompt Retrieval for Improving Zero-Shot Evaluation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Prompt Engineering;Large Language Model;Zero-shot Evaluation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;2",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Eib6OOeVJI",
        "title": "Pre-training Multi-task Contrastive Learning Models for Scientific Literature Understanding",
        "track": "main",
        "status": "Long Findings",
        "keywords": "scientific literature understanding;multi-task learning;contrastive learning;language model pre-training",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Ek87791lcO",
        "title": "Prompt as Triggers for Backdoor Attack: Examining the Vulnerability in Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Backdoor Attack; Prompt; Large Language Model",
        "authors": "",
        "rating": "",
        "confidence": "5;5;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "EkftL7NgtW",
        "title": "DNA: Denoised Neighborhood Aggregation for Fine-grained Category Discovery",
        "track": "main",
        "status": "Long Main",
        "keywords": "Fine-grained Category Discovery;Denoised Neighborhood Contrastive Learning",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "EnUgSeghBl",
        "title": "Impressions: Visual Semiotics and Aesthetic Impact Understanding",
        "track": "main",
        "status": "Long Main",
        "keywords": "Visual Semiotics;Stylistic Analysis;Computational Aesthetics;Image Captioning;Multimodal Datasets",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "EpBNf4Arod",
        "title": "PR-MCS: Perturbation Robust Metric for MultiLingual Image Captioning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Image Captioning metric;Perturbation Robustness",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "EpJ7qqR0ad",
        "title": "MetaReVision: Meta-Learning with Retrieval for Visually Grounded Compositional Concept Acquisition",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Compositional Learning;Meta-Learning;Retrieval-enhance Learning;Visual-Language Models",
        "authors": "",
        "rating": "",
        "confidence": "2;3;4;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "EtC8wfjSw4",
        "title": "Human Raters Cannot Distinguish English Translations from Original English Texts",
        "track": "main",
        "status": "Short Main",
        "keywords": "translationese;human evaluation;translation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "EtNebdSBpe",
        "title": "Learning under Label Proportions for Text Classification",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Label Proportions;Privacy;Weak Supervision;Theory",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "EuMmDTVFjL",
        "title": "Dimensions of Online Conflict: Towards Modeling Agonism",
        "track": "main",
        "status": "Long Findings",
        "keywords": "online conversations;conflict;agonism;content moderation",
        "authors": "",
        "rating": "",
        "confidence": "5;4;5",
        "correctness": "4;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "EvVWHQ5l6X",
        "title": "One For All $\\&$ All For One: Bypassing Hyperparameter Tuning with Model Averaging for Cross-Lingual Transfer",
        "track": "main",
        "status": "Short Findings",
        "keywords": "zero-shot cross-lingual transfer;multilingual representation learning",
        "authors": "",
        "rating": "",
        "confidence": "4;2;5",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "EwNVh5fuRF",
        "title": "Select, Prompt, Filter: Distilling Large Language Models for Summarizing Conversations",
        "track": "main",
        "status": "Short Main",
        "keywords": "Text Summarization;Generative AI;Knowledge distillation;Data filtering",
        "authors": "",
        "rating": "",
        "confidence": "3;3;2",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Exh156fVSS",
        "title": "Exploiting Contrastive Learning and Numerical Evidence for Confusing Legal Judgment Prediction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "legal artificial intelligence;legal judgment prediction;contrastive learning;information extraction",
        "authors": "",
        "rating": "",
        "confidence": "1;5;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ExpskenHdP",
        "title": "StereoMap: Quantifying the Awareness of Human-like Stereotypes in Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Stereotype;Bias;Social perception in language models",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "F1G7y94K02",
        "title": "Dissecting Recall of Factual Associations in Auto-Regressive Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "language models;knowledge tracing;knowledge localization;interpretability",
        "authors": "",
        "rating": "",
        "confidence": "3;1;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "F4qNZtkk3V",
        "title": "An Empirical Study on Multiple Knowledge from ChatGPT for Emotion Recognition in Conversations",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Emotion Recognition in Conversations;Graph Network;Supervised Contrastive Learning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "FAiFBfFTGZ",
        "title": "Accelerating Toeplitz Neural Network with Constant-time Inference Complexity",
        "track": "main",
        "status": "Long Main",
        "keywords": "Toeplitz Neural Network;inference;constant-time complexity",
        "authors": "",
        "rating": "",
        "confidence": "2;2;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "FAimEpR9Fh",
        "title": "What Makes it Ok to Set a Fire? Iterative Self-distillation of Contexts and Rationales for Disambiguating Defeasible Social and Moral Situations",
        "track": "main",
        "status": "Long Findings",
        "keywords": "moral reasoning;defeasible reasoning;commonsense reasoning;language groundings;knowledge distillation",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "FGBEoz9WzI",
        "title": "Automatic Prompt Augmentation and Selection with Chain-of-Thought from Labeled Data",
        "track": "main",
        "status": "Long Findings",
        "keywords": "large language models;chain-of-thought;prompt tuning;few-shot prompting",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "FGBWDf7Z19",
        "title": "XLS-R fine-tuning on noisy word boundaries for unsupervised speech segmentation into words",
        "track": "main",
        "status": "Short Findings",
        "keywords": "unsupervised speech segmentation into words;self-supervised Learning;self-training",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "FKNtgr0qQy",
        "title": "Emergence of Abstract State Representations in Embodied Sequence Modeling",
        "track": "main",
        "status": "Long Main",
        "keywords": "Interpretability and Analysis; Decision Making via Sequence Modeling; Language Grounding to Vision and Beyond",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "FLSQjYmzIp",
        "title": "Language Guided Visual Question Answering: Elevate Your Multimodal Language Model Using Knowledge-Enriched Prompts",
        "track": "main",
        "status": "Short Findings",
        "keywords": "VQA;Multimodal Language Models;Question Answering",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "FMWVtVct0V",
        "title": "Towards Anytime Fine-tuning: Continually Pre-trained Language Models with Hypernetwork Prompts",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Continual learning; Pre-trained language model; Prompt learning",
        "authors": "",
        "rating": "",
        "confidence": "2;3;3;3",
        "correctness": "3;4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "FMwflM9yVJ",
        "title": "CONTRASTE: Supervised Contrastive Pre-training With Aspect-based Prompts For Aspect Sentiment Triplet Extraction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "supervised contrastive learning;pretraining;t5;encoder-decoder;generative;aste;acos;aesc;tasd;absa",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "FRRlmKxuf2",
        "title": "Cue-CoT: Chain-of-thought Prompting for Responding to In-depth Dialogue Questions with LLMs",
        "track": "main",
        "status": "Long Findings",
        "keywords": "chain-of-thoughts;in-context learning;personalized dialogue system;empathetic dialogue system;large language models",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "FS1a4CDZsP",
        "title": "PAC-tuning: Fine-tuning Pre-trained Language Models with PAC-driven Perturbed Gradient Descent",
        "track": "main",
        "status": "Long Main",
        "keywords": "language model;fine-tuning;pac-bayesian bound;perturbed gradient descent",
        "authors": "",
        "rating": "",
        "confidence": "2;4;3;4",
        "correctness": "3;4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "FTiXh63BVO",
        "title": "Uniform Complexity for Text Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "text complexity;natural language generation;evaluation;narrative generation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "FXObwPWgUc",
        "title": "Leveraging GPT-4 for Automatic Translation Post-Editing",
        "track": "main",
        "status": "Long Findings",
        "keywords": "automatic post editing;neural machine translation;large language models;application",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Faxkz2V56o",
        "title": "Noisy Self-Training with Synthetic Queries for Dense Retrieval",
        "track": "main",
        "status": "Long Findings",
        "keywords": "dense retrieval;self training;synthetic queries",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "FgEM735i5M",
        "title": "Scene Graph Enhanced Pseudo-Labeling for Referring Expression Comprehension",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Referring Expression Comprehension;Visual Grounding",
        "authors": "",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "FghDWBBsIm",
        "title": "Target-to-Source Augmentation for Aspect Sentiment Triplet Extraction",
        "track": "main",
        "status": "Long Main",
        "keywords": "Aspect-Based Sentiment Analysis;Data Augmentation;Reinforcement Learning",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Fj07R03qkz",
        "title": "IAEval: A Comprehensive Evaluation of Instance Attribution on Natural Language Understanding",
        "track": "main",
        "status": "Long Findings",
        "keywords": "evaluation; instance attribution",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Fm0Brp3cTS",
        "title": "UPTON: Preventing Authorship Leakage from Public Text Release via Data Poisoning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Authorship Attribution",
        "authors": "",
        "rating": "",
        "confidence": "4;1;5",
        "correctness": "5;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Fqv0rgvkol",
        "title": "Paraphrase Types for Generation and Detection",
        "track": "main",
        "status": "Long Main",
        "keywords": "paraphrase generation and detection;paraphrase types;paraphrasing tasks",
        "authors": "",
        "rating": "",
        "confidence": "3;5;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "G0ZGGpSj7i",
        "title": "Defining a New NLP Playground",
        "track": "main",
        "status": "Long Findings",
        "keywords": "position paper; theme track; large language models",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "5;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "G12y1Pz3vJ",
        "title": "Improving Unsupervised Relation Extraction by Augmenting Diverse Sentence Pairs",
        "track": "main",
        "status": "Long Main",
        "keywords": "unsupervised relation extraction;relation representation learning;contrastive learning",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "G13P9iWzKc",
        "title": "When Language Models Fall in Love: Animacy Processing in Transformer Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "animacy;language models;selectional constraints;semantics;discourse context",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4;3",
        "correctness": "4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "G3IjhUERrD",
        "title": "CoF-CoT: Enhancing Large Language Models with Coarse-to-Fine Chain-of-Thought Prompting for Multi-domain NLU Tasks",
        "track": "main",
        "status": "Short Main",
        "keywords": "large language model;natural language understanding;chain-of-thought;multi-step reasoning;slot filling;intent detection;semantic parsing;abstract meaning representation",
        "authors": "",
        "rating": "",
        "confidence": "3;2;2",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "G6E3uzABf1",
        "title": "Improving Consistency for Text Summarization with Energy Functions",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Document Summarization;Consistent Summarization",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "G6gj7Dydc5",
        "title": "HEAR: Hearing Enhanced Audio Response for Video-grounded Dialogue",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Video-grounded Dialouge;Video Scene Understanding;Open-ended Video Question Answering",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "G7IbRKrAOE",
        "title": "Calc-X and Calcformers: Empowering Arithmetical Chain-of-Thought through Interaction with Symbolic Systems",
        "track": "main",
        "status": "Short Main",
        "keywords": "arithmetic reasoning;multistep reasoning;dataset;generation",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "2;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "GDPMVALXqv",
        "title": "Using In-Context Learning to Improve Dialogue Safety",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Dialogue Safety;Toxicity in NLP;Bias in NLP;Dialogue Systems;In-Context Learning;Retrieval",
        "authors": "",
        "rating": "",
        "confidence": "3;5;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "GEZW6VqQNg",
        "title": "Can ChatGPT Defend its Belief in Truth? Evaluating LLM Reasoning via Debate",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Reasoning;Large Language Models;ChatGPT",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "GFgPmhLVhC",
        "title": "Syntax Matters: Towards Spoken Language Understanding via Syntax-Aware Attention",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Spoken Language understanding;Syntactic Dependency Parsing;Feature Fusion",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "GLA4ablO3M",
        "title": "FActScore: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Text Generation;Factuality;Evaluation;Large Language Models",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "GOBxWdRpfz",
        "title": "Re-ViLM: Retrieval-Augmented Visual Language Model for Zero and Few-Shot Image Captioning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Retrieval;Visual Language Model;Image-to-Text",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "GQ1rtVVIy2",
        "title": "Identifying {Early Maladaptive Schemas} from Mental Health Question Texts",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Mental Health;Schema Therapy;Early Maladaptive Schema;Personality Disorders;Classification",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "GSNoZKqHgO",
        "title": "Let's Synthesize Step by Step: Iterative Dataset Synthesis with Large Language Models by Extrapolating Errors from Small Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Dataset Synthesis;large language models;efficiency",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "GSnAO2qUHy",
        "title": "Multiview Clickbait Detection via Jointly Modeling Subjective and Objective Preference",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Clickbait Detection;Subjective Feeling;Objective Content Relevance;Heterogeneous Dynamic Graph Network",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "GTqt0X2Swn",
        "title": "Affective and Dynamic Beam Search for Story Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Discourse Analysis;Sentiment Analysis;Affective Computing",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "GWOCiRkjCF",
        "title": "Precedent-Enhanced Legal Judgment Prediction with LLM and Domain-Model Collaboration",
        "track": "main",
        "status": "Long Main",
        "keywords": "NLP;Large Language Model;Model Collaboration",
        "authors": "",
        "rating": "",
        "confidence": "5;5;4",
        "correctness": "2;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "GbApUL7sDL",
        "title": "Do \u201cEnglish\u201d Named Entity Recognizers Work Well on Global Englishes?",
        "track": "main",
        "status": "Long Findings",
        "keywords": "NER;global english",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "GeFFYOCkvS",
        "title": "Multilingual Coarse Political Stance Classification of Media. The Editorial Line of a ChatGPT and Bard Newspaper",
        "track": "main",
        "status": "Short Findings",
        "keywords": "political bias;news;stance classification;instruction-following language models;chatGPT;Bard",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "GgriuyaTZU",
        "title": "Ultra-Fine Entity Typing with Prior Knowledge about Labels: A Simple Clustering Based Strategy",
        "track": "main",
        "status": "Long Findings",
        "keywords": "ultra-fine entity typing;word embeddings;conceptual neighbourhood",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "GnEGvlOcwr",
        "title": "Error Detection for Text-to-SQL Semantic Parsing",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Semantic Parsing;Text-to-SQL;Error Detection",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "5;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Gp8EmdJLUj",
        "title": "Simplicity Level Estimate (SLE): A Learned Reference-Less Metric for Sentence Simpli\ufb01cation",
        "track": "main",
        "status": "Short Main",
        "keywords": "simplification;evaluation;quality estimation",
        "authors": "",
        "rating": "",
        "confidence": "3;1;4;4",
        "correctness": "3;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "GprvtTwOxy",
        "title": "Unlearn What You Want to Forget: Efficient Unlearning for LLMs",
        "track": "main",
        "status": "Long Main",
        "keywords": "Efficient Unlearning;Large Language Model",
        "authors": "",
        "rating": "",
        "confidence": "2;3;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Grj9GJUcuZ",
        "title": "SimCSE++: Improving Contrastive Learning for Sentence Embeddings from Two Perspectives",
        "track": "main",
        "status": "Long Main",
        "keywords": "sentence embedding;contrastive learning;dimention-wise contrastive learning",
        "authors": "",
        "rating": "",
        "confidence": "3;5;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Gzuzpl4Jje",
        "title": "Continual Learning for Multilingual Neural Machine Translation via Dual Importance-based Model Division",
        "track": "main",
        "status": "Long Main",
        "keywords": "Multilingual Neural Machine Translation;Continual Learning;Model Pruning",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4;3",
        "correctness": "4;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "H0SoE2ch5l",
        "title": "Context Quality Matters in Training Fusion-in-Decoder for Extractive Open-Domain Question Answering",
        "track": "main",
        "status": "Long Findings",
        "keywords": "retrieval-augmented generation models;fusion-in-decoder;question answering",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "H5vtCpKisA",
        "title": "Visually-Situated Natural Language Understanding with Contrastive Reading Model and Frozen Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Visual Document Understanding;OCR;Contrastive Learning;Multimodal Language Models;Document Visual Question Answering;Transformer-based Models",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "HFbtrmefx7",
        "title": "FedTherapist: Mental Health Monitoring with User-Generated Linguistic Expressions on Smartphones via Federated Learning",
        "track": "main",
        "status": "Short Main",
        "keywords": "mental health monitoring;federated learning;mobile healthcare;on-device ML;speech",
        "authors": "",
        "rating": "",
        "confidence": "1;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "HGLvAAKNKx",
        "title": "An Empirical Study of Translation Hypothesis Ensembling with Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Translation;Large Language Models;hypothesis ensembling;reranking;MBR decoding",
        "authors": "",
        "rating": "",
        "confidence": "3;3;5",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "HIBDxkl5n4",
        "title": "Continual Event Extraction with Semantic Confusion Rectification",
        "track": "main",
        "status": "Long Main",
        "keywords": "Event extraction;Continual learning;Semantic confusion;Knowledge transfer",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "HIPPG2SH3u",
        "title": "Unified Representation for Non-compositional and Compositional Expressions",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Potentially Idiomatic Expression; Non-compositionality; Phrase Embedding; Idiomatic Expression Processing",
        "authors": "",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "2;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "HJTbcidL5a",
        "title": "TokenDrop + BucketSampler: Towards Efficient Padding-free Fine-tuning of Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Efficient training of LLMs;Efficient fine-tuning of LLMs;Padding-free variable sequence length batching;Token pruning;Regularizer for LLM training;TokenDrop;BucketSampler",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "HKMvR1UaWH",
        "title": "SYMPTOMIFY: Transforming Symptom Annotations with Language Model Knowledge Harvesting",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Symptom Recognition",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "HMVNu8oKAK",
        "title": "Enhancing Textbooks with Visuals from the Web for Improved Learning",
        "track": "main",
        "status": "Long Main",
        "keywords": "textbooks;learning;education;images",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "5;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "HNfwD7QOaq",
        "title": "Large-scale similarity search with Optimal Transport",
        "track": "main",
        "status": "Short Main",
        "keywords": "Optimal transport;Wasserstein distance;Document Classification",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "HQfzPDZJAL",
        "title": "Expository Text Generation: Imitate, Retrieve, Paraphrase",
        "track": "main",
        "status": "Long Main",
        "keywords": "Text Generation;Factuality;Style-guided Generation;Retrieval-augmented Generation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "5;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "HR90GXVHUn",
        "title": "Once Upon a ${\\it Time}$ in ${\\it Graph}$: Relative-Time Pretraining for Complex Temporal Reasoning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Temporal Question Answering;Time-aware Pre-training",
        "authors": "",
        "rating": "",
        "confidence": "4;2;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "HS5BWSqK5I",
        "title": "Efficient Cross-Task Prompt Tuning for Few-Shot Conversational Emotion Recognition",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Prompt Tuning;Emotion Recognition in Conversation;Large Language Models",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "HUzbEPMd6v",
        "title": "SPT: Learning to Selectively Insert Prompts for Better Prompt Tuning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Prompt tuning;neural architecture search;parameter efficient tuning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "HYxJoAWLgT",
        "title": "Decoding Stumpers: Large Language Models vs. Human Problem-Solvers",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Large Language Models;Problem-solving abilities;Stumpers;Cognitive abilities;Human performance;Riddles",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "HaSS8a3Oe7",
        "title": "Can Language Models Understand Physical Concepts?",
        "track": "main",
        "status": "Long Main",
        "keywords": "large language models;embodied concept understanding",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Hbqsmv4jqY",
        "title": "Beyond Labels: Empowering Human Annotators with Natural Language Explanations through a Novel Active-Learning Architecture",
        "track": "main",
        "status": "Long Findings",
        "keywords": "active learning;low-resource learning;explanation generation;natural language explanations",
        "authors": "",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "HewtRLig9V",
        "title": "Cabbage Sweeter than Cake? Analysing the Potential of Large Language Models for Learning Conceptual Spaces",
        "track": "main",
        "status": "Short Main",
        "keywords": "conceptual spaces;large language models;knowledge representation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "HhoG04UD3E",
        "title": "PMIndiaSum: Multilingual and Cross-lingual Headline Summarization for Languages in India",
        "track": "main",
        "status": "Long Findings",
        "keywords": "multilingual;cross-lingual;summarization;dataset;benchmark;languages in India",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "HickNiCqk9",
        "title": "Detrimental Contexts in Open-Domain Question Answering",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Retrieval;Reasoning;Question Answering;DPR;KILT;Fusion In Decoder",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "HjBDSop3ME",
        "title": "Consonant is all you need: a compact representation of English text for efficient NLP",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Text Representation;Tokenization;Language Modeling;Text Classification;POS Tagging;NER;NMT",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "HkXbOUaL4W",
        "title": "Back Transcription as a Method for Evaluating Robustness of Natural Language Understanding Models to Speech Recognition Errors",
        "track": "main",
        "status": "Long Main",
        "keywords": "ASR;NLU;Speech Recognition;TTS;Back Transcription;Evaluation;Robustness",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4;4",
        "correctness": "2;4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Hkj3WyR1JB",
        "title": "EconBERTa: Towards Robust Extraction of Named Entities in Economics",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Named Entity Recognition;Large Language Model;Domain Adaptation;Generalization",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "4;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "HsGirsKN5l",
        "title": "Addressing the Length Bias Challenge in Document-Level Neural Machine Translation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Document;Machine Translation;Length Bias",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3;3",
        "correctness": "3;3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "HsvZUde6wT",
        "title": "Asking Clarification Questions to Handle Ambiguity in Open-Domain QA",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Clarification Question;Open-domain Question Answering",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "HtNQXg979A",
        "title": "Models See Hallucinations: Evaluating the Factuality in Video Captioning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Hallucination;Factuality Evaluation;Video Captioning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "5;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "HtQvhCRTxo",
        "title": "CORE: A Few-Shot Company Relation Classification Dataset for Robust Domain Adaptation.",
        "track": "main",
        "status": "Long Main",
        "keywords": "Few-shot learning;Relation classification;Business application of NLP;Information extraction",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "HvYxdKPqYt",
        "title": "A Frustratingly Easy Plug-and-Play Detection-and-Reasoning Module for Chinese Spelling Check",
        "track": "main",
        "status": "Long Findings",
        "keywords": "natural language processing;chinese spelling check",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "HzecOxOGAS",
        "title": "KeFVP: Knowledge-enhanced Financial Volatility Prediction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Volatility forecasting;Finance;Text mining",
        "authors": "",
        "rating": "",
        "confidence": "4;2;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "I13VHLJjLO",
        "title": "Reward-Augmented Decoding: Efficient Controlled Text Generation With a Unidirectional Reward Model",
        "track": "main",
        "status": "Short Main",
        "keywords": "controllable text generation;reward modeling;weighted decoding",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "I4BFSevtRv",
        "title": "Domain Adaptation for Sentiment Analysis Using Robust Internal Representations",
        "track": "main",
        "status": "Long Findings",
        "keywords": "domain adaptation;sentiment analysis",
        "authors": "",
        "rating": "",
        "confidence": "3;4;2",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "I5BnQIgQIM",
        "title": "From Parse-Execute to Parse-Execute-Refine: Improving Semantic Parser for Complex Question Answering over Knowledge Base",
        "track": "main",
        "status": "Long Main",
        "keywords": "KBQA;Logical Form;BART",
        "authors": "",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "5;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "I5NWLjXbQl",
        "title": "ACQUIRED: A Dataset for Answering Counterfactual Questions In Real-Life Videos",
        "track": "main",
        "status": "Long Main",
        "keywords": "Counterfactual reasoning;Video Question Answering;Commonsense;Multimodal",
        "authors": "",
        "rating": "",
        "confidence": "3;5;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "I5hTganf3z",
        "title": "VECHR: A Dataset for Explainable and Robust Classification of Vulnerability Type in the European Court of Human Rights",
        "track": "main",
        "status": "Short Main",
        "keywords": "nlp for social good;in legal domain;vulnerability classification;rationale dataset;robustness",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3;4",
        "correctness": "4;3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "I8VTNsq5eB",
        "title": "CESAR: Automatic Induction of Compositional Instructions for Multi-turn Dialogs",
        "track": "main",
        "status": "Long Main",
        "keywords": "Instruction Tuning;Open Domain Dialog;Controlled text generation;Task unification;Unified grounding;Compositional learning;Compositional instructions;CESAR",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4;2;4",
        "correctness": "3;2;2;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.2,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "I9DVeu8XKa",
        "title": "CodeFusion: A Pre-trained Diffusion Model for Code Generation",
        "track": "main",
        "status": "Short Main",
        "keywords": "Text-to-code generation;Diffusion models;Program synthesis;Language models",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "IEH9YsR5Ty",
        "title": "mAggretriever: A Simple yet Effective Approach to Zero-Shot Multilingual Dense Retrieval",
        "track": "main",
        "status": "Short Main",
        "keywords": "Multilingual Dense Retrieval;Zero-Shot Language Transferability;Lexical and Semantic Matching",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "IFNbElsnCi",
        "title": "Generating Summaries with Controllable Readability Levels",
        "track": "main",
        "status": "Long Main",
        "keywords": "readability;abstractive summarization;controllable text generation",
        "authors": "",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "IIfdKVyeVh",
        "title": "Vicarious Offense and Noise Audit of Offensive Speech Classifiers: Unifying Human and Machine Disagreement on What is Offensive",
        "track": "main",
        "status": "Long Main",
        "keywords": "human annotation;fairness;noise audit",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "IKz1dWj0I5",
        "title": "Physician Detection of Clinical Harm in Machine Translation: Quality Estimation Aids in Reliance and Backtranslation Identifies Critical Errors",
        "track": "main",
        "status": "Long Main",
        "keywords": "medical machine translation;clinical harm;human-centered NLP",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ILQnct9H4H",
        "title": "TRIGO: Benchmarking Formal Mathematical Proof Reduction for Generative Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Trigonometric Expression Reduction;Automated Theorem Proving;Formal Mathematical Proof Reduction;Complex Number Combination Reasoning;Generative Language Models",
        "authors": "",
        "rating": "",
        "confidence": "4;2;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ILxXKWHkIB",
        "title": "BioFEG: Generate Latent Features for Biomedical Entity Linking",
        "track": "main",
        "status": "Long Main",
        "keywords": "Biomedical entity linking;Unseen entities",
        "authors": "",
        "rating": "",
        "confidence": "5;3;3",
        "correctness": "5;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.666666666666667,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "IPPURnxK2S",
        "title": "Improving generalization in large langue model by learning prefix subspaces",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Deep learning;parameter efficient fine-tuning;prefix-tuning;subspace learning;natural language processing",
        "authors": "",
        "rating": "",
        "confidence": "1;4;3",
        "correctness": "3;5;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "IRUGqnZQwt",
        "title": "Diversifying language models for lesser-studied languages and language-usage contexts: A case of second language Korean",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multilinguality;DEI;NLP applications;L2 Korean;Morpheme parsing/tagging",
        "authors": "",
        "rating": "",
        "confidence": "2;4;4",
        "correctness": "4;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "IT2bT8UigY",
        "title": "Enhancing Accessible Communication: from European Portuguese to Portuguese Sign Language",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Portuguese Sign Language;Machine Translation;Computational Linguistics;Natural Language Processing;Deep Learning",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "IUKw6SyCxv",
        "title": "DiffS2UT: A Semantic Preserving Diffusion Model for Textless Direct Speech-to-Speech Translation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Speech to Speech Translation;Diffusion Models",
        "authors": "",
        "rating": "",
        "confidence": "3;4;2;4",
        "correctness": "4;2;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "IXuCeFnnxU",
        "title": "Noisy Pair Corrector for Dense Retrieval",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Dense Retrieval;Noisy Pair",
        "authors": "",
        "rating": "",
        "confidence": "5;4;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "IZjyMygbw4",
        "title": "Eyes Show the Way: Modelling Gaze Behaviour for Hallucination Detection",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Cognition;Hallucination;NLG;Gaze;Human Attention",
        "authors": "",
        "rating": "",
        "confidence": "3;3;2",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 1.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "IZzZnp7IUs",
        "title": "Crystal: Introspective Reasoners Reinforced with Self-Feedback",
        "track": "main",
        "status": "Long Main",
        "keywords": "introspective reasoning;commonsense reasoning;question answering;reinforcement learning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "IaBBd8Fod8",
        "title": "Breaking through Deterministic Barriers: Randomized Pruning Mask Generation and Selection",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Pruning;Random;Language Models",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "IadylMsom5",
        "title": "Beyond Detection: A Defend-and-Summarize Strategy for Robust and Interpretable Rumor Analysis on Social Media",
        "track": "main",
        "status": "Long Main",
        "keywords": "rumor detection;social network analysis;adversarial attack;interpretability;summarization;unsupervised learning;self-supervised learning",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "IdSrFSqhHl",
        "title": "Self-Polish: Enhance Reasoning in Large Language Models via Problem Refinement",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Reasoning;Large Language Models;Mathematical Problems",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "IdXpzsTWRs",
        "title": "StoryAnalogy: Deriving Story-level Analogies from Large Language Models to Unlock Analogical Understanding",
        "track": "main",
        "status": "Long Main",
        "keywords": "Analogy;Semantic similarity",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "4;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Ie040B4nFm",
        "title": "Integrating Language Models into Direct Speech Translation: An Inference-Time Solution to Control Gender Inflection",
        "track": "main",
        "status": "Short Main",
        "keywords": "Speech translation;Gender Bias;Language Model",
        "authors": "",
        "rating": "",
        "confidence": "4;2;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "IgPf3oLp6B",
        "title": "Query2Triple: Unified Query Encoding for Answering Diverse Complex Queries over Knowledge Graphs",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Knowledge Graph;Complex Query Answering;CQA",
        "authors": "",
        "rating": "",
        "confidence": "5;5;5",
        "correctness": "4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 5.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "IhHB1l1mwp",
        "title": "Seq2seq is All You Need for Coreference Resolution",
        "track": "main",
        "status": "Long Main",
        "keywords": "coreference resolution; sequence-to-sequence models;",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Ihgea6IIWo",
        "title": "Countering Misinformation via Emotional Response Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Misinformation Countering;Automated Fact-Checking;Knowledge-Driven NLG;Automatic Text Summarization;Human-Machine Collaboration;Data Collection",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4;4;3",
        "correctness": "4;3;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.8,
        "correctness_avg": 3.4,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "IksoHnq4rC",
        "title": "End-to-end Adversarial Sample Generation for Data Augmentation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "adversarial sample;data augmentation",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "IlgpELdUeK",
        "title": "Axiomatic Preference Modeling for Longform Question Answering",
        "track": "main",
        "status": "Long Main",
        "keywords": "reward modeling;preference modeling;RLHF;Large Language Models;long form question answering",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "In4L79U5n7",
        "title": "$\\textit{``Don't Take This Out of Context!''}$ On the Need for Contextual Models and Evaluations for Stylistic Rewriting",
        "track": "main",
        "status": "Long Main",
        "keywords": "stylistic rewriting;contextual evaluation;contextual generation",
        "authors": "",
        "rating": "",
        "confidence": "3;3;2;4",
        "correctness": "4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "InhYJzIuBi",
        "title": "Aspect-Category Enhanced Learning with a Neural Coherence Model for Implicit Sentiment Analysis",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Aspect-Based Sentiment Analysis;Implicit Sentiment;Coherence",
        "authors": "",
        "rating": "",
        "confidence": "5;5;3",
        "correctness": "4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "IpJ5rAFLv7",
        "title": "Scaling Vision-Language Models with Sparse Mixture of Experts",
        "track": "main",
        "status": "Long Findings",
        "keywords": "vision language;scaling",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Ipo264MKyt",
        "title": "PersonaLM: Language Model Personalization via Domain-distributed Span Aggregated K-Nearest N-gram Retrieval Augmentation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "speech recognition;language modeling;personalization;domain adaptation;retrieval augmentation",
        "authors": "",
        "rating": "",
        "confidence": "3;3;1",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "IpzCUvade7",
        "title": "Interventional Rationalization",
        "track": "main",
        "status": "Long Main",
        "keywords": "Rationalization;Causal intervention",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "3;3;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "IqEy2fbpt5",
        "title": "Do LLMs Understand Social Knowledge? Evaluating the Sociability of Large Language Models with SocKET Benchmark",
        "track": "main",
        "status": "Long Main",
        "keywords": "large language models;social information;benchmark",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "IsDxBXUEd8",
        "title": "GRI: Graph-based Relative Isomorphism of Word Embedding Spaces",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Attentive graph Convolutions;Isomorphim;Bi-lingual Induction",
        "authors": "",
        "rating": "",
        "confidence": "1;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Itnbse9MMW",
        "title": "An Integrative Survey on Mental Health Conversational Agents to Bridge Computer Science and Medical Perspectives",
        "track": "main",
        "status": "Long Main",
        "keywords": "Conversational Agent;Chatbot;Mental health",
        "authors": "",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "5;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "IvwcvJHLpc",
        "title": "IdealGPT: Iteratively Decomposing Vision and Language Reasoning via Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Vision-Language Learning;Vision-Language Model;Large Language Model;Zero-Shot Evaluation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "IwI7Wpkzm7",
        "title": "Deciphering Stereotypes in Pre-Trained Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Stereotype Examination;Stereotype Dataset Construction;Probing and Other Interpretations",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "J2l0R8N3ks",
        "title": "Zero-shot Sharpness-Aware Quantization for Pre-trained Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "zero-shot quantization;minimax optimization;pre-trained language model",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "J5FFUHZjNx",
        "title": "SteerLM: Attribute Conditioned SFT as an (User-Steerable) Alternative to RLHF",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Steerable AI;Large Language Model;Alignment;Supervised Fine-tuning",
        "authors": "",
        "rating": "",
        "confidence": "5;4;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "J6pq6AcmbE",
        "title": "A Zero-Shot Language Agent for Computer Control with Structured Reflection",
        "track": "main",
        "status": "Long Findings",
        "keywords": "planning;reflection;action;grounding",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4;2",
        "correctness": "3;4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "J6uWPjukdR",
        "title": "Data Similarity is Not Enough to Explain Language Model Performance",
        "track": "main",
        "status": "Short Main",
        "keywords": "similarity;dataset difficulty;pretraining data analysis",
        "authors": "",
        "rating": "",
        "confidence": "5;5;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "J8iaZda5aG",
        "title": "Words, Subwords, and Morphemes: What Really Matters in the Surprisal-Reading Time Relationship?",
        "track": "main",
        "status": "Short Findings",
        "keywords": "psycholinguistics;sentence processing;tokenization",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "J9Vx7eTuWb",
        "title": "TATA: Stance Detection via Topic-Agnostic and Topic-Aware Embeddings",
        "track": "main",
        "status": "Long Main",
        "keywords": "Zero-shot;Few-shot;Stance Detection;Topic-Agnostic;Topic-Aware",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "J9vgDEDjAw",
        "title": "UDAPDR: Unsupervised Domain Adaptation via LLM Prompting and Distillation of Rerankers",
        "track": "main",
        "status": "Long Main",
        "keywords": "Natural Language Processing;Information Retrieval;Domain Adaptation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3;4",
        "correctness": "4;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "JC7uPaMwpW",
        "title": "KBioXLM: A Knowledge-anchored Biomedical Multilingual Pretrained Language Model",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Biomedical;Cross-lingual;Multi-lingual;Pretrained Language Model",
        "authors": "",
        "rating": "",
        "confidence": "2;4;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "JHd4FSJSC5",
        "title": "Anchoring Fine-tuning of Sentence Transformer with Semantic Label Information for Efficient Truly Few-shot Classification",
        "track": "main",
        "status": "Short Main",
        "keywords": "few-shot;sentence transformer;classification;efficiency",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "JI5lhPHVbK",
        "title": "Battle of the Large Language Models: Dolly vs LLaMA vs Vicuna vs Guanaco vs Bard vs ChatGPT - A Text-to-SQL Parsing Comparison",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Text-to-SQL;large language model",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4;5",
        "correctness": "2;4;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "JIrP8CIvx6",
        "title": "Improving Sequential Model Editing with Fact Retrieval",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Model Editing; Sequential Model Editing; Pre-trained Language model",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "JKmsjKJ0Q8",
        "title": "Long-Horizon Dialogue Understanding for Role Identification in the Game of Avalon with Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Dialogue Understanding;Multimodal Reasoning;Long-Horizon Games",
        "authors": "",
        "rating": "",
        "confidence": "4;5;5",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "JMSkoIYFSn",
        "title": "Improving Span Representation by Efficient Span-Level Attention",
        "track": "main",
        "status": "Short Findings",
        "keywords": "representation learning;efficient methods",
        "authors": "",
        "rating": "",
        "confidence": "3;5;5",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "JMbJeMTFos",
        "title": "Improving word mover's distance by leveraging self-attention matrix",
        "track": "main",
        "status": "Long Findings",
        "keywords": "word embeddings;word mover's distance;optimal transport;Gromov-Wasserstein distance;Fused Gromov-Wasserstein distance;Self-Attention;paraphrase identification;semantic textual similarity",
        "authors": "",
        "rating": "",
        "confidence": "2;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "JNd6XPdaXj",
        "title": "Polyglot or Not? Measuring Multilingual Encyclopedic Knowledge in Foundation Models",
        "track": "main",
        "status": "Short Main",
        "keywords": "NLP;machine learning;LLMs;language modeling;multilingual;datasets;benchmarks",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "JPUx2nVgWa",
        "title": "How Many Demonstrations Do You Need for In-context Learning?",
        "track": "main",
        "status": "Long Findings",
        "keywords": "In-context learning: Large language model",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "JRHhpw77q3",
        "title": "Steering Large Language Models for Machine Translation with Finetuning and In-Context Learning",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Machine Translation; In-Context Learning; Efficient Finetuning",
        "authors": "",
        "rating": "",
        "confidence": "4;5;3;3;3",
        "correctness": "4;3;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6,
        "correctness_avg": 3.4,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "JW3UKn4bmG",
        "title": "Is ChatGPT a Good Causal Reasoner? A Comprehensive Evaluation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Causal Reasoning;Large Language Models;Performance Evaluation",
        "authors": "",
        "rating": "",
        "confidence": "3;3;5",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "JWMIm1EyaE",
        "title": "Explaining with Contrastive Phrasal Highlighting: A Case Study in Assisting Humans to Detect Translation Differences",
        "track": "main",
        "status": "Long Main",
        "keywords": "explainability;human-centered evaluation;machine translation evaluation;cross-lingual semantics;contrastive highlights",
        "authors": "",
        "rating": "",
        "confidence": "4;4;2",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "JaP8ZnOxmi",
        "title": "Mitigating Framing Bias with Polarity Minimization Loss",
        "track": "main",
        "status": "Short Findings",
        "keywords": "framing bias",
        "authors": "",
        "rating": "",
        "confidence": "2;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Jc0sVyM0JP",
        "title": "Semantic Parsing by Large Language Models for Intricate Updating Strategies of Zero-Shot Dialogue State Tracking",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Dialogue State Tracking;Zero-Shot;Large Language Models;In-Context Learning;Semantic Parsing",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "JhC3lwWDhZ",
        "title": "Treepiece: Faster Semantic Parsing via Tree Tokenization",
        "track": "main",
        "status": "Short Findings",
        "keywords": "semantic parsing;decoding;tokenization algorithm;parse tree",
        "authors": "",
        "rating": "",
        "confidence": "3;4;2",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "JhzzvJnL9t",
        "title": "Out-of-Domain Intent Detection Considering Multi-turn Dialogue Contexts",
        "track": "main",
        "status": "Reject",
        "keywords": "OOD Detection;Multi-turn Dialogue Contexts",
        "authors": "",
        "rating": "",
        "confidence": "3;3;2",
        "correctness": "2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "JiUTJJrkL4",
        "title": "clembench: Using Game Play to Evaluate Chat-Optimized Language Models as Conversational Agents",
        "track": "main",
        "status": "Long Main",
        "keywords": "large language models; evaluation; dialogue; dialogue games; interaction",
        "authors": "",
        "rating": "",
        "confidence": "4;2;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Jk6LA0NGOU",
        "title": "Explicit Planning Helps Language Models in Logical Reasoning",
        "track": "main",
        "status": "Long Main",
        "keywords": "logical reasoning;large language model;planning",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "JnJsaXfVte",
        "title": "Architectural Sweet Spots for Modeling Human Label Variation by the Example of Argument Quality: It\u2019s Best to Relate Perspectives!",
        "track": "main",
        "status": "Long Main",
        "keywords": "argument quality;perspectivism;inter-annotator-disagreement;LLM;recommender;argument mining",
        "authors": "",
        "rating": "",
        "confidence": "5;5;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Jo9P7hrDdy",
        "title": "SpEL: Structured Prediction for Entity Linking",
        "track": "main",
        "status": "Long Main",
        "keywords": "Structured Prediction;Entity Linking;AIDA dataset;AIDA/testc;SpEL",
        "authors": "",
        "rating": "",
        "confidence": "2;5;3",
        "correctness": "4;5;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "JotVdrvFtJ",
        "title": "Collaborative Generative AI: Integrating GPT-k for Efficient Editing in Text-to-Image Generation",
        "track": "main",
        "status": "Short Main",
        "keywords": "Text-to-image;LLM;Efficiency",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "JrlSX4nHTv",
        "title": "Natural Response Generation for Chinese Reading Comprehension",
        "track": "main",
        "status": "Long Findings",
        "keywords": "machine reading comprehension;dataset",
        "authors": "",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "2;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Js80TDwMfY",
        "title": "Argument-based Detection and Classification of Fallacies in Political Debates",
        "track": "main",
        "status": "Long Main",
        "keywords": "Fallacy Detection;NLP;Token Classification;Political Debates;Machine Learning;Transformers;Argumantation",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "JwbEwhL3VP",
        "title": "Boosting Inference Efficiency: Unleashing the Power of Parameter-Shared Pre-trained Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "pre-trained language model;parameter sharing;inference acceleration",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "JyvycLG00G",
        "title": "EMO-KNOW: A Large Scale Dataset on Emotion-Cause",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Dataset;Emotion Analysis;Emotion-Cause;Large-scale",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;2;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "K1ih2El1IO",
        "title": "A Predictive Factor Analysis of Social Biases and Task-Performance in Pretrained Masked Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "mask language models;social bias;task performance;model size;model type;training corpora;tokenisation;language",
        "authors": "",
        "rating": "",
        "confidence": "5;3;2",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "K2CrJIcFqg",
        "title": "Grounded and well-rounded: a methodological approach to the study of cross-modal and cross-lingual grounding",
        "track": "main",
        "status": "Long Findings",
        "keywords": "grounding;crosslingual grounding;multimodality",
        "authors": "",
        "rating": "",
        "confidence": "2;2;1",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 1.6666666666666667,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "K35sqjeg5J",
        "title": "Semi-supervised multimodal coreference resolution in image narrations",
        "track": "main",
        "status": "Long Main",
        "keywords": "Coreference Resolution;Vision Language Understanding;Narrative Grounding;Semi-Supervised Learning",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "K5DBkivtyO",
        "title": "Diffusion Language Model with Query-Document Relevance for Query-Focused Summarization",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Query-Focused Summarization;Diffusion Language Model;Query-Document Relevance",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "K5o8oDa0Z0",
        "title": "Chain-of-Thought Reasoning in Tabular Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Tabular mathematical reasoning;Chain-of-thought reasoning;Tabular language models",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "K6KcA4ODql",
        "title": "Improving Bias Mitigation through Bias Experts in Natural Language Understanding",
        "track": "main",
        "status": "Long Main",
        "keywords": "Debiasing;natural language understanding;spurious correlation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;2",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "K7p2SnqFoN",
        "title": "Toward Human Readable Prompt Tuning: Kubrick\u2019s The Shining is a good movie, and a good prompt too?",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Prompt tuning;Analysis;Interpretability",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3;2;3;2;3",
        "correctness": "4;3;4;5;3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.7142857142857144,
        "correctness_avg": 3.4285714285714284,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "K8ixbJPkMQ",
        "title": "TaskWeb: Selecting Better Source Tasks for Multi-task NLP",
        "track": "main",
        "status": "Long Main",
        "keywords": "NLP;machine learning;task transfer;task selection;multi-task training",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "KCe98ynJl3",
        "title": "Zero-shot Faithfulness Evaluation for Text Summarization with Foundation Language Model",
        "track": "main",
        "status": "Long Main",
        "keywords": "Faithfulness Evaluation;Summarization Evaluation;Hallucination Detection",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "KE5QunlXcr",
        "title": "Incorporating Syntactic Knowledge into Pre-trained Language Model using Optimization for Overcoming Catastrophic Forgetting",
        "track": "main",
        "status": "Long Findings",
        "keywords": "syntax;BERT;language model;optimization;catastrophic forgetting",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "KE9MKZOOca",
        "title": "ConPrompt: Pre-training a Language Model with Machine-Generated Data for Implicit Hate Speech Detection",
        "track": "main",
        "status": "Long Findings",
        "keywords": "implicit hate speech detection;pre-training;pre-trained language model;machine-generated data;contrastive learning;prompt",
        "authors": "",
        "rating": "",
        "confidence": "5;2;3;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "KEH6Cqjdw2",
        "title": "Legally Enforceable Hate Speech Detection for Public Forums",
        "track": "main",
        "status": "Long Findings",
        "keywords": "hate speech;legal AI;human in the loop;large language models;prompt tuning",
        "authors": "",
        "rating": "",
        "confidence": "3;3;5",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "KFieG8rclT",
        "title": "Contrastive Learning-based Sentence Encoders Implicitly Weight Informative Words",
        "track": "main",
        "status": "Short Findings",
        "keywords": "sentence embedding;contrastive learning;information gain;integrated gradients",
        "authors": "",
        "rating": "",
        "confidence": "3;4;2;2",
        "correctness": "4;2;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "KHfQKygNSc",
        "title": "Robustness of Named-Entity Replacements for In-Context Learning",
        "track": "main",
        "status": "Short Findings",
        "keywords": "large language models;in-context learning;named entities;robustness;natural language understanding",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "KIysY1fMCJ",
        "title": "Aspect-to-Scope Oriented Multi-view Contrastive Learning for Aspect-based Sentiment Analysis",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Graph contrastive learning;aspect-based sentiment analysis",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "KNFG5KLXD3",
        "title": "We Are What We Repeatedly Do: Inducing and Deploying Habitual Schemas in Persona-Based Responses",
        "track": "main",
        "status": "Long Main",
        "keywords": "Dialogue;Response;Generation;Persona;Schema;LLM",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "KOxEqQzvOZ",
        "title": "Debias NLU Datasets via Training-free Perturbations",
        "track": "main",
        "status": "Long Findings",
        "keywords": "natural language understanding; out-of-distribution generalization; data-centric debiasing;",
        "authors": "",
        "rating": "",
        "confidence": "5;4;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "KRQADH68fG",
        "title": "HuatuoGPT, Towards Taming Language Model to Be a Doctor",
        "track": "main",
        "status": "Long Findings",
        "keywords": "large language models;medical application;ChatGPT",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "KSjnVt9awC",
        "title": "Revisiting the Knowledge Injection Frameworks",
        "track": "main",
        "status": "Long Main",
        "keywords": "language models;knowledge pruning;large language models for downstream task",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3;4",
        "correctness": "4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "KTFxOnrbvu",
        "title": "Argument mining as a multi-hop generative machine reading comprehension task",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Argument mining; Machine reading comprehension; Generative model; Chain of thought",
        "authors": "",
        "rating": "",
        "confidence": "3;2;2",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "KUSzNKRI2g",
        "title": "Improving Pacing in Long-Form Story Planning",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Story Generation;Pacing;Hierarchical Planning",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "KfJffhdWO1",
        "title": "Evaluating Evaluation Metrics: A Framework for Analyzing NLG Evaluation Metrics using Measurement Theory",
        "track": "main",
        "status": "Long Main",
        "keywords": "Evaluation;Evaluation Metrics;Measurement Theory;NLG;Large Language Model",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "KgcuY2KIkf",
        "title": "Systematic word meta-sense extension",
        "track": "main",
        "status": "Long Main",
        "keywords": "lexical creativity;regular polysemy;systematicity;contextualized language model;analogical inference;figurative language processing",
        "authors": "",
        "rating": "",
        "confidence": "4;5;5",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "KivNpBsfAS",
        "title": "NLP Evaluation in trouble: On the Need to Measure LLM Data Contamination for each Benchmark",
        "track": "main",
        "status": "Short Findings",
        "keywords": "evaluation;data contamination;large language models;benchmark",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Kjs0mpGJwb",
        "title": "A Structure-Aware Generative Adversarial Network for Bilingual Lexicon Induction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Cross-lingual word embedding;unsupervised;low isomorphic;bilingual lexicon induction",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "KkHY1WGDII",
        "title": "Grammar-Constrained Decoding for Structured NLP Tasks without Finetuning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Grammar-Constrained Decoding;Large Language Model;LLM;Structured NLP;Information Extraction;Entity Disambiguation",
        "authors": "",
        "rating": "",
        "confidence": "2;4;3;4",
        "correctness": "4;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "KkR8wahYQN",
        "title": "FaMeSumm: Investigating and Improving Faithfulness of Medical Summarization",
        "track": "main",
        "status": "Long Main",
        "keywords": "Medical Summarization;Factuality;Faithful Summarization;Abstractive Summarization",
        "authors": "",
        "rating": "",
        "confidence": "3;5;3;4",
        "correctness": "4;3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "KxGI7hLxAo",
        "title": "Mind the Gap Between Conversations for Improved Long-Term Dialogue Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Dialogue system;time-aware dialogue model;long-term conversation generation;multi-session dialogue",
        "authors": "",
        "rating": "",
        "confidence": "2;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "L0SEfyrLsW",
        "title": "SELFOOD: Self-Supervised Out-Of-Distribution Detection via Learning to Rank",
        "track": "main",
        "status": "Long Findings",
        "keywords": "OOD detection;self-supervised;ranking",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3;4;3",
        "correctness": "3;2;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.2,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "L0u9Dkito7",
        "title": "Image and Text: Fighting the same Battle? Super Resolution Learning for Imbalanced Text Classification",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Data Augmentation;Social media;Crisis management",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "L4yVLb6cLu",
        "title": "Hi-ToM: A Benchmark for Evaluating Higher-Order Theory of Mind Reasoning in Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Higher Order Theory of Mind;Chain of Thought Prompting;Large Language Models;Deception",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "L7IW2foTq4",
        "title": "Attention-Enhancing Backdoor Attacks Against BERT-based Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Backdoor Attack;BERT;Attention Loss;natural language processing",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "L7YoWxQq5t",
        "title": "Program Translation via Code Distillation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Program Translation;Intermediate Representations;Neural Machine Translation;Multilingual Code Generation;Pre-training",
        "authors": "",
        "rating": "",
        "confidence": "3;4;2",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "L7ZBpZZ8Va",
        "title": "Orthogonal Subspace Learning for Language Model Continual Learning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "continual learning;orthogonal subspace;paramemter efficient tuning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;5;5",
        "correctness": "4;2;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "L8Cxea5krb",
        "title": "BERTie Bott's Every Flavor Labels: A Tasty Introduction to Semantic Role Labeling for Galician",
        "track": "main",
        "status": "Long Main",
        "keywords": "semantic role labeling;semantic parsing;Galician;Spanish;srl",
        "authors": "",
        "rating": "",
        "confidence": "4;2;4;4",
        "correctness": "3;3;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "L8W6RyMRmL",
        "title": "Reduce Human Labor On Evaluating Conversational Information Retrieval System: A Human-Machine Collaboration Approach",
        "track": "main",
        "status": "Long Main",
        "keywords": "Interactive Evaluation;Human-Machine Collaboration;Conversational Information Retrieval",
        "authors": "",
        "rating": "",
        "confidence": "1;2;3;3",
        "correctness": "4;3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "LCEbV5nsb8",
        "title": "SummIt: Iterative Text Summarization via ChatGPT",
        "track": "main",
        "status": "Long Findings",
        "keywords": "summarization;large language model;text editing",
        "authors": "",
        "rating": "",
        "confidence": "4;2;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "LDAgFeA55o",
        "title": "A Benchmark for Semi-Inductive Link Prediction in Knowledge Graphs",
        "track": "main",
        "status": "Short Findings",
        "keywords": "semi-inductive;link prediction;knowledge graph;unseen entity",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3;3",
        "correctness": "4;3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "LGX5hFWPK2",
        "title": "CoMPosT: Characterizing and Evaluating Caricature in LLM Simulations",
        "track": "main",
        "status": "Long Main",
        "keywords": "large language models;caricatures;language model simulations;survey replication",
        "authors": "",
        "rating": "",
        "confidence": "4;4;2;4",
        "correctness": "4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "LNKGWaRtlE",
        "title": "Ecologically Valid Explanations for Label Variation in NLI",
        "track": "main",
        "status": "Short Findings",
        "keywords": "annotation disagreement;explanation;interpretability;natural language inference;human label variation;textual inferences",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "2;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "LPtO1evrGa",
        "title": "Prompting and Evaluating Large Language Models for Proactive Dialogues: Clarification, Target-guided, and Non-collaboration",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Proactive Dialogue;Asking Clarification Question;Target-guided Conversation",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "LQqlapYGeR",
        "title": "An Iteratively Parallel Generation Method with the Pre-Filling Strategy for Document-level Event Extraction",
        "track": "main",
        "status": "Long Main",
        "keywords": "natural language processing;information extraction;document-level event extraction;parallel generation",
        "authors": "",
        "rating": "",
        "confidence": "5;3;1",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "LRRThBBiov",
        "title": "PRESTO: A Multilingual Dataset for Parsing Realistic Task-Oriented Dialogs",
        "track": "main",
        "status": "Long Main",
        "keywords": "task oriented dialogs;semantic parsing;nlp",
        "authors": "",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "LUDljw5VVD",
        "title": "Large Language Model Is Not a Good Few-shot Information Extractor, but a Good Reranker for Hard Samples!",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large Language Models;Information Extraction",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "LZq3crn3Bv",
        "title": "Cross-Lingual Cross-Target Stance Detection with Dual Knowledge Distillation Framework",
        "track": "main",
        "status": "Long Main",
        "keywords": "cross-lingual cross-target stance detection;dual knowledge distillation;category-oriented contrastive learning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "LawAC9vh8q",
        "title": "Enhancing the Ranking Context of Dense Retrieval through Reciprocal Nearest Neighbors",
        "track": "main",
        "status": "Long Main",
        "keywords": "dense retrieval;reciprocal nearest neighbors;ranking context;contrastive learning;list-wise loss;false negatives;label smoothing;transformers;Large Language Models;information retrieval;natural language processing;deep learning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "LepuyCeWcw",
        "title": "Causal Inference from Text: Unveiling Interactions between Variables",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Causal Inference;Natural Language Processing;Non-confounding Covariates;Disentanglement",
        "authors": "",
        "rating": "",
        "confidence": "5;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Lk1KaQcjaM",
        "title": "AD-NLP: A Benchmark for Anomaly Detection in Natural Language Processing",
        "track": "main",
        "status": "Long Main",
        "keywords": "NLP;anomaly detection;deep learning;machine learning;dataset;benchmark",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3;4",
        "correctness": "3;2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "LkV7Xx06yq",
        "title": "MEGClass: Extremely Weakly Supervised Text Classification via Mutually-Enhancing Text Granularities",
        "track": "main",
        "status": "Long Findings",
        "keywords": "text classification;extremely weak supervision;weakly-supervised learning;document representations;representation learning;pseudo-document generation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4;3",
        "correctness": "3;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Lp4CMWnSyb",
        "title": "Always the Best Fit: Adaptive Domain Gap Filling from Causal Perspective for Few-Shot Relation Extraction",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Cross domain;Causal Inference;Few-Shot;Relation Extraction",
        "authors": "",
        "rating": "",
        "confidence": "3;2;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "M1GRz46Ahz",
        "title": "SHARCS: Efficient Transformers Through Routing with Dynamic Width Sub-networks",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Efficiency;Routing;hardness",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "M1Nogs3zR5",
        "title": "DemoNSF: A Multi-task Demonstration-based Generative Framework for Noisy Slot Filling Task",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Noisy Slot Filling;Input Perturbations;Multi-task Learning;Generative Framework;Large Language Model;Demonstration Learning",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "M3uTqtEgNo",
        "title": "Rethinking and Improving Multi-task Learning for End-to-end Speech Translation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Speech translation;multi-modal translation;machine translation",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4;3",
        "correctness": "3;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "M51c00VxiJ",
        "title": "AMR Parsing is Far from Solved: GrAPES, the Granular AMR Parsing Evaluation Suite",
        "track": "main",
        "status": "Long Main",
        "keywords": "evaluation;dataset;corpus;semantic parsing;AMR;sentence-level semantics;semantic graphs",
        "authors": "",
        "rating": "",
        "confidence": "3;5;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "M5knJ7ovgz",
        "title": "MRRL: Modifying the Reference via Reinforcement Learning for Non-Autoregressive Joint Multiple Intent Detection and Slot Filling",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Non-Autoregressive;Intent Detection and Slot Filling;Reinforcement Learning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "M6BJfQ9oup",
        "title": "Conceptor-Aided Debiasing of Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Natural Language Processing;Large Language Model;Fairness",
        "authors": "",
        "rating": "",
        "confidence": "3;1;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "M9NdVElcbs",
        "title": "Bridging the Digital Divide: Performance Variation across Socio-Economic Factors in Vision-Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Multimodal;Income;Geodiversity;Evaluation;Analysis",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "MEByW1upLk",
        "title": "Learning from Mistakes via Cooperative Study Assistant for Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Models;Reflection and Feedback",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4;2",
        "correctness": "3;3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "MFimS05rLW",
        "title": "Investigating the Effect of Pre-finetuning BERT Models on NLI Involving Presuppositions",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Presupposition;natural language inference;discourse;pragmatics",
        "authors": "",
        "rating": "",
        "confidence": "3;2;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "MKjGklW9TP",
        "title": "ClusterPrompt: Cluster Semantic Enhanced Prompt Learning for New Intent Discovery",
        "track": "main",
        "status": "Long Findings",
        "keywords": "dialogue systems;intent discovery;prompt learning;contrastive learning",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "MLKLYoXypN",
        "title": "Cross-Lingual Consistency of Factual Knowledge in Multilingual Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Model Consistency;Multilinguality;Knowledge Incorporation;Large-scale Pre-trained Language Model;Model Evaluation;Knowledge Probing",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "5;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.666666666666667,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "MLzoMwlxTh",
        "title": "Goal-Driven Explainable Clustering via Language Descriptions",
        "track": "main",
        "status": "Long Main",
        "keywords": "clustering;explainability;large language models",
        "authors": "",
        "rating": "",
        "confidence": "3;2;3;3",
        "correctness": "4;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "MMrqu8SD6y",
        "title": "\"A Tale of Two Movements\": Identifying and Comparing Perspectives in \\#BlackLivesMatter and \\#BlueLivesMatter Movements-related Tweets using Weakly Supervised Graph-based Structured Prediction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "characterization of social movements;social media;discourse analysis;perspective identification",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "MNTCi0i3cU",
        "title": "InstructSafety: A Unified Framework for Building Multidimensional and Explainable Safety Detector through Instruction Tuning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "safety detection;unified framework;instruction tuning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "MQsvD6YOan",
        "title": "Improving Low-resource Question Answering by Augmenting Question Information",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Question Answering;Data augmentation;Low-resource domains",
        "authors": "",
        "rating": "",
        "confidence": "3;4;2",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "MRehcsVc4y",
        "title": "RSVP: Customer Intent Detection via Agent Response Contrastive and Generative Pre-Training",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Intent Detection;Task Adaptive Fine-Tuning;Contrastive Learning;Question Answering",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4;4;3",
        "correctness": "3;3;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.8,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "MSQrAoa7iy",
        "title": "3DRP-Net: 3D Relative Position-aware Network for 3D Visual Grounding",
        "track": "main",
        "status": "Long Main",
        "keywords": "3D visual grounding",
        "authors": "",
        "rating": "",
        "confidence": "3;5;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "MWhwZjFCcq",
        "title": "StyleBART: Decorate Pretrained Model with Style Adapters for Unsupervised Stylistic Headline Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Headline generation; Style transfer; Efficient NLP; Unsupervised learning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "MWisc5Amup",
        "title": "ALDi: Quantifying the Arabic Level of Dialectness of Text",
        "track": "main",
        "status": "Long Main",
        "keywords": "Arabic Dialects;Arabic Dialect Identification;Dialectal Variation;Code-switching;Level of Dialectness",
        "authors": "",
        "rating": "",
        "confidence": "5;4;5",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "MXMA6vQtSZ",
        "title": "Entity-Based Evaluation of Political Bias in Automatic Summarization",
        "track": "main",
        "status": "Short Findings",
        "keywords": "summarization;political bias",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "MYdmanqfvm",
        "title": "What do Deck Chairs and Sun Hats Have in Common? Uncovering Shared Properties in Large Concept Vocabularies",
        "track": "main",
        "status": "Short Main",
        "keywords": "lexical semantics;commonality detection;ultra-fine entity typing;ontology learning",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "MZwFbA3DSF",
        "title": "Pit One Against Many: Leveraging Attention-head Embeddings for Parameter-efficient Multi-head Attention",
        "track": "main",
        "status": "Long Findings",
        "keywords": "multi-head attention; memory efficiency",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "MbKRJUowYX",
        "title": "E-CORE: Emotion Correlation Enhanced Empathetic Dialogue Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "empathetic dialogue generation;graph network;emotion perception;natural language generation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Md1YdfqAed",
        "title": "Balance Act: Mitigating Hubness in Cross-Modal Retrieval with Query and Gallery Banks",
        "track": "main",
        "status": "Long Main",
        "keywords": "Cross-modal Retrieval;Hubness",
        "authors": "",
        "rating": "",
        "confidence": "3;2;4",
        "correctness": "5;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Mefvmgkb9G",
        "title": "CAPSTONE: Curriculum Sampling for Dense Retrieval with Document Expansion",
        "track": "main",
        "status": "Long Main",
        "keywords": "Dense Retrieval;Document Expansion",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "MhEJqeCzgE",
        "title": "Unraveling Feature Extraction Mechanisms in Neural Networks",
        "track": "main",
        "status": "Long Main",
        "keywords": "Interpretability;Infinite-width;Feature extraction;Learning dynamics;Neural tangent kernel",
        "authors": "",
        "rating": "",
        "confidence": "3;3;2",
        "correctness": "5;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "MhU0zxuZ5K",
        "title": "On the Dimensionality of Sentence Embeddings",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Sentence embedding;dimension reduction",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4;3",
        "correctness": "3;4;5;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "MhbiD5FVPF",
        "title": "People Make Better Edits: Measuring the Efficacy of LLM-Generated Counterfactually Augmented Data for Harmful Language Detection",
        "track": "main",
        "status": "Long Main",
        "keywords": "hate speech;sexism;counterfactually augmented data;data augmentation;model robustness",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "MkD0VGShAq",
        "title": "GazeVQA: A Video Question Answering Dataset for Multiview Eye-Gaze Task-Oriented Collaborations",
        "track": "main",
        "status": "Long Main",
        "keywords": "video question answering;human-robot collaboration",
        "authors": "",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Mm5GXKvpXm",
        "title": "CReTIHC: Designing Causal Reasoning Tasks about Temporal Interventions and Hallucinated Confoundings",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Causality;Commonsense reasoning;Large Language Models;Temporal Interventions;Hallucinated Confoundings",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "MmBjKmHIND",
        "title": "Synthetic Data Generation with Large Language Models for Text Classification: Potential and Limitations",
        "track": "main",
        "status": "Long Main",
        "keywords": "Synthetic Data Generation;Data Augmentation;Large Language Models",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4;3",
        "correctness": "2;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "MnPnE4xV0H",
        "title": "Pretraining Language Models with Text-Attributed Heterogeneous Graphs",
        "track": "main",
        "status": "Long Findings",
        "keywords": "language model pretraining;text-attributed heterogeneous graphs;graph neural networks",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "MoEfm3iPMy",
        "title": "Self-Knowledge Guided Retrieval Augmentation for Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "self-knowledge;retrieval augmentation;large language models",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Mq5cyRMGlD",
        "title": "VERVE: Template-based ReflectiVE Rewriting for MotiVational IntErviewing",
        "track": "main",
        "status": "Long Findings",
        "keywords": "motivational interviewing;rewriting;counseling",
        "authors": "",
        "rating": "",
        "confidence": "2;4;5",
        "correctness": "4;2;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Mte6BK69zv",
        "title": "Unraveling Downstream Gender Bias from Large Language Models: A Study on AI Educational Writing Assistance",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large Language Models;Gender Bias;Writing Support;Human-AI Collaboration",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Mtgbc9XFPU",
        "title": "Pre-training Intent-Aware Encoders for Zero- and Few-Shot Intent Classification",
        "track": "main",
        "status": "Long Main",
        "keywords": "intent classification;task-oriented dialogue system",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4;3",
        "correctness": "4;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "MxhTQC9AYV",
        "title": "RealBehavior: A Framework for Faithfully Characterizing Foundation Models\u2019 Human-like Behavior Mechanisms",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Foundation Model;Human-like Behavior;Faithfulness",
        "authors": "",
        "rating": "",
        "confidence": "4;5;3",
        "correctness": "3;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "My6Rgv7xXV",
        "title": "Contextual Interaction for Argument Post Quality Assessment",
        "track": "main",
        "status": "Long Main",
        "keywords": "argument;argument quality;contrastive learning;large language models",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "MyTyc69kKK",
        "title": "TSTR: Target Similarity Tuning Meets the Real World",
        "track": "main",
        "status": "Short Findings",
        "keywords": "prompt engineering;code generation;target similarity tuning;example selection",
        "authors": "",
        "rating": "",
        "confidence": "2;3;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "MzDakXdBbM",
        "title": "Can Large Language Models Fix Data Annotation Errors? An Empirical Study Using Debatepedia for Query-Focused Text Summarization",
        "track": "main",
        "status": "Short Findings",
        "keywords": "ChatGPT;PaLM;Large Language Models;Query Focused Abstractive Text Summarization",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "N3a2vVk8vu",
        "title": "Hierarchical Prompting Assists Large Language Model on Web Navigation",
        "track": "main",
        "status": "Short Findings",
        "keywords": "LLM Prompting;Web Navigation",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "N4VUOeVOfS",
        "title": "Hidding the Ghostwriters: An Adversarial Evaluation of AI-Generated Student Essay Detection",
        "track": "main",
        "status": "Long Main",
        "keywords": "AIGC detection;AI-generated student essay;education",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4;4",
        "correctness": "4;2;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "N58BZj5JB7",
        "title": "Improving Diversity of Demographic Representation in Large Language Models via Collective-Critiques and Self-Voting",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large language models;Fairness;Diversity;Language model reasoning",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "N6f1iHjWvB",
        "title": "Automatic Analysis of Substantiation in Scientific Peer Reviews",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Peer review;Substantiation;Argument mining;Dataset",
        "authors": "",
        "rating": "",
        "confidence": "3;4;2;3;4",
        "correctness": "2;4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.2,
        "correctness_avg": 3.6,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "N6sXsHuWDE",
        "title": "ROME: Evaluating Pre-trained Vision-Language Models on Reasoning beyond Visual Common Sense",
        "track": "main",
        "status": "Long Findings",
        "keywords": "commonsense reasoning;multimodality;pre-trained vision-language models",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "N7R2emgl67",
        "title": "Learning to Rank Context for Named Entity Recognition Using a Synthetic Dataset",
        "track": "main",
        "status": "Long Main",
        "keywords": "ner;transformers;context retrieval",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4;3",
        "correctness": "4;3;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "N8TTwaIBId",
        "title": "CCEval: A Representative Evaluation Benchmark for the Chinese-centric Multilingual Machine Translation",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Multilingual Machine Translation;Low-resource Languages;Evaluation Benchmark;Evaluation Dataset;Chinese-centric;Translation Evaluation;Test Set",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "N8nQjYuyhO",
        "title": "Using Artificial French Data to Understand the Emergence of Gender Bias in Transformer Language Models",
        "track": "main",
        "status": "Short Main",
        "keywords": "Language Model;Transformer;LM Analysis;Gender Bias",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "N924k3YM8V",
        "title": "The ACL OCL Corpus: Advancing Open Science in Computational Linguistics",
        "track": "main",
        "status": "Long Main",
        "keywords": "scholarly corpus;computational linguistics;topic trend analysis;acl anthology",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3;4",
        "correctness": "3;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "NAmRjAIMkz",
        "title": "Pointwise Mutual Information Based Metric and Decoding Strategy for Faithful Generation in Document Grounded Dialogs",
        "track": "main",
        "status": "Long Main",
        "keywords": "docuemnt grounded dialogs;dialog response generation;faithful response generation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "NBH3x0u5oQ",
        "title": "MixEdit: Revisiting Data Augmentation and Beyond for Grammatical Error Correction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "natural language processing;grammatical error correction;data augmentation",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "NHeAUKlTO8",
        "title": "PartialFormer: Modeling Part Instead of Whole for Machine Translation",
        "track": "main",
        "status": "Reject",
        "keywords": "Lightweight Transformer;",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "NMMRH80gha",
        "title": "Simple and Effective Input Reformulations for Translation",
        "track": "main",
        "status": "Long Main",
        "keywords": "natural language processing;data efficiency;input reformulations;multilingual;translation;foundation language models;finetuning;machine learning",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "NMMnxhQm01",
        "title": "The Distributional Hypothesis Does Not Fully Explain the Benefits of Masked Language Model Pretraining",
        "track": "main",
        "status": "Long Main",
        "keywords": "Distributional Hypothesis;MLM;Pretraining",
        "authors": "",
        "rating": "",
        "confidence": "2;4;4;3",
        "correctness": "2;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "NO5dc8Ljvj",
        "title": "C2D2 Dataset: A Resource for the Cognitive Distortion Analysis and Its Impact on Mental Health",
        "track": "main",
        "status": "Long Findings",
        "keywords": "cognitive distortion;mental health;text analysis",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4;3",
        "correctness": "3;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "NPJznfA7ZC",
        "title": "Demystifying Prompts in Language Models via Perplexity Estimation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "LLM;perplexity;prompts",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "NPkkvrv2Vp",
        "title": "Who is Speaking? Speaker-Aware Multiparty Dialogue Act Classification",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Dialogue acts;multiparty dialogues;speaker modeling",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3;4",
        "correctness": "3;2;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "NT4ehxCifo",
        "title": "Large Language Models Meet Open-World Intent Discovery and Recognition: An Evaluation of ChatGPT",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Models;Evaluation;Out of Domain;Intent Recognition",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "NW09xt3kvH",
        "title": "HutCRS: Hierarchical User-Interest Tracking for Conversational Recommender System",
        "track": "main",
        "status": "Long Main",
        "keywords": "Conversational Recommender Rystem;Multi-round Conversations;Hierarchical Interest Tree;Graph Neural Network",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "NXXrvcilq8",
        "title": "Are NLP Models Good at Tracing Thoughts: An Overview of Narrative Understanding",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Narrative Understanding;Reading Comprehension;Summarization;Question Answering",
        "authors": "",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "NYlL3oACU2",
        "title": "Comparing Biases and the Impact of Multilingual Training across Multiple Languages",
        "track": "main",
        "status": "Long Main",
        "keywords": "Fairness;Biases;Multilinguality",
        "authors": "",
        "rating": "",
        "confidence": "5;3;4",
        "correctness": "5;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.666666666666667,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "NYstQhld8J",
        "title": "MarkQA: A large scale KBQA dataset with numerical reasoning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Knowledge base;Question answering;Numerical reasoning",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "NZK22y40DS",
        "title": "Towards Enhancing Relational Rules for Knowledge Graph Link Prediction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Knowledge Graph Reasoning;Graph Neural Network;Inductive Reasoning",
        "authors": "",
        "rating": "",
        "confidence": "3;5;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "NZZB3UGcd8",
        "title": "Editing Large Language Models: Problems, Methods, and Opportunities",
        "track": "main",
        "status": "Long Main",
        "keywords": "Model Editing;Large Language Model;Editing Factual Knowledge",
        "authors": "",
        "rating": "",
        "confidence": "2;1;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Na4DonsjLx",
        "title": "Contrastive Learning for Inference in Dialogue",
        "track": "main",
        "status": "Long Main",
        "keywords": "inference in dialogue;commonsense reasoning in dialogue;contrastive learning;semantic gap;dialogue comprehension;information gap;inductive reasoning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;5;3;4",
        "correctness": "3;3;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "NbkVQsbaqJ",
        "title": "Exploring In-Context Learning for Knowledge Grounded Dialog Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "dialog;knowledge;large language models;in-context learning;retrieval system",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Nc6U1Z0DDt",
        "title": "Balaur: Language Model Pretraining with Lexical Semantic Relations",
        "track": "main",
        "status": "Long Findings",
        "keywords": "language model;lm;pretraining;lexical semantics;lexical semantic relations;hypernymy;semantic specialization;wordnet",
        "authors": "",
        "rating": "",
        "confidence": "3;3;2",
        "correctness": "3;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "NeOsOzNMiS",
        "title": "LayoutDIT: Layout-Aware End-to-End Document Image Translation with Multi-Step Conductive Decoder",
        "track": "main",
        "status": "Long Findings",
        "keywords": "document image;machine translation;layout;multi-step;conductive;end-to-end",
        "authors": "",
        "rating": "",
        "confidence": "2;4;4",
        "correctness": "3;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "NfN3ZDCcsO",
        "title": "SAMRank: Unsupervised Keyphrase Extraction using Self-Attention Map in BERT and GPT-2",
        "track": "main",
        "status": "Long Main",
        "keywords": "Unsupervised Keyphrase Extraction;Pre-trained Language Model;Self-Attention Map;BERT;GPT-2",
        "authors": "",
        "rating": "",
        "confidence": "5;5;4;3",
        "correctness": "4;2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Ni57pgQVqq",
        "title": "APoLLo : Unified Adapter and Prompt Learning for Vision Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Vision Language Models;Prompt Tuning;Adapter Tuning;Contrastive Learning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;2;3",
        "correctness": "3;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "NiEYKbNnQO",
        "title": "Text Rendering Strategies for Pixel Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Pixel-based language modelling;isotropy;word frequency bias",
        "authors": "",
        "rating": "",
        "confidence": "4;2;4",
        "correctness": "3;3;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Nijnhwu1Uz",
        "title": "PromptST: Abstract Prompt Learning for End-to-End Speech Translation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Speech-to-Text Translation;Linguistic Probing Benchmark;Prompt Learning",
        "authors": "",
        "rating": "",
        "confidence": "3;5;4;3;4",
        "correctness": "4;4;2;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.8,
        "correctness_avg": 3.6,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Nk2vfZa4lX",
        "title": "Appraising the Potential Uses and Harms of LLMs for Medical Systematic Reviews",
        "track": "main",
        "status": "Long Main",
        "keywords": "LLMs;Biomedical;Systematic Reviews;Qualitative Study;User Research",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "NlWH0Kvptf",
        "title": "FactSpotter: Evaluating the Factual Faithfulness of Graph-to-Text Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Graph-to-text;Factual Faithfulness;Constrained Text Generation",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "NnVIFpsMAy",
        "title": "Make Every Example Count: On the Stability and Utility of Self-Influence for Learning from Noisy NLP Datasets",
        "track": "main",
        "status": "Long Main",
        "keywords": "data filtering;influence functions;self-influence;curriculum learning;noisy data;machine translation;question answering",
        "authors": "",
        "rating": "",
        "confidence": "4;4;2",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "NomitcTG87",
        "title": "Transformer-based Live Update Generation for Soccer Matches from Microblog Posts",
        "track": "main",
        "status": "Short Main",
        "keywords": "Timeline Summarization;Social Media",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "NphKIYvm9D",
        "title": "Investigating Multilingual Coreference Resolution by Universal Annotations",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multilingual coreference resolution;coreference analysis",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "NrCLVmq0KD",
        "title": "LLM aided semi-supervision for efficient Extractive Dialog Summarization",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Dialog Summarization;Large Language Models;Semi-supervised learning;Transformers;BART;GPT;Rouge",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "NrmYYAO7N4",
        "title": "Expand, Highlight, Generate: RL-driven Document Generation for Passage Reranking",
        "track": "main",
        "status": "Long Main",
        "keywords": "Synthetic document generation;Data augmentation;Information retrieval",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4;3",
        "correctness": "4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "NtHfJrjkiv",
        "title": "ReCEval: Evaluating Reasoning Chains via Correctness and Informativeness",
        "track": "main",
        "status": "Long Main",
        "keywords": "reasoning;multi-step reasoning;evaluation;information-gain",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "NuMemgzPYT",
        "title": "LLM-in-the-loop: Leveraging Large Language Model for Thematic Analysis",
        "track": "main",
        "status": "Short Findings",
        "keywords": "thematic analysis;NLP applications;qualitative research",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4;5",
        "correctness": "3;3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "NwJVbDxfTd",
        "title": "Semantic Similarity Covariance Matrix Shrinkage",
        "track": "main",
        "status": "Long Findings",
        "keywords": "semantics;embeddings;knowledge graphs;covariance;finance;portfolio optimization",
        "authors": "",
        "rating": "",
        "confidence": "4;4;2",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Nx9D21g1lW",
        "title": "PivotFEC: Enhancing Few-shot Factual Error Correction with a Pivot Task Approach using Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Factual Error Correction;Large Language Models;Few-shot",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "NxOeOxe6qs",
        "title": "Variator: Accelerating Pre-trained Models with Plug-and-Play Compression Modules",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large language model;model compression;plugins",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "O1IEUXd4SI",
        "title": "Do Stochastic Parrots have Feelings Too? Improving Neural Detection of Synthetic Text via Emotion Recognition",
        "track": "main",
        "status": "Long Findings",
        "keywords": "synthetic text detection;neural text detection;emotion;affective deficit",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "O36QcmUEDM",
        "title": "JWSign: A Highly Multilingual Corpus of Bible Translations for more Diversity in Sign Language Processing",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Machine Translation;Sign Languages;Dataset;Multilinguality",
        "authors": "",
        "rating": "",
        "confidence": "2;3;2",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "O4gELC78Bq",
        "title": "Towards Detecting Contextual Real-Time Toxicity for In-Game Chat",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Real-Time Toxicity Detection;Game Chat Toxicity;Game Chat Moderation",
        "authors": "",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "O4kDO3yS9B",
        "title": "Rethinking the Evaluation for Conversational Recommendation in the Era of Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Conversational Recommendation;Large Language Model;Evaluation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;2;3",
        "correctness": "4;3;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "O7eKiJpePJ",
        "title": "Instruct and Extract: Instruction Tuning for On-Demand Information Extraction",
        "track": "main",
        "status": "Long Main",
        "keywords": "information extraction;instruction-tuning;language model;open scenario",
        "authors": "",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "O9zrG7NB3X",
        "title": "Learn Your Tokens: Word-Pooled Tokenization for Language Modeling",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Tokenization;Language Modeling;BPE;Subword;Segmentation;Numeracy;Multilingual",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "OC4OLQGtIR",
        "title": "Reducing Sequence Length by Predicting Edit Spans with Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large language model;efficiency;instruction tuning;Local sequence transduction task",
        "authors": "",
        "rating": "",
        "confidence": "5;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ODeHH5FBwx",
        "title": "M2C: Towards Automatic Multimodal Manga Complement",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Manga data;Vision and Language;Chain of Thought Prompting",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "OETPPc15XG",
        "title": "Whispering LLaMA: A Cross-Modal Generative Error Correction Framework for Speech Recognition",
        "track": "main",
        "status": "Short Main",
        "keywords": "Multimodal Learning;Parameter-Efficient Adaptation;Speech Recognition;Generative Error Correction",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "OGdl9d3BEC",
        "title": "Revisiting Block-based Quantisation: What is Important for Sub-8-bit LLM Inference?",
        "track": "main",
        "status": "Long Main",
        "keywords": "large language model;LLM;quantization;NLP",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3;3",
        "correctness": "4;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "OK5yv6Fhl9",
        "title": "MULTITuDE: Large-Scale Multilingual Machine-Generated Text Detection Benchmark",
        "track": "main",
        "status": "Long Main",
        "keywords": "text generation;large language models;multilinguality;machine-generated text detection;benchmark",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "OLcDbSRjbx",
        "title": "DiffuSeq-v2: Bridging Discrete and Continuous Text Spaces for Accelerated Seq2Seq Diffusion Models",
        "track": "main",
        "status": "Short Findings",
        "keywords": "diffusion model;sequence to sequence;text generation",
        "authors": "",
        "rating": "",
        "confidence": "3;5;5",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ORHg3RKho0",
        "title": "Auto-Instruct: Automatic Instruction Generation and Ranking for Black-Box Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large Language Model;Instruction Generation;Instruction Ranking;Multi-Task Learning;In-Context Learning",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "OUiW2DzpzT",
        "title": "Characterizing Mechanisms for Factual Recall in Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Interpretability;NLP;mechanistic interpretability",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "OUmxBN45Gl",
        "title": "Do All Languages Cost the Same? Tokenization in the Era of Commercial Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Tokenization;LLMs;under-resourced languages;equitable LLMs",
        "authors": "",
        "rating": "",
        "confidence": "3;2;5",
        "correctness": "2;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "OVLnZliSHs",
        "title": "MultiTurnCleanup: A Benchmark for Multi-Turn Spoken Conversational Transcript Cleanup",
        "track": "main",
        "status": "Short Main",
        "keywords": "Multi-Turn Spoken Conversations;Crowdsourcing;Transcript Cleanup;Disfluency Detection",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "OVmOQs85Xb",
        "title": "Dynamic Open-book Prompt for Conversational Recommender System",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Conversational Recommender System;Graph Learning;Prompt Learning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "3;2;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "OVt2dIwxR1",
        "title": "Re$^3$Dial: Retrieve, Reorganize and Rescale Conversations for Long-Turn Open-Domain Dialogue Pre-training",
        "track": "main",
        "status": "Long Main",
        "keywords": "Dialogue;Large-scale Pre-training;Pre-training data;Multi-turn Dialogue",
        "authors": "",
        "rating": "",
        "confidence": "3;4;5;3;3",
        "correctness": "3;4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6,
        "correctness_avg": 3.8,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "OXQFcwKrTM",
        "title": "Salespeople vs SalesBot: Exploring the Role of Educational Value in Conversational Recommender Systems",
        "track": "main",
        "status": "Long Findings",
        "keywords": "conversational recommender systems;mixed-initiative conversational agents;mixed-type conversational dataset",
        "authors": "",
        "rating": "",
        "confidence": "5;4;3",
        "correctness": "5;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "OYWeQdQiIn",
        "title": "Identifying Conspiracy Theories News based on Event Relation Graph",
        "track": "main",
        "status": "Long Findings",
        "keywords": "conspiracy theory;misinformation;event relation graph",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "OZOrQQBDou",
        "title": "TCRA-LLM: Token Compression Retrieval Augmented Large Language Model for Inference Cost Reduction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large language model;Retrieval augmented;Knowledge compression;Question Answering",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "OcaifDZKkA",
        "title": "Active Learning for Natural Language Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "active learning;NLG;generation",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Of2xc2GVid",
        "title": "On the Calibration of Large Language Models and Alignment",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large Language Models;Calibration",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "2;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "OfBAABKH5X",
        "title": "Beyond Denouncing Hate: Strategies for Countering Implied Biases and Stereotypes in Language",
        "track": "main",
        "status": "Long Findings",
        "keywords": "counterspeech;stereotypes",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "OgK0kMz5Va",
        "title": "Prompting Scientific Names for Zero-Shot Species Recognition",
        "track": "main",
        "status": "Short Main",
        "keywords": "vision-language model;fine-grained recognition;zero-shot recognition;prompt engineering;species recognition",
        "authors": "",
        "rating": "",
        "confidence": "4;5;5",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "OhZLO1yunf",
        "title": "NEWTON: Are Large Language Models Capable of Physical Reasoning?",
        "track": "main",
        "status": "Long Findings",
        "keywords": "physical reasoning;robotics;object-centric;evaluation;benchmark;reasoning",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;2;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "OkQD6RMUK5",
        "title": "Label Words are Anchors: An Information Flow Perspective for Understanding In-Context Learning",
        "track": "main",
        "status": "Long Main",
        "keywords": "in-context learning;label words;anchors;large language models",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "5;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.666666666666667,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Ov6OZ2TFKI",
        "title": "A Video Is Worth 4096 Tokens: Verbalize Story Videos To Understand Them In Zero Shot",
        "track": "main",
        "status": "Long Main",
        "keywords": "video understanding;large language models;persuasion strategies;zero-shot;long video understanding",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "OwWIl6gb1z",
        "title": "CRoW: Benchmarking Commonsense Reasoning in Real-World Tasks",
        "track": "main",
        "status": "Long Main",
        "keywords": "commonsense reasoning;benchmark;real-world task",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "OwxjgsX68V",
        "title": "CASSI: Contextual and Semantic Structure-based Interpolation Augmentation for Low-Resource NER",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Named Entity Recognition;Text Augmentation;Low-Resource;Structure-Based Augmentation;Language Model;Context Diversity",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Ox0OoyLass",
        "title": "How Well Do Text Embedding Models Understand Syntax?",
        "track": "main",
        "status": "Long Findings",
        "keywords": "sentence embedding;compositional understanding",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "OxoP1qFotz",
        "title": "Quality > Quantity: Synthetic Corpora from Foundation Models for Closed-Domain Extractive Question Answering",
        "track": "main",
        "status": "Reject",
        "keywords": "Closed Domain Question Answering;Prompt Engineering;Foundational Models;Domain Adaptation",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "P04rLpllH7",
        "title": "A Black-Box Attack on Code Models via Representation Nearest Neighbor Search",
        "track": "main",
        "status": "Long Findings",
        "keywords": "black box attacks;code models;robustness;code adversarial example",
        "authors": "",
        "rating": "",
        "confidence": "2;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "P2jDML1Ub6",
        "title": "Are Personalized Stochastic Parrots More Dangerous? Evaluating Persona Biases in Dialogue Systems",
        "track": "main",
        "status": "Long Findings",
        "keywords": "dialogue model persona;fairness;evaluation",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "P5hYS77k10",
        "title": "Quantifying the redundancy between prosody and text",
        "track": "main",
        "status": "Long Main",
        "keywords": "Prosody;Psycholinguistics;Language Models;Information Theory",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "5;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.666666666666667,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "P9V2jcotAF",
        "title": "Beyond Shared Vocabulary: Increasing Representational Word Similarities across Languages for Multilingual Machine Translation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Multilingual Machine Translation;Shared Vocabulary",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3;4",
        "correctness": "4;3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "PAByut8fMZ",
        "title": "A Quality-based Syntactic Template Retriever for Syntactically-Controlled Paraphrase Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Paraphrase generation;Syntactic template retrievers;Mutual diversity",
        "authors": "",
        "rating": "",
        "confidence": "5;4;5",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "PBvSGqYCSa",
        "title": "Bridging Background Knowledge Gaps in Translation with Automatic Explicitation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Explicitation;translation;cross\u2011cultural NLP;pragmatic explicitation;multi-cultural NLP;explanatory translation",
        "authors": "",
        "rating": "",
        "confidence": "3;2;3;3;3",
        "correctness": "4;4;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.8,
        "correctness_avg": 3.8,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "PBwotNgvp3",
        "title": "Zero-shot Topical Text Classification with LLMs - an Experimental Study",
        "track": "main",
        "status": "Long Findings",
        "keywords": "topic classification;zero-shot classification;text classification;LLMs",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "PCNsizlhRU",
        "title": "Towards Conceptualization of ``Fair Explanation'': Disparate Impacts of anti-Asian Hate Speech Explanations on Content Moderators",
        "track": "main",
        "status": "Long Main",
        "keywords": "fairness;explainability;human study;hate speech prediction;content moderators;crowdworkers",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "2;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "PCyB5LUF4z",
        "title": "Learning to Follow Object-Centric Image Editing Instructions Faithfully",
        "track": "main",
        "status": "Long Findings",
        "keywords": "natural language instruction;image editing;stable diffusion;diffusion model;text-to-image;multimodal",
        "authors": "",
        "rating": "",
        "confidence": "4;3;5;4",
        "correctness": "4;4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "PHh1s8dNlY",
        "title": "DIVE: Towards Descriptive and Diverse Visual Commonsense Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Visual commonsense generation;descriptive and diverse text generation;commonsense inference;vision-language model",
        "authors": "",
        "rating": "",
        "confidence": "4;2;3;4;3",
        "correctness": "4;3;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.2,
        "correctness_avg": 3.8,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "PHtXqUNGUA",
        "title": "SummEdits: Measuring LLM Ability at Factual Reasoning Through The Lens of Summarization",
        "track": "main",
        "status": "Long Main",
        "keywords": "factual consistency;faithfulness;summarization;LLMs;benchmark",
        "authors": "",
        "rating": "",
        "confidence": "3;2;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "PNpRxOhVut",
        "title": "A Spectral Viewpoint on Continual Relation Extraction",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Relation Extraction;Information Extraction;Continual Learning;Spectral Analysis",
        "authors": "",
        "rating": "",
        "confidence": "4;3;2",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "PPwRa7Wmg1",
        "title": "VIP5: Towards Multimodal Foundation Models for Recommendation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multimodal Foundation Model;Recommender Systems;Large Language Model;Parameter-efficient Tuning;Personalized Prompt",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3;4",
        "correctness": "3;2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "PSlrVYPTAX",
        "title": "Conversational Recommender System and Large Language Model Are Made for Each Other in E-commerce Pre-sales Dialogue",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Conversational recommendation;large language model;collaboration method",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "PT63nNpyKg",
        "title": "Large Language Models are biased to overestimate profoundness",
        "track": "main",
        "status": "Short Main",
        "keywords": "Large language models;reasoning;bias;nonsensical statements",
        "authors": "",
        "rating": "",
        "confidence": "4;2;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "PT6lSdWEgw",
        "title": "Toxicity in Multilingual Machine Translation at Scale",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Toxicity;Multilingual Machine Translation;Scale",
        "authors": "",
        "rating": "",
        "confidence": "4;4;2",
        "correctness": "3;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "PTko0qsiA4",
        "title": "Large Language Models as Source Planner for Personalized Knowledge-grounded Dialogues",
        "track": "main",
        "status": "Long Findings",
        "keywords": "knowledge-grounded dialogue system;personalized dialogue system;large lanuage models",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3;4",
        "correctness": "4;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "PWWg9q3S0C",
        "title": "From Multilingual Complexity to Emotional Clarity: Leveraging Commonsense to Unveil Emotions in Code-Mixed Dialogues",
        "track": "main",
        "status": "Long Main",
        "keywords": "Emotion Recognition in Conversation;Code-mix dialogues;Commonsense",
        "authors": "",
        "rating": "",
        "confidence": "4;2;5",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "PXkS70nuNp",
        "title": "CRaSh: Clustering, Removing, and Sharing Enhance Fine-tuning without Full Large Language Model",
        "track": "main",
        "status": "Long Main",
        "keywords": "large language models;transfer learning;representation similarity;model privacy",
        "authors": "",
        "rating": "",
        "confidence": "4;2;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "PaVP2Sc6pJ",
        "title": "A Novel Contrastive Learning Method for Clickbait Detection on RoCliCo: A Romanian Clickbait Corpus of News Articles",
        "track": "main",
        "status": "Short Findings",
        "keywords": "clickbait detection;low-resource language;Romanian corpus;contrastive learning",
        "authors": "",
        "rating": "",
        "confidence": "4;5;4;4",
        "correctness": "2;3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Pb1DhkTVLZ",
        "title": "Estimating Large Language Model Capabilities without Labeled Test Data",
        "track": "main",
        "status": "Long Findings",
        "keywords": "large language model;accuracy prediction;confidence;calibration;in-context learning",
        "authors": "",
        "rating": "",
        "confidence": "2;4;4;4",
        "correctness": "3;3;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "PffUQuD8sn",
        "title": "Statistical Depth for Ranking and Characterizing Transformer-Based Text Embeddings",
        "track": "main",
        "status": "Long Main",
        "keywords": "text embeddings;transformers;statistical inference;corpus analysis;statistical depth;in-context learning;synthetic data augmentation",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "PnAmH1silV",
        "title": "On Bilingual Lexicon Induction with Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Bilingual Lexicon Induction;Large Language Models",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "PoMCId4iez",
        "title": "From Dissonance to Insights: Dissecting Disagreements in Rationale Construction for Case Outcome Classification",
        "track": "main",
        "status": "Long Main",
        "keywords": "legal judgement prediction;case outcome classification;disagreement;explainability;rationale dataset",
        "authors": "",
        "rating": "",
        "confidence": "2;3;5",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "PomhVDrvco",
        "title": "EpiK-Eval: Evaluation for Language Models as Epistemic Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "large language models;large language model;LLMs;LLM;language model;language models;LM;LMs;EpiK-Eval;knowledge consolidation;story;benchmark;knowledge-base;KB;theory-of-mind;epistemic;hallucination;hallucinate;dataset;task;scale;scaling;knowledge representation;reasoning;consolidation;knowledge;context;evaluation;limitations;limitation;narrative;narratives;training objective;causal language modeling;masked language modeling",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Pu5tJykUeT",
        "title": "ART: rule bAsed futuRe-inference deducTion",
        "track": "main",
        "status": "Long Main",
        "keywords": "cross-modal;deductive reasoning;deep learning",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Pw9vYSPJKk",
        "title": "DiffusionRet: Diffusion-Enhanced Generative Retriever using Constrained Decoding",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Infromation Retrieval;Diffusion Model;Generative Retrieval;Model-based Retrieval",
        "authors": "",
        "rating": "",
        "confidence": "3;4;5",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "PxEhoPiBB0",
        "title": "Is GPT-4 a Good Data Analyst?",
        "track": "main",
        "status": "Long Findings",
        "keywords": "data analyst;GPT4",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4;3",
        "correctness": "3;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "PyAzL6Z802",
        "title": "Multilingual estimation of political-party positioning: From label aggregation to long-input Transformers",
        "track": "main",
        "status": "Long Main",
        "keywords": "computational social science;scaling analysis;political science;political party positioning",
        "authors": "",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "PyJ78pUMEE",
        "title": "Just Adjust One Prompt: Enhancing In-Context Dialogue Scoring via Constructing the Optimal Subgraph of Demonstrations and Prompts",
        "track": "main",
        "status": "Long Main",
        "keywords": "dialogue evaluation;in-context learning;large language models;prompt generation",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4;3",
        "correctness": "4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "PzINxIyV9o",
        "title": "InterFair: Debiasing with Natural Language Feedback for Fair Interpretable Predictions",
        "track": "main",
        "status": "Short Main",
        "keywords": "Debiasing;Language Models;Rationale;Interactions;User Interventions",
        "authors": "",
        "rating": "",
        "confidence": "2;4;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Q2IInBu2kz",
        "title": "PCMID: Multi-Intent Detection through Supervised Prototypical Contrastive Learning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Dialogue System;Multi-Intent Detection",
        "authors": "",
        "rating": "",
        "confidence": "5;5;4;4",
        "correctness": "4;2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Q2Wu2Cfp2x",
        "title": "Practical Computational Power of Linear Transformers and Their Recurrent and Self-Referential Extensions",
        "track": "main",
        "status": "Short Main",
        "keywords": "recurrent neural networks;RNNs;transformers;computational power;automata;counter machines;formal languages;linear transformers;self-reference;self-referential weight matrix",
        "authors": "",
        "rating": "",
        "confidence": "2;1;2;1;2",
        "correctness": "4;2;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 1.6,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Q4u18Ui7YS",
        "title": "Explore-Instruct: Enhancing Domain-Specific Instruction Coverage through Active Exploration",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Models;Instruction-Tuning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Q5nM3rpiVm",
        "title": "Towards Better Representations for Multi-Label Text Classification with Multi-granularity Information",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multi-label text classification;Text representation;Contrastive learning;Multi-granularity information",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Q93hLxLKLB",
        "title": "We Need to Talk About Reproducibility in NLP Model Comparison",
        "track": "main",
        "status": "Long Main",
        "keywords": "reproducibility;NLP model comparison;corpus splitting strategy",
        "authors": "",
        "rating": "",
        "confidence": "2;3;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Q9BLbN1p6h",
        "title": "Mixture-of-Linguistic-Experts Adapters for Improving and Interpreting Pre-trained Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "adapters;graph neural networks;parameter-efficient fine-tuning;interpretability;dependency trees",
        "authors": "",
        "rating": "",
        "confidence": "4;5;3",
        "correctness": "2;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "QA1jlb1VG7",
        "title": "CITB: A Benchmark for Continual Instruction Tuning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Instruction tuning;continual learning;benchmark;evaluation",
        "authors": "",
        "rating": "",
        "confidence": "3;5;3;4",
        "correctness": "3;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "QAT5suGpNL",
        "title": "Breaking the Language Barrier: Improving Cross-Lingual Reasoning with Structured Self-Attention",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Cross-lingual;Multilingual;Reasoning",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "QAZ2QV8SqN",
        "title": "KG-GPT: A General Framework for Reasoning on Knowledge Graphs Using Large Language Models",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Large Language Model;Knowledge Graph;Reasoning;Question Answering;Fact Verification",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "QEf1MyZGZu",
        "title": "Target-Aware Spatio-Temporal Reasoning via Answering Questions in Dynamic Audio-Visual Scenarios",
        "track": "main",
        "status": "Long Findings",
        "keywords": "audio-visual question answering;spatio-temporal reasoning;multimodal learning;video question answering",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4;3",
        "correctness": "3;3;1;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "QG4BWnsX6m",
        "title": "Multilingual Lottery Tickets to Pretrain Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "lottery ticket hypothesis;negative interference;zero-shot neural architecture search;multilingual pretrained language model",
        "authors": "",
        "rating": "",
        "confidence": "4;1;2",
        "correctness": "3;5;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "QH19wfJrX1",
        "title": "mLongT5: A Multilingual and Efficient Text-To-Text Transformer for Longer Sequences",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Multilinguality;Efficient model;Long inputs",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "QH4EMvwF8I",
        "title": "Query2doc: Query Expansion with Large Language Models",
        "track": "main",
        "status": "Short Main",
        "keywords": "query expansion;large language models;information retrieval",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "QMCjppVJbB",
        "title": "SEAHORSE: A Multilingual, Multifaceted Dataset for Summarization Evaluation",
        "track": "main",
        "status": "Long Main",
        "keywords": "summarization;evaluation;multilingual;human evaluation;automatic metrics;NLG",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "5;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "QPP8wNMBBk",
        "title": "Unsupervised Lexical Simplification with Context Augmentation",
        "track": "main",
        "status": "Short Findings",
        "keywords": "lexical simplification;lexical substitution;lexical semantics;unsupervised",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "QV79qiKAjD",
        "title": "On the Benefits of Learning to Route in Mixture-of-Experts Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "mixture-of-experts;transformer;router;efficiency;conditional compute;sparsely activated models;theory",
        "authors": "",
        "rating": "",
        "confidence": "3;3;2",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "QVnlBmGrWS",
        "title": "ORCHID: A Chinese Debate Corpus for Target-Independent Stance Detection and Argumentative Dialogue Summarization",
        "track": "main",
        "status": "Long Main",
        "keywords": "dialogue dataset;long dialogue summarization;target-independent stance detection",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "QVuVwt1QLh",
        "title": "Unifying Text, Tables, and Images for Multimodal Question Answering",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multimodal Question Answering;Modality Unification;Image Caption",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "QYSPlIZ6bV",
        "title": "TalkUp: Paving the Way for Understanding Empowering Language",
        "track": "main",
        "status": "Long Findings",
        "keywords": "natural language processing;empowerment",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "QYvFUlF19n",
        "title": "In-Context Learning Creates Task Vectors",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Large Language Models;In-Context Learning;Interpretability",
        "authors": "",
        "rating": "",
        "confidence": "5;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "QdhjuI19nv",
        "title": "Compositional Generalization for Data-to-Text Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Compositional Generalization;Data-to-Text Generation;Natural Language Generation;Clustering;Reinforcement Learning;Benchmark",
        "authors": "",
        "rating": "",
        "confidence": "2;4;2;4",
        "correctness": "4;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "QkCYv3TlGk",
        "title": "Non-parallel Accent Transfer based on Fine-grained Controllable Accent Modelling",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Accent Transfer\uff0cFine-grained Controllable Accent Modelling\uff0cNon-parallel",
        "authors": "",
        "rating": "",
        "confidence": "5;2;3",
        "correctness": "3;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "QlY0TSxVIl",
        "title": "Revisiting Automated Topic Model Evaluation with Large Language Models",
        "track": "main",
        "status": "Short Main",
        "keywords": "topic model evaluation;interpretability;large language models;text clustering",
        "authors": "",
        "rating": "",
        "confidence": "4;2;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "QnXfnQ3MFe",
        "title": "Dynamic Low-rank Estimation for Transformer-based Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "low-rank estimation; matrix factorization;",
        "authors": "",
        "rating": "",
        "confidence": "3;2;3;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "QoiOmXy3A7",
        "title": "Describe Me an Auklet: Generating Grounded Perceptual Category Descriptions",
        "track": "main",
        "status": "Long Main",
        "keywords": "language-and-vision;grounding;zero-shot;cognitive theories of categorisation;natural language generation;natural language interpretation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "2;2;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "QtOybganmT",
        "title": "Enhancing Retrieval-Augmented Large Language Models with Iterative Retrieval-Generation Synergy",
        "track": "main",
        "status": "Long Findings",
        "keywords": "retrieval-augmented language model;prompting;retrieval",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "QtyJZe9Sfz",
        "title": "When and Why Does Bias Mitigation Work?",
        "track": "main",
        "status": "Long Findings",
        "keywords": "debiasing;lexical biases;natural language understanding",
        "authors": "",
        "rating": "",
        "confidence": "4;3;1",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Qu0OZXL29t",
        "title": "Centering the Margins: Outlier-Based Identification of Harmed Populations in Toxicity Detection",
        "track": "main",
        "status": "Long Main",
        "keywords": "AI fairness;AI ethics;toxicity detection;hate speech detection;outlier analysis;marginalization;harm measurement",
        "authors": "",
        "rating": "",
        "confidence": "3;5;4",
        "correctness": "4;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Qv2CTIcCPJ",
        "title": "The language of prompting: What linguistic properties make a prompt successful?",
        "track": "main",
        "status": "Long Findings",
        "keywords": "prompting;evaluation;LLMs;zero-shot;robustness;instability;instruction-tuning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "QwejPcX96r",
        "title": "Large language models effectively leverage document-level context for literary translation, but critical errors persist",
        "track": "main",
        "status": "Reject",
        "keywords": "machine translation;paragraph-level translation;literary translation;large language models",
        "authors": "",
        "rating": "",
        "confidence": "2;4;3",
        "correctness": "3;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 1.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Qyw4k4ohgr",
        "title": "Epsilon Sampling Rocks: Investigating Sampling Strategies for Minimum Bayes Risk Decoding for Machine Translation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "machine translation;mbr decoding;decoding strategies;bleurt;automatic evaluation",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "R0XABYPVKI",
        "title": "Knowledge Corpus Error in Question Answering",
        "track": "main",
        "status": "Short Findings",
        "keywords": "large language models;open-domain question answering;retrieval;qa;odqa",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "2;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "R2PwXB08i4",
        "title": "WordNet Is All You Need: A Surprisingly Effective Unsupervised Method for Graded Lexical Entailment",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Graded Lexical Entailment;WordNet",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "R4N3RNBNzJ",
        "title": "STINMatch: Semi-Supervised Semantic-Topological Iteration Network for Financial Risk Detection via News Label Diffusion",
        "track": "main",
        "status": "Long Main",
        "keywords": "semi-supervised;text-graph joint learning;risk detection",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4;3",
        "correctness": "3;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "R4VfYDluYi",
        "title": "Learning Co-Speech Gesture for Multimodal Aphasia Type Detection",
        "track": "main",
        "status": "Long Main",
        "keywords": "Aphasia;NLP;Applications;Speech;Multimodality",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "R4yb4m7Nus",
        "title": "Model-tuning Via Prompts Makes NLP Models Adversarially Robust",
        "track": "main",
        "status": "Long Main",
        "keywords": "Natural Language Processing;Language Models;BERT;RoBERTa;Prompting;Adversarial Robustness",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "R5NzXYY7S2",
        "title": "Modeling Legal Reasoning: LM Annotation at the Edge of Human Agreement",
        "track": "main",
        "status": "Long Main",
        "keywords": "language modeling;annotation;legal reasoning;United States Supreme Court",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "R635gF7lXD",
        "title": "StructGPT: A General Framework for Large Language Model to Reason over Structured Data",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Model;Structured Data",
        "authors": "",
        "rating": "",
        "confidence": "3;5;3",
        "correctness": "3;5;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "R7Op9CHdPz",
        "title": "Causal Reasoning through Two Cognition Layers for Improving Generalization in Visual Question Answering",
        "track": "main",
        "status": "Long Main",
        "keywords": "visual question answering;generalization;casual reasoning;human cognition",
        "authors": "",
        "rating": "",
        "confidence": "2;3;4;3",
        "correctness": "4;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "R7f5euZ9RA",
        "title": "Ranking LLM-Generated Loop Invariants for Program Verification",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Large Language Model;Loop Invariant Synthesis;Re-ranking",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "RAtrnAtAsM",
        "title": "LEGO: A Multi-agent Collaborative Framework with Role-playing and Iterative Feedback for Causality Explanation Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Causality explanation generation; Commonsense reasoning; Large language model",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "RE4oyAdAvM",
        "title": "Domain Adaptation for Conversational Query Production with the RAG Model Feedback",
        "track": "main",
        "status": "Long Findings",
        "keywords": "conversational query production;knowledge-aided dialogue system;text generation",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "RGmQOhSGp0",
        "title": "Beneath the Surface: Unveiling Harmful Memes with Multimodal Reasoning Distilled from Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Harmful meme detection;multimodal reasoning;knowledge distillation;large language models",
        "authors": "",
        "rating": "",
        "confidence": "3;5;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "RJRCWXGtds",
        "title": "Understanding Computational Models of Semantic Change: New Insights from the Speech Community",
        "track": "main",
        "status": "Short Main",
        "keywords": "semantic change detection;semantic shifts;word embeddings;BERT;language contact",
        "authors": "",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "RJq3hJlK6w",
        "title": "Example-based Hypernetworks for Multi-source Adaptation to Unseen Domains",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Domain adaptation;our of distribution;cross-lingual;hypernetworks;prompting",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3;2",
        "correctness": "2;3;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.75,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "RKqtOoMC1M",
        "title": "Multilingual \\textit{k}-Nearest-Neighbor Machine Translation",
        "track": "main",
        "status": "Short Main",
        "keywords": "multilingual machine translation;semi-parametric;kNN-MT",
        "authors": "",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "RLmpJ4xol2",
        "title": "Learning Preference Model for LLMs via Automatic Preference Data Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Model;Reward Model;Preference Model",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "RMDZNIjTt7",
        "title": "IBADR: an Iterative Bias-Aware Dataset Refinement Framework for Debiasing NLU models",
        "track": "main",
        "status": "Long Main",
        "keywords": "debiased models; dataset refinement; spurious correlation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "RN5KLywTll",
        "title": "What's \"up\" with vision-language models? Investigating their struggle with spatial reasoning",
        "track": "main",
        "status": "Long Main",
        "keywords": "vision-language;spatial relations;interpretability",
        "authors": "",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "RO460OVpev",
        "title": "Chinese Metaphorical Relation Extraction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Metaphor understanding;metaphorical relation extraction;linguistic metaphor;cognitive metaphor",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "RSuN6p3wXR",
        "title": "APrompt: Attention Prompt Tuning for Efficient Adaptation of Pre-trained Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Prompt Tuning;Parameter Efficient Learning;Attention Prompt",
        "authors": "",
        "rating": "",
        "confidence": "5;4;5",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "RVQccn8rcr",
        "title": "Polar Ducks and Where to Find Them: Enhancing Entity Linking with Duck Typing and Polar Box Embeddings",
        "track": "main",
        "status": "Long Main",
        "keywords": "Entity linking;Entity disambiguation;Box embeddings",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "RWH1WazQqE",
        "title": "Democratizing LLMs: An Exploration of Cost-Performance Trade-offs in Self-Refined Open-Source Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "large-language-model;open-source;self-refinement;ranking-metric;cost-analysis",
        "authors": "",
        "rating": "",
        "confidence": "1;4;3",
        "correctness": "3;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "RWJYEeaW1d",
        "title": "EasyQuant: An Efficient Data-free Quantization Algorithm for LLMs",
        "track": "main",
        "status": "Long Main",
        "keywords": "model quantization",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "RXIYmRUWGD",
        "title": "Improved Unsupervised Chinese Word Segmentation Using Pre-trained Knowledge and Pseudo-labeling Transfer",
        "track": "main",
        "status": "Short Main",
        "keywords": "Unsupervised Chinese Word Segmentation",
        "authors": "",
        "rating": "",
        "confidence": "5;5;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "RYvNvCU109",
        "title": "Energy and Carbon Considerations of Fine-Tuning BERT",
        "track": "main",
        "status": "Short Findings",
        "keywords": "energy costs;fine-tuning;efficiency evaluation;efficiency;BERT;transformer",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Ra6gfR3XuI",
        "title": "Understanding the Role of Input Token Characters in Language Models: How Does Information Loss Affect Performance?",
        "track": "main",
        "status": "Long Main",
        "keywords": "LLMs;Interpretability;Pretraining",
        "authors": "",
        "rating": "",
        "confidence": "5;4;5",
        "correctness": "3;5;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "RbE83Pmtfk",
        "title": "DeTiME: Diffusion-Enhanced Topic Modeling using Encoder-decoder based LLM",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Topic Modeling;Diffusion;Encoder-Decoder LLM;FlanT5;CNN",
        "authors": "",
        "rating": "",
        "confidence": "5;3;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "RcvJnskt0n",
        "title": "Detection of Multiple Mental Disorders from Social Media with Two-Stream Psychiatric Experts",
        "track": "main",
        "status": "Long Main",
        "keywords": "Mental disease detection;symptom;multi-task learning;interpretability;social media",
        "authors": "",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ReGzwoL3Sl",
        "title": "Semi-Structured Object Sequence Encoders",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Structured object encoders;long sequences",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "RenTc1sUb7",
        "title": "On Task-personalized Multimodal Few-shot Learning for Visually-rich Document Entity Retrieval",
        "track": "main",
        "status": "Long Findings",
        "keywords": "document understanding;multiple modalities;entity retrieval;few shots;meta learning;out of distribution",
        "authors": "",
        "rating": "",
        "confidence": "1;4;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "RgA1tcrxan",
        "title": "M2DF: Multi-grained Multi-curriculum Denoising Framework for Multimodal Aspect-based Sentiment Analysis",
        "track": "main",
        "status": "Long Main",
        "keywords": "aspect-based sentiment analysis",
        "authors": "",
        "rating": "",
        "confidence": "5;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "RkqyZj5QNN",
        "title": "Text Classification via Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large Language Model;Text Classification;Intermediate Rationale Explanations",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "RlPI6mERbr",
        "title": "Pre-trained Speech Processing Models Contain Human-Like Biases that Propagate to Speech Emotion Recognition",
        "track": "main",
        "status": "Long Findings",
        "keywords": "AI bias;speech processing;embeddings;representation learning;bias propagation",
        "authors": "",
        "rating": "",
        "confidence": "3;2;3;3",
        "correctness": "4;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Rn1k3Na4Cn",
        "title": "CLAD-ST: Contrastive Learning with Adversarial Data for Robust Speech Translation",
        "track": "main",
        "status": "Short Main",
        "keywords": "robust speech translation;contrastive learning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "RndkyLWLHc",
        "title": "Natural Language Annotations for Reasoning about Program Semantics",
        "track": "main",
        "status": "Short Findings",
        "keywords": "program understanding;natural language reasoning;dataset",
        "authors": "",
        "rating": "",
        "confidence": "2;3;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Ro3x3mCAkD",
        "title": "Connecting the Dots: What Graph-Based Text Representations Work Best for Text Classification using Graph Neural Networks?",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Graph-Based Text Representation;Graph Neural Networks;Text Classification",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Ror9xJhbdc",
        "title": "Revisiting Instruction Fine-tuned Model Evaluation to Guide Industrial Applications",
        "track": "main",
        "status": "Short Main",
        "keywords": "Instruction Finetuning;Evaluation Metrics;Large Language Models",
        "authors": "",
        "rating": "",
        "confidence": "3;2;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "RsK483IRuO",
        "title": "A Closer Look into Using Large Language Models for Automatic Evaluation",
        "track": "main",
        "status": "Short Findings",
        "keywords": "LLM;automatic evaluation;LLM evaluaiton",
        "authors": "",
        "rating": "",
        "confidence": "4;5;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "RubWYFBZbG",
        "title": "Fair Without Leveling Down: A New Intersectional Fairness Definition",
        "track": "main",
        "status": "Long Main",
        "keywords": "Fairness; Intersectional; Leveling Down",
        "authors": "",
        "rating": "",
        "confidence": "2;3;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Rvz7LvHcdX",
        "title": "Type-Aware Decomposed Framework for Few-Shot Named Entity Recognition",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Named Entity Recognition;Few-Shot Learning",
        "authors": "",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "RwzFNbJ3Ez",
        "title": "SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "generative-AI hallucination;fact-checking;trustworthy artificial intelligence",
        "authors": "",
        "rating": "",
        "confidence": "4;4;2;5",
        "correctness": "4;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "RxvMKDgZH6",
        "title": "Accelerating Multiple Intent Detection and Slot Filling via Targeted Knowledge Distillation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multiple Intent Detection and Slot Filling;Knowledge Distillation;Non-Autoregressive",
        "authors": "",
        "rating": "",
        "confidence": "3;3;5",
        "correctness": "2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Rz5eVgy8Sd",
        "title": "An Intent-based and Annotation-free Method for Duplicate Question Detection in CQA Forums",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Sentence-level Semantics;Textual Inference;Data deduplicating;Instruct-tuning",
        "authors": "",
        "rating": "",
        "confidence": "5;5;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "RzWrY4KYg8",
        "title": "Uncovering Limitations in Text-to-Image Generation: A Contrastive Approach with Structured Semantic Alignment",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multi-modal generation;Semantic consistency;Structure information learning",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "S0eqbM16k2",
        "title": "Instances and Labels: Hierarchy-aware Joint Supervised Contrastive Learning for Hierarchical Multi-Label Text Classification",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Natural language processing;Multi-label Classification;Contrastive Learning in NLP",
        "authors": "",
        "rating": "",
        "confidence": "3;4;2",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "S5eTDhfjHM",
        "title": "tagE: Enabling an Embodied Agent to Understand Human Instructions",
        "track": "main",
        "status": "Long Findings",
        "keywords": "human-robot interaction; NLP for robotics; task and argument extraction; task and argument grounding;",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "S81zso7Imh",
        "title": "IC3: Image Captioning by Committee Consensus",
        "track": "main",
        "status": "Long Main",
        "keywords": "Image Captioning;Large Language Models;Prompt Engineering;Visual Description",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4;3",
        "correctness": "4;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "SAM1HFH6iB",
        "title": "Self-Evolution Learning for Mixup: Enhance Data Augmentation on Few-Shot Text Classification Tasks",
        "track": "main",
        "status": "Long Main",
        "keywords": "self-evolution learning;mixup;pretrained language model;few-shot text classification",
        "authors": "",
        "rating": "",
        "confidence": "5;4;3;3",
        "correctness": "3;2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "SEFD0G4kf0",
        "title": "USB: A Unified Summarization Benchmark Across Tasks and Domains",
        "track": "main",
        "status": "Long Findings",
        "keywords": "summarization;large language models;pretraining;benchmarks;factual correctness",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "SFTvQQA4KJ",
        "title": "FLatS: Principled Out-of-Distribution Detection with Feature-Based Likelihood Ratio Score",
        "track": "main",
        "status": "Short Main",
        "keywords": "OOD Detection;Likelihood Ratio;Intent Classification",
        "authors": "",
        "rating": "",
        "confidence": "4;3;2;3",
        "correctness": "4;3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "SHkMYY26KP",
        "title": "On General Language Understanding",
        "track": "main",
        "status": "Short Findings",
        "keywords": "NLU;evaluation;benchmarking;semantics;dialogue;modelling;measurement",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;1",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "SI2CXa5eok",
        "title": "AMR Parsing with Causal Hierarchical Attention and Pointers",
        "track": "main",
        "status": "Long Main",
        "keywords": "semantic parsing;AMR parsing;hierarical attention;pointer mechanism",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "SJ0Da0j8n7",
        "title": "Exploring Linguistic Probes for Morphological Inflection",
        "track": "main",
        "status": "Short Main",
        "keywords": "morphology;inflection;linguistic probes;English;Spanish;Swahili",
        "authors": "",
        "rating": "",
        "confidence": "4;3;2",
        "correctness": "5;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "SJYTfbI59J",
        "title": "Open-source Large Language Models are Strong Zero-shot Query Likelihood Models for Document Ranking",
        "track": "main",
        "status": "Short Findings",
        "keywords": "large language model;query likelihood model;zero-shot ranking model",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4;3",
        "correctness": "4;2;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "SNB6BwY2zy",
        "title": "Detecting and Mitigating Hallucinations in Multilingual Summarisation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Summarisation;Multilingual NLP;Hallucination;Natural Language Generation;Faithfulness Evaluation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "SP8zIwanHD",
        "title": "$\\textbf{\\emph{CLMSM}}$: A Multi-Task Learning Framework for Pre-training on Procedural Text",
        "track": "main",
        "status": "Long Findings",
        "keywords": "pre-training;procedural reasoning;contrastive learning;masked language modeling;multi-task learning;nlp",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "SPtskxPEiV",
        "title": "Role of Context in Unsupervised Sentence Representation Learning: the Case of Dialog Act Modeling",
        "track": "main",
        "status": "Short Findings",
        "keywords": "unsupervised learning;sentence representation;dialog act modeling",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "SQodZvCM5g",
        "title": "Neuro-Symbolic Sentiment Analysis with Dynamic Word Sense Disambiguation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "sentiment analysis;neuro-symbolic AI;word sense disambiguation",
        "authors": "",
        "rating": "",
        "confidence": "3;4;2",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "SS44Mrv21o",
        "title": "EARA: Improving Biomedical Semantic Textual Similarity with Entity-Aligned Attention and Retrieval Augmentation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Biomedical semantic textual similarity;entity-aligned regularization;retrival augmentation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3;2",
        "correctness": "4;3;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ST0ejo0mnc",
        "title": "A Rewriting Approach for Gender Inclusivity in Portuguese",
        "track": "main",
        "status": "Long Findings",
        "keywords": "nlp;portuguese;gender neutrality;gender inclusivity;machine translation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "4;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "STHKApXVMH",
        "title": "Unnatural Error Correction: GPT-4 Can Almost Perfectly Handle Unnatural Scrambled Text",
        "track": "main",
        "status": "Short Main",
        "keywords": "Large Language Models;Emergent Ability;Scrambled Text;GPT-4",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4;4",
        "correctness": "4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "SUAeMJKg6b",
        "title": "\u201cMistakes Help Us Grow\u201d: Facilitating and Evaluating Growth Mindset Supportive Language in Classrooms",
        "track": "main",
        "status": "Long Main",
        "keywords": "Growth mindset;Language models;Education;Applications",
        "authors": "",
        "rating": "",
        "confidence": "5;5;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "SViJgzox1z",
        "title": "Parameter Efficient Multi-task Fine-tuning by Learning to Transfer Token-wise Prompts",
        "track": "main",
        "status": "Long Findings",
        "keywords": "multi-task learning;token-wise;memory network;instance-dependent prompt",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3;4",
        "correctness": "3;2;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "SdpSaw26XT",
        "title": "Mirror: A Universal Framework for Various Information Extraction Tasks",
        "track": "main",
        "status": "Long Main",
        "keywords": "Information Extraction;Non-Autoregressive Decoding;Multi-task",
        "authors": "",
        "rating": "",
        "confidence": "5;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "SfI8GT3xdb",
        "title": "Chain-of-Questions Training with Latent Answers for Robust Multistep Question Answering",
        "track": "main",
        "status": "Long Main",
        "keywords": "multistep reasoning;question answering;latent variable learning",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ShQoWnMu1b",
        "title": "Learning to Predict Task Transferability via Soft Prompt",
        "track": "main",
        "status": "Long Main",
        "keywords": "transfer learning;prompt tuning",
        "authors": "",
        "rating": "",
        "confidence": "5;3;5",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "SihQ9bBLWa",
        "title": "Annotations Are Not All You Need: A Cross-modal Knowledge Transfer Network for Unsupervised Temporal Sentence Grounding",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Cross-modal Knowledge Transfer;Unsupervised Temporal Sentence Grounding",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "1;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "SkWgL49qwI",
        "title": "A Language Model with Limited Memory Capacity Captures Interference in Human Sentence Processing",
        "track": "main",
        "status": "Long Findings",
        "keywords": "cue-based retrieval;working memory;interference;attention;agreement attraction;neural networks;cognitive modeling;surprisal;attention",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;3;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "SlL3dr0Xa9",
        "title": "Show, Write, and Retrieve: Entity-aware Article Generation and Retrieval",
        "track": "main",
        "status": "Long Findings",
        "keywords": "article generation;article retrieval;named entity recognition",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Sm3RzRKCel",
        "title": "Dialogizer: Context-aware Conversational-QA Dataset Generation from Textual Sources",
        "track": "main",
        "status": "Long Main",
        "keywords": "Dialog System;Conversational Question Answering;Dataset Generation",
        "authors": "",
        "rating": "",
        "confidence": "3;1;4;3",
        "correctness": "2;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "SnFmGmKTn1",
        "title": "KICGPT: Large Language Model with Knowledge in Context for Knowledge Graph Completion",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Knowledge Graph Completion;Large Language Model",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3;4",
        "correctness": "4;3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "SoypWgmvqP",
        "title": "Detecting Propaganda Techniques in Code-Switched Social Media Text",
        "track": "main",
        "status": "Long Main",
        "keywords": "propaganda detection;code-switching;low-resource languages;multilinguality;roman-urdu;natural language processing",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4;3;4;5",
        "correctness": "2;2;3;4;2;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Srxf1V2jPa",
        "title": "RobustGEC: Robust Grammatical Error Correction Against Subtle Context Perturbation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Grammatical Error Correction;Robustness",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "SvmlxXMLYr",
        "title": "COUNT: COntrastive UNlikelihood Text Style Transfer for Text Detoxification",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Text Style Transfer;Detoxification;Unlikelihood Training",
        "authors": "",
        "rating": "",
        "confidence": "4;5;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "SwphsE7hYO",
        "title": "Retrieval-based Knowledge Transfer: An Effective Approach for Extreme Large Language Model Compression",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Model Compression;LLM",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "SxrA1okPXY",
        "title": "Event-Location Tracking in Narratives: A Case Study on Holocaust Testimonies",
        "track": "main",
        "status": "Long Main",
        "keywords": "Location tracking;Narrative understanding;Holocaust testimonies",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "SyEwsV52Dk",
        "title": "Evaluation Metrics in the Era of GPT-4: Reliably Evaluating Large Language Models on Sequence to Sequence Tasks",
        "track": "main",
        "status": "Short Main",
        "keywords": "evaluation;human evaluation;LLM;summarization;simplification;grammatical error correction;ChatGPT;GPT-4;Sequence to sequence",
        "authors": "",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "SzH7d4617q",
        "title": "The Intended Uses of Automated Fact-Checking Artefacts: Why, How and Who",
        "track": "main",
        "status": "Long Findings",
        "keywords": "fact-checking;automated fact-checking;content analysis;intended use;natural language processing;artefacts",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;1",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "T3kZcQ2ivs",
        "title": "Are Embedded Potatoes Still Vegetables? On the Limitations of WordNet Embeddings for Lexical Semantics",
        "track": "main",
        "status": "Long Main",
        "keywords": "Knowledge Base Embedding;Lexical Semantics;WordNet;Link Prediction",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "T3n9nbeIKc",
        "title": "Dataset Bias Mitigation in Multiple-Choice Visual Question Answering and Beyond",
        "track": "main",
        "status": "Long Findings",
        "keywords": "vision language;vcr;vqa;snli-ve;visual question answering;commonsense reasoning;pretraining;multimodal;robust;low-shot;zero-shot;domain-shift;debiased;shortcut",
        "authors": "",
        "rating": "",
        "confidence": "4;2;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "T6GJ2Y0dn7",
        "title": "Intersectional Stereotypes in Large Language Models: Dataset and Analysis",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Stereotype Examination;Intersectional Stereotype;Dataset",
        "authors": "",
        "rating": "",
        "confidence": "5;3;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "T8ABT8q3FS",
        "title": "SegAugment: Maximizing the Utility of Speech Translation Data with Segmentation-based Augmentations",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Speech Translation;Data Augmentation",
        "authors": "",
        "rating": "",
        "confidence": "4;2;4;4",
        "correctness": "3;4;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "T9jJsFUGtI",
        "title": "Citance-Contextualized Summarization of Scientific Papers",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Summarization;Scholarly Document Processing;Scientific Papers;Large Language Models",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "T9wuVnNa5v",
        "title": "SIR-ABSC: Incorporating Syntax into RoBERTa-based Sentiment Analysis Models with a Special Aggregator Token",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Aspect-based sentiment analysis;Pre-trained Language Models;RoBERTa",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "2;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "THr9aJ3z9k",
        "title": "Quick Back-Translation for Unsupervised Machine Translation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "unsupervised machine translation;back-translation;non-autoregressive generation;Transformer",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "TKGgLVYRqJ",
        "title": "Seeing through the mess: evolutionary dynamics of lexical polysemy",
        "track": "main",
        "status": "Long Main",
        "keywords": "polysemy;language change;mathematical modeling;adaptive dynamics;senses;frequency;non-conformism;discriminability",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "5;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "TKo2JXw7vL",
        "title": "Large Language Models Meet Harry Potter: A Dataset for Aligning Dialogue Agents with Characters",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Personalized dialogue systems;dataset",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "TKzERU0kq1",
        "title": "Guiding LLM to Fool Itself: Automatically Manipulating Machine Reading Comprehension Shortcut Triggers",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Shortcuts;Large language models;Question answering",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "TSdWY9GaHA",
        "title": "CHiLL: Zero-shot Custom Interpretable Feature Extraction from Clinical Notes with Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Interpretability;Large Language Models;Healthcare;Electronic Health Records;Feature Extraction;Zero-shot",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "TW2cBze4ZB",
        "title": "Contrastive Deterministic Autoencoders For Language Modeling",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Autoencoders;Contrastive;Transformers",
        "authors": "",
        "rating": "",
        "confidence": "3;3;2",
        "correctness": "2;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "TW831RjYQO",
        "title": "MedEval: A Multi-Level, Multi-Task, and Multi-Domain Medical Benchmark for Language Model Evaluation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Curated Datasets;NLP for Healthcare;Pre-trained Language Models",
        "authors": "",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "TZW4nzgtQ8",
        "title": "Locally Differentially Private Document Generation Using Zero Shot Prompting",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Language Models;Local Differential Privacy;Deanonymization Attacks;Zero Shot Prompting",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4;4;4",
        "correctness": "4;4;3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.2,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Td9LjgO91J",
        "title": "Unleashing the Power of Language Models in Text-Attributed Graph",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Hierarchical Text-attributed Graph;Pre-training;Self-supervised Tasks",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "TdrI4F7wS8",
        "title": "Regulation and NLP (RegNLP): Taming Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "LLM;regulation;ethics;safety;public policy;science influencers",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "TemPqRDMJ8",
        "title": "SOUL: Towards Sentiment and Opinion Understanding of Language",
        "track": "main",
        "status": "Short Main",
        "keywords": "sentiment analysis;sentiment classification;sentiment and opinion understanding",
        "authors": "",
        "rating": "",
        "confidence": "5;5;3;4",
        "correctness": "3;3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Tha4jW8er9",
        "title": "Machine Reading Comprehension using Case-based Reasoning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "question answering;case-based reasoning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "TioAqBt8lz",
        "title": "Structure-aware Knowledge Graph-to-text Generation with Planning Selection and Similarity Distinction",
        "track": "main",
        "status": "Long Main",
        "keywords": "KG-to-text generation;Pre-trained language model;Planning Selection;Similarity Distinction",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Tk4tvmdKVP",
        "title": "Not all quantifiers are equal: Probing Transformer-based language models' understanding of generalised quantifiers",
        "track": "main",
        "status": "Long Main",
        "keywords": "Natural Language Inference;Transformer-based language models",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;5;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "TkJkSkmhUy",
        "title": "Injecting structural hints: Using language models to study inductive biases in language learning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "transfer learning;pretraining;recursion;context-sensitivity",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Tn5hALAaA4",
        "title": "Crosslingual Transfer Learning for Low-Resource Languages Based on Multilingual Colexification Graphs",
        "track": "main",
        "status": "Long Findings",
        "keywords": "multilingual;colexification;transfer learning",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3;4",
        "correctness": "4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "TnpFFjHCcw",
        "title": "Conversational Semantic Parsing using Dynamic Context Graphs",
        "track": "main",
        "status": "Long Main",
        "keywords": "semantic parsing;SPARQL;Knowledge Graphs;Conversational Semantic Parsing",
        "authors": "",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Tnx0922coo",
        "title": "Disentangling Transformer Language Models as Superposed Topic Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Topic Modelling;Mechanistic Interpretability;Pre-trained Language Models;Transformers",
        "authors": "",
        "rating": "",
        "confidence": "2;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ToGkF2nCNG",
        "title": "Measure Children's Mindreading Ability with Machine Reading",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Natural Language Processing;Machine Reading Comprehension;Multimodal;Psychology;Mind-reading",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ToMdTqVIb5",
        "title": "Monte Carlo Thought Search: Large Language Model Querying for Complex Scientific Reasoning in Catalyst Design",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Chain-of-Thought;Large Language Model;Reasoning;Scientific Discovery;Chemistry;Catalysis",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "5;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Tpd5RuSzpq",
        "title": "PUNR: Pre-training with User Behavior Modeling for News Recommendation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "News Recommendation;Pre-training;User Behavior Modeling",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "TqIDmoIzLT",
        "title": "CleanCoNLL: A Nearly Noise-Free Named Entity Recognition Dataset",
        "track": "main",
        "status": "Long Main",
        "keywords": "Dataset Relabeling and Evaluation;Label Error Detection and Correction;Named Entity Recognition;CoNLL-03;Entity Linking",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "TtQfZwf5s5",
        "title": "MT2: Towards a Multi-Task Machine Translation Model with Translation-Specific In-Context Learning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Machine Translation;In-Context Learning",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4;4",
        "correctness": "4;3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "TubO0kgAeL",
        "title": "This is not a Dataset: A Large Negation Benchmark to Challenge Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "negation;dataset;LLM;commonsense;evaluation;foundation models;WordNet;real-word knowledge;Large Language models",
        "authors": "",
        "rating": "",
        "confidence": "5;3;5",
        "correctness": "5;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "TvTwz12BZN",
        "title": "Segmented Recurrent Transformer: An Efficient Sequence-to-Sequence Model",
        "track": "main",
        "status": "Long Findings",
        "keywords": "abstractive summarization;transformers;language models",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "TxEV8D0z0r",
        "title": "trlX: A Framework for Large Scale Reinforcement Learning from Human Feedback",
        "track": "main",
        "status": "Long Main",
        "keywords": "RLHF;LLM;Framework",
        "authors": "",
        "rating": "",
        "confidence": "3;2;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "U1rj4p5aKa",
        "title": "Automatic Pronunciation Assessment - A Review",
        "track": "main",
        "status": "Long Findings",
        "keywords": "computer aided pronunciation training (CAPT);pronunciation assessment;second language learning;pronunciation error detection",
        "authors": "",
        "rating": "",
        "confidence": "4;2;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "U6SEUS76IE",
        "title": "FedID: Federated Interactive Distillation for Large-Scale Pretraining Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "decentralized learning;federated learning;federated distillation;pre-trained language model",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "5;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "U78nBY8hRi",
        "title": "DALE: Generative Data Augmentation for Low-Resource Legal NLP",
        "track": "main",
        "status": "Long Main",
        "keywords": "legal;low-resource;augmentation;generation;efficient",
        "authors": "",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "U7mWHBoTfb",
        "title": "Improving Language Models\u2019 Meaning Understanding and Consistency by Learning Conceptual Roles from Dictionary",
        "track": "main",
        "status": "Long Main",
        "keywords": "Language Model;Consistency;Conceptual Role Theory",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "U8PL5FzvrV",
        "title": "Improving Dialogue Discourse Parsing via Reply-to Structures of Addressee Recognition",
        "track": "main",
        "status": "Long Main",
        "keywords": "Dialogue Discourse Parsing;Reinforcement Learning;Task-aware Structure Transformer",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "UECSdvL8U7",
        "title": "Evaluating Bias and Fairness in Gender-Neutral Pretrained Vision-and-Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "bias;fairness;multimodal",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3;4",
        "correctness": "4;3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "UEx5dZqXvr",
        "title": "Scaling Law for Document Neural Machine Translation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Document Machine Translation;NMT;Scaling",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "UEzKGW4U39",
        "title": "Isotropy-Enhanced Conditional Masked Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Non-autoregressive;Anisotropic Problem;Neural Machine Translation;Natural Language Processing",
        "authors": "",
        "rating": "",
        "confidence": "5;4;5;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "UGd9eSwsvn",
        "title": "Zero-Shot Data Maps. Efficient Dataset Cartography Without Model Training",
        "track": "main",
        "status": "Long Findings",
        "keywords": "data maps;bi-encoders;zero-shot;training dynamics",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3;3",
        "correctness": "5;2;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "UIIi9hBNW8",
        "title": "\"You Are An Expert Linguistic Annotator\": Limits of LLMs as Analyzers of Abstract Meaning Representation",
        "track": "main",
        "status": "Short Findings",
        "keywords": "semantic structure;AMR;linguistic annotation;LLMs;few-shot;zero-shot",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "UMywlqrW3n",
        "title": "Getting MoRE out of Mixture of Language Model Reasoning Experts",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large Language Models;Reasoning;Prompting;Generalization;Calibration;Interpretability",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "UNFR2Y6Xx0",
        "title": "IDTraffickers: An Authorship Attribution Dataset to link and connect Potential Human-Trafficking Operations on Text Escort Advertisements",
        "track": "main",
        "status": "Long Main",
        "keywords": "Human Trafficking;Authorship Attribution;Natural Language Processing;Dataset;Benchmarks",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "UNvLur0th4",
        "title": "Finding Common Ground: Annotating and Predicting Common Ground in Spoken Conversations",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Common Ground;Belief Extraction;Corpus Construction;Cognitive state;T5 Language Model",
        "authors": "",
        "rating": "",
        "confidence": "2;4;3;4",
        "correctness": "4;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "UQpbq4v8Xi",
        "title": "Generating Data for Symbolic Language with Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Model;Data Generation;Symbolic Language;Code Generation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "UTMwcLMhso",
        "title": "Increasing Probability Mass on Answer Choices Does Not Always Improve Accuracy",
        "track": "main",
        "status": "Long Main",
        "keywords": "analysis of language models; probability; surface form competition; multiple-choice tasks; text generation; few-shot prompting",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3;2",
        "correctness": "4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "UVoA0rALMC",
        "title": "Few-shot Unified Question Answering: Tuning Models or Prompts?",
        "track": "main",
        "status": "Long Findings",
        "keywords": "unified question answering;QA;universal QA;paramter efficient QA;model tuning . prompt tuning",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;5;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "UXSqUOMwbE",
        "title": "QA-NatVer: Question Answering for Natural Logic-based Fact Verification",
        "track": "main",
        "status": "Long Main",
        "keywords": "fact-checking;fact extraction and verification;claim verification;natural logic;natural language inference;faithfulness",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "UaZe4SwQF2",
        "title": "Gender Biases in Automatic Evaluation Metrics for Image Captioning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Automatic Evaluation Metrics;Fairness",
        "authors": "",
        "rating": "",
        "confidence": "3;2;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Ud2UQ9ZCep",
        "title": "Open Domain Multi-document Summarization: A Comprehensive Study of Model Brittleness under Retrieval",
        "track": "main",
        "status": "Long Findings",
        "keywords": "summarization;multi-document summarization;retrieval;open-domain",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Ue9i6qgiCw",
        "title": "DecipherPref: Analyzing Influential Factors in Human Preference Judgments via GPT-4",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Models;Summarization Evaluation;Human Preference Judgments;GPT-4",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "UhuizFH1Hx",
        "title": "GSAP-NER: A Novel Task, Corpus, and Baseline for Scholarly Entity Extraction Focused on Machine Learning Models and Datasets",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Information Extraction (IE);ML models;datasets;Named Entity Recognition (NER)",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4;4",
        "correctness": "3;4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "UixzK8evk5",
        "title": "DistillCSE: Distilled Contrastive Learning for Sentence Embeddings",
        "track": "main",
        "status": "Long Findings",
        "keywords": "sentence embedding;self-training;contrastive learning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "UjOPUHPoTM",
        "title": "Blackbird language matrices (BLM), a new task for rule-like generalization in neural networks: Can Large Language Models pass the test?",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Rule-based learning;generalisation;intrinsic evaluation;cognitive modelling;benchmarking",
        "authors": "",
        "rating": "",
        "confidence": "4;2;4",
        "correctness": "2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "UlewKJFkUV",
        "title": "Memorisation Cartography: Mapping out the Memorisation-Generalisation Continuum in Neural Machine Translation",
        "track": "main",
        "status": "Long Main",
        "keywords": "interpretability;neural machine translation;memorization",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3;3",
        "correctness": "4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "UlgNWOzMz2",
        "title": "Isotropic Representation Can Improve Zero-Shot Cross-Lingual Transfer on Multilingual Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "isotropic representation;cross-lingual;multilingual",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "UmKaHvjkiu",
        "title": "PreWoMe: Exploiting Presuppositions as Working Memory for Long Form Question Answering",
        "track": "main",
        "status": "Short Main",
        "keywords": "Long-Form QA;Large Language Models;Presuppositions",
        "authors": "",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Upk6WrdJYM",
        "title": "Efficient k-NN Search with Cross-Encoders using Adaptive Multi-Round CUR Decomposition",
        "track": "main",
        "status": "Short Findings",
        "keywords": "cross-encoder;nearest neighbor search;k-NN;retrieval",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Uuqv7iSNif",
        "title": "New Datasets and Controllable Iterative Data Augmentation Method for Code-switching ASR Error Correction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "ASR Error Correction;Code Switching;Data Augmentation",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "UxdVVhWVq2",
        "title": "Knowledge-Selective Pretraining for Attribute Value Extraction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "attribute value extraction;pretraining",
        "authors": "",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "UyLaqZ6PHA",
        "title": "How Do Large Language Models Capture the Ever-changing World Knowledge? A Review of Recent Advances",
        "track": "main",
        "status": "Long Main",
        "keywords": "large language models;survey;knowledge",
        "authors": "",
        "rating": "",
        "confidence": "4;4;1",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "V3O0NNaPNW",
        "title": "Speaking Style Conversion in the Waveform Domain Using Discrete Self-Supervised Units",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Voice Conversion;Audio Processing;Self-Supervised Learning",
        "authors": "",
        "rating": "",
        "confidence": "3;4;5",
        "correctness": "4;4;1",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "V49Jx2Lj04",
        "title": "IfQA: A Dataset for Open-domain Question Answering under Counterfactual Presuppositions",
        "track": "main",
        "status": "Long Main",
        "keywords": "open-domain question answering;counterfactual reasoning",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "V76kMIJI37",
        "title": "Retrieval-Generation Alignment for End-to-End Task-Oriented Dialogue System",
        "track": "main",
        "status": "Long Main",
        "keywords": "Knowledge Retrieval;End-to-End Task-Oriented Dialogue System",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3;4",
        "correctness": "4;4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "V9xsOja2oC",
        "title": "Homophone Disambiguation Reveals Patterns of Context Mixing in Speech Transformers",
        "track": "main",
        "status": "Long Main",
        "keywords": "speech transformers;context mixing;model interpretability for spoken language",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4;4",
        "correctness": "3;5;5;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 4.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "VC2vPPetCU",
        "title": "Open-ended Commonsense Reasoning with Unrestricted Answer Candidates",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Commonsense Reasoning;Question Answering",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "VCyOXC8RfQ",
        "title": "Measuring bias in Instruction-Following models with P-AT",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large Language Models;Instruction-Following;Bias",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "VGb2RhMFAI",
        "title": "Air-Decoding: Attribute Distribution Reconstruction for Decoding-Time Controllable Text Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "controllable;text generation;decoding-time",
        "authors": "",
        "rating": "",
        "confidence": "4;5;4;3",
        "correctness": "4;4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "VIDDZO2f0A",
        "title": "Editing Common Sense in Transformers",
        "track": "main",
        "status": "Long Main",
        "keywords": "Commonsense;Transformers;Language Models;Model Editing;GPT;Plausibility Judgements",
        "authors": "",
        "rating": "",
        "confidence": "2;4;5",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "VJenYElbmY",
        "title": "Addressing Linguistic Bias through a Contrastive Analysis of Academic Writing in the NLP Domain",
        "track": "main",
        "status": "Long Main",
        "keywords": "contrastive analysis;linguistic bias;lexis;morphology;syntax;cohesion",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "2;5;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "VKHWtusV6H",
        "title": "DSI++: Updating Transformer Memory with New Documents",
        "track": "main",
        "status": "Long Main",
        "keywords": "Differentiable Search Index;Transformer Memory;Catastrophic Forgetting;Continual Learning;Lifelong Learning;Semi-Supervised Learning",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "VLrtaSXOWP",
        "title": "Continual Named Entity Recognition without Catastrophic Forgetting",
        "track": "main",
        "status": "Long Main",
        "keywords": "Continual Named Entity Recognition without Catastrophic Forgetting",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "VN298kRz91",
        "title": "Romanization-based Large-scale Adaptation of Multilingual Language Models",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Multilinguality;Parameter Efficiency;Transliteration",
        "authors": "",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "VQQeyiAqtv",
        "title": "Data Selection Curriculum for Abstractive Text Summarization",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Data Selection;Curriculum Learning;Abstractive Text Summarization",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4;5",
        "correctness": "3;3;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "VSBBOEUcmD",
        "title": "LLM-enhanced Self-training for Cross-domain Constituency Parsing",
        "track": "main",
        "status": "Long Main",
        "keywords": "constituency parsing",
        "authors": "",
        "rating": "",
        "confidence": "4;2;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "VTWWvYtF1R",
        "title": "Reasoning with Language Model is Planning with World Model",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Model;Reasoning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "VWFKRxsgt3",
        "title": "ZeroSCROLLS: A Zero-Shot Benchmark for Long Text Understanding",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Long lexts;summarization;question answering;benchmark;zero-shot",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "VacjehPkIU",
        "title": "Superlim: A Swedish Language Understanding Evaluation Benchmark",
        "track": "main",
        "status": "Long Main",
        "keywords": "Swedish;benchmark;large language models;natural language understanding;transfer learning;evaluation",
        "authors": "",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "5;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 4.666666666666667,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "VdvdRfwTtk",
        "title": "Background Summarization of Event Timelines",
        "track": "main",
        "status": "Long Main",
        "keywords": "text summarization;events;timelines;dataset;evaluation metrics",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "VeBoHwiA7g",
        "title": "SmartSpanNER: Making SpanNER Robust in Low Resource Scenarios",
        "track": "main",
        "status": "Long Findings",
        "keywords": "SpanNER;Named Entity Head;SmartSpanNER;Multi-task Learning",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "VecgMidd4I",
        "title": "Find-2-Find: Multitask Learning for Anaphora Resolution and Object Localization",
        "track": "main",
        "status": "Long Main",
        "keywords": "Anaphora Resolution;Object Localization",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "VgLBPLvHuK",
        "title": "Revisiting Source Context in Nearest Neighbor Machine Translation",
        "track": "main",
        "status": "Long Main",
        "keywords": "nearest neighbor machine translation; source context; retrieval-augmented machine translation",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "VhL4lZXY1U",
        "title": "Beyond Candidates : Adaptive Dialogue Agent Utilizing Persona and Knowledge",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Dialogue System;Adaptive;Candidate-agnostic;Persona;Knowledge",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "VjSxQNhdKs",
        "title": "MCLF: A Multi-grained Contrastive Learning Framework for ASR-robust Spoken Language Understanding",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Spoken Language Understanding;ASR Robustness;Multi-grained Contrastive Learning;Data Augmentation",
        "authors": "",
        "rating": "",
        "confidence": "5;3;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "VmoWVc04KY",
        "title": "Linguistic Compression in Single-Sentence Human-Written Summaries",
        "track": "main",
        "status": "Long Findings",
        "keywords": "summary writing;linguistic compression;text summarization",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "VnMfQuDSgG",
        "title": "Analysis of Style-Shifting on Social Media: Using Neural Language Model Conditioned by Social Meanings",
        "track": "main",
        "status": "Long Findings",
        "keywords": "style-shifting;speech accommodation theory;neural language model",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Vp8WwRMWfv",
        "title": "Recurrent Neural Language Models as Probabilistic Finite-state Automata",
        "track": "main",
        "status": "Long Main",
        "keywords": "Language Models;Formal Language Theory;Recurrent Neural Networks;Finite-state Automata;Minsky",
        "authors": "",
        "rating": "",
        "confidence": "3;2;4",
        "correctness": "5;5;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 5.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "VqGX02f2lS",
        "title": "On the Transferability of Visually Grounded PCFGs",
        "track": "main",
        "status": "Long Findings",
        "keywords": "unsupervised grammar induction;grounded language learning;syntactic parsing;transfer learning",
        "authors": "",
        "rating": "",
        "confidence": "3;3;2",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "VyIe1iVHZ4",
        "title": "TR-Rules: Rule-based Model for Link Forecasting on Temporal Knowledge Graph Considering Temporal Redundancy",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Knowledge Graph;Temporal Knowledge Graph;Link forecasting;Temporal Rules",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "VyjNXY2wgi",
        "title": "DialCoT Meets PPO: Decomposing and Exploring Reasoning Paths in Smaller Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Chain-of-Thought;PPO;Reasoning",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "W0WeKrnfbX",
        "title": "A Self-enhancement Multitask Framework for Unsupervised Aspect Category Detection",
        "track": "main",
        "status": "Long Main",
        "keywords": "Sentiment Analysis;Aspect Category Detection;unsupervised learning;weakly supervised learning;Aspect-based Sentiment Analysis",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "W1w2eovejY",
        "title": "Uncertainty-aware Parameter-Efficient Self-training for Semi-supervised Language Understanding",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Self-Training;Uncertainty Estimation;Pre-trained Language Models;Parameter-Efficient Learning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "2;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "W2ka7qsx1j",
        "title": "A Diffusion Weighted Graph Framework for New Intent Discovery",
        "track": "main",
        "status": "Long Main",
        "keywords": "New Intent Discovery;Contrastive Learning;Graph Structure Learning",
        "authors": "",
        "rating": "",
        "confidence": "4;3;2;3",
        "correctness": "2;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "W4GlqAnXqv",
        "title": "Frequency Balanced Datasets Lead to Better Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Language Models;word frequency;pre-training corpus;low-resource languages",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4;2",
        "correctness": "3;3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "W4Vk1ufh7l",
        "title": "TRIP: Accelerating Document-level Multilingual Pre-training via Triangular Document-level Pre-training on Parallel Data Triplets",
        "track": "main",
        "status": "Long Findings",
        "keywords": "multilingual pre-training; machine translation; cross-lingual summarization",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "W6ijeWfHFU",
        "title": "Improving Factual Consistency for Knowledge-Grounded Dialogue Systems via Knowledge Enhancement and Alignment",
        "track": "main",
        "status": "Long Findings",
        "keywords": "knowledge-grounded dialogue system;factual consistency;knowledge enhancement",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3;3",
        "correctness": "3;4;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "W76aMA1x9l",
        "title": "Detecting Erroneously Recognized Handwritten Byzantine Text",
        "track": "main",
        "status": "Long Findings",
        "keywords": "text classification;error detection;handwritten text recognition",
        "authors": "",
        "rating": "",
        "confidence": "5;4;2",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "WAhhZcaA3R",
        "title": "Enhancing Biomedical Lay Summarisation with External Knowledge Graphs",
        "track": "main",
        "status": "Long Main",
        "keywords": "Summarisation;Knowledge Graphs",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "WC1jbtEwRS",
        "title": "Flatness-Aware Prompt Selection Improves Accuracy and Sample Efficiency",
        "track": "main",
        "status": "Long Findings",
        "keywords": "prompt selection;flatness of prompt",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "WC9yjSosSA",
        "title": "ESPVR: Entity Spans Position Visual Regions for Multimodal Named Entity Recognition",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multimodal named entity recognition;Local visual information;Global visual information",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3;2",
        "correctness": "2;2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "WCxfj3PsWb",
        "title": "Multi-level Adaptive Contrastive Learning for Knowledge Internalization in Dialogue Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "knowledge-grounded dialogue generation;contrastive learning;text degeneration;pre-trained language model",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "WEHwc4hSQR",
        "title": "GD-COMET: A Geo-Diverse Commonsense Inference Model",
        "track": "main",
        "status": "Short Main",
        "keywords": "commonsense reasoning;culture-aware NLP;geo-diverse applications",
        "authors": "",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "WLIFsPSq3t",
        "title": "Beyond Layout Embedding: Layout Attention with Gaussian Biases for Structured Document Understanding",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Structured Document Understanding;Layout Attention;Spatial Relationships;Polar Coordinates",
        "authors": "",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "WLV8cm80DB",
        "title": "$\\textit{Swap and Predict}$ -- Predicting the Semantic Changes in Words across Corpora by Context Swapping",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Computational Semantics;Contextualised Word Embeddings;Semantic Change Detection",
        "authors": "",
        "rating": "",
        "confidence": "3;3;5;4",
        "correctness": "3;4;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "WLZX3et7VT",
        "title": "Active Retrieval Augmented Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Retrieval Augmented Language Model;Long-form Generation;Active Retrieval",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "WQR3xpEJRJ",
        "title": "CTQScorer: Combining Multiple Features for In-context Example Selection for Machine Translation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "few-shot prompting;machine translation;example selection",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "WQamRhhbsf",
        "title": "Impact of Co-occurrence on Factual Knowledge of Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Factual Knowledge;Large Language Models;Co-occurrence;Term Frequency;Data Statistics",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "WRYhaSrThy",
        "title": "Automatic Prompt Optimization with \"Gradient Descent\" and Beam Search",
        "track": "main",
        "status": "Long Main",
        "keywords": "LLM;Prompt;Prompt Optimization;Prompt Engineering;Optimization;Gradient Descent",
        "authors": "",
        "rating": "",
        "confidence": "2;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "WVs1qhIUms",
        "title": "Empirical Study of Zero-Shot NER with ChatGPT",
        "track": "main",
        "status": "Long Main",
        "keywords": "ChatGPT;Named Entity Recognition;Zero-Shot;Reasoning;Large Language Models",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Weszm4zCzP",
        "title": "M$^3$Seg: A Maximum-Minimum Mutual Information Paradigm for Unsupervised Topic Segmentation in ASR Transcripts",
        "track": "main",
        "status": "Short Main",
        "keywords": "Unsupervised topic segmentation;mutual information maximization/minimization;automatic-speech-recognition (ASR) transcripts structuring",
        "authors": "",
        "rating": "",
        "confidence": "3;1;3;5",
        "correctness": "4;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "WiKLXsWzBy",
        "title": "Don\u2019t Trust ChatGPT when your Question is not in English: A Study of Multilingual Abilities and Types of LLMs",
        "track": "main",
        "status": "Long Main",
        "keywords": "multilingual;LLM;GPT",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "WkpTWlXGHC",
        "title": "Scalable-DSC: A Structural Template Prompt Approach to Scalable Dialogue State Correction",
        "track": "main",
        "status": "Long Main",
        "keywords": "Dialogue state tracking;Error propagation;Dialogue state correction",
        "authors": "",
        "rating": "",
        "confidence": "4;5;5",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "WmpyDkTHvI",
        "title": "Text2Tree: Aligning Text Representation to the Label Tree Hierarchy for Imbalanced Medical Classification",
        "track": "main",
        "status": "Long Findings",
        "keywords": "text mining;medical text representation;imbalanced text classification",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "2;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Wom397PB55",
        "title": "TheoremQA: A Theorem-driven Question Answering Dataset",
        "track": "main",
        "status": "Long Main",
        "keywords": "Language Model;Question Answering;Math;Theorem",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "WuuxbObghx",
        "title": "Federated Learning of Large Language Models with Parameter-Efficient Prompt Tuning and Adaptive Optimization",
        "track": "main",
        "status": "Long Main",
        "keywords": "Federated learning;Large Language Models;Prompt tuning;Prefix tuning",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3;3",
        "correctness": "4;3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "WxxYSpsv97",
        "title": "Generating Extractive Answers: Gated Recurrent Memory Reader for Conversational Question Answering",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Conversational Question Answering;Machine Reading Comprehension;Attention",
        "authors": "",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "2;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Wy4adj2FUJ",
        "title": "A Sequence-to-Structure Approach to Document-level Targeted Sentiment Analysis",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Aspect-based Sentiment Analysis;Document-level;Targeted Sentiment Analysis",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3;4;4",
        "correctness": "3;4;3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.8,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Wyod73NboS",
        "title": "Are Language Models Worse than Humans at Following Prompts? It's Complicated",
        "track": "main",
        "status": "Short Findings",
        "keywords": "instruction following;prompting;human study;natural language inference",
        "authors": "",
        "rating": "",
        "confidence": "4;2;2;2",
        "correctness": "4;4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Wz1jEwvpGO",
        "title": "Logic Unveils Truth, While Disguise Obscures It: Transition Logic Augmented Response Selection for Multi-Turn Dialogue",
        "track": "main",
        "status": "Long Findings",
        "keywords": "multi-turn dialogue;dialogue retrieval",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "X2R4yhtenj",
        "title": "Effects of Human Adversarial and Affable Samples on BERT Generalization",
        "track": "main",
        "status": "Long Findings",
        "keywords": "BERT;Generalization;Robustness in NLP",
        "authors": "",
        "rating": "",
        "confidence": "3;2;4",
        "correctness": "2;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "X570XzeYSW",
        "title": "Task-Agnostic Low-Rank Adapters for Unseen English Dialects",
        "track": "main",
        "status": "Long Main",
        "keywords": "Low-resource;Dialects;Hypernetworks;LoRA;Cross-dialectal Alignment",
        "authors": "",
        "rating": "",
        "confidence": "5;3;4;2",
        "correctness": "4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "X597Q58y1U",
        "title": "Enhancing Code-Switching for Cross-lingual SLU: A Unified View of Semantic and Grammatical Coherence",
        "track": "main",
        "status": "Short Main",
        "keywords": "Cross-lingual SLU;Semantic Coherence;Grammatical Coherence",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4;4",
        "correctness": "4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "X6DrwxlMD9",
        "title": "Evaluating Dependencies in Fact Editing for Language Models: Specificity and Implication Awareness",
        "track": "main",
        "status": "Long Findings",
        "keywords": "knowledge editing;large language models;knowledge base",
        "authors": "",
        "rating": "",
        "confidence": "3;4;2",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "X6HDI4cqWF",
        "title": "End-to-End Autoregressive Retrieval via Bootstrapping for Smart Reply Systems",
        "track": "main",
        "status": "Long Findings",
        "keywords": "dialog;smart reply;reply suggestion",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "XB0u7RTXrV",
        "title": "SCENE: Self-Labeled Counterfactuals for Extrapolating to Negative Examples",
        "track": "main",
        "status": "Long Main",
        "keywords": "Question Answering;Counterfactual Generation;Data Augmentation",
        "authors": "",
        "rating": "",
        "confidence": "3;5;4",
        "correctness": "4;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "XEBHsJpFY9",
        "title": "Culturally Aware Natural Language Inference",
        "track": "main",
        "status": "Long Findings",
        "keywords": "cultural norms;natural language inference",
        "authors": "",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "3;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "XEwQ1fDbDN",
        "title": "Examining Inter-Consistency of Large Language Models Collaboration: An In-depth Analysis via Debate",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large Language Models;Inconsistency;Debate;Commonsense Reasoning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "XHftyT3k4j",
        "title": "Enhancing Argument Structure Extraction with Efficient Leverage of Contextual Information",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Argument Mining;Argument structure extraction;Discourse Structure of Arguments",
        "authors": "",
        "rating": "",
        "confidence": "5;3;3",
        "correctness": "2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "XIHl40UylS",
        "title": "STEER: Unified Style Transfer with Expert Reinforcement",
        "track": "main",
        "status": "Long Findings",
        "keywords": "style transfer;natural language generation;reinforcement learning;controllable decoding",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "XILoK6g4va",
        "title": "Hierarchical Fusion for Online Multimodal Dialog Act Classification",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Dialog Act Classification;Multimodality;Early Fusion;Online Inference",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "XJRNw74kXK",
        "title": "POSQA: Probe the World Models of LLMs with Size Comparisons",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Embodied language comprehension;World Model;Large Language Models;AI Alignment",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "XLXCWNNWvL",
        "title": "Training Simultaneous Speech Translation with Robust and Random Wait-k-Tokens Strategy",
        "track": "main",
        "status": "Long Main",
        "keywords": "Simultaneous Speech Translation;Robust and Random Wait-k;Cross-modal alignment",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "XMpzcC9L5z",
        "title": "How Predictable Are Large Language Model Capabilities? A Case Study on BIG-bench",
        "track": "main",
        "status": "Long Findings",
        "keywords": "large language models;performance prediction;benchmarking",
        "authors": "",
        "rating": "",
        "confidence": "3;5;3",
        "correctness": "3;5;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "XNnFTKCacy",
        "title": "Coherent Entity Disambiguation via Modeling Topic and Categorical Dependency",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Entity disambiguation;Knowledge base;Entity linking",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "XQm8tlPKgY",
        "title": "SCITAB: A Challenging Benchmark for Compositional Reasoning and Claim Verification on Scientific Tables",
        "track": "main",
        "status": "Long Main",
        "keywords": "Scientific Fact-Checking;Table Reasoning;Compositional Reasoning;Dataset",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "XT1hoHqs12",
        "title": "ReadPrompt: A Readable Prompting Method for Reliable Knowledge Probing",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Prompt;Pre-trained Language Model;Readability;Knowledge Probing;Fact Retrieval;LAMA Dataset.",
        "authors": "",
        "rating": "",
        "confidence": "1;3;4",
        "correctness": "4;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "XW4t7P2hpN",
        "title": "Shall We Pretrain Autoregressive Language Models with Retrieval? A Comprehensive Study",
        "track": "main",
        "status": "Long Main",
        "keywords": "large language model;pretraining;retrieval augmentation;retro;knowledge retrieval",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "XX73vFMemG",
        "title": "Co-training and Co-distillation for Quality Improvement and Compression of Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Knowledge Distillation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "XbcprEi57p",
        "title": "Referring Image Segmentation via Joint Mask Contextual Embedding Learning and Progressive Alignment Network",
        "track": "main",
        "status": "Long Main",
        "keywords": "segmentation;multi-modality",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "XcNXOVhNlN",
        "title": "Reasoning Makes Good Annotators : An Automatic Task-specific Rules Distilling Framework for Low-resource Relation Extraction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "relation extraction;language model;rule mining and pattern mining",
        "authors": "",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "4;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "XclSRY9Wp8",
        "title": "Modeling Conceptual Attribute Likeness and Domain Inconsistency for Metaphor Detection",
        "track": "main",
        "status": "Long Main",
        "keywords": "Metaphor detection;Attribute likeness;Attribute siamese network;Conceptual metaphor theory",
        "authors": "",
        "rating": "",
        "confidence": "4;2;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Xd2A31vcLd",
        "title": "ReSee: Responding through Seeing Fine-grained Visual Knowledge in Open-domain Dialogue",
        "track": "main",
        "status": "Long Main",
        "keywords": "visual dialogue;multimodal dataset;knowledge-enhanced dialogue;pre-trained language model",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "XhR6ebeEXo",
        "title": "Good Meta-tasks Make A Better Cross-lingual Meta-transfer Learning for Low-resource Languages",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Few-shot Cross-lingual Transfer Learning;Low-resource Languages;Model-agnostic Meta-learning",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "XjwNxSE0v8",
        "title": "Learning Easily Updated General Purpose Text Representations with Adaptable Task-Specific Prefix",
        "track": "main",
        "status": "Short Findings",
        "keywords": "text representations;prefix tuning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3;3",
        "correctness": "4;4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "XkexLrJDss",
        "title": "Exploring the Potential of Large Language Models in Generating Code-Tracing Questions for Introductory Programming Courses",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Large Language Model;Natural Language Processing;Computer Science Education;Novice Programming",
        "authors": "",
        "rating": "",
        "confidence": "5;5;3",
        "correctness": "4;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "XlIrJUKTgS",
        "title": "Improving Seq2Seq Grammatical Error Correction via Decoding Interventions",
        "track": "main",
        "status": "Long Findings",
        "keywords": "grammatical error correction;decoding;sequence-to-sequence;seq2seq",
        "authors": "",
        "rating": "",
        "confidence": "5;3;3;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "XmS9J3Lvip",
        "title": "Towards Formality-Aware Neural Machine Translation by Leveraging Context Information",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Neural Machine Translation;Context-Aware Translation;Formality-Aware Translation;Formality Control",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "XpK2LCt8iM",
        "title": "Turn-Level Active Learning for Dialogue State Tracking",
        "track": "main",
        "status": "Long Main",
        "keywords": "dialogue state tracking;active learning;data annotation",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Xqhdpk0Qrj",
        "title": "GLEN: Generative Retrieval via Lexical Index Learning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Generative retrieval;Document retrieval;Lexical index",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;5;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Xt1JbFofwP",
        "title": "TabPrompt: Graph-based Pre-training and Prompting for Few-shot Table Understanding",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Table Understanding;Prompt-based Learning;Graph Contrastive Learning;Graph Neural Network",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "XtlquCY7qs",
        "title": "MADNet: Maximizing Addressee Deduction Expectation for Multi-Party Conversation Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Dialogue System;Multi-Party Conversation;Addressee Deduction;Latent Edge;Expectation-Maximization",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4;4;3",
        "correctness": "4;4;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6,
        "correctness_avg": 3.8,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "XySNnzF9Ir",
        "title": "Automatic Evaluate Dialogue Appropriateness by Using Dialogue Act",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Automatic Dialogue System Evaluation; Dialogue Evaluation; Dialogue System",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4;4",
        "correctness": "3;2;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "XySq36VD0U",
        "title": "A Lightweight Method to Generate Unanswerable Questions in English",
        "track": "main",
        "status": "Short Findings",
        "keywords": "extractive question answering;machine reading comprehension;data augmentation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "3;4;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Xyb8Qh6vxU",
        "title": "A Comprehensive Evaluation of Large Language Models on Legal Judgment Prediction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Language Model;Law;Legal Judgment Prediction;Large Language Model;Language Model Evaluation",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Xyy1p1IGvn",
        "title": "Semantic matching for text classification with complex class descriptions",
        "track": "main",
        "status": "Long Main",
        "keywords": "natural language processing;few-shot learning;zero-shot learning;semantic matching",
        "authors": "",
        "rating": "",
        "confidence": "3;1;4",
        "correctness": "5;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Y0PN9Eic8T",
        "title": "Dynamic Stashing Quantization for Efficient Transformer Training",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Transformer;Training;Dynamic Stashing Quantization",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4;2",
        "correctness": "4;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Y13EvAJlhQ",
        "title": "Instructive Dialogue Summarization with Query Aggregations",
        "track": "main",
        "status": "Long Main",
        "keywords": "Dialogue Summarization;Query-based Dialogue Summarizaiton;Dialogue Reading Comprehension",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Y28GzovPql",
        "title": "RoBoCoP: A Comprehensive ROmance BOrrowing COgnate Package and Benchmark for Multilingual Cognate Identification",
        "track": "main",
        "status": "Long Main",
        "keywords": "cognates;borrowings;historical lingusitics;database;romance languages;language resources;lexicon",
        "authors": "",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Y2wUa9n7sr",
        "title": "VISTA: Visual-Textual Knowledge Graph Representation Learning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Knowledge Graph;Multimodality;Representation Learning;Knowledge Graph Completion;Transformer",
        "authors": "",
        "rating": "",
        "confidence": "3;4;5;3;3;2;3",
        "correctness": "3;2;5;3;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.2857142857142856,
        "correctness_avg": 3.142857142857143,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Y30NTg87od",
        "title": "Implicit Sense-labeled Connective Recognition as Text Generation",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Implicit Discourse Relation Recognition;Implicit Sense-labeled Connective Recognition;Encoder-Decoder;PDTB-3.0",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Y6w2prqvjM",
        "title": "On the Challenges of Using Black-Box APIs for Toxicity Evaluation in Research",
        "track": "main",
        "status": "Long Main",
        "keywords": "toxicity;black-box API;HELM;evaluation;Real Toxicity Prompts;benchmarking",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Y7Wx7usMtc",
        "title": "Natural Disaster Tweets Classification Using Multimodal Data",
        "track": "main",
        "status": "Long Main",
        "keywords": "Multimodal Data;Multi task learning;NLP of Social Media data;AI for social good",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Y7kK2HcxDK",
        "title": "GDA: Grammar-based Data Augmentation for Text Classification using Slot Information",
        "track": "main",
        "status": "Long Findings",
        "keywords": "data augmentation;rules of grammar;text classification",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "YGK9cd0bHz",
        "title": "WiCE: Real-World Entailment for Claims in Wikipedia",
        "track": "main",
        "status": "Long Main",
        "keywords": "natural language inference;textual entailment;fact-checking",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "YGUUT6CkbB",
        "title": "StrAE: Autoencoding for Pre-Trained Embeddings using Explicit Structure",
        "track": "main",
        "status": "Long Main",
        "keywords": "NLP;Representation Learning;Structure;Semantics;Syntax;Induction;Composition",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "YGYaxZVsJK",
        "title": "Pseudointelligence: A Unifying Lens on Language Model Evaluation",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Evaluation;Large Language Models;Learning Theory;Computational Complexity",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "YHWXlESeS8",
        "title": "Have LLMs Advanced Enough? A Challenging Problem Solving Benchmark For Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Reasoning;Large Language Model;Benchmark;Problem Solving",
        "authors": "",
        "rating": "",
        "confidence": "3;4;5",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "YJMUVwLcEi",
        "title": "Lexical Repetitions Lead to Rote Learning: Unveiling the Impact of Lexical Overlap in Train and Test Reference Summaries",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Lexical Diversity;Summarization;Data-Centric AI",
        "authors": "",
        "rating": "",
        "confidence": "3;2;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "YKKcbwztwH",
        "title": "Parameter-Efficient Cross-lingual Transfer of Vision and Language Models via Translation-based Alignment",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Cross-lingual Transfer;Vision and Language;Parameter Efficiency",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "YMlYb8cWgE",
        "title": "RECAL: Sample-Relation Guided Confidence Calibration over Tabular Data",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Confidence Calibration;Tabular Data;Element-Wise Temperature Scaling",
        "authors": "",
        "rating": "",
        "confidence": "3;2;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "YN6FtojPxD",
        "title": "Quantifying the Dialect Gap and its Correlates Across Languages",
        "track": "main",
        "status": "Long Findings",
        "keywords": "dialect gap;machine translation;automatic speech recognition;performance correlation;multilingual",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4;2",
        "correctness": "3;4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "YO2VZBcinK",
        "title": "Topic-DPR: Topic-based Prompts for Dense Passage Retrieval",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Continuous Prompt;Dense Passage Retrieval;Topic Modeling",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "YQzgk43sFB",
        "title": "Entity Disambiguation on a Tight Labeling Budget",
        "track": "main",
        "status": "Short Findings",
        "keywords": "entity linking;learning under a budget;tensor bilinear model",
        "authors": "",
        "rating": "",
        "confidence": "3;2;2",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "YSWLs0G5va",
        "title": "Joint Entity and Relation Extraction with Span Pruning and Hypergraph Neural Networks",
        "track": "main",
        "status": "Long Main",
        "keywords": "Entity and Relation Extraction;high-order inference;hypergraph neural network",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "YTo9KGNZ3U",
        "title": "Measuring and Mitigating Constraint Violations of In-Context Learning for Utterance-to-API Semantic Parsing",
        "track": "main",
        "status": "Long Findings",
        "keywords": "executable semantic parsing;task-oriented semantic parsing;utterance-to-API generation;in-context learning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "YWbEDZh5ga",
        "title": "On Robustness of Finetuned Transformer-based NLP Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Transformers;Language Models;finetuning;Perturbations;Robustness;Representation Similarity;CKA;STIR",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "YZJ3oewPcu",
        "title": "Language Model Quality Correlates with Psychometric Predictive Power in Multiple Languages",
        "track": "main",
        "status": "Short Main",
        "keywords": "Cognitive Modeling;Language Models;Eye Tracking Data;Cross-linguistic Analysis",
        "authors": "",
        "rating": "",
        "confidence": "5;4;5",
        "correctness": "5;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "YaxyQwG2TP",
        "title": "Content- and Topology-Aware Representation Learning for Scientific Multi-Literature",
        "track": "main",
        "status": "Long Main",
        "keywords": "Representation Learning;Graph-Text Joint Learning;Wasserstein Distance",
        "authors": "",
        "rating": "",
        "confidence": "4;2;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "YbCkHTqZGn",
        "title": "Faithful Model Evaluation for Model-Based Metrics",
        "track": "main",
        "status": "Short Main",
        "keywords": "Evaluation;Model-Based Metrics",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Yg5uDwWQti",
        "title": "Beat LLMs at Their Own Game: Zero-Shot LLM-Generated Text Detection via Querying ChatGPT",
        "track": "main",
        "status": "Short Main",
        "keywords": "LLM-generated text detection;large language model",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "YiITnAhKQd",
        "title": "Somali Information Retrieval Corpus: Bridging the Gap between Query Translation and Dedicated Language Resources",
        "track": "main",
        "status": "Short Main",
        "keywords": "Somali language;low-resource;information retrieval",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "YivRtscaFW",
        "title": "Universal Self-Adaptive Prompting",
        "track": "main",
        "status": "Long Main",
        "keywords": "large language models;prompting;zero-shot;in-context learning",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "YllS5zEzVq",
        "title": "Probing LLMs for Joint Encoding of Linguistic Categories",
        "track": "main",
        "status": "Long Findings",
        "keywords": "language model;transformer;interpretability;probing;syntax;pos;dependency;multilingual",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Ynxo6lene2",
        "title": "Symbolic Planning and Code Generation for Grounded Dialogue",
        "track": "main",
        "status": "Long Main",
        "keywords": "dialogue;information;planning;code;grounding",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "YoKptDpMtt",
        "title": "Effects of sub-word segmentation on performance of transformer language models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Language modeling;Natural language processing;Morphological segmentation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "YokfK5VOoz",
        "title": "Copyright Violations and Large Language Models",
        "track": "main",
        "status": "Short Main",
        "keywords": "language models;copyright;NLP;LLMs",
        "authors": "",
        "rating": "",
        "confidence": "4;2;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Yt4QAWQJ2o",
        "title": "Stylized Dialogue Generation with Feature-Guided Knowledge Augmentation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Stylized Dialogue Generation;Knowledge Augmentation;Feature-guided Selection",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "YvzA0hFCF3",
        "title": "A Challenging Multimodal Video Summary: Simultaneously Extracting and Generating Keyframe-Caption Pairs from Video",
        "track": "main",
        "status": "Long Main",
        "keywords": "Video Summarization;Multimodality",
        "authors": "",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "5;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Yz4VKLeZMG",
        "title": "From Heuristic to Analytic: Cognitively Motivated Strategies for Coherent Physical Commonsense Reasoning",
        "track": "main",
        "status": "Long Main",
        "keywords": "commonsense reasoning;physical commonsense;language model analysis;cognitive modeling",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3;3",
        "correctness": "4;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Yzi6LM20E2",
        "title": "Two Directions for Clinical Data Generation with Large Language Models: Data-to-Label and Label-to-Data",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large language model;clinical text processing;Alzheimer's Disease;data augmentation",
        "authors": "",
        "rating": "",
        "confidence": "2;5;3",
        "correctness": "2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Z1wGHeHBrk",
        "title": "VIPHY: Probing \u201cVisible\u201d Physical Commonsense Knowledge",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Commonsense;Evaluation;Vision-Language Model",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3;3",
        "correctness": "3;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Z2JBNkaJ7k",
        "title": "CiteBench: A Benchmark for Scientific Citation Text Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "related work generation;citation text generation;scientific document processing;multi-document summarization;summarization;benchmark;evaluation",
        "authors": "",
        "rating": "",
        "confidence": "5;5;4",
        "correctness": "4;3;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Z5VthlliRt",
        "title": "A Study on Accessing Linguistic Information in Pre-Trained Language Models by Using Prompts",
        "track": "main",
        "status": "Short Main",
        "keywords": "prompting for linguistic information;morphology;morphological features",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Z65Wq2dvxB",
        "title": "Speak, Memory: An Archaeology of Books Known to ChatGPT/GPT-4",
        "track": "main",
        "status": "Long Main",
        "keywords": "membership inference;memorization;cultural analytics;large language models",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Z7O1kA3pjB",
        "title": "Summarizing Multiple Documents with Conversational Structure for Meta-Review Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multi-document Summarization;Text Generation;Multi-task Learning;Meta-review Generation;Inter-document Relationships",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Z8p4FX15fa",
        "title": "Simple Temporal Adaptation to Changing Label Sets: Hashtag Prediction via Dense KNN",
        "track": "main",
        "status": "Short Main",
        "keywords": "Retrieval Based Models;Ethics;Deletion;Temporal Adaptation;non-parametric",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ZAHyZ3CBds",
        "title": "JointMatch: A Unified Approach for Diverse and Collaborative Pseudo-Labeling to Semi-Supervised Text Classification",
        "track": "main",
        "status": "Long Main",
        "keywords": "Semi-supervised learning;text classification;pseudo-labeling;adaptive local thresholding;cross-labeling;weighted disagreement and agreement update.",
        "authors": "",
        "rating": "",
        "confidence": "5;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ZB66oX17CQ",
        "title": "A Fine-Grained Taxonomy of Replies to Hate Speech",
        "track": "main",
        "status": "Long Main",
        "keywords": "counterspeech;hate speech;taxonomy",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ZBi4ijmOzs",
        "title": "End-to-End Single-Channel Speaker-Turn Aware Conversational Speech Translation",
        "track": "main",
        "status": "Long Main",
        "keywords": "speech translation;conversation;speaker-turn detection",
        "authors": "",
        "rating": "",
        "confidence": "3;4;5;3;4;4",
        "correctness": "4;4;3;3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.8333333333333335,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ZE6fN4OO18",
        "title": "Leveraging Multiple Teachers for Test-Time Adaptation of Language-Guided Classifiers",
        "track": "main",
        "status": "Long Findings",
        "keywords": "test-time adaptation;learning from language;data programming",
        "authors": "",
        "rating": "",
        "confidence": "3;2;2",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ZF8Ye9xWZc",
        "title": "RoMQA: A Benchmark for Robust, Multi-evidence, Multi-answer Question Answering",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Question answering",
        "authors": "",
        "rating": "",
        "confidence": "4;1;3",
        "correctness": "4;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ZJrEDp19kC",
        "title": "Visually Grounded Continual Language Learning with Selective Specialization",
        "track": "main",
        "status": "Long Findings",
        "keywords": "continual learning;lifelong learning;vision-language;language grounding",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ZJua8VeHCh",
        "title": "OssCSE: Overcoming Surface Structure Bias in Contrastive Learning for Unsupervised Sentence Embedding",
        "track": "main",
        "status": "Long Main",
        "keywords": "Unsupervised Sentence Embedding;Contrastive Learning",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4;3",
        "correctness": "4;3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ZNQh02cCxt",
        "title": "Enhancing Abstractiveness of Summarization Models through Calibrated Distillation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "abstractive summarization;knowledge distillation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ZQV5iRPAua",
        "title": "Evaluating Verifiability in Generative Search Engines",
        "track": "main",
        "status": "Long Findings",
        "keywords": "generative;search;engines;verifiability",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ZQrRDCxfhW",
        "title": "Task-Attentive Transformer Architecture for Continual Learning of Vision-and-Language Tasks Using Knowledge Distillation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multimodal Learning;Continual Learning;Catastrophic forgetting",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ZSHcpMXWxX",
        "title": "DUMB: A Dutch Model Benchmark",
        "track": "main",
        "status": "Long Main",
        "keywords": "Dutch;Benchmark;GLUE;Evaluation;Language Models",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ZT3yJWAsrq",
        "title": "'Person' == Light-skinned, Western Man, and Sexualization of Women of Color: Stereotypes in Stable Diffusion",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Stable Diffusion;text-to-image generation;representation;bias;stereotypes;sexualization;national identity;nonbinary gender",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ZTM90jlGAm",
        "title": "Sentiment Analysis on Streaming User Reviews via Dual-Channel Dynamic Graph Neural Network",
        "track": "main",
        "status": "Long Main",
        "keywords": "Sentiment Analysis; Streaming User Reviews; Dynamic Graph Neural Network; Online Review Websites",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ZVy8L79f5f",
        "title": "Linking Surface Facts to Large-Scale Knowledge Graphs",
        "track": "main",
        "status": "Long Main",
        "keywords": "information extraction;fact linking;knowledge graphs;open information extraction",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ZWpJFq6RRU",
        "title": "Accented Speech Recognition With Accent-specific Codebooks",
        "track": "main",
        "status": "Long Main",
        "keywords": "accented speech recognition;cross-attention;codebooks;conformer;domain adaptation",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ZZ3PL3qT9f",
        "title": "Causal Document-Grounded Dialogue Pre-training",
        "track": "main",
        "status": "Long Main",
        "keywords": "Document-grounded dialogue;task specific pretraining;causal effect",
        "authors": "",
        "rating": "",
        "confidence": "1;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Ze2IIzaSF3",
        "title": "HiddenTables and PyQTax: A Cooperative Game and Dataset For TableQA to Ensure Scale and Data Privacy Across a Myriad of Taxonomies",
        "track": "main",
        "status": "Long Main",
        "keywords": "table question answering;dataset;large language models;data privacy;agents;cooperative game",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ZgJSDBU3px",
        "title": "CaseEncoder: A Knowledge-enhanced Pre-trained Model for Legal Case Encoding",
        "track": "main",
        "status": "Long Main",
        "keywords": "Legal case retrieval;pre-trained language model;knowledge",
        "authors": "",
        "rating": "",
        "confidence": "2;5;3",
        "correctness": "3;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ZhZFUOV5hb",
        "title": "Auto Search Indexer for End-to-End Document Retrieval",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Document Retrieval;Generative Retrieval;End to End",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4;3",
        "correctness": "4;3;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ZjWkQz9qXn",
        "title": "Query-based Image Captioning from Multi-context 360\u00b0 Images",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Image Captioning;360-degree image;Vision and Language",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ZjfclaOF7M",
        "title": "UniMath: A Foundational and Multimodal Mathematical Reasoner",
        "track": "main",
        "status": "Short Main",
        "keywords": "Multimodal Math Reasoning;Math Word Problem Solving;Geometry Problem Solving",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ZkR2bWvRpZ",
        "title": "Prompt-Based Monte-Carlo Tree Search for Goal-oriented Dialogue Policy Planning",
        "track": "main",
        "status": "Short Main",
        "keywords": "Prompting;MCTS;Dialogue Policy Planning",
        "authors": "",
        "rating": "",
        "confidence": "3;2;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "Zlm7F7g9FK",
        "title": "NLI4CT: Multi-Evidence Natural Language Inference for Clinical Trial Reports",
        "track": "main",
        "status": "Long Main",
        "keywords": "NLI;Clinical Trial;Textual entailment;Evidence retrieval;NLP",
        "authors": "",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ZskD7TlNVZ",
        "title": "Translating away Translationese without Parallel Data",
        "track": "main",
        "status": "Long Main",
        "keywords": "Translationese Mitigation;Text Style Transfer;Unsupervised Training;Bias Mitigation",
        "authors": "",
        "rating": "",
        "confidence": "3;2;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ZsuPbCxPnA",
        "title": "Non-autoregressive Text Editing with Copy-aware Latent Alignments",
        "track": "main",
        "status": "Long Main",
        "keywords": "text generation;text editing;grammatical error correction;sentence fusion",
        "authors": "",
        "rating": "",
        "confidence": "3;4;1",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "a0yFO9gKc5",
        "title": "Benchmarking and Improving Text-to-SQL Generation under Ambiguity",
        "track": "main",
        "status": "Long Main",
        "keywords": "Semantic Parsing;Text-to-SQL;Ambiguity;Beam Search;ChatGPT;LLMs for Text-to-SQL",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "aB3Hwh4UzP",
        "title": "A Mechanistic Interpretation of Arithmetic Reasoning in Language Models using Causal Mediation Analysis",
        "track": "main",
        "status": "Long Main",
        "keywords": "LLMs;Arithmetic Reasoning;Interpretability;Causality;Causal Mediation Analysis;Reasoning",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3;3",
        "correctness": "4;3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "aBvwASLqMg",
        "title": "On the Representational Capacity of Recurrent Neural Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "RNN;LM;Turing machine;formal languages;probabilistic;language model",
        "authors": "",
        "rating": "",
        "confidence": "3;4;2",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "aCHq10rQiH",
        "title": "CREATOR: Tool Creation for Disentangling Abstract and Concrete Reasoning of Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large Language Models;Tool Creation;Model Reasoning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "aE7feUD7o7",
        "title": "Unified Low-Resource Sequence Labeling by Sample-Aware Dynamic Sparse Finetuning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Sequence Labeling;Low Resource Learning;Sparse Finetuning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "aFIx8T43LU",
        "title": "Log-FGAER: Logic-Guided Fine-Grained Address Entity Recognition from Multi-Turn Spoken Dialogue",
        "track": "main",
        "status": "Long Main",
        "keywords": "Fine-grained address entity recognition;probabilistic soft logic;address extraction;data augmentation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "aICXDsoH3O",
        "title": "Towards large language model-based personal agents in the enterprise: Current trends and open problems",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large language models;task-oriented;chatbots;multi-modal",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "aIp5EZeO3f",
        "title": "ZGUL: Zero-shot Generalization to Unseen Languages using Multi-source Ensembling of Language Adapters",
        "track": "main",
        "status": "Long Main",
        "keywords": "Multilinguality;Low Resource Languages;Parameter-Efficient Fine-Tuning (PEFT)",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "aJILUuANbs",
        "title": "Multi-Stage Pre-training Enhanced by ChatGPT for Multi-Scenario Multi-Domain Dialogue Summarization",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multi-Scenario Multi-Domain Dialogue Summarization;Multi-Stage Pre-training;ChatGPT",
        "authors": "",
        "rating": "",
        "confidence": "4;4;2",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "aLkknJNdl6",
        "title": "Towards Low-Resource Automatic Program Repair with Meta-Learning and Pretrained Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Low-resource APR",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "aN8zkE15Nx",
        "title": "An Investigation of LLMs\u2019 Inefficacy in Understanding Converse Relations",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large language models;inverse scaling;converse relation",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4;3",
        "correctness": "3;4;5;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "aNFWz8zubu",
        "title": "EtiCor: Corpus for Analyzing LLMs for Etiquettes",
        "track": "main",
        "status": "Short Main",
        "keywords": "Social Norms;Etiquette;LLMs",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "aP5f7cgY1M",
        "title": "Rather a Nurse than a Physician - Contrastive Explanations under Investigation",
        "track": "main",
        "status": "Long Main",
        "keywords": "explainability;contrastive explanations;human annotations",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "aPZ7AjA5YV",
        "title": "Revisiting Large Language Models as Zero-shot Relation Extractors",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Relation Extraction;Large Language Models;Zero-shot Learning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "aRlH9AkiEA",
        "title": "KEPLET: Knowledge-Enhanced Pretrained Language Model with Topic Entity Awareness",
        "track": "main",
        "status": "Long Findings",
        "keywords": "language model;knowledge enhanced language model",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "aURCCzSuhc",
        "title": "Taxonomy Expansion for Named Entity Recognition",
        "track": "main",
        "status": "Long Main",
        "keywords": "named entity recognition;taxonomy",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4;4",
        "correctness": "4;4;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "aUn1BAzo7q",
        "title": "Weakly Supervised Semantic Parsing with Execution-based Spurious Program Filtering",
        "track": "main",
        "status": "Long Main",
        "keywords": "weakly supervised semantic parsing;spurious programs",
        "authors": "",
        "rating": "",
        "confidence": "4;2;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "aVejMt2gYN",
        "title": "Inference-Time Policy Adapters (IPA): Tailoring Extreme-Scale LMs without Fine-tuning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Language Model;Text Generation;Reinforcement Learning;Inference-time Algorithm",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "aVqGqTyky7",
        "title": "Contrastive Distant Supervision for Debiased and Denoised Machine Reading Comprehension",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Distant Supervision;Machine Reading Comprehension;Contrastive Learning",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "aXi6UwdygV",
        "title": "Cognate Transformer for Automated Phonological Reconstruction and Cognate Reflex Prediction",
        "track": "main",
        "status": "Long Main",
        "keywords": "Computational historical linguistics;Phonological reconstruction;Cognate reflex prediction;Transformer",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "5;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "aY4avQ0ItI",
        "title": "A Systematic Study of Performance Disparities in Multilingual Task-Oriented Dialogue Systems",
        "track": "main",
        "status": "Long Main",
        "keywords": "multilingual task-oriented dialogue systems;analysis of performance disparities",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "aaMwMjrDz0",
        "title": "Conditional Natural Language Inference",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Natural language inference;NLI;explanation;contradictory aspect;token-level explanation;interpretable model",
        "authors": "",
        "rating": "",
        "confidence": "4;2;3",
        "correctness": "2;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "adIeh9ZsfC",
        "title": "An Empirical Study of Frame Selection for Text-to-Video Retrieval",
        "track": "main",
        "status": "Long Findings",
        "keywords": "text-to-video retrival;frame selection",
        "authors": "",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "adjZtG9bDM",
        "title": "Evaluation of African American Language Bias in Natural Language Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "benchmarking large language models;african american language;bias and fairness;language generation",
        "authors": "",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "4;1;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ae6MmBuX6k",
        "title": "MCC-KD: Multi-CoT Consistent Knowledge Distillation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Knowledge Distillation;Chain of Thought;Reasoning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "aeLyo8GAco",
        "title": "Hierarchical Catalogue Generation for Literature Review: A Benchmark",
        "track": "main",
        "status": "Long Findings",
        "keywords": "scientific document processing;multi-document summarization;datasets;metrics",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ahVTS392C3",
        "title": "JASMINE: Arabic GPT Models for Few-Shot Learning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Arabic;Arabic dialects varieties;GPT;Few-shot learning",
        "authors": "",
        "rating": "",
        "confidence": "2;4;5",
        "correctness": "5;5;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ai6kjD6cyX",
        "title": "Event Causality Extraction via Implicit Cause-Effect Interactions",
        "track": "main",
        "status": "Long Main",
        "keywords": "Event Causality Extraction;Generative Language Models;Knowledge Distillation;Optimal Transport",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "aipbZ5obaz",
        "title": "Comparing Styles across Languages",
        "track": "main",
        "status": "Long Main",
        "keywords": "NLP;Style;Cross-Cultural;Multilingual;Explainability;Lexica",
        "authors": "",
        "rating": "",
        "confidence": "2;3;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ajzFrKT3U7",
        "title": "Leveraging Structured Information for Explainable Multi-hop Question Answering and Reasoning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Natural Language Processing;Multi-hop Question Answering",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ak6PQPmmEK",
        "title": "The student becomes the master: Outperforming GPT3 on Scientific Factual Error Correction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Factual Error Correction;GPT;Domain Adaptation;Distribution Shift",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3;3",
        "correctness": "4;3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "akJUrevmwI",
        "title": "Do Language Models Have a Common Sense regarding Time? Revisiting Temporal Commonsense Reasoning in the Era of Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Benchmarking;Temporal Reasoning;LLMs",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "alxWMBcNVN",
        "title": "Personalized Distillation: Empowering Open-Sourced LLMs with Adaptive Learning for Code Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Distillation;code generation;adaptive learning",
        "authors": "",
        "rating": "",
        "confidence": "4;2;5",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "aolJqJ50ZA",
        "title": "Explore the Way: Exploring Reasoning Path by Bridging Entities for Effective Cross-Document Relation Extraction",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Cross-document relation extraction;Document relation extraction;Reasoning Path Construction",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "asYObzj0IT",
        "title": "Comparing Prompt-Based and Standard Fine-Tuning for Urdu Text Classification",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Prompt-based Fine-tuning;Urdu Text Classification;Pre-trained Language Models",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ayoGdkXi4V",
        "title": "Lazy-k Decoding: Constrained Decoding for Information Extraction",
        "track": "main",
        "status": "Long Main",
        "keywords": "structured prediction;constrained decoding;token classification;information extraction;beam search",
        "authors": "",
        "rating": "",
        "confidence": "2;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ayzVnzaUzB",
        "title": "When the Majority is Wrong: Modeling Annotator Disagreement for Subjective Tasks",
        "track": "main",
        "status": "Long Main",
        "keywords": "annotator disagreement;hate speech;toxicity detection;offensive content detection;AI fairness",
        "authors": "",
        "rating": "",
        "confidence": "4;2;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "b07c10sXzN",
        "title": "Lifelong Sequence Generation with Dynamic Module Expansion and Adaptation",
        "track": "main",
        "status": "Long Main",
        "keywords": "lifelong learning;sequence generation;dynamic module;forward knowledge transfer",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4;5",
        "correctness": "4;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "b1J3WplfgM",
        "title": "SKD-NER: Continual Named Entity Recognition via Span-based Knowledge Distillation with Reinforcement Learning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Continual learning;Named Entity Recognition;Knowledge Distillation;Reinforcement Learning",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "3;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "b1XS87j323",
        "title": "A Multi-Task Dataset for Assessing Discourse Coherence in Chinese Essays: Structure, Theme, and Logic Analysis",
        "track": "main",
        "status": "Long Main",
        "keywords": "discourse coherence assessment",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "b3lGS64ZZK",
        "title": "A Fair and In-Depth Evaluation of Existing End-to-End Entity Linking Systems",
        "track": "main",
        "status": "Long Main",
        "keywords": "entity linking;entity linking evaluation;entity linking benchmarks",
        "authors": "",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "b5pbHYNJnX",
        "title": "Rethinking Model Selection and Decoding for Keyphrase Generation with Pre-trained Sequence-to-Sequence Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Keyphrase Generation;Pre-trained Language Models;Text Generation Decoding;Performance Evaluation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3;5",
        "correctness": "4;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "b6JnUJxOpN",
        "title": "Temporal Extrapolation and Knowledge Transfer for Lifelong Temporal Knowledge Graph Reasoning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Temporal Knowledge Graph;Lifelong Reasoning;Temporal Extrapolation;Knowledge Transfer.",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "b6e1wV03hy",
        "title": "Retrieval-Augmented Few-shot Text Classification",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Retrieval-augmented methods;Few-shot text classification",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "b7ZJcAkjC3",
        "title": "Enhancing Structured Evidence Extraction for Fact Verification",
        "track": "main",
        "status": "Long Main",
        "keywords": "fact verification; evidence extraction",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "b7gtyaaM2y",
        "title": "Towards General Error Diagnosis via Behavioral Testing in Machine Translation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "behavioral testing;machine translation",
        "authors": "",
        "rating": "",
        "confidence": "4;2;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "bB32QLrpu4",
        "title": "Granularity Matters: Pathological Graph-driven Cross-modal Alignment for Brain CT Report Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Medical Report Generation;Contrastive Learning;Knowledge Graph;Brain CT",
        "authors": "",
        "rating": "",
        "confidence": "3;4;2",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "bNeDLx5O6w",
        "title": "MAF: Multi-Aspect Feedback for Improving Reasoning in Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "large language models;feedback generation;reasoning;self-correction;in-context learning;prompting;prompt engineering;error correction",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "bQLMv4v0Gc",
        "title": "Construction Artifacts in Metaphor Identification Datasets",
        "track": "main",
        "status": "Short Main",
        "keywords": "metaphors;resources;bias",
        "authors": "",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "bSfBgrmabV",
        "title": "Dual-Feedback Knowledge Retrieval for Task-Oriented Dialogue Systems",
        "track": "main",
        "status": "Long Main",
        "keywords": "End-to-End Task-Oriented Dialogue System;Knowledge Retrieval;Retriever training",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "bVO1sWgnTx",
        "title": "Efficient Classification of Long Documents via State-Space Models",
        "track": "main",
        "status": "Short Main",
        "keywords": "Long Document Classification;State Space Models;Efficient NLP",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "bWXIut4pNM",
        "title": "INGENIOUS: Using Informative Data Subsets for Efficient Pre-Training of Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Efficient training;Language Models;Data selection",
        "authors": "",
        "rating": "",
        "confidence": "2;4;3;4",
        "correctness": "2;2;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.25,
        "correctness_avg": 2.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "bZel7wM6fN",
        "title": "Understanding the Inner-workings of Language Models Through Representation Dissimilarity",
        "track": "main",
        "status": "Short Main",
        "keywords": "language models;interpretability;stitching",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3;1;5",
        "correctness": "4;4;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.8,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "bc2xgl7oGf",
        "title": "The Iron(ic) Melting Pot: Reviewing Human Evaluation in Humour, Irony and Sarcasm Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "human evaluation;humour;sarcasm;irony;natural language generation;position paper;critical survey;sociology",
        "authors": "",
        "rating": "",
        "confidence": "5;5;4",
        "correctness": "3;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "bdgUPZhF9b",
        "title": "InstructoR: Instructing Unsupervised Conversational Dense Retrieval with Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Conversational Dense Retrieval;Unsupervised Information Retrieval;Large Language Models",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4;4",
        "correctness": "4;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "bflAMCWJh8",
        "title": "PerturbScore: Connecting Discrete and Continuous Perturbations in NLP",
        "track": "main",
        "status": "Long Findings",
        "keywords": "perturbation in NLP;robustness in NLP",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 1.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "bgskDuMqcz",
        "title": "Adapt in Contexts: Retrieval-Augmented Domain Adaptation via In-Context Learning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Domain Adaptation;in-context learning;Retrieval Augmentation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;2;4",
        "correctness": "2;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "bkGVmCE3UJ",
        "title": "Counting the Bugs in ChatGPT's Wugs: A Multilingual Investigation into the Morphological Capabilities of a Large Language Model",
        "track": "main",
        "status": "Long Main",
        "keywords": "wug-testing;morphology;chatGPT;morphological generalization",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "bmeKrAzRqz",
        "title": "Pre-Trained Language Models Augmented with Synthetic Scanpaths for Natural Language Understanding",
        "track": "main",
        "status": "Short Main",
        "keywords": "Human gaze data;synthetic scanpaths;gaze-augmented language model;natural language understanding;transformer;deep neural networks",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "bpArUWbkUF",
        "title": "Argue with Me Tersely: Towards Sentence-Level Counter-Argument Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Counter-Argument Generation;ArgTersely;Arg-LLaMA;Arg-Judge",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "bqaW5sGZOq",
        "title": "Revisiting Machine Translation for Cross-lingual Classification",
        "track": "main",
        "status": "Long Main",
        "keywords": "multilinguality;cross-lingual classification;machine translation",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "bt9Ho2FMxd",
        "title": "Unmasking the Hidden Meaning: Bridging Implicit and Explicit Hate Speech Embedding Representations",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Hate Speech Detection;Implicit Hate Embeddings",
        "authors": "",
        "rating": "",
        "confidence": "3;5;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "bvl3p6JUlv",
        "title": "Mitigating Biases in Hate Speech Detection from A Causal Perspective",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Hate speech detection;Causal inference;Bias mitigation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "bxFwIn0wZ0",
        "title": "Enabling Large Language Models to Generate Text with Citations",
        "track": "main",
        "status": "Long Main",
        "keywords": "large language model;llm;citation;attribution;qa;evaluation;benchmark",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "bxltAqTJe2",
        "title": "$\\textit{From Chaos to Clarity}$: Claim Normalization to Empower Fact-Checking",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Claim Normalization;Social Media;Claims;Misinformation",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "bxsrykzSnq",
        "title": "HaluEval: A Large-Scale Hallucination Evaluation Benchmark for Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Models;Hallucination",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "c0utj9Q4YY",
        "title": "Toward Joint Language Modeling for Speech Units and Text",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Language modeling;Speech processing;Spoken Language Understanding",
        "authors": "",
        "rating": "",
        "confidence": "2;3;5",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "c27QqxALfo",
        "title": "MM-Reasoner: A Multi-Modal Knowledge-Aware Framework for Knowledge-Based Visual Question Answering",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Vision-Language Models;Large Language Models;Visual Question Answering",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "c2xBtTNceS",
        "title": "Inverse Reinforcement Learning for Text Summarization",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Abstractive Summarization;Inverse Reinforcement Learning;Reward Function Optimization",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "cBhzqp8WlV",
        "title": "Advancements in Arabic Grammatical Error Detection and Correction: An Empirical Investigation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Grammatical Error Correction;Grammatical Error Detection;Arabic",
        "authors": "",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "cCJGuKJYG8",
        "title": "Towards Reliable Misinformation Mitigation: Generalization, Uncertainty, and GPT-4",
        "track": "main",
        "status": "Long Main",
        "keywords": "misinformation;LLM;GPT-4;uncertainty quantification;generalization",
        "authors": "",
        "rating": "",
        "confidence": "4;5;3",
        "correctness": "2;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "cD9blNBYF2",
        "title": "DialogQAE: N-to-N Question Answer Pair Extraction from Customer Service Chatlog",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Dialogue QA Extraction",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "cFXHe1mW7V",
        "title": "Can You Follow Me? Testing Situational Understanding for ChatGPT",
        "track": "main",
        "status": "Long Main",
        "keywords": "Situational Understanding;Analysis of Models;ChatGPT",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "5;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "cFsfgaEMlw",
        "title": "4 and 7-bit Labeling for Projective and Non-Projective Dependency Trees",
        "track": "main",
        "status": "Short Main",
        "keywords": "parsing;dependency parsing;sequence labeling;parsing as sequence labeling;encoding",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "cI6oe7i5mj",
        "title": "GPT Deciphering Fedspeak: Quantifying Dissent Among Hawks and Doves",
        "track": "main",
        "status": "Short Findings",
        "keywords": "FOMC;Fed;GPT;LLM;dissent",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "cMMxJxzYkZ",
        "title": "Harnessing the Power of Large Language Models for Empathetic Response Generation: Empirical Investigations and Improvements",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Empathetic Response Generation;Large Language Models;ChatGPT",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4;5;4",
        "correctness": "4;4;4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.8,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "cOxL1tlSQw",
        "title": "Dynamic Stance: Modeling Discussions by Labeling the Interactions",
        "track": "main",
        "status": "Long Findings",
        "keywords": "stance;corpus;multi-lingual;cross-topic",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "cVAHzYRVUO",
        "title": "Inductive Relation Inference of Knowledge Graph Enhanced by Ontology Information",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Ontology Information;Inductive Relation Inference;Knowledge Graph",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "cWw5FfVhvl",
        "title": "MoT: Memory-of-Thought Enables ChatGPT to Self-Improve",
        "track": "main",
        "status": "Long Main",
        "keywords": "LLM;ChatGPT;Self-Improve;Large Language Model;Memory",
        "authors": "",
        "rating": "",
        "confidence": "2;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "cgmlfA1sPl",
        "title": "Late Fusion of Transformers for Sentiment Analysis of Code-Switched Data",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Code-switched;Transformer;Sentiment Analysis;GLUECoS benchmark dataset;Late Fusion;Neural Network",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "4;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "chCrhE2kl4",
        "title": "TK-KNN: A Balanced Distance-Based Pseudo Labeling Approach for Semi-Supervised Intent Classification",
        "track": "main",
        "status": "Long Findings",
        "keywords": "semi-supervised learning;intent classification;contrastive learning",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ci6cexmrmD",
        "title": "DepWiGNN: A Depth-wise Graph Neural Network for Multi-hop Spatial Reasoning in Text",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Spatial Reasoning;Tensor Product Representation;Graph Neural Network",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "cjbdRN8Yxy",
        "title": "Compressing Context to Enhance Inference Efficiency of Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Model;Input Compression",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ckKuQDW2RZ",
        "title": "Conic10K: A Challenging Math Problem Understanding and Reasoning Dataset",
        "track": "main",
        "status": "Long Findings",
        "keywords": "math problem;reasoning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "clTPP37Rpu",
        "title": "Beyond Factuality: A Comprehensive Evaluation of Large Language Models as Knowledge Generators",
        "track": "main",
        "status": "Long Main",
        "keywords": "Evaluation framework;Knowledge generation;Large language model;",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "clxLDVanxO",
        "title": "ReTAG: Reasoning Aware Table to Analytic Text Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Table to Text Generation;Table Understanding;Structured Reasoning",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "cmQj1FdsOJ",
        "title": "Evaluating the Knowledge Base Completion Potential of GPT",
        "track": "main",
        "status": "Short Findings",
        "keywords": "knowledge base completion;knowledge graphs;probing language models;evaluation",
        "authors": "",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "cooAE3hYUC",
        "title": "BasahaCorpus: An Expanded Linguistic Resource for Readability Assessment in Central Philippine Languages",
        "track": "main",
        "status": "Short Main",
        "keywords": "readability assessment;corpus;linguistic resource;cross-lingual;Philippine languages;low-resource NLP",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "crfQrbxWAK",
        "title": "Schema-adaptable Knowledge Graph Construction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Knowledge Graph Construction;Information Extraction",
        "authors": "",
        "rating": "",
        "confidence": "2;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "csBtifBXKo",
        "title": "Adaptive End-to-End Metric Learning for Zero-Shot Cross-Domain Slot Filling",
        "track": "main",
        "status": "Long Main",
        "keywords": "end-to-end;zero-shot learning;metric learning;slot filling",
        "authors": "",
        "rating": "",
        "confidence": "2;3;2",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "cvRvFj3Pyv",
        "title": "Empathy Intent Drives Empathy Detection",
        "track": "main",
        "status": "Long Main",
        "keywords": "Empathy detection;Empathy intent recognition;Cascaded interactive attention;Label signal enhancement",
        "authors": "",
        "rating": "",
        "confidence": "5;4;3;3",
        "correctness": "4;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "cw6v58yo6s",
        "title": "Baize: An Open-Source Chat Model with Parameter-Efficient Tuning on Self-Chat Data",
        "track": "main",
        "status": "Long Main",
        "keywords": "large language model;knowledge disillation;data generation;chatbot;chat model;text generation",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "czxX6jjpVJ",
        "title": "Discovering Highly Influential Shortcut Reasoning: An Automated Template-Free Approach",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Shortcut Reasoning;Inference;Robustness",
        "authors": "",
        "rating": "",
        "confidence": "3;4;5",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "d00kbjbYv2",
        "title": "How to Train Your Dragon: Diverse Augmentation Towards Generalizable Dense Retrieval",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Generalizable Dense Retrieval;Data Augmentation;Progressive Training",
        "authors": "",
        "rating": "",
        "confidence": "2;4;3;4",
        "correctness": "2;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "d0qmGnKfXa",
        "title": "From Relevance to Utility: Evidence Retrieval with Feedback for Fact Verification",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Utility; Evidence Retrieval; Fact Verification",
        "authors": "",
        "rating": "",
        "confidence": "5;3;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "d0zla3M3LI",
        "title": "Tree Prompting: Efficient Task Adaptation without Fine-Tuning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Decision tree;large language model;chain prompting;prompt engineering",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "d94iPelgSD",
        "title": "Intra-Event and Inter-Event Dependency-Aware Graph Network for Event Argument Extraction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "event argument extraction;intra-event dependency;inter-event dependency;dependency-aware graph network",
        "authors": "",
        "rating": "",
        "confidence": "3;4;5",
        "correctness": "2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "dABNxI5c1X",
        "title": "Modeling Empathic Similarity in Personal Narratives",
        "track": "main",
        "status": "Long Main",
        "keywords": "empathy;semantic similarity;personal narratives",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3;4",
        "correctness": "4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.25,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "dFlGP1l65l",
        "title": "When it Rains, it Pours: Modeling Media Storms and the News Ecosystem",
        "track": "main",
        "status": "Long Findings",
        "keywords": "political communication;news media;political science",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "dFvwxdSj0B",
        "title": "Retrieval-Augmented Parsing for Complex Graphs by Exploiting Structure and Uncertainty",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Uncertainty Quantification;Retrieval;Semantic Parsing",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "dHHumVX2XV",
        "title": "Efficient Continue Training of Temporal Language Model with Structural Information",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Temporal Generalization;Syntactic Change;Temporal Language Model;Pre-trained Language Model",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "dJ5yzTX4rZ",
        "title": "Solving Hard Analogy Questions with Relation Embedding Chains",
        "track": "main",
        "status": "Long Main",
        "keywords": "relation embedding;analogy questions;ConceptNet;knowledge graphs",
        "authors": "",
        "rating": "",
        "confidence": "5;4;2",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "dQxLtay1M3",
        "title": "HyperNetwork-based Decoupling to Improve Model Generalization for Few-Shot Relation Extraction",
        "track": "main",
        "status": "Long Main",
        "keywords": "Relation Extraction;Few-Shot Relation Extraction",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "dRlYuG3bj7",
        "title": "SentiStream: A Co-Training Framework for Adaptive Online Sentiment Analysis in Evolving Data Streams",
        "track": "main",
        "status": "Long Main",
        "keywords": "Online Sentiment analysis;Streaming learning",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "1;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "dVOXsyVcik",
        "title": "Dynamic Top-k Estimation Consolidates Disagreement between Feature Attribution Methods",
        "track": "main",
        "status": "Short Main",
        "keywords": "interpretability;explainability;top-k;ranking;agreement;feature attribution",
        "authors": "",
        "rating": "",
        "confidence": "3;3;2;2",
        "correctness": "3;3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "dVfeS1pp2e",
        "title": "Strong and Efficient Baselines for Open Domain Conversational Question Answering",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Open Domain Conversational Question Answering",
        "authors": "",
        "rating": "",
        "confidence": "2;3;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "dZWiI6A09u",
        "title": "Explainable Claim Verification via Knowledge-Grounded Reasoning with Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Claim Verification;Natural Language Reasoning;Large Language Model",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "daGbpBMkoy",
        "title": "Narrative Order Aware Story Generation via Bidirectional Pretraining Model with Optimal Transport Reward",
        "track": "main",
        "status": "Long Findings",
        "keywords": "story generation;narrative order;optimal transport",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "dbRZyDxYlL",
        "title": "Improving Speech Translation by Fusing Speech and Text",
        "track": "main",
        "status": "Long Findings",
        "keywords": "speech translation;multimodal",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "dcYt9ByOOK",
        "title": "Responsible AI Considerations in Text Summarization Research: A Review of Current Practices",
        "track": "main",
        "status": "Long Findings",
        "keywords": "responsible AI;automatic summarization",
        "authors": "",
        "rating": "",
        "confidence": "3;5;4",
        "correctness": "3;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ddldNozhnM",
        "title": "CLEME: Debiasing Multi-reference Evaluation for Grammatical Error Correction",
        "track": "main",
        "status": "Long Main",
        "keywords": "natural language processing;grammatical error correction;evaluation metric",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "di1Foopybz",
        "title": "CoSyn: Detecting Implicit Hate Speech in Online Conversations Using a Context Synergized Hyperbolic Network",
        "track": "main",
        "status": "Long Main",
        "keywords": "hate-speech;hyperbolic;social-good;implicit",
        "authors": "",
        "rating": "",
        "confidence": "5;5;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "diItUQ1idA",
        "title": "Abstractive Open Information Extraction",
        "track": "main",
        "status": "Long Main",
        "keywords": "Open Information Extraction;Relation Extraction;Natural Language Generation",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "diUHb3jt3j",
        "title": "Uncovering the Root of Hate Speech: A Dataset for Identifying Hate Instigating Speech",
        "track": "main",
        "status": "Long Findings",
        "keywords": "hate speech;hate instigating speech;machine learning;natural language processing",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "1;2;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 1.6666666666666667,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "djmjglxOZ7",
        "title": "Finding Support Examples for In-Context Learning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "In-Context Learning;ICL;Language Model",
        "authors": "",
        "rating": "",
        "confidence": "3;4;5",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "dl4e3EBz5j",
        "title": "GlotLID: Language Identification for Low-Resource Languages",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Language Identification;Low-Resource Languages",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "dnIfD7RJLU",
        "title": "GEM: Gestalt Enhanced Markup Language Model for Web Understanding via Render Tree",
        "track": "main",
        "status": "Long Main",
        "keywords": "Gestalt;Markup Language;Web Understanding;Language Model",
        "authors": "",
        "rating": "",
        "confidence": "3;5;4",
        "correctness": "4;5;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "dnQI76LKQy",
        "title": "MultiCMET: A Novel Chinese Benchmark for Understanding Multimodal Metaphor",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multimodal metaphor;Benchmark;Chinese language;Domain lexicon;Metaphor understanding",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "dp9jTeKXec",
        "title": "From Simple to Complex: A Progressive Framework for Document-level Informative Argument Extraction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Document-level event extraction;informative argument extraction;simple-to-complex prediction",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "dpS5VxAwuF",
        "title": "Multimodal Embodied Plan Prediction Augmented with Synthetic Embodied Dialogue",
        "track": "main",
        "status": "Long Main",
        "keywords": "Embodied AI;Embodied Task Completion;Language and Robotics;Plan Prediction;Dialog Simulation",
        "authors": "",
        "rating": "",
        "confidence": "4;1;5",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "dq25TkeI1W",
        "title": "Probing LLMs for hate speech detection: strengths and vulnerabilities",
        "track": "main",
        "status": "Long Findings",
        "keywords": "hate speech;explanation;large language models;detection",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "drG2ScCe4C",
        "title": "Spoiler Detection as Semantic Text Matching",
        "track": "main",
        "status": "Short Main",
        "keywords": "dataset;spoiler detection;semantic text matching",
        "authors": "",
        "rating": "",
        "confidence": "4;5;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "du1t38uXPA",
        "title": "DeCrisisMB: Debiased Semi-Supervised Learning for Crisis Tweet Classification via Memory Bank",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Semi-Supervised Learning;Debiasing;Crisis Tweet Classification",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3;4",
        "correctness": "4;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "dvDi1Oc2y7",
        "title": "GBT: Generative Boosting Training Approach for Paraphrase Identification",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Paraphrase Identification;Data Augmentation;Text Semantic Matching",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "2;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "dwGKBFXiy2",
        "title": "NASH: A Simple Unified Framework of Structured Pruning for Accelerating Encoder-Decoder Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Model Compression;Structured Pruning;Encoder-Decoder Language Model",
        "authors": "",
        "rating": "",
        "confidence": "4;1;3;4",
        "correctness": "3;4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "dwj886NUqy",
        "title": "GreedyCAS: Unsupervised Scientific Abstract Segmentation with Normalized Mutual Information",
        "track": "main",
        "status": "Long Main",
        "keywords": "Abstract Segmentation;Mutual Information;Argument Mining",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "dxCviFd7rj",
        "title": "Visual Elements Mining as Prompts for Instruction Learning for Target-Oriented Multimodal Sentiment Classification",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Target-oriented multimodal sentiment classification;Instruction learning",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "e2B31gDhnj",
        "title": "Domain Private Transformers for Multi-Domain Dialog Systems",
        "track": "main",
        "status": "Short Findings",
        "keywords": "differential privacy;language models;dialogue;multi-domain language models",
        "authors": "",
        "rating": "",
        "confidence": "2;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "e3eIqCPCT9",
        "title": "Learning to Rank Generation with Pairwise Partial Rewards",
        "track": "main",
        "status": "Long Main",
        "keywords": "Reinforcement learning;learning to rank;reward shaping;conditional text generation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "e3gXrvjGys",
        "title": "A Unified Framework for Synaesthesia Analysis",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Synaesthesia Analysis;Generation Model;Lingusitic",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "e4dXIBRQ9u",
        "title": "Grammatical Error Correction via Mixed-Grained Weighted Training",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Grammatical Error Correction;Weighted Training",
        "authors": "",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "e4m1Gu6rVP",
        "title": "Distilling ChatGPT for Explainable Automated Student Answer Assessment",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Student answer assessment;Rationale generation;Large language model",
        "authors": "",
        "rating": "",
        "confidence": "2;3;4",
        "correctness": "4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "e5UzmaR8EE",
        "title": "Towards Interpretable Mental Health Analysis with Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "mental health analysis;large language models;prompt engineering;explainability",
        "authors": "",
        "rating": "",
        "confidence": "5;3;5;4",
        "correctness": "4;3;5;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "e8jvAr4Aaj",
        "title": "Enhancing Conversational Search: Large Language Model-Aided Informative Query Rewriting",
        "track": "main",
        "status": "Long Findings",
        "keywords": "conversational search;conversational passage retrieval;query rewriting;query reformulation",
        "authors": "",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "e8wYLib8HC",
        "title": "Transformer Working Memory Enables Regular Language Reasoning And Natural Language Length Extrapolation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Transformer;Algorithmic reasoning;Length extrapolation;Working memory",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4;2",
        "correctness": "4;4;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "eBUgomB8uo",
        "title": "Towards Multilingual Interlinear Morphological Glossing",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Computational Language Documentation; Interlinear Morphological Glosses; Structured Prediction;",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "2;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "eCXfUq3RDf",
        "title": "Miracle: Towards Personalized Dialogue Generation with Latent-Space Multiple Personal Attribute Control",
        "track": "main",
        "status": "Long Findings",
        "keywords": "personalized response generaion;dialogue;Natural language generation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "2;4;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "eEV5S2EIp9",
        "title": "Transfer-Free Data-Efficient Multilingual Slot Labeling",
        "track": "main",
        "status": "Long Main",
        "keywords": "Dialogue NLU;Multilingual;Slot Labeling;Data Efficient",
        "authors": "",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "eFnBXtZXIH",
        "title": "When Reviewers Lock Horns: Finding Disagreements in Scientific Peer Reviews",
        "track": "main",
        "status": "Short Main",
        "keywords": "Contradiction Detection;Peer Reviews;NLP",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "4;2;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "eGNwWBfqqs",
        "title": "CCSRD: Content-Centric Speech Representation Disentanglement Learning for End-to-End Speech Translation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "speech translation;representation disentanglement",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "eHqrdft1wn",
        "title": "Aligning Language Models to User Opinions",
        "track": "main",
        "status": "Long Findings",
        "keywords": "personalization;large language model",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "eNu9odz1sz",
        "title": "Universal Domain Adaptation for Robust Handling of Distributional Shifts in NLP",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Domain Adaptation;Universal Domain Adaptation;Out-of-Distribution Detection",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "eSM4RWpuJF",
        "title": "A Hierarchical Encoding-Decoding Scheme for Abstractive Multi-document Summarization",
        "track": "main",
        "status": "Long Findings",
        "keywords": "multi-document summarization;abstractive summarization;pre-trained language models;hierarchical",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "2;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "eTDs4UY52h",
        "title": "Automatic Debate Evaluation with Argumentation Semantics and Natural Language Argument Graph Networks",
        "track": "main",
        "status": "Long Main",
        "keywords": "Argument Evaluation;Debate Analysis;Argumentation Theory;Computational Argumentation",
        "authors": "",
        "rating": "",
        "confidence": "3;4;5",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "eWW0KQhsHe",
        "title": "CHEF in the Language Kitchen: A Generative Data Augmentation Leveraging Korean Morpheme Ingredients",
        "track": "main",
        "status": "Long Main",
        "keywords": "Data Augmentation;Morpheme Blender;Label Discriminator;Contrastive Learning;Korean Language",
        "authors": "",
        "rating": "",
        "confidence": "3;2;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "eXV8sdO5HL",
        "title": "Multi-level Contrastive Learning for Script-based Character Understanding",
        "track": "main",
        "status": "Long Main",
        "keywords": "Natural Language Processing;Character Understanding;Contrastive Learning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3;3",
        "correctness": "3;4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "eaUi1mcvrM",
        "title": "INSTRUCTSCORE: Towards Explainable Text Generation Evaluation with Automatic Feedback",
        "track": "main",
        "status": "Long Main",
        "keywords": "Text generation evaluation;Explainable metric",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ebSOK1nV2r",
        "title": "Answering Questions by Meta-Reasoning over Multiple Chains of Thought",
        "track": "main",
        "status": "Long Main",
        "keywords": "Question Answering;Multi-hop Question Answering;Reasoning;Few-shot;Chain of Thought",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "edwSiVzFpU",
        "title": "End-to-end Task-oriented Dialogue: A Survey of Tasks, Methods, and Future Directions",
        "track": "main",
        "status": "Long Main",
        "keywords": "End-to-End Task-Oriented Dialogue (EToD);Task-oriented Dialogue Systems (ToD);Pre-trained Models in Dialogue Systems",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "eeP1y7zPQ7",
        "title": "Fast and Robust Early-Exiting Framework for Autoregressive Language Models with Synchronized Parallel Decoding",
        "track": "main",
        "status": "Long Main",
        "keywords": "Efficient Decoding of Language Model;Early-Exiting Framework;Parallel Decoding;Adaptive Confidence Estimation",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4;4",
        "correctness": "4;5;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "eiFRPhpsW6",
        "title": "Why Should This Article Be Deleted? Transparent Stance Detection in Multilingual Wikipedia Editor Discussions",
        "track": "main",
        "status": "Long Main",
        "keywords": "Wikipedia;deletion discussion;stance detection;content moderation;policy;multilingual",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "eiHT1VAs4K",
        "title": "Preserving Knowledge Invariance: Rethinking Robustness Evaluation of Open Information Extraction",
        "track": "main",
        "status": "Long Main",
        "keywords": "open information extraction;robustness evaluation;high-quality paraphrase",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "erorKQYQ7P",
        "title": "Co$^2$PT: Mitigating Bias in Pre-trained Language Models through Counterfactual Contrastive Prompt Tuning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "bias;contrastive learning;prompt tuning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "euYA3EmI0e",
        "title": "Learning to Correct Noisy Labels for Fine-Grained Entity Typing via Co-Prediction Prompt Tuning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "fine-grained entity typing;natural language processing;noisy labels;co-prediction prompt tuning;large language model",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ev8dLLwScW",
        "title": "Ditto: A Simple and Efficient Approach to Improve Sentence Embeddings",
        "track": "main",
        "status": "Short Main",
        "keywords": "Sentence embeddings;BERT;Transformer;Self-attention",
        "authors": "",
        "rating": "",
        "confidence": "4;2;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ewedHtUI5X",
        "title": "ASSERT: Automated Safety Scenario Red Teaming for Evaluating the Robustness of Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "robustness;safety;red teaming;large language models",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "eyuTFB2CBM",
        "title": "KEPL: Knowledge Enhanced Prompt Learning for Chinese Hypernym-Hyponym Extraction",
        "track": "main",
        "status": "Long Main",
        "keywords": "Knowledge Base;prompt;Hypernym discovery",
        "authors": "",
        "rating": "",
        "confidence": "5;3;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "f05z3XqUeu",
        "title": "RainProof: An Umbrella to Shield Text Generator from Out-Of-Distribution Data",
        "track": "main",
        "status": "Long Main",
        "keywords": "NLP;OOD detection;natural language generation",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "f10SqktqkF",
        "title": "Investigating Online Community Engagement through Stancetaking",
        "track": "main",
        "status": "Long Findings",
        "keywords": "stancetaking; community variation; sociolinguistics; community identity",
        "authors": "",
        "rating": "",
        "confidence": "5;4;2",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "f1y1tG5pAE",
        "title": "The BLA Benchmark: Investigating Basic Language Abilities of Pre-Trained Multimodal Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Dataset;Evaluation;Zero-shot;Prompting;Visual Grounding;Language Constructions",
        "authors": "",
        "rating": "",
        "confidence": "5;5;4",
        "correctness": "4;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "f34v92a86l",
        "title": "Efficient Grammatical Error Correction Via Multi-Task Training and Optimized Training Schedule",
        "track": "main",
        "status": "Long Main",
        "keywords": "Grammatical error correction;Multi-task training;Sequence-to-sequence;Fine-tuning",
        "authors": "",
        "rating": "",
        "confidence": "4;5;5;4",
        "correctness": "2;4;5;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "f42iMss8J3",
        "title": "Visual Storytelling with Question-Answer Plans",
        "track": "main",
        "status": "Long Findings",
        "keywords": "visual storytelling;multimodaility;story generation",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "f6S1411OlZ",
        "title": "Towards a Unified Framework for Reference Retrieval and Related Work Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "related work generation;lexicon-enhance retrieval;instruction tuning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "f7eqyX0nJP",
        "title": "ZEROTOP: Zero-Shot Task-Oriented Semantic Parsing using Large Language Models",
        "track": "main",
        "status": "Short Main",
        "keywords": "zero-shot;semantic parsing;mtop;large language models;llm;QA datasets",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "fCvJrponuK",
        "title": "Sparse Black-Box Multimodal Attack for Vision-Language Adversary Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Vision-and-Language;adversarial learning;multimodal attack;black-box attack",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4;4",
        "correctness": "2;3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "fEuslEGN0j",
        "title": "Fine-tuned LLMs Know More, Hallucinate Less with Few-Shot Sequence-to-Sequence Semantic Parsing over Wikidata",
        "track": "main",
        "status": "Long Main",
        "keywords": "knowledge base question answering;Wikidata;semantic parsing;large language models",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "fG6zH1LBHE",
        "title": "MediaHG: Rethinking Eye-catchy Features in Social Media Headline Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "headline generation\uff0cstyle-content attractiveness\uff0csocial media",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "fK6N4R6TpF",
        "title": "NERvous About My Health: Constructing a Bengali Medical Named Entity Recognition Dataset",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Named Entity Recognition;Natural Language Processing;Consumer Health",
        "authors": "",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "fL8AKDvELp",
        "title": "HyperRouter: Towards Efficient Training and Inference of Sparse Mixture of Experts",
        "track": "main",
        "status": "Short Main",
        "keywords": "Sparse mixture of experts;hypernetwork;efficient training of LLMs;large language models",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "fLJVvFGFEE",
        "title": "Representativeness as a Forgotten Lesson for Multilingual and Code-switched Data Collection and Preparation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multilingualism;Code-switching;representativeness;data preparation;annotation;transcription",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "fM7x9Lvb9r",
        "title": "Controllable Contrastive Generation for Multilingual Biomedical Entity Linking",
        "track": "main",
        "status": "Long Main",
        "keywords": "Multilingual Biomedical Entity Linking;Controllable Generation;Contrastive Learning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3;4",
        "correctness": "3;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "fNi7eet4Qc",
        "title": "Prompt-Based Editing for Text Style Transfer",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Text style transfer; Prompt-based editing; Large language models",
        "authors": "",
        "rating": "",
        "confidence": "4;5;5",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "fNlSVIsbIT",
        "title": "HoneyBee: Progressive Instruction Finetuning of Large Language Models for Materials Science",
        "track": "main",
        "status": "Long Findings",
        "keywords": "materials science;LLaMa;instructions based finetuning;progressive finetuning;feedback based instructions",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "fONyQKyvsY",
        "title": "Analysing State-Backed Propaganda Websites: a New Dataset and Linguistic Study",
        "track": "main",
        "status": "Short Main",
        "keywords": "misinformation;disinformation;social media;dataset;social science",
        "authors": "",
        "rating": "",
        "confidence": "4;3;2",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "fOoZipX9z3",
        "title": "Grounding Visual Illusions in Language: Do Vision-Language Models Perceive Illusions Like Humans?",
        "track": "main",
        "status": "Long Main",
        "keywords": "vision-language model;visual illusion;grounding",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "5;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "fRpif5Sflc",
        "title": "Rumor Detection on Social Media with Crowd Intelligence and ChatGPT-Assisted Networks",
        "track": "main",
        "status": "Long Main",
        "keywords": "Rumor Detection; Crowd Intelligence; Large Language Model; Heterogeneous Graph; Semantic Feature Learning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "5;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "fXyoHAVffT",
        "title": "Unsupervised Candidate Answer Extraction through Differentiable Masker-Reconstructor Model",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Candidate Answer Extraction;Self-consitency Learning;Unsupervised Learning;Masker-Reconstructor Model",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "fbbbbfhAxC",
        "title": "Cross-lingual Transfer Can Worsen Bias in Sentiment Analysis",
        "track": "main",
        "status": "Long Main",
        "keywords": "bias;fairness;multilingual;sentiment analysis;counterfactual;contrastive",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "feiAVaSXdb",
        "title": "Measuring and Narrowing the Compositionality Gap in Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "language modeling;prompting;question answering;language model tool use",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "fgQ7JQoBIM",
        "title": "C-STS: Conditional Semantic Textual Similarity",
        "track": "main",
        "status": "Long Main",
        "keywords": "Conditional similarity;Sentence similarity;Dataset",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "fhEkqMyvb0",
        "title": "Disentangling Structure and Style: Political Bias Detection in News by Inducing Document Hierarchy",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Natural Language Processing;NLP Applications;Political Bias;Journalism",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "fi90p5364y",
        "title": "Generating Commonsense Counterfactuals for Stable Relation Extraction",
        "track": "main",
        "status": "Long Main",
        "keywords": "Counterfactual Data Augmentation;Commonsense-constrained Generation;Relation Extraction",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "fkAKjbRvxj",
        "title": "Information Value: Measuring Utterance Predictability as Distance from Plausible Alternatives",
        "track": "main",
        "status": "Long Main",
        "keywords": "surprisal;alternatives;acceptability;reading times;predictability",
        "authors": "",
        "rating": "",
        "confidence": "5;4;2;4",
        "correctness": "4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "fkmSyrSjnq",
        "title": "Topic-Informed Dialogue Summarization using Topic Distribution and Prompt-based Modeling",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Dialogue Summarization;Topic Distribution;Topic-Informed Prompt",
        "authors": "",
        "rating": "",
        "confidence": "2;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "flkXLt9WKn",
        "title": "Dialogue Chain-of-Thought Distillation for Commonsense-aware Conversational Agents",
        "track": "main",
        "status": "Long Main",
        "keywords": "Commonsense Reasoning;Dialogue;Large Language Model",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "3;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "fonxcS8gqM",
        "title": "Improving Long Document Topic Segmentation Models With Enhanced Coherence Modeling",
        "track": "main",
        "status": "Long Main",
        "keywords": "topic segmentation;text coherence;semantic similarity;sentence structure;contrastive learning",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "fqKoLPfCba",
        "title": "Large-Scale and Multi-Perspective Opinion Summarization with Diverse Review Subsets",
        "track": "main",
        "status": "Long Findings",
        "keywords": "opinion summarization;multi-document summarization;large-scale;multi-perspective;contrastive learning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "fqWbXPX99P",
        "title": "CT-GAT: Cross-Task Generative Adversarial Attack based on Transferability",
        "track": "main",
        "status": "Long Main",
        "keywords": "Adversarial Attacks;Transferability;Generative Methods",
        "authors": "",
        "rating": "",
        "confidence": "3;4;2;3",
        "correctness": "3;2;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "fsGowIsscZ",
        "title": "A Diachronic Perspective on User Trust in AI under Uncertainty",
        "track": "main",
        "status": "Long Main",
        "keywords": "trust;calibration;confidence;collaboration",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ft0c1K3492",
        "title": "SciRepEval: A Multi-Format Benchmark for Scientific Document Representations",
        "track": "main",
        "status": "Long Main",
        "keywords": "Scientific tasks benchmark;multi task learning;task specific embeddings",
        "authors": "",
        "rating": "",
        "confidence": "3;2;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "fvGJOVkm0b",
        "title": "EntSUMv2: Dataset, Models and Evaluation for More Abstractive Entity-Centric Summarization",
        "track": "main",
        "status": "Short Main",
        "keywords": "summarization;entity;dataset;evaluation",
        "authors": "",
        "rating": "",
        "confidence": "4;2;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "fwA8iKyIlk",
        "title": "Elaborative Simplification as Implicit Questions Under Discussion",
        "track": "main",
        "status": "Long Main",
        "keywords": "text simplification;elaborative simplification;questions under discussion",
        "authors": "",
        "rating": "",
        "confidence": "5;3;5",
        "correctness": "4;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "fwmZinFwgX",
        "title": "Enhancing Reasoning Capabilities by Instruction Learning and Chain-of-Thoughts for Implicit Discourse Relation Recognition",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Implicit discourse relation recognition;Instruction learning;In-context learning;Chain-of-Thoughts",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "fxdvWG4rJe",
        "title": "Towards Making the Most of ChatGPT for Machine Translation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Machine Translation;Large Language Model;Prompt Engineering",
        "authors": "",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "4;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "fxotfo1j8T",
        "title": "Navigating the Grey Area: How Expressions of Uncertainty and Overconfidence Affect Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "expressions of uncertainty;analysis of language models",
        "authors": "",
        "rating": "",
        "confidence": "2;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "fyza2OQ9NI",
        "title": "MathDial: A Dialogue Tutoring Dataset with Rich Pedagogical Properties Grounded in Math Reasoning Problems",
        "track": "main",
        "status": "Long Findings",
        "keywords": "dialogue;dataset;collection;response generation;natural language generation;math;reasoning;tutoring",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4;4",
        "correctness": "3;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "fzb2sxexWN",
        "title": "Semi-automatic Data Enhancement for Document-Level Relation Extraction with Distant Supervision from Large Language Models",
        "track": "main",
        "status": "Short Main",
        "keywords": "Long Context\uff0cDocument-level\uff0cRelation Extraction;Large Language Model",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "g04NBFnIxb",
        "title": "ViPE: Visualise Pretty-much Everything",
        "track": "main",
        "status": "Long Main",
        "keywords": "Visual metaphors;music video generation;text-to-image synthesis;abstract visualization;diffusion models for abstract art;synthetic data generation;unsupervised label generation",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4;2",
        "correctness": "3;3;5;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "g0wzziJSmN",
        "title": "The Effect of Scaling, Retrieval Augmentation and Form on the Factual Consistency of Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "consistency;evaluation;large language models;retrieval-augmentation;causal analysis",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "g1LLeiHX0P",
        "title": "Representative Demonstration Selection for In-Context Learning with Two-Stage Determinantal Point Process",
        "track": "main",
        "status": "Long Main",
        "keywords": "In-Context Learning;Representative Subset Selection;Determinantal Point Process",
        "authors": "",
        "rating": "",
        "confidence": "2;4;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "g1Q9Uu8lCp",
        "title": "xDial-Eval: A Multilingual Open-Domain Dialogue Evaluation Benchmark",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Automatic Dialogue Evaluation;Multilingual Dialogue;Large Language Models",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "g3VOQpuqlF",
        "title": "Adapting Pretrained Text-to-Text Models for Long Text Sequences",
        "track": "main",
        "status": "Long Findings",
        "keywords": "long context;summarization",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "g3faCfrwm7",
        "title": "Just Ask for Calibration: Strategies for Eliciting Calibrated Confidence Scores from Language Models Fine-Tuned with Human Feedback",
        "track": "main",
        "status": "Short Main",
        "keywords": "calibration;RLHF;language model;verbalized probability",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4;4",
        "correctness": "3;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "g4FAvRcSuf",
        "title": "Self-Supervised Behavior Cloned Transformers are Path Crawlers for Text Games",
        "track": "main",
        "status": "Short Findings",
        "keywords": "text games;reinforcement learning;behavior cloning;self-supervision",
        "authors": "",
        "rating": "",
        "confidence": "3;3;2",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "g84UrdUwBA",
        "title": "Harnessing Black-Box Control to Boost Commonsense in LM's Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "controllable text generation;generative commonsense reasoning",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "g8OqNaz6dY",
        "title": "Efficient Algorithms for Recognizing Weighted Tree-Adjoining Languages",
        "track": "main",
        "status": "Long Main",
        "keywords": "algorithms;parsing;semirings;tree adjoining grammars;linear indexed grammars;embedded pushdown automata",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;5;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "gAzBhetShk",
        "title": "Exploring Chain of Thought Style Prompting for Text-to-SQL",
        "track": "main",
        "status": "Long Main",
        "keywords": "Text-to-Sql;Prompt engineering;Chain-of-Thought;Least-to-Most;Question Decomposition.",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "gBI7thSo0X",
        "title": "Values, Ethics, Morals? On the Use of Moral Concepts in NLP Research",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Ethics;Morality;Moral Values;Natural Language Processing;Survey",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "gGmccVXoy2",
        "title": "Decomposing Complex Queries for Tip-of-the-tongue Retrieval",
        "track": "main",
        "status": "Long Findings",
        "keywords": "information retrieval; large language models; query decomposition",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "gI11vXg1W4",
        "title": "PRCA: Fitting Black-Box Large Language Models for Retrieval Question Answering via Pluggable Reward-Driven Contextual Adapter",
        "track": "main",
        "status": "Long Main",
        "keywords": "Retrieval Question Answering;Black-Box LLMs;Retrieval Augmentation;Pluggable Reward-Driven Contextual Adapter",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "gJXydPLBkt",
        "title": "QUDeval: The Evaluation of Questions Under Discussion Discourse Parsing",
        "track": "main",
        "status": "Long Main",
        "keywords": "discourse; questions under discussion; QUD; evaluation",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "gJZqSRfV21",
        "title": "ReLM: Leveraging Language Models for Enhanced Chemical Reaction Prediction",
        "track": "main",
        "status": "Short Findings",
        "keywords": "graph neural networks;chemical reaction",
        "authors": "",
        "rating": "",
        "confidence": "5;4;5",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "gQUDsNE3Lh",
        "title": "HARE: Explainable Hate Speech Detection with Step-by-Step Reasoning",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Hate Speech Detection;Large Language Models",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "gQeZoe2j3v",
        "title": "Mulan: A Multi-Level Alignment Model for Video Question Answering",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Video Question Answering;Multi-Level Alignment;Contrastive Learning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "2;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "gUKVyjoQBG",
        "title": "COHESENTIA: A Novel Benchmark of Incremental versus Holistic Assessment of Coherence in Generated Texts",
        "track": "main",
        "status": "Long Main",
        "keywords": "coherence;benchmark;cohesion;consistency;relevance;linguistic theory;gpt;nlp applications",
        "authors": "",
        "rating": "",
        "confidence": "3;4;5",
        "correctness": "4;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "gVTtkPJbRq",
        "title": "GPT-4 as an Effective Zero-Shot Evaluator for Scientific Figure Captions",
        "track": "main",
        "status": "Short Findings",
        "keywords": "text generation;scientific figure caption;caption evaluation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "gWWjz9NBo9",
        "title": "PromptMix: A Class Boundary Augmentation Method for Large Language Model Distillation",
        "track": "main",
        "status": "Long Main",
        "keywords": "large language models;knowledge distillation;text classification;few-shot learning",
        "authors": "",
        "rating": "",
        "confidence": "4;5;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "gXq1cwkUZc",
        "title": "Query Rewriting in Retrieval-Augmented Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "large language model;retrieval augmentation;query rewriting.",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4;3",
        "correctness": "2;3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "gZhvtIRu7i",
        "title": "MILDSum: A Novel Benchmark Dataset for Multilingual Summarization of Indian Legal Case Judgments",
        "track": "main",
        "status": "Short Main",
        "keywords": "Cross-Lingual Summarization;Multilingual corpus for Summarization;Summarization-Translation Pipeline;Legal NLP",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "gZykO63OUh",
        "title": "DREAM: Deployment of Recombination and Ensembles in Argument Mining",
        "track": "main",
        "status": "Long Main",
        "keywords": "Argument Mining;Recombination;Ensemble Methods",
        "authors": "",
        "rating": "",
        "confidence": "4;4;2",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "gccSE5vDZ7",
        "title": "Multilingual Simplification of Medical Texts",
        "track": "main",
        "status": "Long Main",
        "keywords": "Simplification;Medical Simplification;Multilingual",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "gd8TxhKoLv",
        "title": "PROTEGE: Prompt-based Diverse Question Generation from Web Articles",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large Language Models;Question Generation;Question Answering;Diversity;Fidelity",
        "authors": "",
        "rating": "",
        "confidence": "2;3;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "gdUBK65fwn",
        "title": "LLM-Adapters: An Adapter Family for Parameter-Efficient Fine-Tuning of Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Parameter-Efficient Fine-Tuning;Large Language Models",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4;4",
        "correctness": "4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ggTNeg2fem",
        "title": "Multimodal Automated Fact-Checking: A Survey",
        "track": "main",
        "status": "Long Findings",
        "keywords": "fact checking;multimodality;survey",
        "authors": "",
        "rating": "",
        "confidence": "5;3;3",
        "correctness": "3;2;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ghF1EB6APx",
        "title": "Cross-Modal Conceptualization in Bottleneck Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "interpretability;cross-modal learning;concept-based models;cross-attention mechanism;robustness",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "gjrs5oF8TC",
        "title": "INVITE: a Testbed of Automatically Generated Invalid Questions to Evaluate Large Language Models for Hallucinations",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Large Language Models;Hallucinations;Question Answering",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "gkQo3CoPLd",
        "title": "GeoLM: Empowering Language Models for Geospatially Grounded Language Understanding",
        "track": "main",
        "status": "Long Main",
        "keywords": "geospatial grounding;language model",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "glxrubmH91",
        "title": "RAPL: A Relation-Aware Prototype Learning Approach for Few-Shot Document-Level Relation Extraction",
        "track": "main",
        "status": "Long Main",
        "keywords": "Document-Level Relation Extraction;Few-Shot Learning;Metric-Based Meta-Learning;Relation-Aware Prototype Learning",
        "authors": "",
        "rating": "",
        "confidence": "3;4;2",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "gmVEVn0Qi5",
        "title": "InterroLang: Exploring NLP Models and Datasets through Dialogue-based Explanations",
        "track": "main",
        "status": "Long Findings",
        "keywords": "explainability;dialogue;interpretability;dataset analysis;conversational ai;simulatability",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "goH9e5Vd44",
        "title": "Licon: A Diverse, Controllable and Challenging Linguistic Concept Learning Benchmark",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Concept Learning;Zero-shot Learning;Linguistic Description",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "gqkg54QNDY",
        "title": "ViSoBERT: A Pre-Trained Language Model for Vietnamese Social Media Text Processing",
        "track": "main",
        "status": "Long Main",
        "keywords": "Language Models;Social Media Processing;Low resource",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "gslZifaE3t",
        "title": "How to Determine the Most Powerful Pre-trained Language Model without Brute Force Fine-tuning? An Empirical Survey",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Pre-trained Language Models;Transfer Learning;Transferability Estimation;Model Selection",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "gybvlVXT6z",
        "title": "Black-Box Tuning of Vision-Language Models with Effective Gradient Approximation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Prompt Tuning;Black-box Model;Vision-language Model",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "gzRBs4gIbz",
        "title": "Non-autoregressive Streaming Transformer for Simultaneous Translation",
        "track": "main",
        "status": "Long Main",
        "keywords": "simultaneous translation;non-autoregressive generation",
        "authors": "",
        "rating": "",
        "confidence": "4;5;2",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "h00GHjWDEp",
        "title": "LINC: A Neurosymbolic Approach for Logical Reasoning by Combining Language Models with First-Order Logic Provers",
        "track": "main",
        "status": "Long Main",
        "keywords": "large language models;logical reasoning;neuro-symbolic AI",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "h1YhUpPKEq",
        "title": "Non-Programmers Can Label Programs Indirectly via Active Examples: A Case Study with Text-to-SQL",
        "track": "main",
        "status": "Long Main",
        "keywords": "Semantic Parsing; Annotation; Code generation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "5;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.666666666666667,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "h1nUUpmvpf",
        "title": "Cross-Cultural Analysis of Human Values, Morals, and Biases in Folk Tales",
        "track": "main",
        "status": "Long Main",
        "keywords": "values;morality;bias;folk tales",
        "authors": "",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "h4NNcIZUHT",
        "title": "DiSTRICT: Dialogue State Tracking with Retriever Driven In-Context Tuning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Dialogue state tracking;in-context tuning;semantic retrieval",
        "authors": "",
        "rating": "",
        "confidence": "4;5;5",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "h5gum6ximf",
        "title": "Don't waste a single annotation: improving single-label classifiers through soft labels",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Don't Waste a Single Annotation: Improving Single-Label Classifiers Through Soft Labels",
        "authors": "",
        "rating": "",
        "confidence": "5;4;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "h96N32OkAx",
        "title": "CoLT5: Faster Long-Range Transformers with Conditional Computation",
        "track": "main",
        "status": "Long Main",
        "keywords": "long context;conditional computation;efficient nlp",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "hA8h2KtSv2",
        "title": "Stop Uploading Test Data in Plain Text: Practical Strategies for Mitigating Data Contamination by Evaluation Benchmarks",
        "track": "main",
        "status": "Short Main",
        "keywords": "data contamination;contamination;evaluation;test data;benchmarks;closed models;pretraining",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "hCsppacsqS",
        "title": "MuG: A Multimodal Classification Benchmark on Game Data with Tabular, Textual, and Visual Fields",
        "track": "main",
        "status": "Long Findings",
        "keywords": "multimodal classification benchmark;resources and evaluation;multimodal graph neural network",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "hDzfqmLrol",
        "title": "DeltaScore: Fine-Grained Story Evaluation with Perturbations",
        "track": "main",
        "status": "Long Findings",
        "keywords": "story;evaluation;metric;PLM",
        "authors": "",
        "rating": "",
        "confidence": "3;3;2",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "hEWgNQF1TM",
        "title": "Parameter-Efficient Language Model Tuning with Active Learning in Low-Resource Settings",
        "track": "main",
        "status": "Long Main",
        "keywords": "parameter-efficient fine-tuning;active learning;low-resource settings",
        "authors": "",
        "rating": "",
        "confidence": "3;2;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "hEglNMGeqj",
        "title": "Better Together: Enhancing Generative Knowledge Graph Completion with Language Models and Neighborhood Information",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Knowledge graphs;Knowledge graph completion;Language models;Graph neighborhood;Transformer",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "hGUu750pcx",
        "title": "Exploring Large Language Models for Multi-Modal Out-of-Distribution Detection",
        "track": "main",
        "status": "Long Findings",
        "keywords": "OOD Detection",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "2;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "hInB4JIQ5P",
        "title": "CoEdIT: Text Editing by Task-Specific Instruction Tuning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Text Editing;Instruction Tuning;Large Language Models",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "hMqRphmoM9",
        "title": "Prompting is not a substitute for probability measurements in large language models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Models;Behavioral Testing of Language Models;Metalinguistic Judgment;Prompting;Minimal Pairs",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "hNSbSaD1WC",
        "title": "The Cost of Compression: Investigating the Impact of Compression on Parametric Knowledge in Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Pruning;Quantization;Language Models",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "hPr1QC623H",
        "title": "Is Probing All You Need? Indicator Tasks as an Alternative to Probing Embedding Spaces",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Probing;Probe;Indicator;Word Representations;Embedding Space;Interpretability;Context;Social Bias;Morphology;Semantics;Gender;Concept Erasure",
        "authors": "",
        "rating": "",
        "confidence": "2;2;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "hRJZIsC9VU",
        "title": "Introducing Rhetorical Parallelism Detection: A New Task with Datasets, Metrics, and Baselines",
        "track": "main",
        "status": "Long Main",
        "keywords": "rhetorical parallelism;sequence labeling;NLP;Latin;Chinese;resource",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "5;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "hTLIAYTi5w",
        "title": "ClozEx: A Task toward Generation of English Cloze Explanation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "language assessment;english education;text generation;dataset",
        "authors": "",
        "rating": "",
        "confidence": "4;5;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "hUWrmo7nNh",
        "title": "Bi-Drop: Enhancing Fine-tuning Generalization via Synchronous sub-net Estimation and Optimization",
        "track": "main",
        "status": "Long Findings",
        "keywords": "pretrained language model;adaptive sub-net Optimization",
        "authors": "",
        "rating": "",
        "confidence": "3;3;2",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "hWNsvpWfhy",
        "title": "Localizing Active Objects from Egocentric Vision with Symbolic World Knowledge",
        "track": "main",
        "status": "Long Main",
        "keywords": "Object state change;Pre-conditions;Post-conditions;Egocentric videos;Active grounding;Multimodal",
        "authors": "",
        "rating": "",
        "confidence": "4;5;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "hXXyBtlo4D",
        "title": "MMNMT: Modularizing Multilingual Neural Machine Translation with Flexibly Assembled MoE and Dense Blocks",
        "track": "main",
        "status": "Long Main",
        "keywords": "MoE;Multilingual Machine Translation;Modularizing",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "haPIkA8aOk",
        "title": "Adaptation with Self-Evaluation to Improve Selective Prediction in LLMs",
        "track": "main",
        "status": "Long Findings",
        "keywords": "large language models;selective prediction;adaptation with self-evaluation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "hcDE6sOEfu",
        "title": "Ignore This Title and HackAPrompt: Exposing Systemic Vulnerabilities of LLMs Through a Global Prompt Hacking Competition",
        "track": "main",
        "status": "Long Main",
        "keywords": "Ignore This Title: Expose Systemic Vulnerabilities of LLMs through a Global Scale Prompt Hacking Competition",
        "authors": "",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "4;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "hdxMdgKddK",
        "title": "DocTrack: A Visually-Rich Document Dataset Really Aligned with Human Eye Movement for Machine Reading",
        "track": "main",
        "status": "Long Findings",
        "keywords": "visually-rich document;dataset;eye tracking;human reading order;preordering",
        "authors": "",
        "rating": "",
        "confidence": "2;3;4;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "hfZKiBh4zS",
        "title": "MPrompt: Exploring Multi-level Prompt Tuning for Machine Reading Comprehension",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Question Answering;Prompt Learning;Soft Prompt;Machine Reading Comprehension",
        "authors": "",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "hfmmVWJecp",
        "title": "Non-Compositionality in Sentiment: New Data and Analyses",
        "track": "main",
        "status": "Short Findings",
        "keywords": "sentiment analysis;compositionality;data annotation",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;3;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "hgF8In32gL",
        "title": "Text encoders bottleneck compositionality in contrastive vision-language models",
        "track": "main",
        "status": "Long Main",
        "keywords": "vision-language;text encoders;interpretability",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "hiJ2hzwghq",
        "title": "BiasX: \u201cThinking Slow\u201d in Toxic Content Moderation with Explanations of Implied Social Biases",
        "track": "main",
        "status": "Short Main",
        "keywords": "Social biases;Toxicity moderation;Human-AI collaboration;Free-text explanations",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "hjEnagXGYV",
        "title": "Time-Considerable Dialogue Models via Reranking by Time Dependency",
        "track": "main",
        "status": "Long Findings",
        "keywords": "dialogue model;dialogue system;response generation;time information",
        "authors": "",
        "rating": "",
        "confidence": "2;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "hl6TVdQjeh",
        "title": "Robustness Tests for Automatic Machine Translation Metrics with Adversarial Attacks",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Automatic metric;textual adversarial attack;machine translation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "hlqIu07ics",
        "title": "Towards a Mechanistic Interpretation of Multi-Step Reasoning Capabilities of Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "model interpretation;reasoning;attention mechanism;large language model",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "hmOwOZWzYE",
        "title": "GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints",
        "track": "main",
        "status": "Short Main",
        "keywords": "efficient nlp;multi-query attention;fast inference",
        "authors": "",
        "rating": "",
        "confidence": "4;2;2",
        "correctness": "4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "hn0B3jTlwE",
        "title": "Goodtriever: Adaptive Toxicity Mitigation with Retrieval-augmented Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "toxicity mitigation;retrieval-augmented;continual learning",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "hoO5anfnRk",
        "title": "EDIS: Entity-Driven Image Search over Multimodal Web Content",
        "track": "main",
        "status": "Long Main",
        "keywords": "Image search; Cross-modal retrieval; Multimodality fusion",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "hpUNou0UaJ",
        "title": "impact of sample selection on in-context learning for entity extraction from scientific writing",
        "track": "main",
        "status": "Long Findings",
        "keywords": "GPT-3.5;in-context learning;sample selection;entity;scientific",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "hsjQHAM8MV",
        "title": "Can We Edit Factual Knowledge by In-Context Learning?",
        "track": "main",
        "status": "Long Main",
        "keywords": "In-Context Learning;Knowledge Editing;Large Language Models",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "hsptWISmi6",
        "title": "Post-hoc Utterance Refining Method by Entity Mining for Faithful Knowledge Grounded Conversations",
        "track": "main",
        "status": "Long Main",
        "keywords": "Utterance Refining;Knowledge Grounded Conversation;Entity Mining;Entity-level Hallucination",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "htulPWUheU",
        "title": "Cross-Document Event Coreference Resolution on Discourse Structure",
        "track": "main",
        "status": "Long Main",
        "keywords": "Event Coreference Resolution;Discourse Structure;Shortest Dependency Path",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "hv3VpXDIh8",
        "title": "CodeTransOcean: A Comprehensive Multilingual Benchmark for Code Translation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Code translation;Multilingual datasets;Multilingual modeling;Large language models",
        "authors": "",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "hxExXDMwcc",
        "title": "PlugMed: Improving Specificity in Patient-Centered Medical Dialogue Generation using In-Context Learning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Medical;Dialogue Generation;In-context Learning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "hyBwGem8OS",
        "title": "InteMATs: Integrating Granularity-Specific Multilingual Adapters for Cross-Lingual Transfer",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multilingual Language Model Enhancement;Cross-lingual Transfer;Parameter-Efficient Method",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "i0RfSS9CUU",
        "title": "Active Learning Principles for In-Context Learning with Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "active learning;in-context learning;few-shot learning;large language models",
        "authors": "",
        "rating": "",
        "confidence": "4;4;2",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "i0vMIpaEn4",
        "title": "Adaptive Policy with Wait-k Model for Simultaneous Translation",
        "track": "main",
        "status": "Long Main",
        "keywords": "simultaneous machine translation;wait-k;adaptive policy;read/write supervision signals",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "i17SCD0YDI",
        "title": "KEBAP: Korean Error Explainable Benchmark Dataset for ASR and Post-processing",
        "track": "main",
        "status": "Long Main",
        "keywords": "Automatic Speech Recognition (ASR);Error Explainable Benchmark;Post-procssing;Recognition Accuracy;User Readability",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "i1KSRMVlST",
        "title": "Cognitive Dissonance: Why Do Language Model Outputs Disagree with Internal Representations of Truthfulness?",
        "track": "main",
        "status": "Short Main",
        "keywords": "language models;truthfulness;question answering;interpretability",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "i65hZUPwuQ",
        "title": "Mirages. On Anthropomorphism in Dialogue Systems",
        "track": "main",
        "status": "Long Main",
        "keywords": "Dialogue systems;conversational AI;anthropomorphism;ethics",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "i7ifZu49kW",
        "title": "Improving Neural Machine Translation by Multi-Knowledge Integration with Prompting",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Machine Translation;Multi-Knowledge Integration;Prompting",
        "authors": "",
        "rating": "",
        "confidence": "4;5;3",
        "correctness": "3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "iAeDYlEXrM",
        "title": "A Critical Analysis of Document Out-of-Distribution Detection",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Document Understanding;Pretraining;Out-of-Distribution;Document intelligence;Robustness",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "iBv0M8WrFi",
        "title": "A Cheaper and Better Diffusion Language Model with Soft-Masked Noise",
        "track": "main",
        "status": "Long Main",
        "keywords": "Diffusion Language Model;Soft-masked Noise",
        "authors": "",
        "rating": "",
        "confidence": "4;3;5;4",
        "correctness": "4;3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "iCLJHkE5s1",
        "title": "TRAMS: Training-free Memory Selection for Long-range Language Modeling",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Language Model; Inference Strategy; Long-context Modeling",
        "authors": "",
        "rating": "",
        "confidence": "2;3;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "iCNoSVJl2y",
        "title": "CCIM: Cross-modal Cross-lingual Interactive Image Translation",
        "track": "main",
        "status": "Short Findings",
        "keywords": "cross-modal cross-lingual interactive decoding;text image machine translation;text image recogntion",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "iDBUssVu5Z",
        "title": "Text Fact Transfer",
        "track": "main",
        "status": "Long Main",
        "keywords": "Text Generation;Factuality;Text Style Transfer;Information Extraction",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "iDQBP0cvzX",
        "title": "Best of Both Worlds: Towards Improving Temporal Knowledge Base Question Answering via Targeted Fact Extraction",
        "track": "main",
        "status": "Short Main",
        "keywords": "Temporal KBQA;Fact Extraction;Semantic Parsing;Questional Answering",
        "authors": "",
        "rating": "",
        "confidence": "1;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "iDZQG9aUGH",
        "title": "Bayesian Multi-Task Transfer Learning for Soft Prompt Tuning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "prompt tuning;parameter-efficient fine-tuning;transfer learning;bayesian method",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3;5",
        "correctness": "3;4;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "iEACF99lQz",
        "title": "Merging Generated and Retrieved Knowledge for Open-Domain QA",
        "track": "main",
        "status": "Long Main",
        "keywords": "large language model;retrieval-augmented language model;open-domain question answering",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "iHb4MOMyOd",
        "title": "Bipartite Graph Pre-training for Unsupervised Extractive Summarization with Graph Convolutional Auto-Encoders",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Bipartite Graph;Graph Pre-training;Unsupervised Extractive Summarization;Graph Convolutional Auto-Encoders",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "iIoHir5Hyg",
        "title": "Well Begun is Half Done: Generator-agnostic Knowledge Pre-Selection for Knowledge-Grounded Dialogue",
        "track": "main",
        "status": "Long Main",
        "keywords": "Knowledge-grounded Dialogue;Knowledge Selection;Generator-agnostic",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "iIpnncYQZb",
        "title": "Toward a Critical Toponymy Framework for Named Entity Recognition: A Case Study of Airbnb in New York City",
        "track": "main",
        "status": "Long Main",
        "keywords": "critical toponymy;named entity recognition;geographic information science;gentrification;new york city;airbnb;place",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "iLTNcB3601",
        "title": "Improving End-to-End Speech Processing by Efficient Text Data Utilization with Latent Synthesis",
        "track": "main",
        "status": "Long Findings",
        "keywords": "joint speech-text learning;spoken language understanding;speech recognition",
        "authors": "",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "iMnwXQemEr",
        "title": "Discovering Universal Geometry in Embeddings with ICA",
        "track": "main",
        "status": "Long Main",
        "keywords": "Embeddings;Independent Component Analysis;Principal Component Analysis;Cross-lingual;Interpretability;Isotropy;Whitening",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "iO5YOddOyG",
        "title": "Is ChatGPT a Good Multi-Party Conversation Solver?",
        "track": "main",
        "status": "Long Findings",
        "keywords": "large language models;multi-party conversations;zero-shot;in-context learning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "iRISsJCzTA",
        "title": "Controllable Chest X-Ray Report Generation from Longitudinal Representations",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Controllable Report Generation;Longitudinal Chest X-Rays;Multimodal Transformer",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "iRIj0OvFG1",
        "title": "Intuitive Multilingual Audio-Visual Speech Recognition with a Single-Trained Model",
        "track": "main",
        "status": "Short Findings",
        "keywords": "audio-visual speech recognition;speech recognition;multimodal;multilingual",
        "authors": "",
        "rating": "",
        "confidence": "4;4;2",
        "correctness": "4;2;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "iVINvItqhb",
        "title": "GradSim: Gradient-Based Language Grouping for Effective Multilingual Training",
        "track": "main",
        "status": "Long Main",
        "keywords": "Effective multilingual learning;language grouping;gradient-based similarity",
        "authors": "",
        "rating": "",
        "confidence": "5;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "iWVpissNEP",
        "title": "Towards Building More Robust NER datasets: An Empirical Study on NER Dataset Bias from a Dataset Difficulty View",
        "track": "main",
        "status": "Long Main",
        "keywords": "Robustness;OOD Generalization;Dataset Bias;NER",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "iammae3CbG",
        "title": "Prototype-based HyperAdapter for Sample-Efficient Multi-task Tuning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Multi-task learning;Fine-tuning;Sample-efficiency;Prototype learning",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4;4",
        "correctness": "4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "iaxdEnxgju",
        "title": "FaLA: Fast Linear Adaptation for Replacing Backbone Models on Edge Devices",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Foundation Models;Personalization;Efficient Parameter Tuning;On device",
        "authors": "",
        "rating": "",
        "confidence": "4;4;2",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ifuvyCdLro",
        "title": "Medical Text Simplification: Optimizing for Readability with Unlikelihood Training and Reranked Beam Search Decoding",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Medical Text;Simplification;Healthcare;Beam Search Decoding;Unlikelihood Learning",
        "authors": "",
        "rating": "",
        "confidence": "2;3;4",
        "correctness": "4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ii9ZoryPH2",
        "title": "DecoMT: Decomposed Prompting for Machine Translation Between Related Languages using Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "NLP;LLM;few-shot prompting;Machine Translation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "iiWP7khhwP",
        "title": "Long-Range Language Modeling with Selective Cache",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Language Modeling;Long Dependency;Long-term Memory",
        "authors": "",
        "rating": "",
        "confidence": "5;3;2",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "iipuAqcPGL",
        "title": "Can Large Language Models Capture Dissenting Human Voices?",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Model;Natural Language Inference;Human Disagreement",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ilCMZV0Qdl",
        "title": "Exploiting Emotion-Semantic Correlations for Empathetic Response Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Emotion;Semantic;Correlation;Empathetic;Dialogue;Generation",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "in5xvBrMHv",
        "title": "Complex Event Schema Induction with Knowledge-Enriched Diffusion Model",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Complex Event Schema Induction;Diffusion Model;Large Language Model",
        "authors": "",
        "rating": "",
        "confidence": "2;5;4",
        "correctness": "2;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "inN4TdboJX",
        "title": "Noisy Exemplars Make Large Language Models More Robust: A Domain-Agnostic Behavioral Analysis",
        "track": "main",
        "status": "Short Main",
        "keywords": "Large Language Models;Robustness;Perturbation Analysis;Few-shot Prompting;Chain-of-thought",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "islVqaCzfa",
        "title": "InstructCoder: Empowering Language Models to Edit Code",
        "track": "main",
        "status": "Reject",
        "keywords": "Code Edit;Instruction Finetuning",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ivSJdhcuTi",
        "title": "Out-of-Distribution Generalization in Natural Language Processing: Past, Present, and Future",
        "track": "main",
        "status": "Long Main",
        "keywords": "Out-of-Distribution Generalization; OOD Robustness",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "iw4zUlc5OF",
        "title": "On the Zero-Shot Generalization of Machine-Generated Text Detectors",
        "track": "main",
        "status": "Short Findings",
        "keywords": "detection;NLG;zero-shot generalization",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "2;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ix6h7Bkq62",
        "title": "Standardizing Distress Analysis: Emotion-Driven Distress Identification and Cause Extraction (DICE) in Multimodal Online Posts",
        "track": "main",
        "status": "Long Main",
        "keywords": "Hate speech;Social media;Multimodal online posts;Distress content;Causal phrases;Emotional information;Zero-shot strategy",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "2;2;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "iytcEQ5I5v",
        "title": "SDOH-NLI: a Dataset for Inferring Social Determinants of Health from Clinical Notes",
        "track": "main",
        "status": "Short Findings",
        "keywords": "social determinants of health;natural language inference;nli;clinical notes;dataset",
        "authors": "",
        "rating": "",
        "confidence": "3;5;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "j2bP0STpw7",
        "title": "The Vault: A Comprehensive Multilingual Dataset for Advancing Code Understanding and Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "deep-learning;ai4code;dataset;benchmark;code-understanding;code-generation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "j48JCRagwR",
        "title": "Improving Contrastive Learning of Sentence Embeddings with Focal InfoNCE",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Contrastive Learning;Sentence Textual Similarity;Sentence Embdding;Negative Sample Reweighing",
        "authors": "",
        "rating": "",
        "confidence": "5;2;2",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "j61Sx05QRj",
        "title": "NeuSTIP: A Neuro-Symbolic Model for Link and Time Prediction in Temporal Knowledge Graphs",
        "track": "main",
        "status": "Long Main",
        "keywords": "Information Extraction;Neuro-Symbolic Knowledge Graph Completion;Temporal Knowledge Graph Completion",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "j6g3qwoQKU",
        "title": "POE: Process of Elimination for Multiple Choice Reasoning",
        "track": "main",
        "status": "Short Main",
        "keywords": "language models;prompting;scoring;multiple choice reasoning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "j9E9xLlTmB",
        "title": "Analyzing Cognitive Plausibility of Subword Tokenization",
        "track": "main",
        "status": "Short Main",
        "keywords": "subword tokenization;subword segmentation;cognitive signals;cognitive plausibility;lexical decision;vocabulary size;morphological segmentation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "j9e3WVc49w",
        "title": "Knowledge Distillation \u2248 Label Smoothing: Fact or Fallacy?",
        "track": "main",
        "status": "Short Main",
        "keywords": "knowledge distillation;label smoothing;regularization;interpretation of knowledge distillation",
        "authors": "",
        "rating": "",
        "confidence": "3;4;5",
        "correctness": "4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "jAf0gd0ez4",
        "title": "Interactive Text Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Interactivity;Text Generation;RL;IL",
        "authors": "",
        "rating": "",
        "confidence": "3;2;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "jImeNRfAy2",
        "title": "Self-Detoxifying Language Models via Toxification Reversal",
        "track": "main",
        "status": "Long Main",
        "keywords": "Language Model Detoxification;Language Model Safety;Natural Languge Generation",
        "authors": "",
        "rating": "",
        "confidence": "2;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "jLEnVo0RW3",
        "title": "Retrieving Multimodal Information for Augmented Generation: A Survey",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Retrieval-augmented language models;Multimodality",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "jLmSsybvkR",
        "title": "Dior-CVAE: Pre-trained Language Models and Diffusion Priors for Variational Dialog Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Dialogue Generation;Diffusion Model;Variational Auto-encoder",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "jMwvnqKTBG",
        "title": "Mind the Gap: Automated Corpus Creation for Enthymeme Detection and Reconstruction in Learner Arguments",
        "track": "main",
        "status": "Long Findings",
        "keywords": "dataset;argumentation;argument mining;enthymeme",
        "authors": "",
        "rating": "",
        "confidence": "4;2;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "jPrl18r4RA",
        "title": "Meta-Learning Online Adaptation of Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "meta-learning;question-answering;online learning;knowledge;adaptation",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3;3",
        "correctness": "3;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "jQcShOpcfM",
        "title": "DPP-TTS: Diversifying prosodic features of speech via determinantal point processes",
        "track": "main",
        "status": "Long Main",
        "keywords": "Speech prosody; prosodic segmentation; text-to-speech",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "jQozdfjJSZ",
        "title": "MingOfficial: A Ming Official Career Dataset and a Historical Context-Aware Representation Learning Framework",
        "track": "main",
        "status": "Long Main",
        "keywords": "graph representation learning;graph neural network;Ming Dynasty",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "jSu7hAIZM0",
        "title": "Preserving Privacy Through Dememorization: An Unlearning Technique For Mitigating Memorization Risks In Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large langauge models;privacy;memorization",
        "authors": "",
        "rating": "",
        "confidence": "2;3;2",
        "correctness": "2;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "jTiJPDv82w",
        "title": "ToxicChat: Unveiling Hidden Challenges of Toxicity Detection in Real-World User-AI Conversation",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Toxicity;Real-World User-AI Interaction;Domain Adaptation;LLM-based Chatbots",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "2;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "jUgBvYwc50",
        "title": "ZARA: Improving Few-Shot Self-Rationalization for Small Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "free-text explanation;rationale;self-rationalization",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "jUkDEaE0fK",
        "title": "LDM$^2$: A Large Decision Model Imitating Human Cognition with Dynamic Memory Enhancement",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large Language Model;Decision Making;Memory Enhanced",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "jUrRIcedTN",
        "title": "Modeling Highlighting of Metaphors in Multitask Contrastive Learning Paradigms",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Metaphor;Highlighted Aspect;Source Domain;Multitask Learning;Contrastive Learning",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "jVa7tFQw9N",
        "title": "Automatic Evaluation of Attribution by Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large Language Models; Attribution Evaluation; Attribution of LLMs; Evaluation of LLMs;",
        "authors": "",
        "rating": "",
        "confidence": "2;4;3;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "jWL2GhQw5D",
        "title": "More than Votes? Voting and Language based Partisanship in the US Supreme Court",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Fairness and Bias; Sociolinguistic; Cultural Analysis; Partisanship Analysis",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4;4",
        "correctness": "4;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "jWqkEB3wJP",
        "title": "RobustEmbed: Robust Sentence Embeddings Using Self-Supervised Contrastive Pre-Training",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Trustworthy Machine Learning;Text Representation;Adversarial Attacks;Self-Supervised Contrastive Learning",
        "authors": "",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "jZXjHnzPyk",
        "title": "TrojanSQL: SQL Injection against Natural Language Interface to Database",
        "track": "main",
        "status": "Long Main",
        "keywords": "text-to-SQL;NLIDB;security;SQL Injection;NL2Code",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "jbicunmyXh",
        "title": "LATENTLOGIC: Learning Logic Rules in Latent Space over Knowledge Graphs",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Knowledge Graph;Reasoning;Logic Rule",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4;4",
        "correctness": "3;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "jcqBLHFcYA",
        "title": "MindGames: Targeting Theory of Mind in Large Language Models with Dynamic Epistemic Modal Logic",
        "track": "main",
        "status": "Short Findings",
        "keywords": "logic;epistemic logic;theory of mind;language models",
        "authors": "",
        "rating": "",
        "confidence": "3;5;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "jcx5YIN3Sd",
        "title": "That was the last straw, we need more: Are Translation Systems Sensitive to Disambiguating Context?",
        "track": "main",
        "status": "Long Findings",
        "keywords": "model evaluation;model analysis;dataset creation;machine translation;LM",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "jfaJdk29k4",
        "title": "Prompting Large Language Models with Chain-of-Thought for Few-Shot Knowledge Base Question Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Models;Chain-of-Thought;Few-Shot;Knowledge Base Question Generation",
        "authors": "",
        "rating": "",
        "confidence": "2;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "jg2WCVrjhS",
        "title": "Uncertainty Guided Global Memory Improves Multi-Hop Question Answering",
        "track": "main",
        "status": "Short Main",
        "keywords": "Transformer;Memory;Multi-hop Question Answering",
        "authors": "",
        "rating": "",
        "confidence": "1;4;4;3",
        "correctness": "3;2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "jhdVt7rC8k",
        "title": "Large Language Models are Temporal and Causal Reasoners for Video Question Answering",
        "track": "main",
        "status": "Long Main",
        "keywords": "large language models;temporal and causal reasoning",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "jjSOGqLT2X",
        "title": "Video-Helpful Multimodal Machine Translation",
        "track": "main",
        "status": "Long Main",
        "keywords": "[Multimodal machine translation;Video]",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "jkI9KGEFQz",
        "title": "Support or Refute: Analyzing the Stance of Evidence to Detect Out-of-Context Mis- and Disinformation",
        "track": "main",
        "status": "Long Main",
        "keywords": "out-of-context;stance analysis;misinformation;Internet evidence",
        "authors": "",
        "rating": "",
        "confidence": "4;2;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "jmopGajkFY",
        "title": "MEGA: Multilingual Evaluation of Generative AI",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Models;Multilinguality;Evaluation;Low Resource Languages;Benchmarking",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3;3",
        "correctness": "4;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "jp80nsryCF",
        "title": "Transductive Learning for Textual Few-Shot Classification in API-based Embedding Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "NLP;few shot;text classifiers",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "jph8GlHueb",
        "title": "MUX-PLMs: Data Multiplexing for High-throughput Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Efficient Inference;Multi-input Multi-output architectures;Data Multiplexing",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "jqOIacThP3",
        "title": "Verb Conjugation in Transformers Is Determined by Linear Encodings of Subject Number",
        "track": "main",
        "status": "Short Findings",
        "keywords": "interpretability;analysis;representations;hidden vectors;syntax;subject-verb agreement;transformers;pre-trained models;language models;bert;causal analysis;causality;causal intervention;inlp",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "jqOymNqzuB",
        "title": "Ideology Takes Multiple Looks: A High-Quality Dataset for Multifaceted Ideology Detection",
        "track": "main",
        "status": "Long Main",
        "keywords": "Ideology detection;multifaceted ideology schema;dataset;political spectrum",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4;3",
        "correctness": "4;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "jqbhtSDPz7",
        "title": "The Art of SOCRATIC QUESTIONING: Recursive Thinking with Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Chain of Thought;prompting;large language model;reasoning;multimodal;question answering",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "jsmV1WxXyb",
        "title": "Statistically Profiling Biases in Natural Language Reasoning Datasets and Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "nature language processing;model robustness;bias analysis",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "juUEOaH7bK",
        "title": "ULF: Unsupervised Labeling Function Correction using Cross-Validation for Weak Supervision",
        "track": "main",
        "status": "Short Main",
        "keywords": "weak supervision;cross-validation;denoising methods",
        "authors": "",
        "rating": "",
        "confidence": "3;3;2",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "jvNVmkGxiU",
        "title": "Human Learning by Model Feedback: The Dynamics of Iterative Prompting with Midjourney",
        "track": "main",
        "status": "Long Main",
        "keywords": "Interaction;Text-to-Image;alignment;Cognitive Science",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "jvTV8vSa3X",
        "title": "Text-guided 3D Human Generation from 2D Collections",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Text-guided Visual Generation;3D Human Generation",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "5;4;1",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "jw1iZfW5zN",
        "title": "A Framework for Bidirectional Decoding: Case Study in Morphological Inflection",
        "track": "main",
        "status": "Long Findings",
        "keywords": "morphology;decoding;inflection;transformers",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "jxgz7FEqWq",
        "title": "Sparse Low-rank Adaptation of Pre-trained Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Parameter-efficient;Sparse Adaptation",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "k2VHhq2LH9",
        "title": "Reasoning about Ambiguous Definite Descriptions",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Natural language reasoning;definite descriptions;ambiguity;large language models",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "k3i6PKlKY8",
        "title": "mRedditSum: A Multimodal Abstractive Summarization Dataset of Reddit Threads with Images",
        "track": "main",
        "status": "Long Main",
        "keywords": "Multimodal Abstractive Summarization Dataset",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "k4QqDDoRyI",
        "title": "ATFormer: A Learned Performance Model with Transfer Learning Across Devices for Deep Learning Tensor Programs",
        "track": "main",
        "status": "Long Main",
        "keywords": "Tensor Program; Performance Model; Efficient Transfer Learning; NLP Application; Model Deployment",
        "authors": "",
        "rating": "",
        "confidence": "2;2;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "k8rxolXsPE",
        "title": "SuperDialseg: A Large-scale Dataset for Supervised Dialogue Segmentation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Dialogue Segmentation;Dataset;Benchmark",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "k95cAni5Hk",
        "title": "Toxicity, Morality, and Speech Act Guided Stance Detection",
        "track": "main",
        "status": "Long Findings",
        "keywords": "stance detection;toxicity;morality. speech act classification;Twitter",
        "authors": "",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "2;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "kCzhhVMo4r",
        "title": "Length-Adaptive Distillation: Customizing Small Language Model for Dynamic Token Pruning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "knowledge distillation;language model compression;token pruning",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "kEcDQzX3cI",
        "title": "Vicinal Risk Minimization for Few-Shot Cross-lingual Transfer in Abusive Language Detection",
        "track": "main",
        "status": "Long Main",
        "keywords": "Vicinal Risk Minimization;Few-Shot Cross-lingual Transfer;Abusive Language Detection",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "kEflZNzau4",
        "title": "Language Model is Suitable for Correction of Handwritten Mathematical Expressions Recognition",
        "track": "main",
        "status": "Long Main",
        "keywords": "LaTeX mathematical expression;handwritten mathematical expression recognition;language model;LaTeX language property",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3;3",
        "correctness": "3;4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "kEhBOEsXXx",
        "title": "HPE: Answering Complex Questions over Text by Hybrid Question Parsing and Execution",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multi-hop Question answering; Neuro-Symbolic method; Tree Structure Reasoning; Semantic Parsing",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3;4",
        "correctness": "4;4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "kEzI6OYXV4",
        "title": "Are All Steps Equally Important? Benchmarking Essentiality Detection in Event Processes",
        "track": "main",
        "status": "Short Main",
        "keywords": "Event Granularities;Essentiality;Event Processes;Goals;Steps",
        "authors": "",
        "rating": "",
        "confidence": "5;4;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "kFQrpCFanH",
        "title": "Dynosaur: A Dynamic Growth Paradigm for Instruction-Tuning Data Curation",
        "track": "main",
        "status": "Long Main",
        "keywords": "instruction tuning;dynamic;generalizable",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "kIRIjRPgfR",
        "title": "MacLaSa: Multi-Aspect Controllable Text Generation via Efficient Sampling from Compact Latent Space",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Natural Language Generation;Controllable Text Generation;Pretrained Language Models",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "kKKzd8SaMy",
        "title": "The Interpreter Understands Your Meaning: End-to-end Spoken Language Understanding Aided by Speech Translation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "spoken language understanding;multilinguality;bayesian transfer learning",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "kKX9X0tMRH",
        "title": "DisCo: Distilled Student Models Co-training for Semi-supervised Text Mining",
        "track": "main",
        "status": "Long Main",
        "keywords": "co-training;semi-supervised learning;knowledge distillation",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "kNCHv0NZ69",
        "title": "A Tale of Pronouns: Interpretability Informs Gender Bias Mitigation for Fairer Instruction-Tuned Machine Translation",
        "track": "main",
        "status": "Long Main",
        "keywords": "machine translation;gender bias;ethics;interpretability;instruction fine-tuned language models",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "kNUglj7Kq1",
        "title": "Unifying Cross-Lingual Transfer across Scenarios of Resource Scarcity",
        "track": "main",
        "status": "Long Main",
        "keywords": "cross-lingual transfer;low-resource scenarios;parameter-efficient fine-tuning",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "kOhxudaIEj",
        "title": "CS2W: A Chinese Spoken-to-Written Style Conversion Dataset with Multiple Conversion Types",
        "track": "main",
        "status": "Long Main",
        "keywords": "Spoken-to-Written Style Conversion;Disfluency Detection;Grammatical Error Correction;ASR",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "5;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "kQSlGF9lH6",
        "title": "Investigating Efficiently Extending Transformers for Long Input Summarization",
        "track": "main",
        "status": "Long Main",
        "keywords": "summarization;nlp;architectures;long context",
        "authors": "",
        "rating": "",
        "confidence": "5;3;3",
        "correctness": "5;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "kUNzgI1HxN",
        "title": "Frugal Prompting for Dialog Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "dialog;dialog generation;natural language generation;dialogue generation;dialogue;NLP",
        "authors": "",
        "rating": "",
        "confidence": "3;2;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "kXHDXPubz9",
        "title": "A Rose by Any Other Name would not Smell as Sweet: Social Bias in Names Mistranslation",
        "track": "main",
        "status": "Long Main",
        "keywords": "fairness and bias;NLP-related harms;name translation;evaluation",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "kY7lpT8z1E",
        "title": "Contrastive Learning of Sentence Embeddings from Scratch",
        "track": "main",
        "status": "Long Main",
        "keywords": "contrastive learning;sentence embeddings",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "kZob2CsZXm",
        "title": "COVID-19 Vaccine Misinformation in Middle Income Countries",
        "track": "main",
        "status": "Long Main",
        "keywords": "COVID-19;vaccine;misinformation;NLP applications;domain-specific pre-training;text augmentation;distributed lag model",
        "authors": "",
        "rating": "",
        "confidence": "5;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "kayoyzcsTa",
        "title": "$\\textit{Lost in Translation, Found in Spans}$: Identifying Claims in Multilingual Social Media",
        "track": "main",
        "status": "Long Main",
        "keywords": "Claim Span Identification;Multilinguality;Social Media;Claims;Low-resource Languages",
        "authors": "",
        "rating": "",
        "confidence": "4;2;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "kc2YhavobV",
        "title": "Continual Generalized Intent Discovery: Marching Towards Dynamic and Open-world Intent Recognition",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Out of Domain;Intent classification;Continual Learning",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "kda8szucLZ",
        "title": "Continual Dialogue State Tracking via Example-Guided Question Answering",
        "track": "main",
        "status": "Long Main",
        "keywords": "dialogue state tracking;dialogue;natural language processing;continual learning",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "kdjSXbypKX",
        "title": "TRAVEL: Tag-Aware Conversational FAQ Retrieval via Reinforcement Learning",
        "track": "main",
        "status": "Long Main",
        "keywords": "FAQ retrieval;Conversational FAQ Retrieval;Dialogue System;Human-machine interaction",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "kgxtMJHe7w",
        "title": "Selective Labeling: How to Radically Lower Data-Labeling Costs for Document Extraction Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "information extraction;selective labeling;data efficiency;annotation efficiency",
        "authors": "",
        "rating": "",
        "confidence": "2;2;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "kj4MRgh2K5",
        "title": "Transparency at the Source: Evaluating and Interpreting Language Models With Access to the True Distribution",
        "track": "main",
        "status": "Long Findings",
        "keywords": "language models;perplexity;interpretability;PCFG;learning dynamics;synthetic data",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "2;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "kp1U6wBPXq",
        "title": "Adapting Language Models to Compress Contexts",
        "track": "main",
        "status": "Long Main",
        "keywords": "language models;transformers;long-range language modeling;retrieval-augmented language modeling;in-context learning",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "kqm0SOisFq",
        "title": "Information Extraction from Legal Wills: How Well Does GPT-4 Do?",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Information Extraction;Legal Natural Language Processing",
        "authors": "",
        "rating": "",
        "confidence": "5;3;4",
        "correctness": "3;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "kspXkK9PtA",
        "title": "Enhancing Task-oriented Dialogue Systems with Generative Post-processing Networks",
        "track": "main",
        "status": "Long Main",
        "keywords": "Task-oriented Dialogue System;Reinforcement Learning;Natural Language Generation",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4;3",
        "correctness": "4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ktzudN7JmJ",
        "title": "ROBBIE: Robust Bias Evaluation of Large Generative Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "bias;fairness;toxicity;natural language generation;large language models;llm;evaluation",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "kuYRp78Qnp",
        "title": "Non-compositional Expression Generation Based on Curriculum Learning and Continual Learning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Non-compositional expression;Curriculum learning;continual learning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "kuwz9k061u",
        "title": "Measuring the Knowledge Acquisition-Utilization Gap in Pretrained Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Knowledge Acquisition;Knowledge Utilization;Pretrained Language Models",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "kyHwalUpPu",
        "title": "Empowering Psychotherapy with Large Language Models: Cognitive Distortion Detection through Diagnosis of Thought Prompting",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Psychotherapy;Cognitive distortion;Cognitive behavior therapy;Large language models",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "2;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "l4eviuXtBd",
        "title": "HadSkip: Homotopic and Adaptive Layer Skipping of Pre-trained Language Models for Efficient Inference",
        "track": "main",
        "status": "Long Findings",
        "keywords": "language model inference;efficiency",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "lBAc5JgyMI",
        "title": "Narrative Style and the Spread of Health Misinformation on Twitter",
        "track": "main",
        "status": "Long Findings",
        "keywords": "narrative communication;misinformation;computational social sciences;natural language processing;linguistic analysis;classification",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "lC4vFCM2VA",
        "title": "Towards Zero-shot Relation Extraction in Web Mining: A Multimodal Approach with Relative XML Path",
        "track": "main",
        "status": "Long Findings",
        "keywords": "web mining;xml path;document ai;zero shot;transfer learning",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4;4",
        "correctness": "3;3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "lCy3RwscMn",
        "title": "Deep Natural Language Feature Learning for Interpretable Prediction",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Model;Reasoning;Explanability;BERT",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "lKPReKSJio",
        "title": "FREDSum: A Dialogue Summarization Corpus for French Political Debates",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Dialogue;Summarization;Corpus;Dataset;Political Debate",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "lKi1myznJe",
        "title": "ReasoningLM: Enabling Structural Subgraph Reasoning in Pre-trained Language Models for Question Answering over Knowledge Graph",
        "track": "main",
        "status": "Long Main",
        "keywords": "Pre-trained Language Model;Knowledge Graph Question Answering",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "lOPMuJSVz8",
        "title": "Women Wearing Lipstick: Measuring the Bias Between an Object and Its Related Gender",
        "track": "main",
        "status": "Short Findings",
        "keywords": "image captioning;visual grounding;gender bias",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "lReh4LaP8f",
        "title": "Structural Priming Demonstrates Abstract Grammatical Representations in Multilingual Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "abstraction;representation;multilingual language models;psychlinguistics;linguistic structure",
        "authors": "",
        "rating": "",
        "confidence": "5;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "lVat423gKI",
        "title": "Language Representation Projection: Can We Transfer Factual Knowledge across Languages in Multilingual Language Models?",
        "track": "main",
        "status": "Short Main",
        "keywords": "multilingual language models;factual knowledge;cross-lingual knowledge transfer",
        "authors": "",
        "rating": "",
        "confidence": "4;4;2",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "lWlBAJTFOm",
        "title": "Small Language Models Fine-tuned to Coordinate Larger Language Models improve Complex Reasoning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Language Model Reasoning;Problem decomposition;Multistep reasoning",
        "authors": "",
        "rating": "",
        "confidence": "4;5;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "lbtVebcVny",
        "title": "Revisiting De-Identification of Electronic Medical Records: Evaluation of Within- and Cross-Hospital Generalization",
        "track": "main",
        "status": "Short Main",
        "keywords": "De-Identification;Electronic Medical Records;Domain Generalization",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ldbYAF0ad0",
        "title": "Large Language Models are Not Yet Human-Level Evaluators for Abstractive Summarization",
        "track": "main",
        "status": "Long Findings",
        "keywords": "LLM evaluation;ChatGPT;abstractive summarization evaluation;GPT-4",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ldtjC7TSJ5",
        "title": "Non-Autoregressive Sentence Ordering",
        "track": "main",
        "status": "Long Findings",
        "keywords": "sentence ordering;non-autoregressive transformer",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "lhSLoOYLDv",
        "title": "Joint Semantic and Strategy Matching for Persuasive Dialogue",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Persuasive dialogue;Application of dialogue;Retrieval-based dialogue",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3;4",
        "correctness": "3;2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.25,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ljjy0Sw5sx",
        "title": "Descriptive Prompt Paraphrasing for Target-Oriented Multimodal Sentiment Classification",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Target-Oriented Multimodal Sentiment Classification;Prompt Learning;Multimodal Sentiment Analysis",
        "authors": "",
        "rating": "",
        "confidence": "4;5;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ljsGKc8cVR",
        "title": "Longtriever: a Pre-trained Long Text Encoder for Dense Document Retrieval",
        "track": "main",
        "status": "Long Main",
        "keywords": "dense retrieval;document retrieval",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "llv2GnH5bD",
        "title": "Retrofitting Light-weight Language Models for Emotions using Supervised Contrastive Learning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Emotion;Contrastive Learning;Retrofitting",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "lojtRAQOls",
        "title": "Using LLM for Improving Key Event Discovery: Temporal-Guided News Stream Clustering with Event Summaries",
        "track": "main",
        "status": "Short Findings",
        "keywords": "news stream clustering;event discovery;political discourse characterization;LLM",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "lpyU0zyEsS",
        "title": "Identifying Informational Sources in News Articles",
        "track": "main",
        "status": "Long Main",
        "keywords": "computational journalism;source prediction;document-level modeling",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "lqe06F5OiU",
        "title": "Chain-of-Thought Embeddings for Stance Detection on Social Media",
        "track": "main",
        "status": "Short Findings",
        "keywords": "chain of thought;prompting;chatgpt;stance detection",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4;3",
        "correctness": "4;3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ls4Pfsl2jZ",
        "title": "Multi-step Jailbreaking Privacy Attacks on ChatGPT",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large language models;privacy;extraction attacks",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "m1TV5K9Cvc",
        "title": "Evaluating Emotion Arcs Across Languages: Bridging the Global Divide in Sentiment Analysis",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Emotion Arcs;Sentiment Analysis;Low-Resource NLP;Multilingual;Emotion Lexicons",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "mAxs9qiXbo",
        "title": "Debiasing Multimodal Models via Causal Information Minimization",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multimodal;Causality;Debiasing;Out-of-distribution",
        "authors": "",
        "rating": "",
        "confidence": "2;4;5",
        "correctness": "3;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "mCnBRLJuhY",
        "title": "The Curious Case of Hallucinatory (Un)answerability: Finding Truths in the Hidden States of Over-Confident Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "LLMs;explainability;answerability;hallucinations",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "mDPUF7ubAv",
        "title": "An Empirical Study of Instruction-tuning Large Language Models in Chinese",
        "track": "main",
        "status": "Long Findings",
        "keywords": "large language models;instruction fine-tune",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "mDgLGrL6ze",
        "title": "ECHo: A Visio-Linguistic Dataset for Event Causality Inference via Human-Centric Reasoning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "visio-linguistic commonsense reasoning;theory of mind;chain of thought",
        "authors": "",
        "rating": "",
        "confidence": "4;3;2",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "mERmlOPxPY",
        "title": "Definitions Matter: Guiding GPT for Multi-label Classification",
        "track": "main",
        "status": "Short Findings",
        "keywords": "GPT-3;zero-shot classification;LLM",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "mGEfAu17Rk",
        "title": "Hallucination Detection for Grounded Instruction Generation",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Hallucination detection;multimodality;natural language generation",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "mIsrzEjeG4",
        "title": "When Do Decompositions Help for Machine Reading?",
        "track": "main",
        "status": "Short Main",
        "keywords": "decomposition;machine reading;question answering",
        "authors": "",
        "rating": "",
        "confidence": "5;4;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "mJCXoiIeJU",
        "title": "On the Automatic Generation and Simplification of Children's Stories",
        "track": "main",
        "status": "Long Main",
        "keywords": "Natural Language Generation;NLP for Education;LLMs",
        "authors": "",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "mKuH13Oq3x",
        "title": "Adaptive Gating in Mixture-of-Experts based Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Mixture of Experts;Adaptive Computation;Training Efficiency",
        "authors": "",
        "rating": "",
        "confidence": "4;2;2",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "mLJOMUwQyz",
        "title": "INFORM : Information eNtropy based multi-step reasoning FOR large language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Chain-of-Thoughts;Multi-Step Reasoning;Large Language Models;Prompting;In-context Learning",
        "authors": "",
        "rating": "",
        "confidence": "4;5;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "mLlJavL0PB",
        "title": "InstructExcel: A Benchmark for Natural Language Instruction in Excel",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Code generation;program synthesis;benchmark;large language models",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "mN62FSvZVW",
        "title": "Sociocultural Norm Similarities and Differences via Situational Alignment and Explainable Textual Entailment",
        "track": "main",
        "status": "Long Main",
        "keywords": "social norms;culture;chain-of-thought reasoning",
        "authors": "",
        "rating": "",
        "confidence": "5;3;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "mNMwIwydgr",
        "title": "Are we biased on bias? Characterizing social bias research in the ACL community",
        "track": "main",
        "status": "Reject",
        "keywords": "Social Bias;Survey;Ethics",
        "authors": "",
        "rating": "",
        "confidence": "5;3;4",
        "correctness": "3;2;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 1.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "mPaNp1eglz",
        "title": "Comparing the Evaluation and Production of Loophole Behavior in Humans and Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "theory of mind;pragmatics;social reasoning;loopholes;large-language models;artificial intelligence",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "2;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "mQxqo1di63",
        "title": "KAPALM: Knowledge grAPh enhAnced Language Models for Fake News Detection",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Knowledge Graph; Fake news detection",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "2;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "mRETTyZEJa",
        "title": "GROVE: A Retrieval-augmented Complex Story Generation Framework with A Forest of Evidence",
        "track": "main",
        "status": "Long Findings",
        "keywords": "story generation;large language model;iterative prompting",
        "authors": "",
        "rating": "",
        "confidence": "2;3;3",
        "correctness": "4;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "mTiHLHu3sP",
        "title": "GPT-RE: In-context Learning for Relation Extraction using Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large language models;relation extraction;in-context learning",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "mU6C04mAJk",
        "title": "ToViLaG: Your Visual-Language Generative Model is Also An Evildoer",
        "track": "main",
        "status": "Long Main",
        "keywords": "Toxicity;text-to-image generation;image-to-text generation;Detoxification;Multimodality;generation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "mW5M8qkAxt",
        "title": "Confidence-based Ensembling of Perspective-aware Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Data perspectivism;irony;hate speech;confidence;ensemble",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "mYniPxMGLL",
        "title": "Dancing Between Success and Failure: Edit-level Simplification Evaluation using SALSA",
        "track": "main",
        "status": "Long Main",
        "keywords": "model evaluation;text simplification;fine-grained annotation;language model analysis;human evaluation",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4;4",
        "correctness": "5;3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "mb35Pb69e8",
        "title": "TCFLE-8: a Corpus of Learner Written Productions for French as a Foreign Language and its Application to Automated Essay Scoring",
        "track": "main",
        "status": "Long Main",
        "keywords": "Learner corpus;AES;French;Learner written essays;French certification exam",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "5;5;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 5.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "mkEkfHveEL",
        "title": "Interview Evaluation: A Novel Approach for Automatic Evaluation of Conversational Question Answering Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Conversational Question Answering;Evaluation metrics;Conversational history;Conversational question generation;Prompting",
        "authors": "",
        "rating": "",
        "confidence": "3;2;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "mmlQICRJMc",
        "title": "AdaSent: Efficient Domain-Adapted Sentence Embeddings for Few-Shot Classification",
        "track": "main",
        "status": "Long Main",
        "keywords": "few-shot text classification;sentence embedding;domain adaptation;parameter-efficient fine-tuning",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "mnzjuOhkR2",
        "title": "Struct-XLM: A Structure Discovery Multilingual Language Model for Enhancing Cross-lingual Transfer through Reinforcement Learning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Cross-lingual Representaion Alignment;Cross-lingual Transfer Learning;Reinforcement Learning",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "mpL9ikuYez",
        "title": "Proto-lm: A Prototypical Network-Based Framework for Built-in Interpretability in Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Prototypes;NLP;Interpretability;Faithfulness",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "mqnK19Dm80",
        "title": "Generative Emotion Cause Triplet Extraction in Conversations with Commonsense Knowledge",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Emotion Cause Analysis;Commonsense Knowledge;Emotion Recognition in Conversations",
        "authors": "",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "mrARDvuKi2",
        "title": "2INER: Instructive and In-Context Learning on Few-Shot Named Entity Recognition",
        "track": "main",
        "status": "Long Findings",
        "keywords": "prompt-based learning;instruction finetuning;in-context learning;NER",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "mrD5HN7ZNR",
        "title": "APP: Adaptive Prototypical Pseudo-Labeling for Few-shot OOD Detection",
        "track": "main",
        "status": "Long Findings",
        "keywords": "OOD;Intent Detection;Few-shot;Prototype",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "muTWDq9bVs",
        "title": "Speculative Decoding: Exploiting Speculative Execution for Accelerating Seq2seq Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "speculative decoding;efficient seq2seq generation",
        "authors": "",
        "rating": "",
        "confidence": "3;2;4",
        "correctness": "2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "mvtjk1mlrq",
        "title": "Knowledge Rumination for Pre-trained Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Knowledge rumination;pretrained language model",
        "authors": "",
        "rating": "",
        "confidence": "1;4;3;3",
        "correctness": "4;5;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.75,
        "correctness_avg": 4.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "mx0ltXW10S",
        "title": "TopWORDS-Poetry: Simultaneous Text Segmentation and Word Discovery for Classical Chinese Poetry via Bayesian Inference",
        "track": "main",
        "status": "Long Main",
        "keywords": "Word Discovery;Text Segmentation;Classical Chinese Poetry;Bayesian Inference;Unsupervised Method",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "n1Sx9ZjJRs",
        "title": "TOD-Flow: Modeling the Structure of Task-Oriented Dialogues",
        "track": "main",
        "status": "Long Main",
        "keywords": "Task-oriented Dialogue;Dialog policy learning;interpretability;precondition inference",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "n20PghmZaD",
        "title": "A New Benchmark and Reverse Validation Method for Passage-level Hallucination Detection",
        "track": "main",
        "status": "Long Findings",
        "keywords": "hallucination detection; LLM",
        "authors": "",
        "rating": "",
        "confidence": "3;4;5",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "n6qiOfZVYp",
        "title": "VIBE: Topic-Driven Temporal Adaptation for Twitter Classification",
        "track": "main",
        "status": "Long Main",
        "keywords": "temporal adaptation; neural topic model; social media; twitter classification",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3;4",
        "correctness": "5;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 4.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "n9y4IDFcCr",
        "title": "GROOViST: A Metric for Grounding Objects in Visual Storytelling",
        "track": "main",
        "status": "Short Main",
        "keywords": "visual storytelling;grounding;NLG evaluation",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "nC47EZVfAw",
        "title": "Low-Resource Comparative Opinion Quintuple Extraction by Data Augmentation with Prompting",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Comparative opinion quintuple extraction;Low-resource;Data augmentation;Large language models;Sentiment analysis",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3;4",
        "correctness": "4;3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "nC8WUrpWjG",
        "title": "Answer-state Recurrent Relational Network (AsRRN) for Constructed Response Assessment and Feedback Grouping",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Writing assessment;relation networks;contrastive learning",
        "authors": "",
        "rating": "",
        "confidence": "1;4;2",
        "correctness": "2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 1.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "nE9aUYqz6k",
        "title": "What Else Do I Need to Know? The Effect of Background Information on Users\u2019 Reliance on QA Systems",
        "track": "main",
        "status": "Long Main",
        "keywords": "human-centered NLP;over-reliance;explainability",
        "authors": "",
        "rating": "",
        "confidence": "5;3;4",
        "correctness": "3;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "nFagtplIb8",
        "title": "Improving Chinese Pop Song and Hokkien Gezi Opera Singing Voice Synthesis by Enhancing Local Modeling",
        "track": "main",
        "status": "Long Main",
        "keywords": "Singing voice synthesis;local modeling enhancement;local adaptive weights loss;Hokkien Gezi Opera;Chinese pop song",
        "authors": "",
        "rating": "",
        "confidence": "5;4;3;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "nGCwDjinT8",
        "title": "Adaptive Hinge Balance Loss for Document-Level Relation Extraction",
        "track": "main",
        "status": "Short Findings",
        "keywords": "document-level relation extraction;multi-label classification;balancing methods;loss function design",
        "authors": "",
        "rating": "",
        "confidence": "5;3;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "nGFQ7IqOyg",
        "title": "Non-Autoregressive Math Word Problem Solver with Unified Tree Structure",
        "track": "main",
        "status": "Long Main",
        "keywords": "MWP solving;non-autoregressive solver;unified tree structure",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "nI0X5IZOQA",
        "title": "Oolong: Investigating What Makes Transfer Learning Hard with Controlled Studies",
        "track": "main",
        "status": "Short Main",
        "keywords": "crosslingual;knowledge transfer;language model;finetuning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "4;3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "nIp7wkMeMP",
        "title": "Enhancing Low-resource Fine-grained Named Entity Recognition by Leveraging Coarse-grained Datasets",
        "track": "main",
        "status": "Long Main",
        "keywords": "Named Entity Recognition;Fine-grained NER;Low-resource scenario",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "nIuJXuSdhn",
        "title": "Can LLMs Facilitate Interpretation of Pre-trained Language Models?",
        "track": "main",
        "status": "Long Main",
        "keywords": "Interpretation;explainability;Large Language Models;Neuron Analysis",
        "authors": "",
        "rating": "",
        "confidence": "4;2;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "nMjktU5AiP",
        "title": "IndiSocialFT: Multilingual Word Representation for Indian languages in code-mixed environment",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Indian Languages;Multilingual Word Embedding;Code-mixed;Social Media Text",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "nPzrjWrtlz",
        "title": "The Truth, The Whole Truth, and Nothing but the Truth: A New Benchmark Dataset for Hebrew Text Credibility Assessment",
        "track": "main",
        "status": "Long Findings",
        "keywords": "NLP and social media;NLP application;Fake news detection;Fact Checking;Credibility Assessment",
        "authors": "",
        "rating": "",
        "confidence": "4;5;3",
        "correctness": "3;1;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "nRB8VpeM7b",
        "title": "Pushdown Layers: Encoding Recursive Structure in Transformer Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "recursive structure;syntactic language models;generalization",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "nSPsxWVe4k",
        "title": "SLOG: A Structural Generalization Benchmark for Semantic Parsing",
        "track": "main",
        "status": "Long Main",
        "keywords": "compositional generalization;structural generalization;long-distance dependencies;recursion;semantic parsing",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "nT4S0wgrwp",
        "title": "Understanding Translationese in Cross-Lingual Summarization",
        "track": "main",
        "status": "Long Findings",
        "keywords": "summarization;multi-lingual summarization;cross-lingual summarization",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "nTKRAgssvX",
        "title": "SiMFy: A Simple Yet Effective Approach for Temporal Knowledge Graph Reasoning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Temporal Knowledge Graph;Reasoning;Multilayer Perceptron;Historical Frequency",
        "authors": "",
        "rating": "",
        "confidence": "3;4;5",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "nWXMv949ZH",
        "title": "Logic-LM: Empowering Large Language Models with Symbolic Solvers for Faithful Logical Reasoning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Logical Reasoning;Language Model;Symbolic Language;Self-Refinement",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "3;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "nYbOG9EaxD",
        "title": "A Question Answering Framework for Decontextualizing User-facing Snippets from Scientific Documents",
        "track": "main",
        "status": "Long Main",
        "keywords": "decontextualization;snippets;text-simplification",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "nYgu408UIo",
        "title": "Why LLMs Hallucinate, and How to Get (Evidential) Closure: Perceptual, Intensional, and Extensional Learning for Faithful Natural Language Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Truth;Semantics;Meaning;Hallucination;Identification;Natural Language Generation",
        "authors": "",
        "rating": "",
        "confidence": "1;3;2",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "neRWI1hWyO",
        "title": "Allies: Prompting Large Language Model with Beam Search",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large Language Model;Question Answering;Beam Search",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "4;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "newk6aDMRi",
        "title": "Teacher Perception of Automatically Extracted Grammar Concepts for L2 Language Learning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "NLP for pedagogy;second language learning;low-resource languages",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "nmSvzxwfRZ",
        "title": "FinePrompt: Unveiling the Role of Finetuned Inductive Bias on Compositional Reasoning in GPT-4",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Large Language Model;Prompt Learning;Fine-tuning;Compositional Reasoning;Question Answering",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "nmnPI4eNuh",
        "title": "DeSIQ: Towards an Unbiased, Challenging Benchmark for Social Intelligence Understanding",
        "track": "main",
        "status": "Long Main",
        "keywords": "Question Answering; Social Intelligence; Multimodal Learning",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "nntsSuRSPb",
        "title": "TextMixer: Mixing Multiple Inputs for Privacy-Preserving Inference",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Privacy-preserving Inference;Multi-input Multi-output network",
        "authors": "",
        "rating": "",
        "confidence": "3;2;4",
        "correctness": "4;4;1",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "noEKNSB8Zq",
        "title": "\u201cKelly is a Warm Person, Joseph is a Role Model\u201d: Gender Biases in LLM-Generated Reference Letters",
        "track": "main",
        "status": "Long Findings",
        "keywords": "fairness;reference letter generation;LLMs",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "noIvPGG8P1",
        "title": "Search Augmented Instruction Learning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "large language model;instruction tuning;question answering",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "noPuQXVx8Y",
        "title": "Exploring the Sensitivity of LLMs' Decision-Making Capabilities: Insights from Prompt Variations and Hyperparameters",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Language Models;Decision-Making;Cognitive Psychology;Chain of Thought",
        "authors": "",
        "rating": "",
        "confidence": "3;5;2;4",
        "correctness": "4;4;2;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "noUf45O1PX",
        "title": "BanLemma: A Word Formation Dependent Rule and Dictionary Based Bangla Lemmatizer",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Computational Linguistics;Morphology;Bangla NLP;Lemmatization",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "nsupkM0ppH",
        "title": "Watermarking PLMs on Classification Tasks by Combining Contrastive Learning with Weight Perturbation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "PLM;Warermarking;backdoor;contrastive learning;weight perturbation",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4;4",
        "correctness": "3;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "nuLtpgr9l5",
        "title": "Disfluent Cues for Enhanced Speech Understanding in Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "disfluency detection;disfluencies;self-repairs;large language models;interruptions;contextual cues;spontaneous speech",
        "authors": "",
        "rating": "",
        "confidence": "4;5;2",
        "correctness": "4;1;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "nuPp6jdCgg",
        "title": "Evaluating Large Language Models on Controlled Generation Tasks",
        "track": "main",
        "status": "Long Main",
        "keywords": "Evaluation;Large Language Model;Analysis",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "nucyYJZS5z",
        "title": "Lion: Adversarial Distillation of Proprietary Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "large language models;instruction following;knowledge distillation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "nw6JxagUNG",
        "title": "Methodological Insights in Detecting Subtle Semantic Shifts with Contextualized and Static Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "semantic shift detection;contextualized embeddings;static embeddings;political communities",
        "authors": "",
        "rating": "",
        "confidence": "2;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "nwTqq0XW3w",
        "title": "Language and Mental Health: Measures of Emotion Dynamics from Text as Linguistic Biosocial Markers",
        "track": "main",
        "status": "Long Main",
        "keywords": "Utterance Emotion Dynamics;Mental Health;Social Media;Sentiment Analysis;Emotion Arcs;Emotional Reactivity;Lexicons",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "o2HBfgY20b",
        "title": "API-Bank: A Comprehensive Benchmark for Tool-Augmented LLMs",
        "track": "main",
        "status": "Long Main",
        "keywords": "Tool-Augmented LLMs;Large Language Model;Benchmark",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "4;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "o5LeRFe7VS",
        "title": "Test-time Augmentation for Factual Probing",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Factual Probing;TTA;Calibration",
        "authors": "",
        "rating": "",
        "confidence": "4;3;2",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "o5bOK5a9qz",
        "title": "DemaFormer: Damped Exponential Moving Average Transformer with Energy-Based Modeling for Temporal Language Grounding",
        "track": "main",
        "status": "Long Findings",
        "keywords": "temporal language grounding;energy-based modeling;exponential-moving average;transformer",
        "authors": "",
        "rating": "",
        "confidence": "1;4;3;5",
        "correctness": "2;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "o6D5yTpK8w",
        "title": "Exploring Graph Pre-training for Aspect-based Sentiment Analysis",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Aspect-based Sentiment Analysis; Generative model; Graph pre-train",
        "authors": "",
        "rating": "",
        "confidence": "4;5;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "o7Cpy0nZZb",
        "title": "Improving Conversational Recommendation Systems via Bias Analysis and Language-Model-Enhanced Data Augmentation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Conversational Recommendation;Bias Mitigation;Generative Data;Data Augmentation",
        "authors": "",
        "rating": "",
        "confidence": "2;4;3",
        "correctness": "3;2;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.0,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "o7SWorg8EM",
        "title": "S2abEL: A Dataset for Entity Linking from Scientific Tables",
        "track": "main",
        "status": "Long Main",
        "keywords": "Table Entity Linking;Machine Learning;Dataset",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "2;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "o9wco8bIVN",
        "title": "Unsupervised Grammatical Error Correction Rivaling Supervised Methods",
        "track": "main",
        "status": "Long Main",
        "keywords": "Unsupervised Grammatical Error Correction",
        "authors": "",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "oC5e8mAKAP",
        "title": "Weakly-Supervised Learning of Visual Relations in Multimodal Pretraining",
        "track": "main",
        "status": "Long Main",
        "keywords": "vision-and-language;multimodal;pretraining;zero-shot;fine-grained",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3;2",
        "correctness": "4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "oEsYs3WRc3",
        "title": "Enhancing Chat Language Models by Scaling High-quality Instructional Conversations",
        "track": "main",
        "status": "Long Main",
        "keywords": "Instructional Data;Language Models",
        "authors": "",
        "rating": "",
        "confidence": "5;2;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "oEsuNpkA8d",
        "title": "Gold: A Global and Local-aware Denoising Framework for Commonsense Knowledge Graph Noise Detection",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Knowledege Graph Denoising;Commonsense Reasoning;Question Answering",
        "authors": "",
        "rating": "",
        "confidence": "4;4;2",
        "correctness": "2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "oOKU31j9Q6",
        "title": "A Word Sense Distribution-based approach for Semantic Change Prediction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Semantic Change Detection;Temporal Semantics;Sense Embeddings",
        "authors": "",
        "rating": "",
        "confidence": "5;5;3",
        "correctness": "3;1;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "oSYifZI06H",
        "title": "Generative Spoken Language Model based on continuous word-sized audio tokens",
        "track": "main",
        "status": "Long Main",
        "keywords": "spoken language models;speech generation;zerospeech;textless nlp",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "oTtA9uIlR8",
        "title": "Detecting Syntactic Change with Pre-trained Transformer Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "BERT;Transformers;language change;syntax;syntactic change",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "oVAod8GRI9",
        "title": "Image Manipulation via Multi-Hop Instructions - A New Dataset and Weakly-Supervised Neuro-Symbolic Approach",
        "track": "main",
        "status": "Long Main",
        "keywords": "Neuro-Symbolic Reasoning;Natural Language Guided Image Manipulation;Visual Question Answering;Weakly Supervised Learning",
        "authors": "",
        "rating": "",
        "confidence": "3;5;2",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "oVJXUvXT9b",
        "title": "ASPIRO: Any-shot Structured Parsing-error-Induced ReprOmpting for Consistent Data-to-Text Generation",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Large Language Models;Data-to-Text;data disambiguation;structured data verbalisation;few-shot learning;multi-shot re-prompting",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "oYRlrDN6uj",
        "title": "Manifold-Preserving Transformers are Effective for Short-Long Range Encoding",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Orthogonal attention;Lipschitz;Entropic Transformer",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "oYs7h2dE2e",
        "title": "CombLM: Adapting Black-Box Language Models through Small Fine-Tuned Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "black-box;language models;large language models;adaptation;domain adaptation",
        "authors": "",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "oaNa4rNIpU",
        "title": "HistAlign: Improving Context Dependency in Language Generation by Aligning with History",
        "track": "main",
        "status": "Long Main",
        "keywords": "generation;language models;summarization;data-to-text",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "odPKQiL2X8",
        "title": "Exploring All-In-One Knowledge Distillation Framework for Neural Machine Translation",
        "track": "main",
        "status": "Long Main",
        "keywords": "neural machine translation;efficient knowledge distillation;multi-model scenario",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "oeZiXoCHgq",
        "title": "ACT-SQL: In-Context Learning for Text-to-SQL with Automatically-Generated Chain-of-Thought",
        "track": "main",
        "status": "Long Findings",
        "keywords": "text-to-SQL;large language models;in-context learning;chain of thought",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ogh9vskMDH",
        "title": "Open-Ended Instructable Embodied Agents with Memory-Augmented Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Task Planning;Embodied AI;LLMs;Robotics",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ojgwuBVokp",
        "title": "Random Entity Quantization for Parameter-Efficient Compositional Knowledge Graph Representation",
        "track": "main",
        "status": "Long Main",
        "keywords": "knowledge graph;knowledge representation",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "okV4KG4kMg",
        "title": "Can Language Models Laugh at YouTube Short-form Videos?",
        "track": "main",
        "status": "Long Main",
        "keywords": "video;humor;explanation;youtube;short-form videos;funny",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "5;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "olEEp3Phda",
        "title": "Symbolization, Prompt, and Classification: A Framework for Implicit Speaker Identification in Novels",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Speaker Identification;Audiobook Production;Prompting",
        "authors": "",
        "rating": "",
        "confidence": "2;3;5;2",
        "correctness": "3;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "olzuxDCxMZ",
        "title": "Investigating Bias in Multilingual Language Models: Cross-Lingual Transfer of Debiasing Techniques",
        "track": "main",
        "status": "Short Main",
        "keywords": "bias mitigation;cross-lingual transferability;multilingual BERT",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "on3Wo4VODO",
        "title": "The Law and NLP: Bridging Disciplinary Disconnects",
        "track": "main",
        "status": "Short Findings",
        "keywords": "legal natural language processing;legal artificial intelligence;legal precedent retrieval;access to justice",
        "authors": "",
        "rating": "",
        "confidence": "5;5;1",
        "correctness": "2;5;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "onr6HrKxn0",
        "title": "DEPN: Detecting and Editing Privacy Neurons in Pretrained Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Privacy Protection;Language Model",
        "authors": "",
        "rating": "",
        "confidence": "4;5;2",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "oqqmjw1BD1",
        "title": "Bridging the Gap between Synthetic and Authentic Images for Multimodal Machine Translation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Multimodal Machine Translation;Text-to-image Generation",
        "authors": "",
        "rating": "",
        "confidence": "2;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "orSVYeobMr",
        "title": "RoAST: Robustifying Language Models via Adversarial Perturbation with Selective Training",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Language model robustness;adversarial training",
        "authors": "",
        "rating": "",
        "confidence": "4;5;3",
        "correctness": "4;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "orefzVRWqV",
        "title": "PsyAttention: Psychological Attention Model for Personality Detection",
        "track": "main",
        "status": "Long Findings",
        "keywords": "personality detection; BigFive; PsyAttention; psychological features",
        "authors": "",
        "rating": "",
        "confidence": "4;5;2",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "oseYM8qxW4",
        "title": "Critic-Driven Decoding for Mitigating Hallucinations in Data-to-text Generation",
        "track": "main",
        "status": "Short Main",
        "keywords": "data-to-text generation;hallucinations;decoding approaches;natural language genereation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "osox1GoFLS",
        "title": "Disentangling Extraction and Reasoning in Multi-hop Spatial Reasoning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Spatial Reasoning;Spatial Role Labeling;Disentangling Extraction and Reasoning;Pretrained Language Models;Large Language Models",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "oueo4cEgSJ",
        "title": "Hierarchical Pretraining on Multimodal Electronic Health Records",
        "track": "main",
        "status": "Long Main",
        "keywords": "Clinical Text;Multimodal Learning;Pretraining;Electronic Health Records",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ouiQX2XWYc",
        "title": "Watermarking LLMs with Weight Quantization",
        "track": "main",
        "status": "Long Findings",
        "keywords": "watermarking;LLM;model quantization",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ovkb6woHvT",
        "title": "GLEN: General-Purpose Event Detection for Thousands of Types",
        "track": "main",
        "status": "Long Main",
        "keywords": "event extraction; event detection; dataset",
        "authors": "",
        "rating": "",
        "confidence": "5;3;4",
        "correctness": "5;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "owc65ImkyU",
        "title": "Plan, Verify and Switch: Integrated Reasoning with Diverse X-of-Thoughts",
        "track": "main",
        "status": "Long Main",
        "keywords": "Math Reasoning;Chain-of-Thought",
        "authors": "",
        "rating": "",
        "confidence": "4;5;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "oxZKOzePQX",
        "title": "SWEET - Weakly Supervised Person Name Extraction for Fighting Human Trafficking",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Information Extraction;Large Language Models;Generation;NLP Applications;Resources and Evaluation",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "p0GyMJugcE",
        "title": "Once is Enough: A Light-Weight Cross-Attention for Fast Sentence Pair Modeling",
        "track": "main",
        "status": "Short Main",
        "keywords": "information retrieval;text matching;embedding",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "p2P1Q4FpEB",
        "title": "A Framework for Vision-Language Warm-up Tasks in Multimodal Dialogue Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "multimodal agent;multimodal dialogue agent;multi-turn dialogue agent;warm-up task",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3;3",
        "correctness": "3;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "pFTBsdZ1UM",
        "title": "Indicative Summarization of Long Discussions",
        "track": "main",
        "status": "Long Main",
        "keywords": "Summarization;Computational Argumentation;Large Language Models;Social Media Discussions",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "pGlnFVmI4x",
        "title": "Boosting Summarization with Normalizing Flows and Aggressive Training",
        "track": "main",
        "status": "Long Main",
        "keywords": "summarization;normalizing flows;posterior collapse;aggressive training",
        "authors": "",
        "rating": "",
        "confidence": "4;3;2",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "pHrNmdzX2C",
        "title": "FinGPT: Large Generative Models for a Small Language",
        "track": "main",
        "status": "Long Main",
        "keywords": "large language models;gpt;causal model;finnish;transformers;monolingual language models;BLOOM",
        "authors": "",
        "rating": "",
        "confidence": "3;2;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "pHwLbEkB0J",
        "title": "Cross-lingual Prompting: Improving Zero-shot Chain-of-Thought Reasoning across Languages",
        "track": "main",
        "status": "Long Main",
        "keywords": "Chain-of-Thought; Cross-lingual Prompting; Cross-lingual self-consistency Prompting",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "pJwlMI7AYm",
        "title": "NERetrieve: Dataset for Next Generation Named Entity Recognition and Retrieval",
        "track": "main",
        "status": "Long Findings",
        "keywords": "zero shot ner;retrieval;exhaustive search",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "pMCRGmB7Rv",
        "title": "BioPlanner: Automatic Evaluation of LLMs on Protocol Planning in Biology",
        "track": "main",
        "status": "Long Main",
        "keywords": "LLMs;GPT-4;Science;Biology;Evaluation",
        "authors": "",
        "rating": "",
        "confidence": "4;3;2",
        "correctness": "3;5;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "pO7YD7PADN",
        "title": "Understanding the Effect of Model Compression on Social Bias in Large Language Models",
        "track": "main",
        "status": "Short Main",
        "keywords": "social bias;large language models;model compression;quantization;knowledge distillation",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "pPiJykFn0K",
        "title": "Harnessing the power of LLMs: Evaluating human-AI text co-creation through the lens of news headline generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "human-centered NLP;large language model;human-AI collaboration;text summarization",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "pQFgViJp77",
        "title": "The Skipped Beat: A Study of Sociopragmatic Understanding in LLMs for 64 Languages",
        "track": "main",
        "status": "Long Main",
        "keywords": "sociopragmatics;benchmark;large language models;social media;ChatGPT;multilinguality",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "pW6xXXnCQu",
        "title": "PsyCoT: Psychological Questionnaire as Powerful Chain-of-Thought for Personality Detection",
        "track": "main",
        "status": "Long Findings",
        "keywords": "personality detection;psychological questionnaire;chain-of-thought",
        "authors": "",
        "rating": "",
        "confidence": "5;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "pYRCUypbuq",
        "title": "Did You Mean...? Confidence-based Trade-offs in Semantic Parsing",
        "track": "main",
        "status": "Short Main",
        "keywords": "calibration;semantic parsing;safety;paraphrasing",
        "authors": "",
        "rating": "",
        "confidence": "2;4;3;1",
        "correctness": "4;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "paUJOst3OE",
        "title": "MAPO: Boosting Large Language Model Performance with Model-Adaptive Prompt Optimization",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Prompts Optimization;Large Language Models;Reinforcement Learning",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "pfeod9GPAw",
        "title": "Extractive Summarization via ChatGPT for Faithful Summary Generation",
        "track": "main",
        "status": "Short Findings",
        "keywords": "summarization;large language model;faithfulness",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3;4",
        "correctness": "3;3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "pgEIr2HY2E",
        "title": "Improving Summarization with Human Edits",
        "track": "main",
        "status": "Long Main",
        "keywords": "Human-aligned AI;  Unlikelihood Training;  Human Edits;  Imitation Edits;  Human Feedback",
        "authors": "",
        "rating": "",
        "confidence": "4;4;2;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "phJtMADSdy",
        "title": "Multi-User MultiWOZ: Task-Oriented Dialogues among Multiple Users",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multiparty Dialogues;Contextual Query Rewriting;Dialogue Summarization;Dialogue Systems",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "pi764D1Xrx",
        "title": "Ask Language Model to Clean Your Noisy Translation Data",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Machine Translation;Large Language Models;Data Generation;Noise",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "piC2Dm47U1",
        "title": "Novel Relation Detection: Discovering Unknown Relation Types via Multi-Strategy Self-Supervised Learning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Relation Detection;Out-of-Scope Detection;Self-Supervised Learning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4;3",
        "correctness": "4;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "pk0OZZkYMP",
        "title": "Analyzing Modular Approaches for Visual Question Decomposition",
        "track": "main",
        "status": "Long Main",
        "keywords": "Vision\u2013language;visual question answering;modular;neuro-symbolic;prompting;question decomposition",
        "authors": "",
        "rating": "",
        "confidence": "2;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "pkZcvEYZEm",
        "title": "NAIL: Lexical Retrieval Indices with Efficient Non-Autoregressive Decoders",
        "track": "main",
        "status": "Long Main",
        "keywords": "information retrieval;text retrieval;large language models;non-autoregressive decoders",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "pnnab961TD",
        "title": "Towards Informative Open-ended Text Generation with Dynamic Knowledge Triples",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Informativeness;Knowledge graph;open-ended text generation",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ppaIkXurvg",
        "title": "The Troubling Emergence of Hallucination in Large Language Models - An Extensive Definition, Quantification, and Prescriptive Remediations",
        "track": "main",
        "status": "Long Main",
        "keywords": "large language models;hallucination;dataset;mitigation",
        "authors": "",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ppb7gyhc7k",
        "title": "Learning Retrieval Augmentation for Personalized Dialogue Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Personalized Dialogue Generation;Retrieval-augmented Dialogue Generation;Persona-Based Dialogue Generation",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "psv7operF8",
        "title": "Adaptive Textual Label Noise Learning based on Pre-trained Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "learning with noisy labels;label noise learning;pre-trained models;text classification",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ptcFuwr4YD",
        "title": "Can you Summarize my learnings? Towards Perspective-based Educational Dialogue Summarization",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Summarization;Text-generation;AI4Education",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "puLH3BEl93",
        "title": "Improving Zero-shot Reader by Reducing Distractions from Irrelevant Documents in Open-Domain Question Answering",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Open-Domain Question Answering;Large Language Model;Prompt Engineering",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "puMfaHb1hY",
        "title": "G-Eval: NLG Evaluation using Gpt-4 with Better Human Alignment",
        "track": "main",
        "status": "Long Main",
        "keywords": "generation evaluation",
        "authors": "",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "pvEkYbUPVW",
        "title": "Measuring Faithful and Plausible Visual Grounding in VQA",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Visual Grounding;Visual Question Answering",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "2;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "pxscU6TidP",
        "title": "AutoPlan: Automatic Planning of Interactive Decision-Making Tasks With Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Planning;Decision Making;Large Language Model",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "pyjppDCsq7",
        "title": "Influence Scores at Scale for Efficient Language Data Sampling",
        "track": "main",
        "status": "Long Main",
        "keywords": "data effiency;data sampling;difficulty metrics;influence scores;pruning",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "q09vTY1Cqh",
        "title": "RepoCoder: Repository-Level Code Completion Through Iterative Retrieval and Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "code completion;large pre-trained language model;code repository;retrieval augmented generation",
        "authors": "",
        "rating": "",
        "confidence": "5;5;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "q0c1JTukWE",
        "title": "On Surgical Fine-tuning for Language Encoders",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Efficient Fine Tuning;Language Models;Language Encoders;Linguistics;Optimization;Distributional Shifts;Temporal Shifts",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "2;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "q4oWkMHkQx",
        "title": "Task-Level Thinking Steps Help Large Language Models for Challenging Classification Task",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Models;Prompt Engineering;Text Classification;Chain of Thought",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "q7IvUsjEkb",
        "title": "Dynamic Voting for Efficient Reasoning in Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "large language models;multi-path voting;computational resource;early exiting",
        "authors": "",
        "rating": "",
        "confidence": "5;3;4",
        "correctness": "4;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "q88QSsc75T",
        "title": "Simultaneous Machine Translation with Tailored Reference",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Simultaneous Machine Translation;Machine Translation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;2;4;4;2;3",
        "correctness": "4;4;4;3;2;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.2857142857142856,
        "correctness_avg": 3.5714285714285716,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "q8aTDcIXnO",
        "title": "TempTabQA: Temporal Question Answering for Semi-Structured Tables",
        "track": "main",
        "status": "Long Main",
        "keywords": "Semi-structured;Temporal Reasoning;Inference;Question Answering;New Resource;New Dataset;Wikipedia InfoBox",
        "authors": "",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "3;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "qDspFDJEHP",
        "title": "Three Questions Concerning the Use of Large Language Models to Facilitate Mathematics Learning",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Mathematics Learning;Adaptive Feedback;Large Language Models",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "qE5vtBMbCJ",
        "title": "LEXTREME: A Multi-Lingual and Multi-Task Benchmark for the Legal Domain",
        "track": "main",
        "status": "Long Findings",
        "keywords": "legal;nlp;benchmark;multilingual;multitask",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "qGr17uesSx",
        "title": "SimCKP: Simple Contrastive Learning of Keyphrase Representations",
        "track": "main",
        "status": "Long Findings",
        "keywords": "keyphrase prediction;contrastive learning;reranking",
        "authors": "",
        "rating": "",
        "confidence": "4;4;5;5",
        "correctness": "4;3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "qJqJXpysnh",
        "title": "Handshape-Aware Sign Language Recognition: Extended Datasets and Exploration of Handshape-Inclusive Methods",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Sign language recognition;handshape",
        "authors": "",
        "rating": "",
        "confidence": "3;3;2;3",
        "correctness": "4;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "qMSG8S7zh0",
        "title": "On Uncertainty Calibration and Selective Generation in Probabilistic Neural Summarization: A Benchmark Study",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Uncertainty;calibration;ensembles;generation;summarisation",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4;3",
        "correctness": "4;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "qOOQW9DcpF",
        "title": "In-context Learning for Few-shot Multimodal Named Entity Recognition",
        "track": "main",
        "status": "Long Findings",
        "keywords": "In-context Learning;Few-shot Multimodal Named Entity Recognition",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "2;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "qPIV6XQizX",
        "title": "A Reference-free Segmentation Quality Index (SegReFree)",
        "track": "main",
        "status": "Long Findings",
        "keywords": "segmentation;metrics",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "qPfQq8c3kv",
        "title": "High-quality argumentative information in low resources approaches improve counter-narrative generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "counter-narratives;argument mining;finetuning",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "qRbhKhqp0b",
        "title": "The Past, Present and Better Future of Feedback Learning in Large Language Models for Subjective Human Preferences and Values",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large language models;survey;review;human feedback;human preference;human values;alignment",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "qRg3AxBDnN",
        "title": "Learning the Visualness of Text Using Large Vision-Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "text visualness;vision-language models;multimodal learning",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3;3",
        "correctness": "4;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "qS1ip2dGH0",
        "title": "The Shifted and The Overlooked: A Task-oriented Investigation of User-GPT Interactions",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large language models;Real-world NLP applications;User-GPT interaction analysis",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "qT4bw58Yl2",
        "title": "MProto: Multi-Prototype Network with Denoised Optimal Transport for Distantly Supervised Named Entity Recognition",
        "track": "main",
        "status": "Long Main",
        "keywords": "Information Extraction;Named Entity Recognition;Distant Supervision",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "qWbCkbBN1P",
        "title": "Reducing Spurious Correlations in Aspect-based Sentiment Analysis with Explanation from Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "aspect-based sentiment analysis;spurious correlations;large language models",
        "authors": "",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "qZwsO1Qi3V",
        "title": "Syntactic Substitutability as Unsupervised Dependency Syntax",
        "track": "main",
        "status": "Long Main",
        "keywords": "unsupervised dependency parsing;syntax;syntactic probing;linguistically informed",
        "authors": "",
        "rating": "",
        "confidence": "3;5;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "qae0FlfrG6",
        "title": "Does the Correctness of Factual Knowledge Matter for Factual Knowledge-Enhanced Pre-trained Language Models?",
        "track": "main",
        "status": "Long Main",
        "keywords": "factual knowledge;language model;knowledge-enhanced",
        "authors": "",
        "rating": "",
        "confidence": "4;1;2",
        "correctness": "4;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "qegD54EWAl",
        "title": "Hiding in Plain Sight: Tweets with Hate Speech Masked by Homoglyphs",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Homoglyphs;Dataset;Hate Speech Detection;Twitter",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "3;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "qhwYFIrSm7",
        "title": "A Diachronic Analysis of Paradigm Shifts in NLP Research: When, How, and Why?",
        "track": "main",
        "status": "Long Main",
        "keywords": "Scholarly Document Processing;NLP Scientometrics",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "qiV0mvkVyq",
        "title": "PROSE: A Pronoun Omission Solution for Chinese-English Spoken Language Translation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Chinese-English Spoken Language Translation;Zero-Pronoun;Mention-Aware Semantic Augmentation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "qlCtkvgQJH",
        "title": "LogiCoT: Logical Chain-of-Thought Instruction Tuning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "instruction tuning;chain-of-thought;large language model;logical reasoning;GPT-4",
        "authors": "",
        "rating": "",
        "confidence": "5;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "qlwXv0oHJD",
        "title": "Towards Noise-Tolerant Speech-Referring Video Object Segmentation: Bridging Speech and Text",
        "track": "main",
        "status": "Long Main",
        "keywords": "Noisy Speech;Speech-Referring Video Object Segmentation",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "qnHB2SMQLA",
        "title": "Take a Closer Look at Multilinguality! Improve Multilingual Pre-Training Using Monolingual Corpora Only",
        "track": "main",
        "status": "Long Findings",
        "keywords": "multilinguality;mutlilingual pre-training",
        "authors": "",
        "rating": "",
        "confidence": "5;5;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "qnO9IRNA9d",
        "title": "Instructed Language Models with Retrievers Are Powerful Entity Linkers",
        "track": "main",
        "status": "Long Main",
        "keywords": "Knowledge Grounding;Entity Linking;Generative Model;Large Language Model",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "qo17ZiVnH2",
        "title": "Filling the Image Information Gap for VQA: Prompting Large Language Models to Proactively Ask Questions",
        "track": "main",
        "status": "Long Findings",
        "keywords": "visual question answering;knowledge reasoning;in-context learning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "qq6ctdUwCX",
        "title": "Loose lips sink ships: Mitigating Length Bias in Reinforcement Learning from Human Feedback",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Alignment;Large Language Model;Debias",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "qtZI5YDe5d",
        "title": "UReader: Universal OCR-free Visually-situated Language Understanding with Multimodal Large Language Model",
        "track": "main",
        "status": "Long Findings",
        "keywords": "OCR-free;visually-situated language understanding;multimodal large language model",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;2;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "qvftjm8DNC",
        "title": "The PEACE-Reviews dataset: Modeling Cognitive Appraisals in Emotion Text Analysis",
        "track": "main",
        "status": "Long Findings",
        "keywords": "cognitive appraisals;emotions;language modeling;computational social science",
        "authors": "",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "qyvabTsnWg",
        "title": "Document-level Relationship Extraction by Bidirectional Constraints of Beta Rules",
        "track": "main",
        "status": "Long Main",
        "keywords": "Document-level Relation Extraction;Logical Consistency;Beta Distribution;Bidirectional Constraints",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "qzYtTabDPY",
        "title": "Revisiting the Optimality of Word Lengths",
        "track": "main",
        "status": "Long Main",
        "keywords": "word length;uniform information density;zipf;law of abbreviation",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "r2z3qPltxs",
        "title": "Counter Turing Test (CT2): AI-Generated Text Detection is Not as Easy as You May Think - Introducing AI Detectability Index (ADI)",
        "track": "main",
        "status": "Long Main",
        "keywords": "AI-generated text detection",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;5;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.666666666666667,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "r3utB5u4zP",
        "title": "Generating and Evaluating Tests for K-12 Students with Language Model Simulations: A Case Study on Sentence Reading Efficiency",
        "track": "main",
        "status": "Long Main",
        "keywords": "language model;student test generation;psychometrics",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "r65IWQmsHF",
        "title": "Understanding HTML with Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "html understanding;web navigation;large language models;semantic classification;description generation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "rBfVlElyVW",
        "title": "MAGNIFICo: Evaluating the In-Context Learning Ability of Large Language Models to Generalize to Novel Interpretations",
        "track": "main",
        "status": "Long Main",
        "keywords": "Benchmarking LLMs;Compositional Generalization;In-Context Learning",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4;3",
        "correctness": "4;4;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 4.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "rBrzSCruKl",
        "title": "Promoting Topic Coherence and Inter-Document Consorts in Multi-Document Summarization via Simplicial Complex and Sheaf Graph",
        "track": "main",
        "status": "Long Main",
        "keywords": "multi document summarization;abstractive summarization",
        "authors": "",
        "rating": "",
        "confidence": "3;5;1",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "rDuv0LGf3T",
        "title": "Prompting ChatGPT in MNER: Enhanced Multimodal Named Entity Recognition with Auxiliary Refined Knowledge",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multimodal Named Entity Recognition;Information Extraction;Large Language Model",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "rG3QZA7JXV",
        "title": "CRT-QA: A Dataset of Complex Reasoning Question Answering over Tabular Data",
        "track": "main",
        "status": "Long Main",
        "keywords": "Table QA;Table analysis;Large language model reasoning;Large language model with tool-use",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "rHjZFQvj9k",
        "title": "Norm of Word Embedding Encodes Information Gain",
        "track": "main",
        "status": "Long Main",
        "keywords": "Word embedding;Euclidean norm;Skip-gram with Negative Sampling;Softmax function;Kullback-Leibler divergence;Information geometry;Exponential family of probability distributions",
        "authors": "",
        "rating": "",
        "confidence": "3;4;2",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "rI7ebWPRLr",
        "title": "Efficient Long-Range Transformers: You Need to Attend More, but Not Necessarily at Every Layer",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Long-Range Transformer;Attention Mechanism;Mixed Attention Span",
        "authors": "",
        "rating": "",
        "confidence": "5;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "rIc17Kziiq",
        "title": "Larger Probes Tell a Different Story: Extending Psycholinguistic Datasets Via In-Context Learning",
        "track": "main",
        "status": "Short Main",
        "keywords": "Psycholinguistic datasets;Negation;Role Reversal;Larger Dataset;ICL",
        "authors": "",
        "rating": "",
        "confidence": "5;5;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "rJXYb7D4ck",
        "title": "Tagging-Assisted Generation Model with Encoder and Decoder Supervision for Aspect Sentiment Triplet Extraction",
        "track": "main",
        "status": "Long Main",
        "keywords": "ABSA; ASTE; sentiment analysis; generation seq2seq model; sequence tagging;  semantic alignment",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "rJhk7Fpnvh",
        "title": "Sources of Hallucination by Large Language Models on Inference Tasks",
        "track": "main",
        "status": "Long Findings",
        "keywords": "LLM;LM;language model;hallucination;natural language inference;NLI;entailment;directional;attestation;relative frequency;predicate",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "rKjzOYrXKd",
        "title": "GRENADE: Graph-Centric Language Model for Self-Supervised Representation Learning on Text-Attributed Graphs",
        "track": "main",
        "status": "Long Findings",
        "keywords": "textual attributed graph;text rich network;representation learning;graph neural network;language model",
        "authors": "",
        "rating": "",
        "confidence": "2;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "rLx2eDYcMK",
        "title": "VivesDebate-Speech: A Corpus of Spoken Argumentation to Leverage Audio Features for Argument Mining",
        "track": "main",
        "status": "Short Main",
        "keywords": "Argument Mining;Argument Segmentation;Argument Classification;Speech Corpus",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "rMLnxh4oT5",
        "title": "CASE: Commonsense-Augmented Score with an Expanded Answer Space",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Commonsense Reasoning;Question Answering;Language Model;Zero-shot",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3;3",
        "correctness": "4;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "rQJAaOh4nr",
        "title": "Self-prompted Chain-of-Thought on Large Language Models for Open-domain Multi-hop Reasoning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Chain-of-Thought;Large Language Models;In-context-Learning;Open-domain question-answering;Multi-hop question-answering",
        "authors": "",
        "rating": "",
        "confidence": "2;1;5",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "rRwPzcSFeL",
        "title": "TrueTeacher: Learning Factual Consistency Evaluation with Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "factuality;attribution;consistency;hallucinations",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "rTAIgZe3wo",
        "title": "ACTOR: Active Learning with Annotator-specific Classification Heads to Embrace Human Label Variation",
        "track": "main",
        "status": "Short Main",
        "keywords": "Active Learning;Human Label Variation;Multi-task Learning",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "rVsnAmxnR9",
        "title": "Ask To The Point: Open-Domain Entity-Centric Question Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Question Generation;Entity-Centric;Multi-Task",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "rXn9WO4M2p",
        "title": "Self-Influence Guided Data Reweighting for Language Model Pre-training",
        "track": "main",
        "status": "Long Main",
        "keywords": "pre-training;multilingual pretraining;self-influence;language models;data reweighting",
        "authors": "",
        "rating": "",
        "confidence": "5;5;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "rbaK24KnIO",
        "title": "Combining Denoising Autoencoders with Contrastive Learning to fine-tune Transformer Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "transfer learning;contrastive learning;denoising autoencoders;NLU",
        "authors": "",
        "rating": "",
        "confidence": "3;2;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "rd0C4kD0o4",
        "title": "Efficient Latent Variable Modeling for Knowledge-Grounded Dialogue Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "knowledge-grounded dialogue generation",
        "authors": "",
        "rating": "",
        "confidence": "4;2;4;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "rgKfPzAF2j",
        "title": "Byte Pair Encoding for Symbolic Music",
        "track": "main",
        "status": "Long Main",
        "keywords": "Symbolic music;BPE;Music generation;MIR",
        "authors": "",
        "rating": "",
        "confidence": "3;4;2;3",
        "correctness": "4;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "rgos321qpD",
        "title": "PEFTDebias : Capturing debiasing information using PEFTs",
        "track": "main",
        "status": "Short Main",
        "keywords": "paramter-efficient finetuning (PEFT);bias mitigation;debias;bias;gender;group;language model;debiasing;LoRA debias;prompt debias;adapter debias",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "rhGh8jLOPd",
        "title": "MaXM: Towards Multilingual Visual Question Answering",
        "track": "main",
        "status": "Long Findings",
        "keywords": "VQA;multilinguality",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "rjDaTBwEBX",
        "title": "In What Languages are Generative Language Models the Most Formal? Analyzing Formality Distribution across Languages",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multilingual language models;language models;formality bias analysis;bias analysis in language models",
        "authors": "",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "rjd8AqRyW3",
        "title": "OpenAsp: A Benchmark for Multi-document Open Aspect-based Summarization",
        "track": "main",
        "status": "Long Main",
        "keywords": "Aspect-based Summarization;Datasets;Annotation;Multi-document Summarization",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "rmhSMGjWPp",
        "title": "Multi-label and Multi-target Sampling of Machine Annotation for Computational Stance Detection",
        "track": "main",
        "status": "Short Findings",
        "keywords": "stance detection;machine annotation;computational social science",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "rn7Fn3CV7b",
        "title": "CoVariance-based Causal Debiasing for Entity and Relation Extraction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Causal Debiasing;Entity and Relation Extraction;Covariance Optimizing;Variance Optimizing",
        "authors": "",
        "rating": "",
        "confidence": "4;2;4;4",
        "correctness": "3;4;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "rq4UfmpRA9",
        "title": "Democratizing Reasoning Ability: Tailored Learning from Large Language Model",
        "track": "main",
        "status": "Long Main",
        "keywords": "large language model;reasoning;distillation;open-source",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "rs78DlnUB8",
        "title": "Complexity-Guided Curriculum Learning for Text Graphs",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Curriculum Learning;Graph Neural Network;Text Graph",
        "authors": "",
        "rating": "",
        "confidence": "3;3;2",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "rwHOXIBFwq",
        "title": "Combining Counting Processes and Classification Improves a Stopping Rule for Technology Assisted Review",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Technology assisted review;TAR;total recall;stopping criteria;counting processes;classification",
        "authors": "",
        "rating": "",
        "confidence": "2;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "rwcLHjtUmn",
        "title": "A Suite of Generative Tasks for Multi-Level Multimodal Webpage Understanding",
        "track": "main",
        "status": "Long Main",
        "keywords": "Webpage Understanding;Multimodal Data;Text Generation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "5;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.666666666666667,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "rwcTxeSsVI",
        "title": "For Generated Text, Is NLI-Neutral Text the Best Text?",
        "track": "main",
        "status": "Short Findings",
        "keywords": "generation;natural language inference",
        "authors": "",
        "rating": "",
        "confidence": "2;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "rwpv2kCt4X",
        "title": "Accuracy is not enough: Evaluating Personalization in Summarizers",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Personalized Summarization Evaluation;Meta Evaluation;Automated Accuracy Metrics",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "rzW3RouIXc",
        "title": "Query-as-context Pre-training for Dense Passage Retrieval",
        "track": "main",
        "status": "Long Main",
        "keywords": "Query prediction;Dense passage retrieval;Pre-training",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "rzdqmUFVnv",
        "title": "Multi-Granularity Information Interaction Framework for Incomplete Utterance Rewriting",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Incomplete Utterance Rewriting;Information Interaction;Multi-Granularity",
        "authors": "",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "s1Lrw1HTcT",
        "title": "ChatGPT to Replace Crowdsourcing of Paraphrases for Intent Classification: Higher Diversity and Comparable Model Robustness",
        "track": "main",
        "status": "Long Main",
        "keywords": "natural language generation;paraphrase generation;crowdsourcing;large language models;intent classification;text diversity",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "s4xIeYimGQ",
        "title": "Large Language Models are Better Reasoners with Self-Verification",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large Language Models;Self-verification;Reasoning Ability;Chain of Thought;Backward Verification",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "s7Vh8OIIm6",
        "title": "Hybrid Inverted Index Is a Robust Accelerator for Dense Retrieval",
        "track": "main",
        "status": "Long Main",
        "keywords": "Dense Retrieval;ANN Index;Inverted Index",
        "authors": "",
        "rating": "",
        "confidence": "2;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "sCtJmxhvJe",
        "title": "\"Fifty Shades of Bias\": Normative Ratings of Gender Bias in GPT Generated English Text",
        "track": "main",
        "status": "Long Main",
        "keywords": "Gender bias;NLP;LLMs;GPT",
        "authors": "",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "sCu26OfxxZ",
        "title": "INA: An Integrative Approach for Enhancing Negotiation Strategies with Reward-Based Dialogue Agent",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Negotiation;Dialogue Agent;Prompting",
        "authors": "",
        "rating": "",
        "confidence": "5;2;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "sCxiD2Rx4l",
        "title": "DUnE: Dataset for Unified Editing",
        "track": "main",
        "status": "Long Main",
        "keywords": "Model Editing;Editing Large Language Models;Learning from Human Feedback",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "sEvU6r8e7N",
        "title": "RefGPT: Dialogue Generation of GPT, by GPT, and for GPT",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Dialogue Generation;GPT;Model Hallucination;LLM",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "sFtyaTTtap",
        "title": "Towards Example-Based NMT with Multi-Levenshtein Transformers",
        "track": "main",
        "status": "Long Main",
        "keywords": "Neural Machine Translation;Non Autoregressive Transformers;Levenshtein Transformer;Translation Memory;Computer Assisted Translation",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "5;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "sGrYJQZMQo",
        "title": "Active Instruction Tuning: Improving Cross-Task Generalization by Training on Prompt Sensitive Tasks",
        "track": "main",
        "status": "Long Main",
        "keywords": "Instruction Tuning;Large Language Models;Active Learning",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4;5",
        "correctness": "4;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "sJUCMYtgIK",
        "title": "Augmenting Zero-Shot Dense Retrievers with Plug-in Mixture-of-Memories",
        "track": "main",
        "status": "Long Main",
        "keywords": "Retrieval Augmented Language Model;Zero-shot Dense Retrieval;Mixture of Memory",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "sJb43ykK3o",
        "title": "RegaVAE: A Retrieval-Augmented Gaussian Mixture Variational Auto-Encoder for Language Modeling",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Retrieval-Augmented Language Model;Hallucination;Variational Auto-Encoder",
        "authors": "",
        "rating": "",
        "confidence": "5;2;3",
        "correctness": "2;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "sKdsBUAnts",
        "title": "Building Persona Consistent Dialogue Agents with Offline Reinforcement Learning",
        "track": "main",
        "status": "Long Main",
        "keywords": "NLP;persona consistent dialogue;offline reinforcement learning",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "sM9NTLjsUh",
        "title": "Failures Pave the Way: Enhancing Large Language Models through Tuning-free Rule Accumulation",
        "track": "main",
        "status": "Long Main",
        "keywords": "large langauge models;zero-shot learning;prompt",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "sOTbFCUrDj",
        "title": "A Generation-based Deductive Method for Math Word Problems",
        "track": "main",
        "status": "Long Main",
        "keywords": "math word problem;natural language processing",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "sOngusZCsN",
        "title": "Knowledge-Augmented Language Model Verification",
        "track": "main",
        "status": "Long Main",
        "keywords": "Knowledge-Augmented Language Models;Verification",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "sPB354cbmL",
        "title": "Improved Training of Deep Text Clustering",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Text Clustering;Deep Clustering",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 1.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "sPpft5DQJN",
        "title": "Interpreting Embedding Spaces by Conceptualization",
        "track": "main",
        "status": "Long Main",
        "keywords": "Interpretability;knowledge tracing",
        "authors": "",
        "rating": "",
        "confidence": "3;5;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "sQ1iTreITk",
        "title": "Density-Aware Prototypical Network for Few-Shot Relation Classification",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Few-shot relation classification;None-of-the-above challenge;Density estimation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "sRHVpB7GE6",
        "title": "Fast and Accurate Factual Inconsistency Detection Over Long Documents",
        "track": "main",
        "status": "Long Main",
        "keywords": "Hallucination detection;Inconsistency detection;hallucination;automatic evaluation;metric;long document;efficient;fast;accurate;long;natural language generation;task agnostic;nlp;nlg",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "sS02W7Sloj",
        "title": "Diversify Question Generation with Retrieval-Augmented Style Transfer",
        "track": "main",
        "status": "Long Main",
        "keywords": "Question Generation; Retrieval Augmented Generation;Style Transfer",
        "authors": "",
        "rating": "",
        "confidence": "3;2;1",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "sTeoqvTH2j",
        "title": "HiCL: Hierarchical Contrastive Learning of Unsupervised Sentence Embeddings",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Contrastive Learning;Semantic Textual Similarity;Hierarchical Training",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4;2",
        "correctness": "2;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "sVSeGRCZT8",
        "title": "Three Stream Based Multi-level Event Contrastive Learning for Text-Video Event Extraction",
        "track": "main",
        "status": "Long Main",
        "keywords": "Event extraction; Multimodal",
        "authors": "",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "sX4yqbYlRm",
        "title": "Beneath Surface Similarity: Large Language Models Make Reasonable Scientific Analogies after Structure Abduction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Analogical Reasoning;Large Language Models;Resources and Benchmark",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "sXErPfdA7Q",
        "title": "Document-Level Machine Translation with Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Models;Document-Level Machine Translation;Evaluation and Explaination",
        "authors": "",
        "rating": "",
        "confidence": "5;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "sYYRTVaG3n",
        "title": "Meta-Learning of Prompt Generation for Lightweight Prompt Engineering on Language-Model-as-a-Service",
        "track": "main",
        "status": "Long Findings",
        "keywords": "prompt tuning;prompt engineering;in-context learning;language model",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "sZEAMUizsd",
        "title": "Outlier Suppression+: Accurate quantization of large language models by equivalent and effective shifting and scaling",
        "track": "main",
        "status": "Long Main",
        "keywords": "quantization;large language models;outlier",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3;4;4",
        "correctness": "2;4;4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6,
        "correctness_avg": 3.4,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "sZGAxcUcNU",
        "title": "Memory-Based Invariance Learning for Out-of-Domain Text Classification",
        "track": "main",
        "status": "Long Main",
        "keywords": "Domain generalization; key-value memory; invariance learning; transfer learning",
        "authors": "",
        "rating": "",
        "confidence": "3;3;2",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "sbLFUT4DaG",
        "title": "Increasing Coverage and Precision of Textual Information in Multilingual Knowledge Graphs",
        "track": "main",
        "status": "Long Main",
        "keywords": "knowledge graph;multilingual;entity linking;knowledge graph completion",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "sbuO0s1r71",
        "title": "Evaluating Cross-Domain Text-to-SQL Models and Benchmarks",
        "track": "main",
        "status": "Long Main",
        "keywords": "Text-to-SQL;Natural language interfaces to databases;Benchmarks;Evaluation",
        "authors": "",
        "rating": "",
        "confidence": "3;5;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "scAXKWMJR3",
        "title": "Automated Few-Shot Classification with Instruction-Finetuned Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "few-shot classification;prompt automation;large language models",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "sdC55K8cP0",
        "title": "WikiChat: Stopping the Hallucination of Large Language Model Chatbots by Few-Shot Grounding on Wikipedia",
        "track": "main",
        "status": "Long Findings",
        "keywords": "large language models;hallucination;knowledge-grounded dialogue",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "2;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "se0YmUUfPs",
        "title": "Manipulating the Perceived Personality Traits of Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "nlp",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3;4",
        "correctness": "2;5;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "sfkpJxeDzk",
        "title": "The Framework Tax: Disparities Between Inference Efficiency in NLP Research and Deployment",
        "track": "main",
        "status": "Long Main",
        "keywords": "efficiency;latency;inference",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "siiVduxdRz",
        "title": "Condensing Multilingual Knowledge with Lightweight Language-Specific Modules",
        "track": "main",
        "status": "Long Main",
        "keywords": "Multilingual Machine Translation;Lightweight;Language interference;Distillation",
        "authors": "",
        "rating": "",
        "confidence": "5;4;3",
        "correctness": "4;3;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "sriK75T3kd",
        "title": "No offence, Bert - I insult only humans! Multilingual sentence-level attack on toxicity detection networks",
        "track": "main",
        "status": "Short Findings",
        "keywords": "toxicity detection;adversarial attack;multilingual;neural networks",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "st5RaWdLTn",
        "title": "AdaTranS: Adapting with Boundary-based Shrinking for End-to-End Speech Translation",
        "track": "main",
        "status": "Short Findings",
        "keywords": "speech translation;modality adaptation",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4;4",
        "correctness": "2;4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "sthusQGkef",
        "title": "Chain of Thought with Explicit Evidence Reasoning for Few-shot Relation Extraction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Relation Extraction;In-context Learning;Few Shot Learning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "svSNikfCs1",
        "title": "Exploiting Asymmetry for Synthetic Training Data Generation: SynthIE and the Case of Information Extraction",
        "track": "main",
        "status": "Long Main",
        "keywords": "LLM;Synthetic Data Generation;Information Extraction;Closed Information Extraction;Parsing;Structured Output",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "svUOik2Xu1",
        "title": "Robust Prompt Optimization for Large Language Models Against Distribution Shifts",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Model; prompt optimization; distribution shifts; sentiment analysis; question answering;",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "sxJU7X2ZG0",
        "title": "Generative Calibration for In-context Learning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Calibration;In-context Learning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "syj9VaxutQ",
        "title": "A Framework for Exploring Player Perceptions of LLM-Generated Dialogue in Commercial Video Games",
        "track": "main",
        "status": "Long Findings",
        "keywords": "human-centered;dialogue generation;video games;interactive storytelling",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "t035Emm4Vt",
        "title": "WSDMS: Debunk Fake News via Weakly Supervised Detection of Misinforming Sentences with Contextualized Social Wisdom",
        "track": "main",
        "status": "Long Main",
        "keywords": "Fake News Detection;Weakly Supervised Learning;Misinformation;Social Network",
        "authors": "",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "t42YUsyv3d",
        "title": "DRAFT: Dense Retrieval Augmented Few-shot Topic classifier Framework",
        "track": "main",
        "status": "Long Findings",
        "keywords": "few-shot topic classification;real-world application",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 1.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "t6p5LtTlqr",
        "title": "Enhancing Neural Machine Translation with Semantic Units",
        "track": "main",
        "status": "Long Findings",
        "keywords": "machine translation",
        "authors": "",
        "rating": "",
        "confidence": "4;5;4;1",
        "correctness": "4;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "tBtc4Ousge",
        "title": "Intervention-Based Alignment of Code Search with Execution Feedback",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Code Search;Misalignment;Reinforcement Learning;Intervention",
        "authors": "",
        "rating": "",
        "confidence": "4;4;2",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "tCEtFcrq8n",
        "title": "Generalizing Few-Shot Named Entity Recognizers to Unseen Domains with Type-Related Features",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Named entity recognition;Few-shot learning;Domain generalization;Prompt learning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "tCGyM6CpRI",
        "title": "Optimizing Retrieval-augmented Reader Models via Token Elimination",
        "track": "main",
        "status": "Long Main",
        "keywords": "fusion in decoder;efficiency;long-form question answering",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "tEN5ONyUre",
        "title": "Interpreting Indirect Answers to Yes-No Questions in Multiple Languages",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multilinguality;Question Answering;Yes-no Question",
        "authors": "",
        "rating": "",
        "confidence": "4;2;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "tJt1v8eugw",
        "title": "Multi-Defendant Legal Judgment Prediction via Hierarchical Reasoning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "legal text mining;legal judgment prediction;legal reasoning",
        "authors": "",
        "rating": "",
        "confidence": "5;5;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "tL7hS11keH",
        "title": "CoAnnotating: Uncertainty-Guided Work Allocation between Human and Large Language Models for Data Annotation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Human\u2013Artificial Intelligence Collaboration;Large Language Model;Data Annotation;Weak Supervision",
        "authors": "",
        "rating": "",
        "confidence": "5;4;3;4",
        "correctness": "3;5;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "tNN3ToWzCM",
        "title": "Smart \u201cChef\u201d: Verifying the Effect of Role-based Paraphrasing for Aspect Term Extraction",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Information Extraction;Aspect Term Extraction;ChatGPT",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3;4",
        "correctness": "3;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "tPJDg5G9SR",
        "title": "Attack Prompt Generation for Red Teaming and Defending Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large Language Models;Red Teaming Attack;Defense;Safety",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "tQOncmMEVO",
        "title": "G-SPEED: General SParse Efficient Editing MoDel",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Text Editing",
        "authors": "",
        "rating": "",
        "confidence": "3;2;4",
        "correctness": "2;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "tRYqTsaSyZ",
        "title": "Causal Intervention for Abstractive Related Work Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Related work generation;text summarization;causal intervention",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "tSfZo6nSN1",
        "title": "RECAP: Towards Precise Radiology Report Generation via Dynamic Disease Progression Reasoning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "radiology report generation;text generation grounded on vision",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "2;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "tZXaHWfsXB",
        "title": "Transcending Scaling Laws with 0.1% Extra Compute",
        "track": "main",
        "status": "Long Main",
        "keywords": "language models;scaling laws;emergent abilities;efficiency;pretraining",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4;3",
        "correctness": "4;5;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 4.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "taXJRZs43y",
        "title": "Where to start? Analyzing the potential value of intermediate models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Intertraining;fine tuned;intermediate;finetune",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4;2",
        "correctness": "4;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "tauoKi9IWO",
        "title": "LLMDet: A Third Party Large Language Models Generated Text Detection Tool",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Text Detection;Large Language Model;Fine-grained Tracing;Proxy Perplexity",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4;4;4",
        "correctness": "3;3;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.8,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "tbHe97ENFD",
        "title": "Exploring the Impact of Corpus Diversity on Financial Pretrained Language Models",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Financial NLP;Pre-trained Language Model;Generalization",
        "authors": "",
        "rating": "",
        "confidence": "5;3;2;5",
        "correctness": "3;3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "tbRPPWDy76",
        "title": "MEEP: Is this Engaging? Prompting Large Language Models for Dialogue Evaluation in Multilingual Settings",
        "track": "main",
        "status": "Long Findings",
        "keywords": "automatic evaluation of dialogue;dialogue evaluation;multilingual;metrics;engagingness;prompting;LLM;large language model;multilinguality",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "te3pXuiVk3",
        "title": "MemeCap: A Dataset for Captioning and Interpreting Memes",
        "track": "main",
        "status": "Long Main",
        "keywords": "meme;captioning;image;large multimodal model",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "tfHJ9uLNlR",
        "title": "BiSPN: Generating Entity Set and Relation Set Coherently in One Pass",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Information Extraction;Joint Entity-Relation Extraction;Non-autoregressive Generation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "tkY0l8mHii",
        "title": "A Query-Parallel Machine Reading Comprehension Framework for Low-resource NER",
        "track": "main",
        "status": "Long Findings",
        "keywords": "NER;low-resource;in-domain transfer;cross-domain transfer",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "tm5UxNFrlD",
        "title": "Location-Aware Visual Question Generation with Lightweight Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Location-aware Visual Question Generation;Visual Question Generation;Question Generation;Lightweight Models",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "toUPGCAMic",
        "title": "ALCUNA: Large Language Models Meet New Knowledge",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Model;Model Evaluation;Knowledge",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "tquKyw04gE",
        "title": "MultiCoNER v2: a Large Multilingual dataset for Fine-grained and Noisy Named Entity Recognition",
        "track": "main",
        "status": "Short Findings",
        "keywords": "ner;multilingual ner;fine-grained ner;noisy ner",
        "authors": "",
        "rating": "",
        "confidence": "3;5;4",
        "correctness": "3;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "tueh30tKiv",
        "title": "Length is a Curse and a Blessing for Document-level Semantics",
        "track": "main",
        "status": "Long Main",
        "keywords": "contrastive learning;sentence representation learning;document representation learning;semantics;document length",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4;5",
        "correctness": "3;4;3;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "u03xn1COsO",
        "title": "Is ChatGPT a General-Purpose Natural Language Processing Task Solver?",
        "track": "main",
        "status": "Long Main",
        "keywords": "Chatgpt evaluation;general-purpose task solver;zero-shot learning",
        "authors": "",
        "rating": "",
        "confidence": "4;5;2;3",
        "correctness": "3;4;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "u14dVx4rMW",
        "title": "ImageNetVC: Zero- and Few-Shot Visual Commonsense Evaluation on 1000 ImageNet Categories",
        "track": "main",
        "status": "Long Findings",
        "keywords": "visual commonsense;large language model;visually-augmented language model",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "u69aCtohTC",
        "title": "Unveiling the Implicit Toxicity in Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Model;Toxicity;Safety;Reinforcement Learning",
        "authors": "",
        "rating": "",
        "confidence": "3;4;2;4",
        "correctness": "4;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "u9Fvsy8Brx",
        "title": "mmT5: Modular Multilingual Pre-Training Solves Source Language Hallucinations",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Modularity;Multilinguality;Adapters;Parameter-efficiency",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "u9gI4JlOSj",
        "title": "How Does Generative Retrieval Scale to Millions of Passages?",
        "track": "main",
        "status": "Long Main",
        "keywords": "generative retrieval;differentiable search index;information retrieval",
        "authors": "",
        "rating": "",
        "confidence": "3;5;2",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "uB9ZnBCBX6",
        "title": "Text-Transport: Toward Learning Causal Effects of Natural Language",
        "track": "main",
        "status": "Long Main",
        "keywords": "causal inference;causal effects;distribution shift;domain adaptation;transportability",
        "authors": "",
        "rating": "",
        "confidence": "2;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "uBnIvIcAFx",
        "title": "Vera: A General-Purpose Plausibility Estimation Model for Commonsense Statements",
        "track": "main",
        "status": "Long Main",
        "keywords": "commonsense;verification;plausibility",
        "authors": "",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "uDMyRJw6ty",
        "title": "Clinical Contradiction Detection",
        "track": "main",
        "status": "Long Main",
        "keywords": "clinical contradiction detection;medical ontologies;clinical distant supervision",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "uEAFmlWYig",
        "title": "Towards Robust Pruning: An Adaptive Knowledge-Retention Pruning Strategy for Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Robust Pruning;Language Models",
        "authors": "",
        "rating": "",
        "confidence": "2;2;2;4;2",
        "correctness": "3;3;3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.4,
        "correctness_avg": 3.4,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "uPz5a2NvrG",
        "title": "Normal-Abnormal Decoupling Memory for Medical Report Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Medical Report Generation;Normal-Abnormal Decoupling;Semantic Extraction;Abnormal Mode Memory",
        "authors": "",
        "rating": "",
        "confidence": "4;2;5",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "uQfyuhhHBq",
        "title": "Penalty Decoding: Well Suppress the Self-Reinforcement Effect in Open-Ended Text Generation",
        "track": "main",
        "status": "Short Main",
        "keywords": "decoding algorithm;open-ended text generation;self-reinforcement;repetition penalty",
        "authors": "",
        "rating": "",
        "confidence": "5;4;5",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "uRIFDS3gtG",
        "title": "LACMA: Language-Aligning Contrastive Learning with Meta-Actions for Embodied Instruction Following",
        "track": "main",
        "status": "Long Main",
        "keywords": "Embodied AI;Vision and Language Navigation",
        "authors": "",
        "rating": "",
        "confidence": "5;3;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "uUvlXyriM7",
        "title": "CLASS: A Design Framework for Building Intelligent Tutoring Systems Based on Learning Science principles",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Intelligent Tutoring Systems;NLP for education;AI Tutors;Learning Science",
        "authors": "",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "uZp3i8yEs4",
        "title": "`Don't Get Too Technical with Me': A Discourse Structure-Based Framework for Automatic Science Journalism",
        "track": "main",
        "status": "Long Main",
        "keywords": "automatic scientific journalism;summarization;style transfer",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "uaZQ21cuzW",
        "title": "From Wrong To Right: A Recursive Approach Towards Vision-Language Explanation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Vision-Language Models;Visual Reasoning;Vision-Language Explanation;Self Training",
        "authors": "",
        "rating": "",
        "confidence": "3;2;5",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ubXaboYnzN",
        "title": "QTSumm: Query-Focused Summarization over Tabular Data",
        "track": "main",
        "status": "Long Main",
        "keywords": "Summarization;Text Generation;Reasoning over Structured Data",
        "authors": "",
        "rating": "",
        "confidence": "5;3;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "uckh15CSS1",
        "title": "ExplainCPE: A Free-text Explanation Benchmark of Chinese Pharmacist Examination",
        "track": "main",
        "status": "Long Findings",
        "keywords": "datasets;interpretability;large language model",
        "authors": "",
        "rating": "",
        "confidence": "5;2;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "udiNCxGKLl",
        "title": "Transformer-Based Language Model Surprisal Predicts Human Reading Times Best with About Two Billion Training Tokens",
        "track": "main",
        "status": "Short Findings",
        "keywords": "surprisal theory;human sentence processing;large language models",
        "authors": "",
        "rating": "",
        "confidence": "5;5;5",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 5.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "udl5f2seyU",
        "title": "DiFair: A Benchmark for Disentangled Assessment of Gender Knowledge and Bias",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Bias;Gender-Bias;Transformers;Task;Dataset;Language Modeling",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "uemYdRTVvP",
        "title": "SeqXGPT: Sentence-Level AI-Generated Text Detection",
        "track": "main",
        "status": "Long Main",
        "keywords": "AI generated text detection;security in NLP;LLM",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ufu4C0bTwB",
        "title": "Target-oriented Proactive Dialogue Systems with Personalization: Problem Formulation and Dataset Curation",
        "track": "main",
        "status": "Short Main",
        "keywords": "Target-oriented dialogue;Proactive dialogue;Personalization;Dataset curation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;2",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "uh5euNmL7t",
        "title": "Hyperpolyglot LLMs: Cross-Lingual Interpretability in Token Embeddings",
        "track": "main",
        "status": "Short Main",
        "keywords": "Multilingual models;cross-lingual representations",
        "authors": "",
        "rating": "",
        "confidence": "3;3;2",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "uhVJ3SLq80",
        "title": "BioT5: Enriching Cross-modal Integration in Biology with Chemical Knowledge and Natural Language Associations",
        "track": "main",
        "status": "Long Main",
        "keywords": "cross-modal;biology;text;molecule;protein",
        "authors": "",
        "rating": "",
        "confidence": "2;4;4;4",
        "correctness": "4;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ul47tFdRn6",
        "title": "DiffuVST: Narrating Fictional Scenes with Global-History-Guided Denoising Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "visual storytelling;diffusion language models;global history guidance",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "2;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ulqYwmcUnL",
        "title": "XTREME-UP: A User-Centric Scarce-Data Benchmark for Under-Represented Languages",
        "track": "main",
        "status": "Long Findings",
        "keywords": "nlp;low-resource;under-represented;scarce data;benchmark",
        "authors": "",
        "rating": "",
        "confidence": "5;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "unKIy4mpnn",
        "title": "Making Body Movement in Sign Language Corpus Accessible for Linguists and Machines with Three-Dimensional Normalization of MediaPipe",
        "track": "main",
        "status": "Long Findings",
        "keywords": "sign language;pose processing;wlasl;movement processing",
        "authors": "",
        "rating": "",
        "confidence": "3;5;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "up8EYzyrKV",
        "title": "Towards Mitigating LLM Hallucination via Self Reflection",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Hallucination;Large Language Model;Medical Question Answering;Generative Question Answering;Question Answering",
        "authors": "",
        "rating": "",
        "confidence": "3;3;5;4",
        "correctness": "4;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "us7p0VsOhl",
        "title": "GLGR: Question-aware Global-to-Local Graph Reasoning for Multi-party Dialogue Reading Comprehension",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multi-party dialogue reading comprehension;Global-to-local graph reasoning",
        "authors": "",
        "rating": "",
        "confidence": "2;4;3;4",
        "correctness": "4;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "usnEi3Bfnt",
        "title": "Structural generalization in COGS: Supertagging is (almost) all you need",
        "track": "main",
        "status": "Long Main",
        "keywords": "semantic parsing;compositional generalization;graph-based parsing",
        "authors": "",
        "rating": "",
        "confidence": "2;3;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "uu6Oq7MN7g",
        "title": "CodeT5+: Open Code Large Language Models for Code Understanding and Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Model;Code Intelligence;Code Understanding and Generation",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "uuUQraD4XX",
        "title": "Large Language Models Can Self-Improve",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Models;Commonsense Reasoning;Arithmetic Reasoning;Chain of Thought",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4;4",
        "correctness": "3;4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "uvbbsn4l6y",
        "title": "Look-back Decoding for Open-Ended Text Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "open-ended text generation;decoding;story generation;document continuation",
        "authors": "",
        "rating": "",
        "confidence": "2;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ux826WlJtt",
        "title": "DemoSG: Demonstration-enhanced Schema-guided Generation for Low-resource Event Extraction",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Low-resource;Event Extraction;Few-shot;Domain Adaptation;Demonstration-based Learning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;2",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "uxzlH5bLrJ",
        "title": "Can Brain Signals Reveal Inner Alignment with Human Languages?",
        "track": "main",
        "status": "Short Findings",
        "keywords": "EEG;Human Languages;Inner Alignment;Interpretation",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4;3",
        "correctness": "3;3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 1.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "uyUO80sbm0",
        "title": "Explain-then-translate: an analysis on improving program translation with self-generated explanations",
        "track": "main",
        "status": "Long Findings",
        "keywords": "code generation;machine translation;program translation;large language model;prompting;chain-of-thought",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "uyl1O2LkAF",
        "title": "TaTA: A Multilingual Table-to-Text Dataset for African Languages",
        "track": "main",
        "status": "Long Findings",
        "keywords": "table-to-text;multilingual;NLG;African languages",
        "authors": "",
        "rating": "",
        "confidence": "3;1;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "uz4OrlHDA8",
        "title": "Predict the Future from the Past? On the Temporal Data Distribution Shift in Financial Sentiment Classifications",
        "track": "main",
        "status": "Long Main",
        "keywords": "Distribution Shift;Financial Sentiment Classifications;Language Models Robustness",
        "authors": "",
        "rating": "",
        "confidence": "3;3;2",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "uz89EXE540",
        "title": "Self-Supervised Rule Learning to Link Text Segments to Relational Elements of Structured Knowledge",
        "track": "main",
        "status": "Long Findings",
        "keywords": "self-supervised learning;rule learning;relation linking;question answering",
        "authors": "",
        "rating": "",
        "confidence": "3;2;3",
        "correctness": "3;2;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "v15z3FzZGu",
        "title": "Adapter Pruning using Tropical Characterization",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Pruning;Adapters;Parameter Efficient Transfer Learning;Domain Adaptation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3;2",
        "correctness": "3;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "v2wbkddf52",
        "title": "Quality Estimation-Assisted Automatic Post-Editing",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Automaric Post-Editing;Quality Estimation;Multi-task Learning",
        "authors": "",
        "rating": "",
        "confidence": "3;2;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "v6VbokqzvP",
        "title": "R$^3$ Prompting: Review, Rephrase and Resolve for Chain-of-Thought Reasoning in Large Language Models under Noisy Context",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Chain-of-Thought;Large Language Models;Arithmetic Reasoning;Prompt Learning",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "v6hcCtzAWz",
        "title": "Simple Hardware-Efficient PCFGs with Independent Left and Right Productions",
        "track": "main",
        "status": "Short Findings",
        "keywords": "grammar induction;unsupervised parsing;latent variable models",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "v6iM1bO78t",
        "title": "Incorporating Worker Perspectives into MTurk Annotation Practices for NLP",
        "track": "main",
        "status": "Long Main",
        "keywords": "data collection;annotators;mechanical turk;AI ethics;data quality",
        "authors": "",
        "rating": "",
        "confidence": "2;1;4",
        "correctness": "3;3;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "v7JgI9dny2",
        "title": "Simpler neural networks prefer subregular languages",
        "track": "main",
        "status": "Long Findings",
        "keywords": "subregularity;formal language theory;minimum description length;inductive biases",
        "authors": "",
        "rating": "",
        "confidence": "3;3;2",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "v8fRIzqeob",
        "title": "Exploring the Cognitive Knowledge Structure of Large Language Models: An Educational Diagnostic Assessment Approach",
        "track": "main",
        "status": "Short Findings",
        "keywords": "large language models;diagnostic assessment;knowledge structure",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "v9CVjuNlDI",
        "title": "Breaking Boundaries in Retrieval Systems: Unsupervised Domain Adaptation with Denoise-Finetuning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Information Retrieval;Domain adaptation;Denoise-finetuning;Unsupervised",
        "authors": "",
        "rating": "",
        "confidence": "2;1;4;2",
        "correctness": "2;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 2.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "vBZ5eBdrgH",
        "title": "$\\textit{SelectNoise:}$ Unsupervised Noise Injection to Enable Zero-Shot Machine Translation for Extremely Low-resource Languages",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Machine Translation;Low resource languages;Noise Injection;Zero-shot;BPE",
        "authors": "",
        "rating": "",
        "confidence": "5;4;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "vDvFT7IX4O",
        "title": "Tree of Clarifications: Answering Ambiguous Questions with Retrieval-Augmented Large Language Models",
        "track": "main",
        "status": "Short Main",
        "keywords": "Question Answering;Large Language Model;Ambiguous QA;Open-domain QA",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4;3",
        "correctness": "4;4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "vLoSutEAJM",
        "title": "The neural dynamics of word recognition and integration",
        "track": "main",
        "status": "Long Main",
        "keywords": "processing;word recognition;speech comprehension;EEG;neuroscience;cognitive neuroscience;cognitive science;psychology;time series",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "vMpmabFTFw",
        "title": "Learning to Compose Representations of Different Encoder Layers towards Improving Compositional Generalization",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Compositional Generalization;Seq2Seq Models;Machine Translation;Semantic Parsing",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3;4",
        "correctness": "4;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "vOX7Dfwo3v",
        "title": "Symbol tuning improves in-context learning in language models",
        "track": "main",
        "status": "Long Main",
        "keywords": "in-context learning;large language models;natural language processing",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "vR1yERC0Wd",
        "title": "Global Structure Knowledge-Guided Relation Extraction Method for Visually-Rich Document",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Visually-Rich Document;Visual relation extraction",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "vU0KbvQ91x",
        "title": "Learning to Abstract with Nonparametric Variational Information Bottleneck",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Representation Learning;Analysis of Neural Networks;Nonparametric Variational Information Bottleneck;Deep Learning",
        "authors": "",
        "rating": "",
        "confidence": "1;3;2;3;2;3",
        "correctness": "3;3;3;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 2.3333333333333335,
        "correctness_avg": 3.1666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "vVdRgpC1Oh",
        "title": "An Empirical Study of Multimodal Model Merging",
        "track": "main",
        "status": "Long Findings",
        "keywords": "model merging; vision-and-language",
        "authors": "",
        "rating": "",
        "confidence": "3;4;5",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "vVrwnY76W1",
        "title": "Remember what you did so you know what to do next",
        "track": "main",
        "status": "Short Findings",
        "keywords": "large language models;text games",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "vW3TFDUKWl",
        "title": "Mitigating Backdoor Poisoning Attacks through the Lens of Spurious Correlation",
        "track": "main",
        "status": "Long Main",
        "keywords": "backdoor attack;backdoor defence;spurious correlation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "4;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "vWol8k64op",
        "title": "A Dataset for Investigating the Impact of Context for Offensive Language Detection in Tweets",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Offensive Language Detection;Twitter Dataset;Language Resources and Evaluation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4;4",
        "correctness": "4;3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "vWy66avGPR",
        "title": "Perceptual Structure in the absence of grounding: the impact of abstractedness and subjectivity in color language for LLMs",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Color language;grounding;language models",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "2;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "va7nzRsbA4",
        "title": "What Makes Chain-of-Thought Prompting Effective? A Counterfactual Study",
        "track": "main",
        "status": "Long Findings",
        "keywords": "LLMs;Analysis;Chain-of-thought;Reasoning;Prompting;Few-shot Reasoning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "vaKgq549Dy",
        "title": "FactKB: Generalizable Factuality Evaluation using Language Models Enhanced with Factual Knowledge",
        "track": "main",
        "status": "Long Main",
        "keywords": "factuality evaluation;knowledge bases;summarization",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "vdLFYqupHA",
        "title": "Enhancing Uncertainty-Based Hallucination Detection with Stronger Focus",
        "track": "main",
        "status": "Long Main",
        "keywords": "hallucination detection;large language model;text generation",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "vexCLJO7vo",
        "title": "MenatQA: A New Dataset for Testing the Temporal Comprehension and Reasoning Abilities of Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Temporal Reasoning;Large Language Models",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "vg55TCMjbC",
        "title": "Reading Books is Great, But Not if You Are Driving! Visually Grounded Reasoning about Defeasible Commonsense Norms",
        "track": "main",
        "status": "Long Main",
        "keywords": "Multimodal;Commonsense;Dataset;Social Norm;Morality",
        "authors": "",
        "rating": "",
        "confidence": "5;3;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "vgaJRhYVje",
        "title": "Coarse-to-Fine Contrastive Learning in Image-Text-Graph Space for Improved Vision-Language Compositionality",
        "track": "main",
        "status": "Long Main",
        "keywords": "Vision-Language Compositionality;Systematic Generalization;Vision-Language Contrastive Learning;Multimodal Foundation Models",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "vgg3dKoyDH",
        "title": "Analyzing Norm Violations in Live-Stream Chat",
        "track": "main",
        "status": "Long Main",
        "keywords": "Norm Violation;Toxicity Detection;Live Streaming",
        "authors": "",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "4;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "vjTnfxbkaL",
        "title": "Hierarchical Enhancement Framework for Aspect-based Argument Mining",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Aspect-based Argument Mining;Nested Named Entity Recognition;Argument Unit Recognition and Classification;Aspect Term Extraction",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "vkEYzLIdLX",
        "title": "Dolphin: A Challenging and Diverse Benchmark for Arabic NLG",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Arabic language;Dialectal Arabic;NLG benchmark.",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "voBhcwDyPt",
        "title": "On the Risk of Misinformation Pollution with Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large Language Models;Misinformation;Question Answering",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "vooJHgn1Gm",
        "title": "Fidelity-Enriched Contrastive Search: Reconciling the Faithfulness-Diversity Trade-Off in Text Generation",
        "track": "main",
        "status": "Short Main",
        "keywords": "hallucination;faithfulness;decoding",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "vpkEJM9qYR",
        "title": "Unveiling the Multi-Annotation Process: Examining the Influence of Annotation Quantity and Instance Difficulty on Model Performance",
        "track": "main",
        "status": "Long Findings",
        "keywords": "multi-annotation;label-distribution;PVI;annotator-set;$\\mathcal{V}$-Information;entropy;annotation budget;datamaps;cartography",
        "authors": "",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "3;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "vq4BnrPyPb",
        "title": "Knowledge is a Region in Weight Space for Fine-tuned Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Weight space;loss landscape;loss space;finetuning;fine-tune;loss connectivity;basin;minima",
        "authors": "",
        "rating": "",
        "confidence": "4;3;2;4",
        "correctness": "3;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "vscmppXqXE",
        "title": "GEMINI: Controlling The Sentence-Level Summary Style in Abstractive Text Summarization",
        "track": "main",
        "status": "Long Main",
        "keywords": "Text Summarization;Summary Style",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "5;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "vtC3sLXjDY",
        "title": "How Reliable Are AI-Generated-Text Detectors? An Assessment Framework Using Evasive Soft Prompts",
        "track": "main",
        "status": "Long Findings",
        "keywords": "AI-generated-text detection;soft prompts;Large language models",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "vtqfPW6OSm",
        "title": "Linear-Time Modeling of Linguistic Structure: An Order-Theoretic Perspective",
        "track": "main",
        "status": "Long Main",
        "keywords": "structured prediction;dependency parsing;coreference resolution",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "5;5;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 5.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "vuabr8zbCq",
        "title": "Improving the Robustness of Summarization Models by Detecting and Removing Input Noise",
        "track": "main",
        "status": "Long Findings",
        "keywords": "summarization;robustness to noise;safety in ML",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "vvnUi75U9i",
        "title": "Is Explanation the Cure? Misinformation Mitigation in the Short Term and Long Term",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Fake news debunking strategy;misinformation;Counterfactual Explanation;Natural Language Generation;Warning Tag;Longterm study",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "w3hL7wFgb3",
        "title": "We're Afraid Language Models Aren't Modeling Ambiguity",
        "track": "main",
        "status": "Long Main",
        "keywords": "evaluation;semantics;ambiguity",
        "authors": "",
        "rating": "",
        "confidence": "2;4;3;4",
        "correctness": "4;5;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "w4FwmICSHZ",
        "title": "Multitask Multimodal Prompted Training for Interactive Embodied Task Completion",
        "track": "main",
        "status": "Long Main",
        "keywords": "Vision and Language;Embodied AI;Natural Language Interaction",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "w4YwLzuD29",
        "title": "Selecting Key Views for Zero-Shot Entity Linking",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Zero-shot entity linking;Multi-view",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "w8LoOWsbU7",
        "title": "Learning Language-guided Adaptive Hyper-modality Representation for Multimodal Sentiment Analysis",
        "track": "main",
        "status": "Long Main",
        "keywords": "multimodal sentiment analysis;multimodal representation learning",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "wDfXP6uAkR",
        "title": "Towards LLM-driven Dialogue State Tracking",
        "track": "main",
        "status": "Long Main",
        "keywords": "dialogue state tracking;large language models",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "wFILOtxmxU",
        "title": "Syntax-Aware Retrieval Augmented Code Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Code Generation;Retrieval Augmented Generation;Neural-Symbolic",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "wFaBjgGqaL",
        "title": "Conceptual structure coheres in human cognition but not in large language models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Models;Cognitive Science;Semantic Norms;Human conceptual structure;AI conceptual structure",
        "authors": "",
        "rating": "",
        "confidence": "5;4;3",
        "correctness": "5;5;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.666666666666667,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "wKqdk1sOMY",
        "title": "Execution-Based Evaluation for Open-Domain Code Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "code generation;open domain;execution-based evaluation",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "2;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "wRwbv3aWzN",
        "title": "VLIS: Unimodal Language Models Guide Multimodal Language Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "visual-language models;image captioning;multimodal understanding;language model decoding",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "wV44qtTJ61",
        "title": "Prompt-based Logical Semantics Enhancement for Implicit Discourse Relation Recognition",
        "track": "main",
        "status": "Long Main",
        "keywords": "implicit discourse relation recognition;logical semantics enhancement;prompt-based connective prediction;mutual information maximization",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "wWFWwyXElN",
        "title": "LLM-powered Data Augmentation for Enhanced Cross-lingual Performance",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Models;Data Augmentation;Multilingual Commonsense Reasoning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "wWT51dSyBj",
        "title": "Gradient-based Gradual Pruning for Language-Specific Multilingual Neural Machine Translation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Multilingual neural machine translation;language-specific sub-network extraction;model pruning;gradual pruning schedule;gradient-based pruning criterion",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "wYdA8CF94e",
        "title": "HalOmi: A Manually Annotated Benchmark for Multilingual Hallucination and Omission Detection in Machine Translation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Hallucination;Omissions;Dataset;Machine Translation",
        "authors": "",
        "rating": "",
        "confidence": "3;5;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "wZKRStVJJe",
        "title": "Toxicity in chatgpt: Analyzing persona-assigned language models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "AI Safety;Toxicity analysis;LLMs",
        "authors": "",
        "rating": "",
        "confidence": "5;5;4",
        "correctness": "5;5;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "wZmgpJMdb3",
        "title": "DocAsRef: An Empirical Study on Repurposing Reference-based Summary Quality Metrics as Reference-free Metrics",
        "track": "main",
        "status": "Short Findings",
        "keywords": "summarization;evaluation;zero-shot",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "wcgfB88Slx",
        "title": "Explanation Selection Using Unlabeled Data for Chain-of-Thought Prompting",
        "track": "main",
        "status": "Long Main",
        "keywords": "Reasoning; In-Context Learning; Chain-of-Thought; Prompting",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "wcqBfk4jv6",
        "title": "Improving Biomedical Abstractive Summarisation with Knowledge Aggregation from Citation Papers",
        "track": "main",
        "status": "Long Main",
        "keywords": "Biomedical Text Summarisation;Abstractive Summarisation;Knowledge Aggregation;Citation Graph",
        "authors": "",
        "rating": "",
        "confidence": "2;3;4",
        "correctness": "4;4;5",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.333333333333333,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "wiI8ycNfgJ",
        "title": "LLM-FP4: 4-Bit Floating-Point Quantized Transformers",
        "track": "main",
        "status": "Long Main",
        "keywords": "Model Compression;Model Quantization",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4;2",
        "correctness": "3;4;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "wirDXDQwYZ",
        "title": "Pragmatic Reasoning Unlocks Quantifier Semantics for Foundation Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Pragmatic Reasoning;Rational Speech Act;Quantifier Understanding;Generalized Quantifiers",
        "authors": "",
        "rating": "",
        "confidence": "4;2;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "wnE8wDd61Z",
        "title": "Knowledge Graph Compression Enhances Diverse Commonsense Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "commonsense generation;knowledge graph compression",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "wpjRa3d9OJ",
        "title": "Temporal Knowledge Graph Forecasting Without Knowledge Using In-Context Learning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Temporal Knowledge Graph;In-context Learning;Large Language Model",
        "authors": "",
        "rating": "",
        "confidence": "3;4;5",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "wpsbUYi9nN",
        "title": "Large Language Models Know Your Contextual Search Intent: A Prompting Framework for Conversational Search",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Conversational search; passage retrieval; large language models; contextual search intent understanding",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "wrBIS6FOfV",
        "title": "MoqaGPT : Zero-Shot Multi-modal Open-domain Question Answering with Large Language Model",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large Language Model;Multimodal;Open-domain question answering",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "wtqb7pNL4e",
        "title": "Can ChatGPT Assess Human Personalities? A General Evaluation Framework",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Human personality assessment;Large language models;ChatGPT;Myers\u2013Briggs Type Indicator",
        "authors": "",
        "rating": "",
        "confidence": "1;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "wwm55qcNdK",
        "title": "SoulChat: Improving LLMs' Empathy, Listening, and Comfort Abilities through Fine-tuning with Multi-turn Empathy Conversations",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Empathy Conversation;Large Language Model;Mental Health AI;Multi-turn Empathetic Conversation Dataset;Psychological Counseling AI",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "x2W2dKdNI8",
        "title": "Selectively Answering Ambiguous Questions",
        "track": "main",
        "status": "Long Main",
        "keywords": "question answering;calibration;ambiguity",
        "authors": "",
        "rating": "",
        "confidence": "1;4;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "x32rlkzM69",
        "title": "The Past, Present, and Future of Typological Databases in NLP",
        "track": "main",
        "status": "Short Findings",
        "keywords": "typology;typological feature prediction;large language models",
        "authors": "",
        "rating": "",
        "confidence": "4;2;4",
        "correctness": "2;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "x3e1zQ1ub1",
        "title": "In-Context Demonstration Selection with Cross Entropy Difference",
        "track": "main",
        "status": "Long Findings",
        "keywords": "in-context learning;data selection;peft",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "x6aiktiAl8",
        "title": "Compressing and Debiasing Vision-Language Pre-Trained Models for Visual Question Answering",
        "track": "main",
        "status": "Long Main",
        "keywords": "visual question answering;out-of-distribution;robustness;debiasing",
        "authors": "",
        "rating": "",
        "confidence": "4;3;2;3",
        "correctness": "3;3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "x7zquRQfoB",
        "title": "How to Enhance Causal Discrimination of Utterances: A Case on Affective Reasoning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Causal Discrimination;Conversation;Independent Noise;SCM",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "x9BmfezTvD",
        "title": "Debiasing Made State-of-the-art: Revisiting the Simple Seed-based Weak Supervision for Text Classification",
        "track": "main",
        "status": "Long Main",
        "keywords": "text classification;weak supervision;label noise;label bias",
        "authors": "",
        "rating": "",
        "confidence": "2;4;2",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "xCXlOmGimw",
        "title": "Diversity Enhanced Narrative Question Generation for Storybooks",
        "track": "main",
        "status": "Long Main",
        "keywords": "Question Generation;Natural Language Generation;NLP applications",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "5;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "xDfyOL1unK",
        "title": "NovaCOMET: Open Commonsense Foundation Models with Symbolic Knowledge Distillation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Knowledge;Commonsense;Distillation;Model;Symbolic",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "xF6ORNff2k",
        "title": "Adaptive Structure Induction for Aspect-based Sentiment Analysis with Spectral Perspective",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Sentiment analysis;Spectral analysis;Structure induction",
        "authors": "",
        "rating": "",
        "confidence": "5;3;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "xJ3O94DnMZ",
        "title": "Make Your Decision Convincing! A Unified Two-Stage Framework: Self-Attribution and Decision-Making",
        "track": "main",
        "status": "Long Findings",
        "keywords": "rationale;reliable link;two-stage framework",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "xKRg5dfWyv",
        "title": "Bootstrapping Small \\& High Performance Language Models with Unmasking-Removal Training Policy",
        "track": "main",
        "status": "Short Main",
        "keywords": "language models;efficient pre-training;masking policy",
        "authors": "",
        "rating": "",
        "confidence": "2;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "xL8SLt02mt",
        "title": "An Expression Tree Decoding Strategy for Mathematical Equation Generation",
        "track": "main",
        "status": "Long Main",
        "keywords": "Expression tree;Equation;Parallel Decoding;Math Word Problem",
        "authors": "",
        "rating": "",
        "confidence": "3;4;2",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "xMudYCcBum",
        "title": "Using Interpretation Methods for Model Enhancement",
        "track": "main",
        "status": "Long Main",
        "keywords": "interpretation methods;few-shot",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "xNzu8DivUj",
        "title": "Continually Improving Extractive QA via Human Feedback",
        "track": "main",
        "status": "Long Main",
        "keywords": "QA;human feedback;bandit learning",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "xOyBEJq0O8",
        "title": "GATITOS: Using a New Multilingual Lexicon for Low-resource Machine Translation",
        "track": "main",
        "status": "Long Main",
        "keywords": "machine translation;low-resource;lexicons;dictionaries;unsupervised;NMT;MT;data augmentation",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3;4",
        "correctness": "3;3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "xQbFsx8usC",
        "title": "Temporal Knowledge Graph Reasoning Based on N-tuple Modeling",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Knowledge graph;n-ary temporal knowledge graph;graph convolution network",
        "authors": "",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "xVMV2IYbWH",
        "title": "An Adaptive Prompt Generation Framework for Task-oriented Dialogue System",
        "track": "main",
        "status": "Long Findings",
        "keywords": "adaptive prompt;LLM;task-oriented dialogue;black-box;prompt learning",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "2;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "xX2KjzdFPH",
        "title": "Improving Image Captioning via Predicting Structured Concepts",
        "track": "main",
        "status": "Long Main",
        "keywords": "Image captioning;GCN",
        "authors": "",
        "rating": "",
        "confidence": "3;4;5;5",
        "correctness": "3;3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.25,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "xapBkUt0yf",
        "title": "CompoundPiece: Evaluating and Improving Decompounding Performance of Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "segmentation;multilinguality;tokenization;compound;compounds",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "xarWXEhhdy",
        "title": "Self-supervised Meta-Prompt Learning with Meta-Gradient Regularization for Few-shot Generalization",
        "track": "main",
        "status": "Long Findings",
        "keywords": "prompt tuning;self-supervised meta-learning;meta-gradient regularization",
        "authors": "",
        "rating": "",
        "confidence": "4;2;3;3",
        "correctness": "4;3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "xbnNgqGefc",
        "title": "Discourse Structures Guided Fine-grained Propaganda Identification",
        "track": "main",
        "status": "Long Main",
        "keywords": "misinformation;propaganda;discourse structure",
        "authors": "",
        "rating": "",
        "confidence": "4;5;3",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "xeecFHJ4d4",
        "title": "IRFL: Image Recognition of Figurative Language",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Figurative Language;Multimodal Figurative Language;Resources",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "xfTQmGPPtQ",
        "title": "Parameter-efficient Tuning for Large Language Model without Calculating Its Gradients",
        "track": "main",
        "status": "Long Main",
        "keywords": "Parameter-efficient Tuning;Large Language Model;Gradient-free",
        "authors": "",
        "rating": "",
        "confidence": "4;2;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "xhqICRykZk",
        "title": "Text Augmented Spatial Aware Zero-shot Referring Image Segmentation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Zero-shot Referring Image Segmentation;Multi-modal Learning;Visual-text Matching",
        "authors": "",
        "rating": "",
        "confidence": "4;3;2",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "xlg5jVmPSg",
        "title": "Towards A Holistic Landscape of Situated Theory of Mind in Large Language Models",
        "track": "main",
        "status": "Long Findings",
        "keywords": "theory of mind;large language models;mental states",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "xn8NKZosDV",
        "title": "Event Ontology Completion with Hierarchical Structure Evolution Networks",
        "track": "main",
        "status": "Long Main",
        "keywords": "Event Ontology Completion;Event Type Induction;Hierarchy Expansion;Type Naming",
        "authors": "",
        "rating": "",
        "confidence": "5;2;2",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "xozJw0kZXF",
        "title": "Evaluating Object Hallucination in Large Vision-Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Vision-Language Model;Object Hallucination",
        "authors": "",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "xp4wEivhM9",
        "title": "Is a Prestigious Job the same as a Prestigious Country? A Case Study on Multilingual Sentence Embeddings and European Countries",
        "track": "main",
        "status": "Short Findings",
        "keywords": "multilngual language models;nationality bias;sentence representation",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "xxTtwEuOpS",
        "title": "Understanding Compositional Data Augmentation in Typologically Diverse Morphological Inflection",
        "track": "main",
        "status": "Long Main",
        "keywords": "morphological inflection;computational morphology;data augmentation",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "xyvTFX7hDs",
        "title": "Cultural Concept Adaptation on Multimodal Reasoning",
        "track": "main",
        "status": "Long Main",
        "keywords": "Cross-cultural;Adaptation;Low-resource;Multi-modal;Data augmentation",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "xzveggFhiQ",
        "title": "Multi-Modal Knowledge Graph Transformer Framework for Multi-Modal Entity Alignment",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Multi-Modal Entity Alignment;Multi-Modal Knowledge Graph;Transformer",
        "authors": "",
        "rating": "",
        "confidence": "3;3;5",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "y0P5KXN5X1",
        "title": "Factual Relation Discrimination for Factuality-oriented Abstractive Summarization",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Factuality-oriented Abstractive Summarization;Factual Relation Discrimination",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "y2V6YgLaW7",
        "title": "The Internal State of an LLM Knows When It's Lying",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large Language Models;hallucination in LLM;LLM veracity;LLM activations",
        "authors": "",
        "rating": "",
        "confidence": "4;4;3;2",
        "correctness": "4;3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "y34lg6q50A",
        "title": "Fusing Temporal Graphs into Transformers for Time-Sensitive Question Answering",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Time-sensitive Question Answering;Temporal Graph Fusion;Temporal Reasoning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "y5UTUcTQU5",
        "title": "Dual-Channel Span for Aspect Sentiment Triplet Extraction",
        "track": "main",
        "status": "Long Main",
        "keywords": "aspect sentiment triplet extraction;dual-channel;span generation;noise reduction",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "y5ctUSk99X",
        "title": "GPTAraEval: A Comprehensive Evaluation of ChatGPT on Arabic NLP",
        "track": "main",
        "status": "Long Main",
        "keywords": "Arabic NLP;Arabic Dialects;ChatGPT;GPT4",
        "authors": "",
        "rating": "",
        "confidence": "5;4;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "y6Ej5BZkrR",
        "title": "Let's Think Frame by Frame with VIP: A Video Infilling and Prediction Dataset for Evaluating Video Chain-of-Thought",
        "track": "main",
        "status": "Long Main",
        "keywords": "chain of thought;video reasoning;large language models;dataset;vision and language",
        "authors": "",
        "rating": "",
        "confidence": "4;4;2",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "y8ebFPsyET",
        "title": "TESTA: Temporal-Spatial Token Aggregation for Long-form Video-Language Understanding",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Video-Language Understanding;Token Aggregation;Long-form Video Understanding",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "yAZSZob2dN",
        "title": "Boot and Switch: Alternating Distillation for Zero-Shot Dense Retrieval",
        "track": "main",
        "status": "Long Findings",
        "keywords": "dense retrieval;iterated learning;alternating distillation;bootstrapping",
        "authors": "",
        "rating": "",
        "confidence": "4;4;2",
        "correctness": "2;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "yB8cQIICqe",
        "title": "EZ-STANCE: A Large Dataset for Zero-Shot Stance Detection",
        "track": "main",
        "status": "Long Findings",
        "keywords": "dataset;stance detection;zero-shot",
        "authors": "",
        "rating": "",
        "confidence": "3;4;5",
        "correctness": "3;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "yBd2UREDNL",
        "title": "MixTEA: Semi-supervised Entity Alignment with Mixture Teaching",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Knowledge Graph;Entity Alignment;Knowledge Representation",
        "authors": "",
        "rating": "",
        "confidence": "4;3;5",
        "correctness": "3;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "yDeIWA7ICp",
        "title": "Social Commonsense-Guided Search Query Generation for Open-Domain Knowledge-Powered Conversations",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Conversational AI;Knowledge-Powered Dialog;Commonsense Knowledge",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "yE44WcphJY",
        "title": "Dissecting In-Context Learning of Translations in GPT-3",
        "track": "main",
        "status": "Short Findings",
        "keywords": "translation;large language models;in context learning",
        "authors": "",
        "rating": "",
        "confidence": "4;5;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "yF3lSXb82y",
        "title": "InvGC: Robust Cross-Modal Retrieval by Inverse Graph Convolution",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Cross-Modal Retrieval;Data Degeneration;Graph Convolution",
        "authors": "",
        "rating": "",
        "confidence": "5;4;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "yKLUvxMCQ3",
        "title": "Establishing Trustworthiness: Rethinking Tasks and Model Evaluation",
        "track": "main",
        "status": "Short Main",
        "keywords": "Trustworthiness;Tasks;Evaluation;Skills;Trust",
        "authors": "",
        "rating": "",
        "confidence": "4;2;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "yO4cAfFjlp",
        "title": "Theory of Mind for Multi-Agent Collaboration via Large Language Models",
        "track": "main",
        "status": "Long Main",
        "keywords": "Large Language Models;Multi-Agent Reinforcement Learning;Theory of Mind",
        "authors": "",
        "rating": "",
        "confidence": "2;3;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "yThuxNysaJ",
        "title": "DelucionQA: Detecting Hallucinations in Domain-specific Question Answering",
        "track": "main",
        "status": "Long Findings",
        "keywords": "hallucination;LLM;large-language-model;natural-language-generation;question-answering",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "yVoLLzLwdp",
        "title": "Is ChatGPT a Financial Expert? Evaluating Language Models on Financial Natural Language Processing",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Financial Natural Language Processing;Large Language Models;ChatGPT",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "2;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "yXVLsdvyg9",
        "title": "Improving Question Generation with Multi-level Content Planning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "questin generation;multi-level content planning",
        "authors": "",
        "rating": "",
        "confidence": "3;4;5;4",
        "correctness": "2;3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "yXYJPAlLqn",
        "title": "Sparse Universal Transformer",
        "track": "main",
        "status": "Long Main",
        "keywords": "efficient UT;transformers;sparse moe;conditional computation;NLP;wmt14;cfq;compositional generalization;natural language processing;sparse",
        "authors": "",
        "rating": "",
        "confidence": "4;3;4",
        "correctness": "4;5;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ybc9V6Cbq2",
        "title": "Better Quality Pre-training Data and T5 Models for African Languages",
        "track": "main",
        "status": "Short Main",
        "keywords": "multilingual;low-resource languages;african languages",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "3;2;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "yjqgHcTLnP",
        "title": "ARKitSceneRefer: Text-based Localization of Small Objects in Diverse Real-World 3D Indoor Scenes",
        "track": "main",
        "status": "Long Findings",
        "keywords": "3D;Dataset;Visual Grounding;Referring Expression Comprehension",
        "authors": "",
        "rating": "",
        "confidence": "2;5;4",
        "correctness": "3;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.6666666666666665,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "ytQFU2XsBR",
        "title": "Automatic Model Selection with Large Language Models for Reasoning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Large Language Models;In-Context Learning;Reasoning",
        "authors": "",
        "rating": "",
        "confidence": "3;4;4;3",
        "correctness": "4;2;2;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.5,
        "correctness_avg": 2.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "z1RYLqEpuP",
        "title": "Evaluating and Modeling Attribution for Cross-Lingual Question Answering",
        "track": "main",
        "status": "Long Main",
        "keywords": "Attribution;Cross-Lingual Question Answering;Multilingual Modeling;Open-Retrieval Question Answering;Attribution Detection",
        "authors": "",
        "rating": "",
        "confidence": "2;4;4",
        "correctness": "4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "z2JVmJ6Tlq",
        "title": "Self-supervised Post-processing Method to Enrich Pretrained Word Vectors",
        "track": "main",
        "status": "Short Findings",
        "keywords": "Retrofitting;Word Embedding;Word Semantics",
        "authors": "",
        "rating": "",
        "confidence": "2;4;4",
        "correctness": "3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "z69tlSxAwf",
        "title": "Novel Slot Detection With an Incremental Setting",
        "track": "main",
        "status": "Long Findings",
        "keywords": "dialog system; novel slot detection; incremental learning",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4;3",
        "correctness": "3;3;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.75,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "z8gM4ZfK8l",
        "title": "Improving Cross-lingual Transfer through Subtree-aware Word Reordering",
        "track": "main",
        "status": "Long Findings",
        "keywords": "multilingual;cross lingual;cross lingual transfer;reordering;syntax",
        "authors": "",
        "rating": "",
        "confidence": "4;2;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 2.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "z9CqYTwOiO",
        "title": "Solving the Right Problem is Key for Translational NLP: A Case Study in UMLS Vocabulary Insertion",
        "track": "main",
        "status": "Long Findings",
        "keywords": "biomedical NLP;translational NLP;synonymy prediction;knowledge base construction",
        "authors": "",
        "rating": "",
        "confidence": "3;5;4",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "z9l6nHpTyT",
        "title": "Adapter-TST: A Parameter Efficient Method for Multiple-Attribute Text Style Transfer",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Text style transfer;Parameter-efficient;Adapter",
        "authors": "",
        "rating": "",
        "confidence": "4;5;5",
        "correctness": "4;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.666666666666667,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "zByqDt16qZ",
        "title": "Evaluating the Rationale Understanding of Critical Reasoning in Logical Reading Comprehension",
        "track": "main",
        "status": "Long Main",
        "keywords": "natural language understanding;reading comprehension;evaluation;dataset;rationale",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "zEJFYWWmbG",
        "title": "Primacy Effect of ChatGPT",
        "track": "main",
        "status": "Short Main",
        "keywords": "Primacy Effect;ChatGPT;Large Language Models;Natural Language Understanding",
        "authors": "",
        "rating": "",
        "confidence": "4;4;5",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 4.333333333333333,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "zIb2DlqBxm",
        "title": "PHD: Pixel-Based Language Modeling of Historical Documents",
        "track": "main",
        "status": "Long Main",
        "keywords": "Visual language modelling;Historical documents;Multimodal models",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "zIgc1Qeceh",
        "title": "Holistic Inter-Annotator Agreement and Corpus Coherence Estimation in a Large-scale Multilingual Annotation Campaign",
        "track": "main",
        "status": "Long Main",
        "keywords": "persuasion techniques;annotation;inter-annotator agreement;data quality;IAA",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "4;5;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "zLAHDHhgLa",
        "title": "Fine-grained Conversational Decoding via Isotropic and Proximal Search",
        "track": "main",
        "status": "Short Main",
        "keywords": "text generation; dialogue system; decoding strategy",
        "authors": "",
        "rating": "",
        "confidence": "3;3;3",
        "correctness": "4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.0,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "zM3mlyflTt",
        "title": "Approximating Two-Layer Feedforward Networks for Efficient Transformers",
        "track": "main",
        "status": "Long Findings",
        "keywords": "transformers;moe;mixture of experts;pkm;product key memories;approximate computation;efficient transformers;language modelling",
        "authors": "",
        "rating": "",
        "confidence": "2;4;2;3",
        "correctness": "3;4;3;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 2.75,
        "correctness_avg": 3.25,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "zSUOfRVl28",
        "title": "Decoding the Silent Majority: Inducing Belief Augmented Social Graph with Large Language Model for Response Forecasting",
        "track": "main",
        "status": "Long Main",
        "keywords": "Response Forecasting;Social Media;Social Network;Language Model;ChatGPT;Personalization;Response Prediction",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3;3",
        "correctness": "3;4;4;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.25,
        "correctness_avg": 3.75,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "zVi11zjaPe",
        "title": "EIT: Enhanced Interactive Transformer",
        "track": "main",
        "status": "Reject",
        "keywords": "Transformer; Multi-head self-attention; Multi-view learning;",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3;4",
        "correctness": "3;4;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.5,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "zWGDn1AmRH",
        "title": "ReFSQL: A Retrieval-Augmentation Framework for Text-to-SQL Generation",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Text-to-SQL;Retrieval-Augmentation",
        "authors": "",
        "rating": "",
        "confidence": "3;3;4",
        "correctness": "2;3;4",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "zaBPb6Pu21",
        "title": "Chinese Lexical Substitution: Dataset and Method",
        "track": "main",
        "status": "Long Main",
        "keywords": "Lexical substitution;Chinese writing assistance;Substitution generation",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "3;4;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 5.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 3.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "zdMislOLTv",
        "title": "Zero-Shot-BERT-Adapters: a Zero-Shot Pipeline for Unknown Intent Detection",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Zero Shot;Intent Detection;Emerging Intents;BERT;Adapters;NLP;Multiligual",
        "authors": "",
        "rating": "",
        "confidence": "4;2;3",
        "correctness": "3;2;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 1.0,
        "confidence_avg": 3.0,
        "correctness_avg": 2.3333333333333335,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "zeGXjQYhXz",
        "title": "Video-Text Retrieval by Supervised Sparse Multi-Grained Learning",
        "track": "main",
        "status": "Long Findings",
        "keywords": "Video-Text Retrieval;Multimodal Learning",
        "authors": "",
        "rating": "",
        "confidence": "3;4;3",
        "correctness": "1;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "zpayaLaUhL",
        "title": "Absolute Position Embedding Learns Sinusoid-like Waves for Attention Based on Relative Position",
        "track": "main",
        "status": "Long Main",
        "keywords": "position embedding;attention mechanism;Transformer;BERT;RoBERTa",
        "authors": "",
        "rating": "",
        "confidence": "4;3;3",
        "correctness": "5;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 3.3333333333333335,
        "correctness_avg": 4.0,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "zrBrl2iQUr",
        "title": "Crossing the Aisle: Unveiling Partisan and Counter-Partisan Events in News Reporting",
        "track": "main",
        "status": "Short Findings",
        "keywords": "partisan event;media bias",
        "authors": "",
        "rating": "",
        "confidence": "4;4;4",
        "correctness": "3;3;2",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 3.0,
        "confidence_avg": 4.0,
        "correctness_avg": 2.6666666666666665,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    },
    {
        "id": "zwqDROxClj",
        "title": "IAG: Induction-Augmented Generation Framework for Answering Reasoning Questions",
        "track": "main",
        "status": "Long Main",
        "keywords": "Open-domain question answering;Inductive reasoning;Prompting",
        "authors": "",
        "rating": "",
        "confidence": "4;3;5;4",
        "correctness": "4;3;4;3",
        "technical_novelty": "",
        "empirical_novelty": "",
        "presentation": "",
        "rating_avg": 4.0,
        "confidence_avg": 4.0,
        "correctness_avg": 3.5,
        "technical_novelty_avg": 0,
        "empirical_novelty_avg": 0,
        "presentation_avg": 0,
        "corr_rating_confidence": 0,
        "corr_rating_correctness": 0
    }
]